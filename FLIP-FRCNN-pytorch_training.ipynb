{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Code for using FiftyOne to train a Faster RCNN on COCO data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x2b200a1e8d0>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import torchvision.models.detection.roi_heads\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "from dataset import FiftyOneTorchDataset, get_transforms\n",
    "from model import create_model\n",
    "from utils import add_detections\n",
    "\n",
    "from engine import train_model\n",
    "import config\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load full dataset from model zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5crNDNsRWdPT",
    "outputId": "4f3ff734-ca0a-4312-a811-7f84db514fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to 'C:\\Users\\blain\\fiftyone\\coco-2017\\validation' if necessary\n",
      "Found annotations at 'C:\\Users\\blain\\fiftyone\\coco-2017\\raw\\instances_val2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading 'coco-2017' split 'validation'\n",
      " 100% |███████████████| 5000/5000 [14.7s elapsed, 0s remaining, 359.5 samples/s]      \n",
      "Dataset 'coco-2017-validation' created\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x2b23e75dc70>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"800\"\n            src=\"http://localhost:5151/?notebook=true&handleId=6245bf31-8c1d-45e5-a593-a4c025157b61\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lodad in the dataset from the FiftyOne model Zoo\n",
    "fo_dataset = foz.load_zoo_dataset(\"coco-2017\", \"validation\")\n",
    "\n",
    "#needed to calculate image height and width\n",
    "fo_dataset.compute_metadata()\n",
    "\n",
    "session = fo.launch_app(fo_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqU6Ckq4WKHK"
   },
   "source": [
    "For example, cluttered images make it difficult for models to localize objects. We can use FiftyOne to create a view containing only samples with more than, say, 10 objects. You can perform the same operations on views as datasets, so we can create an instance of our PyTorch dataset from this view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kLACOukJFUxd"
   },
   "outputs": [],
   "source": [
    "#if we want to see images with more than 10 items, we can\n",
    "# busy_view = fo_dataset.match(F(\"ground_truth.detections\").length() > 10)\n",
    "# busy_torch_dataset = FiftyOneTorchDataset(busy_view)\n",
    "# session.view = busy_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKsE_7TOWXBE"
   },
   "source": [
    "### Create training and testing views (and corresponding PyTorch datasets) that only contain some items from the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TELK0NWmWrMT",
    "outputId": "8bf582cf-e483-4643-8f6b-7c664a2d6c5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning on 70 samples\n",
      "Testing on 18 samples\n"
     ]
    }
   ],
   "source": [
    "subset = True\n",
    "\n",
    "train_transforms, test_transforms = get_transforms()\n",
    "\n",
    "if subset:\n",
    "    # to filter certain items from the dataset we can\n",
    "    item_list = [\"car\", \"dog\", \"bus\", 'fork', 'tie', 'person']\n",
    "    item_list = ['mouse']\n",
    "    item_view = fo_dataset.filter_labels(\"ground_truth\",\n",
    "            F(\"label\").is_in(item_list))\n",
    "\n",
    "    #session.view = item_view\n",
    "\n",
    "    # split the dataset in train and test set\n",
    "    train_view = item_view.take((len(item_view) * config.TRAIN_TEST_SPLIT), seed=51)\n",
    "    test_view = item_view.exclude([s.id for s in train_view])\n",
    "\n",
    "else:\n",
    "    train_view = fo_dataset.take(len(fo_dataset) * config.TRAIN_TEST_SPLIT)\n",
    "    test_view = fo_dataset.exclude([s.id for s in train_view])\n",
    "    item_list = fo_dataset.distinct(\"ground_truth.detections.label\")\n",
    "\n",
    "print(f'Traning on {len(train_view)} samples')\n",
    "print(f'Testing on {len(test_view)} samples')\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "train_dataset = FiftyOneTorchDataset(train_view, train_transforms,\n",
    "        classes=item_list)\n",
    "evaluation_dataset = FiftyOneTorchDataset(test_view, test_transforms,\n",
    "        classes=item_list)\n",
    "\n",
    "#this is needed for later use, but not for creating the dataset\n",
    "if item_list[0] != 'background':\n",
    "     item_list.insert(0,'background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# # map labels to single vehicle class\n",
    "# vehicle_list = ['car', 'bus', 'truck']\n",
    "# vehicles_map = {c: \"vehicle\" for c in vehicle_list}\n",
    "#\n",
    "# train_map_view = train_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "# test_map_view = test_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "#\n",
    "# # use our dataset and defined transformations\n",
    "# torch_map_dataset = FiftyOneTorchDataset(train_map_view, train_transforms)\n",
    "# torch_map_dataset_test = FiftyOneTorchDataset(test_map_view, test_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5je6lVBWz5r"
   },
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# #to change the loss function, create a new function and implement like below\n",
    "# import torchvision\n",
    "# torchvision.models.detection.roi_heads.fastrcnn_loss = cliprcnn_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blain\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: [0]  [0/2]  eta: 0:00:04  lr: 0.005000  loss: 0.7571 (0.7571)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0000 (0.0000)  loss_objectness: 0.7515 (0.7515)  loss_rpn_box_reg: 0.0055 (0.0055)  time: 2.2715  data: 0.2451  max mem: 8555\n",
      "Training Epoch: [0]  [1/2]  eta: 0:00:02  lr: 0.005000  loss: 0.7571 (0.7607)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0000 (0.0004)  loss_objectness: 0.7515 (0.7534)  loss_rpn_box_reg: 0.0055 (0.0069)  time: 2.0415  data: 0.1590  max mem: 8896\n",
      "Training Epoch: [0] Total time: 0:00:04 (2.0425 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/2]  eta: 0:00:49  model_time: 24.4671 (24.4671)  evaluator_time: 0.1330 (0.1330)  time: 24.6702  data: 0.0670  max mem: 11985\n",
      "Test:  [1/2]  eta: 0:00:13  model_time: 1.5143 (12.9907)  evaluator_time: 0.0460 (0.0895)  time: 13.1528  data: 0.0700  max mem: 11985\n",
      "Test: Total time: 0:00:26 (13.1538 s / it)\n",
      "Averaged stats: model_time: 1.5143 (12.9907)  evaluator_time: 0.0460 (0.0895)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.022\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Testing Epoch: [0]  [0/2]  eta: 0:00:02  lr: 0.005000  loss: 0.6421 (0.6421)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0046 (0.0046)  loss_objectness: 0.6332 (0.6332)  loss_rpn_box_reg: 0.0043 (0.0043)  time: 1.4003  data: 0.0620  max mem: 11985\n",
      "Testing Epoch: [0]  [1/2]  eta: 0:00:01  lr: 0.005000  loss: 0.6384 (0.6403)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0000 (0.0023)  loss_objectness: 0.6319 (0.6326)  loss_rpn_box_reg: 0.0043 (0.0054)  time: 1.4183  data: 0.0640  max mem: 11985\n",
      "Testing Epoch: [0] Total time: 0:00:02 (1.4188 s / it)\n",
      "Training Epoch: [1]  [0/2]  eta: 0:00:03  lr: 0.005000  loss: 0.6456 (0.6456)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0020 (0.0020)  loss_objectness: 0.6354 (0.6354)  loss_rpn_box_reg: 0.0082 (0.0082)  time: 1.8194  data: 0.0660  max mem: 11985\n",
      "Training Epoch: [1]  [1/2]  eta: 0:00:01  lr: 0.005000  loss: 0.5077 (0.5766)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0000 (0.0010)  loss_objectness: 0.5024 (0.5689)  loss_rpn_box_reg: 0.0053 (0.0067)  time: 1.6259  data: 0.0640  max mem: 11985\n",
      "Training Epoch: [1] Total time: 0:00:03 (1.6269 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/2]  eta: 0:00:08  model_time: 4.2167 (4.2166)  evaluator_time: 0.0460 (0.0460)  time: 4.3327  data: 0.0670  max mem: 13458\n",
      "Test:  [1/2]  eta: 0:00:03  model_time: 3.3773 (3.7970)  evaluator_time: 0.0460 (0.0465)  time: 3.9180  data: 0.0720  max mem: 13458\n",
      "Test: Total time: 0:00:07 (3.9185 s / it)\n",
      "Averaged stats: model_time: 3.3773 (3.7970)  evaluator_time: 0.0460 (0.0465)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.027\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Testing Epoch: [1]  [0/2]  eta: 0:00:01  lr: 0.005000  loss: 0.3898 (0.3898)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0037 (0.0037)  loss_objectness: 0.3822 (0.3822)  loss_rpn_box_reg: 0.0039 (0.0039)  time: 0.5461  data: 0.0700  max mem: 13458\n",
      "Testing Epoch: [1]  [1/2]  eta: 0:00:00  lr: 0.005000  loss: 0.3752 (0.3825)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0000 (0.0018)  loss_objectness: 0.3688 (0.3755)  loss_rpn_box_reg: 0.0039 (0.0051)  time: 0.8407  data: 0.0735  max mem: 13458\n",
      "Testing Epoch: [1] Total time: 0:00:01 (0.8417 s / it)\n",
      "Training Epoch: [2]  [0/2]  eta: 0:00:03  lr: 0.005000  loss: 0.3754 (0.3754)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0000 (0.0000)  loss_objectness: 0.3697 (0.3697)  loss_rpn_box_reg: 0.0057 (0.0057)  time: 1.5694  data: 0.0670  max mem: 13458\n",
      "Training Epoch: [2]  [1/2]  eta: 0:00:01  lr: 0.005000  loss: 0.2619 (0.3187)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0000 (0.0017)  loss_objectness: 0.2527 (0.3112)  loss_rpn_box_reg: 0.0057 (0.0057)  time: 1.6929  data: 0.0650  max mem: 13458\n",
      "Training Epoch: [2] Total time: 0:00:03 (1.6944 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/2]  eta: 0:00:03  model_time: 1.7614 (1.7614)  evaluator_time: 0.0470 (0.0470)  time: 1.8824  data: 0.0720  max mem: 13458\n",
      "Test:  [1/2]  eta: 0:00:01  model_time: 1.6644 (1.7129)  evaluator_time: 0.0470 (0.0470)  time: 1.8359  data: 0.0735  max mem: 13458\n",
      "Test: Total time: 0:00:03 (1.8359 s / it)\n",
      "Averaged stats: model_time: 1.6644 (1.7129)  evaluator_time: 0.0470 (0.0470)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Testing Epoch: [2]  [0/2]  eta: 0:00:02  lr: 0.005000  loss: 0.2017 (0.2017)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0019 (0.0019)  loss_objectness: 0.1962 (0.1962)  loss_rpn_box_reg: 0.0035 (0.0035)  time: 1.3923  data: 0.0700  max mem: 13458\n",
      "Testing Epoch: [2]  [1/2]  eta: 0:00:01  lr: 0.005000  loss: 0.1900 (0.1959)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0013 (0.0016)  loss_objectness: 0.1826 (0.1894)  loss_rpn_box_reg: 0.0035 (0.0048)  time: 1.4118  data: 0.0675  max mem: 13458\n",
      "Testing Epoch: [2] Total time: 0:00:02 (1.4123 s / it)\n",
      "Training Epoch: [3]  [0/2]  eta: 0:00:02  lr: 0.005000  loss: 0.2032 (0.2032)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0012 (0.0012)  loss_objectness: 0.1971 (0.1971)  loss_rpn_box_reg: 0.0049 (0.0049)  time: 1.4423  data: 0.0720  max mem: 13458\n",
      "Training Epoch: [3]  [1/2]  eta: 0:00:01  lr: 0.005000  loss: 0.1345 (0.1688)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0012 (0.0024)  loss_objectness: 0.1248 (0.1609)  loss_rpn_box_reg: 0.0049 (0.0055)  time: 1.5443  data: 0.0680  max mem: 13458\n",
      "Training Epoch: [3] Total time: 0:00:03 (1.5453 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/2]  eta: 0:00:03  model_time: 1.6704 (1.6704)  evaluator_time: 0.0470 (0.0470)  time: 1.7864  data: 0.0660  max mem: 13458\n",
      "Test:  [1/2]  eta: 0:00:01  model_time: 1.5934 (1.6319)  evaluator_time: 0.0460 (0.0465)  time: 1.7484  data: 0.0675  max mem: 13458\n",
      "Test: Total time: 0:00:03 (1.7489 s / it)\n",
      "Averaged stats: model_time: 1.5934 (1.6319)  evaluator_time: 0.0460 (0.0465)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Testing Epoch: [3]  [0/2]  eta: 0:00:02  lr: 0.005000  loss: 0.1065 (0.1065)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0034 (0.0034)  loss_objectness: 0.0999 (0.0999)  loss_rpn_box_reg: 0.0033 (0.0033)  time: 1.4013  data: 0.0680  max mem: 13458\n",
      "Testing Epoch: [3]  [1/2]  eta: 0:00:01  lr: 0.005000  loss: 0.0951 (0.1008)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0011 (0.0022)  loss_objectness: 0.0883 (0.0941)  loss_rpn_box_reg: 0.0033 (0.0045)  time: 1.4273  data: 0.0670  max mem: 13458\n",
      "Testing Epoch: [3] Total time: 0:00:02 (1.4283 s / it)\n",
      "Training Epoch: [4]  [0/2]  eta: 0:00:02  lr: 0.005000  loss: 0.1048 (0.1048)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0026 (0.0026)  loss_objectness: 0.0979 (0.0979)  loss_rpn_box_reg: 0.0043 (0.0043)  time: 1.4413  data: 0.0640  max mem: 13458\n",
      "Training Epoch: [4]  [1/2]  eta: 0:00:01  lr: 0.005000  loss: 0.0781 (0.0914)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0026 (0.0026)  loss_objectness: 0.0700 (0.0839)  loss_rpn_box_reg: 0.0043 (0.0049)  time: 1.5293  data: 0.0645  max mem: 13458\n",
      "Training Epoch: [4] Total time: 0:00:03 (1.5303 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/2]  eta: 0:00:03  model_time: 1.6634 (1.6634)  evaluator_time: 0.0460 (0.0460)  time: 1.7814  data: 0.0700  max mem: 13458\n",
      "Test:  [1/2]  eta: 0:00:01  model_time: 1.5443 (1.6039)  evaluator_time: 0.0460 (0.0460)  time: 1.7222  data: 0.0699  max mem: 13458\n",
      "Test: Total time: 0:00:03 (1.7222 s / it)\n",
      "Averaged stats: model_time: 1.5443 (1.6039)  evaluator_time: 0.0460 (0.0460)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Testing Epoch: [4]  [0/2]  eta: 0:00:02  lr: 0.005000  loss: 0.0633 (0.0633)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0018 (0.0018)  loss_objectness: 0.0585 (0.0585)  loss_rpn_box_reg: 0.0030 (0.0030)  time: 1.3893  data: 0.0720  max mem: 13458\n",
      "Testing Epoch: [4]  [1/2]  eta: 0:00:01  lr: 0.005000  loss: 0.0596 (0.0615)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0018 (0.0026)  loss_objectness: 0.0509 (0.0547)  loss_rpn_box_reg: 0.0030 (0.0041)  time: 1.4143  data: 0.0700  max mem: 13458\n",
      "Testing Epoch: [4] Total time: 0:00:02 (1.4148 s / it)\n",
      "Training Epoch: [5]  [0/2]  eta: 0:00:03  lr: 0.005000  loss: 0.0590 (0.0590)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0023 (0.0023)  loss_objectness: 0.0520 (0.0520)  loss_rpn_box_reg: 0.0047 (0.0047)  time: 1.7334  data: 0.0630  max mem: 13458\n",
      "Training Epoch: [5]  [1/2]  eta: 0:00:01  lr: 0.005000  loss: 0.0583 (0.0586)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0023 (0.0038)  loss_objectness: 0.0485 (0.0503)  loss_rpn_box_reg: 0.0043 (0.0045)  time: 1.7679  data: 0.0625  max mem: 13458\n",
      "Training Epoch: [5] Total time: 0:00:03 (1.7684 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/2]  eta: 0:00:03  model_time: 1.6904 (1.6904)  evaluator_time: 0.0460 (0.0460)  time: 1.8064  data: 0.0670  max mem: 13458\n",
      "Test:  [1/2]  eta: 0:00:01  model_time: 1.5574 (1.6239)  evaluator_time: 0.0460 (0.0465)  time: 1.7434  data: 0.0700  max mem: 13458\n",
      "Test: Total time: 0:00:03 (1.7444 s / it)\n",
      "Averaged stats: model_time: 1.5574 (1.6239)  evaluator_time: 0.0460 (0.0465)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Testing Epoch: [5]  [0/2]  eta: 0:00:02  lr: 0.005000  loss: 0.0472 (0.0472)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0028 (0.0028)  loss_objectness: 0.0416 (0.0416)  loss_rpn_box_reg: 0.0028 (0.0028)  time: 1.3933  data: 0.0660  max mem: 13458\n",
      "Testing Epoch: [5]  [1/2]  eta: 0:00:01  lr: 0.005000  loss: 0.0429 (0.0451)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0020 (0.0024)  loss_objectness: 0.0363 (0.0390)  loss_rpn_box_reg: 0.0028 (0.0037)  time: 1.4173  data: 0.0695  max mem: 13458\n",
      "Testing Epoch: [5] Total time: 0:00:02 (1.4183 s / it)\n",
      "Training Epoch: [6]  [0/2]  eta: 0:00:03  lr: 0.005000  loss: 0.0469 (0.0469)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0031 (0.0031)  loss_objectness: 0.0400 (0.0400)  loss_rpn_box_reg: 0.0038 (0.0038)  time: 1.5944  data: 0.0710  max mem: 13458\n",
      "Training Epoch: [6]  [1/2]  eta: 0:00:01  lr: 0.005000  loss: 0.0469 (0.0489)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0031 (0.0038)  loss_objectness: 0.0400 (0.0413)  loss_rpn_box_reg: 0.0038 (0.0039)  time: 1.7004  data: 0.0695  max mem: 13458\n",
      "Training Epoch: [6] Total time: 0:00:03 (1.7014 s / it)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "MODEL_TYPE='CLIP-FRCNN'\n",
    "# CLIP-Backbone-FRCNN creates a FRCNN using CLIP features as the model backbone\n",
    "# CLIP-FRCNN creates a FRCNN using CLIP features as the model backbone, and embeds the rois using CLIP's embedding\n",
    "# Fully custom vanilla uses a pre-trained resnet50 backbone, and generates new anchor generator and roi pooling\n",
    "# Custom-Vanilla uses the pre-trained FRCNN from pytorch and replaces the roi heads only\n",
    "#\n",
    "import clip\n",
    "text_tokens = clip.tokenize([\"This is \" + desc for desc in item_list]).cuda()\n",
    "\n",
    "model = create_model(MODEL_TYPE, text_tokens)\n",
    "test = True\n",
    "\n",
    "\n",
    "if test:\n",
    "    train_model(model, evaluation_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=8)\n",
    "else:\n",
    "    train_model(model, train_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_TYPE='CLIP-Backbone-FRCNN'\n",
    "\n",
    "model = create_model(MODEL_TYPE, classes=item_list)\n",
    "test = False\n",
    "\n",
    "if test:\n",
    "    train_model(model, evaluation_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=2)\n",
    "else:\n",
    "    train_model(model, train_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "acbb3df601244291b8b2fb9ea1137573",
      "32b6ec3046e64d04b4134553dc434fe0",
      "d8c6a316609d4ca5bfee139b93177ef5",
      "a1645bdfb02b42fba268f7000f183639",
      "4a4788a4fd6841788b20cfbf54a3d10b",
      "5d836b94d13e459d82429606496e4d4f",
      "a410071b34034a91aeda7ef1114969c2",
      "c063e7d90f6a4027b53d1b70c8c07742"
     ]
    },
    "id": "bHa6KRbEWuxz",
    "outputId": "3b4ebd0b-aa69-4a4d-b73c-b8cf24d8b461"
   },
   "outputs": [],
   "source": [
    "#train a custom vanilla model so that we can compare and make sure the CLIP FRCNN is comparable\n",
    "# Fully-Custom-Vanilla is most appropriate as it generates the model in a similar fashion\n",
    "MODEL_TYPE = 'Fully-Custom-Vanilla'\n",
    "\n",
    "vanilla_model = create_model(MODEL_TYPE, classes=item_list)\n",
    "train_model(vanilla_model, train_dataset, evaluation_dataset, num_epochs=10, MODEL_TYPE=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj3vLT1eXFnk"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkzG1i3AW1O7",
    "outputId": "ec7971c3-66ef-4a57-e710-248cb53dee8e"
   },
   "outputs": [],
   "source": [
    "add_detections(model, evaluation_dataset, fo_dataset, field_name=\"predictions\")\n",
    "\n",
    "results = fo.evaluate_detections(\n",
    "    test_view,\n",
    "    \"predictions\",\n",
    "    classes=item_list,\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uYdXrhgYdJ_",
    "outputId": "2eb792e9-342f-4dc8-f6c0-e1503d8bf193"
   },
   "outputs": [],
   "source": [
    "results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcJBOM76aJPR",
    "outputId": "ac452527-7608-4e8d-f57e-18a0470acd30"
   },
   "outputs": [],
   "source": [
    "results.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nddFfGSnXo7i"
   },
   "source": [
    "By default, objects are only matched with other objects of the same class. In order to get an interesting confusion matrix, we need to match interclass objects by setting `classwise=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_53aCMna2Vt",
    "outputId": "4db71f31-73e3-4036-f623-efd8e2ac85bf"
   },
   "outputs": [],
   "source": [
    "results_interclass = fo.evaluate_detections(\n",
    "    test_view, \n",
    "    \"predictions\", \n",
    "    classes=item_list,\n",
    "    compute_mAP=True, \n",
    "    classwise=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot = results.plot_pr_curves(classes=item_list)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "Nbqf-NuAZ7Ps",
    "outputId": "571cd947-c94a-4b9a-ed93-2330fbddea7e"
   },
   "outputs": [],
   "source": [
    "results_interclass.plot_confusion_matrix(classes=item_list, include_other=False, include_missing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElSV7tTbYKLr"
   },
   "source": [
    "The [detection evaluation](https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#detections) also added the attributes `eval_fp`, `eval_tp`, and `eval_fn` to every predicted detection indicating if it is a false positive, true positive, or false negative. \n",
    "Let's create a view to find the worst samples by sorting by `eval_fp` using the [FiftyOne App](https://voxel51.com/docs/fiftyone/user_guide/app.html) to visualize the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786,
     "resources": {
      "https://localhost:5151/polling?sessionId=de0b710e-15f8-4c57-ba46-ae7955f716b1": {
       "data": "eyJtZXNzYWdlcyI6IFtdfQ==",
       "headers": [
        [
         "access-control-allow-headers",
         "x-requested-with"
        ],
        [
         "content-type",
         "text/html; charset=UTF-8"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "Pm4Z52rd8AC1",
    "outputId": "62d39076-7ef3-4fe3-95ae-500d0f8f8a3f"
   },
   "outputs": [],
   "source": [
    "session.view = test_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786,
     "resources": {
      "https://localhost:5151/polling?sessionId=ebbc318d-3578-4fb1-9ae7-68596117572b": {
       "data": "eyJtZXNzYWdlcyI6IFtdfQ==",
       "headers": [
        [
         "access-control-allow-headers",
         "x-requested-with"
        ],
        [
         "content-type",
         "text/html; charset=UTF-8"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "njLG0l5K-ucV",
    "outputId": "bda6f02d-d8fe-49be-d212-31e0e70779e3"
   },
   "outputs": [],
   "source": [
    "session.view = test_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReXDVFgLZLtf"
   },
   "source": [
    "It would be best to get this [data reannotated to fix these mistakes](https://towardsdatascience.com/managing-annotation-mistakes-with-fiftyone-and-labelbox-fc6e87b51102), but in the meantime, we can easily remedy this by simply creating a new view that remaps the labels `car`, `truck`, and `bus` all to `vehicle` and then retraining the model with that. This is only possible because we are backing our data in FiftyOne and loading views into PyTorch as needed. Without FiftyOne, the PyTorch dataset class or the underlying data would need to be changed to remap these classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# map labels to single vehicle class\n",
    "vehicle_list = ['car', 'bus', 'truck']\n",
    "vehicles_map = {c: \"vehicle\" for c in vehicle_list}\n",
    "\n",
    "train_map_view = train_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "test_map_view = test_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "torch_map_dataset = FiftyOneTorchDataset(train_map_view, train_transforms)\n",
    "torch_map_dataset_test = FiftyOneTorchDataset(test_map_view, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynRCHQv8XB_v"
   },
   "outputs": [],
   "source": [
    "# Only 2 classes (background and vehicle)\n",
    "MODEL_TYPE = 'Vanilla-FRCNN'\n",
    "vehicle_model = create_model(MODEL_TYPE, num_classes=(len(vehicles_map)+1))\n",
    "train_model(vehicle_model, torch_map_dataset, torch_map_dataset_test, num_epochs=2, MODEL_TYPE=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-mrVOl4XFbp",
    "outputId": "6d8bec76-ebe8-4a36-959a-52bb1aab8498"
   },
   "outputs": [],
   "source": [
    "add_detections(vehicle_model, torch_map_dataset_test, test_map_view, field_name=\"vehicle_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfd3xvhaXhl_",
    "outputId": "d9c4a2fe-538a-4979-c3f8-f5ede0c98aa1"
   },
   "outputs": [],
   "source": [
    "vehicle_results = fo.evaluate_detections(\n",
    "    test_map_view, \n",
    "    \"vehicle_predictions\", \n",
    "    classes=[\"vehicle\"], \n",
    "    eval_key=\"vehicle_eval\", \n",
    "    compute_mAP=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFvddH3rk0NR",
    "outputId": "59572ba2-f9ad-4dd2-e9ac-90877190ff99"
   },
   "outputs": [],
   "source": [
    "vehicle_results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwbhq18sk1PL",
    "outputId": "d6985867-5049-4678-cc88-d5041a0079ed"
   },
   "outputs": [],
   "source": [
    "vehicle_results.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJMAkJbWZ_u1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Due to our ability to easily visualize and manage our dataset with FiftyOne, we were able to spot and take action on a dataset issue that would otherwise have gone unnoticed if we only concerned ourselves with dataset-wide evaluation metrics and fixed dataset representations. Through these efforts, we managed to increase the mAP of the model to 43%.\n",
    "\n",
    "Even though this example workflow may not work in all situations, this kind of class-merging strategy can be effective in cases where more fine-grained discrimination is not called for."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "fiftyone_pytorch_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "torch-frcnn",
   "language": "python",
   "display_name": "torch-frcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "32b6ec3046e64d04b4134553dc434fe0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a4788a4fd6841788b20cfbf54a3d10b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5d836b94d13e459d82429606496e4d4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1645bdfb02b42fba268f7000f183639": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c063e7d90f6a4027b53d1b70c8c07742",
      "placeholder": "​",
      "style": "IPY_MODEL_a410071b34034a91aeda7ef1114969c2",
      "value": " 160M/160M [01:05&lt;00:00, 2.55MB/s]"
     }
    },
    "a410071b34034a91aeda7ef1114969c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acbb3df601244291b8b2fb9ea1137573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8c6a316609d4ca5bfee139b93177ef5",
       "IPY_MODEL_a1645bdfb02b42fba268f7000f183639"
      ],
      "layout": "IPY_MODEL_32b6ec3046e64d04b4134553dc434fe0"
     }
    },
    "c063e7d90f6a4027b53d1b70c8c07742": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8c6a316609d4ca5bfee139b93177ef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d836b94d13e459d82429606496e4d4f",
      "max": 167502836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a4788a4fd6841788b20cfbf54a3d10b",
      "value": 167502836
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}