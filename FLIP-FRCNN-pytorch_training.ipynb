{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Code for using FiftyOne to train a Faster RCNN on COCO data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x151f7079850>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import torchvision.models.detection.roi_heads\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "from dataset import FiftyOneTorchDataset, get_transforms\n",
    "from model import create_model\n",
    "from utils import add_detections\n",
    "\n",
    "from engine import train_model\n",
    "import config\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load full dataset from model zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5crNDNsRWdPT",
    "outputId": "4f3ff734-ca0a-4312-a811-7f84db514fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to 'C:\\Users\\blain\\fiftyone\\coco-2017\\validation' if necessary\n",
      "Found annotations at 'C:\\Users\\blain\\fiftyone\\coco-2017\\raw\\instances_val2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading existing dataset 'coco-2017-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x1518de62520>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"800\"\n            src=\"http://localhost:5151/?notebook=true&handleId=1c087eec-8397-4dd2-be4a-ce637dc13c33\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lodad in the dataset from the FiftyOne model Zoo\n",
    "fo_dataset = foz.load_zoo_dataset(\"coco-2017\", \"validation\")\n",
    "\n",
    "#needed to calculate image height and width\n",
    "fo_dataset.compute_metadata()\n",
    "\n",
    "session = fo.launch_app(fo_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqU6Ckq4WKHK"
   },
   "source": [
    "For example, cluttered images make it difficult for models to localize objects. We can use FiftyOne to create a view containing only samples with more than, say, 10 objects. You can perform the same operations on views as datasets, so we can create an instance of our PyTorch dataset from this view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kLACOukJFUxd"
   },
   "outputs": [],
   "source": [
    "#if we want to see images with more than 10 items, we can\n",
    "# busy_view = fo_dataset.match(F(\"ground_truth.detections\").length() > 10)\n",
    "# busy_torch_dataset = FiftyOneTorchDataset(busy_view)\n",
    "# session.view = busy_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKsE_7TOWXBE"
   },
   "source": [
    "### Create training and testing views (and corresponding PyTorch datasets) that only contain some items from the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TELK0NWmWrMT",
    "outputId": "8bf582cf-e483-4643-8f6b-7c664a2d6c5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning on 4000 samples\n",
      "Testing on 1000 samples\n"
     ]
    }
   ],
   "source": [
    "subset = False\n",
    "\n",
    "train_transforms, test_transforms = get_transforms()\n",
    "\n",
    "if subset:\n",
    "    # to filter certain items from the dataset we can\n",
    "    item_list = [\"car\", \"dog\", \"bus\", 'fork', 'tie', 'person']\n",
    "    item_list = ['bus', 'dog']\n",
    "    item_view = fo_dataset.filter_labels(\"ground_truth\",\n",
    "            F(\"label\").is_in(item_list))\n",
    "\n",
    "    #session.view = item_view\n",
    "\n",
    "    # split the dataset in train and test set\n",
    "    train_view = item_view.take((len(item_view) * config.TRAIN_TEST_SPLIT), seed=51)\n",
    "    test_view = item_view.exclude([s.id for s in train_view])\n",
    "\n",
    "else:\n",
    "    train_view = fo_dataset.take(len(fo_dataset) * config.TRAIN_TEST_SPLIT)\n",
    "    test_view = fo_dataset.exclude([s.id for s in train_view])\n",
    "    item_list = fo_dataset.distinct(\"ground_truth.detections.label\")\n",
    "\n",
    "print(f'Traning on {len(train_view)} samples')\n",
    "print(f'Testing on {len(test_view)} samples')\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "train_dataset = FiftyOneTorchDataset(train_view, train_transforms,\n",
    "        classes=item_list)\n",
    "evaluation_dataset = FiftyOneTorchDataset(test_view, test_transforms,\n",
    "        classes=item_list)\n",
    "\n",
    "#this is needed for later use, but not for creating the dataset\n",
    "if item_list[0] != 'background':\n",
    "     item_list.insert(0,'background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# # map labels to single vehicle class\n",
    "# vehicle_list = ['car', 'bus', 'truck']\n",
    "# vehicles_map = {c: \"vehicle\" for c in vehicle_list}\n",
    "#\n",
    "# train_map_view = train_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "# test_map_view = test_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "#\n",
    "# # use our dataset and defined transformations\n",
    "# torch_map_dataset = FiftyOneTorchDataset(train_map_view, train_transforms)\n",
    "# torch_map_dataset_test = FiftyOneTorchDataset(test_map_view, test_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5je6lVBWz5r"
   },
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# #to change the loss function, create a new function and implement like below\n",
    "# import torchvision\n",
    "# torchvision.models.detection.roi_heads.fastrcnn_loss = cliprcnn_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blain\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: [0]  [   0/2000]  eta: 0:34:44  lr: 0.000010  loss: 0.8216 (0.8216)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0545 (0.0545)  loss_objectness: 0.7490 (0.7490)  loss_rpn_box_reg: 0.0180 (0.0180)  time: 1.0420  data: 0.1370  max mem: 2779\n",
      "Training Epoch: [0]  [  10/2000]  eta: 0:14:42  lr: 0.000060  loss: 0.9044 (0.9838)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0845 (0.0919)  loss_objectness: 0.7285 (0.7303)  loss_rpn_box_reg: 0.0977 (0.1616)  time: 0.4435  data: 0.0724  max mem: 3101\n",
      "Training Epoch: [0]  [  20/2000]  eta: 0:13:19  lr: 0.000110  loss: 1.0105 (1.0031)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0891 (0.1071)  loss_objectness: 0.7152 (0.7122)  loss_rpn_box_reg: 0.1620 (0.1838)  time: 0.3720  data: 0.0632  max mem: 3101\n",
      "Training Epoch: [0]  [  30/2000]  eta: 0:12:54  lr: 0.000160  loss: 0.9538 (0.9851)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0900 (0.1149)  loss_objectness: 0.6652 (0.6905)  loss_rpn_box_reg: 0.1290 (0.1797)  time: 0.3654  data: 0.0601  max mem: 3105\n",
      "Training Epoch: [0]  [  40/2000]  eta: 0:12:35  lr: 0.000210  loss: 0.8082 (0.9282)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0668 (0.1030)  loss_objectness: 0.6061 (0.6609)  loss_rpn_box_reg: 0.1044 (0.1642)  time: 0.3662  data: 0.0587  max mem: 3105\n",
      "Training Epoch: [0]  [  50/2000]  eta: 0:12:24  lr: 0.000260  loss: 0.8082 (0.9195)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0937 (0.1166)  loss_objectness: 0.5373 (0.6327)  loss_rpn_box_reg: 0.1354 (0.1702)  time: 0.3640  data: 0.0591  max mem: 3105\n",
      "Training Epoch: [0]  [  60/2000]  eta: 0:12:14  lr: 0.000310  loss: 0.7852 (0.8833)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1459 (0.1148)  loss_objectness: 0.4693 (0.6027)  loss_rpn_box_reg: 0.1354 (0.1658)  time: 0.3638  data: 0.0599  max mem: 3105\n",
      "Training Epoch: [0]  [  70/2000]  eta: 0:12:06  lr: 0.000360  loss: 0.5805 (0.8451)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1227 (0.1169)  loss_objectness: 0.4081 (0.5695)  loss_rpn_box_reg: 0.0830 (0.1587)  time: 0.3637  data: 0.0626  max mem: 3105\n",
      "Training Epoch: [0]  [  80/2000]  eta: 0:11:57  lr: 0.000410  loss: 0.5248 (0.8151)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1304 (0.1213)  loss_objectness: 0.3390 (0.5409)  loss_rpn_box_reg: 0.0881 (0.1528)  time: 0.3601  data: 0.0611  max mem: 3105\n",
      "Training Epoch: [0]  [  90/2000]  eta: 0:11:50  lr: 0.000460  loss: 0.6206 (0.7983)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1305 (0.1262)  loss_objectness: 0.3391 (0.5202)  loss_rpn_box_reg: 0.1061 (0.1519)  time: 0.3564  data: 0.0587  max mem: 3105\n",
      "Training Epoch: [0]  [ 100/2000]  eta: 0:11:41  lr: 0.000509  loss: 0.6459 (0.7781)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1446 (0.1267)  loss_objectness: 0.3388 (0.4998)  loss_rpn_box_reg: 0.1329 (0.1516)  time: 0.3501  data: 0.0634  max mem: 3105\n",
      "Training Epoch: [0]  [ 110/2000]  eta: 0:11:26  lr: 0.000559  loss: 0.6616 (0.7769)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1446 (0.1366)  loss_objectness: 0.2876 (0.4858)  loss_rpn_box_reg: 0.1518 (0.1545)  time: 0.3214  data: 0.0655  max mem: 3105\n",
      "Training Epoch: [0]  [ 120/2000]  eta: 0:11:13  lr: 0.000609  loss: 0.6537 (0.7633)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1492 (0.1413)  loss_objectness: 0.2812 (0.4714)  loss_rpn_box_reg: 0.1186 (0.1506)  time: 0.3017  data: 0.0715  max mem: 3105\n",
      "Training Epoch: [0]  [ 130/2000]  eta: 0:11:01  lr: 0.000659  loss: 0.5676 (0.7435)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1217 (0.1399)  loss_objectness: 0.2770 (0.4559)  loss_rpn_box_reg: 0.1087 (0.1477)  time: 0.3023  data: 0.0695  max mem: 3105\n",
      "Training Epoch: [0]  [ 140/2000]  eta: 0:10:56  lr: 0.000709  loss: 0.5676 (0.7428)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1600 (0.1435)  loss_objectness: 0.2808 (0.4461)  loss_rpn_box_reg: 0.1167 (0.1532)  time: 0.3216  data: 0.0633  max mem: 3105\n",
      "Training Epoch: [0]  [ 150/2000]  eta: 0:10:47  lr: 0.000759  loss: 0.7028 (0.7452)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2095 (0.1509)  loss_objectness: 0.2964 (0.4363)  loss_rpn_box_reg: 0.1454 (0.1581)  time: 0.3261  data: 0.0659  max mem: 3105\n",
      "Training Epoch: [0]  [ 160/2000]  eta: 0:10:38  lr: 0.000809  loss: 0.7670 (0.7475)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2461 (0.1560)  loss_objectness: 0.2830 (0.4311)  loss_rpn_box_reg: 0.1246 (0.1605)  time: 0.3072  data: 0.0671  max mem: 3105\n",
      "Training Epoch: [0]  [ 170/2000]  eta: 0:10:31  lr: 0.000859  loss: 0.7670 (0.7423)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1685 (0.1584)  loss_objectness: 0.2697 (0.4218)  loss_rpn_box_reg: 0.1246 (0.1621)  time: 0.3092  data: 0.0663  max mem: 3105\n",
      "Training Epoch: [0]  [ 180/2000]  eta: 0:10:31  lr: 0.000909  loss: 0.5538 (0.7329)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1071 (0.1558)  loss_objectness: 0.2607 (0.4143)  loss_rpn_box_reg: 0.1525 (0.1628)  time: 0.3454  data: 0.0632  max mem: 3105\n",
      "Training Epoch: [0]  [ 190/2000]  eta: 0:10:30  lr: 0.000959  loss: 0.4870 (0.7206)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1053 (0.1541)  loss_objectness: 0.2458 (0.4050)  loss_rpn_box_reg: 0.1167 (0.1615)  time: 0.3749  data: 0.0615  max mem: 3105\n",
      "Training Epoch: [0]  [ 200/2000]  eta: 0:10:27  lr: 0.001009  loss: 0.5139 (0.7187)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1313 (0.1546)  loss_objectness: 0.2674 (0.4003)  loss_rpn_box_reg: 0.1137 (0.1639)  time: 0.3641  data: 0.0616  max mem: 3105\n",
      "Training Epoch: [0]  [ 210/2000]  eta: 0:10:24  lr: 0.001059  loss: 0.6545 (0.7139)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1534 (0.1554)  loss_objectness: 0.2860 (0.3953)  loss_rpn_box_reg: 0.1271 (0.1632)  time: 0.3564  data: 0.0620  max mem: 3105\n",
      "Training Epoch: [0]  [ 220/2000]  eta: 0:10:22  lr: 0.001109  loss: 0.4961 (0.7006)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1386 (0.1543)  loss_objectness: 0.2457 (0.3871)  loss_rpn_box_reg: 0.0739 (0.1592)  time: 0.3630  data: 0.0621  max mem: 3105\n",
      "Training Epoch: [0]  [ 230/2000]  eta: 0:10:18  lr: 0.001159  loss: 0.4810 (0.6979)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1688 (0.1577)  loss_objectness: 0.2109 (0.3806)  loss_rpn_box_reg: 0.0696 (0.1597)  time: 0.3553  data: 0.0610  max mem: 3105\n",
      "Training Epoch: [0]  [ 240/2000]  eta: 0:10:15  lr: 0.001209  loss: 0.5972 (0.6955)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1983 (0.1584)  loss_objectness: 0.2189 (0.3750)  loss_rpn_box_reg: 0.1425 (0.1621)  time: 0.3465  data: 0.0610  max mem: 3105\n",
      "Training Epoch: [0]  [ 250/2000]  eta: 0:10:12  lr: 0.001259  loss: 0.5972 (0.6904)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1359 (0.1575)  loss_objectness: 0.2249 (0.3720)  loss_rpn_box_reg: 0.1425 (0.1609)  time: 0.3509  data: 0.0615  max mem: 3105\n",
      "Training Epoch: [0]  [ 260/2000]  eta: 0:10:10  lr: 0.001309  loss: 0.5312 (0.6862)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1235 (0.1580)  loss_objectness: 0.2290 (0.3672)  loss_rpn_box_reg: 0.1193 (0.1609)  time: 0.3638  data: 0.0649  max mem: 3105\n",
      "Training Epoch: [0]  [ 270/2000]  eta: 0:10:07  lr: 0.001359  loss: 0.5705 (0.6854)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1218 (0.1571)  loss_objectness: 0.2752 (0.3649)  loss_rpn_box_reg: 0.1945 (0.1635)  time: 0.3656  data: 0.0673  max mem: 3105\n",
      "Training Epoch: [0]  [ 280/2000]  eta: 0:10:05  lr: 0.001409  loss: 0.6786 (0.6902)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1522 (0.1585)  loss_objectness: 0.2758 (0.3627)  loss_rpn_box_reg: 0.2100 (0.1690)  time: 0.3663  data: 0.0636  max mem: 3105\n",
      "Training Epoch: [0]  [ 290/2000]  eta: 0:10:01  lr: 0.001459  loss: 0.6236 (0.6864)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1664 (0.1580)  loss_objectness: 0.2479 (0.3581)  loss_rpn_box_reg: 0.1622 (0.1703)  time: 0.3668  data: 0.0624  max mem: 3105\n",
      "Training Epoch: [0]  [ 300/2000]  eta: 0:09:59  lr: 0.001508  loss: 0.5479 (0.6821)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1331 (0.1588)  loss_objectness: 0.2349 (0.3548)  loss_rpn_box_reg: 0.1343 (0.1686)  time: 0.3633  data: 0.0614  max mem: 3105\n",
      "Training Epoch: [0]  [ 310/2000]  eta: 0:09:55  lr: 0.001558  loss: 0.4920 (0.6768)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1283 (0.1583)  loss_objectness: 0.2507 (0.3515)  loss_rpn_box_reg: 0.0835 (0.1670)  time: 0.3613  data: 0.0607  max mem: 3105\n",
      "Training Epoch: [0]  [ 320/2000]  eta: 0:09:50  lr: 0.001608  loss: 0.4769 (0.6776)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1646 (0.1602)  loss_objectness: 0.2503 (0.3482)  loss_rpn_box_reg: 0.0835 (0.1692)  time: 0.3361  data: 0.0621  max mem: 3105\n",
      "Training Epoch: [0]  [ 330/2000]  eta: 0:09:48  lr: 0.001658  loss: 0.7407 (0.6790)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1646 (0.1610)  loss_objectness: 0.2484 (0.3461)  loss_rpn_box_reg: 0.1168 (0.1720)  time: 0.3476  data: 0.0640  max mem: 3105\n",
      "Training Epoch: [0]  [ 340/2000]  eta: 0:09:43  lr: 0.001708  loss: 0.6047 (0.6773)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1727 (0.1622)  loss_objectness: 0.2484 (0.3436)  loss_rpn_box_reg: 0.0913 (0.1714)  time: 0.3535  data: 0.0635  max mem: 3105\n",
      "Training Epoch: [0]  [ 350/2000]  eta: 0:09:41  lr: 0.001758  loss: 0.6613 (0.6796)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2015 (0.1640)  loss_objectness: 0.2620 (0.3419)  loss_rpn_box_reg: 0.1805 (0.1737)  time: 0.3526  data: 0.0639  max mem: 3105\n",
      "Training Epoch: [0]  [ 360/2000]  eta: 0:09:39  lr: 0.001808  loss: 0.6374 (0.6762)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2094 (0.1648)  loss_objectness: 0.2620 (0.3391)  loss_rpn_box_reg: 0.1581 (0.1723)  time: 0.3788  data: 0.0631  max mem: 3105\n",
      "Training Epoch: [0]  [ 370/2000]  eta: 0:09:36  lr: 0.001858  loss: 0.5131 (0.6732)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1608 (0.1658)  loss_objectness: 0.2175 (0.3360)  loss_rpn_box_reg: 0.0756 (0.1713)  time: 0.3766  data: 0.0605  max mem: 3105\n",
      "Training Epoch: [0]  [ 380/2000]  eta: 0:09:33  lr: 0.001908  loss: 0.4218 (0.6693)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1513 (0.1666)  loss_objectness: 0.2012 (0.3331)  loss_rpn_box_reg: 0.0743 (0.1696)  time: 0.3681  data: 0.0604  max mem: 3105\n",
      "Training Epoch: [0]  [ 390/2000]  eta: 0:09:30  lr: 0.001958  loss: 0.4865 (0.6671)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1542 (0.1667)  loss_objectness: 0.2071 (0.3305)  loss_rpn_box_reg: 0.0865 (0.1699)  time: 0.3658  data: 0.0606  max mem: 3105\n",
      "Training Epoch: [0]  [ 400/2000]  eta: 0:09:26  lr: 0.002008  loss: 0.5163 (0.6643)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1469 (0.1670)  loss_objectness: 0.2241 (0.3288)  loss_rpn_box_reg: 0.0865 (0.1686)  time: 0.3497  data: 0.0612  max mem: 3105\n",
      "Training Epoch: [0]  [ 410/2000]  eta: 0:09:19  lr: 0.002058  loss: 0.5800 (0.6642)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1722 (0.1678)  loss_objectness: 0.2241 (0.3273)  loss_rpn_box_reg: 0.1098 (0.1691)  time: 0.3096  data: 0.0590  max mem: 3105\n",
      "Training Epoch: [0]  [ 420/2000]  eta: 0:09:14  lr: 0.002108  loss: 0.5986 (0.6622)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1802 (0.1680)  loss_objectness: 0.2482 (0.3259)  loss_rpn_box_reg: 0.1345 (0.1682)  time: 0.3004  data: 0.0585  max mem: 3105\n",
      "Training Epoch: [0]  [ 430/2000]  eta: 0:09:10  lr: 0.002158  loss: 0.6242 (0.6603)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2020 (0.1688)  loss_objectness: 0.2129 (0.3229)  loss_rpn_box_reg: 0.1369 (0.1686)  time: 0.3235  data: 0.0599  max mem: 3105\n",
      "Training Epoch: [0]  [ 440/2000]  eta: 0:09:06  lr: 0.002208  loss: 0.6143 (0.6595)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1965 (0.1695)  loss_objectness: 0.2129 (0.3212)  loss_rpn_box_reg: 0.1217 (0.1688)  time: 0.3365  data: 0.0616  max mem: 3105\n",
      "Training Epoch: [0]  [ 450/2000]  eta: 0:09:03  lr: 0.002258  loss: 0.5833 (0.6580)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1881 (0.1696)  loss_objectness: 0.2370 (0.3191)  loss_rpn_box_reg: 0.1178 (0.1692)  time: 0.3518  data: 0.0644  max mem: 3105\n",
      "Training Epoch: [0]  [ 460/2000]  eta: 0:09:00  lr: 0.002308  loss: 0.4978 (0.6553)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1688 (0.1699)  loss_objectness: 0.1961 (0.3165)  loss_rpn_box_reg: 0.1142 (0.1689)  time: 0.3610  data: 0.0621  max mem: 3105\n",
      "Training Epoch: [0]  [ 470/2000]  eta: 0:08:57  lr: 0.002358  loss: 0.4978 (0.6547)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1915 (0.1702)  loss_objectness: 0.1961 (0.3160)  loss_rpn_box_reg: 0.0942 (0.1685)  time: 0.3627  data: 0.0575  max mem: 3105\n",
      "Training Epoch: [0]  [ 480/2000]  eta: 0:08:53  lr: 0.002408  loss: 0.5111 (0.6545)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1915 (0.1712)  loss_objectness: 0.2664 (0.3149)  loss_rpn_box_reg: 0.0990 (0.1684)  time: 0.3546  data: 0.0580  max mem: 3105\n",
      "Training Epoch: [0]  [ 490/2000]  eta: 0:08:50  lr: 0.002458  loss: 0.5020 (0.6515)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1686 (0.1711)  loss_objectness: 0.2317 (0.3135)  loss_rpn_box_reg: 0.0990 (0.1669)  time: 0.3482  data: 0.0606  max mem: 3105\n",
      "Training Epoch: [0]  [ 500/2000]  eta: 0:08:47  lr: 0.002507  loss: 0.4717 (0.6489)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1499 (0.1707)  loss_objectness: 0.2317 (0.3127)  loss_rpn_box_reg: 0.0858 (0.1655)  time: 0.3583  data: 0.0614  max mem: 3105\n",
      "Training Epoch: [0]  [ 510/2000]  eta: 0:08:43  lr: 0.002557  loss: 0.4661 (0.6446)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1211 (0.1702)  loss_objectness: 0.2197 (0.3104)  loss_rpn_box_reg: 0.0803 (0.1640)  time: 0.3605  data: 0.0604  max mem: 3105\n",
      "Training Epoch: [0]  [ 520/2000]  eta: 0:08:40  lr: 0.002607  loss: 0.4699 (0.6427)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1450 (0.1699)  loss_objectness: 0.2265 (0.3095)  loss_rpn_box_reg: 0.0858 (0.1633)  time: 0.3561  data: 0.0615  max mem: 3105\n",
      "Training Epoch: [0]  [ 530/2000]  eta: 0:08:37  lr: 0.002657  loss: 0.4659 (0.6397)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1406 (0.1702)  loss_objectness: 0.2276 (0.3075)  loss_rpn_box_reg: 0.0774 (0.1620)  time: 0.3595  data: 0.0622  max mem: 3105\n",
      "Training Epoch: [0]  [ 540/2000]  eta: 0:08:33  lr: 0.002707  loss: 0.4659 (0.6368)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1307 (0.1692)  loss_objectness: 0.2246 (0.3062)  loss_rpn_box_reg: 0.0783 (0.1614)  time: 0.3573  data: 0.0608  max mem: 3105\n",
      "Training Epoch: [0]  [ 550/2000]  eta: 0:08:29  lr: 0.002757  loss: 0.4900 (0.6357)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1610 (0.1698)  loss_objectness: 0.2246 (0.3053)  loss_rpn_box_reg: 0.0887 (0.1607)  time: 0.3454  data: 0.0605  max mem: 3105\n",
      "Training Epoch: [0]  [ 560/2000]  eta: 0:08:26  lr: 0.002807  loss: 0.6190 (0.6345)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1951 (0.1698)  loss_objectness: 0.2194 (0.3044)  loss_rpn_box_reg: 0.0851 (0.1602)  time: 0.3471  data: 0.0635  max mem: 3106\n",
      "Training Epoch: [0]  [ 570/2000]  eta: 0:08:23  lr: 0.002857  loss: 0.4713 (0.6314)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1313 (0.1693)  loss_objectness: 0.2194 (0.3032)  loss_rpn_box_reg: 0.0674 (0.1589)  time: 0.3574  data: 0.0644  max mem: 3106\n",
      "Training Epoch: [0]  [ 580/2000]  eta: 0:08:19  lr: 0.002907  loss: 0.5124 (0.6314)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1610 (0.1705)  loss_objectness: 0.2358 (0.3025)  loss_rpn_box_reg: 0.0884 (0.1585)  time: 0.3590  data: 0.0613  max mem: 3106\n",
      "Training Epoch: [0]  [ 590/2000]  eta: 0:08:16  lr: 0.002957  loss: 0.6429 (0.6317)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2773 (0.1718)  loss_objectness: 0.2523 (0.3020)  loss_rpn_box_reg: 0.1054 (0.1579)  time: 0.3537  data: 0.0604  max mem: 3106\n",
      "Training Epoch: [0]  [ 600/2000]  eta: 0:08:12  lr: 0.003007  loss: 0.5289 (0.6295)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2023 (0.1720)  loss_objectness: 0.2164 (0.3005)  loss_rpn_box_reg: 0.0887 (0.1570)  time: 0.3417  data: 0.0598  max mem: 3106\n",
      "Training Epoch: [0]  [ 610/2000]  eta: 0:08:08  lr: 0.003057  loss: 0.5217 (0.6290)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1429 (0.1722)  loss_objectness: 0.2110 (0.2999)  loss_rpn_box_reg: 0.0776 (0.1570)  time: 0.3427  data: 0.0621  max mem: 3106\n",
      "Training Epoch: [0]  [ 620/2000]  eta: 0:08:05  lr: 0.003107  loss: 0.4756 (0.6266)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1429 (0.1722)  loss_objectness: 0.2217 (0.2985)  loss_rpn_box_reg: 0.0708 (0.1560)  time: 0.3521  data: 0.0601  max mem: 3106\n",
      "Training Epoch: [0]  [ 630/2000]  eta: 0:08:01  lr: 0.003157  loss: 0.4756 (0.6271)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1584 (0.1735)  loss_objectness: 0.1933 (0.2973)  loss_rpn_box_reg: 0.1106 (0.1562)  time: 0.3476  data: 0.0573  max mem: 3106\n",
      "Training Epoch: [0]  [ 640/2000]  eta: 0:07:58  lr: 0.003207  loss: 0.5204 (0.6256)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2235 (0.1741)  loss_objectness: 0.1972 (0.2961)  loss_rpn_box_reg: 0.1258 (0.1555)  time: 0.3513  data: 0.0575  max mem: 3106\n",
      "Training Epoch: [0]  [ 650/2000]  eta: 0:07:54  lr: 0.003257  loss: 0.5048 (0.6241)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1866 (0.1741)  loss_objectness: 0.2130 (0.2951)  loss_rpn_box_reg: 0.0999 (0.1549)  time: 0.3563  data: 0.0585  max mem: 3106\n",
      "Training Epoch: [0]  [ 660/2000]  eta: 0:07:51  lr: 0.003307  loss: 0.5105 (0.6232)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1866 (0.1745)  loss_objectness: 0.2337 (0.2944)  loss_rpn_box_reg: 0.0896 (0.1544)  time: 0.3541  data: 0.0593  max mem: 3106\n",
      "Training Epoch: [0]  [ 670/2000]  eta: 0:07:47  lr: 0.003357  loss: 0.5403 (0.6217)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1675 (0.1745)  loss_objectness: 0.2129 (0.2929)  loss_rpn_box_reg: 0.0651 (0.1543)  time: 0.3432  data: 0.0583  max mem: 3106\n",
      "Training Epoch: [0]  [ 680/2000]  eta: 0:07:43  lr: 0.003407  loss: 0.4360 (0.6204)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1645 (0.1748)  loss_objectness: 0.1779 (0.2915)  loss_rpn_box_reg: 0.0650 (0.1542)  time: 0.3400  data: 0.0581  max mem: 3106\n",
      "Training Epoch: [0]  [ 690/2000]  eta: 0:07:40  lr: 0.003457  loss: 0.4360 (0.6188)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1613 (0.1745)  loss_objectness: 0.1779 (0.2906)  loss_rpn_box_reg: 0.0696 (0.1537)  time: 0.3565  data: 0.0605  max mem: 3106\n",
      "Training Epoch: [0]  [ 700/2000]  eta: 0:07:37  lr: 0.003506  loss: 0.4909 (0.6182)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1395 (0.1742)  loss_objectness: 0.2223 (0.2902)  loss_rpn_box_reg: 0.0896 (0.1538)  time: 0.3674  data: 0.0649  max mem: 3106\n",
      "Training Epoch: [0]  [ 710/2000]  eta: 0:07:33  lr: 0.003556  loss: 0.5946 (0.6186)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1657 (0.1745)  loss_objectness: 0.2305 (0.2897)  loss_rpn_box_reg: 0.1306 (0.1545)  time: 0.3579  data: 0.0636  max mem: 3106\n",
      "Training Epoch: [0]  [ 720/2000]  eta: 0:07:30  lr: 0.003606  loss: 0.5946 (0.6167)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1326 (0.1738)  loss_objectness: 0.2305 (0.2891)  loss_rpn_box_reg: 0.1048 (0.1538)  time: 0.3521  data: 0.0622  max mem: 3106\n",
      "Training Epoch: [0]  [ 730/2000]  eta: 0:07:26  lr: 0.003656  loss: 0.4467 (0.6144)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1041 (0.1731)  loss_objectness: 0.1962 (0.2879)  loss_rpn_box_reg: 0.0847 (0.1534)  time: 0.3601  data: 0.0591  max mem: 3106\n",
      "Training Epoch: [0]  [ 740/2000]  eta: 0:07:23  lr: 0.003706  loss: 0.4618 (0.6127)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.0987 (0.1729)  loss_objectness: 0.1962 (0.2870)  loss_rpn_box_reg: 0.0906 (0.1528)  time: 0.3547  data: 0.0586  max mem: 3106\n",
      "Training Epoch: [0]  [ 750/2000]  eta: 0:07:19  lr: 0.003756  loss: 0.5249 (0.6116)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1810 (0.1735)  loss_objectness: 0.2093 (0.2862)  loss_rpn_box_reg: 0.0726 (0.1519)  time: 0.3547  data: 0.0634  max mem: 3106\n",
      "Training Epoch: [0]  [ 760/2000]  eta: 0:07:16  lr: 0.003806  loss: 0.5249 (0.6117)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1930 (0.1742)  loss_objectness: 0.2220 (0.2858)  loss_rpn_box_reg: 0.0726 (0.1517)  time: 0.3647  data: 0.0678  max mem: 3106\n",
      "Training Epoch: [0]  [ 770/2000]  eta: 0:07:12  lr: 0.003856  loss: 0.4745 (0.6109)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1714 (0.1747)  loss_objectness: 0.1961 (0.2848)  loss_rpn_box_reg: 0.0769 (0.1514)  time: 0.3453  data: 0.0636  max mem: 3106\n",
      "Training Epoch: [0]  [ 780/2000]  eta: 0:07:09  lr: 0.003906  loss: 0.4594 (0.6094)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1480 (0.1745)  loss_objectness: 0.1961 (0.2841)  loss_rpn_box_reg: 0.0648 (0.1507)  time: 0.3314  data: 0.0610  max mem: 3106\n",
      "Training Epoch: [0]  [ 790/2000]  eta: 0:07:05  lr: 0.003956  loss: 0.5207 (0.6097)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1480 (0.1753)  loss_objectness: 0.2181 (0.2840)  loss_rpn_box_reg: 0.0811 (0.1503)  time: 0.3516  data: 0.0636  max mem: 3106\n",
      "Training Epoch: [0]  [ 800/2000]  eta: 0:07:01  lr: 0.004006  loss: 0.6130 (0.6095)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2363 (0.1760)  loss_objectness: 0.2216 (0.2833)  loss_rpn_box_reg: 0.1007 (0.1502)  time: 0.3449  data: 0.0624  max mem: 3106\n",
      "Training Epoch: [0]  [ 810/2000]  eta: 0:06:58  lr: 0.004056  loss: 0.5487 (0.6087)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1778 (0.1759)  loss_objectness: 0.2071 (0.2826)  loss_rpn_box_reg: 0.1093 (0.1502)  time: 0.3298  data: 0.0629  max mem: 3106\n",
      "Training Epoch: [0]  [ 820/2000]  eta: 0:06:54  lr: 0.004106  loss: 0.4894 (0.6076)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1576 (0.1756)  loss_objectness: 0.1973 (0.2822)  loss_rpn_box_reg: 0.0729 (0.1498)  time: 0.3429  data: 0.0593  max mem: 3106\n",
      "Training Epoch: [0]  [ 830/2000]  eta: 0:06:51  lr: 0.004156  loss: 0.5587 (0.6068)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1869 (0.1762)  loss_objectness: 0.2364 (0.2816)  loss_rpn_box_reg: 0.0729 (0.1490)  time: 0.3580  data: 0.0625  max mem: 3106\n",
      "Training Epoch: [0]  [ 840/2000]  eta: 0:06:47  lr: 0.004206  loss: 0.5045 (0.6046)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1826 (0.1760)  loss_objectness: 0.2145 (0.2806)  loss_rpn_box_reg: 0.0624 (0.1480)  time: 0.3565  data: 0.0678  max mem: 3106\n",
      "Training Epoch: [0]  [ 850/2000]  eta: 0:06:43  lr: 0.004256  loss: 0.4078 (0.6039)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1362 (0.1761)  loss_objectness: 0.1720 (0.2795)  loss_rpn_box_reg: 0.0776 (0.1483)  time: 0.3434  data: 0.0612  max mem: 3106\n",
      "Training Epoch: [0]  [ 860/2000]  eta: 0:06:40  lr: 0.004306  loss: 0.4187 (0.6026)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1392 (0.1762)  loss_objectness: 0.1868 (0.2788)  loss_rpn_box_reg: 0.0848 (0.1475)  time: 0.3378  data: 0.0597  max mem: 3106\n",
      "Training Epoch: [0]  [ 870/2000]  eta: 0:06:36  lr: 0.004356  loss: 0.5312 (0.6015)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1699 (0.1760)  loss_objectness: 0.1900 (0.2780)  loss_rpn_box_reg: 0.0847 (0.1475)  time: 0.3350  data: 0.0611  max mem: 3106\n",
      "Training Epoch: [0]  [ 880/2000]  eta: 0:06:32  lr: 0.004406  loss: 0.5410 (0.6003)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1739 (0.1763)  loss_objectness: 0.2000 (0.2771)  loss_rpn_box_reg: 0.0847 (0.1470)  time: 0.3345  data: 0.0592  max mem: 3106\n",
      "Training Epoch: [0]  [ 890/2000]  eta: 0:06:29  lr: 0.004456  loss: 0.4296 (0.5995)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1700 (0.1761)  loss_objectness: 0.1799 (0.2761)  loss_rpn_box_reg: 0.0882 (0.1473)  time: 0.3319  data: 0.0578  max mem: 3106\n",
      "Training Epoch: [0]  [ 900/2000]  eta: 0:06:25  lr: 0.004505  loss: 0.5306 (0.5989)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1666 (0.1763)  loss_objectness: 0.1972 (0.2756)  loss_rpn_box_reg: 0.1027 (0.1470)  time: 0.3400  data: 0.0590  max mem: 3106\n",
      "Training Epoch: [0]  [ 910/2000]  eta: 0:06:22  lr: 0.004555  loss: 0.4396 (0.5971)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1351 (0.1757)  loss_objectness: 0.1985 (0.2747)  loss_rpn_box_reg: 0.0670 (0.1467)  time: 0.3530  data: 0.0589  max mem: 3106\n",
      "Training Epoch: [0]  [ 920/2000]  eta: 0:06:18  lr: 0.004605  loss: 0.4901 (0.5965)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1512 (0.1764)  loss_objectness: 0.1845 (0.2740)  loss_rpn_box_reg: 0.0548 (0.1462)  time: 0.3528  data: 0.0589  max mem: 3106\n",
      "Training Epoch: [0]  [ 930/2000]  eta: 0:06:14  lr: 0.004655  loss: 0.5874 (0.5970)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2515 (0.1772)  loss_objectness: 0.2037 (0.2737)  loss_rpn_box_reg: 0.0812 (0.1461)  time: 0.3457  data: 0.0600  max mem: 3106\n",
      "Training Epoch: [0]  [ 940/2000]  eta: 0:06:10  lr: 0.004705  loss: 0.7281 (0.5991)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2710 (0.1789)  loss_objectness: 0.2261 (0.2733)  loss_rpn_box_reg: 0.1479 (0.1469)  time: 0.3116  data: 0.0591  max mem: 3106\n",
      "Training Epoch: [0]  [ 950/2000]  eta: 0:06:07  lr: 0.004755  loss: 0.4714 (0.5969)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2044 (0.1786)  loss_objectness: 0.1854 (0.2722)  loss_rpn_box_reg: 0.0801 (0.1462)  time: 0.3181  data: 0.0590  max mem: 3106\n",
      "Training Epoch: [0]  [ 960/2000]  eta: 0:06:03  lr: 0.004805  loss: 0.3680 (0.5954)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1275 (0.1785)  loss_objectness: 0.1494 (0.2713)  loss_rpn_box_reg: 0.0479 (0.1456)  time: 0.3605  data: 0.0578  max mem: 3106\n",
      "Training Epoch: [0]  [ 970/2000]  eta: 0:06:00  lr: 0.004855  loss: 0.4267 (0.5937)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1515 (0.1783)  loss_objectness: 0.2155 (0.2708)  loss_rpn_box_reg: 0.0523 (0.1447)  time: 0.3641  data: 0.0584  max mem: 3106\n",
      "Training Epoch: [0]  [ 980/2000]  eta: 0:05:56  lr: 0.004905  loss: 0.5507 (0.5945)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2179 (0.1793)  loss_objectness: 0.2304 (0.2704)  loss_rpn_box_reg: 0.0627 (0.1448)  time: 0.3397  data: 0.0600  max mem: 3106\n",
      "Training Epoch: [0]  [ 990/2000]  eta: 0:05:52  lr: 0.004955  loss: 0.5501 (0.5934)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2171 (0.1789)  loss_objectness: 0.2031 (0.2698)  loss_rpn_box_reg: 0.1040 (0.1448)  time: 0.3236  data: 0.0596  max mem: 3106\n",
      "Training Epoch: [0]  [1000/2000]  eta: 0:05:49  lr: 0.005000  loss: 0.4870 (0.5930)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1384 (0.1795)  loss_objectness: 0.1863 (0.2690)  loss_rpn_box_reg: 0.1097 (0.1445)  time: 0.3420  data: 0.0607  max mem: 3106\n",
      "Training Epoch: [0]  [1010/2000]  eta: 0:05:45  lr: 0.005000  loss: 0.5560 (0.5932)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2100 (0.1799)  loss_objectness: 0.1957 (0.2689)  loss_rpn_box_reg: 0.1097 (0.1444)  time: 0.3423  data: 0.0608  max mem: 3106\n",
      "Training Epoch: [0]  [1020/2000]  eta: 0:05:41  lr: 0.005000  loss: 0.5868 (0.5950)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2678 (0.1820)  loss_objectness: 0.2584 (0.2688)  loss_rpn_box_reg: 0.1347 (0.1443)  time: 0.3098  data: 0.0644  max mem: 3106\n",
      "Training Epoch: [0]  [1030/2000]  eta: 0:05:38  lr: 0.005000  loss: 0.5994 (0.5946)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.2470 (0.1824)  loss_objectness: 0.2272 (0.2682)  loss_rpn_box_reg: 0.1043 (0.1440)  time: 0.3124  data: 0.0607  max mem: 3106\n",
      "Training Epoch: [0]  [1040/2000]  eta: 0:05:34  lr: 0.005000  loss: 0.5287 (0.5933)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1903 (0.1823)  loss_objectness: 0.2172 (0.2678)  loss_rpn_box_reg: 0.0617 (0.1432)  time: 0.3398  data: 0.0582  max mem: 3106\n",
      "Training Epoch: [0]  [1050/2000]  eta: 0:05:31  lr: 0.005000  loss: 0.4997 (0.5928)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1618 (0.1825)  loss_objectness: 0.2170 (0.2673)  loss_rpn_box_reg: 0.0647 (0.1431)  time: 0.3469  data: 0.0604  max mem: 3106\n",
      "Training Epoch: [0]  [1060/2000]  eta: 0:05:27  lr: 0.005000  loss: 0.4312 (0.5910)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1733 (0.1823)  loss_objectness: 0.1833 (0.2663)  loss_rpn_box_reg: 0.0596 (0.1424)  time: 0.3481  data: 0.0583  max mem: 3106\n",
      "Training Epoch: [0]  [1070/2000]  eta: 0:05:24  lr: 0.005000  loss: 0.4613 (0.5903)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1433 (0.1819)  loss_objectness: 0.1924 (0.2659)  loss_rpn_box_reg: 0.0596 (0.1424)  time: 0.3475  data: 0.0607  max mem: 3106\n",
      "Training Epoch: [0]  [1080/2000]  eta: 0:05:20  lr: 0.005000  loss: 0.5017 (0.5894)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1212 (0.1820)  loss_objectness: 0.2208 (0.2655)  loss_rpn_box_reg: 0.0581 (0.1419)  time: 0.3490  data: 0.0624  max mem: 3106\n",
      "Training Epoch: [0]  [1090/2000]  eta: 0:05:17  lr: 0.005000  loss: 0.4411 (0.5889)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1293 (0.1821)  loss_objectness: 0.2073 (0.2653)  loss_rpn_box_reg: 0.0538 (0.1415)  time: 0.3485  data: 0.0660  max mem: 3106\n",
      "Training Epoch: [0]  [1100/2000]  eta: 0:05:13  lr: 0.005000  loss: 0.5380 (0.5878)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1639 (0.1821)  loss_objectness: 0.1899 (0.2645)  loss_rpn_box_reg: 0.0671 (0.1412)  time: 0.3484  data: 0.0636  max mem: 3106\n",
      "Training Epoch: [0]  [1110/2000]  eta: 0:05:10  lr: 0.005000  loss: 0.4096 (0.5864)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1817 (0.1822)  loss_objectness: 0.1692 (0.2637)  loss_rpn_box_reg: 0.0524 (0.1405)  time: 0.3578  data: 0.0586  max mem: 3106\n",
      "Training Epoch: [0]  [1120/2000]  eta: 0:05:06  lr: 0.005000  loss: 0.4098 (0.5858)  loss_classifier: 0.0000 (0.0000)  loss_box_reg: 0.1867 (0.1826)  loss_objectness: 0.1692 (0.2630)  loss_rpn_box_reg: 0.0569 (0.1401)  time: 0.3583  data: 0.0643  max mem: 3106\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16848/3491434429.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     15\u001B[0m     \u001B[0mtrain_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevaluation_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevaluation_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mNUM_EPOCHS\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mMODEL_TYPE\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mMODEL_TYPE\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m8\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m     \u001B[0mtrain_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevaluation_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mNUM_EPOCHS\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mMODEL_TYPE\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mMODEL_TYPE\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Git\\TORCH_CLIP_FRCNN_Trainable\\engine.py\u001B[0m in \u001B[0;36mtrain_model\u001B[1;34m(model, train_dataset, validation_dataset, num_epochs, MODEL_TYPE, batch_size)\u001B[0m\n\u001B[0;32m    170\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnum_epochs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    171\u001B[0m         \u001B[1;31m# train for one epoch, printing every 10 iterations\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 172\u001B[1;33m         \u001B[0mtraining_metrics\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_one_epoch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_data_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDEVICE\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprint_freq\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscaler\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mscaler\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    173\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    174\u001B[0m         \u001B[1;31m# if MODEL_TYPE == 'CLIP-FRCNN':  # check that we dont change the weights from the backbone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Git\\TORCH_CLIP_FRCNN_Trainable\\engine.py\u001B[0m in \u001B[0;36mtrain_one_epoch\u001B[1;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler, training)\u001B[0m\n\u001B[0;32m     32\u001B[0m             )\n\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m     \u001B[1;32mfor\u001B[0m \u001B[0mimages\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtargets\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmetric_logger\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlog_every\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprint_freq\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m         \u001B[0mimages\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mimage\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mimages\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m         \u001B[0mtargets\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtargets\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Git\\TORCH_CLIP_FRCNN_Trainable\\utils.py\u001B[0m in \u001B[0;36mlog_every\u001B[1;34m(self, iterable, print_freq, header)\u001B[0m\n\u001B[0;32m    207\u001B[0m             )\n\u001B[0;32m    208\u001B[0m         \u001B[0mMB\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1024.0\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m1024.0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 209\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0mobj\u001B[0m \u001B[1;32min\u001B[0m \u001B[0miterable\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    210\u001B[0m             \u001B[0mdata_time\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mend\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    211\u001B[0m             \u001B[1;32myield\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    519\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    520\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 521\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    522\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    523\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    559\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    560\u001B[0m         \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 561\u001B[1;33m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    562\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    563\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 52\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcollate_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Git\\TORCH_CLIP_FRCNN_Trainable\\utils.py\u001B[0m in \u001B[0;36mcollate_fn\u001B[1;34m(batch)\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalid\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mbad\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mreplace\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m             \u001B[0mbatch\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mbad\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchoice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\random.py\u001B[0m in \u001B[0;36mchoice\u001B[1;34m(self, seq)\u001B[0m\n\u001B[0;32m    344\u001B[0m         \u001B[1;34m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    345\u001B[0m         \u001B[1;31m# raises IndexError if seq is empty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 346\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mseq\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_randbelow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseq\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    347\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    348\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mshuffle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrandom\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "MODEL_TYPE='CLIP-FRCNN'\n",
    "# CLIP-Backbone-FRCNN creates a FRCNN using CLIP features as the model backbone\n",
    "# CLIP-FRCNN creates a FRCNN using CLIP features as the model backbone, and embeds the rois using CLIP's embedding\n",
    "# Fully custom vanilla uses a pre-trained resnet50 backbone, and generates new anchor generator and roi pooling\n",
    "# Custom-Vanilla uses the pre-trained FRCNN from pytorch and replaces the roi heads only\n",
    "#\n",
    "import clip\n",
    "text_tokens = clip.tokenize([\"This is \" + desc for desc in item_list]).cuda()\n",
    "\n",
    "model = create_model(MODEL_TYPE, text_tokens)\n",
    "test = False\n",
    "\n",
    "\n",
    "if test:\n",
    "    train_model(model, evaluation_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=8)\n",
    "else:\n",
    "    train_model(model, train_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_TYPE='CLIP-Backbone-FRCNN'\n",
    "\n",
    "model = create_model(MODEL_TYPE, classes=item_list)\n",
    "test = False\n",
    "\n",
    "if test:\n",
    "    train_model(model, evaluation_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=2)\n",
    "else:\n",
    "    train_model(model, train_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "acbb3df601244291b8b2fb9ea1137573",
      "32b6ec3046e64d04b4134553dc434fe0",
      "d8c6a316609d4ca5bfee139b93177ef5",
      "a1645bdfb02b42fba268f7000f183639",
      "4a4788a4fd6841788b20cfbf54a3d10b",
      "5d836b94d13e459d82429606496e4d4f",
      "a410071b34034a91aeda7ef1114969c2",
      "c063e7d90f6a4027b53d1b70c8c07742"
     ]
    },
    "id": "bHa6KRbEWuxz",
    "outputId": "3b4ebd0b-aa69-4a4d-b73c-b8cf24d8b461"
   },
   "outputs": [],
   "source": [
    "#train a custom vanilla model so that we can compare and make sure the CLIP FRCNN is comparable\n",
    "# Fully-Custom-Vanilla is most appropriate as it generates the model in a similar fashion\n",
    "MODEL_TYPE = 'Fully-Custom-Vanilla'\n",
    "\n",
    "vanilla_model = create_model(MODEL_TYPE, classes=item_list)\n",
    "train_model(vanilla_model, train_dataset, evaluation_dataset, num_epochs=10, MODEL_TYPE=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj3vLT1eXFnk"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkzG1i3AW1O7",
    "outputId": "ec7971c3-66ef-4a57-e710-248cb53dee8e"
   },
   "outputs": [],
   "source": [
    "add_detections(model, evaluation_dataset, fo_dataset, field_name=\"predictions\")\n",
    "\n",
    "results = fo.evaluate_detections(\n",
    "    test_view,\n",
    "    \"predictions\",\n",
    "    classes=item_list,\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uYdXrhgYdJ_",
    "outputId": "2eb792e9-342f-4dc8-f6c0-e1503d8bf193"
   },
   "outputs": [],
   "source": [
    "results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcJBOM76aJPR",
    "outputId": "ac452527-7608-4e8d-f57e-18a0470acd30"
   },
   "outputs": [],
   "source": [
    "results.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nddFfGSnXo7i"
   },
   "source": [
    "By default, objects are only matched with other objects of the same class. In order to get an interesting confusion matrix, we need to match interclass objects by setting `classwise=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_53aCMna2Vt",
    "outputId": "4db71f31-73e3-4036-f623-efd8e2ac85bf"
   },
   "outputs": [],
   "source": [
    "results_interclass = fo.evaluate_detections(\n",
    "    test_view, \n",
    "    \"predictions\", \n",
    "    classes=item_list,\n",
    "    compute_mAP=True, \n",
    "    classwise=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot = results.plot_pr_curves(classes=item_list)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "Nbqf-NuAZ7Ps",
    "outputId": "571cd947-c94a-4b9a-ed93-2330fbddea7e"
   },
   "outputs": [],
   "source": [
    "results_interclass.plot_confusion_matrix(classes=item_list, include_other=False, include_missing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElSV7tTbYKLr"
   },
   "source": [
    "The [detection evaluation](https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#detections) also added the attributes `eval_fp`, `eval_tp`, and `eval_fn` to every predicted detection indicating if it is a false positive, true positive, or false negative. \n",
    "Let's create a view to find the worst samples by sorting by `eval_fp` using the [FiftyOne App](https://voxel51.com/docs/fiftyone/user_guide/app.html) to visualize the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786,
     "resources": {
      "https://localhost:5151/polling?sessionId=de0b710e-15f8-4c57-ba46-ae7955f716b1": {
       "data": "eyJtZXNzYWdlcyI6IFtdfQ==",
       "headers": [
        [
         "access-control-allow-headers",
         "x-requested-with"
        ],
        [
         "content-type",
         "text/html; charset=UTF-8"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "Pm4Z52rd8AC1",
    "outputId": "62d39076-7ef3-4fe3-95ae-500d0f8f8a3f"
   },
   "outputs": [],
   "source": [
    "session.view = test_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786,
     "resources": {
      "https://localhost:5151/polling?sessionId=ebbc318d-3578-4fb1-9ae7-68596117572b": {
       "data": "eyJtZXNzYWdlcyI6IFtdfQ==",
       "headers": [
        [
         "access-control-allow-headers",
         "x-requested-with"
        ],
        [
         "content-type",
         "text/html; charset=UTF-8"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "njLG0l5K-ucV",
    "outputId": "bda6f02d-d8fe-49be-d212-31e0e70779e3"
   },
   "outputs": [],
   "source": [
    "session.view = test_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReXDVFgLZLtf"
   },
   "source": [
    "It would be best to get this [data reannotated to fix these mistakes](https://towardsdatascience.com/managing-annotation-mistakes-with-fiftyone-and-labelbox-fc6e87b51102), but in the meantime, we can easily remedy this by simply creating a new view that remaps the labels `car`, `truck`, and `bus` all to `vehicle` and then retraining the model with that. This is only possible because we are backing our data in FiftyOne and loading views into PyTorch as needed. Without FiftyOne, the PyTorch dataset class or the underlying data would need to be changed to remap these classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# map labels to single vehicle class\n",
    "vehicle_list = ['car', 'bus', 'truck']\n",
    "vehicles_map = {c: \"vehicle\" for c in vehicle_list}\n",
    "\n",
    "train_map_view = train_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "test_map_view = test_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "torch_map_dataset = FiftyOneTorchDataset(train_map_view, train_transforms)\n",
    "torch_map_dataset_test = FiftyOneTorchDataset(test_map_view, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynRCHQv8XB_v"
   },
   "outputs": [],
   "source": [
    "# Only 2 classes (background and vehicle)\n",
    "MODEL_TYPE = 'Vanilla-FRCNN'\n",
    "vehicle_model = create_model(MODEL_TYPE, num_classes=(len(vehicles_map)+1))\n",
    "train_model(vehicle_model, torch_map_dataset, torch_map_dataset_test, num_epochs=2, MODEL_TYPE=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-mrVOl4XFbp",
    "outputId": "6d8bec76-ebe8-4a36-959a-52bb1aab8498"
   },
   "outputs": [],
   "source": [
    "add_detections(vehicle_model, torch_map_dataset_test, test_map_view, field_name=\"vehicle_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfd3xvhaXhl_",
    "outputId": "d9c4a2fe-538a-4979-c3f8-f5ede0c98aa1"
   },
   "outputs": [],
   "source": [
    "vehicle_results = fo.evaluate_detections(\n",
    "    test_map_view, \n",
    "    \"vehicle_predictions\", \n",
    "    classes=[\"vehicle\"], \n",
    "    eval_key=\"vehicle_eval\", \n",
    "    compute_mAP=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFvddH3rk0NR",
    "outputId": "59572ba2-f9ad-4dd2-e9ac-90877190ff99"
   },
   "outputs": [],
   "source": [
    "vehicle_results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwbhq18sk1PL",
    "outputId": "d6985867-5049-4678-cc88-d5041a0079ed"
   },
   "outputs": [],
   "source": [
    "vehicle_results.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJMAkJbWZ_u1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Due to our ability to easily visualize and manage our dataset with FiftyOne, we were able to spot and take action on a dataset issue that would otherwise have gone unnoticed if we only concerned ourselves with dataset-wide evaluation metrics and fixed dataset representations. Through these efforts, we managed to increase the mAP of the model to 43%.\n",
    "\n",
    "Even though this example workflow may not work in all situations, this kind of class-merging strategy can be effective in cases where more fine-grained discrimination is not called for."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "fiftyone_pytorch_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "torch-frcnn",
   "language": "python",
   "display_name": "torch-frcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "32b6ec3046e64d04b4134553dc434fe0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a4788a4fd6841788b20cfbf54a3d10b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5d836b94d13e459d82429606496e4d4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1645bdfb02b42fba268f7000f183639": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c063e7d90f6a4027b53d1b70c8c07742",
      "placeholder": "​",
      "style": "IPY_MODEL_a410071b34034a91aeda7ef1114969c2",
      "value": " 160M/160M [01:05&lt;00:00, 2.55MB/s]"
     }
    },
    "a410071b34034a91aeda7ef1114969c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acbb3df601244291b8b2fb9ea1137573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8c6a316609d4ca5bfee139b93177ef5",
       "IPY_MODEL_a1645bdfb02b42fba268f7000f183639"
      ],
      "layout": "IPY_MODEL_32b6ec3046e64d04b4134553dc434fe0"
     }
    },
    "c063e7d90f6a4027b53d1b70c8c07742": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8c6a316609d4ca5bfee139b93177ef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d836b94d13e459d82429606496e4d4f",
      "max": 167502836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a4788a4fd6841788b20cfbf54a3d10b",
      "value": 167502836
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}