{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZ2cvwpPWXBt",
    "outputId": "6444f42e-7465-4625-e4b1-3c207385fce9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x1eb4ba01850>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "from dataset import FiftyOneTorchDataset\n",
    "from model import create_model\n",
    "from utils import add_detections, get_transforms\n",
    "\n",
    "import config\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(fo.list_datasets())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if len(fo.list_datasets()) > 0:\n",
    "    dataset = fo.load_dataset(\"coco-2017-validation\")\n",
    "    dataset.delete()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to 'C:\\Users\\blain\\fiftyone\\coco-2017\\validation' if necessary\n",
      "Found annotations at 'C:\\Users\\blain\\fiftyone\\coco-2017\\raw\\instances_val2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading 'coco-2017' split 'validation'\n",
      " 100% |███████████████| 5000/5000 [15.7s elapsed, 0s remaining, 332.3 samples/s]      \n",
      "Dataset 'coco-2017-validation' created\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x1eb622058e0>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"800\"\n            src=\"http://localhost:5151/?notebook=true&handleId=22860394-8e6c-4fd0-bf24-dba24a4eebd4\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning on 4000 samples\n",
      "Testing on 1000 samples\n"
     ]
    }
   ],
   "source": [
    "#Load in the dataset from the FiftyOne model Zoo\n",
    "fo_dataset = foz.load_zoo_dataset(\"coco-2017\", \"validation\")\n",
    "\n",
    "#needed to calculate image height and width\n",
    "fo_dataset.compute_metadata()\n",
    "\n",
    "session = fo.launch_app(fo_dataset)\n",
    "\n",
    "subset = False\n",
    "\n",
    "train_transforms, test_transforms = get_transforms()\n",
    "\n",
    "if subset:\n",
    "    # to filter certain items from the dataset we can\n",
    "    item_list = [\"car\", \"dog\", \"bus\", 'fork', 'tie', 'person', 'airplane']\n",
    "    item_list = [\"man\", \"boy\", \"skis\"]\n",
    "    #item_list = ['airplane', 'cat']\n",
    "    item_view = fo_dataset.filter_labels(\"ground_truth\",\n",
    "            F(\"label\").is_in(item_list))\n",
    "\n",
    "    #session.view = item_view\n",
    "\n",
    "    # split the dataset in train and test set\n",
    "    train_view = item_view.take((len(item_view) * config.TRAIN_TEST_SPLIT), seed=51)\n",
    "    test_view = item_view.exclude([s.id for s in train_view])\n",
    "\n",
    "else:\n",
    "    train_view = fo_dataset.take(len(fo_dataset) * config.TRAIN_TEST_SPLIT)\n",
    "    test_view = fo_dataset.exclude([s.id for s in train_view])\n",
    "    item_list = fo_dataset.distinct(\"ground_truth.detections.label\")\n",
    "\n",
    "print(f'Traning on {len(train_view)} samples')\n",
    "print(f'Testing on {len(test_view)} samples')\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "train_dataset = FiftyOneTorchDataset(train_view, train_transforms,\n",
    "        classes=item_list)\n",
    "evaluation_dataset = FiftyOneTorchDataset(test_view, test_transforms,\n",
    "        classes=item_list)\n",
    "\n",
    "# #this is needed for later use, but not for creating the dataset\n",
    "# if item_list[0] != 'background':\n",
    "#      item_list.insert(0,'background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Faster RCNN performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# MODEL_TYPE = 'CLIP-Backbone-FRCNN'\n",
    "# CHECKPOINT_NAME = f'{MODEL_TYPE}_epoch_28.pth'\n",
    "#\n",
    "# if item_list[0] != 'background':\n",
    "#      item_list.insert(0,'background')\n",
    "#\n",
    "# frcnn_model = create_model(MODEL_TYPE, classes=item_list)\n",
    "# checkpoint = torch.load(CHECKPOINT_NAME)\n",
    "# frcnn_model = create_model(MODEL_TYPE, classes=item_list)\n",
    "#\n",
    "# frcnn_model.load_state_dict(checkpoint)\n",
    "# frcnn_model.eval()\n",
    "#\n",
    "# add_detections(frcnn_model, evaluation_dataset, fo_dataset, field_name=\"frcnn_predictions\")\n",
    "#\n",
    "# results = fo.evaluate_detections(\n",
    "#     test_view,\n",
    "#     \"frcnn_predictions\",\n",
    "#     classes=item_list,\n",
    "#     eval_key=\"eval\",\n",
    "#     compute_mAP=True\n",
    "# )\n",
    "# session.view = item_view\n",
    "# print(f'mAP: {results.mAP()}')\n",
    "# results.print_report()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check CLIP FRCNN performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test out the trained CLIP-FRCNN\n",
    "MODEL_TYPE = 'CLIP-RPN'\n",
    "WEIGHTS_NAME = 'rpn'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# tokenize item list for CLIP\n",
    "import clip\n",
    "_, preprocess = clip.load(\"RN50\", device=config.DEVICE)\n",
    "\n",
    "if item_list[0] != '':\n",
    "     item_list.insert(0,' ')\n",
    "\n",
    "text_tokens = clip.tokenize([\"This is \" + desc for desc in item_list]).cuda()\n",
    "\n",
    "CHECKPOINT_NAME = f'{MODEL_TYPE}_{WEIGHTS_NAME}.pth'\n",
    "checkpoint = torch.load(CHECKPOINT_NAME)\n",
    "clip_frcnn_model = create_model(MODEL_TYPE, classes=text_tokens)\n",
    "\n",
    "clip_frcnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "print(f'loaded checkpoint at epoch {epoch}')\n",
    "\n",
    "clip_frcnn_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      " 100% |███████████████| 1000/1000 [2.0m elapsed, 0s remaining, 8.6 samples/s]      \n",
      "Evaluating detections...\n",
      " 100% |███████████████| 1000/1000 [35.2s elapsed, 0s remaining, 27.9 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████| 1000/1000 [1.1m elapsed, 0s remaining, 18.2 samples/s]      \n",
      "mAP: 0.0076217544159791085\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "                     0.00      0.00      0.00         0\n",
      "      airplane       0.01      0.89      0.01        27\n",
      "         apple       0.04      0.17      0.07        60\n",
      "      backpack       0.01      0.07      0.02        86\n",
      "        banana       0.17      0.36      0.23        88\n",
      "  baseball bat       0.01      0.04      0.01        24\n",
      "baseball glove       0.00      0.00      0.00        24\n",
      "          bear       0.04      0.20      0.07        10\n",
      "           bed       0.02      0.63      0.05        49\n",
      "         bench       0.00      0.11      0.01        72\n",
      "       bicycle       0.02      0.36      0.04        67\n",
      "          bird       0.26      0.81      0.40       452\n",
      "          boat       0.00      0.35      0.01        54\n",
      "          book       0.50      0.41      0.45       449\n",
      "        bottle       0.25      0.35      0.29       283\n",
      "          bowl       0.01      0.05      0.02       132\n",
      "      broccoli       0.00      0.00      0.00        72\n",
      "           bus       0.01      0.75      0.03        40\n",
      "          cake       0.16      0.41      0.23       120\n",
      "           car       0.05      0.32      0.09       318\n",
      "        carrot       0.00      0.00      0.00        55\n",
      "           cat       0.04      0.72      0.07        39\n",
      "    cell phone       0.01      0.09      0.03        56\n",
      "         chair       0.05      0.06      0.06       332\n",
      "         clock       0.02      0.34      0.04        53\n",
      "         couch       0.02      0.37      0.04        57\n",
      "           cow       0.35      0.89      0.51       294\n",
      "           cup       0.04      0.11      0.06       183\n",
      "  dining table       0.02      0.09      0.03       141\n",
      "           dog       0.03      0.71      0.06        55\n",
      "         donut       0.00      0.00      0.00        80\n",
      "      elephant       0.06      0.76      0.11       101\n",
      "  fire hydrant       0.04      0.58      0.07        26\n",
      "          fork       0.00      0.02      0.00        50\n",
      "       frisbee       0.00      0.09      0.00        22\n",
      "       giraffe       0.02      0.74      0.05        57\n",
      "    hair drier       0.00      0.00      0.00         1\n",
      "       handbag       0.06      0.04      0.05       112\n",
      "         horse       0.01      0.82      0.03        56\n",
      "       hot dog       0.00      0.11      0.00        19\n",
      "      keyboard       0.07      0.17      0.10        40\n",
      "          kite       0.00      0.00      0.00        69\n",
      "         knife       0.00      0.00      0.00        75\n",
      "        laptop       0.02      0.49      0.03        43\n",
      "     microwave       0.01      0.36      0.02        14\n",
      "    motorcycle       0.03      0.61      0.05        46\n",
      "         mouse       0.00      0.00      0.00        30\n",
      "        orange       0.01      0.08      0.01        48\n",
      "          oven       0.01      0.50      0.01        22\n",
      " parking meter       0.00      0.15      0.00        13\n",
      "        person       0.13      0.08      0.10      2139\n",
      "         pizza       0.02      0.31      0.04        35\n",
      "  potted plant       0.01      0.08      0.01        50\n",
      "  refrigerator       0.01      0.21      0.02        39\n",
      "        remote       0.00      0.02      0.00        60\n",
      "      sandwich       0.05      0.15      0.07        41\n",
      "      scissors       0.02      0.08      0.04        13\n",
      "         sheep       0.01      0.69      0.02        39\n",
      "          sink       0.01      0.26      0.03        53\n",
      "    skateboard       0.01      0.39      0.02        36\n",
      "          skis       0.00      0.00      0.00        32\n",
      "     snowboard       0.00      0.62      0.00        13\n",
      "         spoon       0.00      0.00      0.00        49\n",
      "   sports ball       0.00      0.10      0.00        61\n",
      "     stop sign       0.01      0.62      0.01         8\n",
      "      suitcase       0.07      0.49      0.13       160\n",
      "     surfboard       0.00      0.61      0.01        38\n",
      "    teddy bear       0.08      0.15      0.10        54\n",
      " tennis racket       0.01      0.28      0.02        40\n",
      "           tie       0.04      0.01      0.02        74\n",
      "       toaster       0.00      0.00      0.00         1\n",
      "        toilet       0.02      0.49      0.03        47\n",
      "    toothbrush       0.00      0.00      0.00         9\n",
      " traffic light       0.01      0.17      0.03       119\n",
      "         train       0.01      0.65      0.01        23\n",
      "         truck       0.03      0.38      0.05        71\n",
      "            tv       0.01      0.12      0.02        64\n",
      "      umbrella       0.01      0.39      0.02        56\n",
      "          vase       0.10      0.07      0.08        72\n",
      "    wine glass       0.07      0.04      0.05        68\n",
      "         zebra       0.02      0.92      0.04        48\n",
      "\n",
      "     micro avg       0.03      0.27      0.05      8228\n",
      "     macro avg       0.04      0.29      0.05      8228\n",
      "  weighted avg       0.12      0.27      0.13      8228\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x1eb65e19040>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"800\"\n            src=\"http://localhost:5151/?notebook=true&handleId=d943f5cb-7a2f-4f05-9206-cf2ca5782a35\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find performance without clustering\n",
    "add_detections(clip_frcnn_model, evaluation_dataset, fo_dataset, field_name=\"clip_RPN_predictions_no_clustering\", PRED_CLUSTERING=False)\n",
    "\n",
    "results = fo.evaluate_detections(\n",
    "    test_view,\n",
    "    \"clip_RPN_predictions_no_clustering\",\n",
    "    classes=item_list,\n",
    "    eval_key=\"clip_eval_no_clustering\",\n",
    "    compute_mAP=True\n",
    ")\n",
    "\n",
    "print(f'mAP: {results.mAP()}')\n",
    "results.print_report()\n",
    "\n",
    "session.view = test_view"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoint at epoch 23\n",
      "Using device cuda\n",
      "   0% |/--------------|    1/1000 [314.5ms elapsed, 5.2m remaining, 3.2 samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blain\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 1000/1000 [2.1m elapsed, 0s remaining, 8.4 samples/s]      \n",
      "Evaluating detections...\n",
      " 100% |███████████████| 1000/1000 [6.7s elapsed, 0s remaining, 149.3 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████| 1000/1000 [10.2s elapsed, 0s remaining, 97.9 samples/s]      \n",
      "mAP: 0.010486062785356395\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "                     0.00      0.00      0.00         0\n",
      "      airplane       0.03      0.37      0.05        27\n",
      "         apple       0.06      0.06      0.06        54\n",
      "      backpack       0.00      0.00      0.00        86\n",
      "        banana       0.20      0.08      0.12        61\n",
      "  baseball bat       0.05      0.04      0.04        24\n",
      "baseball glove       0.00      0.00      0.00        24\n",
      "          bear       0.12      0.10      0.11        10\n",
      "           bed       0.14      0.33      0.20        49\n",
      "         bench       0.01      0.03      0.01        72\n",
      "       bicycle       0.09      0.09      0.09        66\n",
      "          bird       0.13      0.09      0.11       124\n",
      "          boat       0.00      0.00      0.00        54\n",
      "          book       0.30      0.05      0.08       296\n",
      "        bottle       0.17      0.04      0.07       205\n",
      "          bowl       0.03      0.02      0.02       132\n",
      "      broccoli       0.00      0.00      0.00        72\n",
      "           bus       0.11      0.53      0.18        40\n",
      "          cake       0.22      0.08      0.11        90\n",
      "           car       0.15      0.06      0.09       310\n",
      "        carrot       0.00      0.00      0.00        55\n",
      "           cat       0.32      0.56      0.41        39\n",
      "    cell phone       0.02      0.02      0.02        56\n",
      "         chair       0.20      0.02      0.04       332\n",
      "         clock       0.13      0.11      0.12        53\n",
      "         couch       0.07      0.12      0.09        57\n",
      "           cow       0.19      0.15      0.17        62\n",
      "           cup       0.16      0.05      0.08       183\n",
      "  dining table       0.05      0.03      0.04       141\n",
      "           dog       0.13      0.35      0.19        55\n",
      "         donut       0.00      0.00      0.00        80\n",
      "      elephant       0.30      0.27      0.29        81\n",
      "  fire hydrant       0.10      0.15      0.12        26\n",
      "          fork       0.00      0.00      0.00        50\n",
      "       frisbee       0.01      0.05      0.02        22\n",
      "       giraffe       0.21      0.19      0.20        57\n",
      "    hair drier       0.00      0.00      0.00         1\n",
      "       handbag       0.17      0.03      0.05       112\n",
      "         horse       0.12      0.32      0.17        56\n",
      "       hot dog       0.00      0.00      0.00        19\n",
      "      keyboard       0.20      0.10      0.13        40\n",
      "          kite       0.00      0.00      0.00        69\n",
      "         knife       0.00      0.00      0.00        75\n",
      "        laptop       0.14      0.30      0.19        43\n",
      "     microwave       0.06      0.29      0.09        14\n",
      "    motorcycle       0.16      0.22      0.19        46\n",
      "         mouse       0.00      0.00      0.00        30\n",
      "        orange       0.05      0.08      0.06        48\n",
      "          oven       0.01      0.09      0.02        22\n",
      " parking meter       0.00      0.00      0.00        13\n",
      "        person       0.38      0.04      0.07      2098\n",
      "         pizza       0.21      0.29      0.24        35\n",
      "  potted plant       0.05      0.08      0.06        50\n",
      "  refrigerator       0.01      0.03      0.01        39\n",
      "        remote       0.01      0.02      0.02        60\n",
      "      sandwich       0.30      0.17      0.22        41\n",
      "      scissors       0.20      0.08      0.11        13\n",
      "         sheep       0.01      0.08      0.01        37\n",
      "          sink       0.06      0.08      0.07        53\n",
      "    skateboard       0.01      0.03      0.02        36\n",
      "          skis       0.00      0.00      0.00        32\n",
      "     snowboard       0.01      0.08      0.01        13\n",
      "         spoon       0.00      0.00      0.00        49\n",
      "   sports ball       0.01      0.03      0.01        61\n",
      "     stop sign       0.03      0.25      0.06         8\n",
      "      suitcase       0.05      0.07      0.06        95\n",
      "     surfboard       0.02      0.11      0.03        38\n",
      "    teddy bear       0.29      0.07      0.12        54\n",
      " tennis racket       0.05      0.07      0.06        40\n",
      "           tie       0.00      0.00      0.00        74\n",
      "       toaster       0.00      0.00      0.00         1\n",
      "        toilet       0.10      0.19      0.13        47\n",
      "    toothbrush       0.00      0.00      0.00         9\n",
      " traffic light       0.06      0.05      0.05       119\n",
      "         train       0.03      0.43      0.06        23\n",
      "         truck       0.17      0.20      0.19        71\n",
      "            tv       0.06      0.09      0.07        64\n",
      "      umbrella       0.05      0.18      0.08        56\n",
      "          vase       0.27      0.04      0.07        72\n",
      "    wine glass       0.30      0.04      0.08        68\n",
      "         zebra       0.05      0.17      0.08        48\n",
      "\n",
      "     micro avg       0.07      0.07      0.07      7237\n",
      "     macro avg       0.09      0.10      0.07      7237\n",
      "  weighted avg       0.19      0.07      0.07      7237\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x1eb6a23c400>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"800\"\n            src=\"http://localhost:5151/?notebook=true&handleId=d9a07107-c59c-4b1e-b6f8-79d9f922c301\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test out the trained CLIP-FRCNN with pred_clustering\n",
    "\n",
    "add_detections(clip_frcnn_model, evaluation_dataset, fo_dataset, field_name=\"clip_RPN_predictions_with_clustering\", PRED_CLUSTERING=True)\n",
    "\n",
    "results = fo.evaluate_detections(\n",
    "    test_view,\n",
    "    \"clip_RPN_predictions_with_clustering\",\n",
    "    classes=item_list,\n",
    "    eval_key=\"clip_eval_with_clustering\",\n",
    "    compute_mAP=True\n",
    ")\n",
    "\n",
    "print(f'mAP: {results.mAP()}')\n",
    "results.print_report()\n",
    "\n",
    "session.view = test_view"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "fiftyone_pytorch_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "torch-frcnn",
   "language": "python",
   "display_name": "torch-frcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "32b6ec3046e64d04b4134553dc434fe0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a4788a4fd6841788b20cfbf54a3d10b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5d836b94d13e459d82429606496e4d4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1645bdfb02b42fba268f7000f183639": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c063e7d90f6a4027b53d1b70c8c07742",
      "placeholder": "​",
      "style": "IPY_MODEL_a410071b34034a91aeda7ef1114969c2",
      "value": " 160M/160M [01:05&lt;00:00, 2.55MB/s]"
     }
    },
    "a410071b34034a91aeda7ef1114969c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acbb3df601244291b8b2fb9ea1137573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8c6a316609d4ca5bfee139b93177ef5",
       "IPY_MODEL_a1645bdfb02b42fba268f7000f183639"
      ],
      "layout": "IPY_MODEL_32b6ec3046e64d04b4134553dc434fe0"
     }
    },
    "c063e7d90f6a4027b53d1b70c8c07742": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8c6a316609d4ca5bfee139b93177ef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d836b94d13e459d82429606496e4d4f",
      "max": 167502836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a4788a4fd6841788b20cfbf54a3d10b",
      "value": 167502836
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}