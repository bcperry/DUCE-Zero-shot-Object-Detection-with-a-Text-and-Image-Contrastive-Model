{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Code for using FiftyOne to train a Faster RCNN on COCO data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZ2cvwpPWXBt",
    "outputId": "6444f42e-7465-4625-e4b1-3c207385fce9",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x146332ad850>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "from dataset import FiftyOneTorchDataset, get_transforms\n",
    "from model import create_model\n",
    "from utils import add_detections\n",
    "\n",
    "from engine import train_model\n",
    "import config\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load full dataset from model zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5crNDNsRWdPT",
    "outputId": "4f3ff734-ca0a-4312-a811-7f84db514fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to 'C:\\Users\\blain\\fiftyone\\coco-2017\\validation' if necessary\n",
      "Downloading annotations to 'C:\\Users\\blain\\fiftyone\\coco-2017\\tmp-download\\annotations_trainval2017.zip'\n",
      " 100% |██████|    1.9Gb/1.9Gb [16.0s elapsed, 0s remaining, 109.0Mb/s]      \n",
      "Extracting annotations to 'C:\\Users\\blain\\fiftyone\\coco-2017\\raw\\instances_val2017.json'\n",
      "Downloading images to 'C:\\Users\\blain\\fiftyone\\coco-2017\\tmp-download\\val2017.zip'\n",
      " 100% |██████|    6.1Gb/6.1Gb [58.6s elapsed, 0s remaining, 109.3Mb/s]      \n",
      "Extracting images to 'C:\\Users\\blain\\fiftyone\\coco-2017\\validation\\data'\n",
      "Writing annotations to 'C:\\Users\\blain\\fiftyone\\coco-2017\\validation\\labels.json'\n",
      "Dataset info written to 'C:\\Users\\blain\\fiftyone\\coco-2017\\info.json'\n",
      "Loading 'coco-2017' split 'validation'\n",
      "                                                                                      \r"
     ]
    }
   ],
   "source": [
    "#Lodad in the dataset from the FiftyOne model Zoo\n",
    "fo_dataset = foz.load_zoo_dataset(\"coco-2017\", \"validation\")\n",
    "\n",
    "#needed to calculate image height and width\n",
    "fo_dataset.compute_metadata()\n",
    "\n",
    "session = fo.launch_app(fo_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqU6Ckq4WKHK"
   },
   "source": [
    "For example, cluttered images make it difficult for models to localize objects. We can use FiftyOne to create a view containing only samples with more than, say, 10 objects. You can perform the same operations on views as datasets, so we can create an instance of our PyTorch dataset from this view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kLACOukJFUxd"
   },
   "outputs": [],
   "source": [
    "#if we want to see images with more than 10 items, we can\n",
    "# busy_view = fo_dataset.match(F(\"ground_truth.detections\").length() > 10)\n",
    "# busy_torch_dataset = FiftyOneTorchDataset(busy_view)\n",
    "# session.view = busy_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKsE_7TOWXBE"
   },
   "source": [
    "### Create training and testing views (and corresponding PyTorch datasets) that only contain some items from the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TELK0NWmWrMT",
    "outputId": "8bf582cf-e483-4643-8f6b-7c664a2d6c5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning on 2458 samples\n",
      "Testing on 615 samples\n"
     ]
    }
   ],
   "source": [
    "# to filter certain items from the dataset we can\n",
    "item_list = [\"car\", \"dog\", \"bus\", 'fork', 'tie', 'person']\n",
    "item_view = fo_dataset.filter_labels(\"ground_truth\",\n",
    "        F(\"label\").is_in(item_list))\n",
    "\n",
    "#session.view = item_view\n",
    "\n",
    "# split the dataset in train and test set\n",
    "train_view = item_view.take((len(item_view) * config.TRAIN_TEST_SPLIT), seed=51)\n",
    "test_view = item_view.exclude([s.id for s in train_view])\n",
    "\n",
    "print(f'Traning on {len(train_view)} samples')\n",
    "print(f'Testing on {len(test_view)} samples')\n",
    "\n",
    "\n",
    "train_transforms, test_transforms = get_transforms()\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "train_dataset = FiftyOneTorchDataset(train_view, train_transforms,\n",
    "        classes=item_list)\n",
    "evaluation_dataset = FiftyOneTorchDataset(test_view, test_transforms,\n",
    "        classes=item_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5je6lVBWz5r"
   },
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20840/3819277074.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_TYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluation_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMODEL_TYPE\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMODEL_TYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Git\\TORCH_CLIP_FRCNN_Trainable\\engine.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_dataset, validation_dataset, num_epochs, MODEL_TYPE)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;31m# train for one epoch, printing every 10 iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mtraining_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mMODEL_TYPE\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'CLIP-FRCNN'\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# check that we dont change the weights from the backbone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Git\\TORCH_CLIP_FRCNN_Trainable\\engine.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler, training)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaler\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mloss_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0moriginal_image_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0moriginal_image_sizes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0moriginal_image_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0moriginal_image_sizes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.3.2\\plugins\\python\\helpers\\pydev\\pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_wait_suspend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.3.2\\plugins\\python\\helpers\\pydev\\pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001b[0m\n\u001b[0;32m   1160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1162\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MODEL_TYPE='CLIP-FRCNN'\n",
    "\n",
    "# CLIP-FRCNN creates a FRCNN using CLIP features as the model backbone\n",
    "# Fully custom vanilla uses a pre-trained resnet50 backbone, and generates new anchor generator and roi pooling\n",
    "# Custom-Vanilla uses the pre-trained FRCNN from pytorch and replaces the roi heads only\n",
    "\n",
    "model = create_model(MODEL_TYPE, num_classes=(len(item_list)+1))\n",
    "train_model(model, train_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "acbb3df601244291b8b2fb9ea1137573",
      "32b6ec3046e64d04b4134553dc434fe0",
      "d8c6a316609d4ca5bfee139b93177ef5",
      "a1645bdfb02b42fba268f7000f183639",
      "4a4788a4fd6841788b20cfbf54a3d10b",
      "5d836b94d13e459d82429606496e4d4f",
      "a410071b34034a91aeda7ef1114969c2",
      "c063e7d90f6a4027b53d1b70c8c07742"
     ]
    },
    "id": "bHa6KRbEWuxz",
    "outputId": "3b4ebd0b-aa69-4a4d-b73c-b8cf24d8b461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Training Epoch: [0]  [   0/1229]  eta: 0:09:46  lr: 0.000010  loss: 2.7297 (2.7297)  loss_classifier: 1.8907 (1.8907)  loss_box_reg: 0.0239 (0.0239)  loss_objectness: 0.7061 (0.7061)  loss_rpn_box_reg: 0.1090 (0.1090)  time: 0.4770  data: 0.1310  max mem: 3239\n",
      "Training Epoch: [0]  [  10/1229]  eta: 0:08:21  lr: 0.000060  loss: 2.6521 (2.6988)  loss_classifier: 1.8757 (1.8517)  loss_box_reg: 0.0388 (0.0390)  loss_objectness: 0.6960 (0.6970)  loss_rpn_box_reg: 0.0922 (0.1111)  time: 0.4113  data: 0.1485  max mem: 3713\n",
      "Training Epoch: [0]  [  20/1229]  eta: 0:07:25  lr: 0.000110  loss: 2.5596 (2.5217)  loss_classifier: 1.7424 (1.6794)  loss_box_reg: 0.0388 (0.0368)  loss_objectness: 0.6896 (0.6891)  loss_rpn_box_reg: 0.0475 (0.1164)  time: 0.3627  data: 0.1444  max mem: 3713\n",
      "Training Epoch: [0]  [  30/1229]  eta: 0:07:02  lr: 0.000160  loss: 1.9389 (2.2141)  loss_classifier: 1.0558 (1.3762)  loss_box_reg: 0.0410 (0.0451)  loss_objectness: 0.6697 (0.6796)  loss_rpn_box_reg: 0.0417 (0.1132)  time: 0.3205  data: 0.1414  max mem: 3713\n",
      "Training Epoch: [0]  [  40/1229]  eta: 0:06:50  lr: 0.000210  loss: 1.1842 (1.9413)  loss_classifier: 0.3916 (1.1191)  loss_box_reg: 0.0466 (0.0495)  loss_objectness: 0.6327 (0.6637)  loss_rpn_box_reg: 0.0601 (0.1089)  time: 0.3214  data: 0.1429  max mem: 3713\n",
      "Training Epoch: [0]  [  50/1229]  eta: 0:06:50  lr: 0.000260  loss: 1.0235 (1.7450)  loss_classifier: 0.2925 (0.9482)  loss_box_reg: 0.0451 (0.0517)  loss_objectness: 0.5838 (0.6427)  loss_rpn_box_reg: 0.0615 (0.1024)  time: 0.3419  data: 0.1521  max mem: 3713\n",
      "Training Epoch: [0]  [  60/1229]  eta: 0:06:42  lr: 0.000310  loss: 0.8468 (1.6144)  loss_classifier: 0.2040 (0.8386)  loss_box_reg: 0.0535 (0.0543)  loss_objectness: 0.5325 (0.6213)  loss_rpn_box_reg: 0.0481 (0.1002)  time: 0.3424  data: 0.1510  max mem: 3713\n",
      "Training Epoch: [0]  [  70/1229]  eta: 0:06:34  lr: 0.000360  loss: 0.9589 (1.5231)  loss_classifier: 0.2647 (0.7662)  loss_box_reg: 0.0586 (0.0572)  loss_objectness: 0.5124 (0.6020)  loss_rpn_box_reg: 0.0639 (0.0976)  time: 0.3193  data: 0.1396  max mem: 3713\n",
      "Training Epoch: [0]  [  80/1229]  eta: 0:06:27  lr: 0.000410  loss: 0.9589 (1.4503)  loss_classifier: 0.2784 (0.7096)  loss_box_reg: 0.0633 (0.0620)  loss_objectness: 0.4647 (0.5822)  loss_rpn_box_reg: 0.0823 (0.0964)  time: 0.3154  data: 0.1375  max mem: 3713\n",
      "Training Epoch: [0]  [  90/1229]  eta: 0:06:22  lr: 0.000460  loss: 0.8817 (1.3822)  loss_classifier: 0.2657 (0.6598)  loss_box_reg: 0.0568 (0.0648)  loss_objectness: 0.4131 (0.5619)  loss_rpn_box_reg: 0.0540 (0.0958)  time: 0.3208  data: 0.1380  max mem: 3713\n",
      "Training Epoch: [0]  [ 100/1229]  eta: 0:06:16  lr: 0.000509  loss: 0.6891 (1.3096)  loss_classifier: 0.2044 (0.6138)  loss_box_reg: 0.0549 (0.0626)  loss_objectness: 0.3688 (0.5421)  loss_rpn_box_reg: 0.0360 (0.0911)  time: 0.3203  data: 0.1403  max mem: 3713\n",
      "Training Epoch: [0]  [ 110/1229]  eta: 0:06:12  lr: 0.000559  loss: 0.6639 (1.2598)  loss_classifier: 0.2044 (0.5782)  loss_box_reg: 0.0559 (0.0643)  loss_objectness: 0.3565 (0.5239)  loss_rpn_box_reg: 0.0360 (0.0934)  time: 0.3195  data: 0.1379  max mem: 3728\n",
      "Training Epoch: [0]  [ 120/1229]  eta: 0:06:07  lr: 0.000609  loss: 0.6971 (1.2156)  loss_classifier: 0.2290 (0.5482)  loss_box_reg: 0.0828 (0.0663)  loss_objectness: 0.3122 (0.5078)  loss_rpn_box_reg: 0.0620 (0.0933)  time: 0.3209  data: 0.1351  max mem: 3728\n",
      "Training Epoch: [0]  [ 130/1229]  eta: 0:06:02  lr: 0.000659  loss: 0.6607 (1.1727)  loss_classifier: 0.1898 (0.5198)  loss_box_reg: 0.0828 (0.0673)  loss_objectness: 0.3045 (0.4924)  loss_rpn_box_reg: 0.0602 (0.0932)  time: 0.3141  data: 0.1349  max mem: 3728\n",
      "Training Epoch: [0]  [ 140/1229]  eta: 0:05:58  lr: 0.000709  loss: 0.6408 (1.1384)  loss_classifier: 0.1501 (0.4961)  loss_box_reg: 0.0672 (0.0692)  loss_objectness: 0.2875 (0.4796)  loss_rpn_box_reg: 0.0822 (0.0935)  time: 0.3157  data: 0.1386  max mem: 3728\n",
      "Training Epoch: [0]  [ 150/1229]  eta: 0:05:54  lr: 0.000759  loss: 0.7152 (1.1162)  loss_classifier: 0.1665 (0.4791)  loss_box_reg: 0.0608 (0.0720)  loss_objectness: 0.3117 (0.4702)  loss_rpn_box_reg: 0.0822 (0.0948)  time: 0.3192  data: 0.1414  max mem: 3728\n",
      "Training Epoch: [0]  [ 160/1229]  eta: 0:05:50  lr: 0.000809  loss: 0.7064 (1.0883)  loss_classifier: 0.1718 (0.4599)  loss_box_reg: 0.0608 (0.0715)  loss_objectness: 0.2865 (0.4620)  loss_rpn_box_reg: 0.0813 (0.0948)  time: 0.3147  data: 0.1410  max mem: 3728\n",
      "Training Epoch: [0]  [ 170/1229]  eta: 0:05:46  lr: 0.000859  loss: 0.5387 (1.0616)  loss_classifier: 0.1657 (0.4411)  loss_box_reg: 0.0501 (0.0707)  loss_objectness: 0.2622 (0.4544)  loss_rpn_box_reg: 0.0370 (0.0954)  time: 0.3144  data: 0.1386  max mem: 3728\n",
      "Training Epoch: [0]  [ 180/1229]  eta: 0:05:41  lr: 0.000909  loss: 0.4938 (1.0314)  loss_classifier: 0.1381 (0.4246)  loss_box_reg: 0.0500 (0.0706)  loss_objectness: 0.2507 (0.4432)  loss_rpn_box_reg: 0.0522 (0.0930)  time: 0.3070  data: 0.1356  max mem: 3728\n",
      "Training Epoch: [0]  [ 190/1229]  eta: 0:05:37  lr: 0.000959  loss: 0.4751 (1.0100)  loss_classifier: 0.1359 (0.4115)  loss_box_reg: 0.0561 (0.0723)  loss_objectness: 0.2564 (0.4343)  loss_rpn_box_reg: 0.0527 (0.0918)  time: 0.3065  data: 0.1364  max mem: 3728\n",
      "Training Epoch: [0]  [ 200/1229]  eta: 0:05:33  lr: 0.001009  loss: 0.4342 (0.9804)  loss_classifier: 0.1059 (0.3964)  loss_box_reg: 0.0458 (0.0711)  loss_objectness: 0.2327 (0.4233)  loss_rpn_box_reg: 0.0520 (0.0896)  time: 0.3151  data: 0.1374  max mem: 3728\n",
      "Training Epoch: [0]  [ 210/1229]  eta: 0:05:30  lr: 0.001059  loss: 0.4966 (0.9653)  loss_classifier: 0.1209 (0.3854)  loss_box_reg: 0.0500 (0.0726)  loss_objectness: 0.2396 (0.4172)  loss_rpn_box_reg: 0.0520 (0.0901)  time: 0.3145  data: 0.1370  max mem: 3728\n",
      "Training Epoch: [0]  [ 220/1229]  eta: 0:05:25  lr: 0.001109  loss: 0.5869 (0.9572)  loss_classifier: 0.1438 (0.3766)  loss_box_reg: 0.1199 (0.0773)  loss_objectness: 0.2554 (0.4111)  loss_rpn_box_reg: 0.0722 (0.0922)  time: 0.3083  data: 0.1359  max mem: 3728\n",
      "Training Epoch: [0]  [ 230/1229]  eta: 0:05:22  lr: 0.001159  loss: 0.5136 (0.9362)  loss_classifier: 0.1159 (0.3655)  loss_box_reg: 0.0524 (0.0758)  loss_objectness: 0.2339 (0.4038)  loss_rpn_box_reg: 0.0432 (0.0911)  time: 0.3076  data: 0.1357  max mem: 3728\n",
      "Training Epoch: [0]  [ 240/1229]  eta: 0:05:18  lr: 0.001209  loss: 0.4240 (0.9243)  loss_classifier: 0.1149 (0.3577)  loss_box_reg: 0.0616 (0.0791)  loss_objectness: 0.2203 (0.3962)  loss_rpn_box_reg: 0.0451 (0.0913)  time: 0.3138  data: 0.1341  max mem: 3728\n",
      "Training Epoch: [0]  [ 250/1229]  eta: 0:05:14  lr: 0.001259  loss: 0.4996 (0.9057)  loss_classifier: 0.1402 (0.3491)  loss_box_reg: 0.0908 (0.0787)  loss_objectness: 0.1989 (0.3885)  loss_rpn_box_reg: 0.0467 (0.0895)  time: 0.3119  data: 0.1337  max mem: 3728\n",
      "Training Epoch: [0]  [ 260/1229]  eta: 0:05:10  lr: 0.001309  loss: 0.5180 (0.8943)  loss_classifier: 0.1398 (0.3416)  loss_box_reg: 0.0670 (0.0791)  loss_objectness: 0.1999 (0.3842)  loss_rpn_box_reg: 0.0467 (0.0894)  time: 0.3053  data: 0.1359  max mem: 3728\n",
      "Training Epoch: [0]  [ 270/1229]  eta: 0:05:07  lr: 0.001359  loss: 0.5890 (0.8919)  loss_classifier: 0.1627 (0.3355)  loss_box_reg: 0.0911 (0.0804)  loss_objectness: 0.2517 (0.3842)  loss_rpn_box_reg: 0.0519 (0.0919)  time: 0.3094  data: 0.1363  max mem: 3728\n",
      "Training Epoch: [0]  [ 280/1229]  eta: 0:05:03  lr: 0.001409  loss: 0.5606 (0.8819)  loss_classifier: 0.1627 (0.3301)  loss_box_reg: 0.0952 (0.0813)  loss_objectness: 0.2217 (0.3791)  loss_rpn_box_reg: 0.0556 (0.0915)  time: 0.3120  data: 0.1375  max mem: 3728\n",
      "Training Epoch: [0]  [ 290/1229]  eta: 0:05:00  lr: 0.001459  loss: 0.5087 (0.8707)  loss_classifier: 0.1433 (0.3243)  loss_box_reg: 0.0995 (0.0830)  loss_objectness: 0.2133 (0.3736)  loss_rpn_box_reg: 0.0439 (0.0899)  time: 0.3064  data: 0.1363  max mem: 3728\n",
      "Training Epoch: [0]  [ 300/1229]  eta: 0:04:56  lr: 0.001508  loss: 0.5071 (0.8594)  loss_classifier: 0.1319 (0.3187)  loss_box_reg: 0.0943 (0.0841)  loss_objectness: 0.2021 (0.3678)  loss_rpn_box_reg: 0.0444 (0.0888)  time: 0.3093  data: 0.1335  max mem: 3728\n",
      "Training Epoch: [0]  [ 310/1229]  eta: 0:04:53  lr: 0.001558  loss: 0.5130 (0.8528)  loss_classifier: 0.1312 (0.3139)  loss_box_reg: 0.0943 (0.0857)  loss_objectness: 0.2236 (0.3643)  loss_rpn_box_reg: 0.0581 (0.0888)  time: 0.3201  data: 0.1334  max mem: 3728\n",
      "Training Epoch: [0]  [ 320/1229]  eta: 0:04:50  lr: 0.001608  loss: 0.4770 (0.8415)  loss_classifier: 0.1254 (0.3081)  loss_box_reg: 0.0939 (0.0860)  loss_objectness: 0.1757 (0.3593)  loss_rpn_box_reg: 0.0464 (0.0881)  time: 0.3241  data: 0.1334  max mem: 3728\n",
      "Training Epoch: [0]  [ 330/1229]  eta: 0:04:47  lr: 0.001658  loss: 0.4402 (0.8357)  loss_classifier: 0.1196 (0.3043)  loss_box_reg: 0.0718 (0.0861)  loss_objectness: 0.1811 (0.3568)  loss_rpn_box_reg: 0.0486 (0.0885)  time: 0.3190  data: 0.1358  max mem: 3728\n",
      "Training Epoch: [0]  [ 340/1229]  eta: 0:04:44  lr: 0.001708  loss: 0.4805 (0.8293)  loss_classifier: 0.1213 (0.3004)  loss_box_reg: 0.0684 (0.0872)  loss_objectness: 0.1901 (0.3527)  loss_rpn_box_reg: 0.0541 (0.0890)  time: 0.3191  data: 0.1395  max mem: 3728\n",
      "Training Epoch: [0]  [ 350/1229]  eta: 0:04:40  lr: 0.001758  loss: 0.4917 (0.8227)  loss_classifier: 0.1213 (0.2963)  loss_box_reg: 0.0684 (0.0875)  loss_objectness: 0.1895 (0.3484)  loss_rpn_box_reg: 0.0901 (0.0904)  time: 0.3154  data: 0.1394  max mem: 3728\n",
      "Training Epoch: [0]  [ 360/1229]  eta: 0:04:37  lr: 0.001808  loss: 0.5175 (0.8171)  loss_classifier: 0.1393 (0.2926)  loss_box_reg: 0.0812 (0.0881)  loss_objectness: 0.2043 (0.3450)  loss_rpn_box_reg: 0.0602 (0.0914)  time: 0.3154  data: 0.1418  max mem: 3728\n",
      "Training Epoch: [0]  [ 370/1229]  eta: 0:04:34  lr: 0.001858  loss: 0.4679 (0.8091)  loss_classifier: 0.1476 (0.2884)  loss_box_reg: 0.0812 (0.0880)  loss_objectness: 0.2042 (0.3418)  loss_rpn_box_reg: 0.0380 (0.0910)  time: 0.3228  data: 0.1426  max mem: 3728\n",
      "Training Epoch: [0]  [ 380/1229]  eta: 0:04:31  lr: 0.001908  loss: 0.3824 (0.8040)  loss_classifier: 0.1476 (0.2838)  loss_box_reg: 0.0476 (0.0874)  loss_objectness: 0.1975 (0.3402)  loss_rpn_box_reg: 0.0372 (0.0926)  time: 0.3179  data: 0.1400  max mem: 3728\n",
      "Training Epoch: [0]  [ 390/1229]  eta: 0:04:28  lr: 0.001958  loss: 0.4294 (0.7967)  loss_classifier: 0.1200 (0.2804)  loss_box_reg: 0.0953 (0.0878)  loss_objectness: 0.1845 (0.3368)  loss_rpn_box_reg: 0.0362 (0.0918)  time: 0.3182  data: 0.1406  max mem: 3728\n",
      "Training Epoch: [0]  [ 400/1229]  eta: 0:04:25  lr: 0.002008  loss: 0.5681 (0.7966)  loss_classifier: 0.1881 (0.2793)  loss_box_reg: 0.1236 (0.0908)  loss_objectness: 0.2109 (0.3340)  loss_rpn_box_reg: 0.0553 (0.0925)  time: 0.3268  data: 0.1430  max mem: 3728\n",
      "Training Epoch: [0]  [ 410/1229]  eta: 0:04:21  lr: 0.002058  loss: 0.6258 (0.7930)  loss_classifier: 0.2327 (0.2778)  loss_box_reg: 0.1865 (0.0924)  loss_objectness: 0.2252 (0.3311)  loss_rpn_box_reg: 0.0609 (0.0917)  time: 0.3238  data: 0.1425  max mem: 3730\n",
      "Training Epoch: [0]  [ 420/1229]  eta: 0:04:18  lr: 0.002108  loss: 0.5521 (0.7881)  loss_classifier: 0.1778 (0.2756)  loss_box_reg: 0.1314 (0.0940)  loss_objectness: 0.2093 (0.3277)  loss_rpn_box_reg: 0.0461 (0.0907)  time: 0.3210  data: 0.1401  max mem: 3730\n",
      "Training Epoch: [0]  [ 430/1229]  eta: 0:04:15  lr: 0.002158  loss: 0.4960 (0.7811)  loss_classifier: 0.1516 (0.2723)  loss_box_reg: 0.1003 (0.0938)  loss_objectness: 0.1853 (0.3247)  loss_rpn_box_reg: 0.0445 (0.0904)  time: 0.3236  data: 0.1397  max mem: 3730\n",
      "Training Epoch: [0]  [ 440/1229]  eta: 0:04:12  lr: 0.002208  loss: 0.4343 (0.7749)  loss_classifier: 0.1247 (0.2696)  loss_box_reg: 0.0692 (0.0940)  loss_objectness: 0.1709 (0.3212)  loss_rpn_box_reg: 0.0499 (0.0901)  time: 0.3233  data: 0.1423  max mem: 3730\n",
      "Training Epoch: [0]  [ 450/1229]  eta: 0:04:09  lr: 0.002258  loss: 0.5311 (0.7716)  loss_classifier: 0.1530 (0.2674)  loss_box_reg: 0.1009 (0.0951)  loss_objectness: 0.1737 (0.3187)  loss_rpn_box_reg: 0.0665 (0.0904)  time: 0.3207  data: 0.1436  max mem: 3730\n",
      "Training Epoch: [0]  [ 460/1229]  eta: 0:04:06  lr: 0.002308  loss: 0.4583 (0.7657)  loss_classifier: 0.1280 (0.2639)  loss_box_reg: 0.0729 (0.0942)  loss_objectness: 0.1740 (0.3154)  loss_rpn_box_reg: 0.0665 (0.0922)  time: 0.3221  data: 0.1404  max mem: 3730\n",
      "Training Epoch: [0]  [ 470/1229]  eta: 0:04:02  lr: 0.002358  loss: 0.4704 (0.7638)  loss_classifier: 0.1342 (0.2633)  loss_box_reg: 0.0659 (0.0954)  loss_objectness: 0.1740 (0.3131)  loss_rpn_box_reg: 0.0837 (0.0921)  time: 0.3195  data: 0.1396  max mem: 3730\n",
      "Training Epoch: [0]  [ 480/1229]  eta: 0:03:59  lr: 0.002408  loss: 0.6219 (0.7597)  loss_classifier: 0.1959 (0.2613)  loss_box_reg: 0.1108 (0.0957)  loss_objectness: 0.2000 (0.3106)  loss_rpn_box_reg: 0.0840 (0.0921)  time: 0.3142  data: 0.1397  max mem: 3730\n",
      "Training Epoch: [0]  [ 490/1229]  eta: 0:03:56  lr: 0.002458  loss: 0.5689 (0.7552)  loss_classifier: 0.1545 (0.2590)  loss_box_reg: 0.0986 (0.0958)  loss_objectness: 0.1762 (0.3081)  loss_rpn_box_reg: 0.0627 (0.0923)  time: 0.3147  data: 0.1386  max mem: 3730\n",
      "Training Epoch: [0]  [ 500/1229]  eta: 0:03:53  lr: 0.002507  loss: 0.4963 (0.7521)  loss_classifier: 0.1419 (0.2574)  loss_box_reg: 0.0837 (0.0965)  loss_objectness: 0.1762 (0.3059)  loss_rpn_box_reg: 0.0703 (0.0923)  time: 0.3198  data: 0.1377  max mem: 3730\n",
      "Training Epoch: [0]  [ 510/1229]  eta: 0:03:49  lr: 0.002557  loss: 0.6640 (0.7506)  loss_classifier: 0.1552 (0.2560)  loss_box_reg: 0.1301 (0.0975)  loss_objectness: 0.1954 (0.3046)  loss_rpn_box_reg: 0.0674 (0.0924)  time: 0.3217  data: 0.1383  max mem: 3730\n",
      "Training Epoch: [0]  [ 520/1229]  eta: 0:03:46  lr: 0.002607  loss: 0.5203 (0.7454)  loss_classifier: 0.1552 (0.2540)  loss_box_reg: 0.0961 (0.0975)  loss_objectness: 0.1732 (0.3020)  loss_rpn_box_reg: 0.0562 (0.0919)  time: 0.3223  data: 0.1377  max mem: 3730\n",
      "Training Epoch: [0]  [ 530/1229]  eta: 0:03:43  lr: 0.002657  loss: 0.4839 (0.7404)  loss_classifier: 0.1349 (0.2520)  loss_box_reg: 0.0821 (0.0978)  loss_objectness: 0.1353 (0.2989)  loss_rpn_box_reg: 0.0547 (0.0916)  time: 0.3230  data: 0.1355  max mem: 3730\n",
      "Training Epoch: [0]  [ 540/1229]  eta: 0:03:40  lr: 0.002707  loss: 0.4895 (0.7399)  loss_classifier: 0.1431 (0.2514)  loss_box_reg: 0.1080 (0.0996)  loss_objectness: 0.1523 (0.2970)  loss_rpn_box_reg: 0.0611 (0.0920)  time: 0.3139  data: 0.1369  max mem: 3730\n",
      "Training Epoch: [0]  [ 550/1229]  eta: 0:03:37  lr: 0.002757  loss: 0.5329 (0.7364)  loss_classifier: 0.1431 (0.2498)  loss_box_reg: 0.1080 (0.1000)  loss_objectness: 0.1692 (0.2949)  loss_rpn_box_reg: 0.0501 (0.0918)  time: 0.3105  data: 0.1398  max mem: 3730\n",
      "Training Epoch: [0]  [ 560/1229]  eta: 0:03:33  lr: 0.002807  loss: 0.4944 (0.7332)  loss_classifier: 0.1509 (0.2485)  loss_box_reg: 0.1109 (0.1008)  loss_objectness: 0.1393 (0.2924)  loss_rpn_box_reg: 0.0340 (0.0915)  time: 0.3191  data: 0.1380  max mem: 3730\n",
      "Training Epoch: [0]  [ 570/1229]  eta: 0:03:30  lr: 0.002857  loss: 0.4989 (0.7312)  loss_classifier: 0.1750 (0.2470)  loss_box_reg: 0.1020 (0.1011)  loss_objectness: 0.1658 (0.2915)  loss_rpn_box_reg: 0.0423 (0.0917)  time: 0.3224  data: 0.1349  max mem: 3730\n",
      "Training Epoch: [0]  [ 580/1229]  eta: 0:03:27  lr: 0.002907  loss: 0.4314 (0.7267)  loss_classifier: 0.1258 (0.2452)  loss_box_reg: 0.0952 (0.1014)  loss_objectness: 0.1417 (0.2888)  loss_rpn_box_reg: 0.0423 (0.0912)  time: 0.3224  data: 0.1360  max mem: 3730\n",
      "Training Epoch: [0]  [ 590/1229]  eta: 0:03:24  lr: 0.002957  loss: 0.4416 (0.7232)  loss_classifier: 0.1283 (0.2440)  loss_box_reg: 0.0936 (0.1013)  loss_objectness: 0.1339 (0.2867)  loss_rpn_box_reg: 0.0356 (0.0912)  time: 0.3277  data: 0.1363  max mem: 3730\n",
      "Training Epoch: [0]  [ 600/1229]  eta: 0:03:21  lr: 0.003007  loss: 0.4594 (0.7187)  loss_classifier: 0.1471 (0.2424)  loss_box_reg: 0.0914 (0.1012)  loss_objectness: 0.1439 (0.2844)  loss_rpn_box_reg: 0.0606 (0.0907)  time: 0.3248  data: 0.1397  max mem: 3730\n",
      "Training Epoch: [0]  [ 610/1229]  eta: 0:03:18  lr: 0.003057  loss: 0.5446 (0.7174)  loss_classifier: 0.1471 (0.2416)  loss_box_reg: 0.0914 (0.1017)  loss_objectness: 0.1693 (0.2831)  loss_rpn_box_reg: 0.0726 (0.0910)  time: 0.3196  data: 0.1422  max mem: 3730\n",
      "Training Epoch: [0]  [ 620/1229]  eta: 0:03:14  lr: 0.003107  loss: 0.6265 (0.7152)  loss_classifier: 0.1488 (0.2409)  loss_box_reg: 0.1134 (0.1024)  loss_objectness: 0.1848 (0.2816)  loss_rpn_box_reg: 0.0693 (0.0904)  time: 0.3213  data: 0.1408  max mem: 3730\n",
      "Training Epoch: [0]  [ 630/1229]  eta: 0:03:11  lr: 0.003157  loss: 0.4775 (0.7108)  loss_classifier: 0.1488 (0.2393)  loss_box_reg: 0.1185 (0.1024)  loss_objectness: 0.1516 (0.2792)  loss_rpn_box_reg: 0.0374 (0.0898)  time: 0.3233  data: 0.1392  max mem: 3730\n",
      "Training Epoch: [0]  [ 640/1229]  eta: 0:03:08  lr: 0.003207  loss: 0.4102 (0.7081)  loss_classifier: 0.1502 (0.2383)  loss_box_reg: 0.0973 (0.1027)  loss_objectness: 0.1283 (0.2777)  loss_rpn_box_reg: 0.0274 (0.0894)  time: 0.3222  data: 0.1407  max mem: 3730\n",
      "Training Epoch: [0]  [ 650/1229]  eta: 0:03:05  lr: 0.003257  loss: 0.4006 (0.7053)  loss_classifier: 0.1214 (0.2370)  loss_box_reg: 0.0806 (0.1027)  loss_objectness: 0.1795 (0.2764)  loss_rpn_box_reg: 0.0394 (0.0892)  time: 0.3265  data: 0.1419  max mem: 3730\n",
      "Training Epoch: [0]  [ 660/1229]  eta: 0:03:02  lr: 0.003307  loss: 0.5469 (0.7040)  loss_classifier: 0.1495 (0.2364)  loss_box_reg: 0.1264 (0.1034)  loss_objectness: 0.1868 (0.2752)  loss_rpn_box_reg: 0.0433 (0.0890)  time: 0.3271  data: 0.1400  max mem: 3730\n",
      "Training Epoch: [0]  [ 670/1229]  eta: 0:02:58  lr: 0.003357  loss: 0.6179 (0.7031)  loss_classifier: 0.1659 (0.2355)  loss_box_reg: 0.1396 (0.1040)  loss_objectness: 0.1913 (0.2742)  loss_rpn_box_reg: 0.0632 (0.0894)  time: 0.3185  data: 0.1416  max mem: 3730\n",
      "Training Epoch: [0]  [ 680/1229]  eta: 0:02:55  lr: 0.003407  loss: 0.5467 (0.7005)  loss_classifier: 0.1535 (0.2344)  loss_box_reg: 0.1091 (0.1041)  loss_objectness: 0.1790 (0.2724)  loss_rpn_box_reg: 0.0648 (0.0896)  time: 0.3148  data: 0.1411  max mem: 3730\n",
      "Training Epoch: [0]  [ 690/1229]  eta: 0:02:52  lr: 0.003457  loss: 0.7097 (0.7012)  loss_classifier: 0.1626 (0.2342)  loss_box_reg: 0.1184 (0.1052)  loss_objectness: 0.1849 (0.2721)  loss_rpn_box_reg: 0.0720 (0.0898)  time: 0.3168  data: 0.1399  max mem: 3730\n",
      "Training Epoch: [0]  [ 700/1229]  eta: 0:02:49  lr: 0.003506  loss: 0.7391 (0.6999)  loss_classifier: 0.1893 (0.2332)  loss_box_reg: 0.1403 (0.1054)  loss_objectness: 0.2036 (0.2712)  loss_rpn_box_reg: 0.0774 (0.0901)  time: 0.3231  data: 0.1406  max mem: 3730\n",
      "Training Epoch: [0]  [ 710/1229]  eta: 0:02:46  lr: 0.003556  loss: 0.6260 (0.6981)  loss_classifier: 0.1571 (0.2325)  loss_box_reg: 0.1236 (0.1058)  loss_objectness: 0.1722 (0.2700)  loss_rpn_box_reg: 0.0630 (0.0898)  time: 0.3287  data: 0.1411  max mem: 3730\n",
      "Training Epoch: [0]  [ 720/1229]  eta: 0:02:43  lr: 0.003606  loss: 0.6440 (0.6980)  loss_classifier: 0.1749 (0.2321)  loss_box_reg: 0.1221 (0.1064)  loss_objectness: 0.1779 (0.2690)  loss_rpn_box_reg: 0.0638 (0.0905)  time: 0.3264  data: 0.1408  max mem: 3730\n",
      "Training Epoch: [0]  [ 730/1229]  eta: 0:02:40  lr: 0.003656  loss: 0.6289 (0.6963)  loss_classifier: 0.1793 (0.2315)  loss_box_reg: 0.1145 (0.1067)  loss_objectness: 0.1779 (0.2677)  loss_rpn_box_reg: 0.0606 (0.0905)  time: 0.3308  data: 0.1491  max mem: 3730\n",
      "Training Epoch: [0]  [ 740/1229]  eta: 0:02:36  lr: 0.003706  loss: 0.5095 (0.6948)  loss_classifier: 0.1793 (0.2310)  loss_box_reg: 0.0944 (0.1072)  loss_objectness: 0.1649 (0.2664)  loss_rpn_box_reg: 0.0422 (0.0902)  time: 0.3365  data: 0.1532  max mem: 3730\n",
      "Training Epoch: [0]  [ 750/1229]  eta: 0:02:33  lr: 0.003756  loss: 0.4659 (0.6927)  loss_classifier: 0.1762 (0.2301)  loss_box_reg: 0.0993 (0.1073)  loss_objectness: 0.1451 (0.2652)  loss_rpn_box_reg: 0.0530 (0.0900)  time: 0.3233  data: 0.1444  max mem: 3730\n",
      "Training Epoch: [0]  [ 760/1229]  eta: 0:02:30  lr: 0.003806  loss: 0.4674 (0.6916)  loss_classifier: 0.1762 (0.2296)  loss_box_reg: 0.1133 (0.1077)  loss_objectness: 0.1451 (0.2644)  loss_rpn_box_reg: 0.0612 (0.0899)  time: 0.3167  data: 0.1413  max mem: 3730\n",
      "Training Epoch: [0]  [ 770/1229]  eta: 0:02:27  lr: 0.003856  loss: 0.5235 (0.6911)  loss_classifier: 0.1781 (0.2295)  loss_box_reg: 0.1213 (0.1084)  loss_objectness: 0.1361 (0.2631)  loss_rpn_box_reg: 0.0682 (0.0901)  time: 0.3297  data: 0.1451  max mem: 3730\n",
      "Training Epoch: [0]  [ 780/1229]  eta: 0:02:24  lr: 0.003906  loss: 0.5251 (0.6900)  loss_classifier: 0.1780 (0.2291)  loss_box_reg: 0.1515 (0.1089)  loss_objectness: 0.1558 (0.2619)  loss_rpn_box_reg: 0.0533 (0.0901)  time: 0.3338  data: 0.1487  max mem: 3730\n",
      "Training Epoch: [0]  [ 790/1229]  eta: 0:02:20  lr: 0.003956  loss: 0.6065 (0.6883)  loss_classifier: 0.1866 (0.2283)  loss_box_reg: 0.1515 (0.1093)  loss_objectness: 0.1527 (0.2605)  loss_rpn_box_reg: 0.0533 (0.0902)  time: 0.3295  data: 0.1525  max mem: 3730\n",
      "Training Epoch: [0]  [ 800/1229]  eta: 0:02:17  lr: 0.004006  loss: 0.6313 (0.6876)  loss_classifier: 0.1866 (0.2278)  loss_box_reg: 0.1311 (0.1098)  loss_objectness: 0.1255 (0.2594)  loss_rpn_box_reg: 0.0861 (0.0906)  time: 0.3403  data: 0.1519  max mem: 3730\n",
      "Training Epoch: [0]  [ 810/1229]  eta: 0:02:14  lr: 0.004056  loss: 0.6109 (0.6863)  loss_classifier: 0.1780 (0.2275)  loss_box_reg: 0.1390 (0.1102)  loss_objectness: 0.1474 (0.2582)  loss_rpn_box_reg: 0.0837 (0.0905)  time: 0.3370  data: 0.1462  max mem: 3730\n",
      "Training Epoch: [0]  [ 820/1229]  eta: 0:02:11  lr: 0.004106  loss: 0.5483 (0.6846)  loss_classifier: 0.1780 (0.2270)  loss_box_reg: 0.1390 (0.1104)  loss_objectness: 0.1520 (0.2571)  loss_rpn_box_reg: 0.0598 (0.0901)  time: 0.3227  data: 0.1451  max mem: 3730\n",
      "Training Epoch: [0]  [ 830/1229]  eta: 0:02:08  lr: 0.004156  loss: 0.4471 (0.6822)  loss_classifier: 0.1520 (0.2259)  loss_box_reg: 0.1001 (0.1102)  loss_objectness: 0.1289 (0.2559)  loss_rpn_box_reg: 0.0491 (0.0900)  time: 0.3312  data: 0.1428  max mem: 3730\n",
      "Training Epoch: [0]  [ 840/1229]  eta: 0:02:05  lr: 0.004206  loss: 0.3828 (0.6788)  loss_classifier: 0.1187 (0.2246)  loss_box_reg: 0.0850 (0.1099)  loss_objectness: 0.1152 (0.2545)  loss_rpn_box_reg: 0.0380 (0.0898)  time: 0.3346  data: 0.1405  max mem: 3730\n",
      "Training Epoch: [0]  [ 850/1229]  eta: 0:02:02  lr: 0.004256  loss: 0.3702 (0.6766)  loss_classifier: 0.1142 (0.2237)  loss_box_reg: 0.0732 (0.1099)  loss_objectness: 0.1261 (0.2534)  loss_rpn_box_reg: 0.0314 (0.0896)  time: 0.3286  data: 0.1421  max mem: 3730\n",
      "Training Epoch: [0]  [ 860/1229]  eta: 0:01:58  lr: 0.004306  loss: 0.3524 (0.6733)  loss_classifier: 0.1131 (0.2226)  loss_box_reg: 0.0732 (0.1094)  loss_objectness: 0.1596 (0.2523)  loss_rpn_box_reg: 0.0339 (0.0890)  time: 0.3298  data: 0.1442  max mem: 3730\n",
      "Training Epoch: [0]  [ 870/1229]  eta: 0:01:55  lr: 0.004356  loss: 0.3308 (0.6702)  loss_classifier: 0.1131 (0.2217)  loss_box_reg: 0.0676 (0.1094)  loss_objectness: 0.1443 (0.2507)  loss_rpn_box_reg: 0.0339 (0.0884)  time: 0.3289  data: 0.1468  max mem: 3730\n",
      "Training Epoch: [0]  [ 880/1229]  eta: 0:01:52  lr: 0.004406  loss: 0.4041 (0.6687)  loss_classifier: 0.1391 (0.2210)  loss_box_reg: 0.1143 (0.1098)  loss_objectness: 0.0879 (0.2494)  loss_rpn_box_reg: 0.0399 (0.0885)  time: 0.3318  data: 0.1466  max mem: 3730\n",
      "Training Epoch: [0]  [ 890/1229]  eta: 0:01:49  lr: 0.004456  loss: 0.5328 (0.6682)  loss_classifier: 0.1490 (0.2206)  loss_box_reg: 0.1143 (0.1100)  loss_objectness: 0.1244 (0.2485)  loss_rpn_box_reg: 0.0534 (0.0891)  time: 0.3342  data: 0.1455  max mem: 3730\n",
      "Training Epoch: [0]  [ 900/1229]  eta: 0:01:46  lr: 0.004505  loss: 0.5785 (0.6677)  loss_classifier: 0.1526 (0.2202)  loss_box_reg: 0.1060 (0.1103)  loss_objectness: 0.1383 (0.2479)  loss_rpn_box_reg: 0.0649 (0.0893)  time: 0.3301  data: 0.1454  max mem: 3730\n",
      "Training Epoch: [0]  [ 910/1229]  eta: 0:01:42  lr: 0.004555  loss: 0.5236 (0.6666)  loss_classifier: 0.1596 (0.2198)  loss_box_reg: 0.1060 (0.1107)  loss_objectness: 0.1729 (0.2470)  loss_rpn_box_reg: 0.0645 (0.0891)  time: 0.3317  data: 0.1472  max mem: 3730\n",
      "Training Epoch: [0]  [ 920/1229]  eta: 0:01:39  lr: 0.004605  loss: 0.4698 (0.6662)  loss_classifier: 0.1572 (0.2197)  loss_box_reg: 0.1046 (0.1116)  loss_objectness: 0.1509 (0.2462)  loss_rpn_box_reg: 0.0404 (0.0887)  time: 0.3303  data: 0.1468  max mem: 3730\n",
      "Training Epoch: [0]  [ 930/1229]  eta: 0:01:36  lr: 0.004655  loss: 0.4732 (0.6647)  loss_classifier: 0.1603 (0.2193)  loss_box_reg: 0.1415 (0.1120)  loss_objectness: 0.1425 (0.2451)  loss_rpn_box_reg: 0.0404 (0.0882)  time: 0.3263  data: 0.1434  max mem: 3730\n",
      "Training Epoch: [0]  [ 940/1229]  eta: 0:01:33  lr: 0.004705  loss: 0.5856 (0.6636)  loss_classifier: 0.1881 (0.2188)  loss_box_reg: 0.1303 (0.1123)  loss_objectness: 0.1610 (0.2443)  loss_rpn_box_reg: 0.0550 (0.0883)  time: 0.3277  data: 0.1440  max mem: 3730\n",
      "Training Epoch: [0]  [ 950/1229]  eta: 0:01:30  lr: 0.004755  loss: 0.6278 (0.6624)  loss_classifier: 0.1881 (0.2184)  loss_box_reg: 0.1245 (0.1127)  loss_objectness: 0.1610 (0.2434)  loss_rpn_box_reg: 0.0595 (0.0880)  time: 0.3265  data: 0.1462  max mem: 3730\n",
      "Training Epoch: [0]  [ 960/1229]  eta: 0:01:26  lr: 0.004805  loss: 0.4432 (0.6603)  loss_classifier: 0.1482 (0.2177)  loss_box_reg: 0.0989 (0.1125)  loss_objectness: 0.1370 (0.2425)  loss_rpn_box_reg: 0.0391 (0.0877)  time: 0.3252  data: 0.1479  max mem: 3730\n",
      "Training Epoch: [0]  [ 970/1229]  eta: 0:01:23  lr: 0.004855  loss: 0.4432 (0.6599)  loss_classifier: 0.1691 (0.2174)  loss_box_reg: 0.0934 (0.1125)  loss_objectness: 0.1405 (0.2420)  loss_rpn_box_reg: 0.0521 (0.0880)  time: 0.3250  data: 0.1466  max mem: 3730\n",
      "Training Epoch: [0]  [ 980/1229]  eta: 0:01:20  lr: 0.004905  loss: 0.5246 (0.6598)  loss_classifier: 0.1781 (0.2170)  loss_box_reg: 0.1063 (0.1127)  loss_objectness: 0.1769 (0.2419)  loss_rpn_box_reg: 0.0523 (0.0882)  time: 0.3243  data: 0.1475  max mem: 3730\n",
      "Training Epoch: [0]  [ 990/1229]  eta: 0:01:17  lr: 0.004955  loss: 0.4904 (0.6580)  loss_classifier: 0.1455 (0.2165)  loss_box_reg: 0.0891 (0.1126)  loss_objectness: 0.1769 (0.2411)  loss_rpn_box_reg: 0.0395 (0.0878)  time: 0.3236  data: 0.1476  max mem: 3730\n",
      "Training Epoch: [0]  [1000/1229]  eta: 0:01:13  lr: 0.005000  loss: 0.3768 (0.6554)  loss_classifier: 0.1364 (0.2157)  loss_box_reg: 0.0850 (0.1125)  loss_objectness: 0.1403 (0.2399)  loss_rpn_box_reg: 0.0348 (0.0873)  time: 0.3305  data: 0.1436  max mem: 3730\n",
      "Training Epoch: [0]  [1010/1229]  eta: 0:01:10  lr: 0.005000  loss: 0.4874 (0.6545)  loss_classifier: 0.1431 (0.2152)  loss_box_reg: 0.1033 (0.1127)  loss_objectness: 0.1290 (0.2392)  loss_rpn_box_reg: 0.0312 (0.0874)  time: 0.3257  data: 0.1425  max mem: 3730\n",
      "Training Epoch: [0]  [1020/1229]  eta: 0:01:07  lr: 0.005000  loss: 0.5007 (0.6532)  loss_classifier: 0.1444 (0.2149)  loss_box_reg: 0.1113 (0.1129)  loss_objectness: 0.1473 (0.2384)  loss_rpn_box_reg: 0.0352 (0.0869)  time: 0.3205  data: 0.1449  max mem: 3730\n",
      "Training Epoch: [0]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.5007 (0.6526)  loss_classifier: 0.1711 (0.2149)  loss_box_reg: 0.1480 (0.1136)  loss_objectness: 0.1470 (0.2376)  loss_rpn_box_reg: 0.0396 (0.0865)  time: 0.3295  data: 0.1454  max mem: 3730\n",
      "Training Epoch: [0]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.4569 (0.6510)  loss_classifier: 0.1803 (0.2145)  loss_box_reg: 0.1206 (0.1136)  loss_objectness: 0.1356 (0.2367)  loss_rpn_box_reg: 0.0252 (0.0862)  time: 0.3299  data: 0.1429  max mem: 3730\n",
      "Training Epoch: [0]  [1050/1229]  eta: 0:00:57  lr: 0.005000  loss: 0.4569 (0.6505)  loss_classifier: 0.1759 (0.2142)  loss_box_reg: 0.1042 (0.1135)  loss_objectness: 0.1383 (0.2363)  loss_rpn_box_reg: 0.0290 (0.0865)  time: 0.3284  data: 0.1430  max mem: 3730\n",
      "Training Epoch: [0]  [1060/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.4834 (0.6491)  loss_classifier: 0.1685 (0.2137)  loss_box_reg: 0.0828 (0.1134)  loss_objectness: 0.1416 (0.2358)  loss_rpn_box_reg: 0.0424 (0.0863)  time: 0.3231  data: 0.1441  max mem: 3730\n",
      "Training Epoch: [0]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.5575 (0.6488)  loss_classifier: 0.1834 (0.2137)  loss_box_reg: 0.1339 (0.1139)  loss_objectness: 0.1416 (0.2351)  loss_rpn_box_reg: 0.0492 (0.0861)  time: 0.3242  data: 0.1463  max mem: 3743\n",
      "Training Epoch: [0]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.5034 (0.6467)  loss_classifier: 0.1678 (0.2130)  loss_box_reg: 0.1231 (0.1137)  loss_objectness: 0.1385 (0.2343)  loss_rpn_box_reg: 0.0322 (0.0857)  time: 0.3317  data: 0.1457  max mem: 3743\n",
      "Training Epoch: [0]  [1090/1229]  eta: 0:00:44  lr: 0.005000  loss: 0.4830 (0.6459)  loss_classifier: 0.1693 (0.2130)  loss_box_reg: 0.1245 (0.1142)  loss_objectness: 0.1238 (0.2334)  loss_rpn_box_reg: 0.0372 (0.0854)  time: 0.3396  data: 0.1487  max mem: 3743\n",
      "Training Epoch: [0]  [1100/1229]  eta: 0:00:41  lr: 0.005000  loss: 0.5733 (0.6456)  loss_classifier: 0.1924 (0.2128)  loss_box_reg: 0.1563 (0.1148)  loss_objectness: 0.1238 (0.2329)  loss_rpn_box_reg: 0.0507 (0.0851)  time: 0.3372  data: 0.1488  max mem: 3743\n",
      "Training Epoch: [0]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.4520 (0.6444)  loss_classifier: 0.1623 (0.2125)  loss_box_reg: 0.1075 (0.1150)  loss_objectness: 0.1426 (0.2322)  loss_rpn_box_reg: 0.0284 (0.0847)  time: 0.3213  data: 0.1436  max mem: 3743\n",
      "Training Epoch: [0]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4281 (0.6431)  loss_classifier: 0.1497 (0.2119)  loss_box_reg: 0.0960 (0.1151)  loss_objectness: 0.1331 (0.2317)  loss_rpn_box_reg: 0.0233 (0.0843)  time: 0.3229  data: 0.1451  max mem: 3743\n",
      "Training Epoch: [0]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.4838 (0.6428)  loss_classifier: 0.1476 (0.2118)  loss_box_reg: 0.1100 (0.1154)  loss_objectness: 0.1295 (0.2314)  loss_rpn_box_reg: 0.0376 (0.0842)  time: 0.3246  data: 0.1433  max mem: 3743\n",
      "Training Epoch: [0]  [1140/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.5606 (0.6418)  loss_classifier: 0.1587 (0.2116)  loss_box_reg: 0.1354 (0.1157)  loss_objectness: 0.1569 (0.2309)  loss_rpn_box_reg: 0.0390 (0.0837)  time: 0.3155  data: 0.1421  max mem: 3743\n",
      "Training Epoch: [0]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.5606 (0.6410)  loss_classifier: 0.1803 (0.2114)  loss_box_reg: 0.1354 (0.1158)  loss_objectness: 0.1778 (0.2304)  loss_rpn_box_reg: 0.0447 (0.0835)  time: 0.3167  data: 0.1442  max mem: 3743\n",
      "Training Epoch: [0]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.4542 (0.6399)  loss_classifier: 0.1569 (0.2110)  loss_box_reg: 0.0923 (0.1159)  loss_objectness: 0.1650 (0.2296)  loss_rpn_box_reg: 0.0346 (0.0833)  time: 0.3278  data: 0.1429  max mem: 3743\n",
      "Training Epoch: [0]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.4190 (0.6397)  loss_classifier: 0.1569 (0.2109)  loss_box_reg: 0.0952 (0.1161)  loss_objectness: 0.1548 (0.2293)  loss_rpn_box_reg: 0.0461 (0.0833)  time: 0.3292  data: 0.1424  max mem: 3743\n",
      "Training Epoch: [0]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.4919 (0.6398)  loss_classifier: 0.1768 (0.2109)  loss_box_reg: 0.0952 (0.1166)  loss_objectness: 0.1523 (0.2288)  loss_rpn_box_reg: 0.0499 (0.0836)  time: 0.3229  data: 0.1427  max mem: 3743\n",
      "Training Epoch: [0]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.4672 (0.6394)  loss_classifier: 0.1464 (0.2107)  loss_box_reg: 0.0950 (0.1170)  loss_objectness: 0.1170 (0.2283)  loss_rpn_box_reg: 0.0568 (0.0834)  time: 0.3302  data: 0.1434  max mem: 3745\n",
      "Training Epoch: [0]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.4327 (0.6378)  loss_classifier: 0.1334 (0.2102)  loss_box_reg: 0.0950 (0.1171)  loss_objectness: 0.1174 (0.2275)  loss_rpn_box_reg: 0.0353 (0.0830)  time: 0.3327  data: 0.1430  max mem: 3745\n",
      "Training Epoch: [0]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.4327 (0.6369)  loss_classifier: 0.1477 (0.2099)  loss_box_reg: 0.1128 (0.1173)  loss_objectness: 0.1233 (0.2268)  loss_rpn_box_reg: 0.0353 (0.0828)  time: 0.3286  data: 0.1424  max mem: 3745\n",
      "Training Epoch: [0]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.4594 (0.6361)  loss_classifier: 0.1443 (0.2095)  loss_box_reg: 0.1023 (0.1173)  loss_objectness: 0.1370 (0.2265)  loss_rpn_box_reg: 0.0417 (0.0828)  time: 0.3262  data: 0.1427  max mem: 3745\n",
      "Training Epoch: [0]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4510 (0.6347)  loss_classifier: 0.1371 (0.2090)  loss_box_reg: 0.1004 (0.1173)  loss_objectness: 0.1187 (0.2257)  loss_rpn_box_reg: 0.0417 (0.0827)  time: 0.3236  data: 0.1412  max mem: 3745\n",
      "Training Epoch: [0] Total time: 0:06:37 (0.3237 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:57  model_time: 0.3470 (0.3470)  evaluator_time: 0.0020 (0.0020)  time: 0.3820  data: 0.0310  max mem: 3745\n",
      "Test:  [100/308]  eta: 0:00:31  model_time: 0.0980 (0.1054)  evaluator_time: 0.0030 (0.0055)  time: 0.1487  data: 0.0384  max mem: 3745\n",
      "Test:  [200/308]  eta: 0:00:16  model_time: 0.1090 (0.1044)  evaluator_time: 0.0030 (0.0051)  time: 0.1471  data: 0.0341  max mem: 3745\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0920 (0.1032)  evaluator_time: 0.0020 (0.0053)  time: 0.1412  data: 0.0387  max mem: 3745\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0900 (0.1030)  evaluator_time: 0.0020 (0.0053)  time: 0.1385  data: 0.0371  max mem: 3745\n",
      "Test: Total time: 0:00:45 (0.1476 s / it)\n",
      "Averaged stats: model_time: 0.0900 (0.1030)  evaluator_time: 0.0020 (0.0053)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.039\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.092\n",
      "Testing Epoch: [0]  [  0/308]  eta: 0:00:47  lr: 0.005000  loss: 0.2337 (0.2337)  loss_classifier: 0.0607 (0.0607)  loss_box_reg: 0.0510 (0.0510)  loss_objectness: 0.0956 (0.0956)  loss_rpn_box_reg: 0.0265 (0.0265)  time: 0.1540  data: 0.0330  max mem: 3745\n",
      "Testing Epoch: [0]  [100/308]  eta: 0:00:36  lr: 0.005000  loss: 0.3694 (0.5516)  loss_classifier: 0.1481 (0.1787)  loss_box_reg: 0.1049 (0.1597)  loss_objectness: 0.1048 (0.1420)  loss_rpn_box_reg: 0.0334 (0.0712)  time: 0.1765  data: 0.0434  max mem: 3948\n",
      "Testing Epoch: [0]  [200/308]  eta: 0:00:18  lr: 0.005000  loss: 0.4861 (0.5244)  loss_classifier: 0.1354 (0.1693)  loss_box_reg: 0.1177 (0.1510)  loss_objectness: 0.1259 (0.1372)  loss_rpn_box_reg: 0.0354 (0.0668)  time: 0.1774  data: 0.0379  max mem: 3948\n",
      "Testing Epoch: [0]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5694 (0.5254)  loss_classifier: 0.1843 (0.1705)  loss_box_reg: 0.1458 (0.1536)  loss_objectness: 0.1479 (0.1361)  loss_rpn_box_reg: 0.0427 (0.0652)  time: 0.1664  data: 0.0412  max mem: 3948\n",
      "Testing Epoch: [0]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.5324 (0.5252)  loss_classifier: 0.1815 (0.1709)  loss_box_reg: 0.1451 (0.1537)  loss_objectness: 0.1413 (0.1361)  loss_rpn_box_reg: 0.0428 (0.0646)  time: 0.1639  data: 0.0393  max mem: 3948\n",
      "Testing Epoch: [0] Total time: 0:00:53 (0.1741 s / it)\n",
      "Training Epoch: [1]  [   0/1229]  eta: 0:06:54  lr: 0.005000  loss: 0.5877 (0.5877)  loss_classifier: 0.1874 (0.1874)  loss_box_reg: 0.1212 (0.1212)  loss_objectness: 0.2116 (0.2116)  loss_rpn_box_reg: 0.0675 (0.0675)  time: 0.3370  data: 0.1720  max mem: 3948\n",
      "Training Epoch: [1]  [  10/1229]  eta: 0:06:33  lr: 0.005000  loss: 0.3053 (0.4150)  loss_classifier: 0.0996 (0.1388)  loss_box_reg: 0.0632 (0.0833)  loss_objectness: 0.1150 (0.1484)  loss_rpn_box_reg: 0.0256 (0.0446)  time: 0.3226  data: 0.1479  max mem: 3948\n",
      "Training Epoch: [1]  [  20/1229]  eta: 0:06:39  lr: 0.005000  loss: 0.3952 (0.4726)  loss_classifier: 0.1496 (0.1579)  loss_box_reg: 0.0900 (0.1090)  loss_objectness: 0.1150 (0.1535)  loss_rpn_box_reg: 0.0267 (0.0522)  time: 0.3303  data: 0.1441  max mem: 3948\n",
      "Training Epoch: [1]  [  30/1229]  eta: 0:06:36  lr: 0.005000  loss: 0.5550 (0.5298)  loss_classifier: 0.1880 (0.1728)  loss_box_reg: 0.1438 (0.1237)  loss_objectness: 0.1352 (0.1711)  loss_rpn_box_reg: 0.0435 (0.0621)  time: 0.3354  data: 0.1463  max mem: 3948\n",
      "Training Epoch: [1]  [  40/1229]  eta: 0:06:30  lr: 0.005000  loss: 0.5767 (0.5746)  loss_classifier: 0.1880 (0.1878)  loss_box_reg: 0.1536 (0.1373)  loss_objectness: 0.1823 (0.1763)  loss_rpn_box_reg: 0.0775 (0.0733)  time: 0.3265  data: 0.1461  max mem: 3948\n",
      "Training Epoch: [1]  [  50/1229]  eta: 0:06:24  lr: 0.005000  loss: 0.5952 (0.5767)  loss_classifier: 0.2021 (0.1882)  loss_box_reg: 0.1683 (0.1428)  loss_objectness: 0.1633 (0.1709)  loss_rpn_box_reg: 0.0683 (0.0748)  time: 0.3196  data: 0.1442  max mem: 3948\n",
      "Training Epoch: [1]  [  60/1229]  eta: 0:06:23  lr: 0.005000  loss: 0.5663 (0.5920)  loss_classifier: 0.1916 (0.1912)  loss_box_reg: 0.1473 (0.1474)  loss_objectness: 0.1550 (0.1776)  loss_rpn_box_reg: 0.0494 (0.0759)  time: 0.3263  data: 0.1445  max mem: 3948\n",
      "Training Epoch: [1]  [  70/1229]  eta: 0:06:17  lr: 0.005000  loss: 0.6027 (0.6181)  loss_classifier: 0.2029 (0.2028)  loss_box_reg: 0.1704 (0.1616)  loss_objectness: 0.1505 (0.1765)  loss_rpn_box_reg: 0.0591 (0.0772)  time: 0.3236  data: 0.1429  max mem: 3948\n",
      "Training Epoch: [1]  [  80/1229]  eta: 0:06:13  lr: 0.005000  loss: 0.5608 (0.6006)  loss_classifier: 0.2029 (0.1979)  loss_box_reg: 0.1704 (0.1563)  loss_objectness: 0.1364 (0.1714)  loss_rpn_box_reg: 0.0501 (0.0749)  time: 0.3154  data: 0.1424  max mem: 3948\n",
      "Training Epoch: [1]  [  90/1229]  eta: 0:06:09  lr: 0.005000  loss: 0.4010 (0.5867)  loss_classifier: 0.1324 (0.1935)  loss_box_reg: 0.0742 (0.1500)  loss_objectness: 0.1255 (0.1660)  loss_rpn_box_reg: 0.0368 (0.0773)  time: 0.3211  data: 0.1429  max mem: 3948\n",
      "Training Epoch: [1]  [ 100/1229]  eta: 0:06:06  lr: 0.005000  loss: 0.5385 (0.5930)  loss_classifier: 0.1625 (0.1951)  loss_box_reg: 0.1080 (0.1527)  loss_objectness: 0.1505 (0.1674)  loss_rpn_box_reg: 0.0492 (0.0778)  time: 0.3238  data: 0.1430  max mem: 3948\n",
      "Training Epoch: [1]  [ 110/1229]  eta: 0:06:03  lr: 0.005000  loss: 0.5491 (0.5873)  loss_classifier: 0.1682 (0.1941)  loss_box_reg: 0.1158 (0.1512)  loss_objectness: 0.1532 (0.1655)  loss_rpn_box_reg: 0.0665 (0.0765)  time: 0.3253  data: 0.1422  max mem: 3948\n",
      "Training Epoch: [1]  [ 120/1229]  eta: 0:06:01  lr: 0.005000  loss: 0.4944 (0.5857)  loss_classifier: 0.1707 (0.1930)  loss_box_reg: 0.0853 (0.1506)  loss_objectness: 0.1239 (0.1653)  loss_rpn_box_reg: 0.0410 (0.0769)  time: 0.3322  data: 0.1492  max mem: 3948\n",
      "Training Epoch: [1]  [ 130/1229]  eta: 0:05:59  lr: 0.005000  loss: 0.4944 (0.5861)  loss_classifier: 0.1494 (0.1918)  loss_box_reg: 0.0853 (0.1490)  loss_objectness: 0.1391 (0.1663)  loss_rpn_box_reg: 0.0336 (0.0790)  time: 0.3408  data: 0.1520  max mem: 3948\n",
      "Training Epoch: [1]  [ 140/1229]  eta: 0:05:57  lr: 0.005000  loss: 0.3776 (0.5811)  loss_classifier: 0.1304 (0.1903)  loss_box_reg: 0.0943 (0.1480)  loss_objectness: 0.1357 (0.1668)  loss_rpn_box_reg: 0.0302 (0.0760)  time: 0.3410  data: 0.1455  max mem: 3948\n",
      "Training Epoch: [1]  [ 150/1229]  eta: 0:05:54  lr: 0.005000  loss: 0.5593 (0.5875)  loss_classifier: 0.1464 (0.1912)  loss_box_reg: 0.1331 (0.1505)  loss_objectness: 0.1709 (0.1688)  loss_rpn_box_reg: 0.0381 (0.0771)  time: 0.3339  data: 0.1418  max mem: 3948\n",
      "Training Epoch: [1]  [ 160/1229]  eta: 0:05:51  lr: 0.005000  loss: 0.5691 (0.5888)  loss_classifier: 0.1996 (0.1921)  loss_box_reg: 0.1505 (0.1511)  loss_objectness: 0.1717 (0.1681)  loss_rpn_box_reg: 0.0713 (0.0775)  time: 0.3315  data: 0.1410  max mem: 3948\n",
      "Training Epoch: [1]  [ 170/1229]  eta: 0:05:47  lr: 0.005000  loss: 0.5110 (0.5858)  loss_classifier: 0.1702 (0.1907)  loss_box_reg: 0.1384 (0.1499)  loss_objectness: 0.1430 (0.1671)  loss_rpn_box_reg: 0.0373 (0.0782)  time: 0.3282  data: 0.1409  max mem: 3948\n",
      "Training Epoch: [1]  [ 180/1229]  eta: 0:05:44  lr: 0.005000  loss: 0.4675 (0.5811)  loss_classifier: 0.1566 (0.1900)  loss_box_reg: 0.1278 (0.1483)  loss_objectness: 0.1430 (0.1665)  loss_rpn_box_reg: 0.0342 (0.0762)  time: 0.3264  data: 0.1408  max mem: 3948\n",
      "Training Epoch: [1]  [ 190/1229]  eta: 0:05:40  lr: 0.005000  loss: 0.3929 (0.5727)  loss_classifier: 0.1292 (0.1874)  loss_box_reg: 0.0804 (0.1459)  loss_objectness: 0.1241 (0.1648)  loss_rpn_box_reg: 0.0274 (0.0746)  time: 0.3278  data: 0.1402  max mem: 3948\n",
      "Training Epoch: [1]  [ 200/1229]  eta: 0:05:37  lr: 0.005000  loss: 0.4637 (0.5767)  loss_classifier: 0.1548 (0.1899)  loss_box_reg: 0.1245 (0.1489)  loss_objectness: 0.1254 (0.1643)  loss_rpn_box_reg: 0.0290 (0.0737)  time: 0.3259  data: 0.1410  max mem: 3948\n",
      "Training Epoch: [1]  [ 210/1229]  eta: 0:05:33  lr: 0.005000  loss: 0.4900 (0.5724)  loss_classifier: 0.1888 (0.1893)  loss_box_reg: 0.1336 (0.1479)  loss_objectness: 0.1337 (0.1636)  loss_rpn_box_reg: 0.0328 (0.0716)  time: 0.3243  data: 0.1445  max mem: 3948\n",
      "Training Epoch: [1]  [ 220/1229]  eta: 0:05:30  lr: 0.005000  loss: 0.4872 (0.5707)  loss_classifier: 0.1722 (0.1890)  loss_box_reg: 0.1223 (0.1477)  loss_objectness: 0.1337 (0.1637)  loss_rpn_box_reg: 0.0318 (0.0703)  time: 0.3248  data: 0.1446  max mem: 3948\n",
      "Training Epoch: [1]  [ 230/1229]  eta: 0:05:26  lr: 0.005000  loss: 0.4258 (0.5634)  loss_classifier: 0.1449 (0.1869)  loss_box_reg: 0.1223 (0.1462)  loss_objectness: 0.1271 (0.1618)  loss_rpn_box_reg: 0.0223 (0.0685)  time: 0.3222  data: 0.1430  max mem: 3948\n",
      "Training Epoch: [1]  [ 240/1229]  eta: 0:05:23  lr: 0.005000  loss: 0.3821 (0.5615)  loss_classifier: 0.1307 (0.1865)  loss_box_reg: 0.1057 (0.1463)  loss_objectness: 0.1106 (0.1614)  loss_rpn_box_reg: 0.0210 (0.0673)  time: 0.3240  data: 0.1427  max mem: 3948\n",
      "Training Epoch: [1]  [ 250/1229]  eta: 0:05:20  lr: 0.005000  loss: 0.5186 (0.5671)  loss_classifier: 0.1610 (0.1868)  loss_box_reg: 0.1248 (0.1466)  loss_objectness: 0.1702 (0.1644)  loss_rpn_box_reg: 0.0532 (0.0694)  time: 0.3321  data: 0.1449  max mem: 3948\n",
      "Training Epoch: [1]  [ 260/1229]  eta: 0:05:17  lr: 0.005000  loss: 0.4692 (0.5630)  loss_classifier: 0.1579 (0.1856)  loss_box_reg: 0.1233 (0.1460)  loss_objectness: 0.1293 (0.1627)  loss_rpn_box_reg: 0.0601 (0.0687)  time: 0.3312  data: 0.1477  max mem: 3948\n",
      "Training Epoch: [1]  [ 270/1229]  eta: 0:05:13  lr: 0.005000  loss: 0.4302 (0.5613)  loss_classifier: 0.1535 (0.1847)  loss_box_reg: 0.1170 (0.1452)  loss_objectness: 0.1293 (0.1625)  loss_rpn_box_reg: 0.0290 (0.0689)  time: 0.3228  data: 0.1417  max mem: 3948\n",
      "Training Epoch: [1]  [ 280/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.4942 (0.5585)  loss_classifier: 0.1563 (0.1841)  loss_box_reg: 0.1171 (0.1453)  loss_objectness: 0.1347 (0.1614)  loss_rpn_box_reg: 0.0313 (0.0678)  time: 0.3194  data: 0.1371  max mem: 3948\n",
      "Training Epoch: [1]  [ 290/1229]  eta: 0:05:07  lr: 0.005000  loss: 0.4942 (0.5609)  loss_classifier: 0.1748 (0.1854)  loss_box_reg: 0.1426 (0.1463)  loss_objectness: 0.1219 (0.1610)  loss_rpn_box_reg: 0.0313 (0.0682)  time: 0.3235  data: 0.1444  max mem: 3948\n",
      "Training Epoch: [1]  [ 300/1229]  eta: 0:05:03  lr: 0.005000  loss: 0.4742 (0.5596)  loss_classifier: 0.1696 (0.1840)  loss_box_reg: 0.1426 (0.1455)  loss_objectness: 0.1009 (0.1614)  loss_rpn_box_reg: 0.0308 (0.0687)  time: 0.3250  data: 0.1458  max mem: 3948\n",
      "Training Epoch: [1]  [ 310/1229]  eta: 0:05:00  lr: 0.005000  loss: 0.4738 (0.5635)  loss_classifier: 0.1574 (0.1850)  loss_box_reg: 0.1216 (0.1469)  loss_objectness: 0.1273 (0.1619)  loss_rpn_box_reg: 0.0330 (0.0698)  time: 0.3230  data: 0.1405  max mem: 3948\n",
      "Training Epoch: [1]  [ 320/1229]  eta: 0:04:56  lr: 0.005000  loss: 0.4722 (0.5590)  loss_classifier: 0.1537 (0.1829)  loss_box_reg: 0.1029 (0.1449)  loss_objectness: 0.1273 (0.1611)  loss_rpn_box_reg: 0.0330 (0.0701)  time: 0.3197  data: 0.1400  max mem: 3948\n",
      "Training Epoch: [1]  [ 330/1229]  eta: 0:04:53  lr: 0.005000  loss: 0.4162 (0.5588)  loss_classifier: 0.1145 (0.1821)  loss_box_reg: 0.0854 (0.1444)  loss_objectness: 0.1194 (0.1618)  loss_rpn_box_reg: 0.0263 (0.0704)  time: 0.3168  data: 0.1415  max mem: 3948\n",
      "Training Epoch: [1]  [ 340/1229]  eta: 0:04:49  lr: 0.005000  loss: 0.5334 (0.5581)  loss_classifier: 0.1609 (0.1824)  loss_box_reg: 0.1368 (0.1446)  loss_objectness: 0.1501 (0.1616)  loss_rpn_box_reg: 0.0341 (0.0695)  time: 0.3181  data: 0.1437  max mem: 3948\n",
      "Training Epoch: [1]  [ 350/1229]  eta: 0:04:46  lr: 0.005000  loss: 0.5426 (0.5573)  loss_classifier: 0.1786 (0.1821)  loss_box_reg: 0.1372 (0.1446)  loss_objectness: 0.1450 (0.1611)  loss_rpn_box_reg: 0.0417 (0.0695)  time: 0.3225  data: 0.1435  max mem: 3948\n",
      "Training Epoch: [1]  [ 360/1229]  eta: 0:04:43  lr: 0.005000  loss: 0.5494 (0.5577)  loss_classifier: 0.1681 (0.1825)  loss_box_reg: 0.1839 (0.1458)  loss_objectness: 0.1193 (0.1603)  loss_rpn_box_reg: 0.0499 (0.0691)  time: 0.3213  data: 0.1419  max mem: 3948\n",
      "Training Epoch: [1]  [ 370/1229]  eta: 0:04:39  lr: 0.005000  loss: 0.5036 (0.5570)  loss_classifier: 0.1771 (0.1827)  loss_box_reg: 0.1357 (0.1457)  loss_objectness: 0.1308 (0.1598)  loss_rpn_box_reg: 0.0446 (0.0688)  time: 0.3235  data: 0.1429  max mem: 3948\n",
      "Training Epoch: [1]  [ 380/1229]  eta: 0:04:36  lr: 0.005000  loss: 0.4719 (0.5578)  loss_classifier: 0.1604 (0.1825)  loss_box_reg: 0.1300 (0.1455)  loss_objectness: 0.1506 (0.1604)  loss_rpn_box_reg: 0.0317 (0.0694)  time: 0.3247  data: 0.1428  max mem: 3948\n",
      "Training Epoch: [1]  [ 390/1229]  eta: 0:04:33  lr: 0.005000  loss: 0.5451 (0.5562)  loss_classifier: 0.1404 (0.1821)  loss_box_reg: 0.1256 (0.1451)  loss_objectness: 0.1738 (0.1604)  loss_rpn_box_reg: 0.0215 (0.0687)  time: 0.3225  data: 0.1417  max mem: 3948\n",
      "Training Epoch: [1]  [ 400/1229]  eta: 0:04:29  lr: 0.005000  loss: 0.4385 (0.5518)  loss_classifier: 0.1198 (0.1807)  loss_box_reg: 0.0882 (0.1439)  loss_objectness: 0.1170 (0.1593)  loss_rpn_box_reg: 0.0198 (0.0680)  time: 0.3205  data: 0.1410  max mem: 3948\n",
      "Training Epoch: [1]  [ 410/1229]  eta: 0:04:26  lr: 0.005000  loss: 0.4509 (0.5500)  loss_classifier: 0.1224 (0.1801)  loss_box_reg: 0.0834 (0.1433)  loss_objectness: 0.1138 (0.1588)  loss_rpn_box_reg: 0.0233 (0.0678)  time: 0.3279  data: 0.1427  max mem: 3948\n",
      "Training Epoch: [1]  [ 420/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.4534 (0.5487)  loss_classifier: 0.1544 (0.1802)  loss_box_reg: 0.0834 (0.1434)  loss_objectness: 0.1138 (0.1579)  loss_rpn_box_reg: 0.0372 (0.0671)  time: 0.3331  data: 0.1421  max mem: 3948\n",
      "Training Epoch: [1]  [ 430/1229]  eta: 0:04:20  lr: 0.005000  loss: 0.3809 (0.5455)  loss_classifier: 0.1354 (0.1794)  loss_box_reg: 0.1036 (0.1426)  loss_objectness: 0.1015 (0.1568)  loss_rpn_box_reg: 0.0306 (0.0667)  time: 0.3310  data: 0.1374  max mem: 3948\n",
      "Training Epoch: [1]  [ 440/1229]  eta: 0:04:16  lr: 0.005000  loss: 0.3809 (0.5420)  loss_classifier: 0.1344 (0.1785)  loss_box_reg: 0.0899 (0.1417)  loss_objectness: 0.1046 (0.1557)  loss_rpn_box_reg: 0.0298 (0.0660)  time: 0.3243  data: 0.1368  max mem: 3948\n",
      "Training Epoch: [1]  [ 450/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.4491 (0.5417)  loss_classifier: 0.1443 (0.1784)  loss_box_reg: 0.0897 (0.1414)  loss_objectness: 0.1371 (0.1564)  loss_rpn_box_reg: 0.0289 (0.0655)  time: 0.3231  data: 0.1378  max mem: 3948\n",
      "Training Epoch: [1]  [ 460/1229]  eta: 0:04:10  lr: 0.005000  loss: 0.5665 (0.5432)  loss_classifier: 0.1542 (0.1788)  loss_box_reg: 0.1059 (0.1418)  loss_objectness: 0.1568 (0.1568)  loss_rpn_box_reg: 0.0434 (0.0658)  time: 0.3367  data: 0.1422  max mem: 3948\n",
      "Training Epoch: [1]  [ 470/1229]  eta: 0:04:07  lr: 0.005000  loss: 0.6176 (0.5448)  loss_classifier: 0.1865 (0.1797)  loss_box_reg: 0.1592 (0.1426)  loss_objectness: 0.1241 (0.1568)  loss_rpn_box_reg: 0.0434 (0.0656)  time: 0.3280  data: 0.1447  max mem: 3948\n",
      "Training Epoch: [1]  [ 480/1229]  eta: 0:04:04  lr: 0.005000  loss: 0.6276 (0.5477)  loss_classifier: 0.1865 (0.1806)  loss_box_reg: 0.1618 (0.1436)  loss_objectness: 0.1462 (0.1572)  loss_rpn_box_reg: 0.0479 (0.0663)  time: 0.3166  data: 0.1406  max mem: 3948\n",
      "Training Epoch: [1]  [ 490/1229]  eta: 0:04:00  lr: 0.005000  loss: 0.6875 (0.5513)  loss_classifier: 0.2407 (0.1820)  loss_box_reg: 0.1859 (0.1446)  loss_objectness: 0.1477 (0.1577)  loss_rpn_box_reg: 0.0532 (0.0670)  time: 0.3185  data: 0.1409  max mem: 3948\n",
      "Training Epoch: [1]  [ 500/1229]  eta: 0:03:57  lr: 0.005000  loss: 0.6203 (0.5503)  loss_classifier: 0.1967 (0.1819)  loss_box_reg: 0.1308 (0.1444)  loss_objectness: 0.1339 (0.1570)  loss_rpn_box_reg: 0.0532 (0.0670)  time: 0.3230  data: 0.1427  max mem: 3948\n",
      "Training Epoch: [1]  [ 510/1229]  eta: 0:03:54  lr: 0.005000  loss: 0.4625 (0.5505)  loss_classifier: 0.1681 (0.1819)  loss_box_reg: 0.0800 (0.1442)  loss_objectness: 0.1392 (0.1570)  loss_rpn_box_reg: 0.0442 (0.0674)  time: 0.3279  data: 0.1411  max mem: 3948\n",
      "Training Epoch: [1]  [ 520/1229]  eta: 0:03:50  lr: 0.005000  loss: 0.5567 (0.5526)  loss_classifier: 0.1844 (0.1826)  loss_box_reg: 0.1807 (0.1456)  loss_objectness: 0.1507 (0.1568)  loss_rpn_box_reg: 0.0417 (0.0677)  time: 0.3239  data: 0.1419  max mem: 3948\n",
      "Training Epoch: [1]  [ 530/1229]  eta: 0:03:47  lr: 0.005000  loss: 0.7064 (0.5558)  loss_classifier: 0.2483 (0.1837)  loss_box_reg: 0.2118 (0.1469)  loss_objectness: 0.1443 (0.1571)  loss_rpn_box_reg: 0.0399 (0.0680)  time: 0.3227  data: 0.1473  max mem: 3948\n",
      "Training Epoch: [1]  [ 540/1229]  eta: 0:03:44  lr: 0.005000  loss: 0.6976 (0.5577)  loss_classifier: 0.2189 (0.1846)  loss_box_reg: 0.1896 (0.1477)  loss_objectness: 0.1784 (0.1574)  loss_rpn_box_reg: 0.0478 (0.0681)  time: 0.3248  data: 0.1457  max mem: 3948\n",
      "Training Epoch: [1]  [ 550/1229]  eta: 0:03:40  lr: 0.005000  loss: 0.5499 (0.5598)  loss_classifier: 0.2189 (0.1857)  loss_box_reg: 0.1640 (0.1485)  loss_objectness: 0.1638 (0.1575)  loss_rpn_box_reg: 0.0478 (0.0681)  time: 0.3205  data: 0.1418  max mem: 3948\n",
      "Training Epoch: [1]  [ 560/1229]  eta: 0:03:37  lr: 0.005000  loss: 0.4888 (0.5591)  loss_classifier: 0.1866 (0.1856)  loss_box_reg: 0.1295 (0.1485)  loss_objectness: 0.1329 (0.1568)  loss_rpn_box_reg: 0.0355 (0.0681)  time: 0.3280  data: 0.1468  max mem: 3948\n",
      "Training Epoch: [1]  [ 570/1229]  eta: 0:03:34  lr: 0.005000  loss: 0.5402 (0.5599)  loss_classifier: 0.1662 (0.1856)  loss_box_reg: 0.1175 (0.1486)  loss_objectness: 0.1329 (0.1573)  loss_rpn_box_reg: 0.0355 (0.0684)  time: 0.3383  data: 0.1472  max mem: 3948\n",
      "Training Epoch: [1]  [ 580/1229]  eta: 0:03:31  lr: 0.005000  loss: 0.3970 (0.5586)  loss_classifier: 0.1311 (0.1851)  loss_box_reg: 0.1069 (0.1484)  loss_objectness: 0.1437 (0.1567)  loss_rpn_box_reg: 0.0267 (0.0685)  time: 0.3316  data: 0.1439  max mem: 3948\n",
      "Training Epoch: [1]  [ 590/1229]  eta: 0:03:28  lr: 0.005000  loss: 0.3435 (0.5563)  loss_classifier: 0.1204 (0.1844)  loss_box_reg: 0.0811 (0.1477)  loss_objectness: 0.0972 (0.1562)  loss_rpn_box_reg: 0.0223 (0.0680)  time: 0.3306  data: 0.1441  max mem: 3948\n",
      "Training Epoch: [1]  [ 600/1229]  eta: 0:03:25  lr: 0.005000  loss: 0.4101 (0.5541)  loss_classifier: 0.1324 (0.1839)  loss_box_reg: 0.0772 (0.1473)  loss_objectness: 0.1160 (0.1556)  loss_rpn_box_reg: 0.0257 (0.0673)  time: 0.3323  data: 0.1404  max mem: 3948\n",
      "Training Epoch: [1]  [ 610/1229]  eta: 0:03:21  lr: 0.005000  loss: 0.3469 (0.5517)  loss_classifier: 0.1312 (0.1831)  loss_box_reg: 0.0860 (0.1467)  loss_objectness: 0.1162 (0.1550)  loss_rpn_box_reg: 0.0241 (0.0669)  time: 0.3265  data: 0.1386  max mem: 3948\n",
      "Training Epoch: [1]  [ 620/1229]  eta: 0:03:18  lr: 0.005000  loss: 0.3469 (0.5498)  loss_classifier: 0.1148 (0.1823)  loss_box_reg: 0.0891 (0.1462)  loss_objectness: 0.1081 (0.1547)  loss_rpn_box_reg: 0.0215 (0.0666)  time: 0.3252  data: 0.1418  max mem: 3948\n",
      "Training Epoch: [1]  [ 630/1229]  eta: 0:03:15  lr: 0.005000  loss: 0.3551 (0.5472)  loss_classifier: 0.1191 (0.1816)  loss_box_reg: 0.0904 (0.1454)  loss_objectness: 0.1081 (0.1542)  loss_rpn_box_reg: 0.0268 (0.0661)  time: 0.3273  data: 0.1422  max mem: 3948\n",
      "Training Epoch: [1]  [ 640/1229]  eta: 0:03:12  lr: 0.005000  loss: 0.4294 (0.5464)  loss_classifier: 0.1363 (0.1815)  loss_box_reg: 0.1047 (0.1454)  loss_objectness: 0.1151 (0.1538)  loss_rpn_box_reg: 0.0279 (0.0656)  time: 0.3287  data: 0.1408  max mem: 3948\n",
      "Training Epoch: [1]  [ 650/1229]  eta: 0:03:08  lr: 0.005000  loss: 0.4323 (0.5446)  loss_classifier: 0.1555 (0.1810)  loss_box_reg: 0.1180 (0.1450)  loss_objectness: 0.1083 (0.1534)  loss_rpn_box_reg: 0.0239 (0.0653)  time: 0.3234  data: 0.1414  max mem: 3948\n",
      "Training Epoch: [1]  [ 660/1229]  eta: 0:03:05  lr: 0.005000  loss: 0.4397 (0.5437)  loss_classifier: 0.1588 (0.1809)  loss_box_reg: 0.1191 (0.1451)  loss_objectness: 0.1083 (0.1530)  loss_rpn_box_reg: 0.0244 (0.0647)  time: 0.3234  data: 0.1418  max mem: 3948\n",
      "Training Epoch: [1]  [ 670/1229]  eta: 0:03:02  lr: 0.005000  loss: 0.5011 (0.5435)  loss_classifier: 0.1815 (0.1808)  loss_box_reg: 0.1543 (0.1449)  loss_objectness: 0.1358 (0.1530)  loss_rpn_box_reg: 0.0286 (0.0648)  time: 0.3281  data: 0.1435  max mem: 3948\n",
      "Training Epoch: [1]  [ 680/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.6333 (0.5451)  loss_classifier: 0.1936 (0.1815)  loss_box_reg: 0.1604 (0.1458)  loss_objectness: 0.1512 (0.1531)  loss_rpn_box_reg: 0.0614 (0.0648)  time: 0.3221  data: 0.1450  max mem: 3948\n",
      "Training Epoch: [1]  [ 690/1229]  eta: 0:02:55  lr: 0.005000  loss: 0.5625 (0.5449)  loss_classifier: 0.1847 (0.1812)  loss_box_reg: 0.1587 (0.1458)  loss_objectness: 0.1284 (0.1529)  loss_rpn_box_reg: 0.0594 (0.0650)  time: 0.3184  data: 0.1407  max mem: 3948\n",
      "Training Epoch: [1]  [ 700/1229]  eta: 0:02:52  lr: 0.005000  loss: 0.5104 (0.5433)  loss_classifier: 0.1433 (0.1807)  loss_box_reg: 0.1098 (0.1452)  loss_objectness: 0.1162 (0.1524)  loss_rpn_box_reg: 0.0309 (0.0649)  time: 0.3201  data: 0.1395  max mem: 3948\n",
      "Training Epoch: [1]  [ 710/1229]  eta: 0:02:49  lr: 0.005000  loss: 0.4623 (0.5442)  loss_classifier: 0.1553 (0.1810)  loss_box_reg: 0.0966 (0.1456)  loss_objectness: 0.1334 (0.1527)  loss_rpn_box_reg: 0.0533 (0.0648)  time: 0.3266  data: 0.1411  max mem: 3948\n",
      "Training Epoch: [1]  [ 720/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.4669 (0.5435)  loss_classifier: 0.1553 (0.1809)  loss_box_reg: 0.1107 (0.1453)  loss_objectness: 0.1608 (0.1529)  loss_rpn_box_reg: 0.0427 (0.0644)  time: 0.3307  data: 0.1433  max mem: 3948\n",
      "Training Epoch: [1]  [ 730/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.4107 (0.5418)  loss_classifier: 0.1310 (0.1804)  loss_box_reg: 0.0826 (0.1448)  loss_objectness: 0.1261 (0.1524)  loss_rpn_box_reg: 0.0273 (0.0642)  time: 0.3307  data: 0.1453  max mem: 3948\n",
      "Training Epoch: [1]  [ 740/1229]  eta: 0:02:39  lr: 0.005000  loss: 0.3054 (0.5392)  loss_classifier: 0.1162 (0.1797)  loss_box_reg: 0.0826 (0.1441)  loss_objectness: 0.0778 (0.1517)  loss_rpn_box_reg: 0.0231 (0.0637)  time: 0.3286  data: 0.1421  max mem: 3948\n",
      "Training Epoch: [1]  [ 750/1229]  eta: 0:02:36  lr: 0.005000  loss: 0.3054 (0.5389)  loss_classifier: 0.1222 (0.1797)  loss_box_reg: 0.0832 (0.1439)  loss_objectness: 0.0793 (0.1518)  loss_rpn_box_reg: 0.0184 (0.0636)  time: 0.3281  data: 0.1403  max mem: 3948\n",
      "Training Epoch: [1]  [ 760/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.4023 (0.5381)  loss_classifier: 0.1471 (0.1794)  loss_box_reg: 0.1112 (0.1437)  loss_objectness: 0.1127 (0.1515)  loss_rpn_box_reg: 0.0227 (0.0635)  time: 0.3278  data: 0.1398  max mem: 3948\n",
      "Training Epoch: [1]  [ 770/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.5394 (0.5392)  loss_classifier: 0.1943 (0.1800)  loss_box_reg: 0.1457 (0.1443)  loss_objectness: 0.1127 (0.1513)  loss_rpn_box_reg: 0.0378 (0.0636)  time: 0.3219  data: 0.1413  max mem: 3948\n",
      "Training Epoch: [1]  [ 780/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.6123 (0.5402)  loss_classifier: 0.2105 (0.1803)  loss_box_reg: 0.1849 (0.1447)  loss_objectness: 0.1244 (0.1511)  loss_rpn_box_reg: 0.0469 (0.0640)  time: 0.3193  data: 0.1439  max mem: 3948\n",
      "Training Epoch: [1]  [ 790/1229]  eta: 0:02:23  lr: 0.005000  loss: 0.4871 (0.5397)  loss_classifier: 0.1719 (0.1798)  loss_box_reg: 0.1285 (0.1443)  loss_objectness: 0.1218 (0.1510)  loss_rpn_box_reg: 0.0498 (0.0647)  time: 0.3239  data: 0.1437  max mem: 3948\n",
      "Training Epoch: [1]  [ 800/1229]  eta: 0:02:19  lr: 0.005000  loss: 0.3923 (0.5393)  loss_classifier: 0.1073 (0.1795)  loss_box_reg: 0.0915 (0.1441)  loss_objectness: 0.1145 (0.1508)  loss_rpn_box_reg: 0.0400 (0.0649)  time: 0.3252  data: 0.1408  max mem: 3948\n",
      "Training Epoch: [1]  [ 810/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.4708 (0.5396)  loss_classifier: 0.1403 (0.1792)  loss_box_reg: 0.1008 (0.1440)  loss_objectness: 0.1473 (0.1510)  loss_rpn_box_reg: 0.0411 (0.0654)  time: 0.3218  data: 0.1374  max mem: 3948\n",
      "Training Epoch: [1]  [ 820/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.4474 (0.5388)  loss_classifier: 0.1362 (0.1787)  loss_box_reg: 0.1041 (0.1438)  loss_objectness: 0.1299 (0.1510)  loss_rpn_box_reg: 0.0294 (0.0654)  time: 0.3209  data: 0.1377  max mem: 3948\n",
      "Training Epoch: [1]  [ 830/1229]  eta: 0:02:09  lr: 0.005000  loss: 0.4088 (0.5388)  loss_classifier: 0.1169 (0.1786)  loss_box_reg: 0.0734 (0.1437)  loss_objectness: 0.1299 (0.1511)  loss_rpn_box_reg: 0.0294 (0.0654)  time: 0.3236  data: 0.1416  max mem: 3948\n",
      "Training Epoch: [1]  [ 840/1229]  eta: 0:02:06  lr: 0.005000  loss: 0.4734 (0.5389)  loss_classifier: 0.1416 (0.1784)  loss_box_reg: 0.1157 (0.1438)  loss_objectness: 0.1345 (0.1510)  loss_rpn_box_reg: 0.0419 (0.0657)  time: 0.3260  data: 0.1450  max mem: 3948\n",
      "Training Epoch: [1]  [ 850/1229]  eta: 0:02:03  lr: 0.005000  loss: 0.4770 (0.5389)  loss_classifier: 0.1451 (0.1784)  loss_box_reg: 0.1295 (0.1437)  loss_objectness: 0.1345 (0.1512)  loss_rpn_box_reg: 0.0411 (0.0656)  time: 0.3267  data: 0.1444  max mem: 3948\n",
      "Training Epoch: [1]  [ 860/1229]  eta: 0:02:00  lr: 0.005000  loss: 0.3546 (0.5371)  loss_classifier: 0.1233 (0.1780)  loss_box_reg: 0.1029 (0.1432)  loss_objectness: 0.0991 (0.1508)  loss_rpn_box_reg: 0.0229 (0.0652)  time: 0.3219  data: 0.1425  max mem: 3948\n",
      "Training Epoch: [1]  [ 870/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.3925 (0.5364)  loss_classifier: 0.1372 (0.1778)  loss_box_reg: 0.0970 (0.1429)  loss_objectness: 0.1123 (0.1507)  loss_rpn_box_reg: 0.0219 (0.0649)  time: 0.3157  data: 0.1431  max mem: 3948\n",
      "Training Epoch: [1]  [ 880/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.4474 (0.5357)  loss_classifier: 0.1289 (0.1775)  loss_box_reg: 0.1085 (0.1428)  loss_objectness: 0.1458 (0.1507)  loss_rpn_box_reg: 0.0274 (0.0648)  time: 0.3225  data: 0.1432  max mem: 3948\n",
      "Training Epoch: [1]  [ 890/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.4183 (0.5348)  loss_classifier: 0.1173 (0.1772)  loss_box_reg: 0.0977 (0.1426)  loss_objectness: 0.1302 (0.1506)  loss_rpn_box_reg: 0.0240 (0.0645)  time: 0.3259  data: 0.1432  max mem: 3948\n",
      "Training Epoch: [1]  [ 900/1229]  eta: 0:01:47  lr: 0.005000  loss: 0.4477 (0.5346)  loss_classifier: 0.1499 (0.1770)  loss_box_reg: 0.1059 (0.1425)  loss_objectness: 0.1119 (0.1503)  loss_rpn_box_reg: 0.0361 (0.0649)  time: 0.3237  data: 0.1423  max mem: 3948\n",
      "Training Epoch: [1]  [ 910/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.4540 (0.5352)  loss_classifier: 0.1513 (0.1772)  loss_box_reg: 0.1256 (0.1426)  loss_objectness: 0.1160 (0.1505)  loss_rpn_box_reg: 0.0361 (0.0649)  time: 0.3221  data: 0.1431  max mem: 3948\n",
      "Training Epoch: [1]  [ 920/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.4395 (0.5343)  loss_classifier: 0.1546 (0.1770)  loss_box_reg: 0.1604 (0.1424)  loss_objectness: 0.1286 (0.1501)  loss_rpn_box_reg: 0.0280 (0.0648)  time: 0.3246  data: 0.1453  max mem: 3948\n",
      "Training Epoch: [1]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.3670 (0.5333)  loss_classifier: 0.1310 (0.1767)  loss_box_reg: 0.0948 (0.1419)  loss_objectness: 0.1171 (0.1500)  loss_rpn_box_reg: 0.0236 (0.0647)  time: 0.3310  data: 0.1432  max mem: 3948\n",
      "Training Epoch: [1]  [ 940/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.4367 (0.5337)  loss_classifier: 0.1640 (0.1770)  loss_box_reg: 0.1174 (0.1424)  loss_objectness: 0.1020 (0.1497)  loss_rpn_box_reg: 0.0261 (0.0646)  time: 0.3286  data: 0.1420  max mem: 3948\n",
      "Training Epoch: [1]  [ 950/1229]  eta: 0:01:30  lr: 0.005000  loss: 0.5112 (0.5328)  loss_classifier: 0.1684 (0.1768)  loss_box_reg: 0.1357 (0.1423)  loss_objectness: 0.1029 (0.1494)  loss_rpn_box_reg: 0.0297 (0.0642)  time: 0.3300  data: 0.1449  max mem: 3948\n",
      "Training Epoch: [1]  [ 960/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.4237 (0.5324)  loss_classifier: 0.1462 (0.1766)  loss_box_reg: 0.0906 (0.1420)  loss_objectness: 0.1190 (0.1495)  loss_rpn_box_reg: 0.0358 (0.0643)  time: 0.3289  data: 0.1449  max mem: 3948\n",
      "Training Epoch: [1]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.4159 (0.5327)  loss_classifier: 0.1320 (0.1766)  loss_box_reg: 0.1039 (0.1420)  loss_objectness: 0.1404 (0.1497)  loss_rpn_box_reg: 0.0472 (0.0644)  time: 0.3251  data: 0.1426  max mem: 3948\n",
      "Training Epoch: [1]  [ 980/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.4408 (0.5317)  loss_classifier: 0.1343 (0.1763)  loss_box_reg: 0.1039 (0.1416)  loss_objectness: 0.1243 (0.1494)  loss_rpn_box_reg: 0.0377 (0.0644)  time: 0.3227  data: 0.1404  max mem: 3948\n",
      "Training Epoch: [1]  [ 990/1229]  eta: 0:01:17  lr: 0.005000  loss: 0.3931 (0.5323)  loss_classifier: 0.1343 (0.1764)  loss_box_reg: 0.0945 (0.1420)  loss_objectness: 0.1288 (0.1494)  loss_rpn_box_reg: 0.0351 (0.0645)  time: 0.3196  data: 0.1390  max mem: 3948\n",
      "Training Epoch: [1]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.4283 (0.5318)  loss_classifier: 0.1471 (0.1761)  loss_box_reg: 0.0909 (0.1417)  loss_objectness: 0.1332 (0.1496)  loss_rpn_box_reg: 0.0352 (0.0645)  time: 0.3245  data: 0.1419  max mem: 3948\n",
      "Training Epoch: [1]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.5116 (0.5323)  loss_classifier: 0.1542 (0.1762)  loss_box_reg: 0.0997 (0.1417)  loss_objectness: 0.1726 (0.1498)  loss_rpn_box_reg: 0.0469 (0.0645)  time: 0.3231  data: 0.1421  max mem: 3948\n",
      "Training Epoch: [1]  [1020/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.5328 (0.5328)  loss_classifier: 0.1853 (0.1765)  loss_box_reg: 0.1366 (0.1420)  loss_objectness: 0.1519 (0.1498)  loss_rpn_box_reg: 0.0469 (0.0644)  time: 0.3237  data: 0.1367  max mem: 3948\n",
      "Training Epoch: [1]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.4643 (0.5315)  loss_classifier: 0.1503 (0.1762)  loss_box_reg: 0.1241 (0.1418)  loss_objectness: 0.1312 (0.1494)  loss_rpn_box_reg: 0.0373 (0.0641)  time: 0.3240  data: 0.1347  max mem: 3948\n",
      "Training Epoch: [1]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.4562 (0.5319)  loss_classifier: 0.1442 (0.1765)  loss_box_reg: 0.1151 (0.1420)  loss_objectness: 0.1057 (0.1493)  loss_rpn_box_reg: 0.0355 (0.0641)  time: 0.3217  data: 0.1393  max mem: 3948\n",
      "Training Epoch: [1]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.5528 (0.5326)  loss_classifier: 0.2142 (0.1769)  loss_box_reg: 0.1367 (0.1423)  loss_objectness: 0.1349 (0.1494)  loss_rpn_box_reg: 0.0363 (0.0640)  time: 0.3218  data: 0.1404  max mem: 3948\n",
      "Training Epoch: [1]  [1060/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.5841 (0.5329)  loss_classifier: 0.1977 (0.1771)  loss_box_reg: 0.1695 (0.1425)  loss_objectness: 0.1349 (0.1493)  loss_rpn_box_reg: 0.0466 (0.0640)  time: 0.3226  data: 0.1421  max mem: 3948\n",
      "Training Epoch: [1]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.4528 (0.5327)  loss_classifier: 0.1733 (0.1770)  loss_box_reg: 0.1320 (0.1424)  loss_objectness: 0.1160 (0.1494)  loss_rpn_box_reg: 0.0492 (0.0639)  time: 0.3230  data: 0.1426  max mem: 3948\n",
      "Training Epoch: [1]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.4648 (0.5329)  loss_classifier: 0.1659 (0.1772)  loss_box_reg: 0.0827 (0.1426)  loss_objectness: 0.1198 (0.1495)  loss_rpn_box_reg: 0.0451 (0.0636)  time: 0.3198  data: 0.1423  max mem: 3948\n",
      "Training Epoch: [1]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.5479 (0.5331)  loss_classifier: 0.1671 (0.1772)  loss_box_reg: 0.1392 (0.1426)  loss_objectness: 0.1395 (0.1498)  loss_rpn_box_reg: 0.0451 (0.0635)  time: 0.3183  data: 0.1416  max mem: 3948\n",
      "Training Epoch: [1]  [1100/1229]  eta: 0:00:41  lr: 0.005000  loss: 0.3948 (0.5323)  loss_classifier: 0.1439 (0.1768)  loss_box_reg: 0.0955 (0.1424)  loss_objectness: 0.1041 (0.1496)  loss_rpn_box_reg: 0.0241 (0.0635)  time: 0.3217  data: 0.1390  max mem: 3948\n",
      "Training Epoch: [1]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.3948 (0.5328)  loss_classifier: 0.1451 (0.1771)  loss_box_reg: 0.0955 (0.1426)  loss_objectness: 0.1041 (0.1496)  loss_rpn_box_reg: 0.0266 (0.0634)  time: 0.3254  data: 0.1416  max mem: 3948\n",
      "Training Epoch: [1]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4504 (0.5318)  loss_classifier: 0.1476 (0.1768)  loss_box_reg: 0.0984 (0.1421)  loss_objectness: 0.1334 (0.1496)  loss_rpn_box_reg: 0.0339 (0.0634)  time: 0.3276  data: 0.1461  max mem: 3948\n",
      "Training Epoch: [1]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.4504 (0.5325)  loss_classifier: 0.1610 (0.1770)  loss_box_reg: 0.1168 (0.1424)  loss_objectness: 0.1476 (0.1497)  loss_rpn_box_reg: 0.0356 (0.0634)  time: 0.3241  data: 0.1459  max mem: 3948\n",
      "Training Epoch: [1]  [1140/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.4751 (0.5314)  loss_classifier: 0.1610 (0.1766)  loss_box_reg: 0.1065 (0.1421)  loss_objectness: 0.1476 (0.1494)  loss_rpn_box_reg: 0.0356 (0.0632)  time: 0.3182  data: 0.1441  max mem: 3948\n",
      "Training Epoch: [1]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.3406 (0.5307)  loss_classifier: 0.1108 (0.1763)  loss_box_reg: 0.0665 (0.1417)  loss_objectness: 0.1151 (0.1494)  loss_rpn_box_reg: 0.0250 (0.0633)  time: 0.3269  data: 0.1472  max mem: 3948\n",
      "Training Epoch: [1]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.3204 (0.5296)  loss_classifier: 0.1093 (0.1759)  loss_box_reg: 0.0939 (0.1413)  loss_objectness: 0.1032 (0.1491)  loss_rpn_box_reg: 0.0250 (0.0633)  time: 0.3343  data: 0.1455  max mem: 3948\n",
      "Training Epoch: [1]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.3298 (0.5294)  loss_classifier: 0.1233 (0.1758)  loss_box_reg: 0.0939 (0.1412)  loss_objectness: 0.1036 (0.1492)  loss_rpn_box_reg: 0.0245 (0.0633)  time: 0.3334  data: 0.1432  max mem: 3948\n",
      "Training Epoch: [1]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.4546 (0.5294)  loss_classifier: 0.1366 (0.1757)  loss_box_reg: 0.1096 (0.1412)  loss_objectness: 0.1082 (0.1492)  loss_rpn_box_reg: 0.0275 (0.0633)  time: 0.3284  data: 0.1454  max mem: 3948\n",
      "Training Epoch: [1]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.4594 (0.5296)  loss_classifier: 0.1591 (0.1758)  loss_box_reg: 0.1392 (0.1415)  loss_objectness: 0.1284 (0.1492)  loss_rpn_box_reg: 0.0342 (0.0631)  time: 0.3224  data: 0.1459  max mem: 3948\n",
      "Training Epoch: [1]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.4937 (0.5293)  loss_classifier: 0.1729 (0.1758)  loss_box_reg: 0.1433 (0.1416)  loss_objectness: 0.1245 (0.1490)  loss_rpn_box_reg: 0.0325 (0.0630)  time: 0.3225  data: 0.1442  max mem: 3948\n",
      "Training Epoch: [1]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.5151 (0.5309)  loss_classifier: 0.1941 (0.1764)  loss_box_reg: 0.1433 (0.1420)  loss_objectness: 0.1135 (0.1493)  loss_rpn_box_reg: 0.0333 (0.0631)  time: 0.3297  data: 0.1445  max mem: 3948\n",
      "Training Epoch: [1]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.5151 (0.5303)  loss_classifier: 0.2036 (0.1762)  loss_box_reg: 0.1327 (0.1419)  loss_objectness: 0.1451 (0.1493)  loss_rpn_box_reg: 0.0387 (0.0629)  time: 0.3345  data: 0.1454  max mem: 3948\n",
      "Training Epoch: [1]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4994 (0.5302)  loss_classifier: 0.1895 (0.1763)  loss_box_reg: 0.1108 (0.1420)  loss_objectness: 0.1366 (0.1492)  loss_rpn_box_reg: 0.0283 (0.0627)  time: 0.3329  data: 0.1442  max mem: 3948\n",
      "Training Epoch: [1] Total time: 0:06:40 (0.3256 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:37  model_time: 0.2770 (0.2770)  evaluator_time: 0.0060 (0.0060)  time: 0.3170  data: 0.0310  max mem: 3948\n",
      "Test:  [100/308]  eta: 0:00:33  model_time: 0.1020 (0.1101)  evaluator_time: 0.0090 (0.0102)  time: 0.1618  data: 0.0405  max mem: 3948\n",
      "Test:  [200/308]  eta: 0:00:17  model_time: 0.1110 (0.1101)  evaluator_time: 0.0050 (0.0095)  time: 0.1559  data: 0.0328  max mem: 3948\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0970 (0.1093)  evaluator_time: 0.0060 (0.0095)  time: 0.1518  data: 0.0383  max mem: 3948\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.1010 (0.1091)  evaluator_time: 0.0050 (0.0094)  time: 0.1477  data: 0.0362  max mem: 3948\n",
      "Test: Total time: 0:00:48 (0.1576 s / it)\n",
      "Averaged stats: model_time: 0.1010 (0.1091)  evaluator_time: 0.0050 (0.0094)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.23s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.096\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.207\n",
      "Testing Epoch: [1]  [  0/308]  eta: 0:00:46  lr: 0.005000  loss: 0.2265 (0.2265)  loss_classifier: 0.0778 (0.0778)  loss_box_reg: 0.0570 (0.0570)  loss_objectness: 0.0830 (0.0830)  loss_rpn_box_reg: 0.0086 (0.0086)  time: 0.1510  data: 0.0290  max mem: 3948\n",
      "Testing Epoch: [1]  [100/308]  eta: 0:00:36  lr: 0.005000  loss: 0.3642 (0.5334)  loss_classifier: 0.1536 (0.1791)  loss_box_reg: 0.1133 (0.1597)  loss_objectness: 0.0882 (0.1286)  loss_rpn_box_reg: 0.0246 (0.0659)  time: 0.1789  data: 0.0423  max mem: 3948\n",
      "Testing Epoch: [1]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.5291 (0.5088)  loss_classifier: 0.1510 (0.1722)  loss_box_reg: 0.1400 (0.1524)  loss_objectness: 0.0927 (0.1221)  loss_rpn_box_reg: 0.0342 (0.0622)  time: 0.1793  data: 0.0367  max mem: 3948\n",
      "Testing Epoch: [1]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5520 (0.5095)  loss_classifier: 0.1902 (0.1730)  loss_box_reg: 0.1496 (0.1560)  loss_objectness: 0.1140 (0.1204)  loss_rpn_box_reg: 0.0306 (0.0601)  time: 0.1706  data: 0.0429  max mem: 3961\n",
      "Testing Epoch: [1]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.5337 (0.5093)  loss_classifier: 0.1694 (0.1731)  loss_box_reg: 0.1496 (0.1563)  loss_objectness: 0.1140 (0.1205)  loss_rpn_box_reg: 0.0306 (0.0595)  time: 0.1694  data: 0.0418  max mem: 3961\n",
      "Testing Epoch: [1] Total time: 0:00:54 (0.1761 s / it)\n",
      "Training Epoch: [2]  [   0/1229]  eta: 0:06:40  lr: 0.005000  loss: 0.9018 (0.9018)  loss_classifier: 0.3168 (0.3168)  loss_box_reg: 0.2448 (0.2448)  loss_objectness: 0.2612 (0.2612)  loss_rpn_box_reg: 0.0790 (0.0790)  time: 0.3260  data: 0.1540  max mem: 3961\n",
      "Training Epoch: [2]  [  10/1229]  eta: 0:06:40  lr: 0.005000  loss: 0.5172 (0.5149)  loss_classifier: 0.1358 (0.1740)  loss_box_reg: 0.1129 (0.1401)  loss_objectness: 0.1189 (0.1525)  loss_rpn_box_reg: 0.0309 (0.0484)  time: 0.3287  data: 0.1424  max mem: 3961\n",
      "Training Epoch: [2]  [  20/1229]  eta: 0:06:29  lr: 0.005000  loss: 0.4367 (0.4725)  loss_classifier: 0.1358 (0.1605)  loss_box_reg: 0.1109 (0.1386)  loss_objectness: 0.1016 (0.1313)  loss_rpn_box_reg: 0.0258 (0.0422)  time: 0.3222  data: 0.1416  max mem: 3961\n",
      "Training Epoch: [2]  [  30/1229]  eta: 0:06:28  lr: 0.005000  loss: 0.4975 (0.4874)  loss_classifier: 0.1493 (0.1658)  loss_box_reg: 0.1109 (0.1380)  loss_objectness: 0.1041 (0.1378)  loss_rpn_box_reg: 0.0316 (0.0458)  time: 0.3208  data: 0.1421  max mem: 3961\n",
      "Training Epoch: [2]  [  40/1229]  eta: 0:06:26  lr: 0.005000  loss: 0.5188 (0.4708)  loss_classifier: 0.1493 (0.1606)  loss_box_reg: 0.0962 (0.1343)  loss_objectness: 0.1210 (0.1328)  loss_rpn_box_reg: 0.0368 (0.0431)  time: 0.3285  data: 0.1418  max mem: 3961\n",
      "Training Epoch: [2]  [  50/1229]  eta: 0:06:22  lr: 0.005000  loss: 0.3487 (0.4582)  loss_classifier: 0.1055 (0.1542)  loss_box_reg: 0.0888 (0.1301)  loss_objectness: 0.0917 (0.1310)  loss_rpn_box_reg: 0.0361 (0.0429)  time: 0.3266  data: 0.1406  max mem: 3961\n",
      "Training Epoch: [2]  [  60/1229]  eta: 0:06:17  lr: 0.005000  loss: 0.3487 (0.4503)  loss_classifier: 0.1055 (0.1512)  loss_box_reg: 0.0647 (0.1248)  loss_objectness: 0.0880 (0.1309)  loss_rpn_box_reg: 0.0331 (0.0434)  time: 0.3186  data: 0.1404  max mem: 3961\n",
      "Training Epoch: [2]  [  70/1229]  eta: 0:06:15  lr: 0.005000  loss: 0.4508 (0.4777)  loss_classifier: 0.1646 (0.1614)  loss_box_reg: 0.0947 (0.1343)  loss_objectness: 0.1370 (0.1340)  loss_rpn_box_reg: 0.0359 (0.0480)  time: 0.3213  data: 0.1435  max mem: 3961\n",
      "Training Epoch: [2]  [  80/1229]  eta: 0:06:12  lr: 0.005000  loss: 0.4429 (0.4681)  loss_classifier: 0.1603 (0.1588)  loss_box_reg: 0.1215 (0.1326)  loss_objectness: 0.1102 (0.1300)  loss_rpn_box_reg: 0.0389 (0.0467)  time: 0.3260  data: 0.1420  max mem: 3961\n",
      "Training Epoch: [2]  [  90/1229]  eta: 0:06:09  lr: 0.005000  loss: 0.3513 (0.4685)  loss_classifier: 0.1306 (0.1591)  loss_box_reg: 0.1206 (0.1349)  loss_objectness: 0.0905 (0.1274)  loss_rpn_box_reg: 0.0284 (0.0470)  time: 0.3248  data: 0.1393  max mem: 3961\n",
      "Training Epoch: [2]  [ 100/1229]  eta: 0:06:05  lr: 0.005000  loss: 0.4556 (0.4799)  loss_classifier: 0.1581 (0.1639)  loss_box_reg: 0.1261 (0.1380)  loss_objectness: 0.1124 (0.1304)  loss_rpn_box_reg: 0.0356 (0.0476)  time: 0.3228  data: 0.1397  max mem: 3961\n",
      "Training Epoch: [2]  [ 110/1229]  eta: 0:06:01  lr: 0.005000  loss: 0.4032 (0.4756)  loss_classifier: 0.1487 (0.1622)  loss_box_reg: 0.1043 (0.1366)  loss_objectness: 0.1337 (0.1302)  loss_rpn_box_reg: 0.0214 (0.0465)  time: 0.3197  data: 0.1395  max mem: 3961\n",
      "Training Epoch: [2]  [ 120/1229]  eta: 0:05:59  lr: 0.005000  loss: 0.3011 (0.4651)  loss_classifier: 0.1029 (0.1586)  loss_box_reg: 0.0871 (0.1326)  loss_objectness: 0.1082 (0.1282)  loss_rpn_box_reg: 0.0214 (0.0458)  time: 0.3257  data: 0.1410  max mem: 3961\n",
      "Training Epoch: [2]  [ 130/1229]  eta: 0:05:55  lr: 0.005000  loss: 0.4536 (0.4745)  loss_classifier: 0.1500 (0.1610)  loss_box_reg: 0.1120 (0.1358)  loss_objectness: 0.1341 (0.1315)  loss_rpn_box_reg: 0.0260 (0.0461)  time: 0.3242  data: 0.1433  max mem: 3961\n",
      "Training Epoch: [2]  [ 140/1229]  eta: 0:05:52  lr: 0.005000  loss: 0.4995 (0.4724)  loss_classifier: 0.1628 (0.1603)  loss_box_reg: 0.1365 (0.1353)  loss_objectness: 0.1252 (0.1309)  loss_rpn_box_reg: 0.0268 (0.0459)  time: 0.3230  data: 0.1411  max mem: 3961\n",
      "Training Epoch: [2]  [ 150/1229]  eta: 0:05:50  lr: 0.005000  loss: 0.5503 (0.4835)  loss_classifier: 0.1904 (0.1641)  loss_box_reg: 0.1469 (0.1381)  loss_objectness: 0.1145 (0.1333)  loss_rpn_box_reg: 0.0456 (0.0480)  time: 0.3339  data: 0.1387  max mem: 3961\n",
      "Training Epoch: [2]  [ 160/1229]  eta: 0:05:48  lr: 0.005000  loss: 0.5503 (0.4872)  loss_classifier: 0.2050 (0.1659)  loss_box_reg: 0.1469 (0.1390)  loss_objectness: 0.1141 (0.1337)  loss_rpn_box_reg: 0.0488 (0.0487)  time: 0.3380  data: 0.1381  max mem: 3961\n",
      "Training Epoch: [2]  [ 170/1229]  eta: 0:05:45  lr: 0.005000  loss: 0.4771 (0.4893)  loss_classifier: 0.1702 (0.1655)  loss_box_reg: 0.1070 (0.1397)  loss_objectness: 0.1126 (0.1335)  loss_rpn_box_reg: 0.0480 (0.0506)  time: 0.3342  data: 0.1367  max mem: 3961\n",
      "Training Epoch: [2]  [ 180/1229]  eta: 0:05:41  lr: 0.005000  loss: 0.4954 (0.4907)  loss_classifier: 0.1523 (0.1660)  loss_box_reg: 0.1270 (0.1398)  loss_objectness: 0.1126 (0.1332)  loss_rpn_box_reg: 0.0414 (0.0518)  time: 0.3272  data: 0.1385  max mem: 3961\n",
      "Training Epoch: [2]  [ 190/1229]  eta: 0:05:38  lr: 0.005000  loss: 0.5196 (0.4944)  loss_classifier: 0.1523 (0.1672)  loss_box_reg: 0.1564 (0.1411)  loss_objectness: 0.1171 (0.1332)  loss_rpn_box_reg: 0.0358 (0.0529)  time: 0.3251  data: 0.1392  max mem: 3961\n",
      "Training Epoch: [2]  [ 200/1229]  eta: 0:05:35  lr: 0.005000  loss: 0.4970 (0.4912)  loss_classifier: 0.1570 (0.1664)  loss_box_reg: 0.1426 (0.1396)  loss_objectness: 0.1161 (0.1322)  loss_rpn_box_reg: 0.0359 (0.0529)  time: 0.3274  data: 0.1399  max mem: 3961\n",
      "Training Epoch: [2]  [ 210/1229]  eta: 0:05:31  lr: 0.005000  loss: 0.4598 (0.4898)  loss_classifier: 0.1441 (0.1659)  loss_box_reg: 0.0984 (0.1391)  loss_objectness: 0.1030 (0.1321)  loss_rpn_box_reg: 0.0309 (0.0528)  time: 0.3234  data: 0.1376  max mem: 3961\n",
      "Training Epoch: [2]  [ 220/1229]  eta: 0:05:28  lr: 0.005000  loss: 0.3955 (0.4893)  loss_classifier: 0.1441 (0.1659)  loss_box_reg: 0.0928 (0.1378)  loss_objectness: 0.1125 (0.1323)  loss_rpn_box_reg: 0.0219 (0.0532)  time: 0.3207  data: 0.1366  max mem: 3961\n",
      "Training Epoch: [2]  [ 230/1229]  eta: 0:05:25  lr: 0.005000  loss: 0.4368 (0.4903)  loss_classifier: 0.1518 (0.1664)  loss_box_reg: 0.1283 (0.1379)  loss_objectness: 0.0969 (0.1318)  loss_rpn_box_reg: 0.0371 (0.0542)  time: 0.3314  data: 0.1466  max mem: 3961\n",
      "Training Epoch: [2]  [ 240/1229]  eta: 0:05:22  lr: 0.005000  loss: 0.4815 (0.4891)  loss_classifier: 0.1580 (0.1660)  loss_box_reg: 0.1274 (0.1373)  loss_objectness: 0.1054 (0.1321)  loss_rpn_box_reg: 0.0371 (0.0537)  time: 0.3345  data: 0.1530  max mem: 3961\n",
      "Training Epoch: [2]  [ 250/1229]  eta: 0:05:19  lr: 0.005000  loss: 0.4541 (0.4898)  loss_classifier: 0.1509 (0.1662)  loss_box_reg: 0.1098 (0.1377)  loss_objectness: 0.1076 (0.1318)  loss_rpn_box_reg: 0.0280 (0.0540)  time: 0.3343  data: 0.1516  max mem: 3961\n",
      "Training Epoch: [2]  [ 260/1229]  eta: 0:05:16  lr: 0.005000  loss: 0.4229 (0.4892)  loss_classifier: 0.1334 (0.1652)  loss_box_reg: 0.1114 (0.1373)  loss_objectness: 0.1198 (0.1326)  loss_rpn_box_reg: 0.0277 (0.0541)  time: 0.3351  data: 0.1463  max mem: 3961\n",
      "Training Epoch: [2]  [ 270/1229]  eta: 0:05:13  lr: 0.005000  loss: 0.4229 (0.4870)  loss_classifier: 0.1334 (0.1648)  loss_box_reg: 0.1114 (0.1366)  loss_objectness: 0.1198 (0.1321)  loss_rpn_box_reg: 0.0278 (0.0536)  time: 0.3333  data: 0.1422  max mem: 3961\n",
      "Training Epoch: [2]  [ 280/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.3456 (0.4845)  loss_classifier: 0.1223 (0.1646)  loss_box_reg: 0.1170 (0.1366)  loss_objectness: 0.0901 (0.1307)  loss_rpn_box_reg: 0.0271 (0.0526)  time: 0.3305  data: 0.1403  max mem: 3961\n",
      "Training Epoch: [2]  [ 290/1229]  eta: 0:05:07  lr: 0.005000  loss: 0.3933 (0.4859)  loss_classifier: 0.1478 (0.1657)  loss_box_reg: 0.1144 (0.1370)  loss_objectness: 0.0958 (0.1309)  loss_rpn_box_reg: 0.0360 (0.0523)  time: 0.3266  data: 0.1396  max mem: 3961\n",
      "Training Epoch: [2]  [ 300/1229]  eta: 0:05:03  lr: 0.005000  loss: 0.4919 (0.4881)  loss_classifier: 0.1608 (0.1660)  loss_box_reg: 0.1144 (0.1384)  loss_objectness: 0.1318 (0.1309)  loss_rpn_box_reg: 0.0464 (0.0528)  time: 0.3230  data: 0.1424  max mem: 3961\n",
      "Training Epoch: [2]  [ 310/1229]  eta: 0:05:00  lr: 0.005000  loss: 0.3786 (0.4828)  loss_classifier: 0.1236 (0.1641)  loss_box_reg: 0.1005 (0.1367)  loss_objectness: 0.1189 (0.1302)  loss_rpn_box_reg: 0.0317 (0.0518)  time: 0.3188  data: 0.1425  max mem: 3961\n",
      "Training Epoch: [2]  [ 320/1229]  eta: 0:04:57  lr: 0.005000  loss: 0.3786 (0.4819)  loss_classifier: 0.1236 (0.1639)  loss_box_reg: 0.0987 (0.1361)  loss_objectness: 0.0988 (0.1308)  loss_rpn_box_reg: 0.0215 (0.0512)  time: 0.3267  data: 0.1423  max mem: 3961\n",
      "Training Epoch: [2]  [ 330/1229]  eta: 0:04:53  lr: 0.005000  loss: 0.4137 (0.4795)  loss_classifier: 0.1428 (0.1630)  loss_box_reg: 0.1007 (0.1349)  loss_objectness: 0.0863 (0.1308)  loss_rpn_box_reg: 0.0230 (0.0509)  time: 0.3280  data: 0.1431  max mem: 3961\n",
      "Training Epoch: [2]  [ 340/1229]  eta: 0:04:50  lr: 0.005000  loss: 0.4133 (0.4814)  loss_classifier: 0.1468 (0.1643)  loss_box_reg: 0.1153 (0.1356)  loss_objectness: 0.0986 (0.1312)  loss_rpn_box_reg: 0.0252 (0.0503)  time: 0.3222  data: 0.1424  max mem: 3961\n",
      "Training Epoch: [2]  [ 350/1229]  eta: 0:04:46  lr: 0.005000  loss: 0.4666 (0.4815)  loss_classifier: 0.1478 (0.1644)  loss_box_reg: 0.1289 (0.1355)  loss_objectness: 0.1221 (0.1314)  loss_rpn_box_reg: 0.0270 (0.0503)  time: 0.3211  data: 0.1395  max mem: 3961\n",
      "Training Epoch: [2]  [ 360/1229]  eta: 0:04:43  lr: 0.005000  loss: 0.4323 (0.4862)  loss_classifier: 0.1381 (0.1649)  loss_box_reg: 0.1051 (0.1357)  loss_objectness: 0.1438 (0.1332)  loss_rpn_box_reg: 0.0372 (0.0523)  time: 0.3213  data: 0.1382  max mem: 3961\n",
      "Training Epoch: [2]  [ 370/1229]  eta: 0:04:40  lr: 0.005000  loss: 0.4885 (0.4890)  loss_classifier: 0.1812 (0.1659)  loss_box_reg: 0.1378 (0.1372)  loss_objectness: 0.1541 (0.1334)  loss_rpn_box_reg: 0.0388 (0.0525)  time: 0.3195  data: 0.1394  max mem: 3961\n",
      "Training Epoch: [2]  [ 380/1229]  eta: 0:04:36  lr: 0.005000  loss: 0.5976 (0.4914)  loss_classifier: 0.2060 (0.1669)  loss_box_reg: 0.1859 (0.1384)  loss_objectness: 0.1215 (0.1336)  loss_rpn_box_reg: 0.0437 (0.0526)  time: 0.3201  data: 0.1401  max mem: 3961\n",
      "Training Epoch: [2]  [ 390/1229]  eta: 0:04:33  lr: 0.005000  loss: 0.5460 (0.4915)  loss_classifier: 0.1762 (0.1668)  loss_box_reg: 0.1474 (0.1383)  loss_objectness: 0.1215 (0.1340)  loss_rpn_box_reg: 0.0387 (0.0524)  time: 0.3241  data: 0.1402  max mem: 3961\n",
      "Training Epoch: [2]  [ 400/1229]  eta: 0:04:30  lr: 0.005000  loss: 0.4492 (0.4907)  loss_classifier: 0.1391 (0.1662)  loss_box_reg: 0.1082 (0.1375)  loss_objectness: 0.1451 (0.1343)  loss_rpn_box_reg: 0.0349 (0.0527)  time: 0.3264  data: 0.1399  max mem: 3961\n",
      "Training Epoch: [2]  [ 410/1229]  eta: 0:04:27  lr: 0.005000  loss: 0.3877 (0.4878)  loss_classifier: 0.1391 (0.1654)  loss_box_reg: 0.1081 (0.1365)  loss_objectness: 0.1137 (0.1338)  loss_rpn_box_reg: 0.0303 (0.0521)  time: 0.3296  data: 0.1391  max mem: 3961\n",
      "Training Epoch: [2]  [ 420/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.3313 (0.4877)  loss_classifier: 0.1216 (0.1651)  loss_box_reg: 0.0634 (0.1362)  loss_objectness: 0.1071 (0.1336)  loss_rpn_box_reg: 0.0303 (0.0529)  time: 0.3277  data: 0.1388  max mem: 3961\n",
      "Training Epoch: [2]  [ 430/1229]  eta: 0:04:20  lr: 0.005000  loss: 0.5569 (0.4904)  loss_classifier: 0.1510 (0.1659)  loss_box_reg: 0.1461 (0.1379)  loss_objectness: 0.1308 (0.1337)  loss_rpn_box_reg: 0.0494 (0.0529)  time: 0.3264  data: 0.1414  max mem: 3961\n",
      "Training Epoch: [2]  [ 440/1229]  eta: 0:04:17  lr: 0.005000  loss: 0.5419 (0.4902)  loss_classifier: 0.1901 (0.1659)  loss_box_reg: 0.1461 (0.1377)  loss_objectness: 0.1365 (0.1338)  loss_rpn_box_reg: 0.0344 (0.0527)  time: 0.3226  data: 0.1418  max mem: 3961\n",
      "Training Epoch: [2]  [ 450/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.5419 (0.4933)  loss_classifier: 0.1853 (0.1668)  loss_box_reg: 0.1401 (0.1383)  loss_objectness: 0.1369 (0.1348)  loss_rpn_box_reg: 0.0296 (0.0534)  time: 0.3187  data: 0.1410  max mem: 3961\n",
      "Training Epoch: [2]  [ 460/1229]  eta: 0:04:10  lr: 0.005000  loss: 0.5825 (0.4961)  loss_classifier: 0.2077 (0.1680)  loss_box_reg: 0.1765 (0.1395)  loss_objectness: 0.1657 (0.1353)  loss_rpn_box_reg: 0.0385 (0.0532)  time: 0.3206  data: 0.1427  max mem: 3961\n",
      "Training Epoch: [2]  [ 470/1229]  eta: 0:04:07  lr: 0.005000  loss: 0.4564 (0.4966)  loss_classifier: 0.1610 (0.1681)  loss_box_reg: 0.1134 (0.1394)  loss_objectness: 0.1396 (0.1357)  loss_rpn_box_reg: 0.0365 (0.0534)  time: 0.3338  data: 0.1434  max mem: 3961\n",
      "Training Epoch: [2]  [ 480/1229]  eta: 0:04:04  lr: 0.005000  loss: 0.4520 (0.4975)  loss_classifier: 0.1571 (0.1686)  loss_box_reg: 0.1011 (0.1393)  loss_objectness: 0.1273 (0.1361)  loss_rpn_box_reg: 0.0350 (0.0535)  time: 0.3373  data: 0.1435  max mem: 3961\n",
      "Training Epoch: [2]  [ 490/1229]  eta: 0:04:00  lr: 0.005000  loss: 0.4696 (0.4974)  loss_classifier: 0.1830 (0.1686)  loss_box_reg: 0.1190 (0.1391)  loss_objectness: 0.1236 (0.1364)  loss_rpn_box_reg: 0.0355 (0.0532)  time: 0.3254  data: 0.1428  max mem: 3961\n",
      "Training Epoch: [2]  [ 500/1229]  eta: 0:03:57  lr: 0.005000  loss: 0.4002 (0.4982)  loss_classifier: 0.1668 (0.1692)  loss_box_reg: 0.1367 (0.1396)  loss_objectness: 0.1127 (0.1364)  loss_rpn_box_reg: 0.0427 (0.0530)  time: 0.3280  data: 0.1416  max mem: 3961\n",
      "Training Epoch: [2]  [ 510/1229]  eta: 0:03:54  lr: 0.005000  loss: 0.3963 (0.4970)  loss_classifier: 0.1502 (0.1688)  loss_box_reg: 0.1340 (0.1394)  loss_objectness: 0.0985 (0.1360)  loss_rpn_box_reg: 0.0364 (0.0527)  time: 0.3274  data: 0.1408  max mem: 3961\n",
      "Training Epoch: [2]  [ 520/1229]  eta: 0:03:51  lr: 0.005000  loss: 0.3405 (0.4960)  loss_classifier: 0.1345 (0.1688)  loss_box_reg: 0.0901 (0.1392)  loss_objectness: 0.1077 (0.1357)  loss_rpn_box_reg: 0.0261 (0.0523)  time: 0.3228  data: 0.1416  max mem: 3961\n",
      "Training Epoch: [2]  [ 530/1229]  eta: 0:03:47  lr: 0.005000  loss: 0.3578 (0.4961)  loss_classifier: 0.1345 (0.1687)  loss_box_reg: 0.0671 (0.1386)  loss_objectness: 0.1154 (0.1357)  loss_rpn_box_reg: 0.0261 (0.0531)  time: 0.3235  data: 0.1425  max mem: 3961\n",
      "Training Epoch: [2]  [ 540/1229]  eta: 0:03:44  lr: 0.005000  loss: 0.4259 (0.4978)  loss_classifier: 0.1523 (0.1693)  loss_box_reg: 0.1344 (0.1398)  loss_objectness: 0.0990 (0.1355)  loss_rpn_box_reg: 0.0307 (0.0532)  time: 0.3223  data: 0.1421  max mem: 3961\n",
      "Training Epoch: [2]  [ 550/1229]  eta: 0:03:41  lr: 0.005000  loss: 0.5404 (0.4987)  loss_classifier: 0.2277 (0.1700)  loss_box_reg: 0.2024 (0.1409)  loss_objectness: 0.0981 (0.1349)  loss_rpn_box_reg: 0.0322 (0.0529)  time: 0.3185  data: 0.1408  max mem: 3961\n",
      "Training Epoch: [2]  [ 560/1229]  eta: 0:03:37  lr: 0.005000  loss: 0.5003 (0.5001)  loss_classifier: 0.1862 (0.1706)  loss_box_reg: 0.1432 (0.1416)  loss_objectness: 0.1095 (0.1351)  loss_rpn_box_reg: 0.0330 (0.0528)  time: 0.3218  data: 0.1415  max mem: 3961\n",
      "Training Epoch: [2]  [ 570/1229]  eta: 0:03:34  lr: 0.005000  loss: 0.4829 (0.4994)  loss_classifier: 0.1789 (0.1710)  loss_box_reg: 0.1341 (0.1415)  loss_objectness: 0.1142 (0.1345)  loss_rpn_box_reg: 0.0249 (0.0524)  time: 0.3300  data: 0.1427  max mem: 3961\n",
      "Training Epoch: [2]  [ 580/1229]  eta: 0:03:31  lr: 0.005000  loss: 0.4036 (0.4990)  loss_classifier: 0.1511 (0.1710)  loss_box_reg: 0.1433 (0.1417)  loss_objectness: 0.0992 (0.1341)  loss_rpn_box_reg: 0.0182 (0.0522)  time: 0.3330  data: 0.1419  max mem: 3961\n",
      "Training Epoch: [2]  [ 590/1229]  eta: 0:03:28  lr: 0.005000  loss: 0.3854 (0.4980)  loss_classifier: 0.1491 (0.1706)  loss_box_reg: 0.1311 (0.1415)  loss_objectness: 0.1028 (0.1339)  loss_rpn_box_reg: 0.0334 (0.0520)  time: 0.3277  data: 0.1427  max mem: 3961\n",
      "Training Epoch: [2]  [ 600/1229]  eta: 0:03:25  lr: 0.005000  loss: 0.3748 (0.4977)  loss_classifier: 0.1438 (0.1704)  loss_box_reg: 0.1209 (0.1413)  loss_objectness: 0.1028 (0.1340)  loss_rpn_box_reg: 0.0268 (0.0520)  time: 0.3258  data: 0.1450  max mem: 3961\n",
      "Training Epoch: [2]  [ 610/1229]  eta: 0:03:21  lr: 0.005000  loss: 0.4908 (0.4986)  loss_classifier: 0.1584 (0.1705)  loss_box_reg: 0.1239 (0.1414)  loss_objectness: 0.1368 (0.1344)  loss_rpn_box_reg: 0.0451 (0.0523)  time: 0.3256  data: 0.1453  max mem: 3961\n",
      "Training Epoch: [2]  [ 620/1229]  eta: 0:03:18  lr: 0.005000  loss: 0.5095 (0.4995)  loss_classifier: 0.1584 (0.1708)  loss_box_reg: 0.1239 (0.1415)  loss_objectness: 0.1308 (0.1345)  loss_rpn_box_reg: 0.0590 (0.0527)  time: 0.3266  data: 0.1448  max mem: 3961\n",
      "Training Epoch: [2]  [ 630/1229]  eta: 0:03:15  lr: 0.005000  loss: 0.4250 (0.4991)  loss_classifier: 0.1477 (0.1705)  loss_box_reg: 0.1165 (0.1411)  loss_objectness: 0.1432 (0.1348)  loss_rpn_box_reg: 0.0383 (0.0528)  time: 0.3249  data: 0.1416  max mem: 3961\n",
      "Training Epoch: [2]  [ 640/1229]  eta: 0:03:11  lr: 0.005000  loss: 0.4002 (0.4988)  loss_classifier: 0.1304 (0.1704)  loss_box_reg: 0.1002 (0.1409)  loss_objectness: 0.1438 (0.1347)  loss_rpn_box_reg: 0.0264 (0.0528)  time: 0.3187  data: 0.1395  max mem: 3961\n",
      "Training Epoch: [2]  [ 650/1229]  eta: 0:03:08  lr: 0.005000  loss: 0.4565 (0.4991)  loss_classifier: 0.1431 (0.1705)  loss_box_reg: 0.0891 (0.1406)  loss_objectness: 0.1084 (0.1350)  loss_rpn_box_reg: 0.0278 (0.0530)  time: 0.3251  data: 0.1421  max mem: 3961\n",
      "Training Epoch: [2]  [ 660/1229]  eta: 0:03:05  lr: 0.005000  loss: 0.4399 (0.4980)  loss_classifier: 0.1486 (0.1702)  loss_box_reg: 0.0925 (0.1401)  loss_objectness: 0.1084 (0.1349)  loss_rpn_box_reg: 0.0347 (0.0528)  time: 0.3291  data: 0.1429  max mem: 3961\n",
      "Training Epoch: [2]  [ 670/1229]  eta: 0:03:02  lr: 0.005000  loss: 0.3940 (0.4997)  loss_classifier: 0.1534 (0.1708)  loss_box_reg: 0.1130 (0.1407)  loss_objectness: 0.1117 (0.1352)  loss_rpn_box_reg: 0.0347 (0.0530)  time: 0.3246  data: 0.1424  max mem: 3961\n",
      "Training Epoch: [2]  [ 680/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.4663 (0.4987)  loss_classifier: 0.1912 (0.1706)  loss_box_reg: 0.1201 (0.1404)  loss_objectness: 0.1117 (0.1348)  loss_rpn_box_reg: 0.0400 (0.0528)  time: 0.3163  data: 0.1422  max mem: 3961\n",
      "Training Epoch: [2]  [ 690/1229]  eta: 0:02:55  lr: 0.005000  loss: 0.4848 (0.5000)  loss_classifier: 0.1921 (0.1712)  loss_box_reg: 0.1401 (0.1412)  loss_objectness: 0.1314 (0.1350)  loss_rpn_box_reg: 0.0386 (0.0527)  time: 0.3193  data: 0.1438  max mem: 3961\n",
      "Training Epoch: [2]  [ 700/1229]  eta: 0:02:52  lr: 0.005000  loss: 0.6123 (0.5022)  loss_classifier: 0.1890 (0.1716)  loss_box_reg: 0.1694 (0.1419)  loss_objectness: 0.1641 (0.1354)  loss_rpn_box_reg: 0.0393 (0.0533)  time: 0.3245  data: 0.1465  max mem: 3961\n",
      "Training Epoch: [2]  [ 710/1229]  eta: 0:02:49  lr: 0.005000  loss: 0.5503 (0.5014)  loss_classifier: 0.1617 (0.1713)  loss_box_reg: 0.1273 (0.1415)  loss_objectness: 0.1641 (0.1354)  loss_rpn_box_reg: 0.0346 (0.0532)  time: 0.3247  data: 0.1471  max mem: 3961\n",
      "Training Epoch: [2]  [ 720/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.5503 (0.5030)  loss_classifier: 0.1665 (0.1717)  loss_box_reg: 0.1323 (0.1421)  loss_objectness: 0.1272 (0.1356)  loss_rpn_box_reg: 0.0309 (0.0537)  time: 0.3288  data: 0.1449  max mem: 3961\n",
      "Training Epoch: [2]  [ 730/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.5611 (0.5028)  loss_classifier: 0.1665 (0.1713)  loss_box_reg: 0.1470 (0.1417)  loss_objectness: 0.1323 (0.1359)  loss_rpn_box_reg: 0.0383 (0.0539)  time: 0.3273  data: 0.1441  max mem: 3961\n",
      "Training Epoch: [2]  [ 740/1229]  eta: 0:02:39  lr: 0.005000  loss: 0.5611 (0.5040)  loss_classifier: 0.1755 (0.1716)  loss_box_reg: 0.1280 (0.1422)  loss_objectness: 0.1612 (0.1363)  loss_rpn_box_reg: 0.0387 (0.0539)  time: 0.3200  data: 0.1439  max mem: 3961\n",
      "Training Epoch: [2]  [ 750/1229]  eta: 0:02:35  lr: 0.005000  loss: 0.4868 (0.5037)  loss_classifier: 0.1755 (0.1714)  loss_box_reg: 0.1280 (0.1423)  loss_objectness: 0.1413 (0.1360)  loss_rpn_box_reg: 0.0375 (0.0539)  time: 0.3189  data: 0.1421  max mem: 3961\n",
      "Training Epoch: [2]  [ 760/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.4708 (0.5046)  loss_classifier: 0.1722 (0.1717)  loss_box_reg: 0.1251 (0.1426)  loss_objectness: 0.0941 (0.1362)  loss_rpn_box_reg: 0.0328 (0.0541)  time: 0.3240  data: 0.1419  max mem: 3961\n",
      "Training Epoch: [2]  [ 770/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.4708 (0.5037)  loss_classifier: 0.1392 (0.1712)  loss_box_reg: 0.1251 (0.1424)  loss_objectness: 0.0965 (0.1361)  loss_rpn_box_reg: 0.0426 (0.0540)  time: 0.3172  data: 0.1421  max mem: 3961\n",
      "Training Epoch: [2]  [ 780/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.4657 (0.5046)  loss_classifier: 0.1773 (0.1716)  loss_box_reg: 0.0854 (0.1422)  loss_objectness: 0.1101 (0.1364)  loss_rpn_box_reg: 0.0355 (0.0544)  time: 0.3138  data: 0.1440  max mem: 3961\n",
      "Training Epoch: [2]  [ 790/1229]  eta: 0:02:22  lr: 0.005000  loss: 0.4604 (0.5051)  loss_classifier: 0.1854 (0.1719)  loss_box_reg: 0.1270 (0.1424)  loss_objectness: 0.1264 (0.1365)  loss_rpn_box_reg: 0.0269 (0.0543)  time: 0.3191  data: 0.1447  max mem: 3961\n",
      "Training Epoch: [2]  [ 800/1229]  eta: 0:02:19  lr: 0.005000  loss: 0.4521 (0.5056)  loss_classifier: 0.1623 (0.1721)  loss_box_reg: 0.1270 (0.1427)  loss_objectness: 0.1264 (0.1365)  loss_rpn_box_reg: 0.0385 (0.0543)  time: 0.3200  data: 0.1431  max mem: 3961\n",
      "Training Epoch: [2]  [ 810/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.5549 (0.5063)  loss_classifier: 0.1669 (0.1723)  loss_box_reg: 0.1164 (0.1428)  loss_objectness: 0.1275 (0.1367)  loss_rpn_box_reg: 0.0398 (0.0545)  time: 0.3249  data: 0.1425  max mem: 3961\n",
      "Training Epoch: [2]  [ 820/1229]  eta: 0:02:12  lr: 0.005000  loss: 0.5549 (0.5060)  loss_classifier: 0.1832 (0.1723)  loss_box_reg: 0.1164 (0.1428)  loss_objectness: 0.1222 (0.1366)  loss_rpn_box_reg: 0.0369 (0.0543)  time: 0.3221  data: 0.1420  max mem: 3961\n",
      "Training Epoch: [2]  [ 830/1229]  eta: 0:02:09  lr: 0.005000  loss: 0.3979 (0.5057)  loss_classifier: 0.1404 (0.1720)  loss_box_reg: 0.0960 (0.1424)  loss_objectness: 0.1222 (0.1367)  loss_rpn_box_reg: 0.0391 (0.0546)  time: 0.3178  data: 0.1419  max mem: 3961\n",
      "Training Epoch: [2]  [ 840/1229]  eta: 0:02:06  lr: 0.005000  loss: 0.3641 (0.5045)  loss_classifier: 0.1215 (0.1716)  loss_box_reg: 0.0691 (0.1419)  loss_objectness: 0.1093 (0.1365)  loss_rpn_box_reg: 0.0425 (0.0544)  time: 0.3201  data: 0.1418  max mem: 3961\n",
      "Training Epoch: [2]  [ 850/1229]  eta: 0:02:03  lr: 0.005000  loss: 0.3179 (0.5036)  loss_classifier: 0.1245 (0.1713)  loss_box_reg: 0.0840 (0.1416)  loss_objectness: 0.0941 (0.1362)  loss_rpn_box_reg: 0.0149 (0.0545)  time: 0.3213  data: 0.1418  max mem: 3961\n",
      "Training Epoch: [2]  [ 860/1229]  eta: 0:01:59  lr: 0.005000  loss: 0.3724 (0.5031)  loss_classifier: 0.1394 (0.1713)  loss_box_reg: 0.1022 (0.1415)  loss_objectness: 0.1046 (0.1360)  loss_rpn_box_reg: 0.0185 (0.0542)  time: 0.3180  data: 0.1411  max mem: 3961\n",
      "Training Epoch: [2]  [ 870/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.4626 (0.5042)  loss_classifier: 0.1720 (0.1714)  loss_box_reg: 0.1218 (0.1415)  loss_objectness: 0.1314 (0.1370)  loss_rpn_box_reg: 0.0223 (0.0543)  time: 0.3196  data: 0.1434  max mem: 3961\n",
      "Training Epoch: [2]  [ 880/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.4910 (0.5054)  loss_classifier: 0.1729 (0.1719)  loss_box_reg: 0.1651 (0.1421)  loss_objectness: 0.1425 (0.1371)  loss_rpn_box_reg: 0.0261 (0.0543)  time: 0.3233  data: 0.1434  max mem: 3961\n",
      "Training Epoch: [2]  [ 890/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.5075 (0.5067)  loss_classifier: 0.1729 (0.1723)  loss_box_reg: 0.1651 (0.1428)  loss_objectness: 0.1268 (0.1370)  loss_rpn_box_reg: 0.0353 (0.0546)  time: 0.3186  data: 0.1421  max mem: 3961\n",
      "Training Epoch: [2]  [ 900/1229]  eta: 0:01:46  lr: 0.005000  loss: 0.5075 (0.5091)  loss_classifier: 0.1768 (0.1730)  loss_box_reg: 0.1630 (0.1437)  loss_objectness: 0.1195 (0.1373)  loss_rpn_box_reg: 0.0774 (0.0552)  time: 0.3233  data: 0.1431  max mem: 3961\n",
      "Training Epoch: [2]  [ 910/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.5331 (0.5102)  loss_classifier: 0.1876 (0.1734)  loss_box_reg: 0.1722 (0.1441)  loss_objectness: 0.1194 (0.1374)  loss_rpn_box_reg: 0.0629 (0.0552)  time: 0.3258  data: 0.1449  max mem: 3961\n",
      "Training Epoch: [2]  [ 920/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.4519 (0.5089)  loss_classifier: 0.1680 (0.1731)  loss_box_reg: 0.1199 (0.1435)  loss_objectness: 0.1194 (0.1374)  loss_rpn_box_reg: 0.0306 (0.0549)  time: 0.3236  data: 0.1449  max mem: 3961\n",
      "Training Epoch: [2]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.4088 (0.5096)  loss_classifier: 0.1627 (0.1732)  loss_box_reg: 0.0837 (0.1437)  loss_objectness: 0.1283 (0.1375)  loss_rpn_box_reg: 0.0306 (0.0551)  time: 0.3262  data: 0.1437  max mem: 3961\n",
      "Training Epoch: [2]  [ 940/1229]  eta: 0:01:33  lr: 0.005000  loss: 0.5037 (0.5092)  loss_classifier: 0.1649 (0.1731)  loss_box_reg: 0.1312 (0.1437)  loss_objectness: 0.1283 (0.1375)  loss_rpn_box_reg: 0.0374 (0.0549)  time: 0.3267  data: 0.1428  max mem: 3961\n",
      "Training Epoch: [2]  [ 950/1229]  eta: 0:01:30  lr: 0.005000  loss: 0.4403 (0.5090)  loss_classifier: 0.1281 (0.1730)  loss_box_reg: 0.0973 (0.1435)  loss_objectness: 0.1262 (0.1377)  loss_rpn_box_reg: 0.0308 (0.0548)  time: 0.3273  data: 0.1416  max mem: 3961\n",
      "Training Epoch: [2]  [ 960/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.4523 (0.5094)  loss_classifier: 0.1434 (0.1732)  loss_box_reg: 0.1093 (0.1436)  loss_objectness: 0.1236 (0.1377)  loss_rpn_box_reg: 0.0353 (0.0549)  time: 0.3248  data: 0.1394  max mem: 3961\n",
      "Training Epoch: [2]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.4866 (0.5088)  loss_classifier: 0.1618 (0.1728)  loss_box_reg: 0.1164 (0.1434)  loss_objectness: 0.1054 (0.1376)  loss_rpn_box_reg: 0.0412 (0.0550)  time: 0.3213  data: 0.1386  max mem: 3961\n",
      "Training Epoch: [2]  [ 980/1229]  eta: 0:01:20  lr: 0.005000  loss: 0.4787 (0.5089)  loss_classifier: 0.1663 (0.1730)  loss_box_reg: 0.1351 (0.1436)  loss_objectness: 0.1054 (0.1374)  loss_rpn_box_reg: 0.0328 (0.0548)  time: 0.3222  data: 0.1394  max mem: 3961\n",
      "Training Epoch: [2]  [ 990/1229]  eta: 0:01:17  lr: 0.005000  loss: 0.5688 (0.5111)  loss_classifier: 0.1970 (0.1735)  loss_box_reg: 0.1647 (0.1444)  loss_objectness: 0.1437 (0.1380)  loss_rpn_box_reg: 0.0328 (0.0553)  time: 0.3242  data: 0.1401  max mem: 3961\n",
      "Training Epoch: [2]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.6399 (0.5122)  loss_classifier: 0.2019 (0.1739)  loss_box_reg: 0.1901 (0.1449)  loss_objectness: 0.1352 (0.1378)  loss_rpn_box_reg: 0.0354 (0.0556)  time: 0.3231  data: 0.1413  max mem: 3961\n",
      "Training Epoch: [2]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.5317 (0.5123)  loss_classifier: 0.1697 (0.1738)  loss_box_reg: 0.1685 (0.1450)  loss_objectness: 0.1047 (0.1377)  loss_rpn_box_reg: 0.0370 (0.0558)  time: 0.3227  data: 0.1400  max mem: 3961\n",
      "Training Epoch: [2]  [1020/1229]  eta: 0:01:07  lr: 0.005000  loss: 0.4292 (0.5121)  loss_classifier: 0.1328 (0.1735)  loss_box_reg: 0.0897 (0.1448)  loss_objectness: 0.0986 (0.1376)  loss_rpn_box_reg: 0.0363 (0.0563)  time: 0.3310  data: 0.1412  max mem: 3961\n",
      "Training Epoch: [2]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.4292 (0.5126)  loss_classifier: 0.1404 (0.1737)  loss_box_reg: 0.1074 (0.1450)  loss_objectness: 0.1055 (0.1376)  loss_rpn_box_reg: 0.0342 (0.0563)  time: 0.3323  data: 0.1417  max mem: 3961\n",
      "Training Epoch: [2]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.3401 (0.5116)  loss_classifier: 0.1571 (0.1734)  loss_box_reg: 0.0966 (0.1448)  loss_objectness: 0.1059 (0.1374)  loss_rpn_box_reg: 0.0257 (0.0561)  time: 0.3286  data: 0.1402  max mem: 3961\n",
      "Training Epoch: [2]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.4277 (0.5115)  loss_classifier: 0.1161 (0.1732)  loss_box_reg: 0.0940 (0.1447)  loss_objectness: 0.1099 (0.1374)  loss_rpn_box_reg: 0.0257 (0.0562)  time: 0.3285  data: 0.1391  max mem: 3961\n",
      "Training Epoch: [2]  [1060/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.4892 (0.5110)  loss_classifier: 0.1593 (0.1730)  loss_box_reg: 0.1238 (0.1445)  loss_objectness: 0.1099 (0.1372)  loss_rpn_box_reg: 0.0369 (0.0563)  time: 0.3220  data: 0.1396  max mem: 3961\n",
      "Training Epoch: [2]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.4823 (0.5126)  loss_classifier: 0.1695 (0.1737)  loss_box_reg: 0.1333 (0.1455)  loss_objectness: 0.1066 (0.1372)  loss_rpn_box_reg: 0.0357 (0.0564)  time: 0.3178  data: 0.1435  max mem: 3961\n",
      "Training Epoch: [2]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.3629 (0.5110)  loss_classifier: 0.1259 (0.1730)  loss_box_reg: 0.1045 (0.1448)  loss_objectness: 0.1036 (0.1369)  loss_rpn_box_reg: 0.0211 (0.0564)  time: 0.3173  data: 0.1436  max mem: 3961\n",
      "Training Epoch: [2]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.4409 (0.5124)  loss_classifier: 0.1355 (0.1734)  loss_box_reg: 0.0851 (0.1450)  loss_objectness: 0.1283 (0.1373)  loss_rpn_box_reg: 0.0337 (0.0567)  time: 0.3239  data: 0.1395  max mem: 3961\n",
      "Training Epoch: [2]  [1100/1229]  eta: 0:00:41  lr: 0.005000  loss: 0.4649 (0.5116)  loss_classifier: 0.1589 (0.1732)  loss_box_reg: 0.1083 (0.1447)  loss_objectness: 0.1346 (0.1372)  loss_rpn_box_reg: 0.0428 (0.0566)  time: 0.3242  data: 0.1375  max mem: 3961\n",
      "Training Epoch: [2]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.3800 (0.5102)  loss_classifier: 0.1250 (0.1726)  loss_box_reg: 0.0967 (0.1442)  loss_objectness: 0.1181 (0.1370)  loss_rpn_box_reg: 0.0230 (0.0564)  time: 0.3210  data: 0.1403  max mem: 3961\n",
      "Training Epoch: [2]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4060 (0.5092)  loss_classifier: 0.1139 (0.1722)  loss_box_reg: 0.0813 (0.1438)  loss_objectness: 0.1073 (0.1368)  loss_rpn_box_reg: 0.0216 (0.0564)  time: 0.3244  data: 0.1410  max mem: 3961\n",
      "Training Epoch: [2]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.4066 (0.5095)  loss_classifier: 0.1139 (0.1723)  loss_box_reg: 0.0882 (0.1440)  loss_objectness: 0.1073 (0.1368)  loss_rpn_box_reg: 0.0267 (0.0564)  time: 0.3293  data: 0.1396  max mem: 3961\n",
      "Training Epoch: [2]  [1140/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.3985 (0.5090)  loss_classifier: 0.1331 (0.1721)  loss_box_reg: 0.1446 (0.1440)  loss_objectness: 0.1092 (0.1365)  loss_rpn_box_reg: 0.0405 (0.0564)  time: 0.3275  data: 0.1396  max mem: 3961\n",
      "Training Epoch: [2]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.4380 (0.5086)  loss_classifier: 0.1466 (0.1720)  loss_box_reg: 0.1426 (0.1440)  loss_objectness: 0.1066 (0.1363)  loss_rpn_box_reg: 0.0365 (0.0564)  time: 0.3218  data: 0.1401  max mem: 3961\n",
      "Training Epoch: [2]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.4149 (0.5081)  loss_classifier: 0.1466 (0.1718)  loss_box_reg: 0.0996 (0.1438)  loss_objectness: 0.1090 (0.1362)  loss_rpn_box_reg: 0.0239 (0.0563)  time: 0.3282  data: 0.1395  max mem: 3961\n",
      "Training Epoch: [2]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.4941 (0.5087)  loss_classifier: 0.1762 (0.1720)  loss_box_reg: 0.1460 (0.1442)  loss_objectness: 0.1187 (0.1362)  loss_rpn_box_reg: 0.0347 (0.0563)  time: 0.3319  data: 0.1405  max mem: 3961\n",
      "Training Epoch: [2]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.4941 (0.5084)  loss_classifier: 0.1762 (0.1720)  loss_box_reg: 0.1553 (0.1443)  loss_objectness: 0.1040 (0.1360)  loss_rpn_box_reg: 0.0331 (0.0561)  time: 0.3245  data: 0.1411  max mem: 3961\n",
      "Training Epoch: [2]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.4594 (0.5086)  loss_classifier: 0.1719 (0.1720)  loss_box_reg: 0.1449 (0.1445)  loss_objectness: 0.0986 (0.1360)  loss_rpn_box_reg: 0.0337 (0.0560)  time: 0.3256  data: 0.1399  max mem: 3961\n",
      "Training Epoch: [2]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.5044 (0.5090)  loss_classifier: 0.1873 (0.1722)  loss_box_reg: 0.1445 (0.1449)  loss_objectness: 0.1279 (0.1360)  loss_rpn_box_reg: 0.0339 (0.0559)  time: 0.3290  data: 0.1412  max mem: 3961\n",
      "Training Epoch: [2]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.5044 (0.5093)  loss_classifier: 0.1847 (0.1725)  loss_box_reg: 0.1265 (0.1448)  loss_objectness: 0.1370 (0.1363)  loss_rpn_box_reg: 0.0348 (0.0557)  time: 0.3279  data: 0.1429  max mem: 3961\n",
      "Training Epoch: [2]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.5509 (0.5096)  loss_classifier: 0.1704 (0.1726)  loss_box_reg: 0.1265 (0.1452)  loss_objectness: 0.1308 (0.1363)  loss_rpn_box_reg: 0.0348 (0.0555)  time: 0.3258  data: 0.1432  max mem: 3961\n",
      "Training Epoch: [2]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4711 (0.5095)  loss_classifier: 0.1473 (0.1724)  loss_box_reg: 0.1147 (0.1448)  loss_objectness: 0.1417 (0.1367)  loss_rpn_box_reg: 0.0325 (0.0556)  time: 0.3230  data: 0.1418  max mem: 3961\n",
      "Training Epoch: [2] Total time: 0:06:39 (0.3249 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:39  model_time: 0.2910 (0.2910)  evaluator_time: 0.0010 (0.0010)  time: 0.3240  data: 0.0300  max mem: 3961\n",
      "Test:  [100/308]  eta: 0:00:32  model_time: 0.1050 (0.1108)  evaluator_time: 0.0030 (0.0046)  time: 0.1600  data: 0.0437  max mem: 3961\n",
      "Test:  [200/308]  eta: 0:00:16  model_time: 0.1140 (0.1103)  evaluator_time: 0.0020 (0.0045)  time: 0.1572  data: 0.0386  max mem: 3961\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0990 (0.1094)  evaluator_time: 0.0030 (0.0045)  time: 0.1524  data: 0.0440  max mem: 3961\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0990 (0.1092)  evaluator_time: 0.0020 (0.0045)  time: 0.1492  data: 0.0424  max mem: 3961\n",
      "Test: Total time: 0:00:46 (0.1525 s / it)\n",
      "Averaged stats: model_time: 0.0990 (0.1092)  evaluator_time: 0.0020 (0.0045)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.113\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.086\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.093\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.168\n",
      "Testing Epoch: [2]  [  0/308]  eta: 0:00:49  lr: 0.005000  loss: 0.2087 (0.2087)  loss_classifier: 0.0688 (0.0688)  loss_box_reg: 0.0672 (0.0672)  loss_objectness: 0.0575 (0.0575)  loss_rpn_box_reg: 0.0152 (0.0152)  time: 0.1610  data: 0.0310  max mem: 3961\n",
      "Testing Epoch: [2]  [100/308]  eta: 0:00:36  lr: 0.005000  loss: 0.3208 (0.5227)  loss_classifier: 0.1386 (0.1791)  loss_box_reg: 0.1067 (0.1631)  loss_objectness: 0.0885 (0.1227)  loss_rpn_box_reg: 0.0199 (0.0578)  time: 0.1777  data: 0.0414  max mem: 3961\n",
      "Testing Epoch: [2]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.4578 (0.5027)  loss_classifier: 0.1618 (0.1728)  loss_box_reg: 0.1463 (0.1564)  loss_objectness: 0.0923 (0.1168)  loss_rpn_box_reg: 0.0255 (0.0566)  time: 0.1789  data: 0.0362  max mem: 3961\n",
      "Testing Epoch: [2]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5189 (0.5031)  loss_classifier: 0.1864 (0.1737)  loss_box_reg: 0.1569 (0.1590)  loss_objectness: 0.1142 (0.1149)  loss_rpn_box_reg: 0.0325 (0.0555)  time: 0.1695  data: 0.0409  max mem: 3969\n",
      "Testing Epoch: [2]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.4617 (0.5026)  loss_classifier: 0.1676 (0.1738)  loss_box_reg: 0.1387 (0.1591)  loss_objectness: 0.1090 (0.1148)  loss_rpn_box_reg: 0.0325 (0.0549)  time: 0.1711  data: 0.0431  max mem: 3969\n",
      "Testing Epoch: [2] Total time: 0:00:54 (0.1764 s / it)\n",
      "Training Epoch: [3]  [   0/1229]  eta: 0:07:21  lr: 0.005000  loss: 0.5130 (0.5130)  loss_classifier: 0.2291 (0.2291)  loss_box_reg: 0.1904 (0.1904)  loss_objectness: 0.0621 (0.0621)  loss_rpn_box_reg: 0.0313 (0.0313)  time: 0.3590  data: 0.1530  max mem: 3969\n",
      "Training Epoch: [3]  [  10/1229]  eta: 0:06:42  lr: 0.005000  loss: 0.4587 (0.4448)  loss_classifier: 0.1431 (0.1458)  loss_box_reg: 0.0802 (0.1030)  loss_objectness: 0.1104 (0.1256)  loss_rpn_box_reg: 0.0313 (0.0703)  time: 0.3303  data: 0.1398  max mem: 3969\n",
      "Training Epoch: [3]  [  20/1229]  eta: 0:06:27  lr: 0.005000  loss: 0.5674 (0.5770)  loss_classifier: 0.1627 (0.1908)  loss_box_reg: 0.1376 (0.1603)  loss_objectness: 0.1513 (0.1547)  loss_rpn_box_reg: 0.0384 (0.0713)  time: 0.3184  data: 0.1420  max mem: 3969\n",
      "Training Epoch: [3]  [  30/1229]  eta: 0:06:23  lr: 0.005000  loss: 0.4896 (0.5613)  loss_classifier: 0.1987 (0.1892)  loss_box_reg: 0.1889 (0.1578)  loss_objectness: 0.1460 (0.1439)  loss_rpn_box_reg: 0.0474 (0.0704)  time: 0.3139  data: 0.1447  max mem: 3969\n",
      "Training Epoch: [3]  [  40/1229]  eta: 0:06:21  lr: 0.005000  loss: 0.4869 (0.5647)  loss_classifier: 0.1623 (0.1926)  loss_box_reg: 0.1416 (0.1673)  loss_objectness: 0.1098 (0.1425)  loss_rpn_box_reg: 0.0374 (0.0624)  time: 0.3207  data: 0.1433  max mem: 3969\n",
      "Training Epoch: [3]  [  50/1229]  eta: 0:06:17  lr: 0.005000  loss: 0.4374 (0.5440)  loss_classifier: 0.1552 (0.1839)  loss_box_reg: 0.1281 (0.1615)  loss_objectness: 0.1231 (0.1397)  loss_rpn_box_reg: 0.0366 (0.0588)  time: 0.3211  data: 0.1401  max mem: 3969\n",
      "Training Epoch: [3]  [  60/1229]  eta: 0:06:14  lr: 0.005000  loss: 0.3462 (0.5294)  loss_classifier: 0.1263 (0.1803)  loss_box_reg: 0.0942 (0.1554)  loss_objectness: 0.1071 (0.1367)  loss_rpn_box_reg: 0.0170 (0.0569)  time: 0.3208  data: 0.1392  max mem: 3969\n",
      "Training Epoch: [3]  [  70/1229]  eta: 0:06:13  lr: 0.005000  loss: 0.3421 (0.5104)  loss_classifier: 0.1263 (0.1747)  loss_box_reg: 0.0806 (0.1482)  loss_objectness: 0.0971 (0.1332)  loss_rpn_box_reg: 0.0180 (0.0543)  time: 0.3285  data: 0.1431  max mem: 3969\n",
      "Training Epoch: [3]  [  80/1229]  eta: 0:06:11  lr: 0.005000  loss: 0.3977 (0.5064)  loss_classifier: 0.1231 (0.1738)  loss_box_reg: 0.0896 (0.1490)  loss_objectness: 0.0854 (0.1314)  loss_rpn_box_reg: 0.0209 (0.0523)  time: 0.3314  data: 0.1451  max mem: 3969\n",
      "Training Epoch: [3]  [  90/1229]  eta: 0:06:09  lr: 0.005000  loss: 0.3486 (0.4896)  loss_classifier: 0.1231 (0.1680)  loss_box_reg: 0.0896 (0.1434)  loss_objectness: 0.0832 (0.1283)  loss_rpn_box_reg: 0.0186 (0.0499)  time: 0.3298  data: 0.1466  max mem: 3969\n",
      "Training Epoch: [3]  [ 100/1229]  eta: 0:06:05  lr: 0.005000  loss: 0.3686 (0.4943)  loss_classifier: 0.1324 (0.1693)  loss_box_reg: 0.0930 (0.1474)  loss_objectness: 0.0978 (0.1293)  loss_rpn_box_reg: 0.0301 (0.0483)  time: 0.3268  data: 0.1461  max mem: 3969\n",
      "Training Epoch: [3]  [ 110/1229]  eta: 0:06:02  lr: 0.005000  loss: 0.4830 (0.5056)  loss_classifier: 0.1634 (0.1737)  loss_box_reg: 0.1408 (0.1536)  loss_objectness: 0.1399 (0.1303)  loss_rpn_box_reg: 0.0301 (0.0480)  time: 0.3248  data: 0.1437  max mem: 3969\n",
      "Training Epoch: [3]  [ 120/1229]  eta: 0:06:00  lr: 0.005000  loss: 0.4209 (0.5043)  loss_classifier: 0.1655 (0.1736)  loss_box_reg: 0.1258 (0.1514)  loss_objectness: 0.1337 (0.1315)  loss_rpn_box_reg: 0.0283 (0.0479)  time: 0.3279  data: 0.1440  max mem: 3969\n",
      "Training Epoch: [3]  [ 130/1229]  eta: 0:05:57  lr: 0.005000  loss: 0.4639 (0.5052)  loss_classifier: 0.1727 (0.1735)  loss_box_reg: 0.0977 (0.1510)  loss_objectness: 0.1210 (0.1321)  loss_rpn_box_reg: 0.0356 (0.0486)  time: 0.3317  data: 0.1468  max mem: 3969\n",
      "Training Epoch: [3]  [ 140/1229]  eta: 0:05:54  lr: 0.005000  loss: 0.4246 (0.5056)  loss_classifier: 0.1394 (0.1731)  loss_box_reg: 0.1188 (0.1510)  loss_objectness: 0.1161 (0.1330)  loss_rpn_box_reg: 0.0356 (0.0486)  time: 0.3297  data: 0.1435  max mem: 3969\n",
      "Training Epoch: [3]  [ 150/1229]  eta: 0:05:51  lr: 0.005000  loss: 0.4246 (0.5064)  loss_classifier: 0.1341 (0.1722)  loss_box_reg: 0.1188 (0.1497)  loss_objectness: 0.0968 (0.1340)  loss_rpn_box_reg: 0.0284 (0.0506)  time: 0.3264  data: 0.1383  max mem: 3969\n",
      "Training Epoch: [3]  [ 160/1229]  eta: 0:05:47  lr: 0.005000  loss: 0.3005 (0.5046)  loss_classifier: 0.1049 (0.1713)  loss_box_reg: 0.0827 (0.1488)  loss_objectness: 0.0955 (0.1327)  loss_rpn_box_reg: 0.0235 (0.0518)  time: 0.3267  data: 0.1402  max mem: 3969\n",
      "Training Epoch: [3]  [ 170/1229]  eta: 0:05:45  lr: 0.005000  loss: 0.3359 (0.5035)  loss_classifier: 0.1227 (0.1709)  loss_box_reg: 0.0985 (0.1492)  loss_objectness: 0.1077 (0.1323)  loss_rpn_box_reg: 0.0233 (0.0511)  time: 0.3276  data: 0.1431  max mem: 3969\n",
      "Training Epoch: [3]  [ 180/1229]  eta: 0:05:42  lr: 0.005000  loss: 0.4583 (0.5020)  loss_classifier: 0.1309 (0.1691)  loss_box_reg: 0.0975 (0.1465)  loss_objectness: 0.1226 (0.1336)  loss_rpn_box_reg: 0.0290 (0.0527)  time: 0.3346  data: 0.1437  max mem: 3969\n",
      "Training Epoch: [3]  [ 190/1229]  eta: 0:05:39  lr: 0.005000  loss: 0.5468 (0.5056)  loss_classifier: 0.1529 (0.1704)  loss_box_reg: 0.1123 (0.1473)  loss_objectness: 0.1647 (0.1350)  loss_rpn_box_reg: 0.0346 (0.0530)  time: 0.3380  data: 0.1435  max mem: 3969\n",
      "Training Epoch: [3]  [ 200/1229]  eta: 0:05:36  lr: 0.005000  loss: 0.4723 (0.5011)  loss_classifier: 0.1430 (0.1682)  loss_box_reg: 0.1266 (0.1451)  loss_objectness: 0.1217 (0.1338)  loss_rpn_box_reg: 0.0346 (0.0541)  time: 0.3323  data: 0.1413  max mem: 3969\n",
      "Training Epoch: [3]  [ 210/1229]  eta: 0:05:33  lr: 0.005000  loss: 0.4089 (0.4960)  loss_classifier: 0.1108 (0.1661)  loss_box_reg: 0.0938 (0.1422)  loss_objectness: 0.1136 (0.1336)  loss_rpn_box_reg: 0.0332 (0.0542)  time: 0.3271  data: 0.1407  max mem: 3969\n",
      "Training Epoch: [3]  [ 220/1229]  eta: 0:05:29  lr: 0.005000  loss: 0.4089 (0.4952)  loss_classifier: 0.1194 (0.1658)  loss_box_reg: 0.1051 (0.1422)  loss_objectness: 0.1066 (0.1335)  loss_rpn_box_reg: 0.0251 (0.0537)  time: 0.3229  data: 0.1433  max mem: 3969\n",
      "Training Epoch: [3]  [ 230/1229]  eta: 0:05:26  lr: 0.005000  loss: 0.4526 (0.4920)  loss_classifier: 0.1204 (0.1637)  loss_box_reg: 0.1263 (0.1404)  loss_objectness: 0.1023 (0.1327)  loss_rpn_box_reg: 0.0294 (0.0552)  time: 0.3233  data: 0.1424  max mem: 3969\n",
      "Training Epoch: [3]  [ 240/1229]  eta: 0:05:23  lr: 0.005000  loss: 0.3281 (0.4904)  loss_classifier: 0.1064 (0.1626)  loss_box_reg: 0.0814 (0.1394)  loss_objectness: 0.1088 (0.1328)  loss_rpn_box_reg: 0.0294 (0.0555)  time: 0.3319  data: 0.1425  max mem: 3969\n",
      "Training Epoch: [3]  [ 250/1229]  eta: 0:05:20  lr: 0.005000  loss: 0.4496 (0.4948)  loss_classifier: 0.1412 (0.1644)  loss_box_reg: 0.1327 (0.1417)  loss_objectness: 0.1142 (0.1329)  loss_rpn_box_reg: 0.0400 (0.0559)  time: 0.3315  data: 0.1425  max mem: 3969\n",
      "Training Epoch: [3]  [ 260/1229]  eta: 0:05:16  lr: 0.005000  loss: 0.4685 (0.4978)  loss_classifier: 0.1654 (0.1657)  loss_box_reg: 0.1587 (0.1431)  loss_objectness: 0.1321 (0.1332)  loss_rpn_box_reg: 0.0319 (0.0559)  time: 0.3218  data: 0.1423  max mem: 3969\n",
      "Training Epoch: [3]  [ 270/1229]  eta: 0:05:13  lr: 0.005000  loss: 0.4048 (0.4940)  loss_classifier: 0.1411 (0.1648)  loss_box_reg: 0.1107 (0.1426)  loss_objectness: 0.0984 (0.1320)  loss_rpn_box_reg: 0.0203 (0.0546)  time: 0.3239  data: 0.1429  max mem: 3969\n",
      "Training Epoch: [3]  [ 280/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.4292 (0.4939)  loss_classifier: 0.1549 (0.1649)  loss_box_reg: 0.1195 (0.1426)  loss_objectness: 0.1126 (0.1320)  loss_rpn_box_reg: 0.0210 (0.0544)  time: 0.3288  data: 0.1432  max mem: 3969\n",
      "Training Epoch: [3]  [ 290/1229]  eta: 0:05:06  lr: 0.005000  loss: 0.5126 (0.4935)  loss_classifier: 0.1594 (0.1654)  loss_box_reg: 0.1285 (0.1434)  loss_objectness: 0.1201 (0.1312)  loss_rpn_box_reg: 0.0244 (0.0535)  time: 0.3265  data: 0.1426  max mem: 3969\n",
      "Training Epoch: [3]  [ 300/1229]  eta: 0:05:05  lr: 0.005000  loss: 0.4302 (0.4933)  loss_classifier: 0.1480 (0.1658)  loss_box_reg: 0.1148 (0.1441)  loss_objectness: 0.1103 (0.1309)  loss_rpn_box_reg: 0.0232 (0.0526)  time: 0.3493  data: 0.1415  max mem: 3969\n",
      "Training Epoch: [3]  [ 310/1229]  eta: 0:05:01  lr: 0.005000  loss: 0.4302 (0.4901)  loss_classifier: 0.1425 (0.1651)  loss_box_reg: 0.1107 (0.1427)  loss_objectness: 0.1124 (0.1304)  loss_rpn_box_reg: 0.0232 (0.0519)  time: 0.3482  data: 0.1416  max mem: 3969\n",
      "Training Epoch: [3]  [ 320/1229]  eta: 0:04:58  lr: 0.005000  loss: 0.4763 (0.4944)  loss_classifier: 0.1537 (0.1666)  loss_box_reg: 0.1347 (0.1445)  loss_objectness: 0.1123 (0.1310)  loss_rpn_box_reg: 0.0307 (0.0523)  time: 0.3319  data: 0.1451  max mem: 3969\n",
      "Training Epoch: [3]  [ 330/1229]  eta: 0:04:55  lr: 0.005000  loss: 0.5458 (0.4983)  loss_classifier: 0.2023 (0.1680)  loss_box_reg: 0.1591 (0.1463)  loss_objectness: 0.1305 (0.1313)  loss_rpn_box_reg: 0.0351 (0.0527)  time: 0.3354  data: 0.1470  max mem: 3969\n",
      "Training Epoch: [3]  [ 340/1229]  eta: 0:04:52  lr: 0.005000  loss: 0.5458 (0.5034)  loss_classifier: 0.1765 (0.1694)  loss_box_reg: 0.1557 (0.1473)  loss_objectness: 0.1443 (0.1319)  loss_rpn_box_reg: 0.0387 (0.0547)  time: 0.3388  data: 0.1455  max mem: 3969\n",
      "Training Epoch: [3]  [ 350/1229]  eta: 0:04:49  lr: 0.005000  loss: 0.5249 (0.5039)  loss_classifier: 0.1556 (0.1692)  loss_box_reg: 0.1452 (0.1474)  loss_objectness: 0.1478 (0.1319)  loss_rpn_box_reg: 0.0593 (0.0554)  time: 0.3337  data: 0.1435  max mem: 3969\n",
      "Training Epoch: [3]  [ 360/1229]  eta: 0:04:45  lr: 0.005000  loss: 0.4120 (0.5033)  loss_classifier: 0.1342 (0.1687)  loss_box_reg: 0.1157 (0.1473)  loss_objectness: 0.1112 (0.1319)  loss_rpn_box_reg: 0.0581 (0.0554)  time: 0.3273  data: 0.1424  max mem: 3969\n",
      "Training Epoch: [3]  [ 370/1229]  eta: 0:04:43  lr: 0.005000  loss: 0.4365 (0.5051)  loss_classifier: 0.1379 (0.1697)  loss_box_reg: 0.1325 (0.1482)  loss_objectness: 0.1273 (0.1322)  loss_rpn_box_reg: 0.0462 (0.0550)  time: 0.3420  data: 0.1456  max mem: 3969\n",
      "Training Epoch: [3]  [ 380/1229]  eta: 0:04:39  lr: 0.005000  loss: 0.4365 (0.5027)  loss_classifier: 0.1622 (0.1691)  loss_box_reg: 0.1250 (0.1474)  loss_objectness: 0.1119 (0.1313)  loss_rpn_box_reg: 0.0232 (0.0549)  time: 0.3405  data: 0.1438  max mem: 3969\n",
      "Training Epoch: [3]  [ 390/1229]  eta: 0:04:36  lr: 0.005000  loss: 0.4277 (0.5035)  loss_classifier: 0.1622 (0.1692)  loss_box_reg: 0.1159 (0.1472)  loss_objectness: 0.1023 (0.1318)  loss_rpn_box_reg: 0.0357 (0.0552)  time: 0.3298  data: 0.1391  max mem: 3969\n",
      "Training Epoch: [3]  [ 400/1229]  eta: 0:04:33  lr: 0.005000  loss: 0.3366 (0.4995)  loss_classifier: 0.1222 (0.1682)  loss_box_reg: 0.0922 (0.1457)  loss_objectness: 0.0927 (0.1311)  loss_rpn_box_reg: 0.0302 (0.0545)  time: 0.3269  data: 0.1375  max mem: 3969\n",
      "Training Epoch: [3]  [ 410/1229]  eta: 0:04:29  lr: 0.005000  loss: 0.3030 (0.4971)  loss_classifier: 0.1184 (0.1674)  loss_box_reg: 0.0863 (0.1448)  loss_objectness: 0.0927 (0.1304)  loss_rpn_box_reg: 0.0302 (0.0545)  time: 0.3248  data: 0.1388  max mem: 3969\n",
      "Training Epoch: [3]  [ 420/1229]  eta: 0:04:26  lr: 0.005000  loss: 0.3866 (0.4949)  loss_classifier: 0.1248 (0.1668)  loss_box_reg: 0.1018 (0.1444)  loss_objectness: 0.1017 (0.1298)  loss_rpn_box_reg: 0.0334 (0.0538)  time: 0.3275  data: 0.1416  max mem: 3969\n",
      "Training Epoch: [3]  [ 430/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.4965 (0.4962)  loss_classifier: 0.1592 (0.1673)  loss_box_reg: 0.1471 (0.1451)  loss_objectness: 0.1314 (0.1302)  loss_rpn_box_reg: 0.0252 (0.0535)  time: 0.3280  data: 0.1412  max mem: 3969\n",
      "Training Epoch: [3]  [ 440/1229]  eta: 0:04:19  lr: 0.005000  loss: 0.5510 (0.4998)  loss_classifier: 0.2088 (0.1682)  loss_box_reg: 0.1688 (0.1463)  loss_objectness: 0.1364 (0.1309)  loss_rpn_box_reg: 0.0285 (0.0544)  time: 0.3298  data: 0.1401  max mem: 3969\n",
      "Training Epoch: [3]  [ 450/1229]  eta: 0:04:16  lr: 0.005000  loss: 0.4537 (0.4990)  loss_classifier: 0.1994 (0.1681)  loss_box_reg: 0.1393 (0.1459)  loss_objectness: 0.1140 (0.1303)  loss_rpn_box_reg: 0.0305 (0.0547)  time: 0.3286  data: 0.1377  max mem: 3969\n",
      "Training Epoch: [3]  [ 460/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.3851 (0.4969)  loss_classifier: 0.1397 (0.1672)  loss_box_reg: 0.0949 (0.1448)  loss_objectness: 0.1140 (0.1301)  loss_rpn_box_reg: 0.0399 (0.0547)  time: 0.3278  data: 0.1384  max mem: 3969\n",
      "Training Epoch: [3]  [ 470/1229]  eta: 0:04:09  lr: 0.005000  loss: 0.4446 (0.4984)  loss_classifier: 0.1442 (0.1674)  loss_box_reg: 0.1055 (0.1447)  loss_objectness: 0.1375 (0.1309)  loss_rpn_box_reg: 0.0526 (0.0554)  time: 0.3301  data: 0.1428  max mem: 3969\n",
      "Training Epoch: [3]  [ 480/1229]  eta: 0:04:06  lr: 0.005000  loss: 0.4837 (0.4978)  loss_classifier: 0.1566 (0.1672)  loss_box_reg: 0.1420 (0.1446)  loss_objectness: 0.1421 (0.1304)  loss_rpn_box_reg: 0.0313 (0.0555)  time: 0.3262  data: 0.1434  max mem: 3969\n",
      "Training Epoch: [3]  [ 490/1229]  eta: 0:04:03  lr: 0.005000  loss: 0.4772 (0.4989)  loss_classifier: 0.1673 (0.1677)  loss_box_reg: 0.1022 (0.1442)  loss_objectness: 0.1421 (0.1313)  loss_rpn_box_reg: 0.0398 (0.0557)  time: 0.3204  data: 0.1399  max mem: 3969\n",
      "Training Epoch: [3]  [ 500/1229]  eta: 0:03:59  lr: 0.005000  loss: 0.4038 (0.4964)  loss_classifier: 0.1079 (0.1666)  loss_box_reg: 0.0653 (0.1429)  loss_objectness: 0.1656 (0.1317)  loss_rpn_box_reg: 0.0384 (0.0551)  time: 0.3162  data: 0.1382  max mem: 3969\n",
      "Training Epoch: [3]  [ 510/1229]  eta: 0:03:56  lr: 0.005000  loss: 0.2956 (0.4940)  loss_classifier: 0.0955 (0.1662)  loss_box_reg: 0.0684 (0.1419)  loss_objectness: 0.1218 (0.1312)  loss_rpn_box_reg: 0.0189 (0.0547)  time: 0.3237  data: 0.1388  max mem: 3969\n",
      "Training Epoch: [3]  [ 520/1229]  eta: 0:03:52  lr: 0.005000  loss: 0.4112 (0.4941)  loss_classifier: 0.1348 (0.1664)  loss_box_reg: 0.0872 (0.1423)  loss_objectness: 0.0932 (0.1310)  loss_rpn_box_reg: 0.0213 (0.0544)  time: 0.3241  data: 0.1358  max mem: 3969\n",
      "Training Epoch: [3]  [ 530/1229]  eta: 0:03:49  lr: 0.005000  loss: 0.4383 (0.4944)  loss_classifier: 0.1809 (0.1671)  loss_box_reg: 0.1208 (0.1424)  loss_objectness: 0.1095 (0.1310)  loss_rpn_box_reg: 0.0191 (0.0539)  time: 0.3252  data: 0.1365  max mem: 3969\n",
      "Training Epoch: [3]  [ 540/1229]  eta: 0:03:46  lr: 0.005000  loss: 0.3678 (0.4914)  loss_classifier: 0.1365 (0.1661)  loss_box_reg: 0.0868 (0.1413)  loss_objectness: 0.1122 (0.1306)  loss_rpn_box_reg: 0.0208 (0.0534)  time: 0.3225  data: 0.1376  max mem: 3969\n",
      "Training Epoch: [3]  [ 550/1229]  eta: 0:03:43  lr: 0.005000  loss: 0.3503 (0.4887)  loss_classifier: 0.1101 (0.1652)  loss_box_reg: 0.0777 (0.1405)  loss_objectness: 0.1045 (0.1297)  loss_rpn_box_reg: 0.0273 (0.0533)  time: 0.3231  data: 0.1360  max mem: 3969\n",
      "Training Epoch: [3]  [ 560/1229]  eta: 0:03:39  lr: 0.005000  loss: 0.4120 (0.4892)  loss_classifier: 0.1512 (0.1653)  loss_box_reg: 0.1176 (0.1407)  loss_objectness: 0.1034 (0.1299)  loss_rpn_box_reg: 0.0245 (0.0533)  time: 0.3242  data: 0.1365  max mem: 3969\n",
      "Training Epoch: [3]  [ 570/1229]  eta: 0:03:36  lr: 0.005000  loss: 0.4649 (0.4888)  loss_classifier: 0.1590 (0.1653)  loss_box_reg: 0.1324 (0.1409)  loss_objectness: 0.1132 (0.1294)  loss_rpn_box_reg: 0.0245 (0.0532)  time: 0.3174  data: 0.1357  max mem: 3969\n",
      "Training Epoch: [3]  [ 580/1229]  eta: 0:03:32  lr: 0.005000  loss: 0.4907 (0.4895)  loss_classifier: 0.1630 (0.1653)  loss_box_reg: 0.1414 (0.1410)  loss_objectness: 0.1132 (0.1293)  loss_rpn_box_reg: 0.0302 (0.0539)  time: 0.3214  data: 0.1325  max mem: 3969\n",
      "Training Epoch: [3]  [ 590/1229]  eta: 0:03:29  lr: 0.005000  loss: 0.4678 (0.4896)  loss_classifier: 0.1630 (0.1653)  loss_box_reg: 0.1402 (0.1410)  loss_objectness: 0.1249 (0.1295)  loss_rpn_box_reg: 0.0257 (0.0538)  time: 0.3172  data: 0.1329  max mem: 3969\n",
      "Training Epoch: [3]  [ 600/1229]  eta: 0:03:25  lr: 0.005000  loss: 0.4678 (0.4903)  loss_classifier: 0.1652 (0.1657)  loss_box_reg: 0.1559 (0.1415)  loss_objectness: 0.1160 (0.1297)  loss_rpn_box_reg: 0.0348 (0.0535)  time: 0.3116  data: 0.1366  max mem: 3969\n",
      "Training Epoch: [3]  [ 610/1229]  eta: 0:03:22  lr: 0.005000  loss: 0.4835 (0.4914)  loss_classifier: 0.1552 (0.1659)  loss_box_reg: 0.1130 (0.1419)  loss_objectness: 0.1271 (0.1301)  loss_rpn_box_reg: 0.0349 (0.0535)  time: 0.3133  data: 0.1365  max mem: 3969\n",
      "Training Epoch: [3]  [ 620/1229]  eta: 0:03:19  lr: 0.005000  loss: 0.4767 (0.4927)  loss_classifier: 0.1447 (0.1663)  loss_box_reg: 0.1105 (0.1427)  loss_objectness: 0.1260 (0.1299)  loss_rpn_box_reg: 0.0286 (0.0538)  time: 0.3141  data: 0.1355  max mem: 3969\n",
      "Training Epoch: [3]  [ 630/1229]  eta: 0:03:15  lr: 0.005000  loss: 0.5195 (0.4936)  loss_classifier: 0.1770 (0.1667)  loss_box_reg: 0.1362 (0.1430)  loss_objectness: 0.1260 (0.1301)  loss_rpn_box_reg: 0.0362 (0.0538)  time: 0.3167  data: 0.1357  max mem: 3969\n",
      "Training Epoch: [3]  [ 640/1229]  eta: 0:03:12  lr: 0.005000  loss: 0.4542 (0.4944)  loss_classifier: 0.1612 (0.1668)  loss_box_reg: 0.1482 (0.1428)  loss_objectness: 0.1179 (0.1305)  loss_rpn_box_reg: 0.0377 (0.0543)  time: 0.3165  data: 0.1354  max mem: 3969\n",
      "Training Epoch: [3]  [ 650/1229]  eta: 0:03:09  lr: 0.005000  loss: 0.3612 (0.4939)  loss_classifier: 0.1325 (0.1666)  loss_box_reg: 0.1150 (0.1431)  loss_objectness: 0.1103 (0.1302)  loss_rpn_box_reg: 0.0372 (0.0540)  time: 0.3159  data: 0.1362  max mem: 3969\n",
      "Training Epoch: [3]  [ 660/1229]  eta: 0:03:05  lr: 0.005000  loss: 0.3500 (0.4941)  loss_classifier: 0.1325 (0.1666)  loss_box_reg: 0.1150 (0.1429)  loss_objectness: 0.0927 (0.1301)  loss_rpn_box_reg: 0.0305 (0.0544)  time: 0.3316  data: 0.1391  max mem: 3969\n",
      "Training Epoch: [3]  [ 670/1229]  eta: 0:03:02  lr: 0.005000  loss: 0.3573 (0.4930)  loss_classifier: 0.1286 (0.1664)  loss_box_reg: 0.0962 (0.1427)  loss_objectness: 0.0927 (0.1297)  loss_rpn_box_reg: 0.0290 (0.0541)  time: 0.3334  data: 0.1418  max mem: 3969\n",
      "Training Epoch: [3]  [ 680/1229]  eta: 0:02:59  lr: 0.005000  loss: 0.4043 (0.4931)  loss_classifier: 0.1457 (0.1665)  loss_box_reg: 0.0968 (0.1430)  loss_objectness: 0.0891 (0.1296)  loss_rpn_box_reg: 0.0257 (0.0539)  time: 0.3253  data: 0.1430  max mem: 3969\n",
      "Training Epoch: [3]  [ 690/1229]  eta: 0:02:56  lr: 0.005000  loss: 0.4587 (0.4936)  loss_classifier: 0.1731 (0.1667)  loss_box_reg: 0.1243 (0.1430)  loss_objectness: 0.1119 (0.1296)  loss_rpn_box_reg: 0.0319 (0.0542)  time: 0.3316  data: 0.1436  max mem: 3969\n",
      "Training Epoch: [3]  [ 700/1229]  eta: 0:02:52  lr: 0.005000  loss: 0.4834 (0.4939)  loss_classifier: 0.1812 (0.1668)  loss_box_reg: 0.1429 (0.1429)  loss_objectness: 0.1320 (0.1299)  loss_rpn_box_reg: 0.0499 (0.0544)  time: 0.3305  data: 0.1420  max mem: 3969\n",
      "Training Epoch: [3]  [ 710/1229]  eta: 0:02:49  lr: 0.005000  loss: 0.4859 (0.4932)  loss_classifier: 0.1582 (0.1666)  loss_box_reg: 0.1301 (0.1426)  loss_objectness: 0.1228 (0.1299)  loss_rpn_box_reg: 0.0384 (0.0541)  time: 0.3242  data: 0.1410  max mem: 3969\n",
      "Training Epoch: [3]  [ 720/1229]  eta: 0:02:46  lr: 0.005000  loss: 0.4491 (0.4930)  loss_classifier: 0.1579 (0.1665)  loss_box_reg: 0.1071 (0.1426)  loss_objectness: 0.1244 (0.1301)  loss_rpn_box_reg: 0.0374 (0.0538)  time: 0.3263  data: 0.1413  max mem: 3969\n",
      "Training Epoch: [3]  [ 730/1229]  eta: 0:02:43  lr: 0.005000  loss: 0.5051 (0.4940)  loss_classifier: 0.1726 (0.1671)  loss_box_reg: 0.1125 (0.1428)  loss_objectness: 0.1395 (0.1304)  loss_rpn_box_reg: 0.0336 (0.0536)  time: 0.3282  data: 0.1385  max mem: 3969\n",
      "Training Epoch: [3]  [ 740/1229]  eta: 0:02:39  lr: 0.005000  loss: 0.4935 (0.4935)  loss_classifier: 0.1720 (0.1670)  loss_box_reg: 0.1484 (0.1429)  loss_objectness: 0.1215 (0.1303)  loss_rpn_box_reg: 0.0299 (0.0533)  time: 0.3262  data: 0.1384  max mem: 3969\n",
      "Training Epoch: [3]  [ 750/1229]  eta: 0:02:36  lr: 0.005000  loss: 0.4568 (0.4932)  loss_classifier: 0.1382 (0.1669)  loss_box_reg: 0.1318 (0.1429)  loss_objectness: 0.1100 (0.1301)  loss_rpn_box_reg: 0.0246 (0.0532)  time: 0.3232  data: 0.1420  max mem: 3969\n",
      "Training Epoch: [3]  [ 760/1229]  eta: 0:02:33  lr: 0.005000  loss: 0.4639 (0.4938)  loss_classifier: 0.1673 (0.1672)  loss_box_reg: 0.1445 (0.1436)  loss_objectness: 0.1101 (0.1299)  loss_rpn_box_reg: 0.0318 (0.0531)  time: 0.3218  data: 0.1435  max mem: 3969\n",
      "Training Epoch: [3]  [ 770/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.3942 (0.4924)  loss_classifier: 0.1206 (0.1668)  loss_box_reg: 0.1087 (0.1429)  loss_objectness: 0.1101 (0.1298)  loss_rpn_box_reg: 0.0285 (0.0529)  time: 0.3205  data: 0.1422  max mem: 3969\n",
      "Training Epoch: [3]  [ 780/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.4031 (0.4922)  loss_classifier: 0.1557 (0.1670)  loss_box_reg: 0.0726 (0.1429)  loss_objectness: 0.0922 (0.1296)  loss_rpn_box_reg: 0.0286 (0.0527)  time: 0.3244  data: 0.1423  max mem: 3969\n",
      "Training Epoch: [3]  [ 790/1229]  eta: 0:02:23  lr: 0.005000  loss: 0.4720 (0.4933)  loss_classifier: 0.1635 (0.1669)  loss_box_reg: 0.1367 (0.1428)  loss_objectness: 0.0922 (0.1301)  loss_rpn_box_reg: 0.0359 (0.0534)  time: 0.3245  data: 0.1397  max mem: 3969\n",
      "Training Epoch: [3]  [ 800/1229]  eta: 0:02:20  lr: 0.005000  loss: 0.4355 (0.4934)  loss_classifier: 0.1438 (0.1670)  loss_box_reg: 0.1145 (0.1428)  loss_objectness: 0.1282 (0.1302)  loss_rpn_box_reg: 0.0330 (0.0535)  time: 0.3191  data: 0.1388  max mem: 3969\n",
      "Training Epoch: [3]  [ 810/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.5095 (0.4947)  loss_classifier: 0.1813 (0.1674)  loss_box_reg: 0.1262 (0.1433)  loss_objectness: 0.1282 (0.1305)  loss_rpn_box_reg: 0.0330 (0.0535)  time: 0.3209  data: 0.1421  max mem: 3969\n",
      "Training Epoch: [3]  [ 820/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.5136 (0.4944)  loss_classifier: 0.1813 (0.1672)  loss_box_reg: 0.1391 (0.1429)  loss_objectness: 0.1366 (0.1307)  loss_rpn_box_reg: 0.0333 (0.0536)  time: 0.3277  data: 0.1417  max mem: 3969\n",
      "Training Epoch: [3]  [ 830/1229]  eta: 0:02:10  lr: 0.005000  loss: 0.4390 (0.4937)  loss_classifier: 0.1528 (0.1670)  loss_box_reg: 0.1138 (0.1427)  loss_objectness: 0.1035 (0.1306)  loss_rpn_box_reg: 0.0304 (0.0534)  time: 0.3342  data: 0.1402  max mem: 3969\n",
      "Training Epoch: [3]  [ 840/1229]  eta: 0:02:07  lr: 0.005000  loss: 0.3846 (0.4938)  loss_classifier: 0.1528 (0.1673)  loss_box_reg: 0.1187 (0.1427)  loss_objectness: 0.0993 (0.1306)  loss_rpn_box_reg: 0.0279 (0.0532)  time: 0.3307  data: 0.1419  max mem: 3969\n",
      "Training Epoch: [3]  [ 850/1229]  eta: 0:02:03  lr: 0.005000  loss: 0.4004 (0.4927)  loss_classifier: 0.1541 (0.1670)  loss_box_reg: 0.1187 (0.1425)  loss_objectness: 0.0950 (0.1302)  loss_rpn_box_reg: 0.0190 (0.0530)  time: 0.3289  data: 0.1407  max mem: 3969\n",
      "Training Epoch: [3]  [ 860/1229]  eta: 0:02:00  lr: 0.005000  loss: 0.4249 (0.4928)  loss_classifier: 0.1522 (0.1671)  loss_box_reg: 0.0925 (0.1423)  loss_objectness: 0.1212 (0.1305)  loss_rpn_box_reg: 0.0238 (0.0530)  time: 0.3283  data: 0.1378  max mem: 3969\n",
      "Training Epoch: [3]  [ 870/1229]  eta: 0:01:57  lr: 0.005000  loss: 0.4225 (0.4916)  loss_classifier: 0.1334 (0.1666)  loss_box_reg: 0.0925 (0.1418)  loss_objectness: 0.1225 (0.1303)  loss_rpn_box_reg: 0.0385 (0.0529)  time: 0.3209  data: 0.1365  max mem: 3969\n",
      "Training Epoch: [3]  [ 880/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.4244 (0.4922)  loss_classifier: 0.1401 (0.1669)  loss_box_reg: 0.1114 (0.1421)  loss_objectness: 0.1209 (0.1303)  loss_rpn_box_reg: 0.0365 (0.0529)  time: 0.3233  data: 0.1379  max mem: 3969\n",
      "Training Epoch: [3]  [ 890/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.4763 (0.4925)  loss_classifier: 0.1786 (0.1671)  loss_box_reg: 0.1595 (0.1423)  loss_objectness: 0.1327 (0.1303)  loss_rpn_box_reg: 0.0352 (0.0527)  time: 0.3319  data: 0.1436  max mem: 3969\n",
      "Training Epoch: [3]  [ 900/1229]  eta: 0:01:47  lr: 0.005000  loss: 0.5435 (0.4943)  loss_classifier: 0.1824 (0.1676)  loss_box_reg: 0.1531 (0.1427)  loss_objectness: 0.1332 (0.1311)  loss_rpn_box_reg: 0.0397 (0.0530)  time: 0.3330  data: 0.1428  max mem: 3969\n",
      "Training Epoch: [3]  [ 910/1229]  eta: 0:01:44  lr: 0.005000  loss: 0.5813 (0.4946)  loss_classifier: 0.1754 (0.1676)  loss_box_reg: 0.1477 (0.1429)  loss_objectness: 0.1322 (0.1310)  loss_rpn_box_reg: 0.0437 (0.0531)  time: 0.3241  data: 0.1386  max mem: 3969\n",
      "Training Epoch: [3]  [ 920/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.5299 (0.4957)  loss_classifier: 0.1894 (0.1681)  loss_box_reg: 0.1477 (0.1432)  loss_objectness: 0.1195 (0.1311)  loss_rpn_box_reg: 0.0537 (0.0533)  time: 0.3251  data: 0.1390  max mem: 3969\n",
      "Training Epoch: [3]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.5965 (0.4973)  loss_classifier: 0.2144 (0.1685)  loss_box_reg: 0.1857 (0.1440)  loss_objectness: 0.1314 (0.1313)  loss_rpn_box_reg: 0.0550 (0.0535)  time: 0.3253  data: 0.1410  max mem: 3969\n",
      "Training Epoch: [3]  [ 940/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.5657 (0.4970)  loss_classifier: 0.1815 (0.1685)  loss_box_reg: 0.1857 (0.1440)  loss_objectness: 0.1224 (0.1310)  loss_rpn_box_reg: 0.0326 (0.0535)  time: 0.3203  data: 0.1411  max mem: 3969\n",
      "Training Epoch: [3]  [ 950/1229]  eta: 0:01:31  lr: 0.005000  loss: 0.5205 (0.4982)  loss_classifier: 0.1875 (0.1690)  loss_box_reg: 0.1609 (0.1445)  loss_objectness: 0.1190 (0.1313)  loss_rpn_box_reg: 0.0312 (0.0533)  time: 0.3235  data: 0.1415  max mem: 3969\n",
      "Training Epoch: [3]  [ 960/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.5517 (0.4989)  loss_classifier: 0.1814 (0.1691)  loss_box_reg: 0.1609 (0.1449)  loss_objectness: 0.1423 (0.1314)  loss_rpn_box_reg: 0.0341 (0.0536)  time: 0.3235  data: 0.1411  max mem: 3969\n",
      "Training Epoch: [3]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.5045 (0.4998)  loss_classifier: 0.1628 (0.1693)  loss_box_reg: 0.1227 (0.1449)  loss_objectness: 0.1226 (0.1317)  loss_rpn_box_reg: 0.0275 (0.0539)  time: 0.3237  data: 0.1417  max mem: 3969\n",
      "Training Epoch: [3]  [ 980/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.4260 (0.4993)  loss_classifier: 0.1628 (0.1693)  loss_box_reg: 0.1145 (0.1446)  loss_objectness: 0.1184 (0.1317)  loss_rpn_box_reg: 0.0275 (0.0537)  time: 0.3240  data: 0.1422  max mem: 3969\n",
      "Training Epoch: [3]  [ 990/1229]  eta: 0:01:17  lr: 0.005000  loss: 0.4559 (0.4996)  loss_classifier: 0.1564 (0.1693)  loss_box_reg: 0.1200 (0.1446)  loss_objectness: 0.1145 (0.1318)  loss_rpn_box_reg: 0.0295 (0.0539)  time: 0.3196  data: 0.1398  max mem: 3969\n",
      "Training Epoch: [3]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.4420 (0.4998)  loss_classifier: 0.1562 (0.1694)  loss_box_reg: 0.1240 (0.1448)  loss_objectness: 0.1088 (0.1317)  loss_rpn_box_reg: 0.0277 (0.0540)  time: 0.3194  data: 0.1400  max mem: 3969\n",
      "Training Epoch: [3]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.4198 (0.4993)  loss_classifier: 0.1562 (0.1693)  loss_box_reg: 0.1284 (0.1448)  loss_objectness: 0.0954 (0.1313)  loss_rpn_box_reg: 0.0277 (0.0538)  time: 0.3249  data: 0.1396  max mem: 3969\n",
      "Training Epoch: [3]  [1020/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.4198 (0.4987)  loss_classifier: 0.1669 (0.1693)  loss_box_reg: 0.1402 (0.1447)  loss_objectness: 0.0897 (0.1310)  loss_rpn_box_reg: 0.0326 (0.0537)  time: 0.3263  data: 0.1386  max mem: 3969\n",
      "Training Epoch: [3]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.4035 (0.4984)  loss_classifier: 0.1523 (0.1692)  loss_box_reg: 0.1431 (0.1447)  loss_objectness: 0.0897 (0.1309)  loss_rpn_box_reg: 0.0310 (0.0537)  time: 0.3287  data: 0.1398  max mem: 3969\n",
      "Training Epoch: [3]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.3734 (0.4976)  loss_classifier: 0.1440 (0.1690)  loss_box_reg: 0.1045 (0.1444)  loss_objectness: 0.0920 (0.1307)  loss_rpn_box_reg: 0.0231 (0.0535)  time: 0.3256  data: 0.1410  max mem: 3969\n",
      "Training Epoch: [3]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.4243 (0.4983)  loss_classifier: 0.1489 (0.1692)  loss_box_reg: 0.1167 (0.1448)  loss_objectness: 0.1272 (0.1308)  loss_rpn_box_reg: 0.0273 (0.0535)  time: 0.3219  data: 0.1408  max mem: 3969\n",
      "Training Epoch: [3]  [1060/1229]  eta: 0:00:55  lr: 0.005000  loss: 0.5926 (0.4993)  loss_classifier: 0.1656 (0.1697)  loss_box_reg: 0.1676 (0.1452)  loss_objectness: 0.1381 (0.1310)  loss_rpn_box_reg: 0.0359 (0.0534)  time: 0.3240  data: 0.1404  max mem: 3969\n",
      "Training Epoch: [3]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.4200 (0.4985)  loss_classifier: 0.1277 (0.1694)  loss_box_reg: 0.1185 (0.1450)  loss_objectness: 0.1066 (0.1308)  loss_rpn_box_reg: 0.0265 (0.0533)  time: 0.3316  data: 0.1398  max mem: 3969\n",
      "Training Epoch: [3]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.4399 (0.4987)  loss_classifier: 0.1544 (0.1696)  loss_box_reg: 0.1560 (0.1453)  loss_objectness: 0.0992 (0.1306)  loss_rpn_box_reg: 0.0254 (0.0531)  time: 0.3280  data: 0.1390  max mem: 3969\n",
      "Training Epoch: [3]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.4797 (0.4988)  loss_classifier: 0.1706 (0.1697)  loss_box_reg: 0.1578 (0.1455)  loss_objectness: 0.0993 (0.1306)  loss_rpn_box_reg: 0.0248 (0.0530)  time: 0.3177  data: 0.1402  max mem: 3969\n",
      "Training Epoch: [3]  [1100/1229]  eta: 0:00:42  lr: 0.005000  loss: 0.3590 (0.4980)  loss_classifier: 0.1305 (0.1694)  loss_box_reg: 0.0996 (0.1453)  loss_objectness: 0.1010 (0.1303)  loss_rpn_box_reg: 0.0244 (0.0530)  time: 0.3196  data: 0.1418  max mem: 3969\n",
      "Training Epoch: [3]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.3522 (0.4975)  loss_classifier: 0.1162 (0.1692)  loss_box_reg: 0.0797 (0.1451)  loss_objectness: 0.1054 (0.1302)  loss_rpn_box_reg: 0.0307 (0.0529)  time: 0.3239  data: 0.1409  max mem: 3969\n",
      "Training Epoch: [3]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4126 (0.4969)  loss_classifier: 0.1162 (0.1690)  loss_box_reg: 0.0882 (0.1449)  loss_objectness: 0.1291 (0.1303)  loss_rpn_box_reg: 0.0346 (0.0528)  time: 0.3212  data: 0.1377  max mem: 3969\n",
      "Training Epoch: [3]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.4217 (0.4963)  loss_classifier: 0.1313 (0.1688)  loss_box_reg: 0.0969 (0.1447)  loss_objectness: 0.1100 (0.1300)  loss_rpn_box_reg: 0.0275 (0.0528)  time: 0.3236  data: 0.1413  max mem: 3969\n",
      "Training Epoch: [3]  [1140/1229]  eta: 0:00:29  lr: 0.005000  loss: 0.4232 (0.4964)  loss_classifier: 0.1552 (0.1689)  loss_box_reg: 0.1229 (0.1450)  loss_objectness: 0.0996 (0.1300)  loss_rpn_box_reg: 0.0191 (0.0525)  time: 0.3235  data: 0.1429  max mem: 3969\n",
      "Training Epoch: [3]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.4772 (0.4964)  loss_classifier: 0.1707 (0.1690)  loss_box_reg: 0.1687 (0.1451)  loss_objectness: 0.0996 (0.1298)  loss_rpn_box_reg: 0.0251 (0.0524)  time: 0.3202  data: 0.1389  max mem: 3969\n",
      "Training Epoch: [3]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.4311 (0.4964)  loss_classifier: 0.1656 (0.1689)  loss_box_reg: 0.1599 (0.1452)  loss_objectness: 0.0861 (0.1299)  loss_rpn_box_reg: 0.0261 (0.0524)  time: 0.3249  data: 0.1379  max mem: 3969\n",
      "Training Epoch: [3]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.4311 (0.4966)  loss_classifier: 0.1594 (0.1690)  loss_box_reg: 0.0889 (0.1450)  loss_objectness: 0.1339 (0.1303)  loss_rpn_box_reg: 0.0347 (0.0524)  time: 0.3290  data: 0.1398  max mem: 3969\n",
      "Training Epoch: [3]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.4174 (0.4965)  loss_classifier: 0.1594 (0.1691)  loss_box_reg: 0.0889 (0.1452)  loss_objectness: 0.1016 (0.1300)  loss_rpn_box_reg: 0.0331 (0.0523)  time: 0.3304  data: 0.1421  max mem: 3969\n",
      "Training Epoch: [3]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.4972 (0.4978)  loss_classifier: 0.1821 (0.1696)  loss_box_reg: 0.1423 (0.1457)  loss_objectness: 0.1116 (0.1303)  loss_rpn_box_reg: 0.0264 (0.0522)  time: 0.3308  data: 0.1434  max mem: 3969\n",
      "Training Epoch: [3]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.5051 (0.4977)  loss_classifier: 0.1892 (0.1696)  loss_box_reg: 0.1278 (0.1458)  loss_objectness: 0.1437 (0.1302)  loss_rpn_box_reg: 0.0264 (0.0521)  time: 0.3257  data: 0.1418  max mem: 3969\n",
      "Training Epoch: [3]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.3358 (0.4971)  loss_classifier: 0.1121 (0.1695)  loss_box_reg: 0.0878 (0.1456)  loss_objectness: 0.1109 (0.1301)  loss_rpn_box_reg: 0.0257 (0.0520)  time: 0.3202  data: 0.1376  max mem: 3969\n",
      "Training Epoch: [3]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.3781 (0.4970)  loss_classifier: 0.1328 (0.1695)  loss_box_reg: 0.0965 (0.1455)  loss_objectness: 0.1106 (0.1301)  loss_rpn_box_reg: 0.0288 (0.0519)  time: 0.3224  data: 0.1414  max mem: 3969\n",
      "Training Epoch: [3]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4691 (0.4971)  loss_classifier: 0.1505 (0.1694)  loss_box_reg: 0.1189 (0.1456)  loss_objectness: 0.1109 (0.1301)  loss_rpn_box_reg: 0.0341 (0.0520)  time: 0.3288  data: 0.1421  max mem: 3969\n",
      "Training Epoch: [3] Total time: 0:06:40 (0.3262 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:06:24  model_time: 0.3710 (0.3710)  evaluator_time: 0.0020 (0.0020)  time: 1.2490  data: 0.0300  max mem: 3969\n",
      "Test:  [100/308]  eta: 0:00:35  model_time: 0.1060 (0.1126)  evaluator_time: 0.0060 (0.0088)  time: 0.1660  data: 0.0444  max mem: 3969\n",
      "Test:  [200/308]  eta: 0:00:17  model_time: 0.1150 (0.1116)  evaluator_time: 0.0030 (0.0079)  time: 0.1611  data: 0.0387  max mem: 3969\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.1030 (0.1113)  evaluator_time: 0.0040 (0.0078)  time: 0.1647  data: 0.0476  max mem: 3969\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.1030 (0.1112)  evaluator_time: 0.0030 (0.0078)  time: 0.1576  data: 0.0445  max mem: 3969\n",
      "Test: Total time: 0:00:49 (0.1619 s / it)\n",
      "Averaged stats: model_time: 0.1030 (0.1112)  evaluator_time: 0.0030 (0.0078)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.17s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.020\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.127\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.220\n",
      "Testing Epoch: [3]  [  0/308]  eta: 0:00:48  lr: 0.005000  loss: 0.1792 (0.1792)  loss_classifier: 0.0575 (0.0575)  loss_box_reg: 0.0550 (0.0550)  loss_objectness: 0.0473 (0.0473)  loss_rpn_box_reg: 0.0193 (0.0193)  time: 0.1580  data: 0.0300  max mem: 3969\n",
      "Testing Epoch: [3]  [100/308]  eta: 0:00:37  lr: 0.005000  loss: 0.3377 (0.5161)  loss_classifier: 0.1292 (0.1675)  loss_box_reg: 0.1171 (0.1665)  loss_objectness: 0.0773 (0.1185)  loss_rpn_box_reg: 0.0226 (0.0636)  time: 0.1826  data: 0.0466  max mem: 3969\n",
      "Testing Epoch: [3]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.4148 (0.4898)  loss_classifier: 0.1328 (0.1593)  loss_box_reg: 0.1413 (0.1582)  loss_objectness: 0.0923 (0.1125)  loss_rpn_box_reg: 0.0283 (0.0598)  time: 0.1782  data: 0.0361  max mem: 3969\n",
      "Testing Epoch: [3]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5462 (0.4895)  loss_classifier: 0.1773 (0.1602)  loss_box_reg: 0.1671 (0.1617)  loss_objectness: 0.1000 (0.1095)  loss_rpn_box_reg: 0.0405 (0.0581)  time: 0.1751  data: 0.0463  max mem: 3973\n",
      "Testing Epoch: [3]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.5462 (0.4895)  loss_classifier: 0.1773 (0.1606)  loss_box_reg: 0.1694 (0.1619)  loss_objectness: 0.1000 (0.1094)  loss_rpn_box_reg: 0.0405 (0.0575)  time: 0.1725  data: 0.0438  max mem: 3973\n",
      "Testing Epoch: [3] Total time: 0:00:54 (0.1769 s / it)\n",
      "Training Epoch: [4]  [   0/1229]  eta: 0:06:39  lr: 0.005000  loss: 0.5490 (0.5490)  loss_classifier: 0.2293 (0.2293)  loss_box_reg: 0.1558 (0.1558)  loss_objectness: 0.1307 (0.1307)  loss_rpn_box_reg: 0.0333 (0.0333)  time: 0.3250  data: 0.1480  max mem: 3973\n",
      "Training Epoch: [4]  [  10/1229]  eta: 0:06:48  lr: 0.005000  loss: 0.4630 (0.5008)  loss_classifier: 0.1737 (0.1630)  loss_box_reg: 0.1384 (0.1185)  loss_objectness: 0.1307 (0.1453)  loss_rpn_box_reg: 0.0333 (0.0740)  time: 0.3355  data: 0.1483  max mem: 3973\n",
      "Training Epoch: [4]  [  20/1229]  eta: 0:06:48  lr: 0.005000  loss: 0.4491 (0.4723)  loss_classifier: 0.1450 (0.1582)  loss_box_reg: 0.0942 (0.1169)  loss_objectness: 0.1123 (0.1328)  loss_rpn_box_reg: 0.0322 (0.0644)  time: 0.3383  data: 0.1519  max mem: 3973\n",
      "Training Epoch: [4]  [  30/1229]  eta: 0:06:46  lr: 0.005000  loss: 0.4882 (0.4842)  loss_classifier: 0.1542 (0.1605)  loss_box_reg: 0.1220 (0.1390)  loss_objectness: 0.1007 (0.1228)  loss_rpn_box_reg: 0.0351 (0.0619)  time: 0.3412  data: 0.1544  max mem: 3973\n",
      "Training Epoch: [4]  [  40/1229]  eta: 0:06:41  lr: 0.005000  loss: 0.4651 (0.4836)  loss_classifier: 0.1542 (0.1632)  loss_box_reg: 0.1430 (0.1357)  loss_objectness: 0.1126 (0.1290)  loss_rpn_box_reg: 0.0299 (0.0557)  time: 0.3376  data: 0.1534  max mem: 3973\n",
      "Training Epoch: [4]  [  50/1229]  eta: 0:06:39  lr: 0.005000  loss: 0.5186 (0.5027)  loss_classifier: 0.1611 (0.1673)  loss_box_reg: 0.1430 (0.1450)  loss_objectness: 0.1297 (0.1315)  loss_rpn_box_reg: 0.0350 (0.0590)  time: 0.3386  data: 0.1520  max mem: 3973\n",
      "Training Epoch: [4]  [  60/1229]  eta: 0:06:35  lr: 0.005000  loss: 0.5222 (0.5069)  loss_classifier: 0.1838 (0.1690)  loss_box_reg: 0.1509 (0.1447)  loss_objectness: 0.1222 (0.1325)  loss_rpn_box_reg: 0.0334 (0.0608)  time: 0.3401  data: 0.1510  max mem: 3973\n",
      "Training Epoch: [4]  [  70/1229]  eta: 0:06:30  lr: 0.005000  loss: 0.4560 (0.5023)  loss_classifier: 0.1708 (0.1683)  loss_box_reg: 0.1506 (0.1491)  loss_objectness: 0.1093 (0.1295)  loss_rpn_box_reg: 0.0202 (0.0554)  time: 0.3332  data: 0.1518  max mem: 3973\n",
      "Training Epoch: [4]  [  80/1229]  eta: 0:06:29  lr: 0.005000  loss: 0.5109 (0.5163)  loss_classifier: 0.1708 (0.1747)  loss_box_reg: 0.1757 (0.1550)  loss_objectness: 0.1256 (0.1296)  loss_rpn_box_reg: 0.0260 (0.0571)  time: 0.3396  data: 0.1536  max mem: 3973\n",
      "Training Epoch: [4]  [  90/1229]  eta: 0:06:27  lr: 0.005000  loss: 0.4316 (0.5134)  loss_classifier: 0.1629 (0.1749)  loss_box_reg: 0.1757 (0.1540)  loss_objectness: 0.1207 (0.1269)  loss_rpn_box_reg: 0.0365 (0.0576)  time: 0.3487  data: 0.1548  max mem: 3973\n",
      "Training Epoch: [4]  [ 100/1229]  eta: 0:06:23  lr: 0.005000  loss: 0.3801 (0.5102)  loss_classifier: 0.1406 (0.1760)  loss_box_reg: 0.1160 (0.1557)  loss_objectness: 0.0863 (0.1246)  loss_rpn_box_reg: 0.0278 (0.0539)  time: 0.3443  data: 0.1514  max mem: 3973\n",
      "Training Epoch: [4]  [ 110/1229]  eta: 0:06:18  lr: 0.005000  loss: 0.2890 (0.4995)  loss_classifier: 0.0907 (0.1714)  loss_box_reg: 0.0909 (0.1523)  loss_objectness: 0.0805 (0.1229)  loss_rpn_box_reg: 0.0144 (0.0529)  time: 0.3334  data: 0.1457  max mem: 3973\n",
      "Training Epoch: [4]  [ 120/1229]  eta: 0:06:15  lr: 0.005000  loss: 0.3844 (0.4998)  loss_classifier: 0.1469 (0.1713)  loss_box_reg: 0.1172 (0.1520)  loss_objectness: 0.0805 (0.1222)  loss_rpn_box_reg: 0.0253 (0.0542)  time: 0.3333  data: 0.1451  max mem: 3973\n",
      "Training Epoch: [4]  [ 130/1229]  eta: 0:06:11  lr: 0.005000  loss: 0.3708 (0.4864)  loss_classifier: 0.1272 (0.1672)  loss_box_reg: 0.1187 (0.1491)  loss_objectness: 0.0786 (0.1186)  loss_rpn_box_reg: 0.0198 (0.0515)  time: 0.3362  data: 0.1440  max mem: 3973\n",
      "Training Epoch: [4]  [ 140/1229]  eta: 0:06:06  lr: 0.005000  loss: 0.2994 (0.4812)  loss_classifier: 0.1151 (0.1652)  loss_box_reg: 0.0968 (0.1479)  loss_objectness: 0.0635 (0.1165)  loss_rpn_box_reg: 0.0150 (0.0517)  time: 0.3258  data: 0.1419  max mem: 3973\n",
      "Training Epoch: [4]  [ 150/1229]  eta: 0:06:02  lr: 0.005000  loss: 0.4630 (0.4851)  loss_classifier: 0.1341 (0.1648)  loss_box_reg: 0.1004 (0.1467)  loss_objectness: 0.1104 (0.1197)  loss_rpn_box_reg: 0.0203 (0.0539)  time: 0.3239  data: 0.1421  max mem: 3973\n",
      "Training Epoch: [4]  [ 160/1229]  eta: 0:05:58  lr: 0.005000  loss: 0.4308 (0.4823)  loss_classifier: 0.1341 (0.1640)  loss_box_reg: 0.1000 (0.1463)  loss_objectness: 0.1173 (0.1190)  loss_rpn_box_reg: 0.0242 (0.0530)  time: 0.3236  data: 0.1415  max mem: 3973\n",
      "Training Epoch: [4]  [ 170/1229]  eta: 0:05:54  lr: 0.005000  loss: 0.4554 (0.4844)  loss_classifier: 0.1579 (0.1652)  loss_box_reg: 0.1427 (0.1466)  loss_objectness: 0.1173 (0.1204)  loss_rpn_box_reg: 0.0264 (0.0522)  time: 0.3222  data: 0.1420  max mem: 3973\n",
      "Training Epoch: [4]  [ 180/1229]  eta: 0:05:51  lr: 0.005000  loss: 0.4554 (0.4840)  loss_classifier: 0.1579 (0.1642)  loss_box_reg: 0.1347 (0.1459)  loss_objectness: 0.1065 (0.1204)  loss_rpn_box_reg: 0.0292 (0.0534)  time: 0.3313  data: 0.1420  max mem: 3973\n",
      "Training Epoch: [4]  [ 190/1229]  eta: 0:05:47  lr: 0.005000  loss: 0.3788 (0.4829)  loss_classifier: 0.1369 (0.1639)  loss_box_reg: 0.0959 (0.1440)  loss_objectness: 0.1243 (0.1210)  loss_rpn_box_reg: 0.0292 (0.0540)  time: 0.3331  data: 0.1413  max mem: 3973\n",
      "Training Epoch: [4]  [ 200/1229]  eta: 0:05:43  lr: 0.005000  loss: 0.3788 (0.4790)  loss_classifier: 0.1300 (0.1627)  loss_box_reg: 0.0748 (0.1416)  loss_objectness: 0.1316 (0.1218)  loss_rpn_box_reg: 0.0240 (0.0528)  time: 0.3264  data: 0.1431  max mem: 3973\n",
      "Training Epoch: [4]  [ 210/1229]  eta: 0:05:40  lr: 0.005000  loss: 0.3244 (0.4748)  loss_classifier: 0.1053 (0.1609)  loss_box_reg: 0.0844 (0.1400)  loss_objectness: 0.1409 (0.1223)  loss_rpn_box_reg: 0.0285 (0.0516)  time: 0.3252  data: 0.1452  max mem: 3973\n",
      "Training Epoch: [4]  [ 220/1229]  eta: 0:05:36  lr: 0.005000  loss: 0.4131 (0.4796)  loss_classifier: 0.1334 (0.1622)  loss_box_reg: 0.1161 (0.1430)  loss_objectness: 0.1086 (0.1226)  loss_rpn_box_reg: 0.0347 (0.0517)  time: 0.3249  data: 0.1444  max mem: 3973\n",
      "Training Epoch: [4]  [ 230/1229]  eta: 0:05:32  lr: 0.005000  loss: 0.5312 (0.4829)  loss_classifier: 0.1634 (0.1635)  loss_box_reg: 0.1722 (0.1453)  loss_objectness: 0.1086 (0.1231)  loss_rpn_box_reg: 0.0364 (0.0510)  time: 0.3209  data: 0.1437  max mem: 3973\n",
      "Training Epoch: [4]  [ 240/1229]  eta: 0:05:28  lr: 0.005000  loss: 0.5478 (0.4859)  loss_classifier: 0.1963 (0.1647)  loss_box_reg: 0.1829 (0.1487)  loss_objectness: 0.0904 (0.1220)  loss_rpn_box_reg: 0.0316 (0.0504)  time: 0.3202  data: 0.1428  max mem: 3973\n",
      "Training Epoch: [4]  [ 250/1229]  eta: 0:05:24  lr: 0.005000  loss: 0.4905 (0.4860)  loss_classifier: 0.1582 (0.1656)  loss_box_reg: 0.1586 (0.1489)  loss_objectness: 0.0866 (0.1219)  loss_rpn_box_reg: 0.0284 (0.0497)  time: 0.3247  data: 0.1420  max mem: 3973\n",
      "Training Epoch: [4]  [ 260/1229]  eta: 0:05:21  lr: 0.005000  loss: 0.4683 (0.4858)  loss_classifier: 0.1582 (0.1655)  loss_box_reg: 0.1319 (0.1490)  loss_objectness: 0.1005 (0.1217)  loss_rpn_box_reg: 0.0228 (0.0496)  time: 0.3279  data: 0.1417  max mem: 3973\n",
      "Training Epoch: [4]  [ 270/1229]  eta: 0:05:17  lr: 0.005000  loss: 0.4789 (0.4877)  loss_classifier: 0.1657 (0.1658)  loss_box_reg: 0.1086 (0.1490)  loss_objectness: 0.1005 (0.1221)  loss_rpn_box_reg: 0.0302 (0.0508)  time: 0.3230  data: 0.1406  max mem: 3973\n",
      "Training Epoch: [4]  [ 280/1229]  eta: 0:05:13  lr: 0.005000  loss: 0.5108 (0.4918)  loss_classifier: 0.1608 (0.1671)  loss_box_reg: 0.1414 (0.1505)  loss_objectness: 0.1072 (0.1222)  loss_rpn_box_reg: 0.0299 (0.0520)  time: 0.3182  data: 0.1375  max mem: 3973\n",
      "Training Epoch: [4]  [ 290/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.5219 (0.4943)  loss_classifier: 0.1895 (0.1684)  loss_box_reg: 0.1686 (0.1521)  loss_objectness: 0.1118 (0.1221)  loss_rpn_box_reg: 0.0279 (0.0517)  time: 0.3211  data: 0.1355  max mem: 3973\n",
      "Training Epoch: [4]  [ 300/1229]  eta: 0:05:06  lr: 0.005000  loss: 0.4012 (0.4913)  loss_classifier: 0.1599 (0.1677)  loss_box_reg: 0.1366 (0.1516)  loss_objectness: 0.0889 (0.1210)  loss_rpn_box_reg: 0.0279 (0.0511)  time: 0.3230  data: 0.1404  max mem: 3973\n",
      "Training Epoch: [4]  [ 310/1229]  eta: 0:05:03  lr: 0.005000  loss: 0.3336 (0.4918)  loss_classifier: 0.1353 (0.1679)  loss_box_reg: 0.1071 (0.1515)  loss_objectness: 0.0944 (0.1213)  loss_rpn_box_reg: 0.0306 (0.0512)  time: 0.3235  data: 0.1430  max mem: 3973\n",
      "Training Epoch: [4]  [ 320/1229]  eta: 0:04:59  lr: 0.005000  loss: 0.4190 (0.4929)  loss_classifier: 0.1512 (0.1684)  loss_box_reg: 0.0897 (0.1515)  loss_objectness: 0.1220 (0.1219)  loss_rpn_box_reg: 0.0268 (0.0511)  time: 0.3242  data: 0.1420  max mem: 3973\n",
      "Training Epoch: [4]  [ 330/1229]  eta: 0:04:56  lr: 0.005000  loss: 0.4699 (0.4913)  loss_classifier: 0.1657 (0.1683)  loss_box_reg: 0.0897 (0.1506)  loss_objectness: 0.1188 (0.1215)  loss_rpn_box_reg: 0.0257 (0.0509)  time: 0.3286  data: 0.1407  max mem: 3973\n",
      "Training Epoch: [4]  [ 340/1229]  eta: 0:04:53  lr: 0.005000  loss: 0.3973 (0.4911)  loss_classifier: 0.1520 (0.1683)  loss_box_reg: 0.0910 (0.1500)  loss_objectness: 0.0925 (0.1218)  loss_rpn_box_reg: 0.0257 (0.0510)  time: 0.3315  data: 0.1403  max mem: 3973\n",
      "Training Epoch: [4]  [ 350/1229]  eta: 0:04:49  lr: 0.005000  loss: 0.3886 (0.4880)  loss_classifier: 0.1463 (0.1675)  loss_box_reg: 0.1072 (0.1495)  loss_objectness: 0.0863 (0.1209)  loss_rpn_box_reg: 0.0223 (0.0501)  time: 0.3230  data: 0.1436  max mem: 3973\n",
      "Training Epoch: [4]  [ 360/1229]  eta: 0:04:46  lr: 0.005000  loss: 0.4145 (0.4874)  loss_classifier: 0.1529 (0.1676)  loss_box_reg: 0.1122 (0.1496)  loss_objectness: 0.1026 (0.1203)  loss_rpn_box_reg: 0.0257 (0.0499)  time: 0.3202  data: 0.1453  max mem: 3973\n",
      "Training Epoch: [4]  [ 370/1229]  eta: 0:04:42  lr: 0.005000  loss: 0.4474 (0.4882)  loss_classifier: 0.1599 (0.1678)  loss_box_reg: 0.1122 (0.1497)  loss_objectness: 0.1115 (0.1203)  loss_rpn_box_reg: 0.0296 (0.0503)  time: 0.3245  data: 0.1425  max mem: 3973\n",
      "Training Epoch: [4]  [ 380/1229]  eta: 0:04:39  lr: 0.005000  loss: 0.4824 (0.4905)  loss_classifier: 0.1732 (0.1688)  loss_box_reg: 0.1555 (0.1508)  loss_objectness: 0.1136 (0.1202)  loss_rpn_box_reg: 0.0417 (0.0507)  time: 0.3271  data: 0.1405  max mem: 3973\n",
      "Training Epoch: [4]  [ 390/1229]  eta: 0:04:36  lr: 0.005000  loss: 0.4719 (0.4880)  loss_classifier: 0.1607 (0.1678)  loss_box_reg: 0.1067 (0.1497)  loss_objectness: 0.1127 (0.1200)  loss_rpn_box_reg: 0.0382 (0.0506)  time: 0.3358  data: 0.1440  max mem: 3973\n",
      "Training Epoch: [4]  [ 400/1229]  eta: 0:04:33  lr: 0.005000  loss: 0.3445 (0.4868)  loss_classifier: 0.1254 (0.1675)  loss_box_reg: 0.1067 (0.1496)  loss_objectness: 0.0911 (0.1195)  loss_rpn_box_reg: 0.0257 (0.0501)  time: 0.3458  data: 0.1493  max mem: 3973\n",
      "Training Epoch: [4]  [ 410/1229]  eta: 0:04:30  lr: 0.005000  loss: 0.3652 (0.4889)  loss_classifier: 0.1333 (0.1679)  loss_box_reg: 0.1150 (0.1502)  loss_objectness: 0.0911 (0.1199)  loss_rpn_box_reg: 0.0276 (0.0509)  time: 0.3445  data: 0.1509  max mem: 3973\n",
      "Training Epoch: [4]  [ 420/1229]  eta: 0:04:27  lr: 0.005000  loss: 0.4845 (0.4912)  loss_classifier: 0.1476 (0.1683)  loss_box_reg: 0.1150 (0.1507)  loss_objectness: 0.1135 (0.1201)  loss_rpn_box_reg: 0.0311 (0.0521)  time: 0.3318  data: 0.1497  max mem: 3973\n",
      "Training Epoch: [4]  [ 430/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.3763 (0.4901)  loss_classifier: 0.1281 (0.1677)  loss_box_reg: 0.1035 (0.1502)  loss_objectness: 0.1102 (0.1202)  loss_rpn_box_reg: 0.0339 (0.0520)  time: 0.3191  data: 0.1470  max mem: 3973\n",
      "Training Epoch: [4]  [ 440/1229]  eta: 0:04:20  lr: 0.005000  loss: 0.3145 (0.4898)  loss_classifier: 0.1248 (0.1678)  loss_box_reg: 0.1014 (0.1499)  loss_objectness: 0.1015 (0.1204)  loss_rpn_box_reg: 0.0257 (0.0516)  time: 0.3189  data: 0.1433  max mem: 3973\n",
      "Training Epoch: [4]  [ 450/1229]  eta: 0:04:16  lr: 0.005000  loss: 0.4095 (0.4889)  loss_classifier: 0.1394 (0.1676)  loss_box_reg: 0.0952 (0.1497)  loss_objectness: 0.1015 (0.1201)  loss_rpn_box_reg: 0.0239 (0.0514)  time: 0.3262  data: 0.1412  max mem: 3973\n",
      "Training Epoch: [4]  [ 460/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.4485 (0.4876)  loss_classifier: 0.1394 (0.1670)  loss_box_reg: 0.1257 (0.1497)  loss_objectness: 0.0862 (0.1196)  loss_rpn_box_reg: 0.0235 (0.0512)  time: 0.3278  data: 0.1404  max mem: 3973\n",
      "Training Epoch: [4]  [ 470/1229]  eta: 0:04:10  lr: 0.005000  loss: 0.4675 (0.4903)  loss_classifier: 0.1677 (0.1674)  loss_box_reg: 0.1474 (0.1501)  loss_objectness: 0.1139 (0.1212)  loss_rpn_box_reg: 0.0334 (0.0516)  time: 0.3266  data: 0.1390  max mem: 3973\n",
      "Training Epoch: [4]  [ 480/1229]  eta: 0:04:06  lr: 0.005000  loss: 0.5464 (0.4927)  loss_classifier: 0.1677 (0.1682)  loss_box_reg: 0.1598 (0.1511)  loss_objectness: 0.1710 (0.1222)  loss_rpn_box_reg: 0.0379 (0.0512)  time: 0.3234  data: 0.1382  max mem: 3973\n",
      "Training Epoch: [4]  [ 490/1229]  eta: 0:04:03  lr: 0.005000  loss: 0.4780 (0.4955)  loss_classifier: 0.1659 (0.1694)  loss_box_reg: 0.1489 (0.1519)  loss_objectness: 0.1466 (0.1230)  loss_rpn_box_reg: 0.0417 (0.0513)  time: 0.3228  data: 0.1403  max mem: 3973\n",
      "Training Epoch: [4]  [ 500/1229]  eta: 0:04:00  lr: 0.005000  loss: 0.4424 (0.4949)  loss_classifier: 0.1611 (0.1692)  loss_box_reg: 0.1295 (0.1518)  loss_objectness: 0.1090 (0.1226)  loss_rpn_box_reg: 0.0286 (0.0513)  time: 0.3259  data: 0.1434  max mem: 3973\n",
      "Training Epoch: [4]  [ 510/1229]  eta: 0:03:56  lr: 0.005000  loss: 0.3596 (0.4945)  loss_classifier: 0.1356 (0.1692)  loss_box_reg: 0.1331 (0.1518)  loss_objectness: 0.0926 (0.1227)  loss_rpn_box_reg: 0.0207 (0.0509)  time: 0.3233  data: 0.1430  max mem: 3973\n",
      "Training Epoch: [4]  [ 520/1229]  eta: 0:03:53  lr: 0.005000  loss: 0.3486 (0.4902)  loss_classifier: 0.1192 (0.1676)  loss_box_reg: 0.0873 (0.1501)  loss_objectness: 0.0931 (0.1222)  loss_rpn_box_reg: 0.0182 (0.0504)  time: 0.3209  data: 0.1396  max mem: 3973\n",
      "Training Epoch: [4]  [ 530/1229]  eta: 0:03:49  lr: 0.005000  loss: 0.3879 (0.4903)  loss_classifier: 0.1261 (0.1676)  loss_box_reg: 0.1224 (0.1503)  loss_objectness: 0.0931 (0.1221)  loss_rpn_box_reg: 0.0235 (0.0504)  time: 0.3235  data: 0.1394  max mem: 3973\n",
      "Training Epoch: [4]  [ 540/1229]  eta: 0:03:46  lr: 0.005000  loss: 0.4417 (0.4904)  loss_classifier: 0.1575 (0.1676)  loss_box_reg: 0.1589 (0.1501)  loss_objectness: 0.1294 (0.1222)  loss_rpn_box_reg: 0.0456 (0.0506)  time: 0.3262  data: 0.1412  max mem: 3973\n",
      "Training Epoch: [4]  [ 550/1229]  eta: 0:03:43  lr: 0.005000  loss: 0.4071 (0.4894)  loss_classifier: 0.1381 (0.1673)  loss_box_reg: 0.0992 (0.1493)  loss_objectness: 0.1138 (0.1223)  loss_rpn_box_reg: 0.0365 (0.0505)  time: 0.3255  data: 0.1411  max mem: 3973\n",
      "Training Epoch: [4]  [ 560/1229]  eta: 0:03:39  lr: 0.005000  loss: 0.4071 (0.4901)  loss_classifier: 0.1454 (0.1677)  loss_box_reg: 0.1046 (0.1493)  loss_objectness: 0.1022 (0.1224)  loss_rpn_box_reg: 0.0369 (0.0507)  time: 0.3265  data: 0.1424  max mem: 3973\n",
      "Training Epoch: [4]  [ 570/1229]  eta: 0:03:36  lr: 0.005000  loss: 0.4825 (0.4908)  loss_classifier: 0.1752 (0.1682)  loss_box_reg: 0.1338 (0.1496)  loss_objectness: 0.1094 (0.1223)  loss_rpn_box_reg: 0.0369 (0.0507)  time: 0.3304  data: 0.1415  max mem: 3973\n",
      "Training Epoch: [4]  [ 580/1229]  eta: 0:03:33  lr: 0.005000  loss: 0.4112 (0.4899)  loss_classifier: 0.1742 (0.1679)  loss_box_reg: 0.1126 (0.1489)  loss_objectness: 0.1201 (0.1226)  loss_rpn_box_reg: 0.0279 (0.0506)  time: 0.3271  data: 0.1392  max mem: 3973\n",
      "Training Epoch: [4]  [ 590/1229]  eta: 0:03:29  lr: 0.005000  loss: 0.3968 (0.4895)  loss_classifier: 0.1416 (0.1679)  loss_box_reg: 0.1061 (0.1489)  loss_objectness: 0.1089 (0.1224)  loss_rpn_box_reg: 0.0252 (0.0503)  time: 0.3196  data: 0.1409  max mem: 3973\n",
      "Training Epoch: [4]  [ 600/1229]  eta: 0:03:26  lr: 0.005000  loss: 0.3968 (0.4880)  loss_classifier: 0.1139 (0.1674)  loss_box_reg: 0.1061 (0.1482)  loss_objectness: 0.1023 (0.1222)  loss_rpn_box_reg: 0.0197 (0.0501)  time: 0.3213  data: 0.1401  max mem: 3973\n",
      "Training Epoch: [4]  [ 610/1229]  eta: 0:03:23  lr: 0.005000  loss: 0.5223 (0.4896)  loss_classifier: 0.1722 (0.1681)  loss_box_reg: 0.1825 (0.1492)  loss_objectness: 0.1031 (0.1223)  loss_rpn_box_reg: 0.0214 (0.0500)  time: 0.3270  data: 0.1397  max mem: 3973\n",
      "Training Epoch: [4]  [ 620/1229]  eta: 0:03:20  lr: 0.005000  loss: 0.5379 (0.4900)  loss_classifier: 0.1926 (0.1681)  loss_box_reg: 0.1165 (0.1492)  loss_objectness: 0.1148 (0.1226)  loss_rpn_box_reg: 0.0256 (0.0501)  time: 0.3303  data: 0.1407  max mem: 3973\n",
      "Training Epoch: [4]  [ 630/1229]  eta: 0:03:16  lr: 0.005000  loss: 0.3082 (0.4888)  loss_classifier: 0.1149 (0.1678)  loss_box_reg: 0.0862 (0.1487)  loss_objectness: 0.1100 (0.1224)  loss_rpn_box_reg: 0.0256 (0.0499)  time: 0.3283  data: 0.1436  max mem: 3973\n",
      "Training Epoch: [4]  [ 640/1229]  eta: 0:03:13  lr: 0.005000  loss: 0.3692 (0.4892)  loss_classifier: 0.1268 (0.1680)  loss_box_reg: 0.1041 (0.1486)  loss_objectness: 0.0930 (0.1224)  loss_rpn_box_reg: 0.0260 (0.0502)  time: 0.3305  data: 0.1449  max mem: 3973\n",
      "Training Epoch: [4]  [ 650/1229]  eta: 0:03:10  lr: 0.005000  loss: 0.4164 (0.4887)  loss_classifier: 0.1369 (0.1680)  loss_box_reg: 0.1103 (0.1482)  loss_objectness: 0.0945 (0.1223)  loss_rpn_box_reg: 0.0358 (0.0503)  time: 0.3372  data: 0.1432  max mem: 3973\n",
      "Training Epoch: [4]  [ 660/1229]  eta: 0:03:06  lr: 0.005000  loss: 0.4741 (0.4901)  loss_classifier: 0.1490 (0.1684)  loss_box_reg: 0.1145 (0.1487)  loss_objectness: 0.1066 (0.1227)  loss_rpn_box_reg: 0.0381 (0.0503)  time: 0.3288  data: 0.1430  max mem: 3973\n",
      "Training Epoch: [4]  [ 670/1229]  eta: 0:03:03  lr: 0.005000  loss: 0.5613 (0.4917)  loss_classifier: 0.1853 (0.1691)  loss_box_reg: 0.1592 (0.1491)  loss_objectness: 0.1185 (0.1228)  loss_rpn_box_reg: 0.0432 (0.0506)  time: 0.3225  data: 0.1427  max mem: 3973\n",
      "Training Epoch: [4]  [ 680/1229]  eta: 0:03:00  lr: 0.005000  loss: 0.4762 (0.4927)  loss_classifier: 0.1636 (0.1690)  loss_box_reg: 0.1134 (0.1490)  loss_objectness: 0.1322 (0.1236)  loss_rpn_box_reg: 0.0530 (0.0512)  time: 0.3244  data: 0.1424  max mem: 3973\n",
      "Training Epoch: [4]  [ 690/1229]  eta: 0:02:57  lr: 0.005000  loss: 0.3905 (0.4905)  loss_classifier: 0.1295 (0.1684)  loss_box_reg: 0.0845 (0.1481)  loss_objectness: 0.1120 (0.1231)  loss_rpn_box_reg: 0.0332 (0.0508)  time: 0.3248  data: 0.1402  max mem: 3973\n",
      "Training Epoch: [4]  [ 700/1229]  eta: 0:02:53  lr: 0.005000  loss: 0.3609 (0.4908)  loss_classifier: 0.1431 (0.1684)  loss_box_reg: 0.0944 (0.1481)  loss_objectness: 0.0984 (0.1231)  loss_rpn_box_reg: 0.0296 (0.0512)  time: 0.3249  data: 0.1408  max mem: 3973\n",
      "Training Epoch: [4]  [ 710/1229]  eta: 0:02:50  lr: 0.005000  loss: 0.4259 (0.4898)  loss_classifier: 0.1524 (0.1680)  loss_box_reg: 0.1199 (0.1479)  loss_objectness: 0.1089 (0.1230)  loss_rpn_box_reg: 0.0296 (0.0509)  time: 0.3251  data: 0.1410  max mem: 3973\n",
      "Training Epoch: [4]  [ 720/1229]  eta: 0:02:47  lr: 0.005000  loss: 0.4293 (0.4898)  loss_classifier: 0.1524 (0.1681)  loss_box_reg: 0.1469 (0.1480)  loss_objectness: 0.1088 (0.1231)  loss_rpn_box_reg: 0.0211 (0.0506)  time: 0.3319  data: 0.1436  max mem: 3973\n",
      "Training Epoch: [4]  [ 730/1229]  eta: 0:02:43  lr: 0.005000  loss: 0.4216 (0.4887)  loss_classifier: 0.1278 (0.1677)  loss_box_reg: 0.1272 (0.1477)  loss_objectness: 0.0918 (0.1226)  loss_rpn_box_reg: 0.0184 (0.0506)  time: 0.3371  data: 0.1464  max mem: 3973\n",
      "Training Epoch: [4]  [ 740/1229]  eta: 0:02:40  lr: 0.005000  loss: 0.3409 (0.4885)  loss_classifier: 0.1167 (0.1676)  loss_box_reg: 0.1010 (0.1476)  loss_objectness: 0.0989 (0.1228)  loss_rpn_box_reg: 0.0292 (0.0505)  time: 0.3310  data: 0.1434  max mem: 3973\n",
      "Training Epoch: [4]  [ 750/1229]  eta: 0:02:37  lr: 0.005000  loss: 0.4311 (0.4888)  loss_classifier: 0.1435 (0.1678)  loss_box_reg: 0.1010 (0.1476)  loss_objectness: 0.1228 (0.1230)  loss_rpn_box_reg: 0.0322 (0.0504)  time: 0.3227  data: 0.1429  max mem: 3973\n",
      "Training Epoch: [4]  [ 760/1229]  eta: 0:02:34  lr: 0.005000  loss: 0.4531 (0.4897)  loss_classifier: 0.1625 (0.1679)  loss_box_reg: 0.1154 (0.1478)  loss_objectness: 0.1238 (0.1234)  loss_rpn_box_reg: 0.0260 (0.0505)  time: 0.3259  data: 0.1436  max mem: 3973\n",
      "Training Epoch: [4]  [ 770/1229]  eta: 0:02:30  lr: 0.005000  loss: 0.4531 (0.4896)  loss_classifier: 0.1452 (0.1679)  loss_box_reg: 0.1102 (0.1478)  loss_objectness: 0.1133 (0.1234)  loss_rpn_box_reg: 0.0437 (0.0504)  time: 0.3284  data: 0.1410  max mem: 3973\n",
      "Training Epoch: [4]  [ 780/1229]  eta: 0:02:27  lr: 0.005000  loss: 0.4990 (0.4915)  loss_classifier: 0.1847 (0.1686)  loss_box_reg: 0.1247 (0.1485)  loss_objectness: 0.1175 (0.1236)  loss_rpn_box_reg: 0.0522 (0.0508)  time: 0.3318  data: 0.1431  max mem: 3973\n",
      "Training Epoch: [4]  [ 790/1229]  eta: 0:02:24  lr: 0.005000  loss: 0.4666 (0.4907)  loss_classifier: 0.1299 (0.1682)  loss_box_reg: 0.1247 (0.1480)  loss_objectness: 0.1362 (0.1238)  loss_rpn_box_reg: 0.0419 (0.0508)  time: 0.3366  data: 0.1437  max mem: 3973\n",
      "Training Epoch: [4]  [ 800/1229]  eta: 0:02:20  lr: 0.005000  loss: 0.4221 (0.4911)  loss_classifier: 0.1419 (0.1683)  loss_box_reg: 0.1234 (0.1483)  loss_objectness: 0.1050 (0.1238)  loss_rpn_box_reg: 0.0242 (0.0507)  time: 0.3308  data: 0.1420  max mem: 3973\n",
      "Training Epoch: [4]  [ 810/1229]  eta: 0:02:17  lr: 0.005000  loss: 0.4695 (0.4911)  loss_classifier: 0.1569 (0.1682)  loss_box_reg: 0.1571 (0.1486)  loss_objectness: 0.0978 (0.1237)  loss_rpn_box_reg: 0.0242 (0.0506)  time: 0.3263  data: 0.1443  max mem: 3973\n",
      "Training Epoch: [4]  [ 820/1229]  eta: 0:02:14  lr: 0.005000  loss: 0.4695 (0.4917)  loss_classifier: 0.1510 (0.1684)  loss_box_reg: 0.1092 (0.1483)  loss_objectness: 0.1036 (0.1241)  loss_rpn_box_reg: 0.0206 (0.0509)  time: 0.3221  data: 0.1439  max mem: 3973\n",
      "Training Epoch: [4]  [ 830/1229]  eta: 0:02:11  lr: 0.005000  loss: 0.4565 (0.4915)  loss_classifier: 0.1537 (0.1683)  loss_box_reg: 0.1278 (0.1482)  loss_objectness: 0.1353 (0.1242)  loss_rpn_box_reg: 0.0331 (0.0508)  time: 0.3193  data: 0.1444  max mem: 3973\n",
      "Training Epoch: [4]  [ 840/1229]  eta: 0:02:07  lr: 0.005000  loss: 0.5375 (0.4932)  loss_classifier: 0.2004 (0.1692)  loss_box_reg: 0.1688 (0.1492)  loss_objectness: 0.1313 (0.1241)  loss_rpn_box_reg: 0.0333 (0.0507)  time: 0.3181  data: 0.1440  max mem: 3973\n",
      "Training Epoch: [4]  [ 850/1229]  eta: 0:02:04  lr: 0.005000  loss: 0.5375 (0.4922)  loss_classifier: 0.1838 (0.1687)  loss_box_reg: 0.1684 (0.1486)  loss_objectness: 0.1064 (0.1241)  loss_rpn_box_reg: 0.0310 (0.0508)  time: 0.3184  data: 0.1424  max mem: 3973\n",
      "Training Epoch: [4]  [ 860/1229]  eta: 0:02:01  lr: 0.005000  loss: 0.2891 (0.4911)  loss_classifier: 0.1018 (0.1683)  loss_box_reg: 0.0918 (0.1482)  loss_objectness: 0.0990 (0.1240)  loss_rpn_box_reg: 0.0276 (0.0506)  time: 0.3224  data: 0.1407  max mem: 3973\n",
      "Training Epoch: [4]  [ 870/1229]  eta: 0:01:57  lr: 0.005000  loss: 0.3889 (0.4904)  loss_classifier: 0.1312 (0.1680)  loss_box_reg: 0.0866 (0.1477)  loss_objectness: 0.1092 (0.1240)  loss_rpn_box_reg: 0.0309 (0.0506)  time: 0.3225  data: 0.1412  max mem: 3973\n",
      "Training Epoch: [4]  [ 880/1229]  eta: 0:01:54  lr: 0.005000  loss: 0.3981 (0.4901)  loss_classifier: 0.1321 (0.1678)  loss_box_reg: 0.0960 (0.1476)  loss_objectness: 0.0997 (0.1238)  loss_rpn_box_reg: 0.0456 (0.0509)  time: 0.3264  data: 0.1425  max mem: 3973\n",
      "Training Epoch: [4]  [ 890/1229]  eta: 0:01:51  lr: 0.005000  loss: 0.3981 (0.4893)  loss_classifier: 0.1400 (0.1675)  loss_box_reg: 0.1186 (0.1475)  loss_objectness: 0.0872 (0.1236)  loss_rpn_box_reg: 0.0207 (0.0507)  time: 0.3294  data: 0.1412  max mem: 3973\n",
      "Training Epoch: [4]  [ 900/1229]  eta: 0:01:47  lr: 0.005000  loss: 0.4072 (0.4889)  loss_classifier: 0.1426 (0.1674)  loss_box_reg: 0.1138 (0.1472)  loss_objectness: 0.1092 (0.1237)  loss_rpn_box_reg: 0.0200 (0.0506)  time: 0.3278  data: 0.1433  max mem: 3973\n",
      "Training Epoch: [4]  [ 910/1229]  eta: 0:01:44  lr: 0.005000  loss: 0.3913 (0.4876)  loss_classifier: 0.1306 (0.1669)  loss_box_reg: 0.0744 (0.1467)  loss_objectness: 0.1133 (0.1236)  loss_rpn_box_reg: 0.0209 (0.0504)  time: 0.3229  data: 0.1431  max mem: 3973\n",
      "Training Epoch: [4]  [ 920/1229]  eta: 0:01:41  lr: 0.005000  loss: 0.3729 (0.4867)  loss_classifier: 0.1253 (0.1666)  loss_box_reg: 0.1036 (0.1462)  loss_objectness: 0.1027 (0.1236)  loss_rpn_box_reg: 0.0222 (0.0502)  time: 0.3184  data: 0.1411  max mem: 3973\n",
      "Training Epoch: [4]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.4327 (0.4857)  loss_classifier: 0.1439 (0.1663)  loss_box_reg: 0.1036 (0.1459)  loss_objectness: 0.1027 (0.1233)  loss_rpn_box_reg: 0.0222 (0.0502)  time: 0.3202  data: 0.1424  max mem: 3973\n",
      "Training Epoch: [4]  [ 940/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.4713 (0.4868)  loss_classifier: 0.1524 (0.1668)  loss_box_reg: 0.1260 (0.1463)  loss_objectness: 0.0835 (0.1233)  loss_rpn_box_reg: 0.0326 (0.0505)  time: 0.3295  data: 0.1431  max mem: 3973\n",
      "Training Epoch: [4]  [ 950/1229]  eta: 0:01:31  lr: 0.005000  loss: 0.4521 (0.4868)  loss_classifier: 0.1524 (0.1668)  loss_box_reg: 0.1139 (0.1461)  loss_objectness: 0.1060 (0.1234)  loss_rpn_box_reg: 0.0285 (0.0505)  time: 0.3293  data: 0.1426  max mem: 3973\n",
      "Training Epoch: [4]  [ 960/1229]  eta: 0:01:28  lr: 0.005000  loss: 0.3485 (0.4868)  loss_classifier: 0.1167 (0.1666)  loss_box_reg: 0.0839 (0.1460)  loss_objectness: 0.1129 (0.1235)  loss_rpn_box_reg: 0.0217 (0.0507)  time: 0.3219  data: 0.1412  max mem: 3973\n",
      "Training Epoch: [4]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.3360 (0.4861)  loss_classifier: 0.1241 (0.1664)  loss_box_reg: 0.0984 (0.1457)  loss_objectness: 0.0973 (0.1237)  loss_rpn_box_reg: 0.0244 (0.0505)  time: 0.3257  data: 0.1409  max mem: 3973\n",
      "Training Epoch: [4]  [ 980/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.3047 (0.4851)  loss_classifier: 0.1247 (0.1662)  loss_box_reg: 0.0984 (0.1454)  loss_objectness: 0.0786 (0.1232)  loss_rpn_box_reg: 0.0174 (0.0502)  time: 0.3228  data: 0.1415  max mem: 3973\n",
      "Training Epoch: [4]  [ 990/1229]  eta: 0:01:18  lr: 0.005000  loss: 0.3845 (0.4852)  loss_classifier: 0.1289 (0.1660)  loss_box_reg: 0.1120 (0.1454)  loss_objectness: 0.0818 (0.1235)  loss_rpn_box_reg: 0.0316 (0.0504)  time: 0.3180  data: 0.1412  max mem: 3973\n",
      "Training Epoch: [4]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.4428 (0.4860)  loss_classifier: 0.1378 (0.1664)  loss_box_reg: 0.1377 (0.1461)  loss_objectness: 0.0988 (0.1233)  loss_rpn_box_reg: 0.0419 (0.0502)  time: 0.3171  data: 0.1418  max mem: 3973\n",
      "Training Epoch: [4]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.4428 (0.4854)  loss_classifier: 0.1378 (0.1662)  loss_box_reg: 0.1458 (0.1460)  loss_objectness: 0.0982 (0.1232)  loss_rpn_box_reg: 0.0213 (0.0499)  time: 0.3190  data: 0.1425  max mem: 3973\n",
      "Training Epoch: [4]  [1020/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.4324 (0.4857)  loss_classifier: 0.1659 (0.1664)  loss_box_reg: 0.1347 (0.1462)  loss_objectness: 0.1062 (0.1232)  loss_rpn_box_reg: 0.0314 (0.0499)  time: 0.3241  data: 0.1438  max mem: 3973\n",
      "Training Epoch: [4]  [1030/1229]  eta: 0:01:05  lr: 0.005000  loss: 0.5483 (0.4870)  loss_classifier: 0.1808 (0.1666)  loss_box_reg: 0.1527 (0.1465)  loss_objectness: 0.1292 (0.1236)  loss_rpn_box_reg: 0.0452 (0.0503)  time: 0.3309  data: 0.1450  max mem: 3973\n",
      "Training Epoch: [4]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.4620 (0.4862)  loss_classifier: 0.1383 (0.1663)  loss_box_reg: 0.1048 (0.1462)  loss_objectness: 0.1284 (0.1235)  loss_rpn_box_reg: 0.0386 (0.0502)  time: 0.3278  data: 0.1428  max mem: 3973\n",
      "Training Epoch: [4]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.3900 (0.4864)  loss_classifier: 0.1342 (0.1664)  loss_box_reg: 0.1048 (0.1463)  loss_objectness: 0.1063 (0.1236)  loss_rpn_box_reg: 0.0231 (0.0501)  time: 0.3258  data: 0.1392  max mem: 3973\n",
      "Training Epoch: [4]  [1060/1229]  eta: 0:00:55  lr: 0.005000  loss: 0.4232 (0.4862)  loss_classifier: 0.1458 (0.1663)  loss_box_reg: 0.1474 (0.1462)  loss_objectness: 0.1073 (0.1236)  loss_rpn_box_reg: 0.0223 (0.0501)  time: 0.3304  data: 0.1405  max mem: 3973\n",
      "Training Epoch: [4]  [1070/1229]  eta: 0:00:52  lr: 0.005000  loss: 0.4702 (0.4873)  loss_classifier: 0.1480 (0.1666)  loss_box_reg: 0.1283 (0.1465)  loss_objectness: 0.1271 (0.1240)  loss_rpn_box_reg: 0.0336 (0.0502)  time: 0.3203  data: 0.1415  max mem: 3973\n",
      "Training Epoch: [4]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.4713 (0.4871)  loss_classifier: 0.1570 (0.1665)  loss_box_reg: 0.1201 (0.1464)  loss_objectness: 0.1230 (0.1240)  loss_rpn_box_reg: 0.0336 (0.0501)  time: 0.3158  data: 0.1411  max mem: 3973\n",
      "Training Epoch: [4]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.4178 (0.4869)  loss_classifier: 0.1422 (0.1665)  loss_box_reg: 0.1350 (0.1464)  loss_objectness: 0.1230 (0.1241)  loss_rpn_box_reg: 0.0267 (0.0499)  time: 0.3230  data: 0.1419  max mem: 3973\n",
      "Training Epoch: [4]  [1100/1229]  eta: 0:00:42  lr: 0.005000  loss: 0.4178 (0.4874)  loss_classifier: 0.1609 (0.1667)  loss_box_reg: 0.1378 (0.1466)  loss_objectness: 0.1107 (0.1240)  loss_rpn_box_reg: 0.0238 (0.0501)  time: 0.3292  data: 0.1384  max mem: 3973\n",
      "Training Epoch: [4]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.3934 (0.4867)  loss_classifier: 0.1372 (0.1664)  loss_box_reg: 0.1158 (0.1462)  loss_objectness: 0.1018 (0.1240)  loss_rpn_box_reg: 0.0221 (0.0502)  time: 0.3268  data: 0.1395  max mem: 3973\n",
      "Training Epoch: [4]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.3802 (0.4861)  loss_classifier: 0.1295 (0.1663)  loss_box_reg: 0.1012 (0.1461)  loss_objectness: 0.0934 (0.1237)  loss_rpn_box_reg: 0.0191 (0.0499)  time: 0.3267  data: 0.1419  max mem: 3973\n",
      "Training Epoch: [4]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.3758 (0.4851)  loss_classifier: 0.1312 (0.1659)  loss_box_reg: 0.1082 (0.1456)  loss_objectness: 0.1082 (0.1239)  loss_rpn_box_reg: 0.0180 (0.0498)  time: 0.3327  data: 0.1397  max mem: 3973\n",
      "Training Epoch: [4]  [1140/1229]  eta: 0:00:29  lr: 0.005000  loss: 0.4021 (0.4865)  loss_classifier: 0.1597 (0.1665)  loss_box_reg: 0.1082 (0.1461)  loss_objectness: 0.1301 (0.1240)  loss_rpn_box_reg: 0.0332 (0.0499)  time: 0.3316  data: 0.1414  max mem: 3973\n",
      "Training Epoch: [4]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.5836 (0.4867)  loss_classifier: 0.1816 (0.1665)  loss_box_reg: 0.1345 (0.1460)  loss_objectness: 0.1565 (0.1243)  loss_rpn_box_reg: 0.0413 (0.0500)  time: 0.3280  data: 0.1425  max mem: 3973\n",
      "Training Epoch: [4]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.4540 (0.4867)  loss_classifier: 0.1756 (0.1665)  loss_box_reg: 0.0999 (0.1460)  loss_objectness: 0.1228 (0.1242)  loss_rpn_box_reg: 0.0396 (0.0500)  time: 0.3262  data: 0.1410  max mem: 3973\n",
      "Training Epoch: [4]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.5188 (0.4888)  loss_classifier: 0.1793 (0.1672)  loss_box_reg: 0.1519 (0.1470)  loss_objectness: 0.1148 (0.1244)  loss_rpn_box_reg: 0.0410 (0.0502)  time: 0.3250  data: 0.1432  max mem: 3973\n",
      "Training Epoch: [4]  [1180/1229]  eta: 0:00:16  lr: 0.005000  loss: 0.5984 (0.4901)  loss_classifier: 0.2186 (0.1677)  loss_box_reg: 0.2024 (0.1475)  loss_objectness: 0.1284 (0.1246)  loss_rpn_box_reg: 0.0591 (0.0503)  time: 0.3244  data: 0.1424  max mem: 3973\n",
      "Training Epoch: [4]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.4919 (0.4892)  loss_classifier: 0.1709 (0.1673)  loss_box_reg: 0.1093 (0.1472)  loss_objectness: 0.1089 (0.1243)  loss_rpn_box_reg: 0.0247 (0.0503)  time: 0.3250  data: 0.1402  max mem: 3973\n",
      "Training Epoch: [4]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.3892 (0.4896)  loss_classifier: 0.1292 (0.1675)  loss_box_reg: 0.1138 (0.1473)  loss_objectness: 0.1043 (0.1245)  loss_rpn_box_reg: 0.0257 (0.0504)  time: 0.3261  data: 0.1417  max mem: 3973\n",
      "Training Epoch: [4]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.3892 (0.4891)  loss_classifier: 0.1357 (0.1673)  loss_box_reg: 0.1198 (0.1470)  loss_objectness: 0.1177 (0.1246)  loss_rpn_box_reg: 0.0275 (0.0503)  time: 0.3275  data: 0.1419  max mem: 3973\n",
      "Training Epoch: [4]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.3771 (0.4894)  loss_classifier: 0.1415 (0.1673)  loss_box_reg: 0.1269 (0.1470)  loss_objectness: 0.1123 (0.1246)  loss_rpn_box_reg: 0.0253 (0.0504)  time: 0.3271  data: 0.1413  max mem: 3973\n",
      "Training Epoch: [4]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4260 (0.4889)  loss_classifier: 0.1591 (0.1672)  loss_box_reg: 0.1269 (0.1469)  loss_objectness: 0.1101 (0.1246)  loss_rpn_box_reg: 0.0253 (0.0502)  time: 0.3274  data: 0.1433  max mem: 3973\n",
      "Training Epoch: [4] Total time: 0:06:42 (0.3273 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:05:59  model_time: 0.3180 (0.3180)  evaluator_time: 0.0020 (0.0020)  time: 1.1680  data: 0.0300  max mem: 3973\n",
      "Test:  [100/308]  eta: 0:00:34  model_time: 0.1050 (0.1114)  evaluator_time: 0.0050 (0.0066)  time: 0.1581  data: 0.0386  max mem: 3973\n",
      "Test:  [200/308]  eta: 0:00:17  model_time: 0.1130 (0.1106)  evaluator_time: 0.0030 (0.0062)  time: 0.1545  data: 0.0334  max mem: 3973\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0970 (0.1095)  evaluator_time: 0.0040 (0.0062)  time: 0.1470  data: 0.0378  max mem: 3973\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0990 (0.1093)  evaluator_time: 0.0030 (0.0062)  time: 0.1498  data: 0.0416  max mem: 3973\n",
      "Test: Total time: 0:00:48 (0.1576 s / it)\n",
      "Averaged stats: model_time: 0.0990 (0.1093)  evaluator_time: 0.0030 (0.0062)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.223\n",
      "Testing Epoch: [4]  [  0/308]  eta: 0:00:51  lr: 0.005000  loss: 0.1939 (0.1939)  loss_classifier: 0.0575 (0.0575)  loss_box_reg: 0.0523 (0.0523)  loss_objectness: 0.0649 (0.0649)  loss_rpn_box_reg: 0.0193 (0.0193)  time: 0.1660  data: 0.0290  max mem: 3973\n",
      "Testing Epoch: [4]  [100/308]  eta: 0:00:36  lr: 0.005000  loss: 0.3424 (0.5085)  loss_classifier: 0.1333 (0.1659)  loss_box_reg: 0.1055 (0.1613)  loss_objectness: 0.0959 (0.1177)  loss_rpn_box_reg: 0.0204 (0.0636)  time: 0.1803  data: 0.0428  max mem: 3973\n",
      "Testing Epoch: [4]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.4329 (0.4842)  loss_classifier: 0.1445 (0.1583)  loss_box_reg: 0.1321 (0.1515)  loss_objectness: 0.1054 (0.1127)  loss_rpn_box_reg: 0.0241 (0.0617)  time: 0.1802  data: 0.0355  max mem: 3973\n",
      "Testing Epoch: [4]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5100 (0.4863)  loss_classifier: 0.1876 (0.1593)  loss_box_reg: 0.1579 (0.1544)  loss_objectness: 0.1119 (0.1117)  loss_rpn_box_reg: 0.0329 (0.0608)  time: 0.1700  data: 0.0411  max mem: 4015\n",
      "Testing Epoch: [4]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.4948 (0.4859)  loss_classifier: 0.1737 (0.1594)  loss_box_reg: 0.1595 (0.1546)  loss_objectness: 0.1100 (0.1117)  loss_rpn_box_reg: 0.0286 (0.0602)  time: 0.1686  data: 0.0398  max mem: 4015\n",
      "Testing Epoch: [4] Total time: 0:00:54 (0.1769 s / it)\n",
      "Training Epoch: [5]  [   0/1229]  eta: 0:06:41  lr: 0.005000  loss: 0.5710 (0.5710)  loss_classifier: 0.1908 (0.1908)  loss_box_reg: 0.1025 (0.1025)  loss_objectness: 0.2275 (0.2275)  loss_rpn_box_reg: 0.0502 (0.0502)  time: 0.3270  data: 0.1400  max mem: 4015\n",
      "Training Epoch: [5]  [  10/1229]  eta: 0:06:43  lr: 0.005000  loss: 0.5710 (0.5762)  loss_classifier: 0.2035 (0.1988)  loss_box_reg: 0.1855 (0.1794)  loss_objectness: 0.0942 (0.1220)  loss_rpn_box_reg: 0.0452 (0.0760)  time: 0.3307  data: 0.1455  max mem: 4015\n",
      "Training Epoch: [5]  [  20/1229]  eta: 0:06:38  lr: 0.005000  loss: 0.4852 (0.5348)  loss_classifier: 0.2006 (0.1928)  loss_box_reg: 0.1339 (0.1687)  loss_objectness: 0.0911 (0.1172)  loss_rpn_box_reg: 0.0335 (0.0562)  time: 0.3301  data: 0.1445  max mem: 4015\n",
      "Training Epoch: [5]  [  30/1229]  eta: 0:06:34  lr: 0.005000  loss: 0.3976 (0.5294)  loss_classifier: 0.1296 (0.1879)  loss_box_reg: 0.1014 (0.1687)  loss_objectness: 0.0977 (0.1193)  loss_rpn_box_reg: 0.0280 (0.0535)  time: 0.3280  data: 0.1439  max mem: 4015\n",
      "Training Epoch: [5]  [  40/1229]  eta: 0:06:28  lr: 0.005000  loss: 0.4338 (0.5359)  loss_classifier: 0.1507 (0.1854)  loss_box_reg: 0.0843 (0.1662)  loss_objectness: 0.1281 (0.1288)  loss_rpn_box_reg: 0.0319 (0.0555)  time: 0.3236  data: 0.1429  max mem: 4015\n",
      "Training Epoch: [5]  [  50/1229]  eta: 0:06:25  lr: 0.005000  loss: 0.5027 (0.5359)  loss_classifier: 0.1861 (0.1884)  loss_box_reg: 0.1559 (0.1689)  loss_objectness: 0.1281 (0.1278)  loss_rpn_box_reg: 0.0319 (0.0509)  time: 0.3238  data: 0.1424  max mem: 4015\n",
      "Training Epoch: [5]  [  60/1229]  eta: 0:06:23  lr: 0.005000  loss: 0.5027 (0.5225)  loss_classifier: 0.1796 (0.1826)  loss_box_reg: 0.1792 (0.1685)  loss_objectness: 0.1091 (0.1221)  loss_rpn_box_reg: 0.0238 (0.0492)  time: 0.3294  data: 0.1413  max mem: 4015\n",
      "Training Epoch: [5]  [  70/1229]  eta: 0:06:19  lr: 0.005000  loss: 0.4449 (0.5180)  loss_classifier: 0.1584 (0.1819)  loss_box_reg: 0.1442 (0.1662)  loss_objectness: 0.0973 (0.1221)  loss_rpn_box_reg: 0.0289 (0.0477)  time: 0.3300  data: 0.1404  max mem: 4015\n",
      "Training Epoch: [5]  [  80/1229]  eta: 0:06:15  lr: 0.005000  loss: 0.5483 (0.5265)  loss_classifier: 0.1867 (0.1846)  loss_box_reg: 0.1442 (0.1676)  loss_objectness: 0.1399 (0.1245)  loss_rpn_box_reg: 0.0336 (0.0499)  time: 0.3245  data: 0.1430  max mem: 4015\n",
      "Training Epoch: [5]  [  90/1229]  eta: 0:06:12  lr: 0.005000  loss: 0.4352 (0.5160)  loss_classifier: 0.1547 (0.1807)  loss_box_reg: 0.1384 (0.1661)  loss_objectness: 0.0973 (0.1211)  loss_rpn_box_reg: 0.0266 (0.0481)  time: 0.3249  data: 0.1420  max mem: 4015\n",
      "Training Epoch: [5]  [ 100/1229]  eta: 0:06:08  lr: 0.005000  loss: 0.4352 (0.5197)  loss_classifier: 0.1231 (0.1801)  loss_box_reg: 0.1079 (0.1641)  loss_objectness: 0.0954 (0.1245)  loss_rpn_box_reg: 0.0267 (0.0510)  time: 0.3260  data: 0.1420  max mem: 4015\n",
      "Training Epoch: [5]  [ 110/1229]  eta: 0:06:05  lr: 0.005000  loss: 0.4978 (0.5111)  loss_classifier: 0.1274 (0.1773)  loss_box_reg: 0.1069 (0.1613)  loss_objectness: 0.1233 (0.1231)  loss_rpn_box_reg: 0.0267 (0.0494)  time: 0.3253  data: 0.1423  max mem: 4015\n",
      "Training Epoch: [5]  [ 120/1229]  eta: 0:06:01  lr: 0.005000  loss: 0.3519 (0.4959)  loss_classifier: 0.1118 (0.1716)  loss_box_reg: 0.1069 (0.1549)  loss_objectness: 0.0921 (0.1217)  loss_rpn_box_reg: 0.0169 (0.0477)  time: 0.3239  data: 0.1405  max mem: 4015\n",
      "Training Epoch: [5]  [ 130/1229]  eta: 0:05:58  lr: 0.005000  loss: 0.3877 (0.4978)  loss_classifier: 0.1233 (0.1722)  loss_box_reg: 0.1126 (0.1558)  loss_objectness: 0.0942 (0.1225)  loss_rpn_box_reg: 0.0242 (0.0472)  time: 0.3225  data: 0.1421  max mem: 4015\n",
      "Training Epoch: [5]  [ 140/1229]  eta: 0:05:55  lr: 0.005000  loss: 0.5426 (0.5041)  loss_classifier: 0.1973 (0.1732)  loss_box_reg: 0.1661 (0.1574)  loss_objectness: 0.1136 (0.1236)  loss_rpn_box_reg: 0.0288 (0.0499)  time: 0.3293  data: 0.1425  max mem: 4015\n",
      "Training Epoch: [5]  [ 150/1229]  eta: 0:05:52  lr: 0.005000  loss: 0.4266 (0.5006)  loss_classifier: 0.1499 (0.1722)  loss_box_reg: 0.1123 (0.1556)  loss_objectness: 0.1037 (0.1223)  loss_rpn_box_reg: 0.0297 (0.0505)  time: 0.3297  data: 0.1450  max mem: 4015\n",
      "Training Epoch: [5]  [ 160/1229]  eta: 0:05:49  lr: 0.005000  loss: 0.4266 (0.4979)  loss_classifier: 0.1431 (0.1712)  loss_box_reg: 0.1009 (0.1541)  loss_objectness: 0.1023 (0.1225)  loss_rpn_box_reg: 0.0297 (0.0501)  time: 0.3273  data: 0.1454  max mem: 4015\n",
      "Training Epoch: [5]  [ 170/1229]  eta: 0:05:46  lr: 0.005000  loss: 0.3725 (0.4881)  loss_classifier: 0.1301 (0.1684)  loss_box_reg: 0.0906 (0.1511)  loss_objectness: 0.0937 (0.1201)  loss_rpn_box_reg: 0.0247 (0.0486)  time: 0.3276  data: 0.1430  max mem: 4015\n",
      "Training Epoch: [5]  [ 180/1229]  eta: 0:05:43  lr: 0.005000  loss: 0.3725 (0.4887)  loss_classifier: 0.1301 (0.1689)  loss_box_reg: 0.1050 (0.1524)  loss_objectness: 0.0898 (0.1198)  loss_rpn_box_reg: 0.0177 (0.0476)  time: 0.3314  data: 0.1431  max mem: 4015\n",
      "Training Epoch: [5]  [ 190/1229]  eta: 0:05:39  lr: 0.005000  loss: 0.3502 (0.4808)  loss_classifier: 0.1208 (0.1667)  loss_box_reg: 0.0884 (0.1507)  loss_objectness: 0.0871 (0.1175)  loss_rpn_box_reg: 0.0162 (0.0459)  time: 0.3310  data: 0.1425  max mem: 4015\n",
      "Training Epoch: [5]  [ 200/1229]  eta: 0:05:36  lr: 0.005000  loss: 0.3166 (0.4764)  loss_classifier: 0.1018 (0.1642)  loss_box_reg: 0.0812 (0.1476)  loss_objectness: 0.0871 (0.1170)  loss_rpn_box_reg: 0.0142 (0.0476)  time: 0.3226  data: 0.1432  max mem: 4015\n",
      "Training Epoch: [5]  [ 210/1229]  eta: 0:05:33  lr: 0.005000  loss: 0.3654 (0.4749)  loss_classifier: 0.1074 (0.1634)  loss_box_reg: 0.0812 (0.1467)  loss_objectness: 0.0948 (0.1174)  loss_rpn_box_reg: 0.0339 (0.0475)  time: 0.3269  data: 0.1451  max mem: 4015\n",
      "Training Epoch: [5]  [ 220/1229]  eta: 0:05:29  lr: 0.005000  loss: 0.3451 (0.4748)  loss_classifier: 0.1388 (0.1635)  loss_box_reg: 0.1024 (0.1463)  loss_objectness: 0.0999 (0.1170)  loss_rpn_box_reg: 0.0333 (0.0481)  time: 0.3262  data: 0.1451  max mem: 4015\n",
      "Training Epoch: [5]  [ 230/1229]  eta: 0:05:26  lr: 0.005000  loss: 0.3393 (0.4702)  loss_classifier: 0.1388 (0.1616)  loss_box_reg: 0.1018 (0.1442)  loss_objectness: 0.0997 (0.1167)  loss_rpn_box_reg: 0.0279 (0.0477)  time: 0.3224  data: 0.1439  max mem: 4015\n",
      "Training Epoch: [5]  [ 240/1229]  eta: 0:05:23  lr: 0.005000  loss: 0.3882 (0.4703)  loss_classifier: 0.1389 (0.1614)  loss_box_reg: 0.0876 (0.1441)  loss_objectness: 0.1061 (0.1167)  loss_rpn_box_reg: 0.0279 (0.0481)  time: 0.3290  data: 0.1439  max mem: 4015\n",
      "Training Epoch: [5]  [ 250/1229]  eta: 0:05:20  lr: 0.005000  loss: 0.4767 (0.4733)  loss_classifier: 0.1575 (0.1624)  loss_box_reg: 0.1283 (0.1462)  loss_objectness: 0.1167 (0.1166)  loss_rpn_box_reg: 0.0255 (0.0481)  time: 0.3295  data: 0.1415  max mem: 4015\n",
      "Training Epoch: [5]  [ 260/1229]  eta: 0:05:16  lr: 0.005000  loss: 0.3768 (0.4695)  loss_classifier: 0.1385 (0.1615)  loss_box_reg: 0.1056 (0.1456)  loss_objectness: 0.0821 (0.1151)  loss_rpn_box_reg: 0.0197 (0.0473)  time: 0.3289  data: 0.1402  max mem: 4015\n",
      "Training Epoch: [5]  [ 270/1229]  eta: 0:05:13  lr: 0.005000  loss: 0.3633 (0.4692)  loss_classifier: 0.1351 (0.1616)  loss_box_reg: 0.1218 (0.1454)  loss_objectness: 0.0758 (0.1153)  loss_rpn_box_reg: 0.0219 (0.0469)  time: 0.3310  data: 0.1415  max mem: 4015\n",
      "Training Epoch: [5]  [ 280/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.3715 (0.4674)  loss_classifier: 0.1238 (0.1608)  loss_box_reg: 0.1188 (0.1442)  loss_objectness: 0.1112 (0.1156)  loss_rpn_box_reg: 0.0289 (0.0468)  time: 0.3264  data: 0.1420  max mem: 4015\n",
      "Training Epoch: [5]  [ 290/1229]  eta: 0:05:06  lr: 0.005000  loss: 0.3259 (0.4638)  loss_classifier: 0.1204 (0.1596)  loss_box_reg: 0.1011 (0.1425)  loss_objectness: 0.0950 (0.1153)  loss_rpn_box_reg: 0.0303 (0.0465)  time: 0.3191  data: 0.1419  max mem: 4015\n",
      "Training Epoch: [5]  [ 300/1229]  eta: 0:05:03  lr: 0.005000  loss: 0.3089 (0.4591)  loss_classifier: 0.1149 (0.1582)  loss_box_reg: 0.0953 (0.1410)  loss_objectness: 0.0767 (0.1141)  loss_rpn_box_reg: 0.0146 (0.0457)  time: 0.3248  data: 0.1411  max mem: 4015\n",
      "Training Epoch: [5]  [ 310/1229]  eta: 0:05:00  lr: 0.005000  loss: 0.3675 (0.4608)  loss_classifier: 0.1188 (0.1586)  loss_box_reg: 0.1110 (0.1424)  loss_objectness: 0.0645 (0.1138)  loss_rpn_box_reg: 0.0283 (0.0460)  time: 0.3227  data: 0.1402  max mem: 4015\n",
      "Training Epoch: [5]  [ 320/1229]  eta: 0:04:56  lr: 0.005000  loss: 0.4298 (0.4609)  loss_classifier: 0.1501 (0.1585)  loss_box_reg: 0.1124 (0.1414)  loss_objectness: 0.0914 (0.1148)  loss_rpn_box_reg: 0.0491 (0.0462)  time: 0.3191  data: 0.1432  max mem: 4015\n",
      "Training Epoch: [5]  [ 330/1229]  eta: 0:04:53  lr: 0.005000  loss: 0.4650 (0.4651)  loss_classifier: 0.1586 (0.1592)  loss_box_reg: 0.1282 (0.1428)  loss_objectness: 0.1295 (0.1156)  loss_rpn_box_reg: 0.0329 (0.0474)  time: 0.3225  data: 0.1463  max mem: 4015\n",
      "Training Epoch: [5]  [ 340/1229]  eta: 0:04:49  lr: 0.005000  loss: 0.4774 (0.4659)  loss_classifier: 0.1546 (0.1593)  loss_box_reg: 0.1356 (0.1430)  loss_objectness: 0.1144 (0.1158)  loss_rpn_box_reg: 0.0329 (0.0477)  time: 0.3199  data: 0.1444  max mem: 4015\n",
      "Training Epoch: [5]  [ 350/1229]  eta: 0:04:46  lr: 0.005000  loss: 0.5014 (0.4675)  loss_classifier: 0.1551 (0.1602)  loss_box_reg: 0.1152 (0.1435)  loss_objectness: 0.1114 (0.1161)  loss_rpn_box_reg: 0.0323 (0.0476)  time: 0.3219  data: 0.1443  max mem: 4015\n",
      "Training Epoch: [5]  [ 360/1229]  eta: 0:04:43  lr: 0.005000  loss: 0.3460 (0.4636)  loss_classifier: 0.1304 (0.1589)  loss_box_reg: 0.0923 (0.1416)  loss_objectness: 0.0991 (0.1160)  loss_rpn_box_reg: 0.0226 (0.0470)  time: 0.3267  data: 0.1435  max mem: 4015\n",
      "Training Epoch: [5]  [ 370/1229]  eta: 0:04:39  lr: 0.005000  loss: 0.3360 (0.4648)  loss_classifier: 0.1263 (0.1594)  loss_box_reg: 0.0923 (0.1416)  loss_objectness: 0.0968 (0.1167)  loss_rpn_box_reg: 0.0235 (0.0471)  time: 0.3252  data: 0.1418  max mem: 4015\n",
      "Training Epoch: [5]  [ 380/1229]  eta: 0:04:36  lr: 0.005000  loss: 0.5145 (0.4687)  loss_classifier: 0.1825 (0.1607)  loss_box_reg: 0.1740 (0.1433)  loss_objectness: 0.1282 (0.1172)  loss_rpn_box_reg: 0.0498 (0.0475)  time: 0.3216  data: 0.1440  max mem: 4015\n",
      "Training Epoch: [5]  [ 390/1229]  eta: 0:04:33  lr: 0.005000  loss: 0.5616 (0.4690)  loss_classifier: 0.1825 (0.1607)  loss_box_reg: 0.1219 (0.1429)  loss_objectness: 0.1370 (0.1176)  loss_rpn_box_reg: 0.0498 (0.0477)  time: 0.3222  data: 0.1441  max mem: 4015\n",
      "Training Epoch: [5]  [ 400/1229]  eta: 0:04:30  lr: 0.005000  loss: 0.4670 (0.4710)  loss_classifier: 0.1664 (0.1616)  loss_box_reg: 0.1219 (0.1437)  loss_objectness: 0.1281 (0.1180)  loss_rpn_box_reg: 0.0454 (0.0478)  time: 0.3276  data: 0.1415  max mem: 4015\n",
      "Training Epoch: [5]  [ 410/1229]  eta: 0:04:26  lr: 0.005000  loss: 0.4467 (0.4687)  loss_classifier: 0.1413 (0.1610)  loss_box_reg: 0.1118 (0.1426)  loss_objectness: 0.1229 (0.1179)  loss_rpn_box_reg: 0.0324 (0.0473)  time: 0.3265  data: 0.1389  max mem: 4015\n",
      "Training Epoch: [5]  [ 420/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.3520 (0.4662)  loss_classifier: 0.1277 (0.1606)  loss_box_reg: 0.0965 (0.1418)  loss_objectness: 0.0786 (0.1171)  loss_rpn_box_reg: 0.0226 (0.0468)  time: 0.3210  data: 0.1378  max mem: 4015\n",
      "Training Epoch: [5]  [ 430/1229]  eta: 0:04:20  lr: 0.005000  loss: 0.3970 (0.4654)  loss_classifier: 0.1345 (0.1604)  loss_box_reg: 0.1240 (0.1422)  loss_objectness: 0.0786 (0.1165)  loss_rpn_box_reg: 0.0226 (0.0464)  time: 0.3211  data: 0.1392  max mem: 4015\n",
      "Training Epoch: [5]  [ 440/1229]  eta: 0:04:16  lr: 0.005000  loss: 0.4210 (0.4663)  loss_classifier: 0.1452 (0.1606)  loss_box_reg: 0.1315 (0.1425)  loss_objectness: 0.1033 (0.1170)  loss_rpn_box_reg: 0.0242 (0.0463)  time: 0.3211  data: 0.1413  max mem: 4015\n",
      "Training Epoch: [5]  [ 450/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.3600 (0.4654)  loss_classifier: 0.1324 (0.1605)  loss_box_reg: 0.1118 (0.1421)  loss_objectness: 0.0958 (0.1168)  loss_rpn_box_reg: 0.0238 (0.0461)  time: 0.3269  data: 0.1428  max mem: 4015\n",
      "Training Epoch: [5]  [ 460/1229]  eta: 0:04:10  lr: 0.005000  loss: 0.3718 (0.4664)  loss_classifier: 0.1373 (0.1608)  loss_box_reg: 0.0906 (0.1421)  loss_objectness: 0.0971 (0.1174)  loss_rpn_box_reg: 0.0238 (0.0462)  time: 0.3358  data: 0.1428  max mem: 4015\n",
      "Training Epoch: [5]  [ 470/1229]  eta: 0:04:07  lr: 0.005000  loss: 0.4571 (0.4686)  loss_classifier: 0.1520 (0.1612)  loss_box_reg: 0.1114 (0.1431)  loss_objectness: 0.1143 (0.1175)  loss_rpn_box_reg: 0.0411 (0.0468)  time: 0.3277  data: 0.1420  max mem: 4015\n",
      "Training Epoch: [5]  [ 480/1229]  eta: 0:04:03  lr: 0.005000  loss: 0.3599 (0.4669)  loss_classifier: 0.1159 (0.1605)  loss_box_reg: 0.1052 (0.1427)  loss_objectness: 0.0928 (0.1173)  loss_rpn_box_reg: 0.0343 (0.0464)  time: 0.3209  data: 0.1427  max mem: 4015\n",
      "Training Epoch: [5]  [ 490/1229]  eta: 0:04:00  lr: 0.005000  loss: 0.3576 (0.4662)  loss_classifier: 0.1159 (0.1602)  loss_box_reg: 0.1040 (0.1431)  loss_objectness: 0.0911 (0.1167)  loss_rpn_box_reg: 0.0240 (0.0462)  time: 0.3274  data: 0.1428  max mem: 4015\n",
      "Training Epoch: [5]  [ 500/1229]  eta: 0:03:57  lr: 0.005000  loss: 0.4777 (0.4693)  loss_classifier: 0.1766 (0.1612)  loss_box_reg: 0.1829 (0.1449)  loss_objectness: 0.0955 (0.1167)  loss_rpn_box_reg: 0.0257 (0.0465)  time: 0.3275  data: 0.1418  max mem: 4015\n",
      "Training Epoch: [5]  [ 510/1229]  eta: 0:03:54  lr: 0.005000  loss: 0.4234 (0.4666)  loss_classifier: 0.1315 (0.1602)  loss_box_reg: 0.0801 (0.1432)  loss_objectness: 0.0987 (0.1169)  loss_rpn_box_reg: 0.0192 (0.0464)  time: 0.3239  data: 0.1385  max mem: 4015\n",
      "Training Epoch: [5]  [ 520/1229]  eta: 0:03:50  lr: 0.005000  loss: 0.3602 (0.4671)  loss_classifier: 0.1315 (0.1604)  loss_box_reg: 0.0855 (0.1432)  loss_objectness: 0.1112 (0.1170)  loss_rpn_box_reg: 0.0185 (0.0464)  time: 0.3248  data: 0.1346  max mem: 4015\n",
      "Training Epoch: [5]  [ 530/1229]  eta: 0:03:47  lr: 0.005000  loss: 0.3602 (0.4654)  loss_classifier: 0.1377 (0.1599)  loss_box_reg: 0.1130 (0.1424)  loss_objectness: 0.1112 (0.1167)  loss_rpn_box_reg: 0.0253 (0.0464)  time: 0.3266  data: 0.1394  max mem: 4015\n",
      "Training Epoch: [5]  [ 540/1229]  eta: 0:03:44  lr: 0.005000  loss: 0.3389 (0.4652)  loss_classifier: 0.1196 (0.1598)  loss_box_reg: 0.0935 (0.1424)  loss_objectness: 0.0998 (0.1166)  loss_rpn_box_reg: 0.0220 (0.0465)  time: 0.3268  data: 0.1449  max mem: 4015\n",
      "Training Epoch: [5]  [ 550/1229]  eta: 0:03:41  lr: 0.005000  loss: 0.4702 (0.4657)  loss_classifier: 0.1335 (0.1597)  loss_box_reg: 0.1224 (0.1425)  loss_objectness: 0.0942 (0.1169)  loss_rpn_box_reg: 0.0231 (0.0466)  time: 0.3270  data: 0.1434  max mem: 4015\n",
      "Training Epoch: [5]  [ 560/1229]  eta: 0:03:37  lr: 0.005000  loss: 0.5549 (0.4671)  loss_classifier: 0.1699 (0.1602)  loss_box_reg: 0.1450 (0.1431)  loss_objectness: 0.1129 (0.1173)  loss_rpn_box_reg: 0.0307 (0.0465)  time: 0.3252  data: 0.1417  max mem: 4015\n",
      "Training Epoch: [5]  [ 570/1229]  eta: 0:03:34  lr: 0.005000  loss: 0.4558 (0.4675)  loss_classifier: 0.1699 (0.1604)  loss_box_reg: 0.1361 (0.1431)  loss_objectness: 0.1129 (0.1173)  loss_rpn_box_reg: 0.0307 (0.0466)  time: 0.3212  data: 0.1404  max mem: 4015\n",
      "Training Epoch: [5]  [ 580/1229]  eta: 0:03:31  lr: 0.005000  loss: 0.4160 (0.4664)  loss_classifier: 0.1500 (0.1599)  loss_box_reg: 0.1170 (0.1425)  loss_objectness: 0.1163 (0.1174)  loss_rpn_box_reg: 0.0303 (0.0465)  time: 0.3230  data: 0.1418  max mem: 4015\n",
      "Training Epoch: [5]  [ 590/1229]  eta: 0:03:28  lr: 0.005000  loss: 0.4057 (0.4656)  loss_classifier: 0.1137 (0.1596)  loss_box_reg: 0.0902 (0.1421)  loss_objectness: 0.1313 (0.1175)  loss_rpn_box_reg: 0.0292 (0.0464)  time: 0.3245  data: 0.1457  max mem: 4015\n",
      "Training Epoch: [5]  [ 600/1229]  eta: 0:03:24  lr: 0.005000  loss: 0.4250 (0.4678)  loss_classifier: 0.1260 (0.1602)  loss_box_reg: 0.1223 (0.1432)  loss_objectness: 0.1128 (0.1175)  loss_rpn_box_reg: 0.0308 (0.0470)  time: 0.3212  data: 0.1427  max mem: 4015\n",
      "Training Epoch: [5]  [ 610/1229]  eta: 0:03:21  lr: 0.005000  loss: 0.4808 (0.4681)  loss_classifier: 0.1519 (0.1602)  loss_box_reg: 0.1347 (0.1433)  loss_objectness: 0.1085 (0.1173)  loss_rpn_box_reg: 0.0308 (0.0473)  time: 0.3281  data: 0.1397  max mem: 4015\n",
      "Training Epoch: [5]  [ 620/1229]  eta: 0:03:18  lr: 0.005000  loss: 0.3787 (0.4682)  loss_classifier: 0.1504 (0.1602)  loss_box_reg: 0.1288 (0.1436)  loss_objectness: 0.0931 (0.1170)  loss_rpn_box_reg: 0.0252 (0.0474)  time: 0.3294  data: 0.1412  max mem: 4015\n",
      "Training Epoch: [5]  [ 630/1229]  eta: 0:03:15  lr: 0.005000  loss: 0.3788 (0.4683)  loss_classifier: 0.1447 (0.1603)  loss_box_reg: 0.1358 (0.1439)  loss_objectness: 0.0939 (0.1169)  loss_rpn_box_reg: 0.0304 (0.0472)  time: 0.3269  data: 0.1422  max mem: 4015\n",
      "Training Epoch: [5]  [ 640/1229]  eta: 0:03:11  lr: 0.005000  loss: 0.3788 (0.4680)  loss_classifier: 0.1342 (0.1601)  loss_box_reg: 0.1112 (0.1436)  loss_objectness: 0.1181 (0.1170)  loss_rpn_box_reg: 0.0308 (0.0474)  time: 0.3243  data: 0.1416  max mem: 4015\n",
      "Training Epoch: [5]  [ 650/1229]  eta: 0:03:08  lr: 0.005000  loss: 0.4363 (0.4692)  loss_classifier: 0.1617 (0.1608)  loss_box_reg: 0.1204 (0.1439)  loss_objectness: 0.1261 (0.1172)  loss_rpn_box_reg: 0.0225 (0.0473)  time: 0.3222  data: 0.1402  max mem: 4015\n",
      "Training Epoch: [5]  [ 660/1229]  eta: 0:03:05  lr: 0.005000  loss: 0.5336 (0.4714)  loss_classifier: 0.1742 (0.1613)  loss_box_reg: 0.1495 (0.1446)  loss_objectness: 0.1310 (0.1178)  loss_rpn_box_reg: 0.0252 (0.0477)  time: 0.3230  data: 0.1414  max mem: 4015\n",
      "Training Epoch: [5]  [ 670/1229]  eta: 0:03:01  lr: 0.005000  loss: 0.5336 (0.4724)  loss_classifier: 0.1585 (0.1614)  loss_box_reg: 0.0951 (0.1447)  loss_objectness: 0.1335 (0.1185)  loss_rpn_box_reg: 0.0390 (0.0478)  time: 0.3223  data: 0.1425  max mem: 4015\n",
      "Training Epoch: [5]  [ 680/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.4000 (0.4713)  loss_classifier: 0.1465 (0.1611)  loss_box_reg: 0.0890 (0.1445)  loss_objectness: 0.0963 (0.1183)  loss_rpn_box_reg: 0.0212 (0.0474)  time: 0.3214  data: 0.1424  max mem: 4015\n",
      "Training Epoch: [5]  [ 690/1229]  eta: 0:02:55  lr: 0.005000  loss: 0.5098 (0.4734)  loss_classifier: 0.1529 (0.1618)  loss_box_reg: 0.1434 (0.1454)  loss_objectness: 0.0963 (0.1184)  loss_rpn_box_reg: 0.0213 (0.0478)  time: 0.3203  data: 0.1433  max mem: 4015\n",
      "Training Epoch: [5]  [ 700/1229]  eta: 0:02:52  lr: 0.005000  loss: 0.5098 (0.4742)  loss_classifier: 0.1732 (0.1620)  loss_box_reg: 0.1565 (0.1460)  loss_objectness: 0.1112 (0.1183)  loss_rpn_box_reg: 0.0296 (0.0479)  time: 0.3211  data: 0.1440  max mem: 4015\n",
      "Training Epoch: [5]  [ 710/1229]  eta: 0:02:48  lr: 0.005000  loss: 0.4268 (0.4748)  loss_classifier: 0.1524 (0.1624)  loss_box_reg: 0.1453 (0.1463)  loss_objectness: 0.0988 (0.1181)  loss_rpn_box_reg: 0.0236 (0.0480)  time: 0.3221  data: 0.1430  max mem: 4015\n",
      "Training Epoch: [5]  [ 720/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.4284 (0.4750)  loss_classifier: 0.1585 (0.1624)  loss_box_reg: 0.1419 (0.1465)  loss_objectness: 0.1016 (0.1182)  loss_rpn_box_reg: 0.0219 (0.0478)  time: 0.3236  data: 0.1406  max mem: 4015\n",
      "Training Epoch: [5]  [ 730/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.3614 (0.4736)  loss_classifier: 0.1479 (0.1622)  loss_box_reg: 0.1359 (0.1462)  loss_objectness: 0.0932 (0.1178)  loss_rpn_box_reg: 0.0206 (0.0474)  time: 0.3263  data: 0.1398  max mem: 4015\n",
      "Training Epoch: [5]  [ 740/1229]  eta: 0:02:39  lr: 0.005000  loss: 0.3328 (0.4740)  loss_classifier: 0.1479 (0.1623)  loss_box_reg: 0.1162 (0.1465)  loss_objectness: 0.0932 (0.1179)  loss_rpn_box_reg: 0.0208 (0.0474)  time: 0.3277  data: 0.1425  max mem: 4015\n",
      "Training Epoch: [5]  [ 750/1229]  eta: 0:02:35  lr: 0.005000  loss: 0.4336 (0.4736)  loss_classifier: 0.1814 (0.1623)  loss_box_reg: 0.1230 (0.1465)  loss_objectness: 0.1062 (0.1177)  loss_rpn_box_reg: 0.0162 (0.0471)  time: 0.3278  data: 0.1431  max mem: 4015\n",
      "Training Epoch: [5]  [ 760/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.4945 (0.4740)  loss_classifier: 0.1630 (0.1626)  loss_box_reg: 0.1435 (0.1467)  loss_objectness: 0.1074 (0.1177)  loss_rpn_box_reg: 0.0382 (0.0471)  time: 0.3229  data: 0.1430  max mem: 4015\n",
      "Training Epoch: [5]  [ 770/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.4945 (0.4741)  loss_classifier: 0.1630 (0.1626)  loss_box_reg: 0.1435 (0.1466)  loss_objectness: 0.1233 (0.1179)  loss_rpn_box_reg: 0.0382 (0.0470)  time: 0.3222  data: 0.1452  max mem: 4015\n",
      "Training Epoch: [5]  [ 780/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.4331 (0.4747)  loss_classifier: 0.1526 (0.1628)  loss_box_reg: 0.1194 (0.1467)  loss_objectness: 0.1292 (0.1181)  loss_rpn_box_reg: 0.0219 (0.0471)  time: 0.3254  data: 0.1448  max mem: 4015\n",
      "Training Epoch: [5]  [ 790/1229]  eta: 0:02:22  lr: 0.005000  loss: 0.4726 (0.4754)  loss_classifier: 0.1698 (0.1629)  loss_box_reg: 0.1164 (0.1467)  loss_objectness: 0.1133 (0.1183)  loss_rpn_box_reg: 0.0613 (0.0474)  time: 0.3263  data: 0.1443  max mem: 4015\n",
      "Training Epoch: [5]  [ 800/1229]  eta: 0:02:19  lr: 0.005000  loss: 0.3605 (0.4733)  loss_classifier: 0.0993 (0.1623)  loss_box_reg: 0.0854 (0.1460)  loss_objectness: 0.1098 (0.1179)  loss_rpn_box_reg: 0.0259 (0.0471)  time: 0.3268  data: 0.1431  max mem: 4015\n",
      "Training Epoch: [5]  [ 810/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.3721 (0.4750)  loss_classifier: 0.1599 (0.1629)  loss_box_reg: 0.1070 (0.1468)  loss_objectness: 0.1107 (0.1181)  loss_rpn_box_reg: 0.0216 (0.0472)  time: 0.3257  data: 0.1409  max mem: 4015\n",
      "Training Epoch: [5]  [ 820/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.4512 (0.4741)  loss_classifier: 0.1650 (0.1627)  loss_box_reg: 0.1490 (0.1468)  loss_objectness: 0.0869 (0.1176)  loss_rpn_box_reg: 0.0219 (0.0470)  time: 0.3257  data: 0.1407  max mem: 4015\n",
      "Training Epoch: [5]  [ 830/1229]  eta: 0:02:09  lr: 0.005000  loss: 0.3458 (0.4731)  loss_classifier: 0.1115 (0.1623)  loss_box_reg: 0.1078 (0.1460)  loss_objectness: 0.0837 (0.1178)  loss_rpn_box_reg: 0.0188 (0.0469)  time: 0.3244  data: 0.1412  max mem: 4015\n",
      "Training Epoch: [5]  [ 840/1229]  eta: 0:02:06  lr: 0.005000  loss: 0.3245 (0.4713)  loss_classifier: 0.1078 (0.1616)  loss_box_reg: 0.0629 (0.1453)  loss_objectness: 0.1047 (0.1177)  loss_rpn_box_reg: 0.0278 (0.0467)  time: 0.3267  data: 0.1405  max mem: 4015\n",
      "Training Epoch: [5]  [ 850/1229]  eta: 0:02:03  lr: 0.005000  loss: 0.3907 (0.4721)  loss_classifier: 0.1249 (0.1619)  loss_box_reg: 0.0971 (0.1455)  loss_objectness: 0.1106 (0.1180)  loss_rpn_box_reg: 0.0279 (0.0467)  time: 0.3292  data: 0.1443  max mem: 4015\n",
      "Training Epoch: [5]  [ 860/1229]  eta: 0:02:00  lr: 0.005000  loss: 0.4549 (0.4720)  loss_classifier: 0.1589 (0.1618)  loss_box_reg: 0.1475 (0.1455)  loss_objectness: 0.1232 (0.1180)  loss_rpn_box_reg: 0.0219 (0.0467)  time: 0.3306  data: 0.1453  max mem: 4015\n",
      "Training Epoch: [5]  [ 870/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.4468 (0.4733)  loss_classifier: 0.1559 (0.1621)  loss_box_reg: 0.1486 (0.1460)  loss_objectness: 0.1203 (0.1184)  loss_rpn_box_reg: 0.0275 (0.0469)  time: 0.3284  data: 0.1449  max mem: 4015\n",
      "Training Epoch: [5]  [ 880/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.4865 (0.4730)  loss_classifier: 0.1523 (0.1619)  loss_box_reg: 0.1105 (0.1456)  loss_objectness: 0.1289 (0.1187)  loss_rpn_box_reg: 0.0341 (0.0468)  time: 0.3223  data: 0.1468  max mem: 4015\n",
      "Training Epoch: [5]  [ 890/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.4669 (0.4731)  loss_classifier: 0.1523 (0.1621)  loss_box_reg: 0.1077 (0.1456)  loss_objectness: 0.1161 (0.1186)  loss_rpn_box_reg: 0.0245 (0.0468)  time: 0.3202  data: 0.1452  max mem: 4015\n",
      "Training Epoch: [5]  [ 900/1229]  eta: 0:01:47  lr: 0.005000  loss: 0.4632 (0.4741)  loss_classifier: 0.1609 (0.1624)  loss_box_reg: 0.1239 (0.1459)  loss_objectness: 0.0978 (0.1186)  loss_rpn_box_reg: 0.0355 (0.0473)  time: 0.3254  data: 0.1438  max mem: 4015\n",
      "Training Epoch: [5]  [ 910/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.4393 (0.4733)  loss_classifier: 0.1492 (0.1621)  loss_box_reg: 0.1368 (0.1456)  loss_objectness: 0.0978 (0.1184)  loss_rpn_box_reg: 0.0355 (0.0471)  time: 0.3294  data: 0.1414  max mem: 4015\n",
      "Training Epoch: [5]  [ 920/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.4439 (0.4747)  loss_classifier: 0.1644 (0.1629)  loss_box_reg: 0.1484 (0.1463)  loss_objectness: 0.1035 (0.1184)  loss_rpn_box_reg: 0.0336 (0.0470)  time: 0.3298  data: 0.1434  max mem: 4015\n",
      "Training Epoch: [5]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.5093 (0.4745)  loss_classifier: 0.1751 (0.1629)  loss_box_reg: 0.1197 (0.1459)  loss_objectness: 0.1134 (0.1187)  loss_rpn_box_reg: 0.0325 (0.0470)  time: 0.3331  data: 0.1466  max mem: 4015\n",
      "Training Epoch: [5]  [ 940/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.3840 (0.4759)  loss_classifier: 0.1733 (0.1636)  loss_box_reg: 0.1197 (0.1466)  loss_objectness: 0.1085 (0.1187)  loss_rpn_box_reg: 0.0301 (0.0469)  time: 0.3305  data: 0.1430  max mem: 4015\n",
      "Training Epoch: [5]  [ 950/1229]  eta: 0:01:30  lr: 0.005000  loss: 0.4126 (0.4756)  loss_classifier: 0.1708 (0.1634)  loss_box_reg: 0.1265 (0.1462)  loss_objectness: 0.1098 (0.1188)  loss_rpn_box_reg: 0.0368 (0.0472)  time: 0.3222  data: 0.1381  max mem: 4015\n",
      "Training Epoch: [5]  [ 960/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.5533 (0.4764)  loss_classifier: 0.1726 (0.1636)  loss_box_reg: 0.0987 (0.1461)  loss_objectness: 0.1098 (0.1190)  loss_rpn_box_reg: 0.0524 (0.0476)  time: 0.3225  data: 0.1387  max mem: 4015\n",
      "Training Epoch: [5]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.5616 (0.4768)  loss_classifier: 0.1726 (0.1636)  loss_box_reg: 0.1007 (0.1461)  loss_objectness: 0.1265 (0.1192)  loss_rpn_box_reg: 0.0413 (0.0480)  time: 0.3271  data: 0.1427  max mem: 4015\n",
      "Training Epoch: [5]  [ 980/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.5255 (0.4783)  loss_classifier: 0.1629 (0.1640)  loss_box_reg: 0.1314 (0.1466)  loss_objectness: 0.1293 (0.1196)  loss_rpn_box_reg: 0.0312 (0.0482)  time: 0.3295  data: 0.1441  max mem: 4015\n",
      "Training Epoch: [5]  [ 990/1229]  eta: 0:01:17  lr: 0.005000  loss: 0.4662 (0.4772)  loss_classifier: 0.1267 (0.1634)  loss_box_reg: 0.1398 (0.1463)  loss_objectness: 0.0992 (0.1193)  loss_rpn_box_reg: 0.0231 (0.0483)  time: 0.3253  data: 0.1425  max mem: 4015\n",
      "Training Epoch: [5]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.3296 (0.4777)  loss_classifier: 0.1145 (0.1634)  loss_box_reg: 0.0969 (0.1467)  loss_objectness: 0.0948 (0.1192)  loss_rpn_box_reg: 0.0231 (0.0485)  time: 0.3216  data: 0.1432  max mem: 4015\n",
      "Training Epoch: [5]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.5532 (0.4786)  loss_classifier: 0.1800 (0.1640)  loss_box_reg: 0.1659 (0.1472)  loss_objectness: 0.1104 (0.1190)  loss_rpn_box_reg: 0.0313 (0.0484)  time: 0.3271  data: 0.1446  max mem: 4015\n",
      "Training Epoch: [5]  [1020/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.5532 (0.4799)  loss_classifier: 0.2020 (0.1644)  loss_box_reg: 0.1865 (0.1478)  loss_objectness: 0.1104 (0.1190)  loss_rpn_box_reg: 0.0383 (0.0487)  time: 0.3232  data: 0.1440  max mem: 4015\n",
      "Training Epoch: [5]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.5171 (0.4810)  loss_classifier: 0.1814 (0.1648)  loss_box_reg: 0.1514 (0.1483)  loss_objectness: 0.1117 (0.1189)  loss_rpn_box_reg: 0.0430 (0.0489)  time: 0.3209  data: 0.1443  max mem: 4015\n",
      "Training Epoch: [5]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.4150 (0.4805)  loss_classifier: 0.1452 (0.1647)  loss_box_reg: 0.1144 (0.1483)  loss_objectness: 0.0897 (0.1188)  loss_rpn_box_reg: 0.0212 (0.0486)  time: 0.3223  data: 0.1428  max mem: 4015\n",
      "Training Epoch: [5]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.4150 (0.4806)  loss_classifier: 0.1401 (0.1647)  loss_box_reg: 0.0985 (0.1481)  loss_objectness: 0.1052 (0.1189)  loss_rpn_box_reg: 0.0225 (0.0488)  time: 0.3178  data: 0.1392  max mem: 4015\n",
      "Training Epoch: [5]  [1060/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.4640 (0.4809)  loss_classifier: 0.1290 (0.1647)  loss_box_reg: 0.0922 (0.1481)  loss_objectness: 0.1267 (0.1192)  loss_rpn_box_reg: 0.0318 (0.0489)  time: 0.3177  data: 0.1385  max mem: 4015\n",
      "Training Epoch: [5]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.3005 (0.4790)  loss_classifier: 0.0886 (0.1639)  loss_box_reg: 0.0719 (0.1473)  loss_objectness: 0.1128 (0.1191)  loss_rpn_box_reg: 0.0216 (0.0487)  time: 0.3176  data: 0.1397  max mem: 4015\n",
      "Training Epoch: [5]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.3267 (0.4798)  loss_classifier: 0.1119 (0.1643)  loss_box_reg: 0.0737 (0.1475)  loss_objectness: 0.1128 (0.1192)  loss_rpn_box_reg: 0.0235 (0.0489)  time: 0.3198  data: 0.1421  max mem: 4015\n",
      "Training Epoch: [5]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.5663 (0.4810)  loss_classifier: 0.2053 (0.1647)  loss_box_reg: 0.1373 (0.1476)  loss_objectness: 0.1163 (0.1194)  loss_rpn_box_reg: 0.0335 (0.0492)  time: 0.3219  data: 0.1438  max mem: 4015\n",
      "Training Epoch: [5]  [1100/1229]  eta: 0:00:41  lr: 0.005000  loss: 0.3975 (0.4803)  loss_classifier: 0.1642 (0.1646)  loss_box_reg: 0.1019 (0.1473)  loss_objectness: 0.1241 (0.1194)  loss_rpn_box_reg: 0.0289 (0.0490)  time: 0.3199  data: 0.1425  max mem: 4015\n",
      "Training Epoch: [5]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.4138 (0.4815)  loss_classifier: 0.1604 (0.1649)  loss_box_reg: 0.1030 (0.1476)  loss_objectness: 0.1319 (0.1196)  loss_rpn_box_reg: 0.0282 (0.0493)  time: 0.3174  data: 0.1399  max mem: 4015\n",
      "Training Epoch: [5]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4872 (0.4807)  loss_classifier: 0.1576 (0.1646)  loss_box_reg: 0.1348 (0.1475)  loss_objectness: 0.0981 (0.1195)  loss_rpn_box_reg: 0.0282 (0.0491)  time: 0.3256  data: 0.1449  max mem: 4015\n",
      "Training Epoch: [5]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.3358 (0.4796)  loss_classifier: 0.1207 (0.1643)  loss_box_reg: 0.1124 (0.1474)  loss_objectness: 0.0831 (0.1191)  loss_rpn_box_reg: 0.0166 (0.0489)  time: 0.3385  data: 0.1484  max mem: 4015\n",
      "Training Epoch: [5]  [1140/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.3412 (0.4796)  loss_classifier: 0.1164 (0.1642)  loss_box_reg: 0.1095 (0.1475)  loss_objectness: 0.0899 (0.1192)  loss_rpn_box_reg: 0.0199 (0.0488)  time: 0.3390  data: 0.1450  max mem: 4015\n",
      "Training Epoch: [5]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.3721 (0.4795)  loss_classifier: 0.1215 (0.1642)  loss_box_reg: 0.1095 (0.1474)  loss_objectness: 0.1127 (0.1191)  loss_rpn_box_reg: 0.0211 (0.0488)  time: 0.3275  data: 0.1446  max mem: 4015\n",
      "Training Epoch: [5]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.3721 (0.4785)  loss_classifier: 0.1231 (0.1637)  loss_box_reg: 0.1096 (0.1471)  loss_objectness: 0.1012 (0.1189)  loss_rpn_box_reg: 0.0217 (0.0488)  time: 0.3205  data: 0.1449  max mem: 4015\n",
      "Training Epoch: [5]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.3476 (0.4779)  loss_classifier: 0.1259 (0.1636)  loss_box_reg: 0.1096 (0.1470)  loss_objectness: 0.0803 (0.1186)  loss_rpn_box_reg: 0.0217 (0.0486)  time: 0.3287  data: 0.1454  max mem: 4015\n",
      "Training Epoch: [5]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.3476 (0.4775)  loss_classifier: 0.1305 (0.1637)  loss_box_reg: 0.1239 (0.1471)  loss_objectness: 0.0803 (0.1183)  loss_rpn_box_reg: 0.0190 (0.0484)  time: 0.3328  data: 0.1445  max mem: 4015\n",
      "Training Epoch: [5]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.3560 (0.4776)  loss_classifier: 0.1318 (0.1637)  loss_box_reg: 0.0967 (0.1469)  loss_objectness: 0.0924 (0.1185)  loss_rpn_box_reg: 0.0179 (0.0484)  time: 0.3359  data: 0.1478  max mem: 4015\n",
      "Training Epoch: [5]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.3546 (0.4765)  loss_classifier: 0.1210 (0.1633)  loss_box_reg: 0.0978 (0.1467)  loss_objectness: 0.0686 (0.1181)  loss_rpn_box_reg: 0.0212 (0.0484)  time: 0.3317  data: 0.1493  max mem: 4015\n",
      "Training Epoch: [5]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.4169 (0.4766)  loss_classifier: 0.1345 (0.1635)  loss_box_reg: 0.1359 (0.1467)  loss_objectness: 0.0768 (0.1182)  loss_rpn_box_reg: 0.0252 (0.0483)  time: 0.3270  data: 0.1498  max mem: 4015\n",
      "Training Epoch: [5]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.4352 (0.4760)  loss_classifier: 0.1540 (0.1633)  loss_box_reg: 0.1188 (0.1463)  loss_objectness: 0.0876 (0.1182)  loss_rpn_box_reg: 0.0252 (0.0482)  time: 0.3273  data: 0.1492  max mem: 4015\n",
      "Training Epoch: [5]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4156 (0.4765)  loss_classifier: 0.1540 (0.1635)  loss_box_reg: 0.1120 (0.1465)  loss_objectness: 0.1197 (0.1183)  loss_rpn_box_reg: 0.0234 (0.0482)  time: 0.3238  data: 0.1459  max mem: 4015\n",
      "Training Epoch: [5] Total time: 0:06:40 (0.3256 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:45  model_time: 0.3040 (0.3040)  evaluator_time: 0.0020 (0.0020)  time: 0.3410  data: 0.0320  max mem: 4015\n",
      "Test:  [100/308]  eta: 0:00:34  model_time: 0.1080 (0.1146)  evaluator_time: 0.0090 (0.0104)  time: 0.1666  data: 0.0399  max mem: 4015\n",
      "Test:  [200/308]  eta: 0:00:17  model_time: 0.1160 (0.1140)  evaluator_time: 0.0040 (0.0094)  time: 0.1607  data: 0.0343  max mem: 4015\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.1050 (0.1131)  evaluator_time: 0.0050 (0.0091)  time: 0.1627  data: 0.0458  max mem: 4015\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.1060 (0.1129)  evaluator_time: 0.0040 (0.0091)  time: 0.1580  data: 0.0434  max mem: 4015\n",
      "Test: Total time: 0:00:50 (0.1625 s / it)\n",
      "Averaged stats: model_time: 0.1060 (0.1129)  evaluator_time: 0.0040 (0.0091)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.051\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.116\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.136\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.098\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.224\n",
      "Testing Epoch: [5]  [  0/308]  eta: 0:00:48  lr: 0.005000  loss: 0.1632 (0.1632)  loss_classifier: 0.0660 (0.0660)  loss_box_reg: 0.0427 (0.0427)  loss_objectness: 0.0445 (0.0445)  loss_rpn_box_reg: 0.0100 (0.0100)  time: 0.1570  data: 0.0330  max mem: 4015\n",
      "Testing Epoch: [5]  [100/308]  eta: 0:00:38  lr: 0.005000  loss: 0.3286 (0.5285)  loss_classifier: 0.1381 (0.1701)  loss_box_reg: 0.1192 (0.1662)  loss_objectness: 0.0830 (0.1179)  loss_rpn_box_reg: 0.0180 (0.0743)  time: 0.1887  data: 0.0501  max mem: 4015\n",
      "Testing Epoch: [5]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.4179 (0.5065)  loss_classifier: 0.1464 (0.1625)  loss_box_reg: 0.1528 (0.1600)  loss_objectness: 0.0934 (0.1121)  loss_rpn_box_reg: 0.0264 (0.0719)  time: 0.1828  data: 0.0383  max mem: 4015\n",
      "Testing Epoch: [5]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5362 (0.5050)  loss_classifier: 0.1852 (0.1625)  loss_box_reg: 0.1492 (0.1626)  loss_objectness: 0.0986 (0.1093)  loss_rpn_box_reg: 0.0336 (0.0706)  time: 0.1760  data: 0.0443  max mem: 4022\n",
      "Testing Epoch: [5]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.5073 (0.5039)  loss_classifier: 0.1620 (0.1623)  loss_box_reg: 0.1525 (0.1627)  loss_objectness: 0.0975 (0.1092)  loss_rpn_box_reg: 0.0292 (0.0697)  time: 0.1751  data: 0.0427  max mem: 4022\n",
      "Testing Epoch: [5] Total time: 0:00:56 (0.1829 s / it)\n",
      "Training Epoch: [6]  [   0/1229]  eta: 0:07:22  lr: 0.005000  loss: 0.8617 (0.8617)  loss_classifier: 0.3264 (0.3264)  loss_box_reg: 0.3158 (0.3158)  loss_objectness: 0.1756 (0.1756)  loss_rpn_box_reg: 0.0439 (0.0439)  time: 0.3600  data: 0.1630  max mem: 4022\n",
      "Training Epoch: [6]  [  10/1229]  eta: 0:06:56  lr: 0.005000  loss: 0.4904 (0.6818)  loss_classifier: 0.1801 (0.2359)  loss_box_reg: 0.1594 (0.1863)  loss_objectness: 0.1461 (0.1594)  loss_rpn_box_reg: 0.0439 (0.1002)  time: 0.3415  data: 0.1484  max mem: 4022\n",
      "Training Epoch: [6]  [  20/1229]  eta: 0:06:53  lr: 0.005000  loss: 0.4161 (0.5743)  loss_classifier: 0.1745 (0.1992)  loss_box_reg: 0.1399 (0.1675)  loss_objectness: 0.1297 (0.1383)  loss_rpn_box_reg: 0.0338 (0.0693)  time: 0.3411  data: 0.1443  max mem: 4022\n",
      "Training Epoch: [6]  [  30/1229]  eta: 0:06:52  lr: 0.005000  loss: 0.4161 (0.5107)  loss_classifier: 0.1441 (0.1745)  loss_box_reg: 0.0903 (0.1412)  loss_objectness: 0.1195 (0.1342)  loss_rpn_box_reg: 0.0281 (0.0608)  time: 0.3451  data: 0.1445  max mem: 4022\n",
      "Training Epoch: [6]  [  40/1229]  eta: 0:06:48  lr: 0.005000  loss: 0.3644 (0.4859)  loss_classifier: 0.1102 (0.1647)  loss_box_reg: 0.1059 (0.1411)  loss_objectness: 0.0941 (0.1251)  loss_rpn_box_reg: 0.0269 (0.0550)  time: 0.3454  data: 0.1538  max mem: 4022\n",
      "Training Epoch: [6]  [  50/1229]  eta: 0:06:40  lr: 0.005000  loss: 0.3870 (0.5002)  loss_classifier: 0.1193 (0.1686)  loss_box_reg: 0.1440 (0.1548)  loss_objectness: 0.0790 (0.1214)  loss_rpn_box_reg: 0.0215 (0.0554)  time: 0.3341  data: 0.1517  max mem: 4022\n",
      "Training Epoch: [6]  [  60/1229]  eta: 0:06:36  lr: 0.005000  loss: 0.4583 (0.4950)  loss_classifier: 0.1635 (0.1694)  loss_box_reg: 0.1440 (0.1559)  loss_objectness: 0.0860 (0.1174)  loss_rpn_box_reg: 0.0268 (0.0524)  time: 0.3305  data: 0.1433  max mem: 4022\n",
      "Training Epoch: [6]  [  70/1229]  eta: 0:06:33  lr: 0.005000  loss: 0.4168 (0.4916)  loss_classifier: 0.1667 (0.1700)  loss_box_reg: 0.1278 (0.1574)  loss_objectness: 0.0928 (0.1150)  loss_rpn_box_reg: 0.0366 (0.0492)  time: 0.3368  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [6]  [  80/1229]  eta: 0:06:26  lr: 0.005000  loss: 0.3390 (0.4739)  loss_classifier: 0.1154 (0.1635)  loss_box_reg: 0.0887 (0.1499)  loss_objectness: 0.0957 (0.1142)  loss_rpn_box_reg: 0.0168 (0.0464)  time: 0.3284  data: 0.1394  max mem: 4022\n",
      "Training Epoch: [6]  [  90/1229]  eta: 0:06:21  lr: 0.005000  loss: 0.3168 (0.4652)  loss_classifier: 0.1058 (0.1614)  loss_box_reg: 0.0823 (0.1472)  loss_objectness: 0.0897 (0.1122)  loss_rpn_box_reg: 0.0202 (0.0444)  time: 0.3190  data: 0.1375  max mem: 4022\n",
      "Training Epoch: [6]  [ 100/1229]  eta: 0:06:16  lr: 0.005000  loss: 0.3281 (0.4609)  loss_classifier: 0.1037 (0.1583)  loss_box_reg: 0.1018 (0.1453)  loss_objectness: 0.0831 (0.1100)  loss_rpn_box_reg: 0.0228 (0.0472)  time: 0.3184  data: 0.1386  max mem: 4022\n",
      "Training Epoch: [6]  [ 110/1229]  eta: 0:06:11  lr: 0.005000  loss: 0.4279 (0.4643)  loss_classifier: 0.1509 (0.1607)  loss_box_reg: 0.1021 (0.1469)  loss_objectness: 0.0934 (0.1106)  loss_rpn_box_reg: 0.0228 (0.0461)  time: 0.3180  data: 0.1381  max mem: 4022\n",
      "Training Epoch: [6]  [ 120/1229]  eta: 0:06:06  lr: 0.005000  loss: 0.4808 (0.4677)  loss_classifier: 0.1667 (0.1619)  loss_box_reg: 0.1449 (0.1480)  loss_objectness: 0.1190 (0.1119)  loss_rpn_box_reg: 0.0233 (0.0459)  time: 0.3152  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [6]  [ 130/1229]  eta: 0:06:02  lr: 0.005000  loss: 0.4899 (0.4705)  loss_classifier: 0.1667 (0.1624)  loss_box_reg: 0.1291 (0.1460)  loss_objectness: 0.1245 (0.1149)  loss_rpn_box_reg: 0.0273 (0.0473)  time: 0.3205  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [6]  [ 140/1229]  eta: 0:05:58  lr: 0.005000  loss: 0.4422 (0.4710)  loss_classifier: 0.1374 (0.1627)  loss_box_reg: 0.1119 (0.1451)  loss_objectness: 0.1267 (0.1160)  loss_rpn_box_reg: 0.0245 (0.0471)  time: 0.3267  data: 0.1365  max mem: 4022\n",
      "Training Epoch: [6]  [ 150/1229]  eta: 0:05:54  lr: 0.005000  loss: 0.4502 (0.4757)  loss_classifier: 0.1571 (0.1643)  loss_box_reg: 0.1305 (0.1459)  loss_objectness: 0.1363 (0.1188)  loss_rpn_box_reg: 0.0273 (0.0466)  time: 0.3223  data: 0.1375  max mem: 4022\n",
      "Training Epoch: [6]  [ 160/1229]  eta: 0:05:51  lr: 0.005000  loss: 0.4419 (0.4750)  loss_classifier: 0.1545 (0.1637)  loss_box_reg: 0.1384 (0.1463)  loss_objectness: 0.1115 (0.1188)  loss_rpn_box_reg: 0.0245 (0.0462)  time: 0.3198  data: 0.1368  max mem: 4022\n",
      "Training Epoch: [6]  [ 170/1229]  eta: 0:05:47  lr: 0.005000  loss: 0.4156 (0.4748)  loss_classifier: 0.1511 (0.1637)  loss_box_reg: 0.1161 (0.1466)  loss_objectness: 0.1234 (0.1196)  loss_rpn_box_reg: 0.0245 (0.0448)  time: 0.3224  data: 0.1373  max mem: 4022\n",
      "Training Epoch: [6]  [ 180/1229]  eta: 0:05:44  lr: 0.005000  loss: 0.5630 (0.4805)  loss_classifier: 0.2186 (0.1654)  loss_box_reg: 0.1727 (0.1485)  loss_objectness: 0.1414 (0.1214)  loss_rpn_box_reg: 0.0285 (0.0451)  time: 0.3248  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [6]  [ 190/1229]  eta: 0:05:40  lr: 0.005000  loss: 0.4693 (0.4780)  loss_classifier: 0.1672 (0.1647)  loss_box_reg: 0.1020 (0.1458)  loss_objectness: 0.1443 (0.1219)  loss_rpn_box_reg: 0.0410 (0.0455)  time: 0.3207  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [6]  [ 200/1229]  eta: 0:05:36  lr: 0.005000  loss: 0.4561 (0.4855)  loss_classifier: 0.1672 (0.1684)  loss_box_reg: 0.0847 (0.1487)  loss_objectness: 0.1103 (0.1226)  loss_rpn_box_reg: 0.0410 (0.0459)  time: 0.3147  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [6]  [ 210/1229]  eta: 0:05:32  lr: 0.005000  loss: 0.4694 (0.4860)  loss_classifier: 0.1693 (0.1693)  loss_box_reg: 0.1584 (0.1488)  loss_objectness: 0.1032 (0.1225)  loss_rpn_box_reg: 0.0391 (0.0454)  time: 0.3132  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [6]  [ 220/1229]  eta: 0:05:28  lr: 0.005000  loss: 0.3884 (0.4857)  loss_classifier: 0.1611 (0.1697)  loss_box_reg: 0.1410 (0.1501)  loss_objectness: 0.0958 (0.1213)  loss_rpn_box_reg: 0.0193 (0.0446)  time: 0.3139  data: 0.1384  max mem: 4022\n",
      "Training Epoch: [6]  [ 230/1229]  eta: 0:05:24  lr: 0.005000  loss: 0.3884 (0.4893)  loss_classifier: 0.1611 (0.1709)  loss_box_reg: 0.1580 (0.1527)  loss_objectness: 0.0905 (0.1211)  loss_rpn_box_reg: 0.0190 (0.0446)  time: 0.3173  data: 0.1391  max mem: 4022\n",
      "Training Epoch: [6]  [ 240/1229]  eta: 0:05:21  lr: 0.005000  loss: 0.4664 (0.4924)  loss_classifier: 0.1886 (0.1714)  loss_box_reg: 0.1803 (0.1539)  loss_objectness: 0.1038 (0.1215)  loss_rpn_box_reg: 0.0394 (0.0455)  time: 0.3176  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [6]  [ 250/1229]  eta: 0:05:18  lr: 0.005000  loss: 0.4634 (0.4891)  loss_classifier: 0.1522 (0.1704)  loss_box_reg: 0.1260 (0.1536)  loss_objectness: 0.0898 (0.1201)  loss_rpn_box_reg: 0.0252 (0.0450)  time: 0.3297  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [6]  [ 260/1229]  eta: 0:05:15  lr: 0.005000  loss: 0.4468 (0.4879)  loss_classifier: 0.1549 (0.1700)  loss_box_reg: 0.1260 (0.1536)  loss_objectness: 0.0971 (0.1197)  loss_rpn_box_reg: 0.0190 (0.0445)  time: 0.3343  data: 0.1397  max mem: 4022\n",
      "Training Epoch: [6]  [ 270/1229]  eta: 0:05:12  lr: 0.005000  loss: 0.4342 (0.4853)  loss_classifier: 0.1399 (0.1692)  loss_box_reg: 0.1085 (0.1528)  loss_objectness: 0.1113 (0.1193)  loss_rpn_box_reg: 0.0224 (0.0440)  time: 0.3214  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [6]  [ 280/1229]  eta: 0:05:08  lr: 0.005000  loss: 0.3122 (0.4810)  loss_classifier: 0.1174 (0.1676)  loss_box_reg: 0.0832 (0.1507)  loss_objectness: 0.0961 (0.1189)  loss_rpn_box_reg: 0.0224 (0.0438)  time: 0.3244  data: 0.1433  max mem: 4022\n",
      "Training Epoch: [6]  [ 290/1229]  eta: 0:05:05  lr: 0.005000  loss: 0.3170 (0.4822)  loss_classifier: 0.1174 (0.1682)  loss_box_reg: 0.0831 (0.1508)  loss_objectness: 0.0961 (0.1190)  loss_rpn_box_reg: 0.0282 (0.0442)  time: 0.3279  data: 0.1428  max mem: 4022\n",
      "Training Epoch: [6]  [ 300/1229]  eta: 0:05:02  lr: 0.005000  loss: 0.4618 (0.4849)  loss_classifier: 0.1335 (0.1689)  loss_box_reg: 0.1162 (0.1522)  loss_objectness: 0.1078 (0.1186)  loss_rpn_box_reg: 0.0369 (0.0451)  time: 0.3231  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [6]  [ 310/1229]  eta: 0:04:59  lr: 0.005000  loss: 0.4636 (0.4877)  loss_classifier: 0.1805 (0.1700)  loss_box_reg: 0.1407 (0.1532)  loss_objectness: 0.1069 (0.1194)  loss_rpn_box_reg: 0.0274 (0.0450)  time: 0.3244  data: 0.1436  max mem: 4022\n",
      "Training Epoch: [6]  [ 320/1229]  eta: 0:04:55  lr: 0.005000  loss: 0.3142 (0.4844)  loss_classifier: 0.1266 (0.1688)  loss_box_reg: 0.0857 (0.1515)  loss_objectness: 0.0986 (0.1191)  loss_rpn_box_reg: 0.0160 (0.0450)  time: 0.3235  data: 0.1443  max mem: 4022\n",
      "Training Epoch: [6]  [ 330/1229]  eta: 0:04:52  lr: 0.005000  loss: 0.3152 (0.4860)  loss_classifier: 0.1266 (0.1690)  loss_box_reg: 0.0791 (0.1516)  loss_objectness: 0.1087 (0.1199)  loss_rpn_box_reg: 0.0174 (0.0456)  time: 0.3200  data: 0.1447  max mem: 4022\n",
      "Training Epoch: [6]  [ 340/1229]  eta: 0:04:49  lr: 0.005000  loss: 0.4160 (0.4859)  loss_classifier: 0.1488 (0.1690)  loss_box_reg: 0.1334 (0.1520)  loss_objectness: 0.1131 (0.1193)  loss_rpn_box_reg: 0.0322 (0.0457)  time: 0.3279  data: 0.1448  max mem: 4022\n",
      "Training Epoch: [6]  [ 350/1229]  eta: 0:04:47  lr: 0.005000  loss: 0.4160 (0.4852)  loss_classifier: 0.1552 (0.1690)  loss_box_reg: 0.1483 (0.1521)  loss_objectness: 0.0900 (0.1189)  loss_rpn_box_reg: 0.0226 (0.0452)  time: 0.3549  data: 0.1433  max mem: 4022\n",
      "Training Epoch: [6]  [ 360/1229]  eta: 0:04:43  lr: 0.005000  loss: 0.4597 (0.4879)  loss_classifier: 0.1759 (0.1701)  loss_box_reg: 0.1758 (0.1536)  loss_objectness: 0.0886 (0.1191)  loss_rpn_box_reg: 0.0271 (0.0451)  time: 0.3480  data: 0.1409  max mem: 4022\n",
      "Training Epoch: [6]  [ 370/1229]  eta: 0:04:40  lr: 0.005000  loss: 0.4839 (0.4873)  loss_classifier: 0.1746 (0.1698)  loss_box_reg: 0.1758 (0.1536)  loss_objectness: 0.0991 (0.1190)  loss_rpn_box_reg: 0.0291 (0.0449)  time: 0.3229  data: 0.1368  max mem: 4022\n",
      "Training Epoch: [6]  [ 380/1229]  eta: 0:04:37  lr: 0.005000  loss: 0.4646 (0.4867)  loss_classifier: 0.1586 (0.1695)  loss_box_reg: 0.1334 (0.1529)  loss_objectness: 0.0994 (0.1192)  loss_rpn_box_reg: 0.0338 (0.0451)  time: 0.3239  data: 0.1383  max mem: 4022\n",
      "Training Epoch: [6]  [ 390/1229]  eta: 0:04:33  lr: 0.005000  loss: 0.4121 (0.4850)  loss_classifier: 0.1570 (0.1690)  loss_box_reg: 0.1270 (0.1525)  loss_objectness: 0.0956 (0.1188)  loss_rpn_box_reg: 0.0304 (0.0447)  time: 0.3227  data: 0.1397  max mem: 4022\n",
      "Training Epoch: [6]  [ 400/1229]  eta: 0:04:30  lr: 0.005000  loss: 0.5073 (0.4882)  loss_classifier: 0.1602 (0.1701)  loss_box_reg: 0.1722 (0.1543)  loss_objectness: 0.0956 (0.1187)  loss_rpn_box_reg: 0.0284 (0.0452)  time: 0.3173  data: 0.1380  max mem: 4022\n",
      "Training Epoch: [6]  [ 410/1229]  eta: 0:04:26  lr: 0.005000  loss: 0.5451 (0.4874)  loss_classifier: 0.1581 (0.1698)  loss_box_reg: 0.1607 (0.1539)  loss_objectness: 0.1008 (0.1184)  loss_rpn_box_reg: 0.0284 (0.0452)  time: 0.3178  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [6]  [ 420/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.3693 (0.4860)  loss_classifier: 0.1408 (0.1693)  loss_box_reg: 0.1004 (0.1529)  loss_objectness: 0.0874 (0.1185)  loss_rpn_box_reg: 0.0214 (0.0453)  time: 0.3193  data: 0.1402  max mem: 4022\n",
      "Training Epoch: [6]  [ 430/1229]  eta: 0:04:20  lr: 0.005000  loss: 0.2832 (0.4811)  loss_classifier: 0.1105 (0.1678)  loss_box_reg: 0.0890 (0.1510)  loss_objectness: 0.0854 (0.1177)  loss_rpn_box_reg: 0.0149 (0.0446)  time: 0.3140  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [6]  [ 440/1229]  eta: 0:04:16  lr: 0.005000  loss: 0.3434 (0.4803)  loss_classifier: 0.1229 (0.1675)  loss_box_reg: 0.0991 (0.1510)  loss_objectness: 0.0779 (0.1173)  loss_rpn_box_reg: 0.0177 (0.0444)  time: 0.3171  data: 0.1361  max mem: 4022\n",
      "Training Epoch: [6]  [ 450/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.4165 (0.4805)  loss_classifier: 0.1662 (0.1677)  loss_box_reg: 0.1274 (0.1510)  loss_objectness: 0.1046 (0.1175)  loss_rpn_box_reg: 0.0183 (0.0442)  time: 0.3219  data: 0.1386  max mem: 4022\n",
      "Training Epoch: [6]  [ 460/1229]  eta: 0:04:09  lr: 0.005000  loss: 0.4199 (0.4797)  loss_classifier: 0.1662 (0.1672)  loss_box_reg: 0.1244 (0.1501)  loss_objectness: 0.0984 (0.1175)  loss_rpn_box_reg: 0.0322 (0.0448)  time: 0.3173  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [6]  [ 470/1229]  eta: 0:04:06  lr: 0.005000  loss: 0.4463 (0.4816)  loss_classifier: 0.1736 (0.1677)  loss_box_reg: 0.0996 (0.1505)  loss_objectness: 0.1061 (0.1181)  loss_rpn_box_reg: 0.0526 (0.0453)  time: 0.3162  data: 0.1401  max mem: 4022\n",
      "Training Epoch: [6]  [ 480/1229]  eta: 0:04:03  lr: 0.005000  loss: 0.3888 (0.4794)  loss_classifier: 0.1454 (0.1669)  loss_box_reg: 0.0996 (0.1496)  loss_objectness: 0.1101 (0.1178)  loss_rpn_box_reg: 0.0348 (0.0451)  time: 0.3186  data: 0.1392  max mem: 4022\n",
      "Training Epoch: [6]  [ 490/1229]  eta: 0:04:00  lr: 0.005000  loss: 0.3328 (0.4789)  loss_classifier: 0.1356 (0.1667)  loss_box_reg: 0.0949 (0.1494)  loss_objectness: 0.1057 (0.1176)  loss_rpn_box_reg: 0.0232 (0.0452)  time: 0.3221  data: 0.1377  max mem: 4022\n",
      "Training Epoch: [6]  [ 500/1229]  eta: 0:03:56  lr: 0.005000  loss: 0.3349 (0.4776)  loss_classifier: 0.1262 (0.1662)  loss_box_reg: 0.0949 (0.1491)  loss_objectness: 0.0993 (0.1173)  loss_rpn_box_reg: 0.0193 (0.0450)  time: 0.3284  data: 0.1371  max mem: 4022\n",
      "Training Epoch: [6]  [ 510/1229]  eta: 0:03:53  lr: 0.005000  loss: 0.3349 (0.4752)  loss_classifier: 0.1202 (0.1652)  loss_box_reg: 0.0947 (0.1482)  loss_objectness: 0.0815 (0.1168)  loss_rpn_box_reg: 0.0184 (0.0449)  time: 0.3222  data: 0.1354  max mem: 4022\n",
      "Training Epoch: [6]  [ 520/1229]  eta: 0:03:50  lr: 0.005000  loss: 0.3373 (0.4749)  loss_classifier: 0.1301 (0.1650)  loss_box_reg: 0.1071 (0.1480)  loss_objectness: 0.0791 (0.1170)  loss_rpn_box_reg: 0.0192 (0.0447)  time: 0.3188  data: 0.1350  max mem: 4022\n",
      "Training Epoch: [6]  [ 530/1229]  eta: 0:03:47  lr: 0.005000  loss: 0.4831 (0.4760)  loss_classifier: 0.1637 (0.1651)  loss_box_reg: 0.1207 (0.1480)  loss_objectness: 0.1069 (0.1173)  loss_rpn_box_reg: 0.0365 (0.0457)  time: 0.3297  data: 0.1363  max mem: 4022\n",
      "Training Epoch: [6]  [ 540/1229]  eta: 0:03:43  lr: 0.005000  loss: 0.4736 (0.4759)  loss_classifier: 0.1564 (0.1649)  loss_box_reg: 0.1299 (0.1480)  loss_objectness: 0.1132 (0.1174)  loss_rpn_box_reg: 0.0453 (0.0456)  time: 0.3328  data: 0.1390  max mem: 4022\n",
      "Training Epoch: [6]  [ 550/1229]  eta: 0:03:40  lr: 0.005000  loss: 0.4119 (0.4772)  loss_classifier: 0.1341 (0.1650)  loss_box_reg: 0.1197 (0.1482)  loss_objectness: 0.1139 (0.1180)  loss_rpn_box_reg: 0.0308 (0.0459)  time: 0.3313  data: 0.1414  max mem: 4022\n",
      "Training Epoch: [6]  [ 560/1229]  eta: 0:03:37  lr: 0.005000  loss: 0.4082 (0.4777)  loss_classifier: 0.1341 (0.1652)  loss_box_reg: 0.1171 (0.1488)  loss_objectness: 0.1072 (0.1180)  loss_rpn_box_reg: 0.0266 (0.0457)  time: 0.3325  data: 0.1401  max mem: 4022\n",
      "Training Epoch: [6]  [ 570/1229]  eta: 0:03:34  lr: 0.005000  loss: 0.5551 (0.4788)  loss_classifier: 0.1814 (0.1655)  loss_box_reg: 0.1551 (0.1490)  loss_objectness: 0.1000 (0.1180)  loss_rpn_box_reg: 0.0325 (0.0463)  time: 0.3316  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [6]  [ 580/1229]  eta: 0:03:30  lr: 0.005000  loss: 0.3864 (0.4789)  loss_classifier: 0.1390 (0.1654)  loss_box_reg: 0.1163 (0.1491)  loss_objectness: 0.0999 (0.1179)  loss_rpn_box_reg: 0.0366 (0.0465)  time: 0.3187  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [6]  [ 590/1229]  eta: 0:03:27  lr: 0.005000  loss: 0.3449 (0.4771)  loss_classifier: 0.1251 (0.1650)  loss_box_reg: 0.1014 (0.1484)  loss_objectness: 0.0800 (0.1174)  loss_rpn_box_reg: 0.0237 (0.0463)  time: 0.3189  data: 0.1380  max mem: 4022\n",
      "Training Epoch: [6]  [ 600/1229]  eta: 0:03:24  lr: 0.005000  loss: 0.3687 (0.4761)  loss_classifier: 0.1258 (0.1644)  loss_box_reg: 0.1116 (0.1478)  loss_objectness: 0.1009 (0.1177)  loss_rpn_box_reg: 0.0295 (0.0462)  time: 0.3227  data: 0.1385  max mem: 4022\n",
      "Training Epoch: [6]  [ 610/1229]  eta: 0:03:21  lr: 0.005000  loss: 0.4970 (0.4784)  loss_classifier: 0.1598 (0.1649)  loss_box_reg: 0.1567 (0.1491)  loss_objectness: 0.0954 (0.1179)  loss_rpn_box_reg: 0.0295 (0.0465)  time: 0.3183  data: 0.1389  max mem: 4022\n",
      "Training Epoch: [6]  [ 620/1229]  eta: 0:03:17  lr: 0.005000  loss: 0.5148 (0.4796)  loss_classifier: 0.1873 (0.1655)  loss_box_reg: 0.1762 (0.1498)  loss_objectness: 0.0912 (0.1178)  loss_rpn_box_reg: 0.0293 (0.0464)  time: 0.3297  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [6]  [ 630/1229]  eta: 0:03:14  lr: 0.005000  loss: 0.4270 (0.4794)  loss_classifier: 0.1591 (0.1654)  loss_box_reg: 0.1277 (0.1498)  loss_objectness: 0.0982 (0.1175)  loss_rpn_box_reg: 0.0218 (0.0466)  time: 0.3285  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [6]  [ 640/1229]  eta: 0:03:11  lr: 0.005000  loss: 0.4270 (0.4796)  loss_classifier: 0.1372 (0.1655)  loss_box_reg: 0.1267 (0.1497)  loss_objectness: 0.0982 (0.1175)  loss_rpn_box_reg: 0.0223 (0.0469)  time: 0.3276  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [6]  [ 650/1229]  eta: 0:03:08  lr: 0.005000  loss: 0.3960 (0.4796)  loss_classifier: 0.1460 (0.1655)  loss_box_reg: 0.1104 (0.1499)  loss_objectness: 0.0819 (0.1176)  loss_rpn_box_reg: 0.0317 (0.0467)  time: 0.3271  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [6]  [ 660/1229]  eta: 0:03:04  lr: 0.005000  loss: 0.3960 (0.4799)  loss_classifier: 0.1519 (0.1655)  loss_box_reg: 0.1612 (0.1502)  loss_objectness: 0.0985 (0.1176)  loss_rpn_box_reg: 0.0221 (0.0466)  time: 0.3212  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [6]  [ 670/1229]  eta: 0:03:01  lr: 0.005000  loss: 0.4430 (0.4797)  loss_classifier: 0.1589 (0.1655)  loss_box_reg: 0.1412 (0.1501)  loss_objectness: 0.1133 (0.1177)  loss_rpn_box_reg: 0.0221 (0.0464)  time: 0.3236  data: 0.1409  max mem: 4022\n",
      "Training Epoch: [6]  [ 680/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.4676 (0.4797)  loss_classifier: 0.1567 (0.1654)  loss_box_reg: 0.1085 (0.1499)  loss_objectness: 0.1185 (0.1181)  loss_rpn_box_reg: 0.0224 (0.0464)  time: 0.3217  data: 0.1401  max mem: 4022\n",
      "Training Epoch: [6]  [ 690/1229]  eta: 0:02:55  lr: 0.005000  loss: 0.3521 (0.4784)  loss_classifier: 0.1186 (0.1647)  loss_box_reg: 0.0927 (0.1492)  loss_objectness: 0.1168 (0.1180)  loss_rpn_box_reg: 0.0249 (0.0465)  time: 0.3202  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [6]  [ 700/1229]  eta: 0:02:51  lr: 0.005000  loss: 0.3521 (0.4769)  loss_classifier: 0.1166 (0.1641)  loss_box_reg: 0.0749 (0.1484)  loss_objectness: 0.1100 (0.1180)  loss_rpn_box_reg: 0.0270 (0.0465)  time: 0.3198  data: 0.1391  max mem: 4022\n",
      "Training Epoch: [6]  [ 710/1229]  eta: 0:02:48  lr: 0.005000  loss: 0.4463 (0.4790)  loss_classifier: 0.1392 (0.1648)  loss_box_reg: 0.1227 (0.1491)  loss_objectness: 0.1395 (0.1184)  loss_rpn_box_reg: 0.0290 (0.0466)  time: 0.3193  data: 0.1406  max mem: 4022\n",
      "Training Epoch: [6]  [ 720/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.4888 (0.4795)  loss_classifier: 0.1829 (0.1652)  loss_box_reg: 0.1501 (0.1495)  loss_objectness: 0.1130 (0.1183)  loss_rpn_box_reg: 0.0315 (0.0465)  time: 0.3218  data: 0.1422  max mem: 4022\n",
      "Training Epoch: [6]  [ 730/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.4153 (0.4789)  loss_classifier: 0.1588 (0.1650)  loss_box_reg: 0.1180 (0.1496)  loss_objectness: 0.0935 (0.1179)  loss_rpn_box_reg: 0.0315 (0.0464)  time: 0.3240  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [6]  [ 740/1229]  eta: 0:02:38  lr: 0.005000  loss: 0.4280 (0.4788)  loss_classifier: 0.1588 (0.1649)  loss_box_reg: 0.1116 (0.1494)  loss_objectness: 0.0935 (0.1181)  loss_rpn_box_reg: 0.0231 (0.0464)  time: 0.3293  data: 0.1403  max mem: 4022\n",
      "Training Epoch: [6]  [ 750/1229]  eta: 0:02:35  lr: 0.005000  loss: 0.4465 (0.4794)  loss_classifier: 0.1588 (0.1650)  loss_box_reg: 0.1234 (0.1499)  loss_objectness: 0.1075 (0.1178)  loss_rpn_box_reg: 0.0266 (0.0467)  time: 0.3271  data: 0.1412  max mem: 4022\n",
      "Training Epoch: [6]  [ 760/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.3689 (0.4779)  loss_classifier: 0.1187 (0.1645)  loss_box_reg: 0.1053 (0.1495)  loss_objectness: 0.0938 (0.1174)  loss_rpn_box_reg: 0.0192 (0.0465)  time: 0.3179  data: 0.1429  max mem: 4022\n",
      "Training Epoch: [6]  [ 770/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.3417 (0.4773)  loss_classifier: 0.1160 (0.1642)  loss_box_reg: 0.1052 (0.1490)  loss_objectness: 0.0777 (0.1174)  loss_rpn_box_reg: 0.0231 (0.0467)  time: 0.3254  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [6]  [ 780/1229]  eta: 0:02:25  lr: 0.005000  loss: 0.3899 (0.4778)  loss_classifier: 0.1415 (0.1643)  loss_box_reg: 0.1266 (0.1491)  loss_objectness: 0.0820 (0.1175)  loss_rpn_box_reg: 0.0336 (0.0469)  time: 0.3304  data: 0.1424  max mem: 4022\n",
      "Training Epoch: [6]  [ 790/1229]  eta: 0:02:22  lr: 0.005000  loss: 0.4515 (0.4780)  loss_classifier: 0.1441 (0.1643)  loss_box_reg: 0.1216 (0.1488)  loss_objectness: 0.1293 (0.1178)  loss_rpn_box_reg: 0.0253 (0.0472)  time: 0.3220  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [6]  [ 800/1229]  eta: 0:02:19  lr: 0.005000  loss: 0.3821 (0.4775)  loss_classifier: 0.1383 (0.1642)  loss_box_reg: 0.1100 (0.1487)  loss_objectness: 0.0863 (0.1175)  loss_rpn_box_reg: 0.0267 (0.0471)  time: 0.3189  data: 0.1391  max mem: 4022\n",
      "Training Epoch: [6]  [ 810/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.3269 (0.4768)  loss_classifier: 0.1198 (0.1642)  loss_box_reg: 0.1013 (0.1485)  loss_objectness: 0.0856 (0.1172)  loss_rpn_box_reg: 0.0267 (0.0468)  time: 0.3204  data: 0.1401  max mem: 4022\n",
      "Training Epoch: [6]  [ 820/1229]  eta: 0:02:12  lr: 0.005000  loss: 0.4255 (0.4769)  loss_classifier: 0.1248 (0.1642)  loss_box_reg: 0.1013 (0.1483)  loss_objectness: 0.0895 (0.1174)  loss_rpn_box_reg: 0.0183 (0.0469)  time: 0.3244  data: 0.1387  max mem: 4022\n",
      "Training Epoch: [6]  [ 830/1229]  eta: 0:02:09  lr: 0.005000  loss: 0.4255 (0.4762)  loss_classifier: 0.1431 (0.1640)  loss_box_reg: 0.1173 (0.1480)  loss_objectness: 0.0895 (0.1173)  loss_rpn_box_reg: 0.0245 (0.0469)  time: 0.3277  data: 0.1380  max mem: 4022\n",
      "Training Epoch: [6]  [ 840/1229]  eta: 0:02:06  lr: 0.005000  loss: 0.4523 (0.4766)  loss_classifier: 0.1490 (0.1640)  loss_box_reg: 0.1386 (0.1484)  loss_objectness: 0.1154 (0.1172)  loss_rpn_box_reg: 0.0401 (0.0470)  time: 0.3257  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [6]  [ 850/1229]  eta: 0:02:03  lr: 0.005000  loss: 0.5020 (0.4771)  loss_classifier: 0.1437 (0.1641)  loss_box_reg: 0.1470 (0.1487)  loss_objectness: 0.1219 (0.1175)  loss_rpn_box_reg: 0.0286 (0.0468)  time: 0.3227  data: 0.1411  max mem: 4022\n",
      "Training Epoch: [6]  [ 860/1229]  eta: 0:01:59  lr: 0.005000  loss: 0.5674 (0.4799)  loss_classifier: 0.1961 (0.1650)  loss_box_reg: 0.1945 (0.1497)  loss_objectness: 0.1606 (0.1181)  loss_rpn_box_reg: 0.0394 (0.0470)  time: 0.3212  data: 0.1432  max mem: 4022\n",
      "Training Epoch: [6]  [ 870/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.5525 (0.4796)  loss_classifier: 0.1946 (0.1651)  loss_box_reg: 0.1929 (0.1498)  loss_objectness: 0.1097 (0.1180)  loss_rpn_box_reg: 0.0289 (0.0468)  time: 0.3225  data: 0.1438  max mem: 4022\n",
      "Training Epoch: [6]  [ 880/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.4189 (0.4795)  loss_classifier: 0.1805 (0.1653)  loss_box_reg: 0.1201 (0.1500)  loss_objectness: 0.0759 (0.1177)  loss_rpn_box_reg: 0.0186 (0.0465)  time: 0.3250  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [6]  [ 890/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.3223 (0.4776)  loss_classifier: 0.1226 (0.1648)  loss_box_reg: 0.0815 (0.1495)  loss_objectness: 0.0705 (0.1172)  loss_rpn_box_reg: 0.0170 (0.0462)  time: 0.3232  data: 0.1412  max mem: 4022\n",
      "Training Epoch: [6]  [ 900/1229]  eta: 0:01:46  lr: 0.005000  loss: 0.3416 (0.4781)  loss_classifier: 0.1226 (0.1648)  loss_box_reg: 0.0857 (0.1494)  loss_objectness: 0.0725 (0.1175)  loss_rpn_box_reg: 0.0180 (0.0464)  time: 0.3218  data: 0.1412  max mem: 4022\n",
      "Training Epoch: [6]  [ 910/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.4327 (0.4780)  loss_classifier: 0.1456 (0.1648)  loss_box_reg: 0.1121 (0.1495)  loss_objectness: 0.0947 (0.1173)  loss_rpn_box_reg: 0.0431 (0.0465)  time: 0.3262  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [6]  [ 920/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.4481 (0.4785)  loss_classifier: 0.1418 (0.1650)  loss_box_reg: 0.1430 (0.1500)  loss_objectness: 0.0972 (0.1172)  loss_rpn_box_reg: 0.0260 (0.0463)  time: 0.3301  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [6]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.4469 (0.4782)  loss_classifier: 0.1418 (0.1648)  loss_box_reg: 0.1379 (0.1499)  loss_objectness: 0.0965 (0.1170)  loss_rpn_box_reg: 0.0281 (0.0465)  time: 0.3323  data: 0.1372  max mem: 4022\n",
      "Training Epoch: [6]  [ 940/1229]  eta: 0:01:33  lr: 0.005000  loss: 0.4110 (0.4779)  loss_classifier: 0.1242 (0.1647)  loss_box_reg: 0.1189 (0.1499)  loss_objectness: 0.0942 (0.1169)  loss_rpn_box_reg: 0.0307 (0.0463)  time: 0.3328  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [6]  [ 950/1229]  eta: 0:01:30  lr: 0.005000  loss: 0.3418 (0.4771)  loss_classifier: 0.1242 (0.1646)  loss_box_reg: 0.1170 (0.1496)  loss_objectness: 0.0915 (0.1167)  loss_rpn_box_reg: 0.0213 (0.0463)  time: 0.3322  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [6]  [ 960/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.3904 (0.4765)  loss_classifier: 0.1258 (0.1644)  loss_box_reg: 0.0985 (0.1491)  loss_objectness: 0.1100 (0.1167)  loss_rpn_box_reg: 0.0327 (0.0463)  time: 0.3294  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [6]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.4085 (0.4760)  loss_classifier: 0.1470 (0.1642)  loss_box_reg: 0.1069 (0.1490)  loss_objectness: 0.0817 (0.1165)  loss_rpn_box_reg: 0.0370 (0.0463)  time: 0.3208  data: 0.1385  max mem: 4022\n",
      "Training Epoch: [6]  [ 980/1229]  eta: 0:01:20  lr: 0.005000  loss: 0.3851 (0.4755)  loss_classifier: 0.1460 (0.1641)  loss_box_reg: 0.1208 (0.1488)  loss_objectness: 0.0817 (0.1165)  loss_rpn_box_reg: 0.0365 (0.0461)  time: 0.3171  data: 0.1412  max mem: 4022\n",
      "Training Epoch: [6]  [ 990/1229]  eta: 0:01:17  lr: 0.005000  loss: 0.3375 (0.4743)  loss_classifier: 0.1186 (0.1637)  loss_box_reg: 0.1198 (0.1484)  loss_objectness: 0.0966 (0.1163)  loss_rpn_box_reg: 0.0200 (0.0459)  time: 0.3201  data: 0.1420  max mem: 4022\n",
      "Training Epoch: [6]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.3351 (0.4735)  loss_classifier: 0.1008 (0.1634)  loss_box_reg: 0.0783 (0.1479)  loss_objectness: 0.0966 (0.1164)  loss_rpn_box_reg: 0.0200 (0.0459)  time: 0.3289  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [6]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.3287 (0.4724)  loss_classifier: 0.1147 (0.1630)  loss_box_reg: 0.0721 (0.1474)  loss_objectness: 0.0910 (0.1162)  loss_rpn_box_reg: 0.0150 (0.0458)  time: 0.3324  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [6]  [1020/1229]  eta: 0:01:07  lr: 0.005000  loss: 0.3292 (0.4723)  loss_classifier: 0.1221 (0.1629)  loss_box_reg: 0.1037 (0.1474)  loss_objectness: 0.0934 (0.1162)  loss_rpn_box_reg: 0.0180 (0.0458)  time: 0.3269  data: 0.1383  max mem: 4022\n",
      "Training Epoch: [6]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.4547 (0.4733)  loss_classifier: 0.1495 (0.1631)  loss_box_reg: 0.1518 (0.1479)  loss_objectness: 0.0934 (0.1163)  loss_rpn_box_reg: 0.0446 (0.0460)  time: 0.3230  data: 0.1392  max mem: 4022\n",
      "Training Epoch: [6]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.4191 (0.4726)  loss_classifier: 0.1463 (0.1630)  loss_box_reg: 0.1463 (0.1479)  loss_objectness: 0.0838 (0.1160)  loss_rpn_box_reg: 0.0446 (0.0458)  time: 0.3224  data: 0.1395  max mem: 4022\n",
      "Training Epoch: [6]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.3524 (0.4725)  loss_classifier: 0.1410 (0.1629)  loss_box_reg: 0.1401 (0.1479)  loss_objectness: 0.0663 (0.1158)  loss_rpn_box_reg: 0.0320 (0.0458)  time: 0.3306  data: 0.1406  max mem: 4022\n",
      "Training Epoch: [6]  [1060/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.3492 (0.4720)  loss_classifier: 0.1355 (0.1628)  loss_box_reg: 0.1175 (0.1479)  loss_objectness: 0.0675 (0.1155)  loss_rpn_box_reg: 0.0320 (0.0458)  time: 0.3257  data: 0.1402  max mem: 4022\n",
      "Training Epoch: [6]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.3204 (0.4714)  loss_classifier: 0.1156 (0.1626)  loss_box_reg: 0.1005 (0.1476)  loss_objectness: 0.0831 (0.1154)  loss_rpn_box_reg: 0.0203 (0.0457)  time: 0.3186  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [6]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.3204 (0.4710)  loss_classifier: 0.1085 (0.1623)  loss_box_reg: 0.0822 (0.1472)  loss_objectness: 0.0917 (0.1156)  loss_rpn_box_reg: 0.0242 (0.0459)  time: 0.3249  data: 0.1420  max mem: 4022\n",
      "Training Epoch: [6]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.5009 (0.4722)  loss_classifier: 0.1759 (0.1627)  loss_box_reg: 0.1593 (0.1478)  loss_objectness: 0.0961 (0.1157)  loss_rpn_box_reg: 0.0242 (0.0460)  time: 0.3313  data: 0.1411  max mem: 4022\n",
      "Training Epoch: [6]  [1100/1229]  eta: 0:00:41  lr: 0.005000  loss: 0.5330 (0.4718)  loss_classifier: 0.1826 (0.1626)  loss_box_reg: 0.1387 (0.1474)  loss_objectness: 0.1018 (0.1159)  loss_rpn_box_reg: 0.0246 (0.0460)  time: 0.3287  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [6]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.4103 (0.4717)  loss_classifier: 0.1307 (0.1624)  loss_box_reg: 0.0874 (0.1471)  loss_objectness: 0.1147 (0.1161)  loss_rpn_box_reg: 0.0259 (0.0460)  time: 0.3228  data: 0.1414  max mem: 4022\n",
      "Training Epoch: [6]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4758 (0.4715)  loss_classifier: 0.1448 (0.1624)  loss_box_reg: 0.1096 (0.1472)  loss_objectness: 0.1131 (0.1160)  loss_rpn_box_reg: 0.0274 (0.0459)  time: 0.3213  data: 0.1403  max mem: 4022\n",
      "Training Epoch: [6]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.4271 (0.4715)  loss_classifier: 0.1568 (0.1624)  loss_box_reg: 0.1242 (0.1470)  loss_objectness: 0.1105 (0.1160)  loss_rpn_box_reg: 0.0224 (0.0460)  time: 0.3257  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [6]  [1140/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.4401 (0.4723)  loss_classifier: 0.1572 (0.1625)  loss_box_reg: 0.1329 (0.1471)  loss_objectness: 0.1175 (0.1164)  loss_rpn_box_reg: 0.0448 (0.0463)  time: 0.3337  data: 0.1457  max mem: 4022\n",
      "Training Epoch: [6]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.4620 (0.4718)  loss_classifier: 0.1583 (0.1623)  loss_box_reg: 0.1288 (0.1469)  loss_objectness: 0.1170 (0.1163)  loss_rpn_box_reg: 0.0411 (0.0462)  time: 0.3310  data: 0.1437  max mem: 4022\n",
      "Training Epoch: [6]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.3945 (0.4718)  loss_classifier: 0.1436 (0.1623)  loss_box_reg: 0.1269 (0.1469)  loss_objectness: 0.1130 (0.1163)  loss_rpn_box_reg: 0.0263 (0.0463)  time: 0.3234  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [6]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.4473 (0.4719)  loss_classifier: 0.1536 (0.1624)  loss_box_reg: 0.1248 (0.1470)  loss_objectness: 0.0988 (0.1163)  loss_rpn_box_reg: 0.0283 (0.0462)  time: 0.3216  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [6]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.4664 (0.4719)  loss_classifier: 0.1475 (0.1622)  loss_box_reg: 0.1247 (0.1468)  loss_objectness: 0.0988 (0.1164)  loss_rpn_box_reg: 0.0283 (0.0464)  time: 0.3232  data: 0.1407  max mem: 4022\n",
      "Training Epoch: [6]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.4303 (0.4715)  loss_classifier: 0.1475 (0.1622)  loss_box_reg: 0.1241 (0.1467)  loss_objectness: 0.1105 (0.1164)  loss_rpn_box_reg: 0.0283 (0.0462)  time: 0.3204  data: 0.1390  max mem: 4022\n",
      "Training Epoch: [6]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.4785 (0.4727)  loss_classifier: 0.1521 (0.1625)  loss_box_reg: 0.1546 (0.1474)  loss_objectness: 0.1105 (0.1164)  loss_rpn_box_reg: 0.0309 (0.0463)  time: 0.3238  data: 0.1384  max mem: 4022\n",
      "Training Epoch: [6]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.5271 (0.4740)  loss_classifier: 0.1996 (0.1630)  loss_box_reg: 0.1768 (0.1482)  loss_objectness: 0.1189 (0.1164)  loss_rpn_box_reg: 0.0366 (0.0464)  time: 0.3288  data: 0.1364  max mem: 4022\n",
      "Training Epoch: [6]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.5271 (0.4744)  loss_classifier: 0.1820 (0.1631)  loss_box_reg: 0.1707 (0.1483)  loss_objectness: 0.1046 (0.1166)  loss_rpn_box_reg: 0.0322 (0.0464)  time: 0.3257  data: 0.1377  max mem: 4022\n",
      "Training Epoch: [6]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.5047 (0.4754)  loss_classifier: 0.1654 (0.1634)  loss_box_reg: 0.1344 (0.1485)  loss_objectness: 0.1046 (0.1169)  loss_rpn_box_reg: 0.0375 (0.0467)  time: 0.3252  data: 0.1382  max mem: 4022\n",
      "Training Epoch: [6] Total time: 0:06:39 (0.3251 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:02:08  model_time: 0.3820 (0.3820)  evaluator_time: 0.0020 (0.0020)  time: 0.4160  data: 0.0300  max mem: 4022\n",
      "Test:  [100/308]  eta: 0:00:32  model_time: 0.1060 (0.1107)  evaluator_time: 0.0040 (0.0068)  time: 0.1568  data: 0.0386  max mem: 4022\n",
      "Test:  [200/308]  eta: 0:00:16  model_time: 0.1110 (0.1096)  evaluator_time: 0.0030 (0.0064)  time: 0.1533  data: 0.0335  max mem: 4022\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0970 (0.1086)  evaluator_time: 0.0040 (0.0063)  time: 0.1476  data: 0.0382  max mem: 4022\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0980 (0.1084)  evaluator_time: 0.0030 (0.0063)  time: 0.1457  data: 0.0374  max mem: 4022\n",
      "Test: Total time: 0:00:47 (0.1536 s / it)\n",
      "Averaged stats: model_time: 0.0980 (0.1084)  evaluator_time: 0.0030 (0.0063)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.17s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.062\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.120\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.083\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
      "Testing Epoch: [6]  [  0/308]  eta: 0:00:50  lr: 0.005000  loss: 0.1650 (0.1650)  loss_classifier: 0.0618 (0.0618)  loss_box_reg: 0.0419 (0.0419)  loss_objectness: 0.0507 (0.0507)  loss_rpn_box_reg: 0.0106 (0.0106)  time: 0.1630  data: 0.0370  max mem: 4022\n",
      "Testing Epoch: [6]  [100/308]  eta: 0:00:38  lr: 0.005000  loss: 0.3440 (0.5204)  loss_classifier: 0.1496 (0.1709)  loss_box_reg: 0.1235 (0.1689)  loss_objectness: 0.0897 (0.1166)  loss_rpn_box_reg: 0.0234 (0.0640)  time: 0.1835  data: 0.0470  max mem: 4022\n",
      "Testing Epoch: [6]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.4584 (0.4935)  loss_classifier: 0.1275 (0.1625)  loss_box_reg: 0.1279 (0.1596)  loss_objectness: 0.0949 (0.1103)  loss_rpn_box_reg: 0.0298 (0.0611)  time: 0.1811  data: 0.0376  max mem: 4022\n",
      "Testing Epoch: [6]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5230 (0.4950)  loss_classifier: 0.1734 (0.1624)  loss_box_reg: 0.1699 (0.1631)  loss_objectness: 0.1086 (0.1090)  loss_rpn_box_reg: 0.0410 (0.0605)  time: 0.1709  data: 0.0437  max mem: 4022\n",
      "Testing Epoch: [6]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.5203 (0.4950)  loss_classifier: 0.1663 (0.1626)  loss_box_reg: 0.1533 (0.1634)  loss_objectness: 0.0994 (0.1089)  loss_rpn_box_reg: 0.0384 (0.0600)  time: 0.1670  data: 0.0400  max mem: 4022\n",
      "Testing Epoch: [6] Total time: 0:00:55 (0.1791 s / it)\n",
      "Training Epoch: [7]  [   0/1229]  eta: 0:07:33  lr: 0.005000  loss: 0.5883 (0.5883)  loss_classifier: 0.2643 (0.2643)  loss_box_reg: 0.1644 (0.1644)  loss_objectness: 0.1448 (0.1448)  loss_rpn_box_reg: 0.0148 (0.0148)  time: 0.3690  data: 0.1810  max mem: 4022\n",
      "Training Epoch: [7]  [  10/1229]  eta: 0:06:33  lr: 0.005000  loss: 0.4369 (0.4671)  loss_classifier: 0.1837 (0.1742)  loss_box_reg: 0.1085 (0.1248)  loss_objectness: 0.1331 (0.1275)  loss_rpn_box_reg: 0.0262 (0.0406)  time: 0.3225  data: 0.1485  max mem: 4022\n",
      "Training Epoch: [7]  [  20/1229]  eta: 0:06:36  lr: 0.005000  loss: 0.3313 (0.3825)  loss_classifier: 0.1154 (0.1409)  loss_box_reg: 0.0900 (0.1083)  loss_objectness: 0.0818 (0.0996)  loss_rpn_box_reg: 0.0216 (0.0337)  time: 0.3258  data: 0.1460  max mem: 4022\n",
      "Training Epoch: [7]  [  30/1229]  eta: 0:06:37  lr: 0.005000  loss: 0.2629 (0.3818)  loss_classifier: 0.0955 (0.1325)  loss_box_reg: 0.0755 (0.1077)  loss_objectness: 0.0772 (0.1047)  loss_rpn_box_reg: 0.0290 (0.0368)  time: 0.3360  data: 0.1439  max mem: 4022\n",
      "Training Epoch: [7]  [  40/1229]  eta: 0:06:30  lr: 0.005000  loss: 0.4411 (0.3946)  loss_classifier: 0.1183 (0.1394)  loss_box_reg: 0.1433 (0.1203)  loss_objectness: 0.0880 (0.1017)  loss_rpn_box_reg: 0.0290 (0.0332)  time: 0.3291  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [7]  [  50/1229]  eta: 0:06:30  lr: 0.005000  loss: 0.3794 (0.4074)  loss_classifier: 0.1483 (0.1424)  loss_box_reg: 0.1433 (0.1231)  loss_objectness: 0.0870 (0.1018)  loss_rpn_box_reg: 0.0219 (0.0401)  time: 0.3302  data: 0.1432  max mem: 4022\n",
      "Training Epoch: [7]  [  60/1229]  eta: 0:06:27  lr: 0.005000  loss: 0.3332 (0.4106)  loss_classifier: 0.1260 (0.1432)  loss_box_reg: 0.1078 (0.1246)  loss_objectness: 0.0870 (0.1026)  loss_rpn_box_reg: 0.0182 (0.0402)  time: 0.3364  data: 0.1428  max mem: 4022\n",
      "Training Epoch: [7]  [  70/1229]  eta: 0:06:21  lr: 0.005000  loss: 0.4536 (0.4171)  loss_classifier: 0.1551 (0.1451)  loss_box_reg: 0.1192 (0.1280)  loss_objectness: 0.1087 (0.1041)  loss_rpn_box_reg: 0.0283 (0.0399)  time: 0.3259  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [7]  [  80/1229]  eta: 0:06:18  lr: 0.005000  loss: 0.4182 (0.4219)  loss_classifier: 0.1578 (0.1460)  loss_box_reg: 0.1192 (0.1252)  loss_objectness: 0.1139 (0.1068)  loss_rpn_box_reg: 0.0230 (0.0441)  time: 0.3246  data: 0.1407  max mem: 4022\n",
      "Training Epoch: [7]  [  90/1229]  eta: 0:06:14  lr: 0.005000  loss: 0.4122 (0.4275)  loss_classifier: 0.1445 (0.1476)  loss_box_reg: 0.1226 (0.1292)  loss_objectness: 0.1013 (0.1077)  loss_rpn_box_reg: 0.0221 (0.0430)  time: 0.3284  data: 0.1397  max mem: 4022\n",
      "Training Epoch: [7]  [ 100/1229]  eta: 0:06:11  lr: 0.005000  loss: 0.4852 (0.4301)  loss_classifier: 0.1613 (0.1489)  loss_box_reg: 0.1357 (0.1294)  loss_objectness: 0.1030 (0.1103)  loss_rpn_box_reg: 0.0282 (0.0415)  time: 0.3285  data: 0.1426  max mem: 4022\n",
      "Training Epoch: [7]  [ 110/1229]  eta: 0:06:08  lr: 0.005000  loss: 0.3889 (0.4296)  loss_classifier: 0.1359 (0.1496)  loss_box_reg: 0.1159 (0.1306)  loss_objectness: 0.0933 (0.1086)  loss_rpn_box_reg: 0.0177 (0.0408)  time: 0.3310  data: 0.1426  max mem: 4022\n",
      "Training Epoch: [7]  [ 120/1229]  eta: 0:06:05  lr: 0.005000  loss: 0.3647 (0.4276)  loss_classifier: 0.1297 (0.1487)  loss_box_reg: 0.1159 (0.1303)  loss_objectness: 0.0863 (0.1088)  loss_rpn_box_reg: 0.0177 (0.0399)  time: 0.3308  data: 0.1425  max mem: 4022\n",
      "Training Epoch: [7]  [ 130/1229]  eta: 0:06:01  lr: 0.005000  loss: 0.3696 (0.4304)  loss_classifier: 0.1431 (0.1491)  loss_box_reg: 0.1136 (0.1309)  loss_objectness: 0.0899 (0.1096)  loss_rpn_box_reg: 0.0307 (0.0409)  time: 0.3248  data: 0.1439  max mem: 4022\n",
      "Training Epoch: [7]  [ 140/1229]  eta: 0:05:58  lr: 0.005000  loss: 0.4159 (0.4314)  loss_classifier: 0.1560 (0.1498)  loss_box_reg: 0.1231 (0.1306)  loss_objectness: 0.0898 (0.1098)  loss_rpn_box_reg: 0.0207 (0.0412)  time: 0.3240  data: 0.1437  max mem: 4022\n",
      "Training Epoch: [7]  [ 150/1229]  eta: 0:05:54  lr: 0.005000  loss: 0.3262 (0.4288)  loss_classifier: 0.1374 (0.1494)  loss_box_reg: 0.0850 (0.1297)  loss_objectness: 0.0898 (0.1091)  loss_rpn_box_reg: 0.0175 (0.0407)  time: 0.3273  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [7]  [ 160/1229]  eta: 0:05:51  lr: 0.005000  loss: 0.4060 (0.4349)  loss_classifier: 0.1685 (0.1519)  loss_box_reg: 0.1419 (0.1325)  loss_objectness: 0.1031 (0.1094)  loss_rpn_box_reg: 0.0207 (0.0411)  time: 0.3283  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [7]  [ 170/1229]  eta: 0:05:48  lr: 0.005000  loss: 0.6278 (0.4469)  loss_classifier: 0.1970 (0.1558)  loss_box_reg: 0.1601 (0.1366)  loss_objectness: 0.1303 (0.1109)  loss_rpn_box_reg: 0.0458 (0.0437)  time: 0.3318  data: 0.1424  max mem: 4022\n",
      "Training Epoch: [7]  [ 180/1229]  eta: 0:05:44  lr: 0.005000  loss: 0.6139 (0.4478)  loss_classifier: 0.1762 (0.1558)  loss_box_reg: 0.1529 (0.1368)  loss_objectness: 0.1018 (0.1117)  loss_rpn_box_reg: 0.0386 (0.0434)  time: 0.3282  data: 0.1403  max mem: 4022\n",
      "Training Epoch: [7]  [ 190/1229]  eta: 0:05:40  lr: 0.005000  loss: 0.4552 (0.4465)  loss_classifier: 0.1474 (0.1560)  loss_box_reg: 0.1175 (0.1370)  loss_objectness: 0.0989 (0.1113)  loss_rpn_box_reg: 0.0239 (0.0422)  time: 0.3214  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [7]  [ 200/1229]  eta: 0:05:37  lr: 0.005000  loss: 0.4552 (0.4501)  loss_classifier: 0.1524 (0.1567)  loss_box_reg: 0.1663 (0.1386)  loss_objectness: 0.0998 (0.1121)  loss_rpn_box_reg: 0.0253 (0.0427)  time: 0.3253  data: 0.1424  max mem: 4022\n",
      "Training Epoch: [7]  [ 210/1229]  eta: 0:05:34  lr: 0.005000  loss: 0.5307 (0.4529)  loss_classifier: 0.1524 (0.1580)  loss_box_reg: 0.1663 (0.1402)  loss_objectness: 0.1040 (0.1123)  loss_rpn_box_reg: 0.0325 (0.0424)  time: 0.3285  data: 0.1441  max mem: 4022\n",
      "Training Epoch: [7]  [ 220/1229]  eta: 0:05:30  lr: 0.005000  loss: 0.3719 (0.4541)  loss_classifier: 0.1474 (0.1588)  loss_box_reg: 0.1098 (0.1411)  loss_objectness: 0.0918 (0.1124)  loss_rpn_box_reg: 0.0157 (0.0418)  time: 0.3251  data: 0.1436  max mem: 4022\n",
      "Training Epoch: [7]  [ 230/1229]  eta: 0:05:27  lr: 0.005000  loss: 0.4707 (0.4548)  loss_classifier: 0.1737 (0.1593)  loss_box_reg: 0.1576 (0.1422)  loss_objectness: 0.0808 (0.1118)  loss_rpn_box_reg: 0.0202 (0.0415)  time: 0.3260  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [7]  [ 240/1229]  eta: 0:05:24  lr: 0.005000  loss: 0.4646 (0.4533)  loss_classifier: 0.1830 (0.1594)  loss_box_reg: 0.1785 (0.1421)  loss_objectness: 0.0888 (0.1111)  loss_rpn_box_reg: 0.0225 (0.0407)  time: 0.3265  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [7]  [ 250/1229]  eta: 0:05:20  lr: 0.005000  loss: 0.4646 (0.4543)  loss_classifier: 0.1830 (0.1599)  loss_box_reg: 0.1644 (0.1438)  loss_objectness: 0.0840 (0.1101)  loss_rpn_box_reg: 0.0230 (0.0404)  time: 0.3218  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [7]  [ 260/1229]  eta: 0:05:17  lr: 0.005000  loss: 0.4261 (0.4522)  loss_classifier: 0.1572 (0.1594)  loss_box_reg: 0.1644 (0.1433)  loss_objectness: 0.0889 (0.1099)  loss_rpn_box_reg: 0.0177 (0.0396)  time: 0.3232  data: 0.1429  max mem: 4022\n",
      "Training Epoch: [7]  [ 270/1229]  eta: 0:05:14  lr: 0.005000  loss: 0.4022 (0.4518)  loss_classifier: 0.1396 (0.1590)  loss_box_reg: 0.0948 (0.1424)  loss_objectness: 0.0984 (0.1105)  loss_rpn_box_reg: 0.0177 (0.0400)  time: 0.3266  data: 0.1404  max mem: 4022\n",
      "Training Epoch: [7]  [ 280/1229]  eta: 0:05:11  lr: 0.005000  loss: 0.3976 (0.4503)  loss_classifier: 0.1370 (0.1588)  loss_box_reg: 0.0961 (0.1412)  loss_objectness: 0.1032 (0.1105)  loss_rpn_box_reg: 0.0210 (0.0398)  time: 0.3305  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [7]  [ 290/1229]  eta: 0:05:07  lr: 0.005000  loss: 0.4076 (0.4494)  loss_classifier: 0.1357 (0.1583)  loss_box_reg: 0.0961 (0.1402)  loss_objectness: 0.0994 (0.1107)  loss_rpn_box_reg: 0.0307 (0.0403)  time: 0.3318  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [7]  [ 300/1229]  eta: 0:05:04  lr: 0.005000  loss: 0.4210 (0.4484)  loss_classifier: 0.1245 (0.1572)  loss_box_reg: 0.0821 (0.1390)  loss_objectness: 0.0889 (0.1107)  loss_rpn_box_reg: 0.0367 (0.0416)  time: 0.3292  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [7]  [ 310/1229]  eta: 0:05:01  lr: 0.005000  loss: 0.4369 (0.4524)  loss_classifier: 0.1355 (0.1584)  loss_box_reg: 0.0997 (0.1399)  loss_objectness: 0.1083 (0.1121)  loss_rpn_box_reg: 0.0366 (0.0420)  time: 0.3248  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [7]  [ 320/1229]  eta: 0:04:57  lr: 0.005000  loss: 0.4144 (0.4517)  loss_classifier: 0.1341 (0.1580)  loss_box_reg: 0.1237 (0.1397)  loss_objectness: 0.1130 (0.1117)  loss_rpn_box_reg: 0.0352 (0.0423)  time: 0.3223  data: 0.1429  max mem: 4022\n",
      "Training Epoch: [7]  [ 330/1229]  eta: 0:04:54  lr: 0.005000  loss: 0.4144 (0.4541)  loss_classifier: 0.1552 (0.1587)  loss_box_reg: 0.1314 (0.1407)  loss_objectness: 0.0867 (0.1123)  loss_rpn_box_reg: 0.0287 (0.0425)  time: 0.3309  data: 0.1433  max mem: 4022\n",
      "Training Epoch: [7]  [ 340/1229]  eta: 0:04:51  lr: 0.005000  loss: 0.4548 (0.4539)  loss_classifier: 0.1648 (0.1584)  loss_box_reg: 0.1305 (0.1405)  loss_objectness: 0.0915 (0.1126)  loss_rpn_box_reg: 0.0261 (0.0425)  time: 0.3370  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [7]  [ 350/1229]  eta: 0:04:48  lr: 0.005000  loss: 0.4867 (0.4591)  loss_classifier: 0.1764 (0.1598)  loss_box_reg: 0.1455 (0.1423)  loss_objectness: 0.1141 (0.1135)  loss_rpn_box_reg: 0.0411 (0.0436)  time: 0.3298  data: 0.1430  max mem: 4022\n",
      "Training Epoch: [7]  [ 360/1229]  eta: 0:04:44  lr: 0.005000  loss: 0.4964 (0.4592)  loss_classifier: 0.1805 (0.1599)  loss_box_reg: 0.1616 (0.1427)  loss_objectness: 0.1079 (0.1135)  loss_rpn_box_reg: 0.0415 (0.0430)  time: 0.3209  data: 0.1442  max mem: 4022\n",
      "Training Epoch: [7]  [ 370/1229]  eta: 0:04:41  lr: 0.005000  loss: 0.3727 (0.4571)  loss_classifier: 0.1070 (0.1591)  loss_box_reg: 0.0966 (0.1420)  loss_objectness: 0.0992 (0.1131)  loss_rpn_box_reg: 0.0129 (0.0429)  time: 0.3255  data: 0.1436  max mem: 4022\n",
      "Training Epoch: [7]  [ 380/1229]  eta: 0:04:38  lr: 0.005000  loss: 0.4453 (0.4613)  loss_classifier: 0.1464 (0.1608)  loss_box_reg: 0.1195 (0.1439)  loss_objectness: 0.1030 (0.1137)  loss_rpn_box_reg: 0.0248 (0.0429)  time: 0.3269  data: 0.1432  max mem: 4022\n",
      "Training Epoch: [7]  [ 390/1229]  eta: 0:04:34  lr: 0.005000  loss: 0.4205 (0.4598)  loss_classifier: 0.1517 (0.1602)  loss_box_reg: 0.1540 (0.1438)  loss_objectness: 0.0915 (0.1132)  loss_rpn_box_reg: 0.0321 (0.0427)  time: 0.3233  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [7]  [ 400/1229]  eta: 0:04:31  lr: 0.005000  loss: 0.3995 (0.4585)  loss_classifier: 0.1430 (0.1599)  loss_box_reg: 0.1432 (0.1435)  loss_objectness: 0.0797 (0.1128)  loss_rpn_box_reg: 0.0207 (0.0422)  time: 0.3202  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [7]  [ 410/1229]  eta: 0:04:27  lr: 0.005000  loss: 0.3995 (0.4562)  loss_classifier: 0.1219 (0.1592)  loss_box_reg: 0.1031 (0.1425)  loss_objectness: 0.0768 (0.1125)  loss_rpn_box_reg: 0.0175 (0.0420)  time: 0.3172  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [7]  [ 420/1229]  eta: 0:04:24  lr: 0.005000  loss: 0.3289 (0.4558)  loss_classifier: 0.1208 (0.1593)  loss_box_reg: 0.0908 (0.1425)  loss_objectness: 0.0933 (0.1122)  loss_rpn_box_reg: 0.0243 (0.0418)  time: 0.3242  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [7]  [ 430/1229]  eta: 0:04:21  lr: 0.005000  loss: 0.4879 (0.4571)  loss_classifier: 0.1749 (0.1599)  loss_box_reg: 0.1424 (0.1432)  loss_objectness: 0.1107 (0.1122)  loss_rpn_box_reg: 0.0332 (0.0418)  time: 0.3334  data: 0.1409  max mem: 4022\n",
      "Training Epoch: [7]  [ 440/1229]  eta: 0:04:18  lr: 0.005000  loss: 0.4879 (0.4585)  loss_classifier: 0.1550 (0.1605)  loss_box_reg: 0.1424 (0.1438)  loss_objectness: 0.1107 (0.1123)  loss_rpn_box_reg: 0.0332 (0.0419)  time: 0.3317  data: 0.1437  max mem: 4022\n",
      "Training Epoch: [7]  [ 450/1229]  eta: 0:04:14  lr: 0.005000  loss: 0.4541 (0.4591)  loss_classifier: 0.1550 (0.1606)  loss_box_reg: 0.1345 (0.1442)  loss_objectness: 0.1015 (0.1120)  loss_rpn_box_reg: 0.0371 (0.0423)  time: 0.3258  data: 0.1425  max mem: 4022\n",
      "Training Epoch: [7]  [ 460/1229]  eta: 0:04:11  lr: 0.005000  loss: 0.4631 (0.4640)  loss_classifier: 0.1717 (0.1618)  loss_box_reg: 0.1563 (0.1460)  loss_objectness: 0.1094 (0.1127)  loss_rpn_box_reg: 0.0517 (0.0436)  time: 0.3160  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [7]  [ 470/1229]  eta: 0:04:07  lr: 0.005000  loss: 0.4631 (0.4652)  loss_classifier: 0.1511 (0.1620)  loss_box_reg: 0.1591 (0.1462)  loss_objectness: 0.1089 (0.1128)  loss_rpn_box_reg: 0.0524 (0.0442)  time: 0.3136  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [7]  [ 480/1229]  eta: 0:04:04  lr: 0.005000  loss: 0.4595 (0.4644)  loss_classifier: 0.1435 (0.1617)  loss_box_reg: 0.1074 (0.1461)  loss_objectness: 0.0947 (0.1124)  loss_rpn_box_reg: 0.0313 (0.0442)  time: 0.3217  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [7]  [ 490/1229]  eta: 0:04:01  lr: 0.005000  loss: 0.4453 (0.4624)  loss_classifier: 0.1171 (0.1609)  loss_box_reg: 0.0939 (0.1453)  loss_objectness: 0.0947 (0.1120)  loss_rpn_box_reg: 0.0222 (0.0442)  time: 0.3230  data: 0.1436  max mem: 4022\n",
      "Training Epoch: [7]  [ 500/1229]  eta: 0:03:58  lr: 0.005000  loss: 0.3135 (0.4615)  loss_classifier: 0.1018 (0.1604)  loss_box_reg: 0.0801 (0.1449)  loss_objectness: 0.0999 (0.1123)  loss_rpn_box_reg: 0.0186 (0.0440)  time: 0.3266  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [7]  [ 510/1229]  eta: 0:03:54  lr: 0.005000  loss: 0.3400 (0.4606)  loss_classifier: 0.1070 (0.1598)  loss_box_reg: 0.0810 (0.1440)  loss_objectness: 0.1085 (0.1127)  loss_rpn_box_reg: 0.0168 (0.0441)  time: 0.3237  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [7]  [ 520/1229]  eta: 0:03:51  lr: 0.005000  loss: 0.3916 (0.4596)  loss_classifier: 0.1324 (0.1596)  loss_box_reg: 0.1112 (0.1436)  loss_objectness: 0.1030 (0.1126)  loss_rpn_box_reg: 0.0319 (0.0438)  time: 0.3178  data: 0.1425  max mem: 4022\n",
      "Training Epoch: [7]  [ 530/1229]  eta: 0:03:48  lr: 0.005000  loss: 0.3916 (0.4603)  loss_classifier: 0.1386 (0.1600)  loss_box_reg: 0.1209 (0.1436)  loss_objectness: 0.1015 (0.1128)  loss_rpn_box_reg: 0.0313 (0.0439)  time: 0.3201  data: 0.1424  max mem: 4022\n",
      "Training Epoch: [7]  [ 540/1229]  eta: 0:03:44  lr: 0.005000  loss: 0.4568 (0.4610)  loss_classifier: 0.1523 (0.1601)  loss_box_reg: 0.1366 (0.1441)  loss_objectness: 0.1016 (0.1127)  loss_rpn_box_reg: 0.0292 (0.0440)  time: 0.3259  data: 0.1438  max mem: 4022\n",
      "Training Epoch: [7]  [ 550/1229]  eta: 0:03:41  lr: 0.005000  loss: 0.3919 (0.4606)  loss_classifier: 0.1523 (0.1601)  loss_box_reg: 0.1162 (0.1439)  loss_objectness: 0.1016 (0.1130)  loss_rpn_box_reg: 0.0186 (0.0437)  time: 0.3263  data: 0.1431  max mem: 4022\n",
      "Training Epoch: [7]  [ 560/1229]  eta: 0:03:38  lr: 0.005000  loss: 0.3583 (0.4606)  loss_classifier: 0.1373 (0.1602)  loss_box_reg: 0.1132 (0.1441)  loss_objectness: 0.0959 (0.1128)  loss_rpn_box_reg: 0.0127 (0.0435)  time: 0.3235  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [7]  [ 570/1229]  eta: 0:03:34  lr: 0.005000  loss: 0.3560 (0.4602)  loss_classifier: 0.1373 (0.1601)  loss_box_reg: 0.1005 (0.1439)  loss_objectness: 0.0760 (0.1126)  loss_rpn_box_reg: 0.0251 (0.0436)  time: 0.3236  data: 0.1441  max mem: 4022\n",
      "Training Epoch: [7]  [ 580/1229]  eta: 0:03:31  lr: 0.005000  loss: 0.4021 (0.4614)  loss_classifier: 0.1293 (0.1606)  loss_box_reg: 0.1120 (0.1444)  loss_objectness: 0.0859 (0.1123)  loss_rpn_box_reg: 0.0387 (0.0440)  time: 0.3300  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [7]  [ 590/1229]  eta: 0:03:28  lr: 0.005000  loss: 0.4021 (0.4609)  loss_classifier: 0.1484 (0.1605)  loss_box_reg: 0.1428 (0.1441)  loss_objectness: 0.0860 (0.1123)  loss_rpn_box_reg: 0.0398 (0.0440)  time: 0.3311  data: 0.1430  max mem: 4022\n",
      "Training Epoch: [7]  [ 600/1229]  eta: 0:03:25  lr: 0.005000  loss: 0.4446 (0.4616)  loss_classifier: 0.1495 (0.1604)  loss_box_reg: 0.1267 (0.1435)  loss_objectness: 0.1199 (0.1136)  loss_rpn_box_reg: 0.0398 (0.0442)  time: 0.3274  data: 0.1440  max mem: 4022\n",
      "Training Epoch: [7]  [ 610/1229]  eta: 0:03:22  lr: 0.005000  loss: 0.3854 (0.4600)  loss_classifier: 0.1231 (0.1598)  loss_box_reg: 0.1043 (0.1426)  loss_objectness: 0.1213 (0.1137)  loss_rpn_box_reg: 0.0292 (0.0439)  time: 0.3296  data: 0.1433  max mem: 4022\n",
      "Training Epoch: [7]  [ 620/1229]  eta: 0:03:18  lr: 0.005000  loss: 0.4300 (0.4614)  loss_classifier: 0.1400 (0.1604)  loss_box_reg: 0.1234 (0.1431)  loss_objectness: 0.1202 (0.1140)  loss_rpn_box_reg: 0.0292 (0.0440)  time: 0.3279  data: 0.1435  max mem: 4022\n",
      "Training Epoch: [7]  [ 630/1229]  eta: 0:03:15  lr: 0.005000  loss: 0.4869 (0.4614)  loss_classifier: 0.1692 (0.1603)  loss_box_reg: 0.1568 (0.1429)  loss_objectness: 0.1247 (0.1142)  loss_rpn_box_reg: 0.0362 (0.0441)  time: 0.3280  data: 0.1426  max mem: 4022\n",
      "Training Epoch: [7]  [ 640/1229]  eta: 0:03:12  lr: 0.005000  loss: 0.4419 (0.4603)  loss_classifier: 0.1287 (0.1598)  loss_box_reg: 0.1216 (0.1423)  loss_objectness: 0.1019 (0.1139)  loss_rpn_box_reg: 0.0328 (0.0444)  time: 0.3361  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [7]  [ 650/1229]  eta: 0:03:09  lr: 0.005000  loss: 0.4109 (0.4608)  loss_classifier: 0.1287 (0.1599)  loss_box_reg: 0.1216 (0.1425)  loss_objectness: 0.0847 (0.1137)  loss_rpn_box_reg: 0.0351 (0.0447)  time: 0.3342  data: 0.1430  max mem: 4022\n",
      "Training Epoch: [7]  [ 660/1229]  eta: 0:03:05  lr: 0.005000  loss: 0.4109 (0.4598)  loss_classifier: 0.1499 (0.1597)  loss_box_reg: 0.1291 (0.1423)  loss_objectness: 0.0935 (0.1134)  loss_rpn_box_reg: 0.0221 (0.0444)  time: 0.3241  data: 0.1432  max mem: 4022\n",
      "Training Epoch: [7]  [ 670/1229]  eta: 0:03:02  lr: 0.005000  loss: 0.3205 (0.4581)  loss_classifier: 0.1130 (0.1592)  loss_box_reg: 0.0837 (0.1416)  loss_objectness: 0.0743 (0.1132)  loss_rpn_box_reg: 0.0184 (0.0442)  time: 0.3272  data: 0.1447  max mem: 4022\n",
      "Training Epoch: [7]  [ 680/1229]  eta: 0:02:59  lr: 0.005000  loss: 0.3593 (0.4582)  loss_classifier: 0.1205 (0.1592)  loss_box_reg: 0.0815 (0.1414)  loss_objectness: 0.0895 (0.1134)  loss_rpn_box_reg: 0.0215 (0.0442)  time: 0.3265  data: 0.1431  max mem: 4022\n",
      "Training Epoch: [7]  [ 690/1229]  eta: 0:02:56  lr: 0.005000  loss: 0.4555 (0.4593)  loss_classifier: 0.1622 (0.1593)  loss_box_reg: 0.1255 (0.1420)  loss_objectness: 0.0981 (0.1136)  loss_rpn_box_reg: 0.0229 (0.0444)  time: 0.3249  data: 0.1420  max mem: 4022\n",
      "Training Epoch: [7]  [ 700/1229]  eta: 0:02:52  lr: 0.005000  loss: 0.3894 (0.4587)  loss_classifier: 0.1444 (0.1591)  loss_box_reg: 0.0805 (0.1414)  loss_objectness: 0.1005 (0.1136)  loss_rpn_box_reg: 0.0229 (0.0446)  time: 0.3339  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [7]  [ 710/1229]  eta: 0:02:49  lr: 0.005000  loss: 0.4255 (0.4594)  loss_classifier: 0.1417 (0.1592)  loss_box_reg: 0.1023 (0.1418)  loss_objectness: 0.0896 (0.1136)  loss_rpn_box_reg: 0.0344 (0.0448)  time: 0.3303  data: 0.1437  max mem: 4022\n",
      "Training Epoch: [7]  [ 720/1229]  eta: 0:02:46  lr: 0.005000  loss: 0.4768 (0.4600)  loss_classifier: 0.1417 (0.1592)  loss_box_reg: 0.1523 (0.1420)  loss_objectness: 0.0923 (0.1137)  loss_rpn_box_reg: 0.0503 (0.0451)  time: 0.3232  data: 0.1444  max mem: 4022\n",
      "Training Epoch: [7]  [ 730/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.5036 (0.4622)  loss_classifier: 0.1732 (0.1599)  loss_box_reg: 0.1575 (0.1428)  loss_objectness: 0.1228 (0.1140)  loss_rpn_box_reg: 0.0494 (0.0454)  time: 0.3233  data: 0.1449  max mem: 4022\n",
      "Training Epoch: [7]  [ 740/1229]  eta: 0:02:39  lr: 0.005000  loss: 0.4999 (0.4616)  loss_classifier: 0.1579 (0.1596)  loss_box_reg: 0.1482 (0.1426)  loss_objectness: 0.1229 (0.1138)  loss_rpn_box_reg: 0.0463 (0.0455)  time: 0.3297  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [7]  [ 750/1229]  eta: 0:02:36  lr: 0.005000  loss: 0.3392 (0.4612)  loss_classifier: 0.1184 (0.1593)  loss_box_reg: 0.0949 (0.1426)  loss_objectness: 0.0838 (0.1136)  loss_rpn_box_reg: 0.0329 (0.0457)  time: 0.3365  data: 0.1422  max mem: 4022\n",
      "Training Epoch: [7]  [ 760/1229]  eta: 0:02:33  lr: 0.005000  loss: 0.4510 (0.4627)  loss_classifier: 0.1454 (0.1598)  loss_box_reg: 0.1204 (0.1428)  loss_objectness: 0.1045 (0.1139)  loss_rpn_box_reg: 0.0425 (0.0462)  time: 0.3329  data: 0.1481  max mem: 4022\n",
      "Training Epoch: [7]  [ 770/1229]  eta: 0:02:30  lr: 0.005000  loss: 0.5344 (0.4630)  loss_classifier: 0.1744 (0.1597)  loss_box_reg: 0.1353 (0.1429)  loss_objectness: 0.1120 (0.1138)  loss_rpn_box_reg: 0.0539 (0.0466)  time: 0.3306  data: 0.1479  max mem: 4022\n",
      "Training Epoch: [7]  [ 780/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.4078 (0.4627)  loss_classifier: 0.1589 (0.1599)  loss_box_reg: 0.1352 (0.1429)  loss_objectness: 0.0852 (0.1136)  loss_rpn_box_reg: 0.0302 (0.0464)  time: 0.3340  data: 0.1456  max mem: 4022\n",
      "Training Epoch: [7]  [ 790/1229]  eta: 0:02:23  lr: 0.005000  loss: 0.4078 (0.4622)  loss_classifier: 0.1442 (0.1596)  loss_box_reg: 0.1196 (0.1427)  loss_objectness: 0.0852 (0.1134)  loss_rpn_box_reg: 0.0223 (0.0465)  time: 0.3314  data: 0.1450  max mem: 4022\n",
      "Training Epoch: [7]  [ 800/1229]  eta: 0:02:20  lr: 0.005000  loss: 0.4100 (0.4625)  loss_classifier: 0.1163 (0.1596)  loss_box_reg: 0.0993 (0.1425)  loss_objectness: 0.0914 (0.1136)  loss_rpn_box_reg: 0.0350 (0.0468)  time: 0.3258  data: 0.1461  max mem: 4022\n",
      "Training Epoch: [7]  [ 810/1229]  eta: 0:02:17  lr: 0.005000  loss: 0.3932 (0.4614)  loss_classifier: 0.1163 (0.1591)  loss_box_reg: 0.0912 (0.1424)  loss_objectness: 0.0998 (0.1134)  loss_rpn_box_reg: 0.0299 (0.0465)  time: 0.3284  data: 0.1448  max mem: 4022\n",
      "Training Epoch: [7]  [ 820/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.3175 (0.4607)  loss_classifier: 0.0941 (0.1588)  loss_box_reg: 0.0687 (0.1418)  loss_objectness: 0.0917 (0.1136)  loss_rpn_box_reg: 0.0261 (0.0465)  time: 0.3342  data: 0.1451  max mem: 4022\n",
      "Training Epoch: [7]  [ 830/1229]  eta: 0:02:10  lr: 0.005000  loss: 0.2706 (0.4594)  loss_classifier: 0.0941 (0.1584)  loss_box_reg: 0.0687 (0.1414)  loss_objectness: 0.0985 (0.1134)  loss_rpn_box_reg: 0.0208 (0.0463)  time: 0.3347  data: 0.1478  max mem: 4022\n",
      "Training Epoch: [7]  [ 840/1229]  eta: 0:02:07  lr: 0.005000  loss: 0.4392 (0.4599)  loss_classifier: 0.1494 (0.1584)  loss_box_reg: 0.1152 (0.1417)  loss_objectness: 0.1044 (0.1136)  loss_rpn_box_reg: 0.0253 (0.0463)  time: 0.3266  data: 0.1456  max mem: 4022\n",
      "Training Epoch: [7]  [ 850/1229]  eta: 0:02:04  lr: 0.005000  loss: 0.4392 (0.4597)  loss_classifier: 0.1363 (0.1583)  loss_box_reg: 0.1152 (0.1416)  loss_objectness: 0.1115 (0.1136)  loss_rpn_box_reg: 0.0297 (0.0462)  time: 0.3271  data: 0.1444  max mem: 4022\n",
      "Training Epoch: [7]  [ 860/1229]  eta: 0:02:00  lr: 0.005000  loss: 0.3368 (0.4590)  loss_classifier: 0.1292 (0.1581)  loss_box_reg: 0.0665 (0.1416)  loss_objectness: 0.0690 (0.1133)  loss_rpn_box_reg: 0.0176 (0.0461)  time: 0.3353  data: 0.1441  max mem: 4022\n",
      "Training Epoch: [7]  [ 870/1229]  eta: 0:01:57  lr: 0.005000  loss: 0.3709 (0.4589)  loss_classifier: 0.1188 (0.1581)  loss_box_reg: 0.0980 (0.1414)  loss_objectness: 0.0791 (0.1133)  loss_rpn_box_reg: 0.0269 (0.0461)  time: 0.3317  data: 0.1449  max mem: 4022\n",
      "Training Epoch: [7]  [ 880/1229]  eta: 0:01:54  lr: 0.005000  loss: 0.3719 (0.4584)  loss_classifier: 0.1188 (0.1579)  loss_box_reg: 0.1077 (0.1412)  loss_objectness: 0.0915 (0.1134)  loss_rpn_box_reg: 0.0204 (0.0459)  time: 0.3273  data: 0.1467  max mem: 4022\n",
      "Training Epoch: [7]  [ 890/1229]  eta: 0:01:51  lr: 0.005000  loss: 0.3694 (0.4571)  loss_classifier: 0.1264 (0.1575)  loss_box_reg: 0.1049 (0.1407)  loss_objectness: 0.0796 (0.1132)  loss_rpn_box_reg: 0.0160 (0.0457)  time: 0.3313  data: 0.1467  max mem: 4022\n",
      "Training Epoch: [7]  [ 900/1229]  eta: 0:01:47  lr: 0.005000  loss: 0.3449 (0.4565)  loss_classifier: 0.1190 (0.1573)  loss_box_reg: 0.0966 (0.1405)  loss_objectness: 0.0871 (0.1132)  loss_rpn_box_reg: 0.0244 (0.0456)  time: 0.3348  data: 0.1481  max mem: 4022\n",
      "Training Epoch: [7]  [ 910/1229]  eta: 0:01:44  lr: 0.005000  loss: 0.4728 (0.4582)  loss_classifier: 0.1467 (0.1577)  loss_box_reg: 0.1247 (0.1411)  loss_objectness: 0.1053 (0.1136)  loss_rpn_box_reg: 0.0294 (0.0458)  time: 0.3323  data: 0.1469  max mem: 4022\n",
      "Training Epoch: [7]  [ 920/1229]  eta: 0:01:41  lr: 0.005000  loss: 0.6090 (0.4604)  loss_classifier: 0.2086 (0.1585)  loss_box_reg: 0.1932 (0.1420)  loss_objectness: 0.1392 (0.1140)  loss_rpn_box_reg: 0.0396 (0.0459)  time: 0.3265  data: 0.1464  max mem: 4022\n",
      "Training Epoch: [7]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.5161 (0.4601)  loss_classifier: 0.1845 (0.1585)  loss_box_reg: 0.1695 (0.1421)  loss_objectness: 0.1074 (0.1137)  loss_rpn_box_reg: 0.0271 (0.0457)  time: 0.3273  data: 0.1483  max mem: 4022\n",
      "Training Epoch: [7]  [ 940/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.3610 (0.4598)  loss_classifier: 0.1314 (0.1584)  loss_box_reg: 0.1069 (0.1419)  loss_objectness: 0.0813 (0.1139)  loss_rpn_box_reg: 0.0150 (0.0456)  time: 0.3318  data: 0.1484  max mem: 4022\n",
      "Training Epoch: [7]  [ 950/1229]  eta: 0:01:31  lr: 0.005000  loss: 0.3017 (0.4584)  loss_classifier: 0.1044 (0.1579)  loss_box_reg: 0.0865 (0.1413)  loss_objectness: 0.0659 (0.1136)  loss_rpn_box_reg: 0.0230 (0.0456)  time: 0.3282  data: 0.1461  max mem: 4022\n",
      "Training Epoch: [7]  [ 960/1229]  eta: 0:01:28  lr: 0.005000  loss: 0.4024 (0.4590)  loss_classifier: 0.1235 (0.1582)  loss_box_reg: 0.1047 (0.1415)  loss_objectness: 0.0759 (0.1137)  loss_rpn_box_reg: 0.0269 (0.0456)  time: 0.3346  data: 0.1462  max mem: 4022\n",
      "Training Epoch: [7]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.4141 (0.4585)  loss_classifier: 0.1703 (0.1581)  loss_box_reg: 0.1090 (0.1412)  loss_objectness: 0.0754 (0.1137)  loss_rpn_box_reg: 0.0233 (0.0455)  time: 0.3399  data: 0.1488  max mem: 4022\n",
      "Training Epoch: [7]  [ 980/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.3202 (0.4575)  loss_classifier: 0.1102 (0.1577)  loss_box_reg: 0.0826 (0.1407)  loss_objectness: 0.0896 (0.1137)  loss_rpn_box_reg: 0.0217 (0.0453)  time: 0.3258  data: 0.1475  max mem: 4022\n",
      "Training Epoch: [7]  [ 990/1229]  eta: 0:01:18  lr: 0.005000  loss: 0.3978 (0.4571)  loss_classifier: 0.1279 (0.1576)  loss_box_reg: 0.0922 (0.1406)  loss_objectness: 0.1032 (0.1136)  loss_rpn_box_reg: 0.0257 (0.0453)  time: 0.3261  data: 0.1476  max mem: 4022\n",
      "Training Epoch: [7]  [1000/1229]  eta: 0:01:15  lr: 0.005000  loss: 0.3998 (0.4570)  loss_classifier: 0.1310 (0.1576)  loss_box_reg: 0.1097 (0.1408)  loss_objectness: 0.0753 (0.1134)  loss_rpn_box_reg: 0.0202 (0.0452)  time: 0.3356  data: 0.1472  max mem: 4022\n",
      "Training Epoch: [7]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.4302 (0.4575)  loss_classifier: 0.1310 (0.1577)  loss_box_reg: 0.1520 (0.1413)  loss_objectness: 0.0855 (0.1133)  loss_rpn_box_reg: 0.0202 (0.0451)  time: 0.3315  data: 0.1454  max mem: 4022\n",
      "Training Epoch: [7]  [1020/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.5300 (0.4591)  loss_classifier: 0.1791 (0.1582)  loss_box_reg: 0.1617 (0.1419)  loss_objectness: 0.1169 (0.1136)  loss_rpn_box_reg: 0.0277 (0.0454)  time: 0.3285  data: 0.1483  max mem: 4022\n",
      "Training Epoch: [7]  [1030/1229]  eta: 0:01:05  lr: 0.005000  loss: 0.4788 (0.4590)  loss_classifier: 0.1534 (0.1581)  loss_box_reg: 0.1460 (0.1419)  loss_objectness: 0.0845 (0.1135)  loss_rpn_box_reg: 0.0506 (0.0454)  time: 0.3337  data: 0.1489  max mem: 4022\n",
      "Training Epoch: [7]  [1040/1229]  eta: 0:01:02  lr: 0.005000  loss: 0.4259 (0.4593)  loss_classifier: 0.1341 (0.1583)  loss_box_reg: 0.1409 (0.1419)  loss_objectness: 0.1088 (0.1137)  loss_rpn_box_reg: 0.0298 (0.0454)  time: 0.3356  data: 0.1477  max mem: 4022\n",
      "Training Epoch: [7]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.4179 (0.4587)  loss_classifier: 0.1266 (0.1580)  loss_box_reg: 0.0945 (0.1418)  loss_objectness: 0.1117 (0.1136)  loss_rpn_box_reg: 0.0271 (0.0454)  time: 0.3348  data: 0.1551  max mem: 4022\n",
      "Training Epoch: [7]  [1060/1229]  eta: 0:00:55  lr: 0.005000  loss: 0.4770 (0.4602)  loss_classifier: 0.1378 (0.1585)  loss_box_reg: 0.1117 (0.1422)  loss_objectness: 0.1121 (0.1139)  loss_rpn_box_reg: 0.0243 (0.0456)  time: 0.3366  data: 0.1578  max mem: 4022\n",
      "Training Epoch: [7]  [1070/1229]  eta: 0:00:52  lr: 0.005000  loss: 0.5307 (0.4595)  loss_classifier: 0.1766 (0.1584)  loss_box_reg: 0.1466 (0.1418)  loss_objectness: 0.1170 (0.1139)  loss_rpn_box_reg: 0.0253 (0.0454)  time: 0.3359  data: 0.1514  max mem: 4022\n",
      "Training Epoch: [7]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.3394 (0.4596)  loss_classifier: 0.1298 (0.1584)  loss_box_reg: 0.0950 (0.1418)  loss_objectness: 0.1125 (0.1140)  loss_rpn_box_reg: 0.0233 (0.0454)  time: 0.3284  data: 0.1492  max mem: 4022\n",
      "Training Epoch: [7]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.3983 (0.4592)  loss_classifier: 0.1499 (0.1583)  loss_box_reg: 0.0950 (0.1417)  loss_objectness: 0.1219 (0.1139)  loss_rpn_box_reg: 0.0220 (0.0453)  time: 0.3320  data: 0.1475  max mem: 4022\n",
      "Training Epoch: [7]  [1100/1229]  eta: 0:00:42  lr: 0.005000  loss: 0.3952 (0.4595)  loss_classifier: 0.1383 (0.1584)  loss_box_reg: 0.0929 (0.1418)  loss_objectness: 0.1167 (0.1140)  loss_rpn_box_reg: 0.0255 (0.0452)  time: 0.3368  data: 0.1463  max mem: 4022\n",
      "Training Epoch: [7]  [1110/1229]  eta: 0:00:39  lr: 0.005000  loss: 0.3952 (0.4592)  loss_classifier: 0.1293 (0.1584)  loss_box_reg: 0.0932 (0.1420)  loss_objectness: 0.0879 (0.1138)  loss_rpn_box_reg: 0.0251 (0.0451)  time: 0.3358  data: 0.1472  max mem: 4022\n",
      "Training Epoch: [7]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.3457 (0.4586)  loss_classifier: 0.1269 (0.1582)  loss_box_reg: 0.1207 (0.1418)  loss_objectness: 0.0802 (0.1136)  loss_rpn_box_reg: 0.0108 (0.0450)  time: 0.3358  data: 0.1475  max mem: 4022\n",
      "Training Epoch: [7]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.3078 (0.4584)  loss_classifier: 0.1269 (0.1582)  loss_box_reg: 0.1207 (0.1421)  loss_objectness: 0.0737 (0.1133)  loss_rpn_box_reg: 0.0140 (0.0448)  time: 0.3366  data: 0.1450  max mem: 4022\n",
      "Training Epoch: [7]  [1140/1229]  eta: 0:00:29  lr: 0.005000  loss: 0.3811 (0.4583)  loss_classifier: 0.1343 (0.1582)  loss_box_reg: 0.1170 (0.1419)  loss_objectness: 0.0709 (0.1135)  loss_rpn_box_reg: 0.0221 (0.0448)  time: 0.3320  data: 0.1452  max mem: 4022\n",
      "Training Epoch: [7]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.3511 (0.4582)  loss_classifier: 0.1552 (0.1582)  loss_box_reg: 0.1149 (0.1420)  loss_objectness: 0.0809 (0.1132)  loss_rpn_box_reg: 0.0287 (0.0448)  time: 0.3361  data: 0.1482  max mem: 4022\n",
      "Training Epoch: [7]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.4320 (0.4594)  loss_classifier: 0.1552 (0.1586)  loss_box_reg: 0.1215 (0.1425)  loss_objectness: 0.0828 (0.1133)  loss_rpn_box_reg: 0.0317 (0.0449)  time: 0.3347  data: 0.1441  max mem: 4022\n",
      "Training Epoch: [7]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.4946 (0.4601)  loss_classifier: 0.1664 (0.1589)  loss_box_reg: 0.1597 (0.1429)  loss_objectness: 0.1006 (0.1134)  loss_rpn_box_reg: 0.0285 (0.0448)  time: 0.3261  data: 0.1420  max mem: 4022\n",
      "Training Epoch: [7]  [1180/1229]  eta: 0:00:16  lr: 0.005000  loss: 0.5409 (0.4607)  loss_classifier: 0.1565 (0.1591)  loss_box_reg: 0.1535 (0.1432)  loss_objectness: 0.1009 (0.1136)  loss_rpn_box_reg: 0.0259 (0.0449)  time: 0.3303  data: 0.1474  max mem: 4022\n",
      "Training Epoch: [7]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.4234 (0.4604)  loss_classifier: 0.1143 (0.1590)  loss_box_reg: 0.1025 (0.1429)  loss_objectness: 0.0984 (0.1137)  loss_rpn_box_reg: 0.0344 (0.0449)  time: 0.3339  data: 0.1477  max mem: 4022\n",
      "Training Epoch: [7]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.3995 (0.4607)  loss_classifier: 0.1106 (0.1591)  loss_box_reg: 0.0996 (0.1429)  loss_objectness: 0.1125 (0.1138)  loss_rpn_box_reg: 0.0304 (0.0449)  time: 0.3323  data: 0.1469  max mem: 4022\n",
      "Training Epoch: [7]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.4026 (0.4605)  loss_classifier: 0.1536 (0.1591)  loss_box_reg: 0.1291 (0.1429)  loss_objectness: 0.1125 (0.1137)  loss_rpn_box_reg: 0.0267 (0.0449)  time: 0.3259  data: 0.1463  max mem: 4022\n",
      "Training Epoch: [7]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.4170 (0.4605)  loss_classifier: 0.1453 (0.1590)  loss_box_reg: 0.1023 (0.1427)  loss_objectness: 0.1032 (0.1138)  loss_rpn_box_reg: 0.0334 (0.0450)  time: 0.3307  data: 0.1456  max mem: 4022\n",
      "Training Epoch: [7]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4026 (0.4604)  loss_classifier: 0.1475 (0.1589)  loss_box_reg: 0.1023 (0.1426)  loss_objectness: 0.1032 (0.1138)  loss_rpn_box_reg: 0.0234 (0.0450)  time: 0.3347  data: 0.1470  max mem: 4022\n",
      "Training Epoch: [7] Total time: 0:06:44 (0.3289 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:02:37  model_time: 0.3600 (0.3600)  evaluator_time: 0.0030 (0.0030)  time: 0.5110  data: 0.1450  max mem: 4022\n",
      "Test:  [100/308]  eta: 0:00:34  model_time: 0.1060 (0.1145)  evaluator_time: 0.0080 (0.0095)  time: 0.1706  data: 0.0459  max mem: 4022\n",
      "Test:  [200/308]  eta: 0:00:17  model_time: 0.1150 (0.1131)  evaluator_time: 0.0040 (0.0084)  time: 0.1644  data: 0.0398  max mem: 4022\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.1020 (0.1119)  evaluator_time: 0.0060 (0.0083)  time: 0.1596  data: 0.0455  max mem: 4022\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.1020 (0.1117)  evaluator_time: 0.0040 (0.0083)  time: 0.1562  data: 0.0437  max mem: 4022\n",
      "Test: Total time: 0:00:49 (0.1606 s / it)\n",
      "Averaged stats: model_time: 0.1020 (0.1117)  evaluator_time: 0.0040 (0.0083)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.080\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.137\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.096\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.252\n",
      "Testing Epoch: [7]  [  0/308]  eta: 0:00:49  lr: 0.005000  loss: 0.2144 (0.2144)  loss_classifier: 0.0931 (0.0931)  loss_box_reg: 0.0655 (0.0655)  loss_objectness: 0.0491 (0.0491)  loss_rpn_box_reg: 0.0067 (0.0067)  time: 0.1600  data: 0.0360  max mem: 4022\n",
      "Testing Epoch: [7]  [100/308]  eta: 0:00:37  lr: 0.005000  loss: 0.3363 (0.5022)  loss_classifier: 0.1256 (0.1644)  loss_box_reg: 0.1293 (0.1629)  loss_objectness: 0.0767 (0.1166)  loss_rpn_box_reg: 0.0233 (0.0582)  time: 0.1861  data: 0.0479  max mem: 4022\n",
      "Testing Epoch: [7]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.3954 (0.4788)  loss_classifier: 0.1392 (0.1583)  loss_box_reg: 0.1395 (0.1556)  loss_objectness: 0.0900 (0.1097)  loss_rpn_box_reg: 0.0270 (0.0551)  time: 0.1813  data: 0.0369  max mem: 4022\n",
      "Testing Epoch: [7]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5352 (0.4790)  loss_classifier: 0.1700 (0.1594)  loss_box_reg: 0.1508 (0.1585)  loss_objectness: 0.1018 (0.1074)  loss_rpn_box_reg: 0.0283 (0.0537)  time: 0.1784  data: 0.0490  max mem: 4022\n",
      "Testing Epoch: [7]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.4645 (0.4788)  loss_classifier: 0.1526 (0.1595)  loss_box_reg: 0.1450 (0.1587)  loss_objectness: 0.0947 (0.1074)  loss_rpn_box_reg: 0.0247 (0.0532)  time: 0.1760  data: 0.0461  max mem: 4022\n",
      "Testing Epoch: [7] Total time: 0:00:55 (0.1796 s / it)\n",
      "Training Epoch: [8]  [   0/1229]  eta: 0:06:23  lr: 0.005000  loss: 0.3284 (0.3284)  loss_classifier: 0.1267 (0.1267)  loss_box_reg: 0.1099 (0.1099)  loss_objectness: 0.0853 (0.0853)  loss_rpn_box_reg: 0.0065 (0.0065)  time: 0.3120  data: 0.1440  max mem: 4022\n",
      "Training Epoch: [8]  [  10/1229]  eta: 0:06:36  lr: 0.005000  loss: 0.3284 (0.4061)  loss_classifier: 0.1267 (0.1376)  loss_box_reg: 0.1089 (0.1269)  loss_objectness: 0.0717 (0.0967)  loss_rpn_box_reg: 0.0126 (0.0449)  time: 0.3254  data: 0.1380  max mem: 4022\n",
      "Training Epoch: [8]  [  20/1229]  eta: 0:06:27  lr: 0.005000  loss: 0.3685 (0.4006)  loss_classifier: 0.1212 (0.1416)  loss_box_reg: 0.1071 (0.1264)  loss_objectness: 0.0707 (0.0936)  loss_rpn_box_reg: 0.0158 (0.0391)  time: 0.3210  data: 0.1369  max mem: 4022\n",
      "Training Epoch: [8]  [  30/1229]  eta: 0:06:23  lr: 0.005000  loss: 0.3591 (0.3940)  loss_classifier: 0.1025 (0.1370)  loss_box_reg: 0.1005 (0.1172)  loss_objectness: 0.0934 (0.0965)  loss_rpn_box_reg: 0.0212 (0.0433)  time: 0.3168  data: 0.1358  max mem: 4022\n",
      "Training Epoch: [8]  [  40/1229]  eta: 0:06:19  lr: 0.005000  loss: 0.3138 (0.3895)  loss_classifier: 0.1004 (0.1371)  loss_box_reg: 0.0972 (0.1177)  loss_objectness: 0.0934 (0.0957)  loss_rpn_box_reg: 0.0181 (0.0390)  time: 0.3181  data: 0.1372  max mem: 4022\n",
      "Training Epoch: [8]  [  50/1229]  eta: 0:06:17  lr: 0.005000  loss: 0.4305 (0.4245)  loss_classifier: 0.1474 (0.1478)  loss_box_reg: 0.1196 (0.1273)  loss_objectness: 0.1074 (0.1065)  loss_rpn_box_reg: 0.0221 (0.0429)  time: 0.3214  data: 0.1385  max mem: 4022\n",
      "Training Epoch: [8]  [  60/1229]  eta: 0:06:15  lr: 0.005000  loss: 0.5292 (0.4409)  loss_classifier: 0.1824 (0.1535)  loss_box_reg: 0.1484 (0.1353)  loss_objectness: 0.1074 (0.1044)  loss_rpn_box_reg: 0.0195 (0.0477)  time: 0.3261  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [8]  [  70/1229]  eta: 0:06:13  lr: 0.005000  loss: 0.3372 (0.4340)  loss_classifier: 0.1310 (0.1512)  loss_box_reg: 0.1098 (0.1327)  loss_objectness: 0.0827 (0.1015)  loss_rpn_box_reg: 0.0195 (0.0485)  time: 0.3270  data: 0.1375  max mem: 4022\n",
      "Training Epoch: [8]  [  80/1229]  eta: 0:06:10  lr: 0.005000  loss: 0.3222 (0.4259)  loss_classifier: 0.1112 (0.1480)  loss_box_reg: 0.0782 (0.1305)  loss_objectness: 0.0768 (0.0998)  loss_rpn_box_reg: 0.0310 (0.0476)  time: 0.3241  data: 0.1371  max mem: 4022\n",
      "Training Epoch: [8]  [  90/1229]  eta: 0:06:07  lr: 0.005000  loss: 0.3690 (0.4321)  loss_classifier: 0.1209 (0.1512)  loss_box_reg: 0.1107 (0.1336)  loss_objectness: 0.0824 (0.1001)  loss_rpn_box_reg: 0.0263 (0.0472)  time: 0.3248  data: 0.1387  max mem: 4022\n",
      "Training Epoch: [8]  [ 100/1229]  eta: 0:06:04  lr: 0.005000  loss: 0.4506 (0.4353)  loss_classifier: 0.1594 (0.1523)  loss_box_reg: 0.1052 (0.1333)  loss_objectness: 0.0924 (0.1017)  loss_rpn_box_reg: 0.0301 (0.0480)  time: 0.3233  data: 0.1391  max mem: 4022\n",
      "Training Epoch: [8]  [ 110/1229]  eta: 0:06:00  lr: 0.005000  loss: 0.4125 (0.4342)  loss_classifier: 0.1410 (0.1520)  loss_box_reg: 0.0942 (0.1339)  loss_objectness: 0.0981 (0.1013)  loss_rpn_box_reg: 0.0301 (0.0470)  time: 0.3197  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [8]  [ 120/1229]  eta: 0:05:58  lr: 0.005000  loss: 0.3745 (0.4337)  loss_classifier: 0.1160 (0.1506)  loss_box_reg: 0.0923 (0.1343)  loss_objectness: 0.0978 (0.1023)  loss_rpn_box_reg: 0.0387 (0.0465)  time: 0.3266  data: 0.1425  max mem: 4022\n",
      "Training Epoch: [8]  [ 130/1229]  eta: 0:05:55  lr: 0.005000  loss: 0.3745 (0.4338)  loss_classifier: 0.1105 (0.1499)  loss_box_reg: 0.0906 (0.1325)  loss_objectness: 0.0916 (0.1022)  loss_rpn_box_reg: 0.0410 (0.0492)  time: 0.3321  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [8]  [ 140/1229]  eta: 0:05:52  lr: 0.005000  loss: 0.2917 (0.4270)  loss_classifier: 0.1044 (0.1482)  loss_box_reg: 0.0927 (0.1309)  loss_objectness: 0.0855 (0.1010)  loss_rpn_box_reg: 0.0181 (0.0468)  time: 0.3264  data: 0.1400  max mem: 4022\n",
      "Training Epoch: [8]  [ 150/1229]  eta: 0:05:49  lr: 0.005000  loss: 0.3124 (0.4247)  loss_classifier: 0.1101 (0.1486)  loss_box_reg: 0.0927 (0.1297)  loss_objectness: 0.0845 (0.1007)  loss_rpn_box_reg: 0.0178 (0.0457)  time: 0.3244  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [8]  [ 160/1229]  eta: 0:05:46  lr: 0.005000  loss: 0.3124 (0.4169)  loss_classifier: 0.1055 (0.1459)  loss_box_reg: 0.0702 (0.1260)  loss_objectness: 0.0728 (0.0994)  loss_rpn_box_reg: 0.0225 (0.0456)  time: 0.3289  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [8]  [ 170/1229]  eta: 0:05:42  lr: 0.005000  loss: 0.3488 (0.4213)  loss_classifier: 0.1071 (0.1464)  loss_box_reg: 0.0935 (0.1276)  loss_objectness: 0.0690 (0.1001)  loss_rpn_box_reg: 0.0301 (0.0473)  time: 0.3222  data: 0.1383  max mem: 4022\n",
      "Training Epoch: [8]  [ 180/1229]  eta: 0:05:39  lr: 0.005000  loss: 0.3913 (0.4196)  loss_classifier: 0.1291 (0.1460)  loss_box_reg: 0.0996 (0.1270)  loss_objectness: 0.0969 (0.1000)  loss_rpn_box_reg: 0.0306 (0.0465)  time: 0.3173  data: 0.1381  max mem: 4022\n",
      "Training Epoch: [8]  [ 190/1229]  eta: 0:05:36  lr: 0.005000  loss: 0.4714 (0.4279)  loss_classifier: 0.1795 (0.1496)  loss_box_reg: 0.1166 (0.1299)  loss_objectness: 0.1057 (0.1012)  loss_rpn_box_reg: 0.0367 (0.0472)  time: 0.3259  data: 0.1378  max mem: 4022\n",
      "Training Epoch: [8]  [ 200/1229]  eta: 0:05:33  lr: 0.005000  loss: 0.4970 (0.4271)  loss_classifier: 0.1844 (0.1500)  loss_box_reg: 0.1349 (0.1300)  loss_objectness: 0.1057 (0.1010)  loss_rpn_box_reg: 0.0345 (0.0461)  time: 0.3253  data: 0.1381  max mem: 4022\n",
      "Training Epoch: [8]  [ 210/1229]  eta: 0:05:30  lr: 0.005000  loss: 0.4373 (0.4264)  loss_classifier: 0.1465 (0.1496)  loss_box_reg: 0.1349 (0.1310)  loss_objectness: 0.0869 (0.1008)  loss_rpn_box_reg: 0.0274 (0.0450)  time: 0.3257  data: 0.1373  max mem: 4022\n",
      "Training Epoch: [8]  [ 220/1229]  eta: 0:05:26  lr: 0.005000  loss: 0.4353 (0.4264)  loss_classifier: 0.1524 (0.1497)  loss_box_reg: 0.1444 (0.1320)  loss_objectness: 0.0754 (0.1004)  loss_rpn_box_reg: 0.0245 (0.0443)  time: 0.3266  data: 0.1380  max mem: 4022\n",
      "Training Epoch: [8]  [ 230/1229]  eta: 0:05:23  lr: 0.005000  loss: 0.4619 (0.4340)  loss_classifier: 0.1598 (0.1516)  loss_box_reg: 0.1625 (0.1354)  loss_objectness: 0.1024 (0.1022)  loss_rpn_box_reg: 0.0320 (0.0449)  time: 0.3218  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [8]  [ 240/1229]  eta: 0:05:20  lr: 0.005000  loss: 0.4481 (0.4333)  loss_classifier: 0.1439 (0.1517)  loss_box_reg: 0.1426 (0.1356)  loss_objectness: 0.1038 (0.1020)  loss_rpn_box_reg: 0.0275 (0.0441)  time: 0.3226  data: 0.1381  max mem: 4022\n",
      "Training Epoch: [8]  [ 250/1229]  eta: 0:05:17  lr: 0.005000  loss: 0.3891 (0.4319)  loss_classifier: 0.1590 (0.1519)  loss_box_reg: 0.1073 (0.1345)  loss_objectness: 0.1038 (0.1020)  loss_rpn_box_reg: 0.0259 (0.0435)  time: 0.3272  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [8]  [ 260/1229]  eta: 0:05:14  lr: 0.005000  loss: 0.3634 (0.4335)  loss_classifier: 0.1497 (0.1526)  loss_box_reg: 0.0996 (0.1344)  loss_objectness: 0.1002 (0.1028)  loss_rpn_box_reg: 0.0277 (0.0437)  time: 0.3300  data: 0.1402  max mem: 4022\n",
      "Training Epoch: [8]  [ 270/1229]  eta: 0:05:11  lr: 0.005000  loss: 0.3599 (0.4311)  loss_classifier: 0.1392 (0.1518)  loss_box_reg: 0.0996 (0.1338)  loss_objectness: 0.0868 (0.1021)  loss_rpn_box_reg: 0.0200 (0.0434)  time: 0.3272  data: 0.1376  max mem: 4022\n",
      "Training Epoch: [8]  [ 280/1229]  eta: 0:05:07  lr: 0.005000  loss: 0.3750 (0.4358)  loss_classifier: 0.1485 (0.1530)  loss_box_reg: 0.0983 (0.1346)  loss_objectness: 0.0961 (0.1043)  loss_rpn_box_reg: 0.0204 (0.0440)  time: 0.3225  data: 0.1377  max mem: 4022\n",
      "Training Epoch: [8]  [ 290/1229]  eta: 0:05:04  lr: 0.005000  loss: 0.3927 (0.4352)  loss_classifier: 0.1485 (0.1525)  loss_box_reg: 0.1016 (0.1345)  loss_objectness: 0.1123 (0.1043)  loss_rpn_box_reg: 0.0360 (0.0439)  time: 0.3163  data: 0.1395  max mem: 4022\n",
      "Training Epoch: [8]  [ 300/1229]  eta: 0:05:01  lr: 0.005000  loss: 0.3942 (0.4356)  loss_classifier: 0.1384 (0.1531)  loss_box_reg: 0.1109 (0.1346)  loss_objectness: 0.1108 (0.1044)  loss_rpn_box_reg: 0.0305 (0.0434)  time: 0.3237  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [8]  [ 310/1229]  eta: 0:04:57  lr: 0.005000  loss: 0.4537 (0.4388)  loss_classifier: 0.1660 (0.1542)  loss_box_reg: 0.1288 (0.1363)  loss_objectness: 0.1022 (0.1048)  loss_rpn_box_reg: 0.0222 (0.0434)  time: 0.3295  data: 0.1403  max mem: 4022\n",
      "Training Epoch: [8]  [ 320/1229]  eta: 0:04:54  lr: 0.005000  loss: 0.4737 (0.4414)  loss_classifier: 0.1691 (0.1553)  loss_box_reg: 0.1345 (0.1377)  loss_objectness: 0.0942 (0.1050)  loss_rpn_box_reg: 0.0251 (0.0433)  time: 0.3226  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [8]  [ 330/1229]  eta: 0:04:51  lr: 0.005000  loss: 0.5273 (0.4460)  loss_classifier: 0.1856 (0.1570)  loss_box_reg: 0.1437 (0.1396)  loss_objectness: 0.1220 (0.1058)  loss_rpn_box_reg: 0.0361 (0.0436)  time: 0.3257  data: 0.1422  max mem: 4022\n",
      "Training Epoch: [8]  [ 340/1229]  eta: 0:04:47  lr: 0.005000  loss: 0.4532 (0.4479)  loss_classifier: 0.1711 (0.1577)  loss_box_reg: 0.1059 (0.1402)  loss_objectness: 0.1261 (0.1066)  loss_rpn_box_reg: 0.0310 (0.0434)  time: 0.3226  data: 0.1404  max mem: 4022\n",
      "Training Epoch: [8]  [ 350/1229]  eta: 0:04:44  lr: 0.005000  loss: 0.4532 (0.4484)  loss_classifier: 0.1402 (0.1577)  loss_box_reg: 0.1058 (0.1406)  loss_objectness: 0.1151 (0.1066)  loss_rpn_box_reg: 0.0267 (0.0435)  time: 0.3182  data: 0.1387  max mem: 4022\n",
      "Training Epoch: [8]  [ 360/1229]  eta: 0:04:41  lr: 0.005000  loss: 0.4351 (0.4489)  loss_classifier: 0.1402 (0.1577)  loss_box_reg: 0.1773 (0.1411)  loss_objectness: 0.0810 (0.1067)  loss_rpn_box_reg: 0.0267 (0.0433)  time: 0.3209  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [8]  [ 370/1229]  eta: 0:04:38  lr: 0.005000  loss: 0.4184 (0.4470)  loss_classifier: 0.1640 (0.1576)  loss_box_reg: 0.1641 (0.1406)  loss_objectness: 0.0737 (0.1062)  loss_rpn_box_reg: 0.0156 (0.0426)  time: 0.3197  data: 0.1383  max mem: 4022\n",
      "Training Epoch: [8]  [ 380/1229]  eta: 0:04:34  lr: 0.005000  loss: 0.4348 (0.4501)  loss_classifier: 0.1711 (0.1587)  loss_box_reg: 0.1106 (0.1410)  loss_objectness: 0.1111 (0.1071)  loss_rpn_box_reg: 0.0187 (0.0433)  time: 0.3214  data: 0.1406  max mem: 4022\n",
      "Training Epoch: [8]  [ 390/1229]  eta: 0:04:31  lr: 0.005000  loss: 0.5855 (0.4524)  loss_classifier: 0.2004 (0.1598)  loss_box_reg: 0.1569 (0.1422)  loss_objectness: 0.1169 (0.1072)  loss_rpn_box_reg: 0.0407 (0.0432)  time: 0.3286  data: 0.1449  max mem: 4022\n",
      "Training Epoch: [8]  [ 400/1229]  eta: 0:04:28  lr: 0.005000  loss: 0.4509 (0.4524)  loss_classifier: 0.1788 (0.1596)  loss_box_reg: 0.1569 (0.1425)  loss_objectness: 0.0831 (0.1070)  loss_rpn_box_reg: 0.0345 (0.0433)  time: 0.3273  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [8]  [ 410/1229]  eta: 0:04:25  lr: 0.005000  loss: 0.3737 (0.4521)  loss_classifier: 0.1307 (0.1595)  loss_box_reg: 0.1148 (0.1422)  loss_objectness: 0.0935 (0.1068)  loss_rpn_box_reg: 0.0339 (0.0436)  time: 0.3258  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [8]  [ 420/1229]  eta: 0:04:22  lr: 0.005000  loss: 0.5051 (0.4530)  loss_classifier: 0.1594 (0.1597)  loss_box_reg: 0.1383 (0.1426)  loss_objectness: 0.0940 (0.1070)  loss_rpn_box_reg: 0.0440 (0.0438)  time: 0.3261  data: 0.1448  max mem: 4022\n",
      "Training Epoch: [8]  [ 430/1229]  eta: 0:04:18  lr: 0.005000  loss: 0.5051 (0.4540)  loss_classifier: 0.1526 (0.1599)  loss_box_reg: 0.1411 (0.1427)  loss_objectness: 0.1187 (0.1077)  loss_rpn_box_reg: 0.0432 (0.0437)  time: 0.3245  data: 0.1446  max mem: 4022\n",
      "Training Epoch: [8]  [ 440/1229]  eta: 0:04:15  lr: 0.005000  loss: 0.4373 (0.4537)  loss_classifier: 0.1457 (0.1597)  loss_box_reg: 0.1268 (0.1422)  loss_objectness: 0.1203 (0.1083)  loss_rpn_box_reg: 0.0360 (0.0435)  time: 0.3257  data: 0.1425  max mem: 4022\n",
      "Training Epoch: [8]  [ 450/1229]  eta: 0:04:12  lr: 0.005000  loss: 0.4598 (0.4574)  loss_classifier: 0.1561 (0.1610)  loss_box_reg: 0.1318 (0.1433)  loss_objectness: 0.1415 (0.1095)  loss_rpn_box_reg: 0.0324 (0.0436)  time: 0.3216  data: 0.1428  max mem: 4022\n",
      "Training Epoch: [8]  [ 460/1229]  eta: 0:04:09  lr: 0.005000  loss: 0.4280 (0.4564)  loss_classifier: 0.1688 (0.1610)  loss_box_reg: 0.1285 (0.1427)  loss_objectness: 0.1134 (0.1091)  loss_rpn_box_reg: 0.0256 (0.0436)  time: 0.3198  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [8]  [ 470/1229]  eta: 0:04:05  lr: 0.005000  loss: 0.4191 (0.4590)  loss_classifier: 0.1680 (0.1619)  loss_box_reg: 0.1113 (0.1437)  loss_objectness: 0.0899 (0.1092)  loss_rpn_box_reg: 0.0256 (0.0442)  time: 0.3195  data: 0.1397  max mem: 4022\n",
      "Training Epoch: [8]  [ 480/1229]  eta: 0:04:02  lr: 0.005000  loss: 0.5632 (0.4598)  loss_classifier: 0.1802 (0.1618)  loss_box_reg: 0.1534 (0.1438)  loss_objectness: 0.1124 (0.1094)  loss_rpn_box_reg: 0.0441 (0.0447)  time: 0.3181  data: 0.1404  max mem: 4022\n",
      "Training Epoch: [8]  [ 490/1229]  eta: 0:03:59  lr: 0.005000  loss: 0.5916 (0.4633)  loss_classifier: 0.1908 (0.1629)  loss_box_reg: 0.1694 (0.1449)  loss_objectness: 0.1264 (0.1104)  loss_rpn_box_reg: 0.0497 (0.0452)  time: 0.3158  data: 0.1408  max mem: 4022\n",
      "Training Epoch: [8]  [ 500/1229]  eta: 0:03:55  lr: 0.005000  loss: 0.5008 (0.4644)  loss_classifier: 0.1603 (0.1631)  loss_box_reg: 0.1557 (0.1452)  loss_objectness: 0.1313 (0.1109)  loss_rpn_box_reg: 0.0286 (0.0452)  time: 0.3212  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [8]  [ 510/1229]  eta: 0:03:52  lr: 0.005000  loss: 0.4047 (0.4639)  loss_classifier: 0.1512 (0.1632)  loss_box_reg: 0.1177 (0.1453)  loss_objectness: 0.1048 (0.1107)  loss_rpn_box_reg: 0.0189 (0.0448)  time: 0.3325  data: 0.1462  max mem: 4022\n",
      "Training Epoch: [8]  [ 520/1229]  eta: 0:03:49  lr: 0.005000  loss: 0.3534 (0.4638)  loss_classifier: 0.1453 (0.1631)  loss_box_reg: 0.1197 (0.1450)  loss_objectness: 0.0784 (0.1112)  loss_rpn_box_reg: 0.0152 (0.0446)  time: 0.3340  data: 0.1493  max mem: 4022\n",
      "Training Epoch: [8]  [ 530/1229]  eta: 0:03:46  lr: 0.005000  loss: 0.3880 (0.4653)  loss_classifier: 0.1593 (0.1635)  loss_box_reg: 0.1416 (0.1456)  loss_objectness: 0.0784 (0.1114)  loss_rpn_box_reg: 0.0170 (0.0447)  time: 0.3332  data: 0.1488  max mem: 4022\n",
      "Training Epoch: [8]  [ 540/1229]  eta: 0:03:43  lr: 0.005000  loss: 0.4722 (0.4662)  loss_classifier: 0.1595 (0.1639)  loss_box_reg: 0.1425 (0.1457)  loss_objectness: 0.1083 (0.1121)  loss_rpn_box_reg: 0.0292 (0.0446)  time: 0.3318  data: 0.1452  max mem: 4022\n",
      "Training Epoch: [8]  [ 550/1229]  eta: 0:03:40  lr: 0.005000  loss: 0.5086 (0.4662)  loss_classifier: 0.1539 (0.1638)  loss_box_reg: 0.1641 (0.1460)  loss_objectness: 0.1081 (0.1120)  loss_rpn_box_reg: 0.0312 (0.0444)  time: 0.3304  data: 0.1404  max mem: 4022\n",
      "Training Epoch: [8]  [ 560/1229]  eta: 0:03:37  lr: 0.005000  loss: 0.5086 (0.4666)  loss_classifier: 0.1544 (0.1640)  loss_box_reg: 0.1600 (0.1462)  loss_objectness: 0.1081 (0.1121)  loss_rpn_box_reg: 0.0251 (0.0443)  time: 0.3309  data: 0.1404  max mem: 4022\n",
      "Training Epoch: [8]  [ 570/1229]  eta: 0:03:33  lr: 0.005000  loss: 0.4555 (0.4672)  loss_classifier: 0.1647 (0.1640)  loss_box_reg: 0.1253 (0.1463)  loss_objectness: 0.1210 (0.1122)  loss_rpn_box_reg: 0.0184 (0.0447)  time: 0.3215  data: 0.1400  max mem: 4022\n",
      "Training Epoch: [8]  [ 580/1229]  eta: 0:03:30  lr: 0.005000  loss: 0.4555 (0.4680)  loss_classifier: 0.1647 (0.1643)  loss_box_reg: 0.1393 (0.1465)  loss_objectness: 0.1123 (0.1124)  loss_rpn_box_reg: 0.0224 (0.0448)  time: 0.3182  data: 0.1384  max mem: 4022\n",
      "Training Epoch: [8]  [ 590/1229]  eta: 0:03:27  lr: 0.005000  loss: 0.5098 (0.4674)  loss_classifier: 0.1772 (0.1640)  loss_box_reg: 0.1393 (0.1460)  loss_objectness: 0.1327 (0.1126)  loss_rpn_box_reg: 0.0224 (0.0447)  time: 0.3187  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [8]  [ 600/1229]  eta: 0:03:23  lr: 0.005000  loss: 0.3821 (0.4672)  loss_classifier: 0.1307 (0.1640)  loss_box_reg: 0.1191 (0.1464)  loss_objectness: 0.0835 (0.1122)  loss_rpn_box_reg: 0.0269 (0.0446)  time: 0.3157  data: 0.1385  max mem: 4022\n",
      "Training Epoch: [8]  [ 610/1229]  eta: 0:03:20  lr: 0.005000  loss: 0.3486 (0.4655)  loss_classifier: 0.1238 (0.1634)  loss_box_reg: 0.0887 (0.1455)  loss_objectness: 0.0847 (0.1122)  loss_rpn_box_reg: 0.0280 (0.0444)  time: 0.3153  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [8]  [ 620/1229]  eta: 0:03:17  lr: 0.005000  loss: 0.3369 (0.4638)  loss_classifier: 0.1229 (0.1629)  loss_box_reg: 0.0887 (0.1452)  loss_objectness: 0.0847 (0.1117)  loss_rpn_box_reg: 0.0218 (0.0440)  time: 0.3213  data: 0.1385  max mem: 4022\n",
      "Training Epoch: [8]  [ 630/1229]  eta: 0:03:13  lr: 0.005000  loss: 0.3324 (0.4627)  loss_classifier: 0.1323 (0.1625)  loss_box_reg: 0.1216 (0.1448)  loss_objectness: 0.0839 (0.1117)  loss_rpn_box_reg: 0.0182 (0.0438)  time: 0.3239  data: 0.1375  max mem: 4022\n",
      "Training Epoch: [8]  [ 640/1229]  eta: 0:03:10  lr: 0.005000  loss: 0.4317 (0.4630)  loss_classifier: 0.1474 (0.1623)  loss_box_reg: 0.1334 (0.1452)  loss_objectness: 0.0865 (0.1115)  loss_rpn_box_reg: 0.0199 (0.0440)  time: 0.3183  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [8]  [ 650/1229]  eta: 0:03:07  lr: 0.005000  loss: 0.4846 (0.4632)  loss_classifier: 0.1703 (0.1624)  loss_box_reg: 0.1560 (0.1454)  loss_objectness: 0.0865 (0.1115)  loss_rpn_box_reg: 0.0225 (0.0439)  time: 0.3225  data: 0.1436  max mem: 4022\n",
      "Training Epoch: [8]  [ 660/1229]  eta: 0:03:04  lr: 0.005000  loss: 0.3998 (0.4622)  loss_classifier: 0.1670 (0.1622)  loss_box_reg: 0.1184 (0.1450)  loss_objectness: 0.0778 (0.1113)  loss_rpn_box_reg: 0.0215 (0.0438)  time: 0.3321  data: 0.1446  max mem: 4022\n",
      "Training Epoch: [8]  [ 670/1229]  eta: 0:03:01  lr: 0.005000  loss: 0.4485 (0.4634)  loss_classifier: 0.1477 (0.1626)  loss_box_reg: 0.1245 (0.1457)  loss_objectness: 0.0942 (0.1114)  loss_rpn_box_reg: 0.0253 (0.0438)  time: 0.3291  data: 0.1439  max mem: 4022\n",
      "Training Epoch: [8]  [ 680/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.4754 (0.4641)  loss_classifier: 0.1545 (0.1627)  loss_box_reg: 0.1385 (0.1458)  loss_objectness: 0.1115 (0.1117)  loss_rpn_box_reg: 0.0323 (0.0439)  time: 0.3431  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [8]  [ 690/1229]  eta: 0:02:54  lr: 0.005000  loss: 0.4693 (0.4657)  loss_classifier: 0.1350 (0.1632)  loss_box_reg: 0.1116 (0.1467)  loss_objectness: 0.1101 (0.1118)  loss_rpn_box_reg: 0.0290 (0.0441)  time: 0.3452  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [8]  [ 700/1229]  eta: 0:02:51  lr: 0.005000  loss: 0.3344 (0.4641)  loss_classifier: 0.1190 (0.1627)  loss_box_reg: 0.1058 (0.1463)  loss_objectness: 0.0683 (0.1112)  loss_rpn_box_reg: 0.0266 (0.0440)  time: 0.3352  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [8]  [ 710/1229]  eta: 0:02:48  lr: 0.005000  loss: 0.3543 (0.4643)  loss_classifier: 0.1300 (0.1628)  loss_box_reg: 0.1197 (0.1465)  loss_objectness: 0.0861 (0.1112)  loss_rpn_box_reg: 0.0270 (0.0438)  time: 0.3331  data: 0.1427  max mem: 4022\n",
      "Training Epoch: [8]  [ 720/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.4249 (0.4642)  loss_classifier: 0.1542 (0.1627)  loss_box_reg: 0.1207 (0.1465)  loss_objectness: 0.1022 (0.1110)  loss_rpn_box_reg: 0.0274 (0.0440)  time: 0.3238  data: 0.1392  max mem: 4022\n",
      "Training Epoch: [8]  [ 730/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.3835 (0.4635)  loss_classifier: 0.1349 (0.1625)  loss_box_reg: 0.1048 (0.1464)  loss_objectness: 0.0892 (0.1109)  loss_rpn_box_reg: 0.0226 (0.0437)  time: 0.3332  data: 0.1429  max mem: 4022\n",
      "Training Epoch: [8]  [ 740/1229]  eta: 0:02:39  lr: 0.005000  loss: 0.3875 (0.4626)  loss_classifier: 0.1359 (0.1621)  loss_box_reg: 0.1158 (0.1461)  loss_objectness: 0.0730 (0.1107)  loss_rpn_box_reg: 0.0214 (0.0437)  time: 0.3397  data: 0.1481  max mem: 4022\n",
      "Training Epoch: [8]  [ 750/1229]  eta: 0:02:35  lr: 0.005000  loss: 0.3915 (0.4634)  loss_classifier: 0.1365 (0.1624)  loss_box_reg: 0.1158 (0.1464)  loss_objectness: 0.0989 (0.1108)  loss_rpn_box_reg: 0.0252 (0.0438)  time: 0.3314  data: 0.1477  max mem: 4022\n",
      "Training Epoch: [8]  [ 760/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.4349 (0.4637)  loss_classifier: 0.1736 (0.1625)  loss_box_reg: 0.1450 (0.1467)  loss_objectness: 0.1094 (0.1109)  loss_rpn_box_reg: 0.0358 (0.0437)  time: 0.3312  data: 0.1459  max mem: 4022\n",
      "Training Epoch: [8]  [ 770/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.3115 (0.4607)  loss_classifier: 0.1246 (0.1615)  loss_box_reg: 0.0877 (0.1456)  loss_objectness: 0.0822 (0.1104)  loss_rpn_box_reg: 0.0136 (0.0433)  time: 0.3455  data: 0.1514  max mem: 4022\n",
      "Training Epoch: [8]  [ 780/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.2600 (0.4610)  loss_classifier: 0.0995 (0.1614)  loss_box_reg: 0.0877 (0.1459)  loss_objectness: 0.0770 (0.1104)  loss_rpn_box_reg: 0.0139 (0.0434)  time: 0.3435  data: 0.1485  max mem: 4022\n",
      "Training Epoch: [8]  [ 790/1229]  eta: 0:02:23  lr: 0.005000  loss: 0.3755 (0.4600)  loss_classifier: 0.1145 (0.1611)  loss_box_reg: 0.1149 (0.1455)  loss_objectness: 0.0935 (0.1102)  loss_rpn_box_reg: 0.0313 (0.0431)  time: 0.3274  data: 0.1378  max mem: 4022\n",
      "Training Epoch: [8]  [ 800/1229]  eta: 0:02:19  lr: 0.005000  loss: 0.3853 (0.4599)  loss_classifier: 0.1232 (0.1610)  loss_box_reg: 0.1101 (0.1452)  loss_objectness: 0.0952 (0.1103)  loss_rpn_box_reg: 0.0228 (0.0433)  time: 0.3238  data: 0.1357  max mem: 4022\n",
      "Training Epoch: [8]  [ 810/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.4183 (0.4606)  loss_classifier: 0.1614 (0.1612)  loss_box_reg: 0.1160 (0.1453)  loss_objectness: 0.1142 (0.1107)  loss_rpn_box_reg: 0.0273 (0.0434)  time: 0.3225  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [8]  [ 820/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.3851 (0.4599)  loss_classifier: 0.1341 (0.1611)  loss_box_reg: 0.1121 (0.1451)  loss_objectness: 0.0796 (0.1104)  loss_rpn_box_reg: 0.0224 (0.0432)  time: 0.3253  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [8]  [ 830/1229]  eta: 0:02:09  lr: 0.005000  loss: 0.3851 (0.4589)  loss_classifier: 0.1304 (0.1607)  loss_box_reg: 0.0925 (0.1447)  loss_objectness: 0.0781 (0.1102)  loss_rpn_box_reg: 0.0157 (0.0432)  time: 0.3293  data: 0.1353  max mem: 4022\n",
      "Training Epoch: [8]  [ 840/1229]  eta: 0:02:06  lr: 0.005000  loss: 0.3984 (0.4585)  loss_classifier: 0.1257 (0.1605)  loss_box_reg: 0.0948 (0.1447)  loss_objectness: 0.0824 (0.1102)  loss_rpn_box_reg: 0.0195 (0.0431)  time: 0.3256  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [8]  [ 850/1229]  eta: 0:02:03  lr: 0.005000  loss: 0.3975 (0.4581)  loss_classifier: 0.1257 (0.1602)  loss_box_reg: 0.1062 (0.1442)  loss_objectness: 0.0880 (0.1102)  loss_rpn_box_reg: 0.0258 (0.0436)  time: 0.3327  data: 0.1412  max mem: 4022\n",
      "Training Epoch: [8]  [ 860/1229]  eta: 0:02:00  lr: 0.005000  loss: 0.3975 (0.4591)  loss_classifier: 0.1176 (0.1605)  loss_box_reg: 0.1059 (0.1448)  loss_objectness: 0.0880 (0.1101)  loss_rpn_box_reg: 0.0263 (0.0437)  time: 0.3313  data: 0.1390  max mem: 4022\n",
      "Training Epoch: [8]  [ 870/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.4347 (0.4592)  loss_classifier: 0.1601 (0.1607)  loss_box_reg: 0.1443 (0.1451)  loss_objectness: 0.0992 (0.1099)  loss_rpn_box_reg: 0.0216 (0.0435)  time: 0.3217  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [8]  [ 880/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.3794 (0.4585)  loss_classifier: 0.1354 (0.1603)  loss_box_reg: 0.1155 (0.1448)  loss_objectness: 0.0915 (0.1096)  loss_rpn_box_reg: 0.0216 (0.0437)  time: 0.3284  data: 0.1397  max mem: 4022\n",
      "Training Epoch: [8]  [ 890/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.3995 (0.4583)  loss_classifier: 0.1354 (0.1604)  loss_box_reg: 0.1042 (0.1447)  loss_objectness: 0.0894 (0.1095)  loss_rpn_box_reg: 0.0239 (0.0437)  time: 0.3330  data: 0.1409  max mem: 4022\n",
      "Training Epoch: [8]  [ 900/1229]  eta: 0:01:47  lr: 0.005000  loss: 0.4157 (0.4579)  loss_classifier: 0.1249 (0.1601)  loss_box_reg: 0.1094 (0.1447)  loss_objectness: 0.1000 (0.1093)  loss_rpn_box_reg: 0.0339 (0.0438)  time: 0.3295  data: 0.1418  max mem: 4022\n",
      "Training Epoch: [8]  [ 910/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.3739 (0.4576)  loss_classifier: 0.1142 (0.1600)  loss_box_reg: 0.1094 (0.1446)  loss_objectness: 0.0797 (0.1094)  loss_rpn_box_reg: 0.0228 (0.0436)  time: 0.3233  data: 0.1407  max mem: 4022\n",
      "Training Epoch: [8]  [ 920/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.3056 (0.4566)  loss_classifier: 0.1106 (0.1597)  loss_box_reg: 0.0977 (0.1444)  loss_objectness: 0.0791 (0.1092)  loss_rpn_box_reg: 0.0172 (0.0434)  time: 0.3211  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [8]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.3133 (0.4562)  loss_classifier: 0.1154 (0.1595)  loss_box_reg: 0.0939 (0.1444)  loss_objectness: 0.0791 (0.1091)  loss_rpn_box_reg: 0.0210 (0.0432)  time: 0.3256  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [8]  [ 940/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.3133 (0.4553)  loss_classifier: 0.1274 (0.1592)  loss_box_reg: 0.0939 (0.1441)  loss_objectness: 0.0780 (0.1090)  loss_rpn_box_reg: 0.0194 (0.0430)  time: 0.3294  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [8]  [ 950/1229]  eta: 0:01:30  lr: 0.005000  loss: 0.3423 (0.4563)  loss_classifier: 0.1274 (0.1595)  loss_box_reg: 0.1147 (0.1448)  loss_objectness: 0.0804 (0.1090)  loss_rpn_box_reg: 0.0194 (0.0430)  time: 0.3284  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [8]  [ 960/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.3599 (0.4558)  loss_classifier: 0.1277 (0.1593)  loss_box_reg: 0.1246 (0.1447)  loss_objectness: 0.0830 (0.1088)  loss_rpn_box_reg: 0.0255 (0.0430)  time: 0.3330  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [8]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.3738 (0.4555)  loss_classifier: 0.1413 (0.1592)  loss_box_reg: 0.1205 (0.1446)  loss_objectness: 0.0830 (0.1085)  loss_rpn_box_reg: 0.0255 (0.0431)  time: 0.3292  data: 0.1402  max mem: 4022\n",
      "Training Epoch: [8]  [ 980/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.5773 (0.4580)  loss_classifier: 0.1952 (0.1602)  loss_box_reg: 0.2007 (0.1455)  loss_objectness: 0.1119 (0.1091)  loss_rpn_box_reg: 0.0389 (0.0432)  time: 0.3212  data: 0.1427  max mem: 4022\n",
      "Training Epoch: [8]  [ 990/1229]  eta: 0:01:17  lr: 0.005000  loss: 0.4867 (0.4583)  loss_classifier: 0.1892 (0.1603)  loss_box_reg: 0.1554 (0.1456)  loss_objectness: 0.1119 (0.1090)  loss_rpn_box_reg: 0.0282 (0.0434)  time: 0.3228  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [8]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.4318 (0.4588)  loss_classifier: 0.1253 (0.1605)  loss_box_reg: 0.1235 (0.1457)  loss_objectness: 0.0993 (0.1091)  loss_rpn_box_reg: 0.0273 (0.0434)  time: 0.3254  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [8]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.4921 (0.4591)  loss_classifier: 0.1742 (0.1607)  loss_box_reg: 0.1265 (0.1456)  loss_objectness: 0.1084 (0.1092)  loss_rpn_box_reg: 0.0278 (0.0436)  time: 0.3269  data: 0.1436  max mem: 4022\n",
      "Training Epoch: [8]  [1020/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.4204 (0.4587)  loss_classifier: 0.1514 (0.1605)  loss_box_reg: 0.0908 (0.1454)  loss_objectness: 0.1021 (0.1091)  loss_rpn_box_reg: 0.0278 (0.0437)  time: 0.3254  data: 0.1441  max mem: 4022\n",
      "Training Epoch: [8]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.3922 (0.4581)  loss_classifier: 0.1083 (0.1602)  loss_box_reg: 0.0968 (0.1452)  loss_objectness: 0.0837 (0.1089)  loss_rpn_box_reg: 0.0273 (0.0438)  time: 0.3281  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [8]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.4086 (0.4583)  loss_classifier: 0.1532 (0.1602)  loss_box_reg: 0.1069 (0.1453)  loss_objectness: 0.0895 (0.1089)  loss_rpn_box_reg: 0.0218 (0.0439)  time: 0.3286  data: 0.1420  max mem: 4022\n",
      "Training Epoch: [8]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.3622 (0.4581)  loss_classifier: 0.1499 (0.1602)  loss_box_reg: 0.1127 (0.1453)  loss_objectness: 0.0818 (0.1088)  loss_rpn_box_reg: 0.0218 (0.0438)  time: 0.3254  data: 0.1401  max mem: 4022\n",
      "Training Epoch: [8]  [1060/1229]  eta: 0:00:55  lr: 0.005000  loss: 0.3381 (0.4577)  loss_classifier: 0.1226 (0.1601)  loss_box_reg: 0.1060 (0.1452)  loss_objectness: 0.0713 (0.1086)  loss_rpn_box_reg: 0.0164 (0.0438)  time: 0.3252  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [8]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.3578 (0.4568)  loss_classifier: 0.1225 (0.1597)  loss_box_reg: 0.1016 (0.1448)  loss_objectness: 0.0785 (0.1086)  loss_rpn_box_reg: 0.0200 (0.0436)  time: 0.3238  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [8]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.3265 (0.4556)  loss_classifier: 0.1134 (0.1593)  loss_box_reg: 0.0839 (0.1444)  loss_objectness: 0.1036 (0.1084)  loss_rpn_box_reg: 0.0200 (0.0435)  time: 0.3188  data: 0.1400  max mem: 4022\n",
      "Training Epoch: [8]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.3063 (0.4555)  loss_classifier: 0.1156 (0.1593)  loss_box_reg: 0.1001 (0.1446)  loss_objectness: 0.0995 (0.1083)  loss_rpn_box_reg: 0.0203 (0.0433)  time: 0.3172  data: 0.1402  max mem: 4022\n",
      "Training Epoch: [8]  [1100/1229]  eta: 0:00:42  lr: 0.005000  loss: 0.3994 (0.4556)  loss_classifier: 0.1453 (0.1592)  loss_box_reg: 0.1187 (0.1447)  loss_objectness: 0.0995 (0.1082)  loss_rpn_box_reg: 0.0246 (0.0434)  time: 0.3228  data: 0.1414  max mem: 4022\n",
      "Training Epoch: [8]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.4061 (0.4564)  loss_classifier: 0.1580 (0.1594)  loss_box_reg: 0.1258 (0.1450)  loss_objectness: 0.1061 (0.1084)  loss_rpn_box_reg: 0.0434 (0.0435)  time: 0.3251  data: 0.1411  max mem: 4022\n",
      "Training Epoch: [8]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4560 (0.4563)  loss_classifier: 0.1520 (0.1593)  loss_box_reg: 0.1281 (0.1450)  loss_objectness: 0.1149 (0.1083)  loss_rpn_box_reg: 0.0330 (0.0437)  time: 0.3246  data: 0.1440  max mem: 4022\n",
      "Training Epoch: [8]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.3854 (0.4555)  loss_classifier: 0.1135 (0.1590)  loss_box_reg: 0.1049 (0.1448)  loss_objectness: 0.0983 (0.1082)  loss_rpn_box_reg: 0.0319 (0.0436)  time: 0.3269  data: 0.1447  max mem: 4022\n",
      "Training Epoch: [8]  [1140/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.3332 (0.4550)  loss_classifier: 0.1060 (0.1588)  loss_box_reg: 0.1163 (0.1447)  loss_objectness: 0.0906 (0.1080)  loss_rpn_box_reg: 0.0166 (0.0435)  time: 0.3248  data: 0.1422  max mem: 4022\n",
      "Training Epoch: [8]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.3332 (0.4547)  loss_classifier: 0.1288 (0.1588)  loss_box_reg: 0.1203 (0.1447)  loss_objectness: 0.0900 (0.1079)  loss_rpn_box_reg: 0.0166 (0.0433)  time: 0.3264  data: 0.1407  max mem: 4022\n",
      "Training Epoch: [8]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.3459 (0.4544)  loss_classifier: 0.1397 (0.1587)  loss_box_reg: 0.1010 (0.1446)  loss_objectness: 0.0900 (0.1078)  loss_rpn_box_reg: 0.0156 (0.0432)  time: 0.3275  data: 0.1409  max mem: 4022\n",
      "Training Epoch: [8]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.3905 (0.4539)  loss_classifier: 0.1500 (0.1587)  loss_box_reg: 0.0940 (0.1443)  loss_objectness: 0.0955 (0.1078)  loss_rpn_box_reg: 0.0212 (0.0431)  time: 0.3310  data: 0.1427  max mem: 4022\n",
      "Training Epoch: [8]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.4531 (0.4547)  loss_classifier: 0.1539 (0.1589)  loss_box_reg: 0.0940 (0.1446)  loss_objectness: 0.1040 (0.1080)  loss_rpn_box_reg: 0.0215 (0.0432)  time: 0.3342  data: 0.1441  max mem: 4022\n",
      "Training Epoch: [8]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.5212 (0.4552)  loss_classifier: 0.1859 (0.1591)  loss_box_reg: 0.1363 (0.1447)  loss_objectness: 0.1273 (0.1082)  loss_rpn_box_reg: 0.0313 (0.0431)  time: 0.3309  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [8]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.4968 (0.4548)  loss_classifier: 0.1524 (0.1591)  loss_box_reg: 0.1109 (0.1445)  loss_objectness: 0.0886 (0.1081)  loss_rpn_box_reg: 0.0313 (0.0432)  time: 0.3362  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [8]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.4876 (0.4555)  loss_classifier: 0.1544 (0.1592)  loss_box_reg: 0.1171 (0.1448)  loss_objectness: 0.1069 (0.1081)  loss_rpn_box_reg: 0.0284 (0.0433)  time: 0.3320  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [8]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.4411 (0.4551)  loss_classifier: 0.1544 (0.1591)  loss_box_reg: 0.1795 (0.1448)  loss_objectness: 0.0995 (0.1080)  loss_rpn_box_reg: 0.0266 (0.0432)  time: 0.3220  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [8]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4127 (0.4552)  loss_classifier: 0.1461 (0.1591)  loss_box_reg: 0.1273 (0.1449)  loss_objectness: 0.0872 (0.1080)  loss_rpn_box_reg: 0.0264 (0.0432)  time: 0.3222  data: 0.1391  max mem: 4022\n",
      "Training Epoch: [8] Total time: 0:06:40 (0.3261 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:42  model_time: 0.2960 (0.2960)  evaluator_time: 0.0010 (0.0010)  time: 0.3320  data: 0.0330  max mem: 4022\n",
      "Test:  [100/308]  eta: 0:00:33  model_time: 0.1090 (0.1136)  evaluator_time: 0.0020 (0.0053)  time: 0.1609  data: 0.0402  max mem: 4022\n",
      "Test:  [200/308]  eta: 0:00:17  model_time: 0.1170 (0.1128)  evaluator_time: 0.0020 (0.0049)  time: 0.1572  data: 0.0350  max mem: 4022\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.1020 (0.1119)  evaluator_time: 0.0020 (0.0049)  time: 0.1563  data: 0.0453  max mem: 4022\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.1030 (0.1116)  evaluator_time: 0.0020 (0.0049)  time: 0.1475  data: 0.0378  max mem: 4022\n",
      "Test: Total time: 0:00:48 (0.1569 s / it)\n",
      "Averaged stats: model_time: 0.1030 (0.1116)  evaluator_time: 0.0020 (0.0049)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.124\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.072\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.246\n",
      "Testing Epoch: [8]  [  0/308]  eta: 0:00:47  lr: 0.005000  loss: 0.1616 (0.1616)  loss_classifier: 0.0715 (0.0715)  loss_box_reg: 0.0538 (0.0538)  loss_objectness: 0.0290 (0.0290)  loss_rpn_box_reg: 0.0073 (0.0073)  time: 0.1540  data: 0.0310  max mem: 4022\n",
      "Testing Epoch: [8]  [100/308]  eta: 0:00:37  lr: 0.005000  loss: 0.3469 (0.5198)  loss_classifier: 0.1545 (0.1770)  loss_box_reg: 0.1258 (0.1661)  loss_objectness: 0.0616 (0.1170)  loss_rpn_box_reg: 0.0170 (0.0597)  time: 0.1870  data: 0.0486  max mem: 4022\n",
      "Testing Epoch: [8]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.4230 (0.4931)  loss_classifier: 0.1532 (0.1687)  loss_box_reg: 0.1408 (0.1583)  loss_objectness: 0.0849 (0.1102)  loss_rpn_box_reg: 0.0266 (0.0559)  time: 0.1838  data: 0.0379  max mem: 4022\n",
      "Testing Epoch: [8]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.4638 (0.4905)  loss_classifier: 0.1959 (0.1693)  loss_box_reg: 0.1495 (0.1602)  loss_objectness: 0.0878 (0.1070)  loss_rpn_box_reg: 0.0338 (0.0540)  time: 0.1763  data: 0.0462  max mem: 4022\n",
      "Testing Epoch: [8]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.4453 (0.4904)  loss_classifier: 0.1739 (0.1694)  loss_box_reg: 0.1239 (0.1605)  loss_objectness: 0.0858 (0.1070)  loss_rpn_box_reg: 0.0338 (0.0535)  time: 0.1734  data: 0.0436  max mem: 4022\n",
      "Testing Epoch: [8] Total time: 0:00:55 (0.1807 s / it)\n",
      "Training Epoch: [9]  [   0/1229]  eta: 0:06:25  lr: 0.005000  loss: 0.2232 (0.2232)  loss_classifier: 0.0973 (0.0973)  loss_box_reg: 0.0656 (0.0656)  loss_objectness: 0.0450 (0.0450)  loss_rpn_box_reg: 0.0153 (0.0153)  time: 0.3140  data: 0.1450  max mem: 4022\n",
      "Training Epoch: [9]  [  10/1229]  eta: 0:06:43  lr: 0.005000  loss: 0.3461 (0.4221)  loss_classifier: 0.1079 (0.1448)  loss_box_reg: 0.0824 (0.1407)  loss_objectness: 0.0741 (0.0908)  loss_rpn_box_reg: 0.0215 (0.0458)  time: 0.3312  data: 0.1499  max mem: 4022\n",
      "Training Epoch: [9]  [  20/1229]  eta: 0:06:43  lr: 0.005000  loss: 0.4322 (0.4754)  loss_classifier: 0.1244 (0.1537)  loss_box_reg: 0.1181 (0.1602)  loss_objectness: 0.1074 (0.1130)  loss_rpn_box_reg: 0.0215 (0.0485)  time: 0.3346  data: 0.1509  max mem: 4022\n",
      "Training Epoch: [9]  [  30/1229]  eta: 0:06:40  lr: 0.005000  loss: 0.4322 (0.4799)  loss_classifier: 0.1495 (0.1623)  loss_box_reg: 0.1230 (0.1503)  loss_objectness: 0.1167 (0.1224)  loss_rpn_box_reg: 0.0274 (0.0448)  time: 0.3357  data: 0.1539  max mem: 4022\n",
      "Training Epoch: [9]  [  40/1229]  eta: 0:06:37  lr: 0.005000  loss: 0.3335 (0.4525)  loss_classifier: 0.1322 (0.1522)  loss_box_reg: 0.0913 (0.1404)  loss_objectness: 0.1049 (0.1133)  loss_rpn_box_reg: 0.0156 (0.0467)  time: 0.3355  data: 0.1522  max mem: 4022\n",
      "Training Epoch: [9]  [  50/1229]  eta: 0:06:30  lr: 0.005000  loss: 0.2826 (0.4365)  loss_classifier: 0.1023 (0.1467)  loss_box_reg: 0.0709 (0.1375)  loss_objectness: 0.0813 (0.1095)  loss_rpn_box_reg: 0.0126 (0.0428)  time: 0.3275  data: 0.1457  max mem: 4022\n",
      "Training Epoch: [9]  [  60/1229]  eta: 0:06:26  lr: 0.005000  loss: 0.3163 (0.4343)  loss_classifier: 0.1070 (0.1459)  loss_box_reg: 0.0968 (0.1368)  loss_objectness: 0.0830 (0.1077)  loss_rpn_box_reg: 0.0200 (0.0438)  time: 0.3227  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [9]  [  70/1229]  eta: 0:06:23  lr: 0.005000  loss: 0.4144 (0.4524)  loss_classifier: 0.1325 (0.1519)  loss_box_reg: 0.1138 (0.1435)  loss_objectness: 0.1011 (0.1135)  loss_rpn_box_reg: 0.0274 (0.0435)  time: 0.3295  data: 0.1455  max mem: 4022\n",
      "Training Epoch: [9]  [  80/1229]  eta: 0:06:19  lr: 0.005000  loss: 0.4144 (0.4468)  loss_classifier: 0.1325 (0.1510)  loss_box_reg: 0.1100 (0.1407)  loss_objectness: 0.1133 (0.1129)  loss_rpn_box_reg: 0.0251 (0.0421)  time: 0.3295  data: 0.1420  max mem: 4022\n",
      "Training Epoch: [9]  [  90/1229]  eta: 0:06:15  lr: 0.005000  loss: 0.3401 (0.4541)  loss_classifier: 0.1243 (0.1526)  loss_box_reg: 0.0942 (0.1432)  loss_objectness: 0.1083 (0.1145)  loss_rpn_box_reg: 0.0305 (0.0437)  time: 0.3261  data: 0.1377  max mem: 4022\n",
      "Training Epoch: [9]  [ 100/1229]  eta: 0:06:12  lr: 0.005000  loss: 0.3539 (0.4551)  loss_classifier: 0.1200 (0.1537)  loss_box_reg: 0.1054 (0.1450)  loss_objectness: 0.0842 (0.1131)  loss_rpn_box_reg: 0.0334 (0.0433)  time: 0.3287  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [9]  [ 110/1229]  eta: 0:06:09  lr: 0.005000  loss: 0.4985 (0.4655)  loss_classifier: 0.1651 (0.1572)  loss_box_reg: 0.1397 (0.1519)  loss_objectness: 0.0810 (0.1119)  loss_rpn_box_reg: 0.0231 (0.0446)  time: 0.3335  data: 0.1426  max mem: 4022\n",
      "Training Epoch: [9]  [ 120/1229]  eta: 0:06:06  lr: 0.005000  loss: 0.5080 (0.4627)  loss_classifier: 0.1775 (0.1573)  loss_box_reg: 0.1375 (0.1518)  loss_objectness: 0.0930 (0.1106)  loss_rpn_box_reg: 0.0209 (0.0431)  time: 0.3334  data: 0.1429  max mem: 4022\n",
      "Training Epoch: [9]  [ 130/1229]  eta: 0:06:02  lr: 0.005000  loss: 0.3451 (0.4608)  loss_classifier: 0.1395 (0.1568)  loss_box_reg: 0.1242 (0.1506)  loss_objectness: 0.0954 (0.1100)  loss_rpn_box_reg: 0.0209 (0.0433)  time: 0.3253  data: 0.1390  max mem: 4022\n",
      "Training Epoch: [9]  [ 140/1229]  eta: 0:05:58  lr: 0.005000  loss: 0.5144 (0.4662)  loss_classifier: 0.1723 (0.1596)  loss_box_reg: 0.1401 (0.1527)  loss_objectness: 0.0970 (0.1098)  loss_rpn_box_reg: 0.0319 (0.0440)  time: 0.3215  data: 0.1365  max mem: 4022\n",
      "Training Epoch: [9]  [ 150/1229]  eta: 0:05:55  lr: 0.005000  loss: 0.3784 (0.4575)  loss_classifier: 0.1435 (0.1568)  loss_box_reg: 0.1375 (0.1484)  loss_objectness: 0.0970 (0.1088)  loss_rpn_box_reg: 0.0226 (0.0435)  time: 0.3266  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [9]  [ 160/1229]  eta: 0:05:52  lr: 0.005000  loss: 0.3484 (0.4568)  loss_classifier: 0.1269 (0.1565)  loss_box_reg: 0.0899 (0.1478)  loss_objectness: 0.0990 (0.1078)  loss_rpn_box_reg: 0.0199 (0.0447)  time: 0.3298  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [9]  [ 170/1229]  eta: 0:05:48  lr: 0.005000  loss: 0.4335 (0.4575)  loss_classifier: 0.1425 (0.1571)  loss_box_reg: 0.1297 (0.1492)  loss_objectness: 0.0809 (0.1070)  loss_rpn_box_reg: 0.0203 (0.0442)  time: 0.3261  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [9]  [ 180/1229]  eta: 0:05:44  lr: 0.005000  loss: 0.3876 (0.4536)  loss_classifier: 0.1166 (0.1560)  loss_box_reg: 0.0942 (0.1478)  loss_objectness: 0.0809 (0.1070)  loss_rpn_box_reg: 0.0182 (0.0429)  time: 0.3208  data: 0.1429  max mem: 4022\n",
      "Training Epoch: [9]  [ 190/1229]  eta: 0:05:40  lr: 0.005000  loss: 0.3626 (0.4514)  loss_classifier: 0.1054 (0.1544)  loss_box_reg: 0.0951 (0.1459)  loss_objectness: 0.1008 (0.1077)  loss_rpn_box_reg: 0.0178 (0.0433)  time: 0.3166  data: 0.1401  max mem: 4022\n",
      "Training Epoch: [9]  [ 200/1229]  eta: 0:05:37  lr: 0.005000  loss: 0.4029 (0.4520)  loss_classifier: 0.1180 (0.1540)  loss_box_reg: 0.1137 (0.1460)  loss_objectness: 0.1027 (0.1079)  loss_rpn_box_reg: 0.0295 (0.0441)  time: 0.3201  data: 0.1409  max mem: 4022\n",
      "Training Epoch: [9]  [ 210/1229]  eta: 0:05:33  lr: 0.005000  loss: 0.4686 (0.4544)  loss_classifier: 0.1604 (0.1554)  loss_box_reg: 0.1549 (0.1472)  loss_objectness: 0.1019 (0.1074)  loss_rpn_box_reg: 0.0321 (0.0444)  time: 0.3254  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [9]  [ 220/1229]  eta: 0:05:30  lr: 0.005000  loss: 0.3837 (0.4494)  loss_classifier: 0.1436 (0.1537)  loss_box_reg: 0.1318 (0.1453)  loss_objectness: 0.0860 (0.1070)  loss_rpn_box_reg: 0.0244 (0.0434)  time: 0.3237  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [9]  [ 230/1229]  eta: 0:05:27  lr: 0.005000  loss: 0.3837 (0.4512)  loss_classifier: 0.1348 (0.1548)  loss_box_reg: 0.0992 (0.1455)  loss_objectness: 0.1141 (0.1083)  loss_rpn_box_reg: 0.0152 (0.0427)  time: 0.3275  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [9]  [ 240/1229]  eta: 0:05:23  lr: 0.005000  loss: 0.4239 (0.4494)  loss_classifier: 0.1498 (0.1543)  loss_box_reg: 0.1362 (0.1447)  loss_objectness: 0.1056 (0.1076)  loss_rpn_box_reg: 0.0158 (0.0428)  time: 0.3265  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [9]  [ 250/1229]  eta: 0:05:20  lr: 0.005000  loss: 0.3665 (0.4504)  loss_classifier: 0.1369 (0.1550)  loss_box_reg: 0.1412 (0.1453)  loss_objectness: 0.0927 (0.1077)  loss_rpn_box_reg: 0.0178 (0.0424)  time: 0.3211  data: 0.1443  max mem: 4022\n",
      "Training Epoch: [9]  [ 260/1229]  eta: 0:05:16  lr: 0.005000  loss: 0.4001 (0.4503)  loss_classifier: 0.1412 (0.1549)  loss_box_reg: 0.1265 (0.1445)  loss_objectness: 0.1117 (0.1085)  loss_rpn_box_reg: 0.0280 (0.0424)  time: 0.3260  data: 0.1442  max mem: 4022\n",
      "Training Epoch: [9]  [ 270/1229]  eta: 0:05:13  lr: 0.005000  loss: 0.3513 (0.4486)  loss_classifier: 0.1391 (0.1546)  loss_box_reg: 0.1084 (0.1448)  loss_objectness: 0.0792 (0.1074)  loss_rpn_box_reg: 0.0286 (0.0418)  time: 0.3280  data: 0.1427  max mem: 4022\n",
      "Training Epoch: [9]  [ 280/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.3513 (0.4463)  loss_classifier: 0.1285 (0.1538)  loss_box_reg: 0.0977 (0.1434)  loss_objectness: 0.0767 (0.1074)  loss_rpn_box_reg: 0.0243 (0.0417)  time: 0.3226  data: 0.1427  max mem: 4022\n",
      "Training Epoch: [9]  [ 290/1229]  eta: 0:05:06  lr: 0.005000  loss: 0.3365 (0.4454)  loss_classifier: 0.1027 (0.1527)  loss_box_reg: 0.0827 (0.1421)  loss_objectness: 0.1028 (0.1075)  loss_rpn_box_reg: 0.0312 (0.0430)  time: 0.3232  data: 0.1409  max mem: 4022\n",
      "Training Epoch: [9]  [ 300/1229]  eta: 0:05:03  lr: 0.005000  loss: 0.3274 (0.4423)  loss_classifier: 0.1009 (0.1517)  loss_box_reg: 0.0827 (0.1409)  loss_objectness: 0.1035 (0.1071)  loss_rpn_box_reg: 0.0201 (0.0426)  time: 0.3233  data: 0.1401  max mem: 4022\n",
      "Training Epoch: [9]  [ 310/1229]  eta: 0:04:59  lr: 0.005000  loss: 0.4559 (0.4464)  loss_classifier: 0.1441 (0.1533)  loss_box_reg: 0.1276 (0.1429)  loss_objectness: 0.0967 (0.1076)  loss_rpn_box_reg: 0.0202 (0.0426)  time: 0.3216  data: 0.1420  max mem: 4022\n",
      "Training Epoch: [9]  [ 320/1229]  eta: 0:04:56  lr: 0.005000  loss: 0.4155 (0.4448)  loss_classifier: 0.1464 (0.1528)  loss_box_reg: 0.1276 (0.1424)  loss_objectness: 0.0967 (0.1070)  loss_rpn_box_reg: 0.0250 (0.0426)  time: 0.3218  data: 0.1433  max mem: 4022\n",
      "Training Epoch: [9]  [ 330/1229]  eta: 0:04:53  lr: 0.005000  loss: 0.3421 (0.4407)  loss_classifier: 0.1066 (0.1514)  loss_box_reg: 0.0935 (0.1407)  loss_objectness: 0.0930 (0.1064)  loss_rpn_box_reg: 0.0145 (0.0421)  time: 0.3285  data: 0.1476  max mem: 4022\n",
      "Training Epoch: [9]  [ 340/1229]  eta: 0:04:50  lr: 0.005000  loss: 0.2860 (0.4391)  loss_classifier: 0.0969 (0.1509)  loss_box_reg: 0.0709 (0.1394)  loss_objectness: 0.0807 (0.1067)  loss_rpn_box_reg: 0.0125 (0.0422)  time: 0.3410  data: 0.1521  max mem: 4022\n",
      "Training Epoch: [9]  [ 350/1229]  eta: 0:04:47  lr: 0.005000  loss: 0.3599 (0.4377)  loss_classifier: 0.1455 (0.1505)  loss_box_reg: 0.1034 (0.1392)  loss_objectness: 0.0778 (0.1063)  loss_rpn_box_reg: 0.0151 (0.0417)  time: 0.3393  data: 0.1511  max mem: 4022\n",
      "Training Epoch: [9]  [ 360/1229]  eta: 0:04:44  lr: 0.005000  loss: 0.4748 (0.4409)  loss_classifier: 0.1496 (0.1515)  loss_box_reg: 0.1302 (0.1397)  loss_objectness: 0.1057 (0.1075)  loss_rpn_box_reg: 0.0219 (0.0421)  time: 0.3270  data: 0.1472  max mem: 4022\n",
      "Training Epoch: [9]  [ 370/1229]  eta: 0:04:40  lr: 0.005000  loss: 0.3724 (0.4385)  loss_classifier: 0.1380 (0.1507)  loss_box_reg: 0.1041 (0.1391)  loss_objectness: 0.0995 (0.1069)  loss_rpn_box_reg: 0.0231 (0.0418)  time: 0.3187  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [9]  [ 380/1229]  eta: 0:04:37  lr: 0.005000  loss: 0.4604 (0.4440)  loss_classifier: 0.1637 (0.1528)  loss_box_reg: 0.1553 (0.1425)  loss_objectness: 0.0949 (0.1071)  loss_rpn_box_reg: 0.0231 (0.0417)  time: 0.3197  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [9]  [ 390/1229]  eta: 0:04:34  lr: 0.005000  loss: 0.5440 (0.4456)  loss_classifier: 0.1765 (0.1530)  loss_box_reg: 0.1553 (0.1425)  loss_objectness: 0.1172 (0.1081)  loss_rpn_box_reg: 0.0280 (0.0420)  time: 0.3232  data: 0.1424  max mem: 4022\n",
      "Training Epoch: [9]  [ 400/1229]  eta: 0:04:30  lr: 0.005000  loss: 0.3835 (0.4427)  loss_classifier: 0.1261 (0.1520)  loss_box_reg: 0.1147 (0.1417)  loss_objectness: 0.0989 (0.1074)  loss_rpn_box_reg: 0.0190 (0.0416)  time: 0.3218  data: 0.1422  max mem: 4022\n",
      "Training Epoch: [9]  [ 410/1229]  eta: 0:04:27  lr: 0.005000  loss: 0.3516 (0.4435)  loss_classifier: 0.1173 (0.1522)  loss_box_reg: 0.1142 (0.1418)  loss_objectness: 0.1077 (0.1077)  loss_rpn_box_reg: 0.0196 (0.0418)  time: 0.3251  data: 0.1414  max mem: 4022\n",
      "Training Epoch: [9]  [ 420/1229]  eta: 0:04:24  lr: 0.005000  loss: 0.3899 (0.4421)  loss_classifier: 0.1252 (0.1518)  loss_box_reg: 0.1179 (0.1415)  loss_objectness: 0.1096 (0.1073)  loss_rpn_box_reg: 0.0270 (0.0415)  time: 0.3237  data: 0.1428  max mem: 4022\n",
      "Training Epoch: [9]  [ 430/1229]  eta: 0:04:20  lr: 0.005000  loss: 0.4029 (0.4414)  loss_classifier: 0.1321 (0.1520)  loss_box_reg: 0.1309 (0.1416)  loss_objectness: 0.0832 (0.1068)  loss_rpn_box_reg: 0.0208 (0.0411)  time: 0.3215  data: 0.1424  max mem: 4022\n",
      "Training Epoch: [9]  [ 440/1229]  eta: 0:04:17  lr: 0.005000  loss: 0.4535 (0.4441)  loss_classifier: 0.1657 (0.1529)  loss_box_reg: 0.1691 (0.1431)  loss_objectness: 0.0855 (0.1070)  loss_rpn_box_reg: 0.0208 (0.0412)  time: 0.3219  data: 0.1433  max mem: 4022\n",
      "Training Epoch: [9]  [ 450/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.5078 (0.4460)  loss_classifier: 0.1738 (0.1537)  loss_box_reg: 0.1768 (0.1439)  loss_objectness: 0.0882 (0.1072)  loss_rpn_box_reg: 0.0246 (0.0412)  time: 0.3175  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [9]  [ 460/1229]  eta: 0:04:10  lr: 0.005000  loss: 0.4144 (0.4439)  loss_classifier: 0.1554 (0.1531)  loss_box_reg: 0.1493 (0.1430)  loss_objectness: 0.0851 (0.1068)  loss_rpn_box_reg: 0.0231 (0.0409)  time: 0.3203  data: 0.1374  max mem: 4022\n",
      "Training Epoch: [9]  [ 470/1229]  eta: 0:04:07  lr: 0.005000  loss: 0.3828 (0.4426)  loss_classifier: 0.1195 (0.1529)  loss_box_reg: 0.1120 (0.1428)  loss_objectness: 0.0845 (0.1066)  loss_rpn_box_reg: 0.0157 (0.0405)  time: 0.3192  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [9]  [ 480/1229]  eta: 0:04:03  lr: 0.005000  loss: 0.4143 (0.4446)  loss_classifier: 0.1682 (0.1539)  loss_box_reg: 0.1494 (0.1439)  loss_objectness: 0.0837 (0.1065)  loss_rpn_box_reg: 0.0289 (0.0402)  time: 0.3221  data: 0.1440  max mem: 4022\n",
      "Training Epoch: [9]  [ 490/1229]  eta: 0:04:00  lr: 0.005000  loss: 0.5133 (0.4459)  loss_classifier: 0.1706 (0.1541)  loss_box_reg: 0.1513 (0.1443)  loss_objectness: 0.1063 (0.1072)  loss_rpn_box_reg: 0.0354 (0.0403)  time: 0.3238  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [9]  [ 500/1229]  eta: 0:03:57  lr: 0.005000  loss: 0.3312 (0.4437)  loss_classifier: 0.1296 (0.1534)  loss_box_reg: 0.1062 (0.1434)  loss_objectness: 0.0997 (0.1069)  loss_rpn_box_reg: 0.0262 (0.0401)  time: 0.3256  data: 0.1439  max mem: 4022\n",
      "Training Epoch: [9]  [ 510/1229]  eta: 0:03:54  lr: 0.005000  loss: 0.2854 (0.4422)  loss_classifier: 0.1113 (0.1530)  loss_box_reg: 0.0760 (0.1423)  loss_objectness: 0.0867 (0.1068)  loss_rpn_box_reg: 0.0170 (0.0401)  time: 0.3296  data: 0.1431  max mem: 4022\n",
      "Training Epoch: [9]  [ 520/1229]  eta: 0:03:50  lr: 0.005000  loss: 0.3816 (0.4423)  loss_classifier: 0.1207 (0.1532)  loss_box_reg: 0.0964 (0.1422)  loss_objectness: 0.0994 (0.1065)  loss_rpn_box_reg: 0.0224 (0.0403)  time: 0.3224  data: 0.1412  max mem: 4022\n",
      "Training Epoch: [9]  [ 530/1229]  eta: 0:03:47  lr: 0.005000  loss: 0.3886 (0.4417)  loss_classifier: 0.1532 (0.1532)  loss_box_reg: 0.1275 (0.1423)  loss_objectness: 0.0775 (0.1061)  loss_rpn_box_reg: 0.0224 (0.0401)  time: 0.3215  data: 0.1425  max mem: 4022\n",
      "Training Epoch: [9]  [ 540/1229]  eta: 0:03:44  lr: 0.005000  loss: 0.5033 (0.4416)  loss_classifier: 0.1786 (0.1530)  loss_box_reg: 0.1387 (0.1425)  loss_objectness: 0.0775 (0.1059)  loss_rpn_box_reg: 0.0274 (0.0402)  time: 0.3235  data: 0.1431  max mem: 4022\n",
      "Training Epoch: [9]  [ 550/1229]  eta: 0:03:40  lr: 0.005000  loss: 0.4173 (0.4428)  loss_classifier: 0.1422 (0.1536)  loss_box_reg: 0.1224 (0.1427)  loss_objectness: 0.0830 (0.1060)  loss_rpn_box_reg: 0.0274 (0.0406)  time: 0.3218  data: 0.1432  max mem: 4022\n",
      "Training Epoch: [9]  [ 560/1229]  eta: 0:03:37  lr: 0.005000  loss: 0.5051 (0.4466)  loss_classifier: 0.1627 (0.1547)  loss_box_reg: 0.1608 (0.1442)  loss_objectness: 0.0839 (0.1063)  loss_rpn_box_reg: 0.0272 (0.0414)  time: 0.3246  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [9]  [ 570/1229]  eta: 0:03:34  lr: 0.005000  loss: 0.5169 (0.4471)  loss_classifier: 0.1627 (0.1548)  loss_box_reg: 0.1449 (0.1441)  loss_objectness: 0.1211 (0.1066)  loss_rpn_box_reg: 0.0227 (0.0416)  time: 0.3276  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [9]  [ 580/1229]  eta: 0:03:31  lr: 0.005000  loss: 0.3547 (0.4467)  loss_classifier: 0.1123 (0.1544)  loss_box_reg: 0.1036 (0.1435)  loss_objectness: 0.1199 (0.1067)  loss_rpn_box_reg: 0.0317 (0.0421)  time: 0.3237  data: 0.1424  max mem: 4022\n",
      "Training Epoch: [9]  [ 590/1229]  eta: 0:03:27  lr: 0.005000  loss: 0.3547 (0.4459)  loss_classifier: 0.1123 (0.1540)  loss_box_reg: 0.1036 (0.1430)  loss_objectness: 0.0947 (0.1069)  loss_rpn_box_reg: 0.0211 (0.0420)  time: 0.3159  data: 0.1418  max mem: 4022\n",
      "Training Epoch: [9]  [ 600/1229]  eta: 0:03:24  lr: 0.005000  loss: 0.4151 (0.4469)  loss_classifier: 0.1390 (0.1543)  loss_box_reg: 0.0898 (0.1427)  loss_objectness: 0.1200 (0.1075)  loss_rpn_box_reg: 0.0211 (0.0424)  time: 0.3217  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [9]  [ 610/1229]  eta: 0:03:21  lr: 0.005000  loss: 0.4151 (0.4455)  loss_classifier: 0.1363 (0.1537)  loss_box_reg: 0.0867 (0.1418)  loss_objectness: 0.1200 (0.1075)  loss_rpn_box_reg: 0.0241 (0.0425)  time: 0.3364  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [9]  [ 620/1229]  eta: 0:03:18  lr: 0.005000  loss: 0.4103 (0.4456)  loss_classifier: 0.1144 (0.1537)  loss_box_reg: 0.1069 (0.1418)  loss_objectness: 0.0929 (0.1075)  loss_rpn_box_reg: 0.0256 (0.0426)  time: 0.3318  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [9]  [ 630/1229]  eta: 0:03:15  lr: 0.005000  loss: 0.4103 (0.4443)  loss_classifier: 0.1394 (0.1532)  loss_box_reg: 0.1196 (0.1414)  loss_objectness: 0.0897 (0.1073)  loss_rpn_box_reg: 0.0263 (0.0424)  time: 0.3276  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [9]  [ 640/1229]  eta: 0:03:11  lr: 0.005000  loss: 0.2822 (0.4422)  loss_classifier: 0.0995 (0.1526)  loss_box_reg: 0.0866 (0.1407)  loss_objectness: 0.0764 (0.1068)  loss_rpn_box_reg: 0.0171 (0.0421)  time: 0.3310  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [9]  [ 650/1229]  eta: 0:03:08  lr: 0.005000  loss: 0.2822 (0.4429)  loss_classifier: 0.1161 (0.1529)  loss_box_reg: 0.1027 (0.1407)  loss_objectness: 0.0920 (0.1070)  loss_rpn_box_reg: 0.0200 (0.0423)  time: 0.3312  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [9]  [ 660/1229]  eta: 0:03:05  lr: 0.005000  loss: 0.5095 (0.4422)  loss_classifier: 0.1368 (0.1526)  loss_box_reg: 0.1535 (0.1407)  loss_objectness: 0.0913 (0.1066)  loss_rpn_box_reg: 0.0224 (0.0423)  time: 0.3251  data: 0.1430  max mem: 4022\n",
      "Training Epoch: [9]  [ 670/1229]  eta: 0:03:02  lr: 0.005000  loss: 0.5131 (0.4429)  loss_classifier: 0.1368 (0.1527)  loss_box_reg: 0.1582 (0.1411)  loss_objectness: 0.0897 (0.1068)  loss_rpn_box_reg: 0.0248 (0.0424)  time: 0.3227  data: 0.1425  max mem: 4022\n",
      "Training Epoch: [9]  [ 680/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.5296 (0.4441)  loss_classifier: 0.1666 (0.1529)  loss_box_reg: 0.1849 (0.1418)  loss_objectness: 0.1144 (0.1067)  loss_rpn_box_reg: 0.0318 (0.0426)  time: 0.3273  data: 0.1387  max mem: 4022\n",
      "Training Epoch: [9]  [ 690/1229]  eta: 0:02:55  lr: 0.005000  loss: 0.5470 (0.4458)  loss_classifier: 0.1827 (0.1539)  loss_box_reg: 0.1770 (0.1425)  loss_objectness: 0.1018 (0.1069)  loss_rpn_box_reg: 0.0344 (0.0425)  time: 0.3264  data: 0.1385  max mem: 4022\n",
      "Training Epoch: [9]  [ 700/1229]  eta: 0:02:52  lr: 0.005000  loss: 0.5470 (0.4461)  loss_classifier: 0.1775 (0.1541)  loss_box_reg: 0.1627 (0.1428)  loss_objectness: 0.1018 (0.1068)  loss_rpn_box_reg: 0.0250 (0.0425)  time: 0.3250  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [9]  [ 710/1229]  eta: 0:02:49  lr: 0.005000  loss: 0.4096 (0.4462)  loss_classifier: 0.1472 (0.1543)  loss_box_reg: 0.1239 (0.1429)  loss_objectness: 0.0995 (0.1067)  loss_rpn_box_reg: 0.0243 (0.0423)  time: 0.3285  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [9]  [ 720/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.4208 (0.4481)  loss_classifier: 0.1548 (0.1551)  loss_box_reg: 0.1239 (0.1437)  loss_objectness: 0.1024 (0.1071)  loss_rpn_box_reg: 0.0243 (0.0422)  time: 0.3262  data: 0.1407  max mem: 4022\n",
      "Training Epoch: [9]  [ 730/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.5973 (0.4492)  loss_classifier: 0.2042 (0.1555)  loss_box_reg: 0.1557 (0.1440)  loss_objectness: 0.1160 (0.1073)  loss_rpn_box_reg: 0.0327 (0.0425)  time: 0.3208  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [9]  [ 740/1229]  eta: 0:02:39  lr: 0.005000  loss: 0.5190 (0.4499)  loss_classifier: 0.1762 (0.1556)  loss_box_reg: 0.1897 (0.1446)  loss_objectness: 0.1159 (0.1073)  loss_rpn_box_reg: 0.0352 (0.0424)  time: 0.3215  data: 0.1382  max mem: 4022\n",
      "Training Epoch: [9]  [ 750/1229]  eta: 0:02:35  lr: 0.005000  loss: 0.4726 (0.4496)  loss_classifier: 0.1634 (0.1556)  loss_box_reg: 0.1405 (0.1443)  loss_objectness: 0.0933 (0.1073)  loss_rpn_box_reg: 0.0238 (0.0424)  time: 0.3242  data: 0.1366  max mem: 4022\n",
      "Training Epoch: [9]  [ 760/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.4004 (0.4497)  loss_classifier: 0.1413 (0.1555)  loss_box_reg: 0.0991 (0.1444)  loss_objectness: 0.0807 (0.1072)  loss_rpn_box_reg: 0.0300 (0.0425)  time: 0.3299  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [9]  [ 770/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.4004 (0.4500)  loss_classifier: 0.1196 (0.1554)  loss_box_reg: 0.1134 (0.1444)  loss_objectness: 0.0749 (0.1072)  loss_rpn_box_reg: 0.0258 (0.0430)  time: 0.3298  data: 0.1366  max mem: 4022\n",
      "Training Epoch: [9]  [ 780/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.4036 (0.4502)  loss_classifier: 0.1196 (0.1555)  loss_box_reg: 0.1130 (0.1444)  loss_objectness: 0.0870 (0.1073)  loss_rpn_box_reg: 0.0269 (0.0430)  time: 0.3239  data: 0.1368  max mem: 4022\n",
      "Training Epoch: [9]  [ 790/1229]  eta: 0:02:22  lr: 0.005000  loss: 0.4036 (0.4500)  loss_classifier: 0.1566 (0.1555)  loss_box_reg: 0.1092 (0.1441)  loss_objectness: 0.1120 (0.1073)  loss_rpn_box_reg: 0.0349 (0.0430)  time: 0.3246  data: 0.1376  max mem: 4022\n",
      "Training Epoch: [9]  [ 800/1229]  eta: 0:02:19  lr: 0.005000  loss: 0.3700 (0.4494)  loss_classifier: 0.1533 (0.1555)  loss_box_reg: 0.1050 (0.1440)  loss_objectness: 0.0884 (0.1070)  loss_rpn_box_reg: 0.0219 (0.0429)  time: 0.3251  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [9]  [ 810/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.4571 (0.4501)  loss_classifier: 0.1636 (0.1560)  loss_box_reg: 0.1275 (0.1442)  loss_objectness: 0.0899 (0.1071)  loss_rpn_box_reg: 0.0232 (0.0428)  time: 0.3282  data: 0.1382  max mem: 4022\n",
      "Training Epoch: [9]  [ 820/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.4126 (0.4493)  loss_classifier: 0.1705 (0.1557)  loss_box_reg: 0.1297 (0.1440)  loss_objectness: 0.0888 (0.1069)  loss_rpn_box_reg: 0.0248 (0.0428)  time: 0.3332  data: 0.1380  max mem: 4022\n",
      "Training Epoch: [9]  [ 830/1229]  eta: 0:02:09  lr: 0.005000  loss: 0.2824 (0.4479)  loss_classifier: 0.1021 (0.1552)  loss_box_reg: 0.0962 (0.1436)  loss_objectness: 0.0750 (0.1065)  loss_rpn_box_reg: 0.0183 (0.0426)  time: 0.3265  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [9]  [ 840/1229]  eta: 0:02:06  lr: 0.005000  loss: 0.4288 (0.4495)  loss_classifier: 0.1550 (0.1558)  loss_box_reg: 0.1094 (0.1443)  loss_objectness: 0.0819 (0.1068)  loss_rpn_box_reg: 0.0281 (0.0426)  time: 0.3225  data: 0.1408  max mem: 4022\n",
      "Training Epoch: [9]  [ 850/1229]  eta: 0:02:03  lr: 0.005000  loss: 0.4822 (0.4490)  loss_classifier: 0.1681 (0.1556)  loss_box_reg: 0.1586 (0.1441)  loss_objectness: 0.1063 (0.1068)  loss_rpn_box_reg: 0.0312 (0.0425)  time: 0.3231  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [9]  [ 860/1229]  eta: 0:02:00  lr: 0.005000  loss: 0.4310 (0.4493)  loss_classifier: 0.1468 (0.1558)  loss_box_reg: 0.1552 (0.1443)  loss_objectness: 0.0868 (0.1067)  loss_rpn_box_reg: 0.0234 (0.0424)  time: 0.3241  data: 0.1366  max mem: 4022\n",
      "Training Epoch: [9]  [ 870/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.3911 (0.4493)  loss_classifier: 0.1502 (0.1559)  loss_box_reg: 0.1252 (0.1442)  loss_objectness: 0.0819 (0.1067)  loss_rpn_box_reg: 0.0188 (0.0424)  time: 0.3272  data: 0.1373  max mem: 4022\n",
      "Training Epoch: [9]  [ 880/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.3911 (0.4489)  loss_classifier: 0.1391 (0.1558)  loss_box_reg: 0.1168 (0.1440)  loss_objectness: 0.0808 (0.1065)  loss_rpn_box_reg: 0.0272 (0.0425)  time: 0.3299  data: 0.1384  max mem: 4022\n",
      "Training Epoch: [9]  [ 890/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.4592 (0.4493)  loss_classifier: 0.1374 (0.1558)  loss_box_reg: 0.1294 (0.1440)  loss_objectness: 0.1061 (0.1067)  loss_rpn_box_reg: 0.0392 (0.0428)  time: 0.3296  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [9]  [ 900/1229]  eta: 0:01:47  lr: 0.005000  loss: 0.4287 (0.4488)  loss_classifier: 0.1385 (0.1556)  loss_box_reg: 0.1185 (0.1439)  loss_objectness: 0.0933 (0.1066)  loss_rpn_box_reg: 0.0231 (0.0427)  time: 0.3232  data: 0.1391  max mem: 4022\n",
      "Training Epoch: [9]  [ 910/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.3070 (0.4486)  loss_classifier: 0.1056 (0.1555)  loss_box_reg: 0.1055 (0.1441)  loss_objectness: 0.0718 (0.1063)  loss_rpn_box_reg: 0.0124 (0.0426)  time: 0.3206  data: 0.1390  max mem: 4022\n",
      "Training Epoch: [9]  [ 920/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.3087 (0.4482)  loss_classifier: 0.0998 (0.1555)  loss_box_reg: 0.0967 (0.1439)  loss_objectness: 0.0743 (0.1062)  loss_rpn_box_reg: 0.0252 (0.0426)  time: 0.3248  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [9]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.3582 (0.4482)  loss_classifier: 0.1625 (0.1556)  loss_box_reg: 0.1470 (0.1441)  loss_objectness: 0.0774 (0.1060)  loss_rpn_box_reg: 0.0272 (0.0426)  time: 0.3276  data: 0.1378  max mem: 4022\n",
      "Training Epoch: [9]  [ 940/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.3582 (0.4475)  loss_classifier: 0.1312 (0.1554)  loss_box_reg: 0.1200 (0.1436)  loss_objectness: 0.0774 (0.1060)  loss_rpn_box_reg: 0.0238 (0.0425)  time: 0.3279  data: 0.1358  max mem: 4022\n",
      "Training Epoch: [9]  [ 950/1229]  eta: 0:01:30  lr: 0.005000  loss: 0.3199 (0.4466)  loss_classifier: 0.1003 (0.1551)  loss_box_reg: 0.0760 (0.1431)  loss_objectness: 0.0880 (0.1058)  loss_rpn_box_reg: 0.0225 (0.0425)  time: 0.3215  data: 0.1367  max mem: 4022\n",
      "Training Epoch: [9]  [ 960/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.3398 (0.4460)  loss_classifier: 0.1310 (0.1550)  loss_box_reg: 0.0943 (0.1426)  loss_objectness: 0.0890 (0.1060)  loss_rpn_box_reg: 0.0221 (0.0423)  time: 0.3231  data: 0.1394  max mem: 4022\n",
      "Training Epoch: [9]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.3398 (0.4454)  loss_classifier: 0.1353 (0.1548)  loss_box_reg: 0.1001 (0.1424)  loss_objectness: 0.0890 (0.1060)  loss_rpn_box_reg: 0.0164 (0.0422)  time: 0.3300  data: 0.1404  max mem: 4022\n",
      "Training Epoch: [9]  [ 980/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.3887 (0.4464)  loss_classifier: 0.1462 (0.1551)  loss_box_reg: 0.1117 (0.1428)  loss_objectness: 0.0938 (0.1062)  loss_rpn_box_reg: 0.0331 (0.0424)  time: 0.3251  data: 0.1384  max mem: 4022\n",
      "Training Epoch: [9]  [ 990/1229]  eta: 0:01:17  lr: 0.005000  loss: 0.3415 (0.4459)  loss_classifier: 0.1166 (0.1548)  loss_box_reg: 0.0958 (0.1426)  loss_objectness: 0.0928 (0.1059)  loss_rpn_box_reg: 0.0271 (0.0425)  time: 0.3249  data: 0.1395  max mem: 4022\n",
      "Training Epoch: [9]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.2953 (0.4458)  loss_classifier: 0.1192 (0.1548)  loss_box_reg: 0.0933 (0.1425)  loss_objectness: 0.0886 (0.1060)  loss_rpn_box_reg: 0.0192 (0.0424)  time: 0.3347  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [9]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.3691 (0.4457)  loss_classifier: 0.1283 (0.1549)  loss_box_reg: 0.0967 (0.1424)  loss_objectness: 0.0894 (0.1060)  loss_rpn_box_reg: 0.0238 (0.0424)  time: 0.3286  data: 0.1394  max mem: 4022\n",
      "Training Epoch: [9]  [1020/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.3832 (0.4462)  loss_classifier: 0.1304 (0.1552)  loss_box_reg: 0.1306 (0.1426)  loss_objectness: 0.0959 (0.1059)  loss_rpn_box_reg: 0.0268 (0.0424)  time: 0.3217  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [9]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.4040 (0.4457)  loss_classifier: 0.1303 (0.1549)  loss_box_reg: 0.1225 (0.1424)  loss_objectness: 0.0967 (0.1060)  loss_rpn_box_reg: 0.0231 (0.0423)  time: 0.3177  data: 0.1374  max mem: 4022\n",
      "Training Epoch: [9]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.4291 (0.4462)  loss_classifier: 0.1310 (0.1550)  loss_box_reg: 0.1155 (0.1423)  loss_objectness: 0.1094 (0.1064)  loss_rpn_box_reg: 0.0231 (0.0425)  time: 0.3149  data: 0.1392  max mem: 4022\n",
      "Training Epoch: [9]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.4474 (0.4460)  loss_classifier: 0.1364 (0.1549)  loss_box_reg: 0.1059 (0.1421)  loss_objectness: 0.1054 (0.1065)  loss_rpn_box_reg: 0.0301 (0.0426)  time: 0.3220  data: 0.1403  max mem: 4022\n",
      "Training Epoch: [9]  [1060/1229]  eta: 0:00:55  lr: 0.005000  loss: 0.3290 (0.4453)  loss_classifier: 0.1148 (0.1546)  loss_box_reg: 0.0910 (0.1418)  loss_objectness: 0.0782 (0.1063)  loss_rpn_box_reg: 0.0291 (0.0426)  time: 0.3255  data: 0.1406  max mem: 4022\n",
      "Training Epoch: [9]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.3320 (0.4453)  loss_classifier: 0.1152 (0.1546)  loss_box_reg: 0.0928 (0.1418)  loss_objectness: 0.0708 (0.1062)  loss_rpn_box_reg: 0.0218 (0.0428)  time: 0.3280  data: 0.1445  max mem: 4022\n",
      "Training Epoch: [9]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.3736 (0.4454)  loss_classifier: 0.1237 (0.1546)  loss_box_reg: 0.0972 (0.1418)  loss_objectness: 0.0913 (0.1063)  loss_rpn_box_reg: 0.0200 (0.0427)  time: 0.3316  data: 0.1478  max mem: 4022\n",
      "Training Epoch: [9]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.3353 (0.4451)  loss_classifier: 0.1189 (0.1544)  loss_box_reg: 0.1108 (0.1419)  loss_objectness: 0.1012 (0.1062)  loss_rpn_box_reg: 0.0174 (0.0426)  time: 0.3306  data: 0.1464  max mem: 4022\n",
      "Training Epoch: [9]  [1100/1229]  eta: 0:00:42  lr: 0.005000  loss: 0.3353 (0.4445)  loss_classifier: 0.1105 (0.1542)  loss_box_reg: 0.1108 (0.1416)  loss_objectness: 0.0781 (0.1061)  loss_rpn_box_reg: 0.0232 (0.0426)  time: 0.3284  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [9]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.4084 (0.4449)  loss_classifier: 0.1438 (0.1542)  loss_box_reg: 0.0975 (0.1416)  loss_objectness: 0.0970 (0.1062)  loss_rpn_box_reg: 0.0283 (0.0428)  time: 0.3247  data: 0.1369  max mem: 4022\n",
      "Training Epoch: [9]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4449 (0.4457)  loss_classifier: 0.1645 (0.1546)  loss_box_reg: 0.1500 (0.1421)  loss_objectness: 0.1067 (0.1063)  loss_rpn_box_reg: 0.0267 (0.0428)  time: 0.3209  data: 0.1385  max mem: 4022\n",
      "Training Epoch: [9]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.4210 (0.4463)  loss_classifier: 0.1503 (0.1545)  loss_box_reg: 0.1427 (0.1420)  loss_objectness: 0.1234 (0.1067)  loss_rpn_box_reg: 0.0269 (0.0430)  time: 0.3247  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [9]  [1140/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.3809 (0.4468)  loss_classifier: 0.1366 (0.1547)  loss_box_reg: 0.1233 (0.1420)  loss_objectness: 0.1246 (0.1069)  loss_rpn_box_reg: 0.0382 (0.0431)  time: 0.3253  data: 0.1397  max mem: 4022\n",
      "Training Epoch: [9]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.4403 (0.4474)  loss_classifier: 0.1497 (0.1548)  loss_box_reg: 0.1586 (0.1423)  loss_objectness: 0.1190 (0.1071)  loss_rpn_box_reg: 0.0430 (0.0432)  time: 0.3263  data: 0.1384  max mem: 4022\n",
      "Training Epoch: [9]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.3592 (0.4470)  loss_classifier: 0.1078 (0.1546)  loss_box_reg: 0.1157 (0.1423)  loss_objectness: 0.0848 (0.1069)  loss_rpn_box_reg: 0.0309 (0.0431)  time: 0.3266  data: 0.1400  max mem: 4022\n",
      "Training Epoch: [9]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.3150 (0.4470)  loss_classifier: 0.1096 (0.1547)  loss_box_reg: 0.1104 (0.1423)  loss_objectness: 0.0725 (0.1070)  loss_rpn_box_reg: 0.0265 (0.0430)  time: 0.3228  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [9]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.3150 (0.4467)  loss_classifier: 0.1227 (0.1547)  loss_box_reg: 0.1091 (0.1423)  loss_objectness: 0.0695 (0.1068)  loss_rpn_box_reg: 0.0207 (0.0429)  time: 0.3206  data: 0.1368  max mem: 4022\n",
      "Training Epoch: [9]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.3113 (0.4461)  loss_classifier: 0.1188 (0.1545)  loss_box_reg: 0.1081 (0.1422)  loss_objectness: 0.0672 (0.1067)  loss_rpn_box_reg: 0.0170 (0.0428)  time: 0.3238  data: 0.1391  max mem: 4022\n",
      "Training Epoch: [9]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.3398 (0.4456)  loss_classifier: 0.1188 (0.1543)  loss_box_reg: 0.1178 (0.1421)  loss_objectness: 0.0726 (0.1066)  loss_rpn_box_reg: 0.0246 (0.0426)  time: 0.3272  data: 0.1402  max mem: 4022\n",
      "Training Epoch: [9]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.3474 (0.4454)  loss_classifier: 0.1236 (0.1543)  loss_box_reg: 0.1265 (0.1422)  loss_objectness: 0.0826 (0.1064)  loss_rpn_box_reg: 0.0250 (0.0425)  time: 0.3277  data: 0.1371  max mem: 4022\n",
      "Training Epoch: [9]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.4558 (0.4464)  loss_classifier: 0.1613 (0.1546)  loss_box_reg: 0.1587 (0.1425)  loss_objectness: 0.1018 (0.1067)  loss_rpn_box_reg: 0.0249 (0.0426)  time: 0.3241  data: 0.1377  max mem: 4022\n",
      "Training Epoch: [9]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4443 (0.4463)  loss_classifier: 0.1613 (0.1545)  loss_box_reg: 0.1587 (0.1424)  loss_objectness: 0.1027 (0.1067)  loss_rpn_box_reg: 0.0249 (0.0426)  time: 0.3239  data: 0.1400  max mem: 4022\n",
      "Training Epoch: [9] Total time: 0:06:40 (0.3257 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:02:05  model_time: 0.3710 (0.3710)  evaluator_time: 0.0030 (0.0030)  time: 0.4060  data: 0.0300  max mem: 4022\n",
      "Test:  [100/308]  eta: 0:00:33  model_time: 0.1070 (0.1124)  evaluator_time: 0.0030 (0.0070)  time: 0.1581  data: 0.0383  max mem: 4022\n",
      "Test:  [200/308]  eta: 0:00:16  model_time: 0.1160 (0.1117)  evaluator_time: 0.0030 (0.0064)  time: 0.1536  data: 0.0321  max mem: 4022\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0990 (0.1104)  evaluator_time: 0.0040 (0.0062)  time: 0.1482  data: 0.0378  max mem: 4022\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0990 (0.1101)  evaluator_time: 0.0030 (0.0062)  time: 0.1501  data: 0.0417  max mem: 4022\n",
      "Test: Total time: 0:00:47 (0.1552 s / it)\n",
      "Averaged stats: model_time: 0.0990 (0.1101)  evaluator_time: 0.0030 (0.0062)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.038\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.083\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.274\n",
      "Testing Epoch: [9]  [  0/308]  eta: 0:00:46  lr: 0.005000  loss: 0.2042 (0.2042)  loss_classifier: 0.0727 (0.0727)  loss_box_reg: 0.0752 (0.0752)  loss_objectness: 0.0444 (0.0444)  loss_rpn_box_reg: 0.0119 (0.0119)  time: 0.1510  data: 0.0300  max mem: 4022\n",
      "Testing Epoch: [9]  [100/308]  eta: 0:00:36  lr: 0.005000  loss: 0.3174 (0.5183)  loss_classifier: 0.1245 (0.1771)  loss_box_reg: 0.1294 (0.1768)  loss_objectness: 0.0739 (0.1084)  loss_rpn_box_reg: 0.0179 (0.0561)  time: 0.1782  data: 0.0420  max mem: 4022\n",
      "Testing Epoch: [9]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.4543 (0.4931)  loss_classifier: 0.1338 (0.1691)  loss_box_reg: 0.1636 (0.1670)  loss_objectness: 0.0845 (0.1043)  loss_rpn_box_reg: 0.0274 (0.0527)  time: 0.1785  data: 0.0354  max mem: 4022\n",
      "Testing Epoch: [9]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.4778 (0.4951)  loss_classifier: 0.1793 (0.1714)  loss_box_reg: 0.1777 (0.1703)  loss_objectness: 0.0973 (0.1020)  loss_rpn_box_reg: 0.0343 (0.0514)  time: 0.1694  data: 0.0421  max mem: 4022\n",
      "Testing Epoch: [9]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.4743 (0.4950)  loss_classifier: 0.1612 (0.1717)  loss_box_reg: 0.1702 (0.1705)  loss_objectness: 0.0888 (0.1019)  loss_rpn_box_reg: 0.0293 (0.0509)  time: 0.1729  data: 0.0454  max mem: 4022\n",
      "Testing Epoch: [9] Total time: 0:00:54 (0.1766 s / it)\n"
     ]
    }
   ],
   "source": [
    "#train a custom vanilla model so that we can compare and make sure the CLIP FRCNN is comparable\n",
    "# Fully-Custom-Vanilla is most appropriate as it generates the model in a similar fashion\n",
    "MODEL_TYPE = 'Fully-Custom-Vanilla'\n",
    "\n",
    "vanilla_model = create_model(MODEL_TYPE, num_classes=(len(item_list)+1))\n",
    "train_model(vanilla_model, train_dataset, evaluation_dataset, num_epochs=10, MODEL_TYPE=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj3vLT1eXFnk"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkzG1i3AW1O7",
    "outputId": "ec7971c3-66ef-4a57-e710-248cb53dee8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      " 100% |█████████████████| 615/615 [45.2s elapsed, 0s remaining, 13.6 samples/s]      \n",
      "Evaluating detections...\n",
      " 100% |█████████████████| 615/615 [11.0s elapsed, 0s remaining, 59.3 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |█████████████████| 615/615 [14.2s elapsed, 0s remaining, 47.1 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "add_detections(model, evaluation_dataset, fo_dataset, field_name=\"predictions\")\n",
    "\n",
    "results = fo.evaluate_detections(\n",
    "    test_view,\n",
    "    \"predictions\",\n",
    "    classes=item_list,\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uYdXrhgYdJ_",
    "outputId": "2eb792e9-342f-4dc8-f6c0-e1503d8bf193"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12274161085786321"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcJBOM76aJPR",
    "outputId": "ac452527-7608-4e8d-f57e-18a0470acd30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.10      0.59      0.17       508\n",
      "         dog       0.15      0.80      0.25        41\n",
      "         bus       0.13      0.70      0.22        90\n",
      "        fork       0.09      0.18      0.12        44\n",
      "         tie       0.11      0.10      0.11        29\n",
      "      person       0.31      0.86      0.45      4349\n",
      "\n",
      "   micro avg       0.26      0.82      0.39      5061\n",
      "   macro avg       0.15      0.54      0.22      5061\n",
      "weighted avg       0.28      0.82      0.41      5061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nddFfGSnXo7i"
   },
   "source": [
    "By default, objects are only matched with other objects of the same class. In order to get an interesting confusion matrix, we need to match interclass objects by setting `classwise=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_53aCMna2Vt",
    "outputId": "4db71f31-73e3-4036-f623-efd8e2ac85bf"
   },
   "outputs": [],
   "source": [
    "results_interclass = fo.evaluate_detections(\n",
    "    test_view, \n",
    "    \"predictions\", \n",
    "    classes=item_list,\n",
    "    compute_mAP=True, \n",
    "    classwise=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot = results.plot_pr_curves(classes=item_list)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "Nbqf-NuAZ7Ps",
    "outputId": "571cd947-c94a-4b9a-ed93-2330fbddea7e"
   },
   "outputs": [],
   "source": [
    "results_interclass.plot_confusion_matrix(classes=item_list, include_other=False, include_missing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElSV7tTbYKLr"
   },
   "source": [
    "The [detection evaluation](https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#detections) also added the attributes `eval_fp`, `eval_tp`, and `eval_fn` to every predicted detection indicating if it is a false positive, true positive, or false negative. \n",
    "Let's create a view to find the worst samples by sorting by `eval_fp` using the [FiftyOne App](https://voxel51.com/docs/fiftyone/user_guide/app.html) to visualize the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786,
     "resources": {
      "https://localhost:5151/polling?sessionId=de0b710e-15f8-4c57-ba46-ae7955f716b1": {
       "data": "eyJtZXNzYWdlcyI6IFtdfQ==",
       "headers": [
        [
         "access-control-allow-headers",
         "x-requested-with"
        ],
        [
         "content-type",
         "text/html; charset=UTF-8"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "Pm4Z52rd8AC1",
    "outputId": "62d39076-7ef3-4fe3-95ae-500d0f8f8a3f"
   },
   "outputs": [],
   "source": [
    "session.view = test_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786,
     "resources": {
      "https://localhost:5151/polling?sessionId=ebbc318d-3578-4fb1-9ae7-68596117572b": {
       "data": "eyJtZXNzYWdlcyI6IFtdfQ==",
       "headers": [
        [
         "access-control-allow-headers",
         "x-requested-with"
        ],
        [
         "content-type",
         "text/html; charset=UTF-8"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "njLG0l5K-ucV",
    "outputId": "bda6f02d-d8fe-49be-d212-31e0e70779e3"
   },
   "outputs": [],
   "source": [
    "session.view = test_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReXDVFgLZLtf"
   },
   "source": [
    "It would be best to get this [data reannotated to fix these mistakes](https://towardsdatascience.com/managing-annotation-mistakes-with-fiftyone-and-labelbox-fc6e87b51102), but in the meantime, we can easily remedy this by simply creating a new view that remaps the labels `car`, `truck`, and `bus` all to `vehicle` and then retraining the model with that. This is only possible because we are backing our data in FiftyOne and loading views into PyTorch as needed. Without FiftyOne, the PyTorch dataset class or the underlying data would need to be changed to remap these classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# map labels to single vehicle class\n",
    "vehicle_list = ['car', 'bus', 'truck']\n",
    "vehicles_map = {c: \"vehicle\" for c in vehicle_list}\n",
    "\n",
    "train_map_view = train_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "test_map_view = test_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "torch_map_dataset = FiftyOneTorchDataset(train_map_view, train_transforms)\n",
    "torch_map_dataset_test = FiftyOneTorchDataset(test_map_view, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ynRCHQv8XB_v"
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'model' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19068/3484283395.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Only 2 classes (background and vehicle)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mMODEL_TYPE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Vanilla-FRCNN'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvehicle_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_TYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvehicles_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch_map_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch_map_dataset_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMODEL_TYPE\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMODEL_TYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Git\\Torch_CLIP_FRCNN\\model.py\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(model_type, num_classes)\u001b[0m\n\u001b[0;32m    116\u001b[0m                            \u001b[0mimage_std\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                            ).half().to(config.DEVICE)\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mtest_backbone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'model' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Only 2 classes (background and vehicle)\n",
    "MODEL_TYPE = 'Vanilla-FRCNN'\n",
    "vehicle_model = create_model(MODEL_TYPE, num_classes=(len(vehicles_map)+1))\n",
    "train_model(vehicle_model, torch_map_dataset, torch_map_dataset_test, num_epochs=2, MODEL_TYPE=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-mrVOl4XFbp",
    "outputId": "6d8bec76-ebe8-4a36-959a-52bb1aab8498"
   },
   "outputs": [],
   "source": [
    "add_detections(vehicle_model, torch_map_dataset_test, test_map_view, field_name=\"vehicle_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfd3xvhaXhl_",
    "outputId": "d9c4a2fe-538a-4979-c3f8-f5ede0c98aa1"
   },
   "outputs": [],
   "source": [
    "vehicle_results = fo.evaluate_detections(\n",
    "    test_map_view, \n",
    "    \"vehicle_predictions\", \n",
    "    classes=[\"vehicle\"], \n",
    "    eval_key=\"vehicle_eval\", \n",
    "    compute_mAP=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFvddH3rk0NR",
    "outputId": "59572ba2-f9ad-4dd2-e9ac-90877190ff99"
   },
   "outputs": [],
   "source": [
    "vehicle_results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwbhq18sk1PL",
    "outputId": "d6985867-5049-4678-cc88-d5041a0079ed"
   },
   "outputs": [],
   "source": [
    "vehicle_results.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJMAkJbWZ_u1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Due to our ability to easily visualize and manage our dataset with FiftyOne, we were able to spot and take action on a dataset issue that would otherwise have gone unnoticed if we only concerned ourselves with dataset-wide evaluation metrics and fixed dataset representations. Through these efforts, we managed to increase the mAP of the model to 43%.\n",
    "\n",
    "Even though this example workflow may not work in all situations, this kind of class-merging strategy can be effective in cases where more fine-grained discrimination is not called for."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "fiftyone_pytorch_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CLIPRCNN",
   "language": "python",
   "name": "cliprcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "32b6ec3046e64d04b4134553dc434fe0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a4788a4fd6841788b20cfbf54a3d10b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5d836b94d13e459d82429606496e4d4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1645bdfb02b42fba268f7000f183639": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c063e7d90f6a4027b53d1b70c8c07742",
      "placeholder": "​",
      "style": "IPY_MODEL_a410071b34034a91aeda7ef1114969c2",
      "value": " 160M/160M [01:05&lt;00:00, 2.55MB/s]"
     }
    },
    "a410071b34034a91aeda7ef1114969c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acbb3df601244291b8b2fb9ea1137573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8c6a316609d4ca5bfee139b93177ef5",
       "IPY_MODEL_a1645bdfb02b42fba268f7000f183639"
      ],
      "layout": "IPY_MODEL_32b6ec3046e64d04b4134553dc434fe0"
     }
    },
    "c063e7d90f6a4027b53d1b70c8c07742": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8c6a316609d4ca5bfee139b93177ef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d836b94d13e459d82429606496e4d4f",
      "max": 167502836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a4788a4fd6841788b20cfbf54a3d10b",
      "value": 167502836
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
