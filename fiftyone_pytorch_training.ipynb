{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Code for using FiftyOne to train a Faster RCNN on COCO data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZ2cvwpPWXBt",
    "outputId": "6444f42e-7465-4625-e4b1-3c207385fce9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x13f84710850>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "from dataset import FiftyOneTorchDataset, get_transforms\n",
    "from model import create_model\n",
    "from utils import add_detections\n",
    "\n",
    "from engine import train_model\n",
    "import config\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load full dataset from model zoo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5crNDNsRWdPT",
    "outputId": "4f3ff734-ca0a-4312-a811-7f84db514fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to 'C:\\Users\\blain\\fiftyone\\coco-2017\\validation' if necessary\n",
      "Found annotations at 'C:\\Users\\blain\\fiftyone\\coco-2017\\raw\\instances_val2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading existing dataset 'coco-2017-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x13f98b0fb80>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"800\"\n            src=\"http://localhost:5151/?notebook=true&handleId=453d868f-0533-497b-975c-6da700bc8527\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lodad in the dataset from the FiftyOne model Zoo\n",
    "fo_dataset = foz.load_zoo_dataset(\"coco-2017\", \"validation\")\n",
    "\n",
    "#needed to calculate image height and width\n",
    "fo_dataset.compute_metadata()\n",
    "\n",
    "session = fo.launch_app(fo_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqU6Ckq4WKHK"
   },
   "source": [
    "For example, cluttered images make it difficult for models to localize objects. We can use FiftyOne to create a view containing only samples with more than, say, 10 objects. You can perform the same operations on views as datasets, so we can create an instance of our PyTorch dataset from this view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kLACOukJFUxd"
   },
   "outputs": [],
   "source": [
    "#if we want to see images with more than 10 items, we can\n",
    "# busy_view = fo_dataset.match(F(\"ground_truth.detections\").length() > 10)\n",
    "# busy_torch_dataset = FiftyOneTorchDataset(busy_view)\n",
    "# session.view = busy_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKsE_7TOWXBE"
   },
   "source": [
    "### Create training and testing views (and corresponding PyTorch datasets) that only contain some items from the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TELK0NWmWrMT",
    "outputId": "8bf582cf-e483-4643-8f6b-7c664a2d6c5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning on 2458 samples\n",
      "Testing on 615 samples\n"
     ]
    }
   ],
   "source": [
    "# to filter certain items from the dataset we can\n",
    "item_list = [\"car\", \"dog\", \"bus\", 'fork', 'tie', 'person']\n",
    "item_view = fo_dataset.filter_labels(\"ground_truth\",\n",
    "        F(\"label\").is_in(item_list))\n",
    "\n",
    "#session.view = item_view\n",
    "\n",
    "# split the dataset in train and test set\n",
    "train_view = item_view.take((len(item_view) * config.TRAIN_TEST_SPLIT), seed=51)\n",
    "test_view = item_view.exclude([s.id for s in train_view])\n",
    "\n",
    "print(f'Traning on {len(train_view)} samples')\n",
    "print(f'Testing on {len(test_view)} samples')\n",
    "\n",
    "\n",
    "train_transforms, test_transforms = get_transforms()\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "train_dataset = FiftyOneTorchDataset(train_view, train_transforms,\n",
    "        classes=item_list)\n",
    "evaluation_dataset = FiftyOneTorchDataset(test_view, test_transforms,\n",
    "        classes=item_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5je6lVBWz5r"
   },
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blain\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: [0]  [   0/1229]  eta: 0:34:29  lr: 0.000010  loss: 2.7686 (2.7686)  loss_classifier: 1.9219 (1.9219)  loss_box_reg: 0.0503 (0.0503)  loss_objectness: 0.7342 (0.7342)  loss_rpn_box_reg: 0.0617 (0.0617)  time: 1.6837  data: 0.3540  max mem: 1310\n",
      "Training Epoch: [0]  [  10/1229]  eta: 0:08:34  lr: 0.000060  loss: 2.7686 (2.7384)  loss_classifier: 1.8906 (1.8610)  loss_box_reg: 0.0497 (0.0578)  loss_objectness: 0.7307 (0.7304)  loss_rpn_box_reg: 0.0755 (0.0892)  time: 0.4224  data: 0.1803  max mem: 1530\n",
      "Training Epoch: [0]  [  20/1229]  eta: 0:07:12  lr: 0.000110  loss: 2.5292 (2.4910)  loss_classifier: 1.6924 (1.5967)  loss_box_reg: 0.0497 (0.0742)  loss_objectness: 0.7189 (0.7180)  loss_rpn_box_reg: 0.0823 (0.1021)  time: 0.2916  data: 0.1571  max mem: 1532\n",
      "Training Epoch: [0]  [  30/1229]  eta: 0:06:42  lr: 0.000160  loss: 1.5667 (2.0816)  loss_classifier: 0.7021 (1.2137)  loss_box_reg: 0.0578 (0.0771)  loss_objectness: 0.6871 (0.6981)  loss_rpn_box_reg: 0.0689 (0.0926)  time: 0.2878  data: 0.1478  max mem: 1535\n",
      "Training Epoch: [0]  [  40/1229]  eta: 0:06:26  lr: 0.000210  loss: 1.1088 (1.8160)  loss_classifier: 0.2427 (0.9669)  loss_box_reg: 0.0750 (0.0822)  loss_objectness: 0.6114 (0.6682)  loss_rpn_box_reg: 0.0884 (0.0988)  time: 0.2904  data: 0.1437  max mem: 1535\n",
      "Training Epoch: [0]  [  50/1229]  eta: 0:06:13  lr: 0.000260  loss: 0.8458 (1.6137)  loss_classifier: 0.1877 (0.8111)  loss_box_reg: 0.0795 (0.0816)  loss_objectness: 0.5307 (0.6305)  loss_rpn_box_reg: 0.0465 (0.0905)  time: 0.2870  data: 0.1433  max mem: 1535\n",
      "Training Epoch: [0]  [  60/1229]  eta: 0:06:05  lr: 0.000310  loss: 0.6843 (1.4650)  loss_classifier: 0.1708 (0.7032)  loss_box_reg: 0.0760 (0.0794)  loss_objectness: 0.4284 (0.5928)  loss_rpn_box_reg: 0.0432 (0.0895)  time: 0.2867  data: 0.1434  max mem: 1535\n",
      "Training Epoch: [0]  [  70/1229]  eta: 0:05:56  lr: 0.000360  loss: 0.6770 (1.3609)  loss_classifier: 0.1708 (0.6346)  loss_box_reg: 0.0642 (0.0820)  loss_objectness: 0.3638 (0.5574)  loss_rpn_box_reg: 0.0548 (0.0868)  time: 0.2858  data: 0.1432  max mem: 1535\n",
      "Training Epoch: [0]  [  80/1229]  eta: 0:05:49  lr: 0.000410  loss: 0.6585 (1.2649)  loss_classifier: 0.1447 (0.5714)  loss_box_reg: 0.0642 (0.0790)  loss_objectness: 0.3296 (0.5254)  loss_rpn_box_reg: 0.0495 (0.0890)  time: 0.2788  data: 0.1424  max mem: 1535\n",
      "Training Epoch: [0]  [  90/1229]  eta: 0:05:44  lr: 0.000460  loss: 0.5369 (1.1808)  loss_classifier: 0.1310 (0.5230)  loss_box_reg: 0.0666 (0.0777)  loss_objectness: 0.2697 (0.4954)  loss_rpn_box_reg: 0.0413 (0.0848)  time: 0.2824  data: 0.1432  max mem: 1535\n",
      "Training Epoch: [0]  [ 100/1229]  eta: 0:05:40  lr: 0.000509  loss: 0.4836 (1.1210)  loss_classifier: 0.1333 (0.4887)  loss_box_reg: 0.0675 (0.0804)  loss_objectness: 0.2478 (0.4701)  loss_rpn_box_reg: 0.0444 (0.0817)  time: 0.2894  data: 0.1446  max mem: 1535\n",
      "Training Epoch: [0]  [ 110/1229]  eta: 0:05:35  lr: 0.000559  loss: 0.5901 (1.0867)  loss_classifier: 0.1580 (0.4624)  loss_box_reg: 0.0923 (0.0826)  loss_objectness: 0.2145 (0.4556)  loss_rpn_box_reg: 0.0513 (0.0860)  time: 0.2885  data: 0.1437  max mem: 1535\n",
      "Training Epoch: [0]  [ 120/1229]  eta: 0:05:31  lr: 0.000609  loss: 0.4887 (1.0389)  loss_classifier: 0.1519 (0.4373)  loss_box_reg: 0.0607 (0.0826)  loss_objectness: 0.2095 (0.4357)  loss_rpn_box_reg: 0.0431 (0.0833)  time: 0.2856  data: 0.1432  max mem: 1535\n",
      "Training Epoch: [0]  [ 130/1229]  eta: 0:05:27  lr: 0.000659  loss: 0.3504 (0.9968)  loss_classifier: 0.1183 (0.4143)  loss_box_reg: 0.0705 (0.0820)  loss_objectness: 0.1863 (0.4184)  loss_rpn_box_reg: 0.0416 (0.0821)  time: 0.2860  data: 0.1441  max mem: 1535\n",
      "Training Epoch: [0]  [ 140/1229]  eta: 0:05:23  lr: 0.000709  loss: 0.4295 (0.9639)  loss_classifier: 0.1287 (0.3964)  loss_box_reg: 0.0734 (0.0838)  loss_objectness: 0.1931 (0.4034)  loss_rpn_box_reg: 0.0511 (0.0803)  time: 0.2892  data: 0.1460  max mem: 1535\n",
      "Training Epoch: [0]  [ 150/1229]  eta: 0:05:20  lr: 0.000759  loss: 0.4295 (0.9362)  loss_classifier: 0.1284 (0.3798)  loss_box_reg: 0.0849 (0.0844)  loss_objectness: 0.2037 (0.3912)  loss_rpn_box_reg: 0.0529 (0.0809)  time: 0.2934  data: 0.1460  max mem: 1535\n",
      "Training Epoch: [0]  [ 160/1229]  eta: 0:05:16  lr: 0.000809  loss: 0.3794 (0.9053)  loss_classifier: 0.1239 (0.3644)  loss_box_reg: 0.0525 (0.0835)  loss_objectness: 0.1651 (0.3786)  loss_rpn_box_reg: 0.0440 (0.0788)  time: 0.2886  data: 0.1466  max mem: 1535\n",
      "Training Epoch: [0]  [ 170/1229]  eta: 0:05:13  lr: 0.000859  loss: 0.3619 (0.8902)  loss_classifier: 0.1240 (0.3531)  loss_box_reg: 0.0645 (0.0858)  loss_objectness: 0.1651 (0.3706)  loss_rpn_box_reg: 0.0440 (0.0807)  time: 0.2876  data: 0.1462  max mem: 1536\n",
      "Training Epoch: [0]  [ 180/1229]  eta: 0:05:10  lr: 0.000909  loss: 0.6049 (0.8787)  loss_classifier: 0.1868 (0.3447)  loss_box_reg: 0.1241 (0.0896)  loss_objectness: 0.1822 (0.3630)  loss_rpn_box_reg: 0.0730 (0.0814)  time: 0.2944  data: 0.1436  max mem: 1536\n",
      "Training Epoch: [0]  [ 190/1229]  eta: 0:05:06  lr: 0.000959  loss: 0.6414 (0.8630)  loss_classifier: 0.1654 (0.3353)  loss_box_reg: 0.1132 (0.0901)  loss_objectness: 0.1933 (0.3560)  loss_rpn_box_reg: 0.0769 (0.0816)  time: 0.2849  data: 0.1413  max mem: 1536\n",
      "Training Epoch: [0]  [ 200/1229]  eta: 0:05:02  lr: 0.001009  loss: 0.5656 (0.8525)  loss_classifier: 0.1654 (0.3290)  loss_box_reg: 0.1147 (0.0947)  loss_objectness: 0.1933 (0.3480)  loss_rpn_box_reg: 0.0614 (0.0808)  time: 0.2739  data: 0.1419  max mem: 1536\n",
      "Training Epoch: [0]  [ 210/1229]  eta: 0:04:58  lr: 0.001059  loss: 0.5474 (0.8368)  loss_classifier: 0.1765 (0.3209)  loss_box_reg: 0.1285 (0.0954)  loss_objectness: 0.1636 (0.3400)  loss_rpn_box_reg: 0.0510 (0.0806)  time: 0.2757  data: 0.1434  max mem: 1536\n",
      "Training Epoch: [0]  [ 220/1229]  eta: 0:04:55  lr: 0.001109  loss: 0.4388 (0.8266)  loss_classifier: 0.1232 (0.3129)  loss_box_reg: 0.0784 (0.0958)  loss_objectness: 0.1551 (0.3360)  loss_rpn_box_reg: 0.0397 (0.0819)  time: 0.2814  data: 0.1422  max mem: 1536\n",
      "Training Epoch: [0]  [ 230/1229]  eta: 0:04:51  lr: 0.001159  loss: 0.4026 (0.8144)  loss_classifier: 0.1229 (0.3048)  loss_box_reg: 0.0751 (0.0951)  loss_objectness: 0.1551 (0.3317)  loss_rpn_box_reg: 0.0509 (0.0829)  time: 0.2824  data: 0.1434  max mem: 1536\n",
      "Training Epoch: [0]  [ 240/1229]  eta: 0:04:48  lr: 0.001209  loss: 0.4850 (0.8048)  loss_classifier: 0.1171 (0.2977)  loss_box_reg: 0.0594 (0.0941)  loss_objectness: 0.1706 (0.3253)  loss_rpn_box_reg: 0.0917 (0.0876)  time: 0.2832  data: 0.1449  max mem: 1536\n",
      "Training Epoch: [0]  [ 250/1229]  eta: 0:04:45  lr: 0.001259  loss: 0.6451 (0.8069)  loss_classifier: 0.1519 (0.2940)  loss_box_reg: 0.0810 (0.0972)  loss_objectness: 0.1936 (0.3216)  loss_rpn_box_reg: 0.1748 (0.0940)  time: 0.2868  data: 0.1444  max mem: 1536\n",
      "Training Epoch: [0]  [ 260/1229]  eta: 0:04:42  lr: 0.001309  loss: 0.7248 (0.8024)  loss_classifier: 0.1637 (0.2893)  loss_box_reg: 0.0999 (0.0989)  loss_objectness: 0.2248 (0.3186)  loss_rpn_box_reg: 0.1007 (0.0956)  time: 0.2808  data: 0.1426  max mem: 1536\n",
      "Training Epoch: [0]  [ 270/1229]  eta: 0:04:38  lr: 0.001359  loss: 0.5246 (0.7901)  loss_classifier: 0.1522 (0.2833)  loss_box_reg: 0.0999 (0.0990)  loss_objectness: 0.2175 (0.3127)  loss_rpn_box_reg: 0.0640 (0.0951)  time: 0.2783  data: 0.1425  max mem: 1536\n",
      "Training Epoch: [0]  [ 280/1229]  eta: 0:04:35  lr: 0.001409  loss: 0.4165 (0.7789)  loss_classifier: 0.1412 (0.2782)  loss_box_reg: 0.0864 (0.0995)  loss_objectness: 0.1541 (0.3076)  loss_rpn_box_reg: 0.0503 (0.0936)  time: 0.2855  data: 0.1457  max mem: 1536\n",
      "Training Epoch: [0]  [ 290/1229]  eta: 0:04:33  lr: 0.001459  loss: 0.4207 (0.7704)  loss_classifier: 0.1416 (0.2733)  loss_box_reg: 0.0764 (0.0994)  loss_objectness: 0.1680 (0.3028)  loss_rpn_box_reg: 0.0520 (0.0948)  time: 0.2935  data: 0.1479  max mem: 1536\n",
      "Training Epoch: [0]  [ 300/1229]  eta: 0:04:30  lr: 0.001508  loss: 0.5501 (0.7655)  loss_classifier: 0.1528 (0.2702)  loss_box_reg: 0.1021 (0.1003)  loss_objectness: 0.1748 (0.3000)  loss_rpn_box_reg: 0.0790 (0.0949)  time: 0.2922  data: 0.1471  max mem: 1536\n",
      "Training Epoch: [0]  [ 310/1229]  eta: 0:04:27  lr: 0.001558  loss: 0.5846 (0.7604)  loss_classifier: 0.1782 (0.2674)  loss_box_reg: 0.1049 (0.1012)  loss_objectness: 0.1714 (0.2967)  loss_rpn_box_reg: 0.0512 (0.0950)  time: 0.2866  data: 0.1445  max mem: 1536\n",
      "Training Epoch: [0]  [ 320/1229]  eta: 0:04:24  lr: 0.001608  loss: 0.5173 (0.7526)  loss_classifier: 0.1537 (0.2635)  loss_box_reg: 0.0980 (0.1011)  loss_objectness: 0.1544 (0.2931)  loss_rpn_box_reg: 0.0512 (0.0948)  time: 0.2874  data: 0.1443  max mem: 1536\n",
      "Training Epoch: [0]  [ 330/1229]  eta: 0:04:21  lr: 0.001658  loss: 0.4554 (0.7468)  loss_classifier: 0.1353 (0.2603)  loss_box_reg: 0.0922 (0.1020)  loss_objectness: 0.1800 (0.2894)  loss_rpn_box_reg: 0.0649 (0.0952)  time: 0.2923  data: 0.1497  max mem: 1536\n",
      "Training Epoch: [0]  [ 340/1229]  eta: 0:04:18  lr: 0.001708  loss: 0.4514 (0.7415)  loss_classifier: 0.1194 (0.2562)  loss_box_reg: 0.0858 (0.1013)  loss_objectness: 0.1696 (0.2873)  loss_rpn_box_reg: 0.0572 (0.0967)  time: 0.2946  data: 0.1487  max mem: 1536\n",
      "Training Epoch: [0]  [ 350/1229]  eta: 0:04:15  lr: 0.001758  loss: 0.3991 (0.7342)  loss_classifier: 0.0970 (0.2527)  loss_box_reg: 0.0655 (0.1011)  loss_objectness: 0.1588 (0.2840)  loss_rpn_box_reg: 0.0478 (0.0965)  time: 0.2940  data: 0.1460  max mem: 1536\n",
      "Training Epoch: [0]  [ 360/1229]  eta: 0:04:12  lr: 0.001808  loss: 0.4087 (0.7275)  loss_classifier: 0.0970 (0.2487)  loss_box_reg: 0.0620 (0.1005)  loss_objectness: 0.1396 (0.2804)  loss_rpn_box_reg: 0.0527 (0.0978)  time: 0.2938  data: 0.1461  max mem: 1538\n",
      "Training Epoch: [0]  [ 370/1229]  eta: 0:04:09  lr: 0.001858  loss: 0.5614 (0.7259)  loss_classifier: 0.1350 (0.2466)  loss_box_reg: 0.0810 (0.1018)  loss_objectness: 0.1549 (0.2778)  loss_rpn_box_reg: 0.0795 (0.0996)  time: 0.2906  data: 0.1434  max mem: 1538\n",
      "Training Epoch: [0]  [ 380/1229]  eta: 0:04:06  lr: 0.001908  loss: 0.5614 (0.7202)  loss_classifier: 0.1719 (0.2442)  loss_box_reg: 0.1048 (0.1023)  loss_objectness: 0.1646 (0.2753)  loss_rpn_box_reg: 0.0718 (0.0984)  time: 0.2844  data: 0.1450  max mem: 1538\n",
      "Training Epoch: [0]  [ 390/1229]  eta: 0:04:03  lr: 0.001958  loss: 0.5242 (0.7174)  loss_classifier: 0.1576 (0.2430)  loss_box_reg: 0.1127 (0.1033)  loss_objectness: 0.1867 (0.2731)  loss_rpn_box_reg: 0.0549 (0.0981)  time: 0.2751  data: 0.1446  max mem: 1538\n",
      "Training Epoch: [0]  [ 400/1229]  eta: 0:04:00  lr: 0.002008  loss: 0.5818 (0.7149)  loss_classifier: 0.1464 (0.2414)  loss_box_reg: 0.1020 (0.1038)  loss_objectness: 0.2002 (0.2717)  loss_rpn_box_reg: 0.0760 (0.0981)  time: 0.2749  data: 0.1422  max mem: 1538\n",
      "Training Epoch: [0]  [ 410/1229]  eta: 0:03:57  lr: 0.002058  loss: 0.5522 (0.7108)  loss_classifier: 0.1453 (0.2395)  loss_box_reg: 0.0858 (0.1041)  loss_objectness: 0.1617 (0.2691)  loss_rpn_box_reg: 0.0760 (0.0980)  time: 0.2816  data: 0.1442  max mem: 1538\n",
      "Training Epoch: [0]  [ 420/1229]  eta: 0:03:54  lr: 0.002108  loss: 0.5457 (0.7088)  loss_classifier: 0.1809 (0.2385)  loss_box_reg: 0.1399 (0.1045)  loss_objectness: 0.1481 (0.2681)  loss_rpn_box_reg: 0.0608 (0.0977)  time: 0.2848  data: 0.1458  max mem: 1538\n",
      "Training Epoch: [0]  [ 430/1229]  eta: 0:03:51  lr: 0.002158  loss: 0.5186 (0.7054)  loss_classifier: 0.1663 (0.2368)  loss_box_reg: 0.1344 (0.1048)  loss_objectness: 0.1605 (0.2662)  loss_rpn_box_reg: 0.0745 (0.0976)  time: 0.2820  data: 0.1438  max mem: 1538\n",
      "Training Epoch: [0]  [ 440/1229]  eta: 0:03:48  lr: 0.002208  loss: 0.4746 (0.7024)  loss_classifier: 0.1555 (0.2357)  loss_box_reg: 0.0997 (0.1057)  loss_objectness: 0.1677 (0.2644)  loss_rpn_box_reg: 0.0457 (0.0966)  time: 0.2785  data: 0.1422  max mem: 1538\n",
      "Training Epoch: [0]  [ 450/1229]  eta: 0:03:45  lr: 0.002258  loss: 0.4746 (0.7012)  loss_classifier: 0.1604 (0.2351)  loss_box_reg: 0.1105 (0.1071)  loss_objectness: 0.1677 (0.2626)  loss_rpn_box_reg: 0.0457 (0.0964)  time: 0.2907  data: 0.1433  max mem: 1538\n",
      "Training Epoch: [0]  [ 460/1229]  eta: 0:03:42  lr: 0.002308  loss: 0.6615 (0.7022)  loss_classifier: 0.2196 (0.2343)  loss_box_reg: 0.1544 (0.1086)  loss_objectness: 0.1595 (0.2611)  loss_rpn_box_reg: 0.0830 (0.0982)  time: 0.2944  data: 0.1436  max mem: 1538\n",
      "Training Epoch: [0]  [ 470/1229]  eta: 0:03:39  lr: 0.002358  loss: 0.7487 (0.7017)  loss_classifier: 0.1582 (0.2333)  loss_box_reg: 0.1119 (0.1088)  loss_objectness: 0.2075 (0.2595)  loss_rpn_box_reg: 0.1102 (0.1001)  time: 0.2868  data: 0.1429  max mem: 1538\n",
      "Training Epoch: [0]  [ 480/1229]  eta: 0:03:36  lr: 0.002408  loss: 0.5330 (0.6971)  loss_classifier: 0.1582 (0.2321)  loss_box_reg: 0.0902 (0.1089)  loss_objectness: 0.1404 (0.2568)  loss_rpn_box_reg: 0.0777 (0.0992)  time: 0.2870  data: 0.1437  max mem: 1538\n",
      "Training Epoch: [0]  [ 490/1229]  eta: 0:03:33  lr: 0.002458  loss: 0.5292 (0.6959)  loss_classifier: 0.1665 (0.2311)  loss_box_reg: 0.1121 (0.1095)  loss_objectness: 0.1385 (0.2556)  loss_rpn_box_reg: 0.0590 (0.0998)  time: 0.2875  data: 0.1439  max mem: 1538\n",
      "Training Epoch: [0]  [ 500/1229]  eta: 0:03:30  lr: 0.002507  loss: 0.5913 (0.6943)  loss_classifier: 0.1495 (0.2297)  loss_box_reg: 0.1180 (0.1093)  loss_objectness: 0.1667 (0.2543)  loss_rpn_box_reg: 0.0579 (0.1011)  time: 0.2806  data: 0.1425  max mem: 1538\n",
      "Training Epoch: [0]  [ 510/1229]  eta: 0:03:27  lr: 0.002557  loss: 0.4725 (0.6912)  loss_classifier: 0.1425 (0.2281)  loss_box_reg: 0.1028 (0.1090)  loss_objectness: 0.1623 (0.2530)  loss_rpn_box_reg: 0.0569 (0.1010)  time: 0.2723  data: 0.1429  max mem: 1538\n",
      "Training Epoch: [0]  [ 520/1229]  eta: 0:03:24  lr: 0.002607  loss: 0.4800 (0.6884)  loss_classifier: 0.1677 (0.2273)  loss_box_reg: 0.1106 (0.1098)  loss_objectness: 0.1599 (0.2509)  loss_rpn_box_reg: 0.0570 (0.1003)  time: 0.2795  data: 0.1448  max mem: 1538\n",
      "Training Epoch: [0]  [ 530/1229]  eta: 0:03:21  lr: 0.002657  loss: 0.4800 (0.6871)  loss_classifier: 0.1761 (0.2268)  loss_box_reg: 0.1523 (0.1108)  loss_objectness: 0.1331 (0.2498)  loss_rpn_box_reg: 0.0528 (0.0997)  time: 0.2849  data: 0.1440  max mem: 1538\n",
      "Training Epoch: [0]  [ 540/1229]  eta: 0:03:18  lr: 0.002707  loss: 0.4362 (0.6833)  loss_classifier: 0.1508 (0.2254)  loss_box_reg: 0.1104 (0.1110)  loss_objectness: 0.1297 (0.2477)  loss_rpn_box_reg: 0.0383 (0.0993)  time: 0.2868  data: 0.1449  max mem: 1538\n",
      "Training Epoch: [0]  [ 550/1229]  eta: 0:03:15  lr: 0.002757  loss: 0.4506 (0.6802)  loss_classifier: 0.1315 (0.2239)  loss_box_reg: 0.0949 (0.1109)  loss_objectness: 0.1122 (0.2465)  loss_rpn_box_reg: 0.0465 (0.0990)  time: 0.2828  data: 0.1465  max mem: 1538\n",
      "Training Epoch: [0]  [ 560/1229]  eta: 0:03:12  lr: 0.002807  loss: 0.4727 (0.6773)  loss_classifier: 0.1324 (0.2229)  loss_box_reg: 0.0907 (0.1108)  loss_objectness: 0.1274 (0.2451)  loss_rpn_box_reg: 0.0474 (0.0986)  time: 0.2794  data: 0.1467  max mem: 1538\n",
      "Training Epoch: [0]  [ 570/1229]  eta: 0:03:09  lr: 0.002857  loss: 0.4727 (0.6736)  loss_classifier: 0.1333 (0.2214)  loss_box_reg: 0.0808 (0.1103)  loss_objectness: 0.1204 (0.2434)  loss_rpn_box_reg: 0.0474 (0.0985)  time: 0.2908  data: 0.1469  max mem: 1538\n",
      "Training Epoch: [0]  [ 580/1229]  eta: 0:03:07  lr: 0.002907  loss: 0.4823 (0.6731)  loss_classifier: 0.1333 (0.2209)  loss_box_reg: 0.0795 (0.1112)  loss_objectness: 0.1204 (0.2419)  loss_rpn_box_reg: 0.0527 (0.0992)  time: 0.3136  data: 0.1464  max mem: 1538\n",
      "Training Epoch: [0]  [ 590/1229]  eta: 0:03:04  lr: 0.002957  loss: 0.4823 (0.6703)  loss_classifier: 0.1210 (0.2196)  loss_box_reg: 0.0867 (0.1108)  loss_objectness: 0.1329 (0.2408)  loss_rpn_box_reg: 0.0789 (0.0992)  time: 0.3122  data: 0.1452  max mem: 1538\n",
      "Training Epoch: [0]  [ 600/1229]  eta: 0:03:01  lr: 0.003007  loss: 0.3980 (0.6699)  loss_classifier: 0.1182 (0.2186)  loss_box_reg: 0.0934 (0.1109)  loss_objectness: 0.1351 (0.2402)  loss_rpn_box_reg: 0.0476 (0.1002)  time: 0.2905  data: 0.1438  max mem: 1538\n",
      "Training Epoch: [0]  [ 610/1229]  eta: 0:02:59  lr: 0.003057  loss: 0.3965 (0.6676)  loss_classifier: 0.1327 (0.2173)  loss_box_reg: 0.0934 (0.1107)  loss_objectness: 0.1493 (0.2391)  loss_rpn_box_reg: 0.0440 (0.1005)  time: 0.3014  data: 0.1520  max mem: 1538\n",
      "Training Epoch: [0]  [ 620/1229]  eta: 0:02:56  lr: 0.003107  loss: 0.5323 (0.6683)  loss_classifier: 0.1576 (0.2167)  loss_box_reg: 0.1039 (0.1115)  loss_objectness: 0.1742 (0.2388)  loss_rpn_box_reg: 0.0502 (0.1013)  time: 0.3068  data: 0.1563  max mem: 1538\n",
      "Training Epoch: [0]  [ 630/1229]  eta: 0:02:53  lr: 0.003157  loss: 0.4198 (0.6648)  loss_classifier: 0.1208 (0.2152)  loss_box_reg: 0.0935 (0.1113)  loss_objectness: 0.1563 (0.2373)  loss_rpn_box_reg: 0.0343 (0.1010)  time: 0.3001  data: 0.1507  max mem: 1538\n",
      "Training Epoch: [0]  [ 640/1229]  eta: 0:02:50  lr: 0.003207  loss: 0.4198 (0.6645)  loss_classifier: 0.1445 (0.2152)  loss_box_reg: 0.0995 (0.1120)  loss_objectness: 0.1418 (0.2363)  loss_rpn_box_reg: 0.0350 (0.1010)  time: 0.2951  data: 0.1470  max mem: 1538\n",
      "Training Epoch: [0]  [ 650/1229]  eta: 0:02:47  lr: 0.003257  loss: 0.5463 (0.6645)  loss_classifier: 0.1703 (0.2151)  loss_box_reg: 0.1250 (0.1127)  loss_objectness: 0.1562 (0.2356)  loss_rpn_box_reg: 0.0703 (0.1011)  time: 0.2906  data: 0.1445  max mem: 1538\n",
      "Training Epoch: [0]  [ 660/1229]  eta: 0:02:44  lr: 0.003307  loss: 0.5463 (0.6630)  loss_classifier: 0.1703 (0.2141)  loss_box_reg: 0.1180 (0.1126)  loss_objectness: 0.1620 (0.2350)  loss_rpn_box_reg: 0.0750 (0.1014)  time: 0.2882  data: 0.1446  max mem: 1538\n",
      "Training Epoch: [0]  [ 670/1229]  eta: 0:02:41  lr: 0.003357  loss: 0.4560 (0.6623)  loss_classifier: 0.1226 (0.2133)  loss_box_reg: 0.1006 (0.1127)  loss_objectness: 0.1656 (0.2345)  loss_rpn_box_reg: 0.0733 (0.1018)  time: 0.2773  data: 0.1423  max mem: 1538\n",
      "Training Epoch: [0]  [ 680/1229]  eta: 0:02:38  lr: 0.003407  loss: 0.5783 (0.6619)  loss_classifier: 0.1790 (0.2130)  loss_box_reg: 0.1117 (0.1127)  loss_objectness: 0.1763 (0.2339)  loss_rpn_box_reg: 0.0865 (0.1023)  time: 0.2796  data: 0.1416  max mem: 1538\n",
      "Training Epoch: [0]  [ 690/1229]  eta: 0:02:35  lr: 0.003457  loss: 0.5912 (0.6611)  loss_classifier: 0.1730 (0.2123)  loss_box_reg: 0.1083 (0.1128)  loss_objectness: 0.1914 (0.2339)  loss_rpn_box_reg: 0.0584 (0.1020)  time: 0.2818  data: 0.1425  max mem: 1538\n",
      "Training Epoch: [0]  [ 700/1229]  eta: 0:02:32  lr: 0.003506  loss: 0.4747 (0.6584)  loss_classifier: 0.1334 (0.2114)  loss_box_reg: 0.0878 (0.1126)  loss_objectness: 0.1959 (0.2331)  loss_rpn_box_reg: 0.0406 (0.1012)  time: 0.2802  data: 0.1431  max mem: 1538\n",
      "Training Epoch: [0]  [ 710/1229]  eta: 0:02:30  lr: 0.003556  loss: 0.4702 (0.6566)  loss_classifier: 0.1440 (0.2108)  loss_box_reg: 0.0878 (0.1128)  loss_objectness: 0.1598 (0.2323)  loss_rpn_box_reg: 0.0415 (0.1007)  time: 0.2844  data: 0.1439  max mem: 1538\n",
      "Training Epoch: [0]  [ 720/1229]  eta: 0:02:27  lr: 0.003606  loss: 0.4830 (0.6543)  loss_classifier: 0.1440 (0.2103)  loss_box_reg: 0.0930 (0.1128)  loss_objectness: 0.1500 (0.2313)  loss_rpn_box_reg: 0.0435 (0.1000)  time: 0.2831  data: 0.1420  max mem: 1538\n",
      "Training Epoch: [0]  [ 730/1229]  eta: 0:02:24  lr: 0.003656  loss: 0.4265 (0.6531)  loss_classifier: 0.1455 (0.2101)  loss_box_reg: 0.1138 (0.1134)  loss_objectness: 0.1332 (0.2302)  loss_rpn_box_reg: 0.0289 (0.0993)  time: 0.2913  data: 0.1417  max mem: 1538\n",
      "Training Epoch: [0]  [ 740/1229]  eta: 0:02:21  lr: 0.003706  loss: 0.4901 (0.6526)  loss_classifier: 0.1721 (0.2104)  loss_box_reg: 0.1270 (0.1139)  loss_objectness: 0.1563 (0.2295)  loss_rpn_box_reg: 0.0323 (0.0988)  time: 0.2935  data: 0.1426  max mem: 1538\n",
      "Training Epoch: [0]  [ 750/1229]  eta: 0:02:18  lr: 0.003756  loss: 0.4931 (0.6512)  loss_classifier: 0.1721 (0.2101)  loss_box_reg: 0.1479 (0.1142)  loss_objectness: 0.1663 (0.2285)  loss_rpn_box_reg: 0.0427 (0.0984)  time: 0.2863  data: 0.1443  max mem: 1538\n",
      "Training Epoch: [0]  [ 760/1229]  eta: 0:02:15  lr: 0.003806  loss: 0.5348 (0.6499)  loss_classifier: 0.1656 (0.2096)  loss_box_reg: 0.1267 (0.1145)  loss_objectness: 0.1378 (0.2274)  loss_rpn_box_reg: 0.0455 (0.0984)  time: 0.2868  data: 0.1452  max mem: 1538\n",
      "Training Epoch: [0]  [ 770/1229]  eta: 0:02:12  lr: 0.003856  loss: 0.5028 (0.6479)  loss_classifier: 0.1656 (0.2089)  loss_box_reg: 0.1178 (0.1146)  loss_objectness: 0.1288 (0.2263)  loss_rpn_box_reg: 0.0347 (0.0980)  time: 0.2823  data: 0.1426  max mem: 1538\n",
      "Training Epoch: [0]  [ 780/1229]  eta: 0:02:09  lr: 0.003906  loss: 0.5578 (0.6475)  loss_classifier: 0.1759 (0.2085)  loss_box_reg: 0.1178 (0.1150)  loss_objectness: 0.1359 (0.2262)  loss_rpn_box_reg: 0.0467 (0.0978)  time: 0.2819  data: 0.1441  max mem: 1538\n",
      "Training Epoch: [0]  [ 790/1229]  eta: 0:02:06  lr: 0.003956  loss: 0.5578 (0.6461)  loss_classifier: 0.1541 (0.2080)  loss_box_reg: 0.1137 (0.1151)  loss_objectness: 0.1522 (0.2254)  loss_rpn_box_reg: 0.0488 (0.0977)  time: 0.2866  data: 0.1452  max mem: 1538\n",
      "Training Epoch: [0]  [ 800/1229]  eta: 0:02:03  lr: 0.004006  loss: 0.4645 (0.6457)  loss_classifier: 0.1438 (0.2077)  loss_box_reg: 0.0901 (0.1153)  loss_objectness: 0.1449 (0.2250)  loss_rpn_box_reg: 0.0347 (0.0978)  time: 0.2801  data: 0.1417  max mem: 1538\n",
      "Training Epoch: [0]  [ 810/1229]  eta: 0:02:00  lr: 0.004056  loss: 0.4645 (0.6451)  loss_classifier: 0.1398 (0.2073)  loss_box_reg: 0.1116 (0.1155)  loss_objectness: 0.1433 (0.2245)  loss_rpn_box_reg: 0.0595 (0.0978)  time: 0.2797  data: 0.1428  max mem: 1538\n",
      "Training Epoch: [0]  [ 820/1229]  eta: 0:01:58  lr: 0.004106  loss: 0.4407 (0.6427)  loss_classifier: 0.1272 (0.2065)  loss_box_reg: 0.1071 (0.1155)  loss_objectness: 0.1528 (0.2234)  loss_rpn_box_reg: 0.0479 (0.0973)  time: 0.2892  data: 0.1449  max mem: 1538\n",
      "Training Epoch: [0]  [ 830/1229]  eta: 0:01:55  lr: 0.004156  loss: 0.4547 (0.6416)  loss_classifier: 0.1421 (0.2062)  loss_box_reg: 0.1061 (0.1160)  loss_objectness: 0.1436 (0.2227)  loss_rpn_box_reg: 0.0278 (0.0967)  time: 0.2963  data: 0.1435  max mem: 1538\n",
      "Training Epoch: [0]  [ 840/1229]  eta: 0:01:52  lr: 0.004206  loss: 0.5236 (0.6413)  loss_classifier: 0.1598 (0.2060)  loss_box_reg: 0.1106 (0.1164)  loss_objectness: 0.1654 (0.2224)  loss_rpn_box_reg: 0.0437 (0.0965)  time: 0.2946  data: 0.1449  max mem: 1538\n",
      "Training Epoch: [0]  [ 850/1229]  eta: 0:01:49  lr: 0.004256  loss: 0.4919 (0.6397)  loss_classifier: 0.1528 (0.2054)  loss_box_reg: 0.1106 (0.1167)  loss_objectness: 0.1601 (0.2215)  loss_rpn_box_reg: 0.0569 (0.0961)  time: 0.2853  data: 0.1481  max mem: 1538\n",
      "Training Epoch: [0]  [ 860/1229]  eta: 0:01:46  lr: 0.004306  loss: 0.5589 (0.6392)  loss_classifier: 0.1736 (0.2055)  loss_box_reg: 0.1344 (0.1171)  loss_objectness: 0.1513 (0.2208)  loss_rpn_box_reg: 0.0498 (0.0958)  time: 0.2857  data: 0.1493  max mem: 1538\n",
      "Training Epoch: [0]  [ 870/1229]  eta: 0:01:43  lr: 0.004356  loss: 0.5046 (0.6379)  loss_classifier: 0.1893 (0.2052)  loss_box_reg: 0.1464 (0.1173)  loss_objectness: 0.1476 (0.2201)  loss_rpn_box_reg: 0.0451 (0.0953)  time: 0.2921  data: 0.1487  max mem: 1538\n",
      "Training Epoch: [0]  [ 880/1229]  eta: 0:01:40  lr: 0.004406  loss: 0.4664 (0.6368)  loss_classifier: 0.1577 (0.2048)  loss_box_reg: 0.1108 (0.1175)  loss_objectness: 0.1263 (0.2192)  loss_rpn_box_reg: 0.0318 (0.0953)  time: 0.2916  data: 0.1460  max mem: 1538\n",
      "Training Epoch: [0]  [ 890/1229]  eta: 0:01:37  lr: 0.004456  loss: 0.3923 (0.6353)  loss_classifier: 0.1400 (0.2043)  loss_box_reg: 0.1010 (0.1177)  loss_objectness: 0.1241 (0.2183)  loss_rpn_box_reg: 0.0423 (0.0949)  time: 0.2816  data: 0.1457  max mem: 1538\n",
      "Training Epoch: [0]  [ 900/1229]  eta: 0:01:34  lr: 0.004505  loss: 0.4099 (0.6349)  loss_classifier: 0.1428 (0.2041)  loss_box_reg: 0.1226 (0.1180)  loss_objectness: 0.1246 (0.2179)  loss_rpn_box_reg: 0.0431 (0.0949)  time: 0.2810  data: 0.1476  max mem: 1538\n",
      "Training Epoch: [0]  [ 910/1229]  eta: 0:01:32  lr: 0.004555  loss: 0.5215 (0.6331)  loss_classifier: 0.1742 (0.2034)  loss_box_reg: 0.1299 (0.1181)  loss_objectness: 0.1315 (0.2170)  loss_rpn_box_reg: 0.0396 (0.0945)  time: 0.2902  data: 0.1461  max mem: 1538\n",
      "Training Epoch: [0]  [ 920/1229]  eta: 0:01:29  lr: 0.004605  loss: 0.4855 (0.6326)  loss_classifier: 0.1295 (0.2031)  loss_box_reg: 0.0980 (0.1184)  loss_objectness: 0.1338 (0.2164)  loss_rpn_box_reg: 0.0505 (0.0947)  time: 0.2890  data: 0.1469  max mem: 1538\n",
      "Training Epoch: [0]  [ 930/1229]  eta: 0:01:26  lr: 0.004655  loss: 0.4686 (0.6310)  loss_classifier: 0.1295 (0.2025)  loss_box_reg: 0.1072 (0.1185)  loss_objectness: 0.1100 (0.2152)  loss_rpn_box_reg: 0.0568 (0.0948)  time: 0.2896  data: 0.1493  max mem: 1538\n",
      "Training Epoch: [0]  [ 940/1229]  eta: 0:01:23  lr: 0.004705  loss: 0.3567 (0.6286)  loss_classifier: 0.1133 (0.2016)  loss_box_reg: 0.0779 (0.1180)  loss_objectness: 0.0943 (0.2144)  loss_rpn_box_reg: 0.0502 (0.0945)  time: 0.2907  data: 0.1483  max mem: 1538\n",
      "Training Epoch: [0]  [ 950/1229]  eta: 0:01:20  lr: 0.004755  loss: 0.4054 (0.6284)  loss_classifier: 0.1384 (0.2016)  loss_box_reg: 0.1107 (0.1185)  loss_objectness: 0.1303 (0.2139)  loss_rpn_box_reg: 0.0354 (0.0944)  time: 0.2889  data: 0.1455  max mem: 1538\n",
      "Training Epoch: [0]  [ 960/1229]  eta: 0:01:17  lr: 0.004805  loss: 0.6038 (0.6278)  loss_classifier: 0.1985 (0.2014)  loss_box_reg: 0.1399 (0.1189)  loss_objectness: 0.1218 (0.2133)  loss_rpn_box_reg: 0.0384 (0.0942)  time: 0.2872  data: 0.1464  max mem: 1538\n",
      "Training Epoch: [0]  [ 970/1229]  eta: 0:01:14  lr: 0.004855  loss: 0.4963 (0.6267)  loss_classifier: 0.1693 (0.2011)  loss_box_reg: 0.1260 (0.1191)  loss_objectness: 0.1155 (0.2126)  loss_rpn_box_reg: 0.0511 (0.0938)  time: 0.2890  data: 0.1469  max mem: 1538\n",
      "Training Epoch: [0]  [ 980/1229]  eta: 0:01:11  lr: 0.004905  loss: 0.5250 (0.6267)  loss_classifier: 0.1666 (0.2012)  loss_box_reg: 0.1260 (0.1197)  loss_objectness: 0.1334 (0.2122)  loss_rpn_box_reg: 0.0478 (0.0935)  time: 0.2908  data: 0.1462  max mem: 1538\n",
      "Training Epoch: [0]  [ 990/1229]  eta: 0:01:08  lr: 0.004955  loss: 0.5779 (0.6261)  loss_classifier: 0.1666 (0.2012)  loss_box_reg: 0.1490 (0.1201)  loss_objectness: 0.1584 (0.2116)  loss_rpn_box_reg: 0.0496 (0.0932)  time: 0.2836  data: 0.1449  max mem: 1538\n",
      "Training Epoch: [0]  [1000/1229]  eta: 0:01:06  lr: 0.005000  loss: 0.5133 (0.6264)  loss_classifier: 0.1978 (0.2012)  loss_box_reg: 0.1501 (0.1205)  loss_objectness: 0.1377 (0.2110)  loss_rpn_box_reg: 0.0496 (0.0937)  time: 0.2827  data: 0.1458  max mem: 1538\n",
      "Training Epoch: [0]  [1010/1229]  eta: 0:01:03  lr: 0.005000  loss: 0.5133 (0.6257)  loss_classifier: 0.1307 (0.2007)  loss_box_reg: 0.1087 (0.1204)  loss_objectness: 0.1352 (0.2105)  loss_rpn_box_reg: 0.0738 (0.0940)  time: 0.2865  data: 0.1450  max mem: 1538\n",
      "Training Epoch: [0]  [1020/1229]  eta: 0:01:00  lr: 0.005000  loss: 0.4151 (0.6249)  loss_classifier: 0.1307 (0.2006)  loss_box_reg: 0.0972 (0.1205)  loss_objectness: 0.1201 (0.2098)  loss_rpn_box_reg: 0.0469 (0.0940)  time: 0.2911  data: 0.1430  max mem: 1538\n",
      "Training Epoch: [0]  [1030/1229]  eta: 0:00:57  lr: 0.005000  loss: 0.3984 (0.6246)  loss_classifier: 0.1636 (0.2001)  loss_box_reg: 0.1026 (0.1205)  loss_objectness: 0.1226 (0.2096)  loss_rpn_box_reg: 0.0545 (0.0944)  time: 0.2921  data: 0.1454  max mem: 1538\n",
      "Training Epoch: [0]  [1040/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.3760 (0.6227)  loss_classifier: 0.1254 (0.1996)  loss_box_reg: 0.0876 (0.1203)  loss_objectness: 0.1367 (0.2090)  loss_rpn_box_reg: 0.0401 (0.0938)  time: 0.2880  data: 0.1429  max mem: 1538\n",
      "Training Epoch: [0]  [1050/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.4338 (0.6218)  loss_classifier: 0.1403 (0.1992)  loss_box_reg: 0.1075 (0.1208)  loss_objectness: 0.1346 (0.2084)  loss_rpn_box_reg: 0.0279 (0.0934)  time: 0.2935  data: 0.1462  max mem: 1538\n",
      "Training Epoch: [0]  [1060/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.4614 (0.6213)  loss_classifier: 0.1539 (0.1991)  loss_box_reg: 0.1370 (0.1212)  loss_objectness: 0.1254 (0.2079)  loss_rpn_box_reg: 0.0394 (0.0931)  time: 0.2926  data: 0.1511  max mem: 1538\n",
      "Training Epoch: [0]  [1070/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.5105 (0.6201)  loss_classifier: 0.1583 (0.1988)  loss_box_reg: 0.1393 (0.1213)  loss_objectness: 0.1200 (0.2070)  loss_rpn_box_reg: 0.0306 (0.0930)  time: 0.2848  data: 0.1469  max mem: 1538\n",
      "Training Epoch: [0]  [1080/1229]  eta: 0:00:43  lr: 0.005000  loss: 0.4529 (0.6183)  loss_classifier: 0.1267 (0.1983)  loss_box_reg: 0.1027 (0.1213)  loss_objectness: 0.1174 (0.2062)  loss_rpn_box_reg: 0.0306 (0.0926)  time: 0.3104  data: 0.1454  max mem: 1538\n",
      "Training Epoch: [0]  [1090/1229]  eta: 0:00:40  lr: 0.005000  loss: 0.4310 (0.6170)  loss_classifier: 0.1542 (0.1978)  loss_box_reg: 0.0961 (0.1210)  loss_objectness: 0.1222 (0.2059)  loss_rpn_box_reg: 0.0503 (0.0924)  time: 0.3107  data: 0.1465  max mem: 1538\n",
      "Training Epoch: [0]  [1100/1229]  eta: 0:00:37  lr: 0.005000  loss: 0.4310 (0.6153)  loss_classifier: 0.1528 (0.1973)  loss_box_reg: 0.1078 (0.1209)  loss_objectness: 0.1236 (0.2052)  loss_rpn_box_reg: 0.0454 (0.0919)  time: 0.2861  data: 0.1424  max mem: 1538\n",
      "Training Epoch: [0]  [1110/1229]  eta: 0:00:34  lr: 0.005000  loss: 0.4553 (0.6150)  loss_classifier: 0.1528 (0.1973)  loss_box_reg: 0.1201 (0.1215)  loss_objectness: 0.1158 (0.2047)  loss_rpn_box_reg: 0.0291 (0.0915)  time: 0.2927  data: 0.1433  max mem: 1538\n",
      "Training Epoch: [0]  [1120/1229]  eta: 0:00:31  lr: 0.005000  loss: 0.5165 (0.6144)  loss_classifier: 0.1880 (0.1971)  loss_box_reg: 0.1335 (0.1220)  loss_objectness: 0.1158 (0.2041)  loss_rpn_box_reg: 0.0323 (0.0911)  time: 0.2962  data: 0.1471  max mem: 1538\n",
      "Training Epoch: [0]  [1130/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.4650 (0.6134)  loss_classifier: 0.1635 (0.1968)  loss_box_reg: 0.1220 (0.1221)  loss_objectness: 0.1391 (0.2036)  loss_rpn_box_reg: 0.0383 (0.0909)  time: 0.2898  data: 0.1460  max mem: 1538\n",
      "Training Epoch: [0]  [1140/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.5181 (0.6129)  loss_classifier: 0.1692 (0.1967)  loss_box_reg: 0.1210 (0.1223)  loss_objectness: 0.1489 (0.2032)  loss_rpn_box_reg: 0.0483 (0.0907)  time: 0.2839  data: 0.1470  max mem: 1538\n",
      "Training Epoch: [0]  [1150/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.5726 (0.6118)  loss_classifier: 0.1733 (0.1964)  loss_box_reg: 0.1147 (0.1223)  loss_objectness: 0.1215 (0.2027)  loss_rpn_box_reg: 0.0407 (0.0904)  time: 0.2911  data: 0.1479  max mem: 1538\n",
      "Training Epoch: [0]  [1160/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.3574 (0.6105)  loss_classifier: 0.1360 (0.1959)  loss_box_reg: 0.0941 (0.1222)  loss_objectness: 0.1215 (0.2022)  loss_rpn_box_reg: 0.0388 (0.0902)  time: 0.2914  data: 0.1437  max mem: 1538\n",
      "Training Epoch: [0]  [1170/1229]  eta: 0:00:17  lr: 0.005000  loss: 0.3491 (0.6093)  loss_classifier: 0.1149 (0.1954)  loss_box_reg: 0.0786 (0.1221)  loss_objectness: 0.1233 (0.2016)  loss_rpn_box_reg: 0.0381 (0.0901)  time: 0.2824  data: 0.1416  max mem: 1538\n",
      "Training Epoch: [0]  [1180/1229]  eta: 0:00:14  lr: 0.005000  loss: 0.4806 (0.6088)  loss_classifier: 0.1237 (0.1952)  loss_box_reg: 0.1190 (0.1222)  loss_objectness: 0.1233 (0.2012)  loss_rpn_box_reg: 0.0432 (0.0902)  time: 0.2811  data: 0.1434  max mem: 1538\n",
      "Training Epoch: [0]  [1190/1229]  eta: 0:00:11  lr: 0.005000  loss: 0.5166 (0.6086)  loss_classifier: 0.1205 (0.1950)  loss_box_reg: 0.1166 (0.1223)  loss_objectness: 0.1410 (0.2010)  loss_rpn_box_reg: 0.0598 (0.0903)  time: 0.2892  data: 0.1454  max mem: 1538\n",
      "Training Epoch: [0]  [1200/1229]  eta: 0:00:08  lr: 0.005000  loss: 0.4247 (0.6073)  loss_classifier: 0.1126 (0.1944)  loss_box_reg: 0.1006 (0.1221)  loss_objectness: 0.1509 (0.2007)  loss_rpn_box_reg: 0.0598 (0.0901)  time: 0.2885  data: 0.1462  max mem: 1538\n",
      "Training Epoch: [0]  [1210/1229]  eta: 0:00:05  lr: 0.005000  loss: 0.4780 (0.6065)  loss_classifier: 0.1417 (0.1944)  loss_box_reg: 0.1086 (0.1223)  loss_objectness: 0.1427 (0.2002)  loss_rpn_box_reg: 0.0378 (0.0896)  time: 0.2771  data: 0.1447  max mem: 1538\n",
      "Training Epoch: [0]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.5275 (0.6072)  loss_classifier: 0.2075 (0.1948)  loss_box_reg: 0.1772 (0.1229)  loss_objectness: 0.1593 (0.1999)  loss_rpn_box_reg: 0.0380 (0.0897)  time: 0.2789  data: 0.1448  max mem: 1538\n",
      "Training Epoch: [0]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.6542 (0.6070)  loss_classifier: 0.1759 (0.1946)  loss_box_reg: 0.1240 (0.1230)  loss_objectness: 0.1299 (0.1995)  loss_rpn_box_reg: 0.0531 (0.0900)  time: 0.2814  data: 0.1450  max mem: 1538\n",
      "Training Epoch: [0] Total time: 0:05:55 (0.2889 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:48  model_time: 0.3128 (0.3128)  evaluator_time: 0.0062 (0.0062)  time: 0.3530  data: 0.0320  max mem: 1538\n",
      "Test:  [100/308]  eta: 0:00:25  model_time: 0.0690 (0.0751)  evaluator_time: 0.0040 (0.0071)  time: 0.1204  data: 0.0379  max mem: 1538\n",
      "Test:  [200/308]  eta: 0:00:12  model_time: 0.0760 (0.0740)  evaluator_time: 0.0020 (0.0064)  time: 0.1194  data: 0.0379  max mem: 1538\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0650 (0.0731)  evaluator_time: 0.0040 (0.0065)  time: 0.1210  data: 0.0437  max mem: 1543\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0650 (0.0730)  evaluator_time: 0.0020 (0.0065)  time: 0.1185  data: 0.0424  max mem: 1543\n",
      "Test: Total time: 0:00:36 (0.1184 s / it)\n",
      "Averaged stats: model_time: 0.0650 (0.0730)  evaluator_time: 0.0020 (0.0065)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.075\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.084\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.145\n",
      "Testing Epoch: [0]  [  0/308]  eta: 0:00:40  lr: 0.005000  loss: 0.2004 (0.2004)  loss_classifier: 0.0644 (0.0644)  loss_box_reg: 0.0590 (0.0590)  loss_objectness: 0.0655 (0.0655)  loss_rpn_box_reg: 0.0116 (0.0116)  time: 0.1300  data: 0.0300  max mem: 1543\n",
      "Testing Epoch: [0]  [100/308]  eta: 0:00:29  lr: 0.005000  loss: 0.3828 (0.5718)  loss_classifier: 0.1345 (0.1893)  loss_box_reg: 0.1136 (0.1779)  loss_objectness: 0.1084 (0.1357)  loss_rpn_box_reg: 0.0253 (0.0689)  time: 0.1484  data: 0.0480  max mem: 1704\n",
      "Testing Epoch: [0]  [200/308]  eta: 0:00:15  lr: 0.005000  loss: 0.4897 (0.5420)  loss_classifier: 0.1738 (0.1782)  loss_box_reg: 0.1570 (0.1682)  loss_objectness: 0.0958 (0.1309)  loss_rpn_box_reg: 0.0312 (0.0645)  time: 0.1414  data: 0.0364  max mem: 1704\n",
      "Testing Epoch: [0]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5872 (0.5442)  loss_classifier: 0.2216 (0.1810)  loss_box_reg: 0.1852 (0.1723)  loss_objectness: 0.1061 (0.1288)  loss_rpn_box_reg: 0.0422 (0.0621)  time: 0.1346  data: 0.0409  max mem: 1704\n",
      "Testing Epoch: [0]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.6195 (0.5444)  loss_classifier: 0.2222 (0.1816)  loss_box_reg: 0.2059 (0.1727)  loss_objectness: 0.1061 (0.1285)  loss_rpn_box_reg: 0.0424 (0.0615)  time: 0.1366  data: 0.0437  max mem: 1704\n",
      "Testing Epoch: [0] Total time: 0:00:42 (0.1396 s / it)\n",
      "Training Epoch: [1]  [   0/1229]  eta: 0:05:04  lr: 0.005000  loss: 0.7515 (0.7515)  loss_classifier: 0.2076 (0.2076)  loss_box_reg: 0.1964 (0.1964)  loss_objectness: 0.1257 (0.1257)  loss_rpn_box_reg: 0.2217 (0.2217)  time: 0.2480  data: 0.1330  max mem: 1704\n",
      "Training Epoch: [1]  [  10/1229]  eta: 0:05:40  lr: 0.005000  loss: 0.6244 (0.5140)  loss_classifier: 0.1602 (0.1494)  loss_box_reg: 0.1122 (0.1128)  loss_objectness: 0.1028 (0.1268)  loss_rpn_box_reg: 0.0811 (0.1250)  time: 0.2794  data: 0.1386  max mem: 1704\n",
      "Training Epoch: [1]  [  20/1229]  eta: 0:05:36  lr: 0.005000  loss: 0.4573 (0.5371)  loss_classifier: 0.1256 (0.1685)  loss_box_reg: 0.0995 (0.1202)  loss_objectness: 0.1312 (0.1499)  loss_rpn_box_reg: 0.0594 (0.0985)  time: 0.2797  data: 0.1392  max mem: 1704\n",
      "Training Epoch: [1]  [  30/1229]  eta: 0:05:38  lr: 0.005000  loss: 0.4476 (0.5150)  loss_classifier: 0.1399 (0.1668)  loss_box_reg: 0.0929 (0.1189)  loss_objectness: 0.1575 (0.1464)  loss_rpn_box_reg: 0.0449 (0.0829)  time: 0.2833  data: 0.1422  max mem: 1704\n",
      "Training Epoch: [1]  [  40/1229]  eta: 0:05:35  lr: 0.005000  loss: 0.4927 (0.5536)  loss_classifier: 0.1543 (0.1792)  loss_box_reg: 0.0969 (0.1394)  loss_objectness: 0.1334 (0.1516)  loss_rpn_box_reg: 0.0526 (0.0835)  time: 0.2866  data: 0.1451  max mem: 1704\n",
      "Training Epoch: [1]  [  50/1229]  eta: 0:05:34  lr: 0.005000  loss: 0.5291 (0.5563)  loss_classifier: 0.1534 (0.1779)  loss_box_reg: 0.0995 (0.1402)  loss_objectness: 0.1338 (0.1518)  loss_rpn_box_reg: 0.0536 (0.0864)  time: 0.2857  data: 0.1440  max mem: 1704\n",
      "Training Epoch: [1]  [  60/1229]  eta: 0:05:33  lr: 0.005000  loss: 0.5923 (0.5671)  loss_classifier: 0.1691 (0.1802)  loss_box_reg: 0.1176 (0.1452)  loss_objectness: 0.1338 (0.1526)  loss_rpn_box_reg: 0.0534 (0.0891)  time: 0.2917  data: 0.1434  max mem: 1704\n",
      "Training Epoch: [1]  [  70/1229]  eta: 0:05:31  lr: 0.005000  loss: 0.5286 (0.5410)  loss_classifier: 0.1443 (0.1736)  loss_box_reg: 0.1127 (0.1373)  loss_objectness: 0.1116 (0.1464)  loss_rpn_box_reg: 0.0398 (0.0837)  time: 0.2920  data: 0.1441  max mem: 1704\n",
      "Training Epoch: [1]  [  80/1229]  eta: 0:05:29  lr: 0.005000  loss: 0.3654 (0.5399)  loss_classifier: 0.1006 (0.1696)  loss_box_reg: 0.0584 (0.1329)  loss_objectness: 0.1224 (0.1549)  loss_rpn_box_reg: 0.0546 (0.0825)  time: 0.2914  data: 0.1428  max mem: 1704\n",
      "Training Epoch: [1]  [  90/1229]  eta: 0:05:26  lr: 0.005000  loss: 0.4523 (0.5263)  loss_classifier: 0.1053 (0.1670)  loss_box_reg: 0.0575 (0.1280)  loss_objectness: 0.1369 (0.1529)  loss_rpn_box_reg: 0.0399 (0.0785)  time: 0.2888  data: 0.1416  max mem: 1704\n",
      "Training Epoch: [1]  [ 100/1229]  eta: 0:05:22  lr: 0.005000  loss: 0.3515 (0.5259)  loss_classifier: 0.1294 (0.1663)  loss_box_reg: 0.0861 (0.1286)  loss_objectness: 0.1213 (0.1539)  loss_rpn_box_reg: 0.0230 (0.0770)  time: 0.2818  data: 0.1426  max mem: 1704\n",
      "Training Epoch: [1]  [ 110/1229]  eta: 0:05:21  lr: 0.005000  loss: 0.4734 (0.5235)  loss_classifier: 0.1688 (0.1660)  loss_box_reg: 0.1198 (0.1288)  loss_objectness: 0.1279 (0.1534)  loss_rpn_box_reg: 0.0430 (0.0754)  time: 0.2886  data: 0.1420  max mem: 1704\n",
      "Training Epoch: [1]  [ 120/1229]  eta: 0:05:17  lr: 0.005000  loss: 0.5220 (0.5258)  loss_classifier: 0.1736 (0.1679)  loss_box_reg: 0.1240 (0.1296)  loss_objectness: 0.1471 (0.1540)  loss_rpn_box_reg: 0.0453 (0.0743)  time: 0.2889  data: 0.1416  max mem: 1704\n",
      "Training Epoch: [1]  [ 130/1229]  eta: 0:05:14  lr: 0.005000  loss: 0.5220 (0.5327)  loss_classifier: 0.1710 (0.1708)  loss_box_reg: 0.1486 (0.1342)  loss_objectness: 0.1483 (0.1531)  loss_rpn_box_reg: 0.0352 (0.0746)  time: 0.2796  data: 0.1456  max mem: 1704\n",
      "Training Epoch: [1]  [ 140/1229]  eta: 0:05:11  lr: 0.005000  loss: 0.5434 (0.5321)  loss_classifier: 0.1708 (0.1696)  loss_box_reg: 0.1545 (0.1344)  loss_objectness: 0.1311 (0.1518)  loss_rpn_box_reg: 0.0363 (0.0764)  time: 0.2822  data: 0.1466  max mem: 1704\n",
      "Training Epoch: [1]  [ 150/1229]  eta: 0:05:07  lr: 0.005000  loss: 0.4958 (0.5337)  loss_classifier: 0.1737 (0.1715)  loss_box_reg: 0.1605 (0.1359)  loss_objectness: 0.1330 (0.1521)  loss_rpn_box_reg: 0.0389 (0.0741)  time: 0.2829  data: 0.1452  max mem: 1704\n",
      "Training Epoch: [1]  [ 160/1229]  eta: 0:05:05  lr: 0.005000  loss: 0.4909 (0.5293)  loss_classifier: 0.1737 (0.1707)  loss_box_reg: 0.1605 (0.1355)  loss_objectness: 0.1341 (0.1514)  loss_rpn_box_reg: 0.0254 (0.0717)  time: 0.2856  data: 0.1495  max mem: 1704\n",
      "Training Epoch: [1]  [ 170/1229]  eta: 0:05:03  lr: 0.005000  loss: 0.4427 (0.5305)  loss_classifier: 0.1276 (0.1700)  loss_box_reg: 0.0814 (0.1361)  loss_objectness: 0.1341 (0.1525)  loss_rpn_box_reg: 0.0370 (0.0719)  time: 0.2947  data: 0.1526  max mem: 1704\n",
      "Training Epoch: [1]  [ 180/1229]  eta: 0:05:00  lr: 0.005000  loss: 0.4606 (0.5251)  loss_classifier: 0.1541 (0.1685)  loss_box_reg: 0.0945 (0.1348)  loss_objectness: 0.1514 (0.1517)  loss_rpn_box_reg: 0.0395 (0.0700)  time: 0.2908  data: 0.1461  max mem: 1704\n",
      "Training Epoch: [1]  [ 190/1229]  eta: 0:04:56  lr: 0.005000  loss: 0.4606 (0.5242)  loss_classifier: 0.1615 (0.1686)  loss_box_reg: 0.1069 (0.1360)  loss_objectness: 0.1484 (0.1502)  loss_rpn_box_reg: 0.0364 (0.0694)  time: 0.2752  data: 0.1380  max mem: 1704\n",
      "Training Epoch: [1]  [ 200/1229]  eta: 0:04:53  lr: 0.005000  loss: 0.3814 (0.5170)  loss_classifier: 0.1447 (0.1663)  loss_box_reg: 0.1068 (0.1340)  loss_objectness: 0.0849 (0.1472)  loss_rpn_box_reg: 0.0290 (0.0695)  time: 0.2705  data: 0.1370  max mem: 1704\n",
      "Training Epoch: [1]  [ 210/1229]  eta: 0:04:50  lr: 0.005000  loss: 0.3924 (0.5137)  loss_classifier: 0.1447 (0.1662)  loss_box_reg: 0.1081 (0.1347)  loss_objectness: 0.0943 (0.1454)  loss_rpn_box_reg: 0.0275 (0.0675)  time: 0.2800  data: 0.1401  max mem: 1704\n",
      "Training Epoch: [1]  [ 220/1229]  eta: 0:04:47  lr: 0.005000  loss: 0.4203 (0.5127)  loss_classifier: 0.1598 (0.1665)  loss_box_reg: 0.1300 (0.1354)  loss_objectness: 0.0978 (0.1441)  loss_rpn_box_reg: 0.0276 (0.0667)  time: 0.2815  data: 0.1412  max mem: 1704\n",
      "Training Epoch: [1]  [ 230/1229]  eta: 0:04:43  lr: 0.005000  loss: 0.4184 (0.5146)  loss_classifier: 0.1443 (0.1676)  loss_box_reg: 0.1115 (0.1361)  loss_objectness: 0.1055 (0.1437)  loss_rpn_box_reg: 0.0494 (0.0672)  time: 0.2778  data: 0.1400  max mem: 1704\n",
      "Training Epoch: [1]  [ 240/1229]  eta: 0:04:41  lr: 0.005000  loss: 0.3802 (0.5139)  loss_classifier: 0.1398 (0.1676)  loss_box_reg: 0.0991 (0.1357)  loss_objectness: 0.1371 (0.1433)  loss_rpn_box_reg: 0.0304 (0.0672)  time: 0.2867  data: 0.1396  max mem: 1704\n",
      "Training Epoch: [1]  [ 250/1229]  eta: 0:04:38  lr: 0.005000  loss: 0.4020 (0.5152)  loss_classifier: 0.1440 (0.1686)  loss_box_reg: 0.1117 (0.1373)  loss_objectness: 0.1276 (0.1435)  loss_rpn_box_reg: 0.0261 (0.0659)  time: 0.2846  data: 0.1394  max mem: 1704\n",
      "Training Epoch: [1]  [ 260/1229]  eta: 0:04:35  lr: 0.005000  loss: 0.4456 (0.5107)  loss_classifier: 0.1453 (0.1672)  loss_box_reg: 0.1117 (0.1360)  loss_objectness: 0.1100 (0.1422)  loss_rpn_box_reg: 0.0268 (0.0653)  time: 0.2783  data: 0.1400  max mem: 1704\n",
      "Training Epoch: [1]  [ 270/1229]  eta: 0:04:32  lr: 0.005000  loss: 0.4456 (0.5156)  loss_classifier: 0.1334 (0.1684)  loss_box_reg: 0.1091 (0.1381)  loss_objectness: 0.1244 (0.1426)  loss_rpn_box_reg: 0.0608 (0.0665)  time: 0.2853  data: 0.1395  max mem: 1704\n",
      "Training Epoch: [1]  [ 280/1229]  eta: 0:04:30  lr: 0.005000  loss: 0.5445 (0.5172)  loss_classifier: 0.1995 (0.1695)  loss_box_reg: 0.1731 (0.1396)  loss_objectness: 0.1641 (0.1426)  loss_rpn_box_reg: 0.0448 (0.0654)  time: 0.2918  data: 0.1409  max mem: 1704\n",
      "Training Epoch: [1]  [ 290/1229]  eta: 0:04:27  lr: 0.005000  loss: 0.5026 (0.5176)  loss_classifier: 0.1621 (0.1696)  loss_box_reg: 0.1313 (0.1392)  loss_objectness: 0.1772 (0.1431)  loss_rpn_box_reg: 0.0387 (0.0658)  time: 0.2930  data: 0.1424  max mem: 1704\n",
      "Training Epoch: [1]  [ 300/1229]  eta: 0:04:24  lr: 0.005000  loss: 0.5026 (0.5195)  loss_classifier: 0.1543 (0.1696)  loss_box_reg: 0.1031 (0.1391)  loss_objectness: 0.1552 (0.1439)  loss_rpn_box_reg: 0.0352 (0.0670)  time: 0.2879  data: 0.1421  max mem: 1704\n",
      "Training Epoch: [1]  [ 310/1229]  eta: 0:04:21  lr: 0.005000  loss: 0.5773 (0.5225)  loss_classifier: 0.1748 (0.1706)  loss_box_reg: 0.1561 (0.1404)  loss_objectness: 0.1457 (0.1439)  loss_rpn_box_reg: 0.0490 (0.0677)  time: 0.2855  data: 0.1437  max mem: 1704\n",
      "Training Epoch: [1]  [ 320/1229]  eta: 0:04:18  lr: 0.005000  loss: 0.5773 (0.5243)  loss_classifier: 0.1589 (0.1707)  loss_box_reg: 0.1076 (0.1405)  loss_objectness: 0.1357 (0.1449)  loss_rpn_box_reg: 0.0532 (0.0682)  time: 0.2824  data: 0.1451  max mem: 1704\n",
      "Training Epoch: [1]  [ 330/1229]  eta: 0:04:15  lr: 0.005000  loss: 0.4672 (0.5226)  loss_classifier: 0.1511 (0.1705)  loss_box_reg: 0.1063 (0.1403)  loss_objectness: 0.1171 (0.1440)  loss_rpn_box_reg: 0.0406 (0.0678)  time: 0.2784  data: 0.1431  max mem: 1704\n",
      "Training Epoch: [1]  [ 340/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.5118 (0.5237)  loss_classifier: 0.1469 (0.1701)  loss_box_reg: 0.1169 (0.1405)  loss_objectness: 0.1308 (0.1442)  loss_rpn_box_reg: 0.0399 (0.0689)  time: 0.2864  data: 0.1406  max mem: 1704\n",
      "Training Epoch: [1]  [ 350/1229]  eta: 0:04:10  lr: 0.005000  loss: 0.4213 (0.5209)  loss_classifier: 0.1159 (0.1690)  loss_box_reg: 0.1096 (0.1395)  loss_objectness: 0.1308 (0.1438)  loss_rpn_box_reg: 0.0340 (0.0685)  time: 0.2882  data: 0.1435  max mem: 1704\n",
      "Training Epoch: [1]  [ 360/1229]  eta: 0:04:07  lr: 0.005000  loss: 0.5206 (0.5239)  loss_classifier: 0.1740 (0.1702)  loss_box_reg: 0.1160 (0.1414)  loss_objectness: 0.1502 (0.1441)  loss_rpn_box_reg: 0.0382 (0.0682)  time: 0.2780  data: 0.1391  max mem: 1704\n",
      "Training Epoch: [1]  [ 370/1229]  eta: 0:04:04  lr: 0.005000  loss: 0.5373 (0.5260)  loss_classifier: 0.1793 (0.1707)  loss_box_reg: 0.1552 (0.1423)  loss_objectness: 0.1538 (0.1440)  loss_rpn_box_reg: 0.0530 (0.0691)  time: 0.2743  data: 0.1312  max mem: 1704\n",
      "Training Epoch: [1]  [ 380/1229]  eta: 0:04:00  lr: 0.005000  loss: 0.4994 (0.5256)  loss_classifier: 0.1582 (0.1710)  loss_box_reg: 0.1376 (0.1425)  loss_objectness: 0.1010 (0.1429)  loss_rpn_box_reg: 0.0357 (0.0692)  time: 0.2716  data: 0.1310  max mem: 1704\n",
      "Training Epoch: [1]  [ 390/1229]  eta: 0:03:57  lr: 0.005000  loss: 0.5047 (0.5291)  loss_classifier: 0.1794 (0.1717)  loss_box_reg: 0.1376 (0.1425)  loss_objectness: 0.1211 (0.1450)  loss_rpn_box_reg: 0.0855 (0.0699)  time: 0.2720  data: 0.1324  max mem: 1704\n",
      "Training Epoch: [1]  [ 400/1229]  eta: 0:03:54  lr: 0.005000  loss: 0.6420 (0.5312)  loss_classifier: 0.1998 (0.1727)  loss_box_reg: 0.1597 (0.1437)  loss_objectness: 0.1644 (0.1453)  loss_rpn_box_reg: 0.0557 (0.0696)  time: 0.2729  data: 0.1341  max mem: 1704\n",
      "Training Epoch: [1]  [ 410/1229]  eta: 0:03:51  lr: 0.005000  loss: 0.4725 (0.5318)  loss_classifier: 0.1682 (0.1728)  loss_box_reg: 0.1342 (0.1439)  loss_objectness: 0.1580 (0.1459)  loss_rpn_box_reg: 0.0372 (0.0692)  time: 0.2694  data: 0.1343  max mem: 1704\n",
      "Training Epoch: [1]  [ 420/1229]  eta: 0:03:48  lr: 0.005000  loss: 0.4871 (0.5314)  loss_classifier: 0.1490 (0.1725)  loss_box_reg: 0.1205 (0.1436)  loss_objectness: 0.1287 (0.1455)  loss_rpn_box_reg: 0.0454 (0.0698)  time: 0.2707  data: 0.1295  max mem: 1704\n",
      "Training Epoch: [1]  [ 430/1229]  eta: 0:03:45  lr: 0.005000  loss: 0.4470 (0.5314)  loss_classifier: 0.1335 (0.1726)  loss_box_reg: 0.1203 (0.1441)  loss_objectness: 0.1213 (0.1451)  loss_rpn_box_reg: 0.0438 (0.0696)  time: 0.2732  data: 0.1278  max mem: 1704\n",
      "Training Epoch: [1]  [ 440/1229]  eta: 0:03:42  lr: 0.005000  loss: 0.3689 (0.5298)  loss_classifier: 0.1278 (0.1722)  loss_box_reg: 0.1056 (0.1440)  loss_objectness: 0.1208 (0.1445)  loss_rpn_box_reg: 0.0289 (0.0691)  time: 0.2725  data: 0.1319  max mem: 1704\n",
      "Training Epoch: [1]  [ 450/1229]  eta: 0:03:39  lr: 0.005000  loss: 0.3780 (0.5261)  loss_classifier: 0.1230 (0.1714)  loss_box_reg: 0.1056 (0.1433)  loss_objectness: 0.0924 (0.1433)  loss_rpn_box_reg: 0.0214 (0.0681)  time: 0.2737  data: 0.1331  max mem: 1704\n",
      "Training Epoch: [1]  [ 460/1229]  eta: 0:03:36  lr: 0.005000  loss: 0.3780 (0.5232)  loss_classifier: 0.1047 (0.1706)  loss_box_reg: 0.0972 (0.1429)  loss_objectness: 0.0924 (0.1422)  loss_rpn_box_reg: 0.0182 (0.0675)  time: 0.2764  data: 0.1316  max mem: 1704\n",
      "Training Epoch: [1]  [ 470/1229]  eta: 0:03:33  lr: 0.005000  loss: 0.3545 (0.5213)  loss_classifier: 0.1103 (0.1701)  loss_box_reg: 0.0972 (0.1425)  loss_objectness: 0.0879 (0.1414)  loss_rpn_box_reg: 0.0304 (0.0672)  time: 0.2726  data: 0.1306  max mem: 1704\n",
      "Training Epoch: [1]  [ 480/1229]  eta: 0:03:30  lr: 0.005000  loss: 0.5112 (0.5214)  loss_classifier: 0.1477 (0.1705)  loss_box_reg: 0.1221 (0.1428)  loss_objectness: 0.1030 (0.1413)  loss_rpn_box_reg: 0.0375 (0.0668)  time: 0.2647  data: 0.1312  max mem: 1704\n",
      "Training Epoch: [1]  [ 490/1229]  eta: 0:03:27  lr: 0.005000  loss: 0.4958 (0.5214)  loss_classifier: 0.1617 (0.1706)  loss_box_reg: 0.1273 (0.1426)  loss_objectness: 0.1251 (0.1413)  loss_rpn_box_reg: 0.0298 (0.0669)  time: 0.2712  data: 0.1323  max mem: 1704\n",
      "Training Epoch: [1]  [ 500/1229]  eta: 0:03:24  lr: 0.005000  loss: 0.4958 (0.5211)  loss_classifier: 0.1688 (0.1706)  loss_box_reg: 0.1273 (0.1428)  loss_objectness: 0.1251 (0.1412)  loss_rpn_box_reg: 0.0282 (0.0665)  time: 0.2778  data: 0.1335  max mem: 1704\n",
      "Training Epoch: [1]  [ 510/1229]  eta: 0:03:21  lr: 0.005000  loss: 0.5117 (0.5200)  loss_classifier: 0.1624 (0.1699)  loss_box_reg: 0.1201 (0.1423)  loss_objectness: 0.1230 (0.1410)  loss_rpn_box_reg: 0.0294 (0.0669)  time: 0.2686  data: 0.1323  max mem: 1704\n",
      "Training Epoch: [1]  [ 520/1229]  eta: 0:03:19  lr: 0.005000  loss: 0.4749 (0.5186)  loss_classifier: 0.1310 (0.1695)  loss_box_reg: 0.1050 (0.1418)  loss_objectness: 0.1230 (0.1406)  loss_rpn_box_reg: 0.0294 (0.0667)  time: 0.2705  data: 0.1322  max mem: 1704\n",
      "Training Epoch: [1]  [ 530/1229]  eta: 0:03:16  lr: 0.005000  loss: 0.3903 (0.5167)  loss_classifier: 0.1288 (0.1691)  loss_box_reg: 0.0991 (0.1413)  loss_objectness: 0.0923 (0.1399)  loss_rpn_box_reg: 0.0341 (0.0663)  time: 0.2784  data: 0.1327  max mem: 1704\n",
      "Training Epoch: [1]  [ 540/1229]  eta: 0:03:13  lr: 0.005000  loss: 0.4299 (0.5163)  loss_classifier: 0.1219 (0.1691)  loss_box_reg: 0.1074 (0.1414)  loss_objectness: 0.1161 (0.1399)  loss_rpn_box_reg: 0.0381 (0.0660)  time: 0.2735  data: 0.1315  max mem: 1704\n",
      "Training Epoch: [1]  [ 550/1229]  eta: 0:03:10  lr: 0.005000  loss: 0.4089 (0.5140)  loss_classifier: 0.1349 (0.1683)  loss_box_reg: 0.0964 (0.1408)  loss_objectness: 0.1161 (0.1392)  loss_rpn_box_reg: 0.0320 (0.0657)  time: 0.2731  data: 0.1315  max mem: 1704\n",
      "Training Epoch: [1]  [ 560/1229]  eta: 0:03:07  lr: 0.005000  loss: 0.4100 (0.5138)  loss_classifier: 0.1492 (0.1681)  loss_box_reg: 0.1142 (0.1409)  loss_objectness: 0.0824 (0.1391)  loss_rpn_box_reg: 0.0347 (0.0657)  time: 0.2786  data: 0.1296  max mem: 1704\n",
      "Training Epoch: [1]  [ 570/1229]  eta: 0:03:04  lr: 0.005000  loss: 0.5144 (0.5139)  loss_classifier: 0.1677 (0.1682)  loss_box_reg: 0.1400 (0.1411)  loss_objectness: 0.0977 (0.1392)  loss_rpn_box_reg: 0.0404 (0.0653)  time: 0.2753  data: 0.1303  max mem: 1704\n",
      "Training Epoch: [1]  [ 580/1229]  eta: 0:03:01  lr: 0.005000  loss: 0.5299 (0.5155)  loss_classifier: 0.1907 (0.1692)  loss_box_reg: 0.1625 (0.1421)  loss_objectness: 0.1178 (0.1391)  loss_rpn_box_reg: 0.0404 (0.0652)  time: 0.2694  data: 0.1327  max mem: 1704\n",
      "Training Epoch: [1]  [ 590/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.5644 (0.5150)  loss_classifier: 0.1815 (0.1689)  loss_box_reg: 0.1548 (0.1417)  loss_objectness: 0.1178 (0.1387)  loss_rpn_box_reg: 0.0383 (0.0657)  time: 0.2678  data: 0.1322  max mem: 1704\n",
      "Training Epoch: [1]  [ 600/1229]  eta: 0:02:55  lr: 0.005000  loss: 0.2891 (0.5128)  loss_classifier: 0.1163 (0.1683)  loss_box_reg: 0.0867 (0.1415)  loss_objectness: 0.0683 (0.1377)  loss_rpn_box_reg: 0.0249 (0.0653)  time: 0.2663  data: 0.1331  max mem: 1704\n",
      "Training Epoch: [1]  [ 610/1229]  eta: 0:02:53  lr: 0.005000  loss: 0.3919 (0.5146)  loss_classifier: 0.1428 (0.1687)  loss_box_reg: 0.1010 (0.1418)  loss_objectness: 0.1137 (0.1382)  loss_rpn_box_reg: 0.0565 (0.0659)  time: 0.2715  data: 0.1352  max mem: 1704\n",
      "Training Epoch: [1]  [ 620/1229]  eta: 0:02:50  lr: 0.005000  loss: 0.6303 (0.5157)  loss_classifier: 0.1753 (0.1691)  loss_box_reg: 0.1418 (0.1422)  loss_objectness: 0.1410 (0.1384)  loss_rpn_box_reg: 0.0603 (0.0660)  time: 0.2729  data: 0.1337  max mem: 1704\n",
      "Training Epoch: [1]  [ 630/1229]  eta: 0:02:47  lr: 0.005000  loss: 0.4807 (0.5155)  loss_classifier: 0.1565 (0.1689)  loss_box_reg: 0.1122 (0.1416)  loss_objectness: 0.1383 (0.1384)  loss_rpn_box_reg: 0.0476 (0.0665)  time: 0.2717  data: 0.1332  max mem: 1704\n",
      "Training Epoch: [1]  [ 640/1229]  eta: 0:02:44  lr: 0.005000  loss: 0.4891 (0.5142)  loss_classifier: 0.1349 (0.1687)  loss_box_reg: 0.1134 (0.1416)  loss_objectness: 0.1206 (0.1379)  loss_rpn_box_reg: 0.0420 (0.0660)  time: 0.2761  data: 0.1329  max mem: 1704\n",
      "Training Epoch: [1]  [ 650/1229]  eta: 0:02:41  lr: 0.005000  loss: 0.4813 (0.5142)  loss_classifier: 0.1530 (0.1687)  loss_box_reg: 0.1134 (0.1416)  loss_objectness: 0.1032 (0.1379)  loss_rpn_box_reg: 0.0365 (0.0660)  time: 0.2750  data: 0.1319  max mem: 1704\n",
      "Training Epoch: [1]  [ 660/1229]  eta: 0:02:38  lr: 0.005000  loss: 0.4547 (0.5138)  loss_classifier: 0.1501 (0.1687)  loss_box_reg: 0.0930 (0.1412)  loss_objectness: 0.1396 (0.1381)  loss_rpn_box_reg: 0.0359 (0.0658)  time: 0.2747  data: 0.1320  max mem: 1704\n",
      "Training Epoch: [1]  [ 670/1229]  eta: 0:02:35  lr: 0.005000  loss: 0.5249 (0.5147)  loss_classifier: 0.1786 (0.1691)  loss_box_reg: 0.1144 (0.1416)  loss_objectness: 0.1338 (0.1384)  loss_rpn_box_reg: 0.0305 (0.0657)  time: 0.2720  data: 0.1328  max mem: 1704\n",
      "Training Epoch: [1]  [ 680/1229]  eta: 0:02:33  lr: 0.005000  loss: 0.5097 (0.5132)  loss_classifier: 0.1765 (0.1685)  loss_box_reg: 0.1241 (0.1411)  loss_objectness: 0.1273 (0.1382)  loss_rpn_box_reg: 0.0315 (0.0653)  time: 0.2725  data: 0.1338  max mem: 1704\n",
      "Training Epoch: [1]  [ 690/1229]  eta: 0:02:30  lr: 0.005000  loss: 0.3525 (0.5125)  loss_classifier: 0.1301 (0.1683)  loss_box_reg: 0.0957 (0.1409)  loss_objectness: 0.0865 (0.1380)  loss_rpn_box_reg: 0.0306 (0.0654)  time: 0.2744  data: 0.1337  max mem: 1704\n",
      "Training Epoch: [1]  [ 700/1229]  eta: 0:02:27  lr: 0.005000  loss: 0.4473 (0.5124)  loss_classifier: 0.1577 (0.1685)  loss_box_reg: 0.1298 (0.1412)  loss_objectness: 0.0928 (0.1376)  loss_rpn_box_reg: 0.0337 (0.0651)  time: 0.2729  data: 0.1341  max mem: 1704\n",
      "Training Epoch: [1]  [ 710/1229]  eta: 0:02:24  lr: 0.005000  loss: 0.5595 (0.5136)  loss_classifier: 0.2039 (0.1689)  loss_box_reg: 0.1672 (0.1416)  loss_objectness: 0.1133 (0.1377)  loss_rpn_box_reg: 0.0606 (0.0655)  time: 0.2734  data: 0.1340  max mem: 1704\n",
      "Training Epoch: [1]  [ 720/1229]  eta: 0:02:21  lr: 0.005000  loss: 0.5963 (0.5144)  loss_classifier: 0.1935 (0.1690)  loss_box_reg: 0.1277 (0.1416)  loss_objectness: 0.1323 (0.1380)  loss_rpn_box_reg: 0.0666 (0.0658)  time: 0.2720  data: 0.1335  max mem: 1704\n",
      "Training Epoch: [1]  [ 730/1229]  eta: 0:02:18  lr: 0.005000  loss: 0.5485 (0.5142)  loss_classifier: 0.1678 (0.1691)  loss_box_reg: 0.1065 (0.1414)  loss_objectness: 0.1338 (0.1378)  loss_rpn_box_reg: 0.0535 (0.0659)  time: 0.2711  data: 0.1316  max mem: 1704\n",
      "Training Epoch: [1]  [ 740/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.5021 (0.5138)  loss_classifier: 0.1613 (0.1691)  loss_box_reg: 0.1155 (0.1414)  loss_objectness: 0.1319 (0.1377)  loss_rpn_box_reg: 0.0354 (0.0655)  time: 0.2680  data: 0.1296  max mem: 1704\n",
      "Training Epoch: [1]  [ 750/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.5004 (0.5145)  loss_classifier: 0.1600 (0.1693)  loss_box_reg: 0.1155 (0.1415)  loss_objectness: 0.1040 (0.1378)  loss_rpn_box_reg: 0.0543 (0.0659)  time: 0.2688  data: 0.1313  max mem: 1704\n",
      "Training Epoch: [1]  [ 760/1229]  eta: 0:02:10  lr: 0.005000  loss: 0.5247 (0.5152)  loss_classifier: 0.1562 (0.1695)  loss_box_reg: 0.1342 (0.1417)  loss_objectness: 0.1048 (0.1378)  loss_rpn_box_reg: 0.0648 (0.0663)  time: 0.2686  data: 0.1334  max mem: 1704\n",
      "Training Epoch: [1]  [ 770/1229]  eta: 0:02:07  lr: 0.005000  loss: 0.5247 (0.5153)  loss_classifier: 0.1721 (0.1695)  loss_box_reg: 0.1287 (0.1413)  loss_objectness: 0.1260 (0.1384)  loss_rpn_box_reg: 0.0541 (0.0661)  time: 0.2695  data: 0.1339  max mem: 1704\n",
      "Training Epoch: [1]  [ 780/1229]  eta: 0:02:04  lr: 0.005000  loss: 0.4696 (0.5165)  loss_classifier: 0.1509 (0.1697)  loss_box_reg: 0.1091 (0.1414)  loss_objectness: 0.1380 (0.1388)  loss_rpn_box_reg: 0.0393 (0.0667)  time: 0.2736  data: 0.1326  max mem: 1704\n",
      "Training Epoch: [1]  [ 790/1229]  eta: 0:02:01  lr: 0.005000  loss: 0.4489 (0.5172)  loss_classifier: 0.1284 (0.1698)  loss_box_reg: 0.1091 (0.1417)  loss_objectness: 0.1163 (0.1387)  loss_rpn_box_reg: 0.0369 (0.0670)  time: 0.2731  data: 0.1323  max mem: 1704\n",
      "Training Epoch: [1]  [ 800/1229]  eta: 0:01:59  lr: 0.005000  loss: 0.5105 (0.5188)  loss_classifier: 0.1682 (0.1703)  loss_box_reg: 0.1411 (0.1424)  loss_objectness: 0.1239 (0.1388)  loss_rpn_box_reg: 0.0369 (0.0674)  time: 0.2726  data: 0.1337  max mem: 1704\n",
      "Training Epoch: [1]  [ 810/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.5257 (0.5185)  loss_classifier: 0.1682 (0.1700)  loss_box_reg: 0.1411 (0.1421)  loss_objectness: 0.1239 (0.1389)  loss_rpn_box_reg: 0.0370 (0.0675)  time: 0.2698  data: 0.1323  max mem: 1704\n",
      "Training Epoch: [1]  [ 820/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.5257 (0.5187)  loss_classifier: 0.1196 (0.1698)  loss_box_reg: 0.0925 (0.1420)  loss_objectness: 0.1125 (0.1393)  loss_rpn_box_reg: 0.0370 (0.0676)  time: 0.2692  data: 0.1307  max mem: 1704\n",
      "Training Epoch: [1]  [ 830/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.4640 (0.5185)  loss_classifier: 0.1572 (0.1696)  loss_box_reg: 0.1194 (0.1418)  loss_objectness: 0.1250 (0.1396)  loss_rpn_box_reg: 0.0304 (0.0676)  time: 0.2713  data: 0.1304  max mem: 1704\n",
      "Training Epoch: [1]  [ 840/1229]  eta: 0:01:47  lr: 0.005000  loss: 0.4825 (0.5200)  loss_classifier: 0.1620 (0.1700)  loss_box_reg: 0.1278 (0.1424)  loss_objectness: 0.1313 (0.1397)  loss_rpn_box_reg: 0.0598 (0.0678)  time: 0.2746  data: 0.1308  max mem: 1704\n",
      "Training Epoch: [1]  [ 850/1229]  eta: 0:01:45  lr: 0.005000  loss: 0.5618 (0.5202)  loss_classifier: 0.1791 (0.1702)  loss_box_reg: 0.1519 (0.1427)  loss_objectness: 0.1348 (0.1397)  loss_rpn_box_reg: 0.0569 (0.0676)  time: 0.2719  data: 0.1304  max mem: 1704\n",
      "Training Epoch: [1]  [ 860/1229]  eta: 0:01:42  lr: 0.005000  loss: 0.5618 (0.5219)  loss_classifier: 0.1766 (0.1706)  loss_box_reg: 0.1519 (0.1433)  loss_objectness: 0.1655 (0.1401)  loss_rpn_box_reg: 0.0439 (0.0680)  time: 0.2661  data: 0.1307  max mem: 1704\n",
      "Training Epoch: [1]  [ 870/1229]  eta: 0:01:39  lr: 0.005000  loss: 0.4935 (0.5212)  loss_classifier: 0.1324 (0.1704)  loss_box_reg: 0.1035 (0.1431)  loss_objectness: 0.1692 (0.1402)  loss_rpn_box_reg: 0.0324 (0.0675)  time: 0.2632  data: 0.1313  max mem: 1704\n",
      "Training Epoch: [1]  [ 880/1229]  eta: 0:01:36  lr: 0.005000  loss: 0.3216 (0.5200)  loss_classifier: 0.1175 (0.1700)  loss_box_reg: 0.0830 (0.1428)  loss_objectness: 0.1141 (0.1401)  loss_rpn_box_reg: 0.0188 (0.0671)  time: 0.2667  data: 0.1324  max mem: 1704\n",
      "Training Epoch: [1]  [ 890/1229]  eta: 0:01:33  lr: 0.005000  loss: 0.4647 (0.5214)  loss_classifier: 0.1694 (0.1705)  loss_box_reg: 0.1125 (0.1433)  loss_objectness: 0.1141 (0.1405)  loss_rpn_box_reg: 0.0266 (0.0672)  time: 0.2706  data: 0.1336  max mem: 1704\n",
      "Training Epoch: [1]  [ 900/1229]  eta: 0:01:31  lr: 0.005000  loss: 0.5640 (0.5224)  loss_classifier: 0.1902 (0.1707)  loss_box_reg: 0.1627 (0.1432)  loss_objectness: 0.1540 (0.1411)  loss_rpn_box_reg: 0.0465 (0.0674)  time: 0.2698  data: 0.1329  max mem: 1704\n",
      "Training Epoch: [1]  [ 910/1229]  eta: 0:01:28  lr: 0.005000  loss: 0.3745 (0.5224)  loss_classifier: 0.1411 (0.1705)  loss_box_reg: 0.0948 (0.1430)  loss_objectness: 0.1541 (0.1416)  loss_rpn_box_reg: 0.0299 (0.0672)  time: 0.2698  data: 0.1314  max mem: 1704\n",
      "Training Epoch: [1]  [ 920/1229]  eta: 0:01:25  lr: 0.005000  loss: 0.3745 (0.5214)  loss_classifier: 0.1175 (0.1701)  loss_box_reg: 0.0875 (0.1426)  loss_objectness: 0.1403 (0.1415)  loss_rpn_box_reg: 0.0319 (0.0673)  time: 0.2720  data: 0.1315  max mem: 1704\n",
      "Training Epoch: [1]  [ 930/1229]  eta: 0:01:22  lr: 0.005000  loss: 0.3700 (0.5207)  loss_classifier: 0.1191 (0.1700)  loss_box_reg: 0.1151 (0.1424)  loss_objectness: 0.1232 (0.1413)  loss_rpn_box_reg: 0.0339 (0.0670)  time: 0.2721  data: 0.1337  max mem: 1704\n",
      "Training Epoch: [1]  [ 940/1229]  eta: 0:01:19  lr: 0.005000  loss: 0.4456 (0.5215)  loss_classifier: 0.1598 (0.1703)  loss_box_reg: 0.1180 (0.1428)  loss_objectness: 0.1160 (0.1414)  loss_rpn_box_reg: 0.0339 (0.0670)  time: 0.2698  data: 0.1337  max mem: 1704\n",
      "Training Epoch: [1]  [ 950/1229]  eta: 0:01:17  lr: 0.005000  loss: 0.4862 (0.5205)  loss_classifier: 0.1514 (0.1699)  loss_box_reg: 0.1159 (0.1424)  loss_objectness: 0.1346 (0.1413)  loss_rpn_box_reg: 0.0357 (0.0669)  time: 0.2710  data: 0.1315  max mem: 1704\n",
      "Training Epoch: [1]  [ 960/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.3977 (0.5199)  loss_classifier: 0.1371 (0.1698)  loss_box_reg: 0.0986 (0.1423)  loss_objectness: 0.0965 (0.1412)  loss_rpn_box_reg: 0.0324 (0.0667)  time: 0.2724  data: 0.1324  max mem: 1704\n",
      "Training Epoch: [1]  [ 970/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.4302 (0.5197)  loss_classifier: 0.1772 (0.1699)  loss_box_reg: 0.1112 (0.1422)  loss_objectness: 0.1094 (0.1412)  loss_rpn_box_reg: 0.0348 (0.0666)  time: 0.2724  data: 0.1324  max mem: 1704\n",
      "Training Epoch: [1]  [ 980/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.4028 (0.5191)  loss_classifier: 0.1488 (0.1698)  loss_box_reg: 0.1333 (0.1420)  loss_objectness: 0.0940 (0.1409)  loss_rpn_box_reg: 0.0336 (0.0664)  time: 0.2707  data: 0.1311  max mem: 1704\n",
      "Training Epoch: [1]  [ 990/1229]  eta: 0:01:06  lr: 0.005000  loss: 0.3667 (0.5187)  loss_classifier: 0.1481 (0.1696)  loss_box_reg: 0.1300 (0.1418)  loss_objectness: 0.0880 (0.1410)  loss_rpn_box_reg: 0.0196 (0.0663)  time: 0.2692  data: 0.1330  max mem: 1704\n",
      "Training Epoch: [1]  [1000/1229]  eta: 0:01:03  lr: 0.005000  loss: 0.4224 (0.5179)  loss_classifier: 0.1436 (0.1694)  loss_box_reg: 0.1039 (0.1414)  loss_objectness: 0.1106 (0.1409)  loss_rpn_box_reg: 0.0363 (0.0661)  time: 0.2732  data: 0.1351  max mem: 1704\n",
      "Training Epoch: [1]  [1010/1229]  eta: 0:01:00  lr: 0.005000  loss: 0.4293 (0.5178)  loss_classifier: 0.1340 (0.1692)  loss_box_reg: 0.0832 (0.1412)  loss_objectness: 0.1550 (0.1411)  loss_rpn_box_reg: 0.0449 (0.0663)  time: 0.2728  data: 0.1348  max mem: 1704\n",
      "Training Epoch: [1]  [1020/1229]  eta: 0:00:57  lr: 0.005000  loss: 0.3917 (0.5161)  loss_classifier: 0.1135 (0.1685)  loss_box_reg: 0.0832 (0.1406)  loss_objectness: 0.1445 (0.1409)  loss_rpn_box_reg: 0.0288 (0.0660)  time: 0.2729  data: 0.1317  max mem: 1704\n",
      "Training Epoch: [1]  [1030/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.3917 (0.5164)  loss_classifier: 0.1119 (0.1683)  loss_box_reg: 0.0970 (0.1405)  loss_objectness: 0.1057 (0.1411)  loss_rpn_box_reg: 0.0248 (0.0664)  time: 0.2708  data: 0.1299  max mem: 1704\n",
      "Training Epoch: [1]  [1040/1229]  eta: 0:00:52  lr: 0.005000  loss: 0.5271 (0.5176)  loss_classifier: 0.1627 (0.1689)  loss_box_reg: 0.1057 (0.1407)  loss_objectness: 0.1437 (0.1415)  loss_rpn_box_reg: 0.0434 (0.0664)  time: 0.2687  data: 0.1336  max mem: 1704\n",
      "Training Epoch: [1]  [1050/1229]  eta: 0:00:49  lr: 0.005000  loss: 0.4811 (0.5172)  loss_classifier: 0.1852 (0.1687)  loss_box_reg: 0.1536 (0.1407)  loss_objectness: 0.1337 (0.1412)  loss_rpn_box_reg: 0.0434 (0.0665)  time: 0.2700  data: 0.1343  max mem: 1704\n",
      "Training Epoch: [1]  [1060/1229]  eta: 0:00:46  lr: 0.005000  loss: 0.4253 (0.5170)  loss_classifier: 0.1571 (0.1687)  loss_box_reg: 0.1508 (0.1407)  loss_objectness: 0.0995 (0.1412)  loss_rpn_box_reg: 0.0349 (0.0664)  time: 0.2668  data: 0.1329  max mem: 1704\n",
      "Training Epoch: [1]  [1070/1229]  eta: 0:00:43  lr: 0.005000  loss: 0.4850 (0.5170)  loss_classifier: 0.1595 (0.1688)  loss_box_reg: 0.1354 (0.1405)  loss_objectness: 0.1383 (0.1414)  loss_rpn_box_reg: 0.0413 (0.0663)  time: 0.2737  data: 0.1330  max mem: 1704\n",
      "Training Epoch: [1]  [1080/1229]  eta: 0:00:41  lr: 0.005000  loss: 0.4850 (0.5163)  loss_classifier: 0.1544 (0.1687)  loss_box_reg: 0.1212 (0.1404)  loss_objectness: 0.1383 (0.1412)  loss_rpn_box_reg: 0.0300 (0.0660)  time: 0.2727  data: 0.1313  max mem: 1704\n",
      "Training Epoch: [1]  [1090/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.4680 (0.5157)  loss_classifier: 0.1544 (0.1687)  loss_box_reg: 0.1290 (0.1405)  loss_objectness: 0.0902 (0.1407)  loss_rpn_box_reg: 0.0209 (0.0657)  time: 0.2671  data: 0.1315  max mem: 1704\n",
      "Training Epoch: [1]  [1100/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4766 (0.5169)  loss_classifier: 0.1874 (0.1692)  loss_box_reg: 0.1501 (0.1413)  loss_objectness: 0.0963 (0.1406)  loss_rpn_box_reg: 0.0291 (0.0657)  time: 0.2648  data: 0.1308  max mem: 1704\n",
      "Training Epoch: [1]  [1110/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.4386 (0.5162)  loss_classifier: 0.1567 (0.1690)  loss_box_reg: 0.1100 (0.1412)  loss_objectness: 0.1060 (0.1405)  loss_rpn_box_reg: 0.0258 (0.0655)  time: 0.2684  data: 0.1323  max mem: 1704\n",
      "Training Epoch: [1]  [1120/1229]  eta: 0:00:30  lr: 0.005000  loss: 0.3700 (0.5158)  loss_classifier: 0.1443 (0.1689)  loss_box_reg: 0.0972 (0.1411)  loss_objectness: 0.0944 (0.1404)  loss_rpn_box_reg: 0.0230 (0.0653)  time: 0.2733  data: 0.1331  max mem: 1704\n",
      "Training Epoch: [1]  [1130/1229]  eta: 0:00:27  lr: 0.005000  loss: 0.3586 (0.5153)  loss_classifier: 0.1270 (0.1688)  loss_box_reg: 0.1004 (0.1411)  loss_objectness: 0.0944 (0.1403)  loss_rpn_box_reg: 0.0267 (0.0651)  time: 0.2745  data: 0.1319  max mem: 1704\n",
      "Training Epoch: [1]  [1140/1229]  eta: 0:00:24  lr: 0.005000  loss: 0.3429 (0.5145)  loss_classifier: 0.1163 (0.1685)  loss_box_reg: 0.0829 (0.1408)  loss_objectness: 0.1024 (0.1403)  loss_rpn_box_reg: 0.0275 (0.0649)  time: 0.2702  data: 0.1318  max mem: 1704\n",
      "Training Epoch: [1]  [1150/1229]  eta: 0:00:21  lr: 0.005000  loss: 0.4062 (0.5147)  loss_classifier: 0.1399 (0.1686)  loss_box_reg: 0.1150 (0.1408)  loss_objectness: 0.1209 (0.1405)  loss_rpn_box_reg: 0.0395 (0.0648)  time: 0.2592  data: 0.1316  max mem: 1704\n",
      "Training Epoch: [1]  [1160/1229]  eta: 0:00:18  lr: 0.005000  loss: 0.4703 (0.5154)  loss_classifier: 0.1580 (0.1689)  loss_box_reg: 0.1263 (0.1411)  loss_objectness: 0.1302 (0.1407)  loss_rpn_box_reg: 0.0395 (0.0647)  time: 0.2604  data: 0.1314  max mem: 1704\n",
      "Training Epoch: [1]  [1170/1229]  eta: 0:00:16  lr: 0.005000  loss: 0.3806 (0.5141)  loss_classifier: 0.1401 (0.1686)  loss_box_reg: 0.0950 (0.1406)  loss_objectness: 0.1089 (0.1404)  loss_rpn_box_reg: 0.0242 (0.0645)  time: 0.2675  data: 0.1291  max mem: 1704\n",
      "Training Epoch: [1]  [1180/1229]  eta: 0:00:13  lr: 0.005000  loss: 0.4315 (0.5139)  loss_classifier: 0.1324 (0.1685)  loss_box_reg: 0.0950 (0.1407)  loss_objectness: 0.0991 (0.1402)  loss_rpn_box_reg: 0.0265 (0.0644)  time: 0.2705  data: 0.1286  max mem: 1704\n",
      "Training Epoch: [1]  [1190/1229]  eta: 0:00:10  lr: 0.005000  loss: 0.4315 (0.5130)  loss_classifier: 0.1417 (0.1683)  loss_box_reg: 0.1129 (0.1405)  loss_objectness: 0.1302 (0.1402)  loss_rpn_box_reg: 0.0239 (0.0640)  time: 0.2715  data: 0.1301  max mem: 1704\n",
      "Training Epoch: [1]  [1200/1229]  eta: 0:00:07  lr: 0.005000  loss: 0.3637 (0.5123)  loss_classifier: 0.1378 (0.1681)  loss_box_reg: 0.0833 (0.1403)  loss_objectness: 0.1369 (0.1401)  loss_rpn_box_reg: 0.0236 (0.0638)  time: 0.2745  data: 0.1326  max mem: 1704\n",
      "Training Epoch: [1]  [1210/1229]  eta: 0:00:05  lr: 0.005000  loss: 0.4311 (0.5119)  loss_classifier: 0.1378 (0.1679)  loss_box_reg: 0.1074 (0.1401)  loss_objectness: 0.1443 (0.1403)  loss_rpn_box_reg: 0.0281 (0.0637)  time: 0.2716  data: 0.1336  max mem: 1704\n",
      "Training Epoch: [1]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.5196 (0.5126)  loss_classifier: 0.1444 (0.1680)  loss_box_reg: 0.1096 (0.1402)  loss_objectness: 0.1371 (0.1405)  loss_rpn_box_reg: 0.0452 (0.0638)  time: 0.2679  data: 0.1301  max mem: 1704\n",
      "Training Epoch: [1]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4999 (0.5129)  loss_classifier: 0.1621 (0.1681)  loss_box_reg: 0.1259 (0.1403)  loss_objectness: 0.1371 (0.1408)  loss_rpn_box_reg: 0.0411 (0.0637)  time: 0.2633  data: 0.1293  max mem: 1704\n",
      "Training Epoch: [1] Total time: 0:05:37 (0.2750 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:45  model_time: 0.3090 (0.3090)  evaluator_time: 0.0020 (0.0020)  time: 0.3410  data: 0.0280  max mem: 1704\n",
      "Test:  [100/308]  eta: 0:00:25  model_time: 0.0730 (0.0787)  evaluator_time: 0.0040 (0.0075)  time: 0.1215  data: 0.0356  max mem: 1704\n",
      "Test:  [200/308]  eta: 0:00:12  model_time: 0.0800 (0.0776)  evaluator_time: 0.0030 (0.0066)  time: 0.1164  data: 0.0306  max mem: 1704\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0690 (0.0768)  evaluator_time: 0.0040 (0.0066)  time: 0.1152  data: 0.0350  max mem: 1704\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0690 (0.0766)  evaluator_time: 0.0030 (0.0066)  time: 0.1121  data: 0.0333  max mem: 1704\n",
      "Test: Total time: 0:00:36 (0.1192 s / it)\n",
      "Averaged stats: model_time: 0.0690 (0.0766)  evaluator_time: 0.0030 (0.0066)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.075\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.100\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.115\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.081\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.195\n",
      "Testing Epoch: [1]  [  0/308]  eta: 0:00:36  lr: 0.005000  loss: 0.1989 (0.1989)  loss_classifier: 0.0680 (0.0680)  loss_box_reg: 0.0584 (0.0584)  loss_objectness: 0.0627 (0.0627)  loss_rpn_box_reg: 0.0097 (0.0097)  time: 0.1200  data: 0.0270  max mem: 1704\n",
      "Testing Epoch: [1]  [100/308]  eta: 0:00:28  lr: 0.005000  loss: 0.3301 (0.5302)  loss_classifier: 0.1105 (0.1697)  loss_box_reg: 0.0992 (0.1648)  loss_objectness: 0.0978 (0.1243)  loss_rpn_box_reg: 0.0229 (0.0713)  time: 0.1378  data: 0.0371  max mem: 1704\n",
      "Testing Epoch: [1]  [200/308]  eta: 0:00:14  lr: 0.005000  loss: 0.4503 (0.5121)  loss_classifier: 0.1636 (0.1637)  loss_box_reg: 0.1562 (0.1593)  loss_objectness: 0.0848 (0.1194)  loss_rpn_box_reg: 0.0392 (0.0697)  time: 0.1415  data: 0.0371  max mem: 1704\n",
      "Testing Epoch: [1]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5595 (0.5144)  loss_classifier: 0.1862 (0.1652)  loss_box_reg: 0.1686 (0.1630)  loss_objectness: 0.1175 (0.1182)  loss_rpn_box_reg: 0.0440 (0.0680)  time: 0.1368  data: 0.0421  max mem: 1704\n",
      "Testing Epoch: [1]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.5595 (0.5136)  loss_classifier: 0.1826 (0.1654)  loss_box_reg: 0.1686 (0.1629)  loss_objectness: 0.1116 (0.1182)  loss_rpn_box_reg: 0.0394 (0.0672)  time: 0.1342  data: 0.0407  max mem: 1704\n",
      "Testing Epoch: [1] Total time: 0:00:41 (0.1359 s / it)\n",
      "Training Epoch: [2]  [   0/1229]  eta: 0:05:28  lr: 0.005000  loss: 0.1446 (0.1446)  loss_classifier: 0.0552 (0.0552)  loss_box_reg: 0.0391 (0.0391)  loss_objectness: 0.0463 (0.0463)  loss_rpn_box_reg: 0.0040 (0.0040)  time: 0.2670  data: 0.1240  max mem: 1704\n",
      "Training Epoch: [2]  [  10/1229]  eta: 0:05:23  lr: 0.005000  loss: 0.5634 (0.4735)  loss_classifier: 0.1776 (0.1600)  loss_box_reg: 0.1206 (0.1371)  loss_objectness: 0.1323 (0.1253)  loss_rpn_box_reg: 0.0411 (0.0512)  time: 0.2656  data: 0.1342  max mem: 1704\n",
      "Training Epoch: [2]  [  20/1229]  eta: 0:05:32  lr: 0.005000  loss: 0.5353 (0.5402)  loss_classifier: 0.1860 (0.1730)  loss_box_reg: 0.1206 (0.1438)  loss_objectness: 0.1323 (0.1432)  loss_rpn_box_reg: 0.0392 (0.0803)  time: 0.2755  data: 0.1353  max mem: 1704\n",
      "Training Epoch: [2]  [  30/1229]  eta: 0:05:31  lr: 0.005000  loss: 0.4987 (0.5260)  loss_classifier: 0.1758 (0.1668)  loss_box_reg: 0.1414 (0.1456)  loss_objectness: 0.0947 (0.1360)  loss_rpn_box_reg: 0.0392 (0.0776)  time: 0.2825  data: 0.1364  max mem: 1704\n",
      "Training Epoch: [2]  [  40/1229]  eta: 0:05:26  lr: 0.005000  loss: 0.5860 (0.5345)  loss_classifier: 0.1758 (0.1710)  loss_box_reg: 0.1588 (0.1579)  loss_objectness: 0.1073 (0.1373)  loss_rpn_box_reg: 0.0397 (0.0685)  time: 0.2749  data: 0.1360  max mem: 1704\n",
      "Training Epoch: [2]  [  50/1229]  eta: 0:05:24  lr: 0.005000  loss: 0.4394 (0.5180)  loss_classifier: 0.1671 (0.1697)  loss_box_reg: 0.1276 (0.1549)  loss_objectness: 0.1073 (0.1301)  loss_rpn_box_reg: 0.0411 (0.0632)  time: 0.2726  data: 0.1322  max mem: 1704\n",
      "Training Epoch: [2]  [  60/1229]  eta: 0:05:23  lr: 0.005000  loss: 0.3936 (0.5153)  loss_classifier: 0.1422 (0.1684)  loss_box_reg: 0.0996 (0.1484)  loss_objectness: 0.0950 (0.1352)  loss_rpn_box_reg: 0.0452 (0.0633)  time: 0.2791  data: 0.1331  max mem: 1704\n",
      "Training Epoch: [2]  [  70/1229]  eta: 0:05:18  lr: 0.005000  loss: 0.4800 (0.5261)  loss_classifier: 0.1631 (0.1728)  loss_box_reg: 0.1378 (0.1533)  loss_objectness: 0.1194 (0.1362)  loss_rpn_box_reg: 0.0472 (0.0638)  time: 0.2730  data: 0.1335  max mem: 1704\n",
      "Training Epoch: [2]  [  80/1229]  eta: 0:05:14  lr: 0.005000  loss: 0.5090 (0.5332)  loss_classifier: 0.1720 (0.1751)  loss_box_reg: 0.1664 (0.1590)  loss_objectness: 0.1194 (0.1362)  loss_rpn_box_reg: 0.0540 (0.0629)  time: 0.2652  data: 0.1324  max mem: 1704\n",
      "Training Epoch: [2]  [  90/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.5090 (0.5292)  loss_classifier: 0.1661 (0.1729)  loss_box_reg: 0.1434 (0.1567)  loss_objectness: 0.1178 (0.1361)  loss_rpn_box_reg: 0.0523 (0.0635)  time: 0.2665  data: 0.1345  max mem: 1704\n",
      "Training Epoch: [2]  [ 100/1229]  eta: 0:05:06  lr: 0.005000  loss: 0.5558 (0.5397)  loss_classifier: 0.1537 (0.1771)  loss_box_reg: 0.1409 (0.1582)  loss_objectness: 0.1322 (0.1373)  loss_rpn_box_reg: 0.0523 (0.0671)  time: 0.2624  data: 0.1354  max mem: 1704\n",
      "Training Epoch: [2]  [ 110/1229]  eta: 0:05:04  lr: 0.005000  loss: 0.5284 (0.5353)  loss_classifier: 0.1733 (0.1768)  loss_box_reg: 0.1426 (0.1593)  loss_objectness: 0.1327 (0.1353)  loss_rpn_box_reg: 0.0371 (0.0640)  time: 0.2682  data: 0.1348  max mem: 1704\n",
      "Training Epoch: [2]  [ 120/1229]  eta: 0:05:02  lr: 0.005000  loss: 0.4848 (0.5324)  loss_classifier: 0.1622 (0.1767)  loss_box_reg: 0.1143 (0.1578)  loss_objectness: 0.1063 (0.1363)  loss_rpn_box_reg: 0.0343 (0.0617)  time: 0.2800  data: 0.1332  max mem: 1704\n",
      "Training Epoch: [2]  [ 130/1229]  eta: 0:04:59  lr: 0.005000  loss: 0.3566 (0.5224)  loss_classifier: 0.1415 (0.1738)  loss_box_reg: 0.1075 (0.1536)  loss_objectness: 0.0860 (0.1340)  loss_rpn_box_reg: 0.0249 (0.0610)  time: 0.2752  data: 0.1323  max mem: 1704\n",
      "Training Epoch: [2]  [ 140/1229]  eta: 0:04:55  lr: 0.005000  loss: 0.4345 (0.5313)  loss_classifier: 0.1783 (0.1770)  loss_box_reg: 0.1311 (0.1581)  loss_objectness: 0.1096 (0.1346)  loss_rpn_box_reg: 0.0310 (0.0616)  time: 0.2637  data: 0.1313  max mem: 1704\n",
      "Training Epoch: [2]  [ 150/1229]  eta: 0:04:52  lr: 0.005000  loss: 0.4983 (0.5337)  loss_classifier: 0.1857 (0.1782)  loss_box_reg: 0.1401 (0.1581)  loss_objectness: 0.1362 (0.1364)  loss_rpn_box_reg: 0.0365 (0.0610)  time: 0.2616  data: 0.1328  max mem: 1704\n",
      "Training Epoch: [2]  [ 160/1229]  eta: 0:04:49  lr: 0.005000  loss: 0.4872 (0.5308)  loss_classifier: 0.1750 (0.1778)  loss_box_reg: 0.1401 (0.1581)  loss_objectness: 0.1334 (0.1356)  loss_rpn_box_reg: 0.0335 (0.0592)  time: 0.2645  data: 0.1323  max mem: 1704\n",
      "Training Epoch: [2]  [ 170/1229]  eta: 0:04:46  lr: 0.005000  loss: 0.4631 (0.5260)  loss_classifier: 0.1578 (0.1755)  loss_box_reg: 0.0997 (0.1551)  loss_objectness: 0.0979 (0.1354)  loss_rpn_box_reg: 0.0303 (0.0600)  time: 0.2652  data: 0.1310  max mem: 1704\n",
      "Training Epoch: [2]  [ 180/1229]  eta: 0:04:43  lr: 0.005000  loss: 0.4631 (0.5245)  loss_classifier: 0.1448 (0.1758)  loss_box_reg: 0.1012 (0.1561)  loss_objectness: 0.0943 (0.1339)  loss_rpn_box_reg: 0.0325 (0.0587)  time: 0.2689  data: 0.1293  max mem: 1704\n",
      "Training Epoch: [2]  [ 190/1229]  eta: 0:04:40  lr: 0.005000  loss: 0.5479 (0.5252)  loss_classifier: 0.1892 (0.1764)  loss_box_reg: 0.1351 (0.1545)  loss_objectness: 0.1253 (0.1355)  loss_rpn_box_reg: 0.0359 (0.0587)  time: 0.2702  data: 0.1301  max mem: 1704\n",
      "Training Epoch: [2]  [ 200/1229]  eta: 0:04:37  lr: 0.005000  loss: 0.5355 (0.5290)  loss_classifier: 0.1768 (0.1767)  loss_box_reg: 0.1221 (0.1554)  loss_objectness: 0.1362 (0.1377)  loss_rpn_box_reg: 0.0370 (0.0592)  time: 0.2672  data: 0.1323  max mem: 1704\n",
      "Training Epoch: [2]  [ 210/1229]  eta: 0:04:34  lr: 0.005000  loss: 0.4599 (0.5292)  loss_classifier: 0.1621 (0.1772)  loss_box_reg: 0.1492 (0.1556)  loss_objectness: 0.1285 (0.1377)  loss_rpn_box_reg: 0.0288 (0.0587)  time: 0.2643  data: 0.1320  max mem: 1704\n",
      "Training Epoch: [2]  [ 220/1229]  eta: 0:04:31  lr: 0.005000  loss: 0.5178 (0.5323)  loss_classifier: 0.1910 (0.1779)  loss_box_reg: 0.1492 (0.1570)  loss_objectness: 0.1255 (0.1371)  loss_rpn_box_reg: 0.0381 (0.0603)  time: 0.2622  data: 0.1337  max mem: 1704\n",
      "Training Epoch: [2]  [ 230/1229]  eta: 0:04:28  lr: 0.005000  loss: 0.5178 (0.5359)  loss_classifier: 0.1709 (0.1792)  loss_box_reg: 0.1376 (0.1577)  loss_objectness: 0.1233 (0.1377)  loss_rpn_box_reg: 0.0564 (0.0613)  time: 0.2614  data: 0.1331  max mem: 1704\n",
      "Training Epoch: [2]  [ 240/1229]  eta: 0:04:26  lr: 0.005000  loss: 0.4442 (0.5364)  loss_classifier: 0.1674 (0.1798)  loss_box_reg: 0.1376 (0.1590)  loss_objectness: 0.1210 (0.1371)  loss_rpn_box_reg: 0.0406 (0.0606)  time: 0.2689  data: 0.1327  max mem: 1704\n",
      "Training Epoch: [2]  [ 250/1229]  eta: 0:04:24  lr: 0.005000  loss: 0.5119 (0.5347)  loss_classifier: 0.1617 (0.1797)  loss_box_reg: 0.1237 (0.1586)  loss_objectness: 0.1096 (0.1362)  loss_rpn_box_reg: 0.0306 (0.0601)  time: 0.2800  data: 0.1337  max mem: 1704\n",
      "Training Epoch: [2]  [ 260/1229]  eta: 0:04:21  lr: 0.005000  loss: 0.4746 (0.5343)  loss_classifier: 0.1663 (0.1791)  loss_box_reg: 0.1364 (0.1582)  loss_objectness: 0.1145 (0.1365)  loss_rpn_box_reg: 0.0306 (0.0606)  time: 0.2749  data: 0.1330  max mem: 1704\n",
      "Training Epoch: [2]  [ 270/1229]  eta: 0:04:18  lr: 0.005000  loss: 0.4600 (0.5340)  loss_classifier: 0.1663 (0.1789)  loss_box_reg: 0.1373 (0.1585)  loss_objectness: 0.1145 (0.1362)  loss_rpn_box_reg: 0.0352 (0.0604)  time: 0.2724  data: 0.1334  max mem: 1704\n",
      "Training Epoch: [2]  [ 280/1229]  eta: 0:04:16  lr: 0.005000  loss: 0.4804 (0.5360)  loss_classifier: 0.1614 (0.1793)  loss_box_reg: 0.1373 (0.1597)  loss_objectness: 0.1146 (0.1358)  loss_rpn_box_reg: 0.0354 (0.0611)  time: 0.2728  data: 0.1344  max mem: 1704\n",
      "Training Epoch: [2]  [ 290/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.4599 (0.5387)  loss_classifier: 0.1190 (0.1799)  loss_box_reg: 0.1121 (0.1609)  loss_objectness: 0.1163 (0.1359)  loss_rpn_box_reg: 0.0493 (0.0620)  time: 0.2684  data: 0.1331  max mem: 1704\n",
      "Training Epoch: [2]  [ 300/1229]  eta: 0:04:10  lr: 0.005000  loss: 0.4188 (0.5365)  loss_classifier: 0.1196 (0.1795)  loss_box_reg: 0.1346 (0.1610)  loss_objectness: 0.0930 (0.1350)  loss_rpn_box_reg: 0.0332 (0.0611)  time: 0.2706  data: 0.1326  max mem: 1704\n",
      "Training Epoch: [2]  [ 310/1229]  eta: 0:04:08  lr: 0.005000  loss: 0.4030 (0.5390)  loss_classifier: 0.1454 (0.1795)  loss_box_reg: 0.1346 (0.1615)  loss_objectness: 0.1033 (0.1363)  loss_rpn_box_reg: 0.0332 (0.0617)  time: 0.2759  data: 0.1324  max mem: 1704\n",
      "Training Epoch: [2]  [ 320/1229]  eta: 0:04:05  lr: 0.005000  loss: 0.4155 (0.5399)  loss_classifier: 0.1592 (0.1802)  loss_box_reg: 0.1459 (0.1622)  loss_objectness: 0.1227 (0.1361)  loss_rpn_box_reg: 0.0334 (0.0613)  time: 0.2693  data: 0.1323  max mem: 1704\n",
      "Training Epoch: [2]  [ 330/1229]  eta: 0:04:02  lr: 0.005000  loss: 0.4628 (0.5393)  loss_classifier: 0.1592 (0.1802)  loss_box_reg: 0.1379 (0.1617)  loss_objectness: 0.1050 (0.1363)  loss_rpn_box_reg: 0.0334 (0.0612)  time: 0.2651  data: 0.1317  max mem: 1704\n",
      "Training Epoch: [2]  [ 340/1229]  eta: 0:04:00  lr: 0.005000  loss: 0.4010 (0.5326)  loss_classifier: 0.1354 (0.1781)  loss_box_reg: 0.0939 (0.1598)  loss_objectness: 0.1008 (0.1348)  loss_rpn_box_reg: 0.0226 (0.0599)  time: 0.2727  data: 0.1307  max mem: 1704\n",
      "Training Epoch: [2]  [ 350/1229]  eta: 0:03:57  lr: 0.005000  loss: 0.3045 (0.5301)  loss_classifier: 0.0982 (0.1771)  loss_box_reg: 0.0910 (0.1584)  loss_objectness: 0.0873 (0.1346)  loss_rpn_box_reg: 0.0173 (0.0600)  time: 0.2756  data: 0.1310  max mem: 1704\n",
      "Training Epoch: [2]  [ 360/1229]  eta: 0:03:55  lr: 0.005000  loss: 0.5039 (0.5312)  loss_classifier: 0.1576 (0.1778)  loss_box_reg: 0.1187 (0.1588)  loss_objectness: 0.1000 (0.1350)  loss_rpn_box_reg: 0.0328 (0.0595)  time: 0.2760  data: 0.1317  max mem: 1704\n",
      "Training Epoch: [2]  [ 370/1229]  eta: 0:03:52  lr: 0.005000  loss: 0.5271 (0.5309)  loss_classifier: 0.1927 (0.1780)  loss_box_reg: 0.1071 (0.1579)  loss_objectness: 0.1208 (0.1353)  loss_rpn_box_reg: 0.0398 (0.0596)  time: 0.2751  data: 0.1335  max mem: 1704\n",
      "Training Epoch: [2]  [ 380/1229]  eta: 0:03:49  lr: 0.005000  loss: 0.4511 (0.5303)  loss_classifier: 0.1470 (0.1776)  loss_box_reg: 0.0973 (0.1575)  loss_objectness: 0.1247 (0.1356)  loss_rpn_box_reg: 0.0356 (0.0595)  time: 0.2694  data: 0.1324  max mem: 1704\n",
      "Training Epoch: [2]  [ 390/1229]  eta: 0:03:46  lr: 0.005000  loss: 0.4657 (0.5300)  loss_classifier: 0.1573 (0.1778)  loss_box_reg: 0.1393 (0.1576)  loss_objectness: 0.1247 (0.1355)  loss_rpn_box_reg: 0.0306 (0.0591)  time: 0.2688  data: 0.1313  max mem: 1704\n",
      "Training Epoch: [2]  [ 400/1229]  eta: 0:03:44  lr: 0.005000  loss: 0.4902 (0.5301)  loss_classifier: 0.1608 (0.1776)  loss_box_reg: 0.1031 (0.1578)  loss_objectness: 0.1183 (0.1355)  loss_rpn_box_reg: 0.0329 (0.0593)  time: 0.2688  data: 0.1328  max mem: 1704\n",
      "Training Epoch: [2]  [ 410/1229]  eta: 0:03:41  lr: 0.005000  loss: 0.5066 (0.5325)  loss_classifier: 0.1608 (0.1783)  loss_box_reg: 0.1183 (0.1586)  loss_objectness: 0.1450 (0.1364)  loss_rpn_box_reg: 0.0357 (0.0591)  time: 0.2694  data: 0.1335  max mem: 1704\n",
      "Training Epoch: [2]  [ 420/1229]  eta: 0:03:38  lr: 0.005000  loss: 0.5104 (0.5337)  loss_classifier: 0.1787 (0.1792)  loss_box_reg: 0.1361 (0.1585)  loss_objectness: 0.1450 (0.1370)  loss_rpn_box_reg: 0.0329 (0.0590)  time: 0.2686  data: 0.1327  max mem: 1704\n",
      "Training Epoch: [2]  [ 430/1229]  eta: 0:03:35  lr: 0.005000  loss: 0.4990 (0.5357)  loss_classifier: 0.1787 (0.1800)  loss_box_reg: 0.1361 (0.1595)  loss_objectness: 0.1291 (0.1368)  loss_rpn_box_reg: 0.0412 (0.0594)  time: 0.2661  data: 0.1335  max mem: 1704\n",
      "Training Epoch: [2]  [ 440/1229]  eta: 0:03:33  lr: 0.005000  loss: 0.4969 (0.5357)  loss_classifier: 0.1543 (0.1799)  loss_box_reg: 0.1168 (0.1597)  loss_objectness: 0.1028 (0.1366)  loss_rpn_box_reg: 0.0388 (0.0596)  time: 0.2723  data: 0.1340  max mem: 1704\n",
      "Training Epoch: [2]  [ 450/1229]  eta: 0:03:30  lr: 0.005000  loss: 0.4480 (0.5357)  loss_classifier: 0.1565 (0.1801)  loss_box_reg: 0.1140 (0.1603)  loss_objectness: 0.0976 (0.1363)  loss_rpn_box_reg: 0.0255 (0.0591)  time: 0.2786  data: 0.1334  max mem: 1704\n",
      "Training Epoch: [2]  [ 460/1229]  eta: 0:03:27  lr: 0.005000  loss: 0.4210 (0.5335)  loss_classifier: 0.1510 (0.1795)  loss_box_reg: 0.1262 (0.1598)  loss_objectness: 0.0966 (0.1356)  loss_rpn_box_reg: 0.0235 (0.0586)  time: 0.2713  data: 0.1324  max mem: 1704\n",
      "Training Epoch: [2]  [ 470/1229]  eta: 0:03:25  lr: 0.005000  loss: 0.4305 (0.5325)  loss_classifier: 0.1510 (0.1793)  loss_box_reg: 0.1040 (0.1589)  loss_objectness: 0.0966 (0.1351)  loss_rpn_box_reg: 0.0186 (0.0591)  time: 0.2714  data: 0.1303  max mem: 1704\n",
      "Training Epoch: [2]  [ 480/1229]  eta: 0:03:22  lr: 0.005000  loss: 0.5223 (0.5336)  loss_classifier: 0.1809 (0.1796)  loss_box_reg: 0.1223 (0.1585)  loss_objectness: 0.1136 (0.1358)  loss_rpn_box_reg: 0.0622 (0.0597)  time: 0.2786  data: 0.1308  max mem: 1704\n",
      "Training Epoch: [2]  [ 490/1229]  eta: 0:03:19  lr: 0.005000  loss: 0.4535 (0.5327)  loss_classifier: 0.1409 (0.1793)  loss_box_reg: 0.1183 (0.1578)  loss_objectness: 0.1118 (0.1354)  loss_rpn_box_reg: 0.0524 (0.0601)  time: 0.2691  data: 0.1326  max mem: 1704\n",
      "Training Epoch: [2]  [ 500/1229]  eta: 0:03:17  lr: 0.005000  loss: 0.4715 (0.5309)  loss_classifier: 0.1477 (0.1787)  loss_box_reg: 0.1140 (0.1571)  loss_objectness: 0.1066 (0.1351)  loss_rpn_box_reg: 0.0306 (0.0600)  time: 0.2684  data: 0.1338  max mem: 1704\n",
      "Training Epoch: [2]  [ 510/1229]  eta: 0:03:14  lr: 0.005000  loss: 0.3658 (0.5290)  loss_classifier: 0.1287 (0.1780)  loss_box_reg: 0.1006 (0.1564)  loss_objectness: 0.1025 (0.1349)  loss_rpn_box_reg: 0.0347 (0.0596)  time: 0.2771  data: 0.1331  max mem: 1704\n",
      "Training Epoch: [2]  [ 520/1229]  eta: 0:03:11  lr: 0.005000  loss: 0.3887 (0.5291)  loss_classifier: 0.1287 (0.1783)  loss_box_reg: 0.1100 (0.1567)  loss_objectness: 0.1025 (0.1347)  loss_rpn_box_reg: 0.0324 (0.0593)  time: 0.2717  data: 0.1325  max mem: 1704\n",
      "Training Epoch: [2]  [ 530/1229]  eta: 0:03:09  lr: 0.005000  loss: 0.4270 (0.5303)  loss_classifier: 0.1553 (0.1790)  loss_box_reg: 0.1359 (0.1572)  loss_objectness: 0.0982 (0.1346)  loss_rpn_box_reg: 0.0255 (0.0595)  time: 0.2649  data: 0.1331  max mem: 1704\n",
      "Training Epoch: [2]  [ 540/1229]  eta: 0:03:06  lr: 0.005000  loss: 0.4612 (0.5314)  loss_classifier: 0.1656 (0.1794)  loss_box_reg: 0.1394 (0.1579)  loss_objectness: 0.1244 (0.1347)  loss_rpn_box_reg: 0.0350 (0.0594)  time: 0.2744  data: 0.1338  max mem: 1704\n",
      "Training Epoch: [2]  [ 550/1229]  eta: 0:03:03  lr: 0.005000  loss: 0.4768 (0.5296)  loss_classifier: 0.1720 (0.1788)  loss_box_reg: 0.1508 (0.1574)  loss_objectness: 0.1151 (0.1345)  loss_rpn_box_reg: 0.0350 (0.0589)  time: 0.2754  data: 0.1331  max mem: 1704\n",
      "Training Epoch: [2]  [ 560/1229]  eta: 0:03:01  lr: 0.005000  loss: 0.4592 (0.5294)  loss_classifier: 0.1390 (0.1787)  loss_box_reg: 0.1016 (0.1575)  loss_objectness: 0.1084 (0.1343)  loss_rpn_box_reg: 0.0324 (0.0589)  time: 0.2721  data: 0.1331  max mem: 1704\n",
      "Training Epoch: [2]  [ 570/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.4132 (0.5294)  loss_classifier: 0.1412 (0.1789)  loss_box_reg: 0.1121 (0.1574)  loss_objectness: 0.1291 (0.1346)  loss_rpn_box_reg: 0.0311 (0.0584)  time: 0.2722  data: 0.1334  max mem: 1704\n",
      "Training Epoch: [2]  [ 580/1229]  eta: 0:02:55  lr: 0.005000  loss: 0.3978 (0.5281)  loss_classifier: 0.1481 (0.1784)  loss_box_reg: 0.1182 (0.1569)  loss_objectness: 0.1122 (0.1341)  loss_rpn_box_reg: 0.0265 (0.0587)  time: 0.2749  data: 0.1320  max mem: 1704\n",
      "Training Epoch: [2]  [ 590/1229]  eta: 0:02:53  lr: 0.005000  loss: 0.3856 (0.5280)  loss_classifier: 0.1427 (0.1784)  loss_box_reg: 0.0989 (0.1573)  loss_objectness: 0.1096 (0.1339)  loss_rpn_box_reg: 0.0309 (0.0584)  time: 0.2757  data: 0.1344  max mem: 1704\n",
      "Training Epoch: [2]  [ 600/1229]  eta: 0:02:50  lr: 0.005000  loss: 0.3888 (0.5280)  loss_classifier: 0.1567 (0.1783)  loss_box_reg: 0.0992 (0.1574)  loss_objectness: 0.1196 (0.1340)  loss_rpn_box_reg: 0.0309 (0.0583)  time: 0.2691  data: 0.1359  max mem: 1704\n",
      "Training Epoch: [2]  [ 610/1229]  eta: 0:02:47  lr: 0.005000  loss: 0.4896 (0.5265)  loss_classifier: 0.1567 (0.1777)  loss_box_reg: 0.1193 (0.1568)  loss_objectness: 0.1196 (0.1339)  loss_rpn_box_reg: 0.0292 (0.0581)  time: 0.2725  data: 0.1329  max mem: 1704\n",
      "Training Epoch: [2]  [ 620/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.3246 (0.5247)  loss_classifier: 0.1160 (0.1767)  loss_box_reg: 0.1093 (0.1562)  loss_objectness: 0.1008 (0.1333)  loss_rpn_box_reg: 0.0292 (0.0585)  time: 0.2750  data: 0.1334  max mem: 1704\n",
      "Training Epoch: [2]  [ 630/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.4349 (0.5264)  loss_classifier: 0.1205 (0.1772)  loss_box_reg: 0.1036 (0.1566)  loss_objectness: 0.1051 (0.1338)  loss_rpn_box_reg: 0.0408 (0.0588)  time: 0.2749  data: 0.1333  max mem: 1704\n",
      "Training Epoch: [2]  [ 640/1229]  eta: 0:02:39  lr: 0.005000  loss: 0.4864 (0.5262)  loss_classifier: 0.1438 (0.1772)  loss_box_reg: 0.1138 (0.1564)  loss_objectness: 0.1203 (0.1339)  loss_rpn_box_reg: 0.0451 (0.0587)  time: 0.2762  data: 0.1304  max mem: 1704\n",
      "Training Epoch: [2]  [ 650/1229]  eta: 0:02:36  lr: 0.005000  loss: 0.4217 (0.5244)  loss_classifier: 0.1438 (0.1768)  loss_box_reg: 0.1322 (0.1563)  loss_objectness: 0.0961 (0.1332)  loss_rpn_box_reg: 0.0270 (0.0582)  time: 0.2686  data: 0.1308  max mem: 1704\n",
      "Training Epoch: [2]  [ 660/1229]  eta: 0:02:34  lr: 0.005000  loss: 0.3258 (0.5227)  loss_classifier: 0.1214 (0.1764)  loss_box_reg: 0.1038 (0.1559)  loss_objectness: 0.0769 (0.1324)  loss_rpn_box_reg: 0.0202 (0.0581)  time: 0.2669  data: 0.1300  max mem: 1704\n",
      "Training Epoch: [2]  [ 670/1229]  eta: 0:02:31  lr: 0.005000  loss: 0.3575 (0.5227)  loss_classifier: 0.1351 (0.1762)  loss_box_reg: 0.1044 (0.1560)  loss_objectness: 0.0753 (0.1323)  loss_rpn_box_reg: 0.0338 (0.0582)  time: 0.2719  data: 0.1302  max mem: 1704\n",
      "Training Epoch: [2]  [ 680/1229]  eta: 0:02:28  lr: 0.005000  loss: 0.3575 (0.5211)  loss_classifier: 0.1392 (0.1757)  loss_box_reg: 0.1106 (0.1554)  loss_objectness: 0.0999 (0.1321)  loss_rpn_box_reg: 0.0338 (0.0579)  time: 0.2682  data: 0.1312  max mem: 1704\n",
      "Training Epoch: [2]  [ 690/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.3866 (0.5213)  loss_classifier: 0.1403 (0.1756)  loss_box_reg: 0.1106 (0.1554)  loss_objectness: 0.1067 (0.1323)  loss_rpn_box_reg: 0.0377 (0.0580)  time: 0.2667  data: 0.1293  max mem: 1704\n",
      "Training Epoch: [2]  [ 700/1229]  eta: 0:02:23  lr: 0.005000  loss: 0.4212 (0.5207)  loss_classifier: 0.1404 (0.1753)  loss_box_reg: 0.1177 (0.1550)  loss_objectness: 0.1192 (0.1322)  loss_rpn_box_reg: 0.0249 (0.0582)  time: 0.2684  data: 0.1297  max mem: 1704\n",
      "Training Epoch: [2]  [ 710/1229]  eta: 0:02:20  lr: 0.005000  loss: 0.3784 (0.5198)  loss_classifier: 0.1223 (0.1748)  loss_box_reg: 0.0925 (0.1545)  loss_objectness: 0.1355 (0.1323)  loss_rpn_box_reg: 0.0240 (0.0582)  time: 0.2698  data: 0.1320  max mem: 1704\n",
      "Training Epoch: [2]  [ 720/1229]  eta: 0:02:17  lr: 0.005000  loss: 0.4150 (0.5202)  loss_classifier: 0.1447 (0.1747)  loss_box_reg: 0.0942 (0.1543)  loss_objectness: 0.1239 (0.1325)  loss_rpn_box_reg: 0.0312 (0.0586)  time: 0.2741  data: 0.1336  max mem: 1704\n",
      "Training Epoch: [2]  [ 730/1229]  eta: 0:02:15  lr: 0.005000  loss: 0.5152 (0.5203)  loss_classifier: 0.1516 (0.1747)  loss_box_reg: 0.1454 (0.1541)  loss_objectness: 0.1313 (0.1330)  loss_rpn_box_reg: 0.0397 (0.0584)  time: 0.2720  data: 0.1332  max mem: 1704\n",
      "Training Epoch: [2]  [ 740/1229]  eta: 0:02:12  lr: 0.005000  loss: 0.4088 (0.5185)  loss_classifier: 0.1216 (0.1741)  loss_box_reg: 0.0958 (0.1536)  loss_objectness: 0.1300 (0.1325)  loss_rpn_box_reg: 0.0319 (0.0583)  time: 0.2667  data: 0.1316  max mem: 1704\n",
      "Training Epoch: [2]  [ 750/1229]  eta: 0:02:09  lr: 0.005000  loss: 0.3079 (0.5178)  loss_classifier: 0.1030 (0.1737)  loss_box_reg: 0.0918 (0.1533)  loss_objectness: 0.0837 (0.1323)  loss_rpn_box_reg: 0.0240 (0.0585)  time: 0.2705  data: 0.1304  max mem: 1704\n",
      "Training Epoch: [2]  [ 760/1229]  eta: 0:02:07  lr: 0.005000  loss: 0.3842 (0.5173)  loss_classifier: 0.1405 (0.1737)  loss_box_reg: 0.1066 (0.1531)  loss_objectness: 0.0973 (0.1323)  loss_rpn_box_reg: 0.0309 (0.0582)  time: 0.2739  data: 0.1310  max mem: 1704\n",
      "Training Epoch: [2]  [ 770/1229]  eta: 0:02:04  lr: 0.005000  loss: 0.5072 (0.5168)  loss_classifier: 0.1431 (0.1734)  loss_box_reg: 0.1101 (0.1529)  loss_objectness: 0.1171 (0.1322)  loss_rpn_box_reg: 0.0318 (0.0583)  time: 0.2704  data: 0.1333  max mem: 1704\n",
      "Training Epoch: [2]  [ 780/1229]  eta: 0:02:01  lr: 0.005000  loss: 0.3504 (0.5142)  loss_classifier: 0.1049 (0.1726)  loss_box_reg: 0.0978 (0.1520)  loss_objectness: 0.0962 (0.1317)  loss_rpn_box_reg: 0.0259 (0.0579)  time: 0.2723  data: 0.1337  max mem: 1704\n",
      "Training Epoch: [2]  [ 790/1229]  eta: 0:01:58  lr: 0.005000  loss: 0.4402 (0.5158)  loss_classifier: 0.1181 (0.1730)  loss_box_reg: 0.1053 (0.1526)  loss_objectness: 0.0906 (0.1319)  loss_rpn_box_reg: 0.0309 (0.0582)  time: 0.2732  data: 0.1323  max mem: 1704\n",
      "Training Epoch: [2]  [ 800/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.5911 (0.5160)  loss_classifier: 0.1989 (0.1734)  loss_box_reg: 0.1578 (0.1530)  loss_objectness: 0.1464 (0.1319)  loss_rpn_box_reg: 0.0324 (0.0578)  time: 0.2772  data: 0.1325  max mem: 1704\n",
      "Training Epoch: [2]  [ 810/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.4291 (0.5159)  loss_classifier: 0.1652 (0.1733)  loss_box_reg: 0.1283 (0.1530)  loss_objectness: 0.1173 (0.1320)  loss_rpn_box_reg: 0.0239 (0.0576)  time: 0.2724  data: 0.1319  max mem: 1704\n",
      "Training Epoch: [2]  [ 820/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.4439 (0.5162)  loss_classifier: 0.1652 (0.1734)  loss_box_reg: 0.1031 (0.1531)  loss_objectness: 0.1051 (0.1323)  loss_rpn_box_reg: 0.0263 (0.0575)  time: 0.2642  data: 0.1317  max mem: 1704\n",
      "Training Epoch: [2]  [ 830/1229]  eta: 0:01:48  lr: 0.005000  loss: 0.4913 (0.5167)  loss_classifier: 0.1853 (0.1735)  loss_box_reg: 0.1473 (0.1531)  loss_objectness: 0.1304 (0.1327)  loss_rpn_box_reg: 0.0326 (0.0575)  time: 0.2688  data: 0.1327  max mem: 1704\n",
      "Training Epoch: [2]  [ 840/1229]  eta: 0:01:45  lr: 0.005000  loss: 0.4886 (0.5162)  loss_classifier: 0.1693 (0.1733)  loss_box_reg: 0.1335 (0.1527)  loss_objectness: 0.1145 (0.1327)  loss_rpn_box_reg: 0.0422 (0.0574)  time: 0.2767  data: 0.1347  max mem: 1704\n",
      "Training Epoch: [2]  [ 850/1229]  eta: 0:01:42  lr: 0.005000  loss: 0.4574 (0.5148)  loss_classifier: 0.1630 (0.1730)  loss_box_reg: 0.1198 (0.1526)  loss_objectness: 0.0931 (0.1321)  loss_rpn_box_reg: 0.0232 (0.0571)  time: 0.2823  data: 0.1344  max mem: 1704\n",
      "Training Epoch: [2]  [ 860/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.4401 (0.5144)  loss_classifier: 0.1630 (0.1730)  loss_box_reg: 0.1198 (0.1522)  loss_objectness: 0.0838 (0.1322)  loss_rpn_box_reg: 0.0232 (0.0570)  time: 0.2733  data: 0.1309  max mem: 1704\n",
      "Training Epoch: [2]  [ 870/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.4446 (0.5134)  loss_classifier: 0.1625 (0.1728)  loss_box_reg: 0.1216 (0.1521)  loss_objectness: 0.0838 (0.1317)  loss_rpn_box_reg: 0.0331 (0.0568)  time: 0.2688  data: 0.1318  max mem: 1704\n",
      "Training Epoch: [2]  [ 880/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.4892 (0.5155)  loss_classifier: 0.1625 (0.1734)  loss_box_reg: 0.1461 (0.1528)  loss_objectness: 0.1057 (0.1322)  loss_rpn_box_reg: 0.0351 (0.0571)  time: 0.2713  data: 0.1325  max mem: 1704\n",
      "Training Epoch: [2]  [ 890/1229]  eta: 0:01:31  lr: 0.005000  loss: 0.5800 (0.5164)  loss_classifier: 0.1852 (0.1738)  loss_box_reg: 0.1158 (0.1529)  loss_objectness: 0.1362 (0.1322)  loss_rpn_box_reg: 0.0359 (0.0574)  time: 0.2713  data: 0.1322  max mem: 1704\n",
      "Training Epoch: [2]  [ 900/1229]  eta: 0:01:29  lr: 0.005000  loss: 0.5174 (0.5167)  loss_classifier: 0.1656 (0.1739)  loss_box_reg: 0.1270 (0.1532)  loss_objectness: 0.1271 (0.1321)  loss_rpn_box_reg: 0.0356 (0.0576)  time: 0.2708  data: 0.1340  max mem: 1704\n",
      "Training Epoch: [2]  [ 910/1229]  eta: 0:01:26  lr: 0.005000  loss: 0.4439 (0.5161)  loss_classifier: 0.1393 (0.1735)  loss_box_reg: 0.1318 (0.1529)  loss_objectness: 0.1187 (0.1321)  loss_rpn_box_reg: 0.0360 (0.0576)  time: 0.2690  data: 0.1337  max mem: 1704\n",
      "Training Epoch: [2]  [ 920/1229]  eta: 0:01:23  lr: 0.005000  loss: 0.3808 (0.5151)  loss_classifier: 0.1322 (0.1729)  loss_box_reg: 0.1080 (0.1523)  loss_objectness: 0.1176 (0.1320)  loss_rpn_box_reg: 0.0348 (0.0578)  time: 0.2705  data: 0.1315  max mem: 1704\n",
      "Training Epoch: [2]  [ 930/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.4005 (0.5150)  loss_classifier: 0.1393 (0.1730)  loss_box_reg: 0.0936 (0.1523)  loss_objectness: 0.1146 (0.1321)  loss_rpn_box_reg: 0.0315 (0.0577)  time: 0.2703  data: 0.1340  max mem: 1704\n",
      "Training Epoch: [2]  [ 940/1229]  eta: 0:01:18  lr: 0.005000  loss: 0.4403 (0.5149)  loss_classifier: 0.1635 (0.1730)  loss_box_reg: 0.1444 (0.1526)  loss_objectness: 0.0939 (0.1317)  loss_rpn_box_reg: 0.0315 (0.0576)  time: 0.2694  data: 0.1354  max mem: 1704\n",
      "Training Epoch: [2]  [ 950/1229]  eta: 0:01:15  lr: 0.005000  loss: 0.4465 (0.5139)  loss_classifier: 0.1633 (0.1727)  loss_box_reg: 0.1613 (0.1524)  loss_objectness: 0.0876 (0.1314)  loss_rpn_box_reg: 0.0309 (0.0574)  time: 0.2759  data: 0.1336  max mem: 1704\n",
      "Training Epoch: [2]  [ 960/1229]  eta: 0:01:12  lr: 0.005000  loss: 0.4034 (0.5129)  loss_classifier: 0.1534 (0.1726)  loss_box_reg: 0.1082 (0.1521)  loss_objectness: 0.1016 (0.1311)  loss_rpn_box_reg: 0.0236 (0.0571)  time: 0.2780  data: 0.1338  max mem: 1704\n",
      "Training Epoch: [2]  [ 970/1229]  eta: 0:01:10  lr: 0.005000  loss: 0.4008 (0.5119)  loss_classifier: 0.1276 (0.1722)  loss_box_reg: 0.1082 (0.1518)  loss_objectness: 0.1016 (0.1307)  loss_rpn_box_reg: 0.0168 (0.0572)  time: 0.2744  data: 0.1323  max mem: 1704\n",
      "Training Epoch: [2]  [ 980/1229]  eta: 0:01:07  lr: 0.005000  loss: 0.5007 (0.5113)  loss_classifier: 0.1035 (0.1720)  loss_box_reg: 0.1244 (0.1515)  loss_objectness: 0.1067 (0.1309)  loss_rpn_box_reg: 0.0254 (0.0570)  time: 0.2747  data: 0.1324  max mem: 1704\n",
      "Training Epoch: [2]  [ 990/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.5052 (0.5118)  loss_classifier: 0.1476 (0.1724)  loss_box_reg: 0.1244 (0.1518)  loss_objectness: 0.1053 (0.1307)  loss_rpn_box_reg: 0.0312 (0.0570)  time: 0.2682  data: 0.1330  max mem: 1704\n",
      "Training Epoch: [2]  [1000/1229]  eta: 0:01:02  lr: 0.005000  loss: 0.3780 (0.5108)  loss_classifier: 0.1361 (0.1720)  loss_box_reg: 0.0972 (0.1514)  loss_objectness: 0.1147 (0.1307)  loss_rpn_box_reg: 0.0244 (0.0566)  time: 0.2661  data: 0.1337  max mem: 1704\n",
      "Training Epoch: [2]  [1010/1229]  eta: 0:00:59  lr: 0.005000  loss: 0.4047 (0.5113)  loss_classifier: 0.1361 (0.1721)  loss_box_reg: 0.0967 (0.1514)  loss_objectness: 0.1226 (0.1310)  loss_rpn_box_reg: 0.0248 (0.0568)  time: 0.2687  data: 0.1339  max mem: 1704\n",
      "Training Epoch: [2]  [1020/1229]  eta: 0:00:56  lr: 0.005000  loss: 0.4420 (0.5110)  loss_classifier: 0.1692 (0.1721)  loss_box_reg: 0.1377 (0.1514)  loss_objectness: 0.1125 (0.1307)  loss_rpn_box_reg: 0.0419 (0.0568)  time: 0.2677  data: 0.1328  max mem: 1704\n",
      "Training Epoch: [2]  [1030/1229]  eta: 0:00:53  lr: 0.005000  loss: 0.4189 (0.5105)  loss_classifier: 0.1484 (0.1720)  loss_box_reg: 0.1233 (0.1511)  loss_objectness: 0.1104 (0.1307)  loss_rpn_box_reg: 0.0317 (0.0568)  time: 0.2707  data: 0.1324  max mem: 1704\n",
      "Training Epoch: [2]  [1040/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.4097 (0.5101)  loss_classifier: 0.1475 (0.1719)  loss_box_reg: 0.0866 (0.1509)  loss_objectness: 0.1104 (0.1306)  loss_rpn_box_reg: 0.0317 (0.0567)  time: 0.2713  data: 0.1326  max mem: 1704\n",
      "Training Epoch: [2]  [1050/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.4589 (0.5104)  loss_classifier: 0.1614 (0.1720)  loss_box_reg: 0.1296 (0.1509)  loss_objectness: 0.1257 (0.1308)  loss_rpn_box_reg: 0.0354 (0.0567)  time: 0.2766  data: 0.1316  max mem: 1704\n",
      "Training Epoch: [2]  [1060/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.4399 (0.5096)  loss_classifier: 0.1348 (0.1717)  loss_box_reg: 0.1223 (0.1506)  loss_objectness: 0.1267 (0.1308)  loss_rpn_box_reg: 0.0335 (0.0565)  time: 0.2772  data: 0.1305  max mem: 1704\n",
      "Training Epoch: [2]  [1070/1229]  eta: 0:00:43  lr: 0.005000  loss: 0.4088 (0.5091)  loss_classifier: 0.1170 (0.1714)  loss_box_reg: 0.0905 (0.1504)  loss_objectness: 0.0986 (0.1306)  loss_rpn_box_reg: 0.0241 (0.0567)  time: 0.2694  data: 0.1315  max mem: 1704\n",
      "Training Epoch: [2]  [1080/1229]  eta: 0:00:40  lr: 0.005000  loss: 0.2959 (0.5080)  loss_classifier: 0.1066 (0.1710)  loss_box_reg: 0.0837 (0.1498)  loss_objectness: 0.0851 (0.1303)  loss_rpn_box_reg: 0.0271 (0.0568)  time: 0.2749  data: 0.1341  max mem: 1704\n",
      "Training Epoch: [2]  [1090/1229]  eta: 0:00:37  lr: 0.005000  loss: 0.4065 (0.5101)  loss_classifier: 0.1301 (0.1716)  loss_box_reg: 0.0920 (0.1504)  loss_objectness: 0.1214 (0.1309)  loss_rpn_box_reg: 0.0319 (0.0572)  time: 0.2763  data: 0.1347  max mem: 1704\n",
      "Training Epoch: [2]  [1100/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4184 (0.5093)  loss_classifier: 0.1406 (0.1713)  loss_box_reg: 0.1265 (0.1500)  loss_objectness: 0.1379 (0.1307)  loss_rpn_box_reg: 0.0314 (0.0572)  time: 0.2715  data: 0.1334  max mem: 1704\n",
      "Training Epoch: [2]  [1110/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.3909 (0.5084)  loss_classifier: 0.1138 (0.1707)  loss_box_reg: 0.1017 (0.1497)  loss_objectness: 0.0897 (0.1305)  loss_rpn_box_reg: 0.0314 (0.0574)  time: 0.2750  data: 0.1333  max mem: 1704\n",
      "Training Epoch: [2]  [1120/1229]  eta: 0:00:29  lr: 0.005000  loss: 0.3361 (0.5068)  loss_classifier: 0.0933 (0.1702)  loss_box_reg: 0.0780 (0.1491)  loss_objectness: 0.0959 (0.1303)  loss_rpn_box_reg: 0.0393 (0.0572)  time: 0.2807  data: 0.1325  max mem: 1704\n",
      "Training Epoch: [2]  [1130/1229]  eta: 0:00:26  lr: 0.005000  loss: 0.4658 (0.5086)  loss_classifier: 0.1512 (0.1709)  loss_box_reg: 0.1163 (0.1498)  loss_objectness: 0.1183 (0.1306)  loss_rpn_box_reg: 0.0393 (0.0572)  time: 0.2774  data: 0.1334  max mem: 1704\n",
      "Training Epoch: [2]  [1140/1229]  eta: 0:00:24  lr: 0.005000  loss: 0.5952 (0.5087)  loss_classifier: 0.2112 (0.1709)  loss_box_reg: 0.1719 (0.1498)  loss_objectness: 0.1349 (0.1306)  loss_rpn_box_reg: 0.0273 (0.0573)  time: 0.2736  data: 0.1334  max mem: 1704\n",
      "Training Epoch: [2]  [1150/1229]  eta: 0:00:21  lr: 0.005000  loss: 0.4517 (0.5093)  loss_classifier: 0.1554 (0.1712)  loss_box_reg: 0.0944 (0.1498)  loss_objectness: 0.1308 (0.1308)  loss_rpn_box_reg: 0.0237 (0.0575)  time: 0.2730  data: 0.1333  max mem: 1704\n",
      "Training Epoch: [2]  [1160/1229]  eta: 0:00:18  lr: 0.005000  loss: 0.5688 (0.5097)  loss_classifier: 0.1770 (0.1711)  loss_box_reg: 0.1029 (0.1496)  loss_objectness: 0.1224 (0.1310)  loss_rpn_box_reg: 0.0689 (0.0579)  time: 0.2677  data: 0.1344  max mem: 1704\n",
      "Training Epoch: [2]  [1170/1229]  eta: 0:00:16  lr: 0.005000  loss: 0.5656 (0.5105)  loss_classifier: 0.1625 (0.1714)  loss_box_reg: 0.1029 (0.1498)  loss_objectness: 0.1309 (0.1316)  loss_rpn_box_reg: 0.0461 (0.0577)  time: 0.2668  data: 0.1333  max mem: 1704\n",
      "Training Epoch: [2]  [1180/1229]  eta: 0:00:13  lr: 0.005000  loss: 0.4505 (0.5107)  loss_classifier: 0.1488 (0.1715)  loss_box_reg: 0.1472 (0.1499)  loss_objectness: 0.1319 (0.1316)  loss_rpn_box_reg: 0.0411 (0.0577)  time: 0.2667  data: 0.1308  max mem: 1704\n",
      "Training Epoch: [2]  [1190/1229]  eta: 0:00:10  lr: 0.005000  loss: 0.4343 (0.5099)  loss_classifier: 0.1466 (0.1713)  loss_box_reg: 0.1097 (0.1496)  loss_objectness: 0.1190 (0.1314)  loss_rpn_box_reg: 0.0430 (0.0575)  time: 0.2664  data: 0.1309  max mem: 1704\n",
      "Training Epoch: [2]  [1200/1229]  eta: 0:00:07  lr: 0.005000  loss: 0.3190 (0.5087)  loss_classifier: 0.1158 (0.1709)  loss_box_reg: 0.1079 (0.1493)  loss_objectness: 0.0777 (0.1311)  loss_rpn_box_reg: 0.0293 (0.0573)  time: 0.2686  data: 0.1325  max mem: 1704\n",
      "Training Epoch: [2]  [1210/1229]  eta: 0:00:05  lr: 0.005000  loss: 0.3946 (0.5090)  loss_classifier: 0.1353 (0.1709)  loss_box_reg: 0.1093 (0.1493)  loss_objectness: 0.0963 (0.1313)  loss_rpn_box_reg: 0.0351 (0.0575)  time: 0.2692  data: 0.1321  max mem: 1704\n",
      "Training Epoch: [2]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.5614 (0.5097)  loss_classifier: 0.1558 (0.1711)  loss_box_reg: 0.1285 (0.1494)  loss_objectness: 0.1365 (0.1318)  loss_rpn_box_reg: 0.0459 (0.0575)  time: 0.2718  data: 0.1329  max mem: 1704\n",
      "Training Epoch: [2]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4669 (0.5092)  loss_classifier: 0.1576 (0.1709)  loss_box_reg: 0.1375 (0.1492)  loss_objectness: 0.1312 (0.1317)  loss_rpn_box_reg: 0.0325 (0.0573)  time: 0.2762  data: 0.1345  max mem: 1704\n",
      "Training Epoch: [2] Total time: 0:05:33 (0.2715 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:56  model_time: 0.3440 (0.3440)  evaluator_time: 0.0030 (0.0030)  time: 0.3780  data: 0.0290  max mem: 1704\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0750 (0.0812)  evaluator_time: 0.0100 (0.0107)  time: 0.1270  data: 0.0353  max mem: 1704\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0820 (0.0801)  evaluator_time: 0.0040 (0.0099)  time: 0.1222  data: 0.0306  max mem: 1704\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0710 (0.0792)  evaluator_time: 0.0080 (0.0097)  time: 0.1203  data: 0.0349  max mem: 1704\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0720 (0.0791)  evaluator_time: 0.0030 (0.0096)  time: 0.1165  data: 0.0333  max mem: 1704\n",
      "Test: Total time: 0:00:38 (0.1248 s / it)\n",
      "Averaged stats: model_time: 0.0720 (0.0791)  evaluator_time: 0.0030 (0.0096)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.20s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.052\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.039\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.092\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.104\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.092\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      "Testing Epoch: [2]  [  0/308]  eta: 0:00:37  lr: 0.005000  loss: 0.2018 (0.2018)  loss_classifier: 0.0756 (0.0756)  loss_box_reg: 0.0617 (0.0617)  loss_objectness: 0.0501 (0.0501)  loss_rpn_box_reg: 0.0143 (0.0143)  time: 0.1230  data: 0.0290  max mem: 1704\n",
      "Testing Epoch: [2]  [100/308]  eta: 0:00:28  lr: 0.005000  loss: 0.3536 (0.5332)  loss_classifier: 0.1473 (0.1705)  loss_box_reg: 0.1178 (0.1681)  loss_objectness: 0.0828 (0.1214)  loss_rpn_box_reg: 0.0190 (0.0731)  time: 0.1386  data: 0.0377  max mem: 1709\n",
      "Testing Epoch: [2]  [200/308]  eta: 0:00:14  lr: 0.005000  loss: 0.3897 (0.5094)  loss_classifier: 0.1426 (0.1638)  loss_box_reg: 0.1218 (0.1598)  loss_objectness: 0.0971 (0.1157)  loss_rpn_box_reg: 0.0247 (0.0700)  time: 0.1376  data: 0.0321  max mem: 1709\n",
      "Testing Epoch: [2]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5336 (0.5108)  loss_classifier: 0.1757 (0.1645)  loss_box_reg: 0.1584 (0.1630)  loss_objectness: 0.1135 (0.1146)  loss_rpn_box_reg: 0.0323 (0.0687)  time: 0.1326  data: 0.0369  max mem: 1709\n",
      "Testing Epoch: [2]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.5336 (0.5100)  loss_classifier: 0.1763 (0.1644)  loss_box_reg: 0.1620 (0.1631)  loss_objectness: 0.1043 (0.1146)  loss_rpn_box_reg: 0.0319 (0.0679)  time: 0.1309  data: 0.0355  max mem: 1709\n",
      "Testing Epoch: [2] Total time: 0:00:41 (0.1364 s / it)\n",
      "Training Epoch: [3]  [   0/1229]  eta: 0:06:09  lr: 0.005000  loss: 0.2440 (0.2440)  loss_classifier: 0.1136 (0.1136)  loss_box_reg: 0.0687 (0.0687)  loss_objectness: 0.0500 (0.0500)  loss_rpn_box_reg: 0.0116 (0.0116)  time: 0.3010  data: 0.1270  max mem: 1709\n",
      "Training Epoch: [3]  [  10/1229]  eta: 0:05:41  lr: 0.005000  loss: 0.4824 (0.5118)  loss_classifier: 0.1661 (0.1708)  loss_box_reg: 0.1149 (0.1437)  loss_objectness: 0.1490 (0.1391)  loss_rpn_box_reg: 0.0282 (0.0582)  time: 0.2802  data: 0.1296  max mem: 1709\n",
      "Training Epoch: [3]  [  20/1229]  eta: 0:05:33  lr: 0.005000  loss: 0.4608 (0.4835)  loss_classifier: 0.1661 (0.1654)  loss_box_reg: 0.1259 (0.1407)  loss_objectness: 0.0811 (0.1198)  loss_rpn_box_reg: 0.0395 (0.0576)  time: 0.2744  data: 0.1317  max mem: 1709\n",
      "Training Epoch: [3]  [  30/1229]  eta: 0:05:27  lr: 0.005000  loss: 0.4818 (0.5020)  loss_classifier: 0.1599 (0.1709)  loss_box_reg: 0.1361 (0.1477)  loss_objectness: 0.0811 (0.1213)  loss_rpn_box_reg: 0.0405 (0.0620)  time: 0.2688  data: 0.1332  max mem: 1709\n",
      "Training Epoch: [3]  [  40/1229]  eta: 0:05:23  lr: 0.005000  loss: 0.4405 (0.4850)  loss_classifier: 0.1532 (0.1645)  loss_box_reg: 0.1313 (0.1407)  loss_objectness: 0.1012 (0.1186)  loss_rpn_box_reg: 0.0401 (0.0612)  time: 0.2685  data: 0.1319  max mem: 1709\n",
      "Training Epoch: [3]  [  50/1229]  eta: 0:05:21  lr: 0.005000  loss: 0.4008 (0.4811)  loss_classifier: 0.1396 (0.1603)  loss_box_reg: 0.1018 (0.1392)  loss_objectness: 0.1012 (0.1214)  loss_rpn_box_reg: 0.0207 (0.0602)  time: 0.2719  data: 0.1305  max mem: 1709\n",
      "Training Epoch: [3]  [  60/1229]  eta: 0:05:16  lr: 0.005000  loss: 0.4652 (0.4955)  loss_classifier: 0.1534 (0.1661)  loss_box_reg: 0.1606 (0.1478)  loss_objectness: 0.1314 (0.1243)  loss_rpn_box_reg: 0.0215 (0.0573)  time: 0.2683  data: 0.1334  max mem: 1709\n",
      "Training Epoch: [3]  [  70/1229]  eta: 0:05:15  lr: 0.005000  loss: 0.4904 (0.4898)  loss_classifier: 0.1844 (0.1660)  loss_box_reg: 0.1504 (0.1477)  loss_objectness: 0.1187 (0.1225)  loss_rpn_box_reg: 0.0320 (0.0536)  time: 0.2711  data: 0.1362  max mem: 1709\n",
      "Training Epoch: [3]  [  80/1229]  eta: 0:05:13  lr: 0.005000  loss: 0.4096 (0.4942)  loss_classifier: 0.1425 (0.1685)  loss_box_reg: 0.1196 (0.1507)  loss_objectness: 0.1000 (0.1225)  loss_rpn_box_reg: 0.0285 (0.0525)  time: 0.2800  data: 0.1350  max mem: 1709\n",
      "Training Epoch: [3]  [  90/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.3962 (0.4914)  loss_classifier: 0.1296 (0.1682)  loss_box_reg: 0.1139 (0.1505)  loss_objectness: 0.0806 (0.1209)  loss_rpn_box_reg: 0.0286 (0.0518)  time: 0.2757  data: 0.1335  max mem: 1709\n",
      "Training Epoch: [3]  [ 100/1229]  eta: 0:05:08  lr: 0.005000  loss: 0.3962 (0.4837)  loss_classifier: 0.1263 (0.1642)  loss_box_reg: 0.1097 (0.1479)  loss_objectness: 0.0806 (0.1193)  loss_rpn_box_reg: 0.0212 (0.0524)  time: 0.2753  data: 0.1329  max mem: 1709\n",
      "Training Epoch: [3]  [ 110/1229]  eta: 0:05:06  lr: 0.005000  loss: 0.3323 (0.4817)  loss_classifier: 0.1263 (0.1626)  loss_box_reg: 0.0992 (0.1465)  loss_objectness: 0.0918 (0.1202)  loss_rpn_box_reg: 0.0156 (0.0523)  time: 0.2762  data: 0.1342  max mem: 1709\n",
      "Training Epoch: [3]  [ 120/1229]  eta: 0:05:02  lr: 0.005000  loss: 0.4261 (0.4882)  loss_classifier: 0.1400 (0.1656)  loss_box_reg: 0.1364 (0.1490)  loss_objectness: 0.1306 (0.1231)  loss_rpn_box_reg: 0.0277 (0.0506)  time: 0.2703  data: 0.1353  max mem: 1709\n",
      "Training Epoch: [3]  [ 130/1229]  eta: 0:04:59  lr: 0.005000  loss: 0.4136 (0.4813)  loss_classifier: 0.1400 (0.1633)  loss_box_reg: 0.1213 (0.1468)  loss_objectness: 0.1105 (0.1213)  loss_rpn_box_reg: 0.0277 (0.0498)  time: 0.2672  data: 0.1326  max mem: 1709\n",
      "Training Epoch: [3]  [ 140/1229]  eta: 0:04:56  lr: 0.005000  loss: 0.4907 (0.4930)  loss_classifier: 0.1658 (0.1668)  loss_box_reg: 0.1213 (0.1515)  loss_objectness: 0.1130 (0.1235)  loss_rpn_box_reg: 0.0410 (0.0512)  time: 0.2680  data: 0.1321  max mem: 1709\n",
      "Training Epoch: [3]  [ 150/1229]  eta: 0:04:54  lr: 0.005000  loss: 0.5215 (0.4896)  loss_classifier: 0.1825 (0.1665)  loss_box_reg: 0.1523 (0.1509)  loss_objectness: 0.1130 (0.1224)  loss_rpn_box_reg: 0.0291 (0.0498)  time: 0.2728  data: 0.1329  max mem: 1709\n",
      "Training Epoch: [3]  [ 160/1229]  eta: 0:04:51  lr: 0.005000  loss: 0.3464 (0.4881)  loss_classifier: 0.1311 (0.1667)  loss_box_reg: 0.0912 (0.1494)  loss_objectness: 0.0998 (0.1227)  loss_rpn_box_reg: 0.0249 (0.0493)  time: 0.2737  data: 0.1328  max mem: 1709\n",
      "Training Epoch: [3]  [ 170/1229]  eta: 0:04:48  lr: 0.005000  loss: 0.4727 (0.4872)  loss_classifier: 0.1382 (0.1660)  loss_box_reg: 0.0809 (0.1461)  loss_objectness: 0.1042 (0.1230)  loss_rpn_box_reg: 0.0381 (0.0521)  time: 0.2693  data: 0.1335  max mem: 1709\n",
      "Training Epoch: [3]  [ 180/1229]  eta: 0:04:45  lr: 0.005000  loss: 0.4865 (0.4951)  loss_classifier: 0.1799 (0.1685)  loss_box_reg: 0.1305 (0.1485)  loss_objectness: 0.1429 (0.1254)  loss_rpn_box_reg: 0.0363 (0.0528)  time: 0.2664  data: 0.1330  max mem: 1709\n",
      "Training Epoch: [3]  [ 190/1229]  eta: 0:04:42  lr: 0.005000  loss: 0.5877 (0.4980)  loss_classifier: 0.1826 (0.1692)  loss_box_reg: 0.1437 (0.1493)  loss_objectness: 0.1293 (0.1259)  loss_rpn_box_reg: 0.0393 (0.0535)  time: 0.2700  data: 0.1321  max mem: 1709\n",
      "Training Epoch: [3]  [ 200/1229]  eta: 0:04:40  lr: 0.005000  loss: 0.4428 (0.4941)  loss_classifier: 0.1453 (0.1679)  loss_box_reg: 0.0909 (0.1471)  loss_objectness: 0.1239 (0.1266)  loss_rpn_box_reg: 0.0356 (0.0525)  time: 0.2751  data: 0.1331  max mem: 1709\n",
      "Training Epoch: [3]  [ 210/1229]  eta: 0:04:37  lr: 0.005000  loss: 0.3523 (0.4900)  loss_classifier: 0.1118 (0.1666)  loss_box_reg: 0.0870 (0.1461)  loss_objectness: 0.0935 (0.1256)  loss_rpn_box_reg: 0.0229 (0.0516)  time: 0.2733  data: 0.1325  max mem: 1709\n",
      "Training Epoch: [3]  [ 220/1229]  eta: 0:04:34  lr: 0.005000  loss: 0.4284 (0.4936)  loss_classifier: 0.1527 (0.1682)  loss_box_reg: 0.1059 (0.1471)  loss_objectness: 0.0956 (0.1258)  loss_rpn_box_reg: 0.0230 (0.0525)  time: 0.2699  data: 0.1303  max mem: 1709\n",
      "Training Epoch: [3]  [ 230/1229]  eta: 0:04:31  lr: 0.005000  loss: 0.4732 (0.4918)  loss_classifier: 0.1705 (0.1680)  loss_box_reg: 0.1104 (0.1468)  loss_objectness: 0.0968 (0.1247)  loss_rpn_box_reg: 0.0551 (0.0523)  time: 0.2703  data: 0.1328  max mem: 1709\n",
      "Training Epoch: [3]  [ 240/1229]  eta: 0:04:28  lr: 0.005000  loss: 0.4745 (0.4949)  loss_classifier: 0.1991 (0.1697)  loss_box_reg: 0.1508 (0.1484)  loss_objectness: 0.0968 (0.1248)  loss_rpn_box_reg: 0.0398 (0.0520)  time: 0.2670  data: 0.1336  max mem: 1709\n",
      "Training Epoch: [3]  [ 250/1229]  eta: 0:04:25  lr: 0.005000  loss: 0.4376 (0.4915)  loss_classifier: 0.1443 (0.1686)  loss_box_reg: 0.1306 (0.1472)  loss_objectness: 0.0969 (0.1244)  loss_rpn_box_reg: 0.0286 (0.0512)  time: 0.2679  data: 0.1313  max mem: 1709\n",
      "Training Epoch: [3]  [ 260/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.3867 (0.4892)  loss_classifier: 0.1248 (0.1671)  loss_box_reg: 0.1049 (0.1464)  loss_objectness: 0.0872 (0.1245)  loss_rpn_box_reg: 0.0225 (0.0511)  time: 0.2794  data: 0.1315  max mem: 1709\n",
      "Training Epoch: [3]  [ 270/1229]  eta: 0:04:20  lr: 0.005000  loss: 0.4045 (0.4902)  loss_classifier: 0.1248 (0.1674)  loss_box_reg: 0.1333 (0.1470)  loss_objectness: 0.1038 (0.1244)  loss_rpn_box_reg: 0.0212 (0.0515)  time: 0.2789  data: 0.1332  max mem: 1709\n",
      "Training Epoch: [3]  [ 280/1229]  eta: 0:04:17  lr: 0.005000  loss: 0.5827 (0.4927)  loss_classifier: 0.1802 (0.1688)  loss_box_reg: 0.1444 (0.1478)  loss_objectness: 0.1126 (0.1245)  loss_rpn_box_reg: 0.0357 (0.0516)  time: 0.2660  data: 0.1321  max mem: 1709\n",
      "Training Epoch: [3]  [ 290/1229]  eta: 0:04:14  lr: 0.005000  loss: 0.6149 (0.4959)  loss_classifier: 0.2004 (0.1697)  loss_box_reg: 0.1082 (0.1485)  loss_objectness: 0.1192 (0.1259)  loss_rpn_box_reg: 0.0393 (0.0517)  time: 0.2635  data: 0.1307  max mem: 1709\n",
      "Training Epoch: [3]  [ 300/1229]  eta: 0:04:12  lr: 0.005000  loss: 0.3910 (0.4938)  loss_classifier: 0.1329 (0.1691)  loss_box_reg: 0.1011 (0.1482)  loss_objectness: 0.1339 (0.1256)  loss_rpn_box_reg: 0.0280 (0.0509)  time: 0.2652  data: 0.1322  max mem: 1709\n",
      "Training Epoch: [3]  [ 310/1229]  eta: 0:04:09  lr: 0.005000  loss: 0.3627 (0.4940)  loss_classifier: 0.1240 (0.1687)  loss_box_reg: 0.1021 (0.1480)  loss_objectness: 0.1249 (0.1262)  loss_rpn_box_reg: 0.0250 (0.0511)  time: 0.2693  data: 0.1366  max mem: 1709\n",
      "Training Epoch: [3]  [ 320/1229]  eta: 0:04:06  lr: 0.005000  loss: 0.4279 (0.4953)  loss_classifier: 0.1329 (0.1686)  loss_box_reg: 0.0930 (0.1476)  loss_objectness: 0.1289 (0.1266)  loss_rpn_box_reg: 0.0449 (0.0525)  time: 0.2731  data: 0.1356  max mem: 1709\n",
      "Training Epoch: [3]  [ 330/1229]  eta: 0:04:03  lr: 0.005000  loss: 0.4327 (0.4935)  loss_classifier: 0.1406 (0.1683)  loss_box_reg: 0.0930 (0.1474)  loss_objectness: 0.1282 (0.1260)  loss_rpn_box_reg: 0.0320 (0.0519)  time: 0.2676  data: 0.1324  max mem: 1709\n",
      "Training Epoch: [3]  [ 340/1229]  eta: 0:04:00  lr: 0.005000  loss: 0.5121 (0.4990)  loss_classifier: 0.1650 (0.1697)  loss_box_reg: 0.1473 (0.1493)  loss_objectness: 0.1282 (0.1269)  loss_rpn_box_reg: 0.0346 (0.0530)  time: 0.2657  data: 0.1335  max mem: 1709\n",
      "Training Epoch: [3]  [ 350/1229]  eta: 0:03:58  lr: 0.005000  loss: 0.4704 (0.4989)  loss_classifier: 0.1570 (0.1696)  loss_box_reg: 0.1365 (0.1494)  loss_objectness: 0.1405 (0.1270)  loss_rpn_box_reg: 0.0393 (0.0530)  time: 0.2699  data: 0.1329  max mem: 1709\n",
      "Training Epoch: [3]  [ 360/1229]  eta: 0:03:55  lr: 0.005000  loss: 0.4595 (0.4989)  loss_classifier: 0.1516 (0.1696)  loss_box_reg: 0.1360 (0.1492)  loss_objectness: 0.1185 (0.1267)  loss_rpn_box_reg: 0.0282 (0.0534)  time: 0.2785  data: 0.1326  max mem: 1709\n",
      "Training Epoch: [3]  [ 370/1229]  eta: 0:03:53  lr: 0.005000  loss: 0.4780 (0.5016)  loss_classifier: 0.1741 (0.1708)  loss_box_reg: 0.1636 (0.1505)  loss_objectness: 0.1162 (0.1269)  loss_rpn_box_reg: 0.0339 (0.0535)  time: 0.2807  data: 0.1347  max mem: 1709\n",
      "Training Epoch: [3]  [ 380/1229]  eta: 0:03:50  lr: 0.005000  loss: 0.5219 (0.5038)  loss_classifier: 0.1888 (0.1717)  loss_box_reg: 0.2162 (0.1526)  loss_objectness: 0.1075 (0.1266)  loss_rpn_box_reg: 0.0395 (0.0529)  time: 0.2802  data: 0.1372  max mem: 1709\n",
      "Training Epoch: [3]  [ 390/1229]  eta: 0:03:47  lr: 0.005000  loss: 0.5032 (0.5022)  loss_classifier: 0.1525 (0.1713)  loss_box_reg: 0.1426 (0.1524)  loss_objectness: 0.0917 (0.1258)  loss_rpn_box_reg: 0.0330 (0.0527)  time: 0.2725  data: 0.1352  max mem: 1709\n",
      "Training Epoch: [3]  [ 400/1229]  eta: 0:03:45  lr: 0.005000  loss: 0.3505 (0.4994)  loss_classifier: 0.1255 (0.1704)  loss_box_reg: 0.1060 (0.1513)  loss_objectness: 0.0917 (0.1253)  loss_rpn_box_reg: 0.0251 (0.0525)  time: 0.2650  data: 0.1325  max mem: 1709\n",
      "Training Epoch: [3]  [ 410/1229]  eta: 0:03:42  lr: 0.005000  loss: 0.4008 (0.5000)  loss_classifier: 0.1333 (0.1703)  loss_box_reg: 0.1249 (0.1517)  loss_objectness: 0.1006 (0.1256)  loss_rpn_box_reg: 0.0230 (0.0525)  time: 0.2657  data: 0.1309  max mem: 1709\n",
      "Training Epoch: [3]  [ 420/1229]  eta: 0:03:39  lr: 0.005000  loss: 0.4368 (0.5005)  loss_classifier: 0.1722 (0.1702)  loss_box_reg: 0.1331 (0.1516)  loss_objectness: 0.1204 (0.1257)  loss_rpn_box_reg: 0.0244 (0.0530)  time: 0.2610  data: 0.1305  max mem: 1709\n",
      "Training Epoch: [3]  [ 430/1229]  eta: 0:03:36  lr: 0.005000  loss: 0.4137 (0.4980)  loss_classifier: 0.1439 (0.1697)  loss_box_reg: 0.1003 (0.1512)  loss_objectness: 0.0875 (0.1250)  loss_rpn_box_reg: 0.0215 (0.0522)  time: 0.2673  data: 0.1310  max mem: 1709\n",
      "Training Epoch: [3]  [ 440/1229]  eta: 0:03:33  lr: 0.005000  loss: 0.3677 (0.4971)  loss_classifier: 0.1371 (0.1694)  loss_box_reg: 0.1034 (0.1512)  loss_objectness: 0.0875 (0.1245)  loss_rpn_box_reg: 0.0172 (0.0519)  time: 0.2723  data: 0.1303  max mem: 1709\n",
      "Training Epoch: [3]  [ 450/1229]  eta: 0:03:31  lr: 0.005000  loss: 0.3453 (0.4949)  loss_classifier: 0.1304 (0.1687)  loss_box_reg: 0.1146 (0.1510)  loss_objectness: 0.0784 (0.1238)  loss_rpn_box_reg: 0.0186 (0.0514)  time: 0.2702  data: 0.1326  max mem: 1709\n",
      "Training Epoch: [3]  [ 460/1229]  eta: 0:03:28  lr: 0.005000  loss: 0.4176 (0.4961)  loss_classifier: 0.1530 (0.1690)  loss_box_reg: 0.1146 (0.1512)  loss_objectness: 0.1252 (0.1247)  loss_rpn_box_reg: 0.0228 (0.0513)  time: 0.2744  data: 0.1354  max mem: 1709\n",
      "Training Epoch: [3]  [ 470/1229]  eta: 0:03:25  lr: 0.005000  loss: 0.4176 (0.4936)  loss_classifier: 0.1530 (0.1680)  loss_box_reg: 0.1006 (0.1503)  loss_objectness: 0.1174 (0.1241)  loss_rpn_box_reg: 0.0228 (0.0512)  time: 0.2718  data: 0.1337  max mem: 1709\n",
      "Training Epoch: [3]  [ 480/1229]  eta: 0:03:23  lr: 0.005000  loss: 0.3196 (0.4935)  loss_classifier: 0.1279 (0.1682)  loss_box_reg: 0.0912 (0.1498)  loss_objectness: 0.1052 (0.1244)  loss_rpn_box_reg: 0.0226 (0.0511)  time: 0.2734  data: 0.1345  max mem: 1709\n",
      "Training Epoch: [3]  [ 490/1229]  eta: 0:03:20  lr: 0.005000  loss: 0.5284 (0.4937)  loss_classifier: 0.1917 (0.1684)  loss_box_reg: 0.1592 (0.1506)  loss_objectness: 0.1041 (0.1240)  loss_rpn_box_reg: 0.0296 (0.0508)  time: 0.2763  data: 0.1343  max mem: 1709\n",
      "Training Epoch: [3]  [ 500/1229]  eta: 0:03:17  lr: 0.005000  loss: 0.5309 (0.4963)  loss_classifier: 0.1862 (0.1691)  loss_box_reg: 0.1854 (0.1515)  loss_objectness: 0.1071 (0.1242)  loss_rpn_box_reg: 0.0330 (0.0515)  time: 0.2754  data: 0.1340  max mem: 1709\n",
      "Training Epoch: [3]  [ 510/1229]  eta: 0:03:15  lr: 0.005000  loss: 0.4129 (0.4957)  loss_classifier: 0.1636 (0.1690)  loss_box_reg: 0.0945 (0.1508)  loss_objectness: 0.1126 (0.1244)  loss_rpn_box_reg: 0.0340 (0.0515)  time: 0.2733  data: 0.1336  max mem: 1709\n",
      "Training Epoch: [3]  [ 520/1229]  eta: 0:03:12  lr: 0.005000  loss: 0.3627 (0.4960)  loss_classifier: 0.1366 (0.1690)  loss_box_reg: 0.0924 (0.1501)  loss_objectness: 0.1149 (0.1245)  loss_rpn_box_reg: 0.0318 (0.0524)  time: 0.2707  data: 0.1307  max mem: 1709\n",
      "Training Epoch: [3]  [ 530/1229]  eta: 0:03:09  lr: 0.005000  loss: 0.5237 (0.4977)  loss_classifier: 0.1870 (0.1701)  loss_box_reg: 0.1453 (0.1512)  loss_objectness: 0.1212 (0.1243)  loss_rpn_box_reg: 0.0346 (0.0521)  time: 0.2780  data: 0.1320  max mem: 1709\n",
      "Training Epoch: [3]  [ 540/1229]  eta: 0:03:07  lr: 0.005000  loss: 0.5114 (0.4965)  loss_classifier: 0.1827 (0.1698)  loss_box_reg: 0.1384 (0.1507)  loss_objectness: 0.1172 (0.1243)  loss_rpn_box_reg: 0.0346 (0.0518)  time: 0.2771  data: 0.1348  max mem: 1709\n",
      "Training Epoch: [3]  [ 550/1229]  eta: 0:03:04  lr: 0.005000  loss: 0.4495 (0.4961)  loss_classifier: 0.1326 (0.1693)  loss_box_reg: 0.1241 (0.1501)  loss_objectness: 0.1172 (0.1245)  loss_rpn_box_reg: 0.0282 (0.0522)  time: 0.2719  data: 0.1363  max mem: 1709\n",
      "Training Epoch: [3]  [ 560/1229]  eta: 0:03:01  lr: 0.005000  loss: 0.3467 (0.4954)  loss_classifier: 0.1237 (0.1691)  loss_box_reg: 0.1216 (0.1502)  loss_objectness: 0.1159 (0.1244)  loss_rpn_box_reg: 0.0221 (0.0517)  time: 0.2738  data: 0.1344  max mem: 1709\n",
      "Training Epoch: [3]  [ 570/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.5044 (0.4980)  loss_classifier: 0.1288 (0.1699)  loss_box_reg: 0.1376 (0.1508)  loss_objectness: 0.0915 (0.1245)  loss_rpn_box_reg: 0.0370 (0.0528)  time: 0.2684  data: 0.1331  max mem: 1709\n",
      "Training Epoch: [3]  [ 580/1229]  eta: 0:02:56  lr: 0.005000  loss: 0.4929 (0.4971)  loss_classifier: 0.1890 (0.1699)  loss_box_reg: 0.1335 (0.1506)  loss_objectness: 0.0895 (0.1239)  loss_rpn_box_reg: 0.0426 (0.0528)  time: 0.2686  data: 0.1332  max mem: 1709\n",
      "Training Epoch: [3]  [ 590/1229]  eta: 0:02:53  lr: 0.005000  loss: 0.4480 (0.4969)  loss_classifier: 0.1674 (0.1694)  loss_box_reg: 0.1174 (0.1500)  loss_objectness: 0.0902 (0.1241)  loss_rpn_box_reg: 0.0331 (0.0533)  time: 0.2704  data: 0.1311  max mem: 1709\n",
      "Training Epoch: [3]  [ 600/1229]  eta: 0:02:50  lr: 0.005000  loss: 0.4805 (0.4967)  loss_classifier: 0.1348 (0.1694)  loss_box_reg: 0.0959 (0.1496)  loss_objectness: 0.1072 (0.1240)  loss_rpn_box_reg: 0.0346 (0.0536)  time: 0.2705  data: 0.1314  max mem: 1709\n",
      "Training Epoch: [3]  [ 610/1229]  eta: 0:02:48  lr: 0.005000  loss: 0.4362 (0.4973)  loss_classifier: 0.1683 (0.1697)  loss_box_reg: 0.1272 (0.1495)  loss_objectness: 0.1097 (0.1244)  loss_rpn_box_reg: 0.0363 (0.0538)  time: 0.2761  data: 0.1365  max mem: 1709\n",
      "Training Epoch: [3]  [ 620/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.4103 (0.4967)  loss_classifier: 0.1683 (0.1696)  loss_box_reg: 0.1306 (0.1493)  loss_objectness: 0.1167 (0.1241)  loss_rpn_box_reg: 0.0311 (0.0537)  time: 0.2786  data: 0.1372  max mem: 1709\n",
      "Training Epoch: [3]  [ 630/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.3372 (0.4968)  loss_classifier: 0.1165 (0.1693)  loss_box_reg: 0.1072 (0.1490)  loss_objectness: 0.0980 (0.1243)  loss_rpn_box_reg: 0.0243 (0.0542)  time: 0.2767  data: 0.1337  max mem: 1709\n",
      "Training Epoch: [3]  [ 640/1229]  eta: 0:02:40  lr: 0.005000  loss: 0.4520 (0.4964)  loss_classifier: 0.1438 (0.1689)  loss_box_reg: 0.1187 (0.1486)  loss_objectness: 0.0980 (0.1243)  loss_rpn_box_reg: 0.0309 (0.0545)  time: 0.2743  data: 0.1322  max mem: 1709\n",
      "Training Epoch: [3]  [ 650/1229]  eta: 0:02:37  lr: 0.005000  loss: 0.4785 (0.4986)  loss_classifier: 0.1709 (0.1695)  loss_box_reg: 0.1559 (0.1495)  loss_objectness: 0.1075 (0.1244)  loss_rpn_box_reg: 0.0416 (0.0553)  time: 0.2711  data: 0.1313  max mem: 1709\n",
      "Training Epoch: [3]  [ 660/1229]  eta: 0:02:34  lr: 0.005000  loss: 0.5684 (0.4991)  loss_classifier: 0.1786 (0.1695)  loss_box_reg: 0.1694 (0.1496)  loss_objectness: 0.1214 (0.1246)  loss_rpn_box_reg: 0.0447 (0.0554)  time: 0.2676  data: 0.1303  max mem: 1709\n",
      "Training Epoch: [3]  [ 670/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.4459 (0.4988)  loss_classifier: 0.1545 (0.1693)  loss_box_reg: 0.1080 (0.1496)  loss_objectness: 0.1202 (0.1245)  loss_rpn_box_reg: 0.0329 (0.0554)  time: 0.2759  data: 0.1321  max mem: 1709\n",
      "Training Epoch: [3]  [ 680/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.3863 (0.4972)  loss_classifier: 0.1326 (0.1687)  loss_box_reg: 0.0971 (0.1489)  loss_objectness: 0.1030 (0.1244)  loss_rpn_box_reg: 0.0336 (0.0552)  time: 0.2767  data: 0.1328  max mem: 1709\n",
      "Training Epoch: [3]  [ 690/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.3646 (0.4958)  loss_classifier: 0.1326 (0.1682)  loss_box_reg: 0.0971 (0.1484)  loss_objectness: 0.0919 (0.1244)  loss_rpn_box_reg: 0.0349 (0.0550)  time: 0.2709  data: 0.1317  max mem: 1709\n",
      "Training Epoch: [3]  [ 700/1229]  eta: 0:02:23  lr: 0.005000  loss: 0.3330 (0.4947)  loss_classifier: 0.1180 (0.1680)  loss_box_reg: 0.1065 (0.1482)  loss_objectness: 0.1018 (0.1239)  loss_rpn_box_reg: 0.0261 (0.0546)  time: 0.2720  data: 0.1302  max mem: 1709\n",
      "Training Epoch: [3]  [ 710/1229]  eta: 0:02:21  lr: 0.005000  loss: 0.3050 (0.4929)  loss_classifier: 0.1125 (0.1674)  loss_box_reg: 0.1065 (0.1478)  loss_objectness: 0.0852 (0.1233)  loss_rpn_box_reg: 0.0203 (0.0544)  time: 0.2718  data: 0.1289  max mem: 1709\n",
      "Training Epoch: [3]  [ 720/1229]  eta: 0:02:18  lr: 0.005000  loss: 0.3011 (0.4915)  loss_classifier: 0.1051 (0.1670)  loss_box_reg: 0.0783 (0.1472)  loss_objectness: 0.0732 (0.1230)  loss_rpn_box_reg: 0.0190 (0.0543)  time: 0.2733  data: 0.1308  max mem: 1709\n",
      "Training Epoch: [3]  [ 730/1229]  eta: 0:02:15  lr: 0.005000  loss: 0.4036 (0.4922)  loss_classifier: 0.1272 (0.1672)  loss_box_reg: 0.1154 (0.1473)  loss_objectness: 0.1024 (0.1231)  loss_rpn_box_reg: 0.0467 (0.0546)  time: 0.2756  data: 0.1326  max mem: 1709\n",
      "Training Epoch: [3]  [ 740/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.4440 (0.4919)  loss_classifier: 0.1744 (0.1673)  loss_box_reg: 0.1302 (0.1474)  loss_objectness: 0.0995 (0.1230)  loss_rpn_box_reg: 0.0353 (0.0542)  time: 0.2784  data: 0.1339  max mem: 1709\n",
      "Training Epoch: [3]  [ 750/1229]  eta: 0:02:10  lr: 0.005000  loss: 0.4335 (0.4917)  loss_classifier: 0.1605 (0.1672)  loss_box_reg: 0.1111 (0.1468)  loss_objectness: 0.0978 (0.1232)  loss_rpn_box_reg: 0.0353 (0.0545)  time: 0.2763  data: 0.1339  max mem: 1709\n",
      "Training Epoch: [3]  [ 760/1229]  eta: 0:02:07  lr: 0.005000  loss: 0.4366 (0.4912)  loss_classifier: 0.1476 (0.1671)  loss_box_reg: 0.1111 (0.1467)  loss_objectness: 0.1142 (0.1231)  loss_rpn_box_reg: 0.0305 (0.0543)  time: 0.2676  data: 0.1315  max mem: 1709\n",
      "Training Epoch: [3]  [ 770/1229]  eta: 0:02:04  lr: 0.005000  loss: 0.4841 (0.4917)  loss_classifier: 0.1748 (0.1674)  loss_box_reg: 0.1470 (0.1472)  loss_objectness: 0.1010 (0.1232)  loss_rpn_box_reg: 0.0278 (0.0540)  time: 0.2683  data: 0.1326  max mem: 1709\n",
      "Training Epoch: [3]  [ 780/1229]  eta: 0:02:02  lr: 0.005000  loss: 0.5736 (0.4927)  loss_classifier: 0.1802 (0.1675)  loss_box_reg: 0.1523 (0.1474)  loss_objectness: 0.1201 (0.1233)  loss_rpn_box_reg: 0.0399 (0.0545)  time: 0.2722  data: 0.1348  max mem: 1709\n",
      "Training Epoch: [3]  [ 790/1229]  eta: 0:01:59  lr: 0.005000  loss: 0.4612 (0.4912)  loss_classifier: 0.1624 (0.1671)  loss_box_reg: 0.1257 (0.1469)  loss_objectness: 0.0958 (0.1229)  loss_rpn_box_reg: 0.0504 (0.0543)  time: 0.2723  data: 0.1319  max mem: 1709\n",
      "Training Epoch: [3]  [ 800/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.3478 (0.4907)  loss_classifier: 0.1132 (0.1668)  loss_box_reg: 0.1044 (0.1468)  loss_objectness: 0.0958 (0.1229)  loss_rpn_box_reg: 0.0408 (0.0542)  time: 0.2711  data: 0.1321  max mem: 1709\n",
      "Training Epoch: [3]  [ 810/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.3912 (0.4910)  loss_classifier: 0.1510 (0.1669)  loss_box_reg: 0.1316 (0.1472)  loss_objectness: 0.1135 (0.1230)  loss_rpn_box_reg: 0.0378 (0.0539)  time: 0.2695  data: 0.1342  max mem: 1709\n",
      "Training Epoch: [3]  [ 820/1229]  eta: 0:01:51  lr: 0.005000  loss: 0.4897 (0.4921)  loss_classifier: 0.1642 (0.1674)  loss_box_reg: 0.1396 (0.1475)  loss_objectness: 0.1321 (0.1232)  loss_rpn_box_reg: 0.0374 (0.0540)  time: 0.2694  data: 0.1322  max mem: 1709\n",
      "Training Epoch: [3]  [ 830/1229]  eta: 0:01:48  lr: 0.005000  loss: 0.3703 (0.4900)  loss_classifier: 0.1415 (0.1668)  loss_box_reg: 0.1085 (0.1468)  loss_objectness: 0.1070 (0.1228)  loss_rpn_box_reg: 0.0287 (0.0536)  time: 0.2706  data: 0.1319  max mem: 1709\n",
      "Training Epoch: [3]  [ 840/1229]  eta: 0:01:45  lr: 0.005000  loss: 0.3453 (0.4890)  loss_classifier: 0.1220 (0.1665)  loss_box_reg: 0.1023 (0.1468)  loss_objectness: 0.0745 (0.1225)  loss_rpn_box_reg: 0.0185 (0.0532)  time: 0.2733  data: 0.1320  max mem: 1709\n",
      "Training Epoch: [3]  [ 850/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.4023 (0.4881)  loss_classifier: 0.1188 (0.1660)  loss_box_reg: 0.0963 (0.1461)  loss_objectness: 0.1119 (0.1228)  loss_rpn_box_reg: 0.0206 (0.0533)  time: 0.2718  data: 0.1320  max mem: 1709\n",
      "Training Epoch: [3]  [ 860/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.4278 (0.4888)  loss_classifier: 0.1240 (0.1661)  loss_box_reg: 0.1165 (0.1463)  loss_objectness: 0.1279 (0.1231)  loss_rpn_box_reg: 0.0354 (0.0533)  time: 0.2661  data: 0.1322  max mem: 1709\n",
      "Training Epoch: [3]  [ 870/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.5116 (0.4902)  loss_classifier: 0.1531 (0.1665)  loss_box_reg: 0.1284 (0.1467)  loss_objectness: 0.1283 (0.1233)  loss_rpn_box_reg: 0.0480 (0.0538)  time: 0.2653  data: 0.1314  max mem: 1709\n",
      "Training Epoch: [3]  [ 880/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.5856 (0.4908)  loss_classifier: 0.2000 (0.1667)  loss_box_reg: 0.1766 (0.1473)  loss_objectness: 0.1246 (0.1231)  loss_rpn_box_reg: 0.0390 (0.0536)  time: 0.2684  data: 0.1339  max mem: 1709\n",
      "Training Epoch: [3]  [ 890/1229]  eta: 0:01:32  lr: 0.005000  loss: 0.4176 (0.4906)  loss_classifier: 0.1530 (0.1668)  loss_box_reg: 0.1060 (0.1475)  loss_objectness: 0.0902 (0.1229)  loss_rpn_box_reg: 0.0347 (0.0535)  time: 0.2664  data: 0.1347  max mem: 1709\n",
      "Training Epoch: [3]  [ 900/1229]  eta: 0:01:29  lr: 0.005000  loss: 0.3731 (0.4897)  loss_classifier: 0.1445 (0.1665)  loss_box_reg: 0.1060 (0.1472)  loss_objectness: 0.0873 (0.1225)  loss_rpn_box_reg: 0.0294 (0.0535)  time: 0.2702  data: 0.1328  max mem: 1709\n",
      "Training Epoch: [3]  [ 910/1229]  eta: 0:01:26  lr: 0.005000  loss: 0.4891 (0.4918)  loss_classifier: 0.1578 (0.1672)  loss_box_reg: 0.1396 (0.1480)  loss_objectness: 0.1041 (0.1227)  loss_rpn_box_reg: 0.0343 (0.0539)  time: 0.2746  data: 0.1322  max mem: 1709\n",
      "Training Epoch: [3]  [ 920/1229]  eta: 0:01:23  lr: 0.005000  loss: 0.5602 (0.4926)  loss_classifier: 0.1901 (0.1675)  loss_box_reg: 0.1505 (0.1484)  loss_objectness: 0.1290 (0.1228)  loss_rpn_box_reg: 0.0525 (0.0539)  time: 0.2722  data: 0.1335  max mem: 1709\n",
      "Training Epoch: [3]  [ 930/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.4662 (0.4931)  loss_classifier: 0.1686 (0.1677)  loss_box_reg: 0.1381 (0.1488)  loss_objectness: 0.1150 (0.1227)  loss_rpn_box_reg: 0.0273 (0.0539)  time: 0.2744  data: 0.1344  max mem: 1709\n",
      "Training Epoch: [3]  [ 940/1229]  eta: 0:01:18  lr: 0.005000  loss: 0.4662 (0.4922)  loss_classifier: 0.1621 (0.1675)  loss_box_reg: 0.1503 (0.1485)  loss_objectness: 0.1106 (0.1225)  loss_rpn_box_reg: 0.0184 (0.0536)  time: 0.2764  data: 0.1326  max mem: 1709\n",
      "Training Epoch: [3]  [ 950/1229]  eta: 0:01:15  lr: 0.005000  loss: 0.5035 (0.4929)  loss_classifier: 0.1782 (0.1678)  loss_box_reg: 0.1718 (0.1490)  loss_objectness: 0.1095 (0.1226)  loss_rpn_box_reg: 0.0273 (0.0536)  time: 0.2692  data: 0.1314  max mem: 1709\n",
      "Training Epoch: [3]  [ 960/1229]  eta: 0:01:13  lr: 0.005000  loss: 0.5323 (0.4939)  loss_classifier: 0.1833 (0.1680)  loss_box_reg: 0.1832 (0.1495)  loss_objectness: 0.1095 (0.1227)  loss_rpn_box_reg: 0.0389 (0.0536)  time: 0.2686  data: 0.1320  max mem: 1709\n",
      "Training Epoch: [3]  [ 970/1229]  eta: 0:01:10  lr: 0.005000  loss: 0.5582 (0.4946)  loss_classifier: 0.1926 (0.1686)  loss_box_reg: 0.1733 (0.1499)  loss_objectness: 0.1059 (0.1227)  loss_rpn_box_reg: 0.0406 (0.0535)  time: 0.2788  data: 0.1358  max mem: 1709\n",
      "Training Epoch: [3]  [ 980/1229]  eta: 0:01:07  lr: 0.005000  loss: 0.4236 (0.4944)  loss_classifier: 0.1469 (0.1685)  loss_box_reg: 0.1074 (0.1498)  loss_objectness: 0.1001 (0.1228)  loss_rpn_box_reg: 0.0226 (0.0532)  time: 0.2801  data: 0.1357  max mem: 1709\n",
      "Training Epoch: [3]  [ 990/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.4236 (0.4945)  loss_classifier: 0.1437 (0.1686)  loss_box_reg: 0.1095 (0.1501)  loss_objectness: 0.1185 (0.1228)  loss_rpn_box_reg: 0.0202 (0.0531)  time: 0.2713  data: 0.1344  max mem: 1709\n",
      "Training Epoch: [3]  [1000/1229]  eta: 0:01:02  lr: 0.005000  loss: 0.4551 (0.4940)  loss_classifier: 0.1660 (0.1684)  loss_box_reg: 0.1711 (0.1501)  loss_objectness: 0.1060 (0.1226)  loss_rpn_box_reg: 0.0266 (0.0529)  time: 0.2672  data: 0.1343  max mem: 1709\n",
      "Training Epoch: [3]  [1010/1229]  eta: 0:00:59  lr: 0.005000  loss: 0.4448 (0.4943)  loss_classifier: 0.1578 (0.1683)  loss_box_reg: 0.1356 (0.1499)  loss_objectness: 0.1060 (0.1228)  loss_rpn_box_reg: 0.0311 (0.0533)  time: 0.2702  data: 0.1336  max mem: 1709\n",
      "Training Epoch: [3]  [1020/1229]  eta: 0:00:56  lr: 0.005000  loss: 0.5167 (0.4961)  loss_classifier: 0.1599 (0.1689)  loss_box_reg: 0.1411 (0.1508)  loss_objectness: 0.1392 (0.1231)  loss_rpn_box_reg: 0.0382 (0.0534)  time: 0.2679  data: 0.1353  max mem: 1709\n",
      "Training Epoch: [3]  [1030/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.5083 (0.4961)  loss_classifier: 0.1885 (0.1691)  loss_box_reg: 0.1411 (0.1509)  loss_objectness: 0.1114 (0.1229)  loss_rpn_box_reg: 0.0280 (0.0533)  time: 0.2665  data: 0.1341  max mem: 1709\n",
      "Training Epoch: [3]  [1040/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.3977 (0.4966)  loss_classifier: 0.1310 (0.1692)  loss_box_reg: 0.1115 (0.1510)  loss_objectness: 0.1114 (0.1230)  loss_rpn_box_reg: 0.0318 (0.0533)  time: 0.2727  data: 0.1332  max mem: 1709\n",
      "Training Epoch: [3]  [1050/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.4946 (0.4965)  loss_classifier: 0.1582 (0.1691)  loss_box_reg: 0.0941 (0.1506)  loss_objectness: 0.1176 (0.1234)  loss_rpn_box_reg: 0.0331 (0.0533)  time: 0.2761  data: 0.1342  max mem: 1709\n",
      "Training Epoch: [3]  [1060/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.5057 (0.4968)  loss_classifier: 0.1582 (0.1694)  loss_box_reg: 0.1022 (0.1508)  loss_objectness: 0.1125 (0.1234)  loss_rpn_box_reg: 0.0282 (0.0532)  time: 0.2780  data: 0.1352  max mem: 1709\n",
      "Training Epoch: [3]  [1070/1229]  eta: 0:00:43  lr: 0.005000  loss: 0.4220 (0.4968)  loss_classifier: 0.1564 (0.1694)  loss_box_reg: 0.1117 (0.1506)  loss_objectness: 0.1104 (0.1236)  loss_rpn_box_reg: 0.0262 (0.0532)  time: 0.2718  data: 0.1349  max mem: 1709\n",
      "Training Epoch: [3]  [1080/1229]  eta: 0:00:40  lr: 0.005000  loss: 0.4869 (0.4965)  loss_classifier: 0.1564 (0.1693)  loss_box_reg: 0.1271 (0.1509)  loss_objectness: 0.0999 (0.1233)  loss_rpn_box_reg: 0.0199 (0.0530)  time: 0.2703  data: 0.1346  max mem: 1709\n",
      "Training Epoch: [3]  [1090/1229]  eta: 0:00:37  lr: 0.005000  loss: 0.4496 (0.4975)  loss_classifier: 0.1760 (0.1699)  loss_box_reg: 0.1367 (0.1509)  loss_objectness: 0.0963 (0.1235)  loss_rpn_box_reg: 0.0214 (0.0531)  time: 0.2734  data: 0.1348  max mem: 1709\n",
      "Training Epoch: [3]  [1100/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4580 (0.4984)  loss_classifier: 0.2234 (0.1703)  loss_box_reg: 0.1226 (0.1514)  loss_objectness: 0.1359 (0.1237)  loss_rpn_box_reg: 0.0294 (0.0530)  time: 0.2663  data: 0.1306  max mem: 1709\n",
      "Training Epoch: [3]  [1110/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.5280 (0.4984)  loss_classifier: 0.1732 (0.1703)  loss_box_reg: 0.2177 (0.1518)  loss_objectness: 0.1053 (0.1235)  loss_rpn_box_reg: 0.0288 (0.0527)  time: 0.2661  data: 0.1321  max mem: 1709\n",
      "Training Epoch: [3]  [1120/1229]  eta: 0:00:29  lr: 0.005000  loss: 0.3985 (0.4975)  loss_classifier: 0.1375 (0.1701)  loss_box_reg: 0.1462 (0.1515)  loss_objectness: 0.0805 (0.1233)  loss_rpn_box_reg: 0.0288 (0.0526)  time: 0.2657  data: 0.1334  max mem: 1709\n",
      "Training Epoch: [3]  [1130/1229]  eta: 0:00:26  lr: 0.005000  loss: 0.3165 (0.4969)  loss_classifier: 0.1332 (0.1700)  loss_box_reg: 0.1088 (0.1512)  loss_objectness: 0.0748 (0.1232)  loss_rpn_box_reg: 0.0217 (0.0524)  time: 0.2714  data: 0.1329  max mem: 1709\n",
      "Training Epoch: [3]  [1140/1229]  eta: 0:00:24  lr: 0.005000  loss: 0.4789 (0.4979)  loss_classifier: 0.1550 (0.1703)  loss_box_reg: 0.1482 (0.1516)  loss_objectness: 0.1231 (0.1235)  loss_rpn_box_reg: 0.0436 (0.0525)  time: 0.2796  data: 0.1349  max mem: 1709\n",
      "Training Epoch: [3]  [1150/1229]  eta: 0:00:21  lr: 0.005000  loss: 0.5462 (0.4978)  loss_classifier: 0.1663 (0.1703)  loss_box_reg: 0.1118 (0.1515)  loss_objectness: 0.1231 (0.1235)  loss_rpn_box_reg: 0.0465 (0.0525)  time: 0.2770  data: 0.1329  max mem: 1709\n",
      "Training Epoch: [3]  [1160/1229]  eta: 0:00:18  lr: 0.005000  loss: 0.3897 (0.4979)  loss_classifier: 0.1544 (0.1703)  loss_box_reg: 0.1118 (0.1515)  loss_objectness: 0.0921 (0.1235)  loss_rpn_box_reg: 0.0395 (0.0527)  time: 0.2696  data: 0.1297  max mem: 1709\n",
      "Training Epoch: [3]  [1170/1229]  eta: 0:00:16  lr: 0.005000  loss: 0.3699 (0.4974)  loss_classifier: 0.1298 (0.1700)  loss_box_reg: 0.0878 (0.1513)  loss_objectness: 0.0773 (0.1234)  loss_rpn_box_reg: 0.0413 (0.0526)  time: 0.2710  data: 0.1275  max mem: 1709\n",
      "Training Epoch: [3]  [1180/1229]  eta: 0:00:13  lr: 0.005000  loss: 0.5527 (0.4988)  loss_classifier: 0.1614 (0.1703)  loss_box_reg: 0.1410 (0.1517)  loss_objectness: 0.1263 (0.1238)  loss_rpn_box_reg: 0.0613 (0.0530)  time: 0.2755  data: 0.1303  max mem: 1709\n",
      "Training Epoch: [3]  [1190/1229]  eta: 0:00:10  lr: 0.005000  loss: 0.5527 (0.4996)  loss_classifier: 0.1681 (0.1707)  loss_box_reg: 0.1512 (0.1521)  loss_objectness: 0.1282 (0.1238)  loss_rpn_box_reg: 0.0443 (0.0531)  time: 0.2745  data: 0.1341  max mem: 1709\n",
      "Training Epoch: [3]  [1200/1229]  eta: 0:00:07  lr: 0.005000  loss: 0.4221 (0.5000)  loss_classifier: 0.1672 (0.1708)  loss_box_reg: 0.1163 (0.1521)  loss_objectness: 0.1262 (0.1241)  loss_rpn_box_reg: 0.0281 (0.0530)  time: 0.2704  data: 0.1329  max mem: 1709\n",
      "Training Epoch: [3]  [1210/1229]  eta: 0:00:05  lr: 0.005000  loss: 0.4301 (0.4999)  loss_classifier: 0.1564 (0.1706)  loss_box_reg: 0.1163 (0.1520)  loss_objectness: 0.1262 (0.1240)  loss_rpn_box_reg: 0.0445 (0.0532)  time: 0.2755  data: 0.1320  max mem: 1709\n",
      "Training Epoch: [3]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.4102 (0.5000)  loss_classifier: 0.1508 (0.1706)  loss_box_reg: 0.1166 (0.1521)  loss_objectness: 0.1005 (0.1240)  loss_rpn_box_reg: 0.0445 (0.0533)  time: 0.2771  data: 0.1330  max mem: 1709\n",
      "Training Epoch: [3]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4503 (0.5006)  loss_classifier: 0.1528 (0.1709)  loss_box_reg: 0.1315 (0.1523)  loss_objectness: 0.1005 (0.1240)  loss_rpn_box_reg: 0.0307 (0.0534)  time: 0.2723  data: 0.1317  max mem: 1709\n",
      "Training Epoch: [3] Total time: 0:05:34 (0.2720 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:30  model_time: 0.2610 (0.2610)  evaluator_time: 0.0010 (0.0010)  time: 0.2930  data: 0.0280  max mem: 1709\n",
      "Test:  [100/308]  eta: 0:00:25  model_time: 0.0730 (0.0775)  evaluator_time: 0.0060 (0.0080)  time: 0.1216  data: 0.0357  max mem: 1709\n",
      "Test:  [200/308]  eta: 0:00:12  model_time: 0.0780 (0.0765)  evaluator_time: 0.0030 (0.0073)  time: 0.1152  data: 0.0302  max mem: 1709\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0690 (0.0759)  evaluator_time: 0.0040 (0.0071)  time: 0.1151  data: 0.0350  max mem: 1709\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0690 (0.0758)  evaluator_time: 0.0020 (0.0071)  time: 0.1121  data: 0.0332  max mem: 1709\n",
      "Test: Total time: 0:00:36 (0.1188 s / it)\n",
      "Averaged stats: model_time: 0.0690 (0.0758)  evaluator_time: 0.0020 (0.0071)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.071\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.193\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.047\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.136\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.032\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.242\n",
      "Testing Epoch: [3]  [  0/308]  eta: 0:00:37  lr: 0.005000  loss: 0.1707 (0.1707)  loss_classifier: 0.0629 (0.0629)  loss_box_reg: 0.0629 (0.0629)  loss_objectness: 0.0379 (0.0379)  loss_rpn_box_reg: 0.0070 (0.0070)  time: 0.1210  data: 0.0270  max mem: 1709\n",
      "Testing Epoch: [3]  [100/308]  eta: 0:00:28  lr: 0.005000  loss: 0.3454 (0.5154)  loss_classifier: 0.1321 (0.1664)  loss_box_reg: 0.1283 (0.1789)  loss_objectness: 0.0798 (0.1087)  loss_rpn_box_reg: 0.0196 (0.0614)  time: 0.1368  data: 0.0379  max mem: 1709\n",
      "Testing Epoch: [3]  [200/308]  eta: 0:00:14  lr: 0.005000  loss: 0.4847 (0.4968)  loss_classifier: 0.1449 (0.1606)  loss_box_reg: 0.1650 (0.1717)  loss_objectness: 0.0859 (0.1050)  loss_rpn_box_reg: 0.0287 (0.0595)  time: 0.1362  data: 0.0325  max mem: 1709\n",
      "Testing Epoch: [3]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5481 (0.4993)  loss_classifier: 0.1736 (0.1622)  loss_box_reg: 0.1909 (0.1753)  loss_objectness: 0.1013 (0.1043)  loss_rpn_box_reg: 0.0330 (0.0574)  time: 0.1317  data: 0.0377  max mem: 1709\n",
      "Testing Epoch: [3]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.4969 (0.4987)  loss_classifier: 0.1630 (0.1623)  loss_box_reg: 0.1909 (0.1754)  loss_objectness: 0.0958 (0.1041)  loss_rpn_box_reg: 0.0323 (0.0569)  time: 0.1288  data: 0.0353  max mem: 1709\n",
      "Testing Epoch: [3] Total time: 0:00:41 (0.1350 s / it)\n",
      "Training Epoch: [4]  [   0/1229]  eta: 0:05:14  lr: 0.005000  loss: 0.4535 (0.4535)  loss_classifier: 0.1571 (0.1571)  loss_box_reg: 0.1569 (0.1569)  loss_objectness: 0.1173 (0.1173)  loss_rpn_box_reg: 0.0222 (0.0222)  time: 0.2560  data: 0.1290  max mem: 1709\n",
      "Training Epoch: [4]  [  10/1229]  eta: 0:05:30  lr: 0.005000  loss: 0.4535 (0.4686)  loss_classifier: 0.1571 (0.1671)  loss_box_reg: 0.1569 (0.1640)  loss_objectness: 0.1002 (0.1001)  loss_rpn_box_reg: 0.0302 (0.0374)  time: 0.2715  data: 0.1322  max mem: 1709\n",
      "Training Epoch: [4]  [  20/1229]  eta: 0:05:29  lr: 0.005000  loss: 0.4083 (0.4650)  loss_classifier: 0.1313 (0.1581)  loss_box_reg: 0.1203 (0.1452)  loss_objectness: 0.1037 (0.1116)  loss_rpn_box_reg: 0.0302 (0.0501)  time: 0.2735  data: 0.1333  max mem: 1709\n",
      "Training Epoch: [4]  [  30/1229]  eta: 0:05:24  lr: 0.005000  loss: 0.4083 (0.4548)  loss_classifier: 0.1273 (0.1519)  loss_box_reg: 0.0833 (0.1359)  loss_objectness: 0.1169 (0.1157)  loss_rpn_box_reg: 0.0352 (0.0513)  time: 0.2701  data: 0.1328  max mem: 1709\n",
      "Training Epoch: [4]  [  40/1229]  eta: 0:05:21  lr: 0.005000  loss: 0.4101 (0.4636)  loss_classifier: 0.1584 (0.1600)  loss_box_reg: 0.1168 (0.1405)  loss_objectness: 0.1133 (0.1150)  loss_rpn_box_reg: 0.0334 (0.0481)  time: 0.2674  data: 0.1332  max mem: 1709\n",
      "Training Epoch: [4]  [  50/1229]  eta: 0:05:17  lr: 0.005000  loss: 0.4879 (0.4835)  loss_classifier: 0.1748 (0.1658)  loss_box_reg: 0.1331 (0.1441)  loss_objectness: 0.1277 (0.1195)  loss_rpn_box_reg: 0.0334 (0.0542)  time: 0.2676  data: 0.1319  max mem: 1709\n",
      "Training Epoch: [4]  [  60/1229]  eta: 0:05:14  lr: 0.005000  loss: 0.4777 (0.4982)  loss_classifier: 0.1688 (0.1655)  loss_box_reg: 0.1366 (0.1473)  loss_objectness: 0.1341 (0.1254)  loss_rpn_box_reg: 0.0520 (0.0601)  time: 0.2677  data: 0.1324  max mem: 1709\n",
      "Training Epoch: [4]  [  70/1229]  eta: 0:05:13  lr: 0.005000  loss: 0.5164 (0.5209)  loss_classifier: 0.1713 (0.1730)  loss_box_reg: 0.1802 (0.1559)  loss_objectness: 0.1344 (0.1292)  loss_rpn_box_reg: 0.0520 (0.0628)  time: 0.2735  data: 0.1345  max mem: 1709\n",
      "Training Epoch: [4]  [  80/1229]  eta: 0:05:11  lr: 0.005000  loss: 0.5535 (0.5232)  loss_classifier: 0.1980 (0.1762)  loss_box_reg: 0.1946 (0.1603)  loss_objectness: 0.1338 (0.1288)  loss_rpn_box_reg: 0.0264 (0.0580)  time: 0.2770  data: 0.1333  max mem: 1709\n",
      "Training Epoch: [4]  [  90/1229]  eta: 0:05:09  lr: 0.005000  loss: 0.4886 (0.5191)  loss_classifier: 0.1631 (0.1751)  loss_box_reg: 0.1509 (0.1606)  loss_objectness: 0.1269 (0.1270)  loss_rpn_box_reg: 0.0284 (0.0565)  time: 0.2764  data: 0.1353  max mem: 1709\n",
      "Training Epoch: [4]  [ 100/1229]  eta: 0:05:06  lr: 0.005000  loss: 0.4011 (0.5135)  loss_classifier: 0.1493 (0.1745)  loss_box_reg: 0.1383 (0.1630)  loss_objectness: 0.0971 (0.1233)  loss_rpn_box_reg: 0.0184 (0.0528)  time: 0.2738  data: 0.1353  max mem: 1709\n",
      "Training Epoch: [4]  [ 110/1229]  eta: 0:05:03  lr: 0.005000  loss: 0.3988 (0.5076)  loss_classifier: 0.1447 (0.1710)  loss_box_reg: 0.1196 (0.1573)  loss_objectness: 0.0923 (0.1260)  loss_rpn_box_reg: 0.0174 (0.0532)  time: 0.2689  data: 0.1326  max mem: 1709\n",
      "Training Epoch: [4]  [ 120/1229]  eta: 0:05:01  lr: 0.005000  loss: 0.3705 (0.5013)  loss_classifier: 0.1311 (0.1696)  loss_box_reg: 0.1007 (0.1549)  loss_objectness: 0.1062 (0.1241)  loss_rpn_box_reg: 0.0304 (0.0526)  time: 0.2709  data: 0.1328  max mem: 1709\n",
      "Training Epoch: [4]  [ 130/1229]  eta: 0:04:58  lr: 0.005000  loss: 0.4821 (0.5074)  loss_classifier: 0.1776 (0.1716)  loss_box_reg: 0.1300 (0.1567)  loss_objectness: 0.1112 (0.1259)  loss_rpn_box_reg: 0.0374 (0.0532)  time: 0.2749  data: 0.1319  max mem: 1709\n",
      "Training Epoch: [4]  [ 140/1229]  eta: 0:04:55  lr: 0.005000  loss: 0.4991 (0.5025)  loss_classifier: 0.1526 (0.1702)  loss_box_reg: 0.1155 (0.1531)  loss_objectness: 0.1275 (0.1258)  loss_rpn_box_reg: 0.0420 (0.0534)  time: 0.2722  data: 0.1299  max mem: 1709\n",
      "Training Epoch: [4]  [ 150/1229]  eta: 0:04:53  lr: 0.005000  loss: 0.4144 (0.4974)  loss_classifier: 0.1500 (0.1688)  loss_box_reg: 0.1094 (0.1511)  loss_objectness: 0.1345 (0.1260)  loss_rpn_box_reg: 0.0239 (0.0515)  time: 0.2724  data: 0.1322  max mem: 1709\n",
      "Training Epoch: [4]  [ 160/1229]  eta: 0:04:51  lr: 0.005000  loss: 0.4027 (0.4942)  loss_classifier: 0.1295 (0.1667)  loss_box_reg: 0.1031 (0.1493)  loss_objectness: 0.1278 (0.1263)  loss_rpn_box_reg: 0.0235 (0.0519)  time: 0.2778  data: 0.1334  max mem: 1709\n",
      "Training Epoch: [4]  [ 170/1229]  eta: 0:04:48  lr: 0.005000  loss: 0.4264 (0.4900)  loss_classifier: 0.1323 (0.1654)  loss_box_reg: 0.1031 (0.1472)  loss_objectness: 0.1076 (0.1257)  loss_rpn_box_reg: 0.0253 (0.0517)  time: 0.2746  data: 0.1304  max mem: 1709\n",
      "Training Epoch: [4]  [ 180/1229]  eta: 0:04:45  lr: 0.005000  loss: 0.4539 (0.4936)  loss_classifier: 0.1675 (0.1678)  loss_box_reg: 0.1497 (0.1487)  loss_objectness: 0.1217 (0.1256)  loss_rpn_box_reg: 0.0337 (0.0515)  time: 0.2692  data: 0.1305  max mem: 1709\n",
      "Training Epoch: [4]  [ 190/1229]  eta: 0:04:42  lr: 0.005000  loss: 0.4508 (0.4893)  loss_classifier: 0.1733 (0.1666)  loss_box_reg: 0.1434 (0.1482)  loss_objectness: 0.0929 (0.1236)  loss_rpn_box_reg: 0.0286 (0.0509)  time: 0.2702  data: 0.1331  max mem: 1709\n",
      "Training Epoch: [4]  [ 200/1229]  eta: 0:04:39  lr: 0.005000  loss: 0.3303 (0.4834)  loss_classifier: 0.1183 (0.1646)  loss_box_reg: 0.0967 (0.1462)  loss_objectness: 0.0867 (0.1229)  loss_rpn_box_reg: 0.0198 (0.0498)  time: 0.2699  data: 0.1314  max mem: 1709\n",
      "Training Epoch: [4]  [ 210/1229]  eta: 0:04:37  lr: 0.005000  loss: 0.3715 (0.4828)  loss_classifier: 0.1244 (0.1646)  loss_box_reg: 0.1124 (0.1471)  loss_objectness: 0.0924 (0.1223)  loss_rpn_box_reg: 0.0205 (0.0489)  time: 0.2716  data: 0.1297  max mem: 1709\n",
      "Training Epoch: [4]  [ 220/1229]  eta: 0:04:34  lr: 0.005000  loss: 0.5901 (0.4905)  loss_classifier: 0.2170 (0.1676)  loss_box_reg: 0.1481 (0.1510)  loss_objectness: 0.1215 (0.1236)  loss_rpn_box_reg: 0.0355 (0.0484)  time: 0.2774  data: 0.1316  max mem: 1709\n",
      "Training Epoch: [4]  [ 230/1229]  eta: 0:04:32  lr: 0.005000  loss: 0.4040 (0.4877)  loss_classifier: 0.1747 (0.1668)  loss_box_reg: 0.1159 (0.1502)  loss_objectness: 0.1062 (0.1231)  loss_rpn_box_reg: 0.0309 (0.0476)  time: 0.2762  data: 0.1324  max mem: 1709\n",
      "Training Epoch: [4]  [ 240/1229]  eta: 0:04:29  lr: 0.005000  loss: 0.5764 (0.4935)  loss_classifier: 0.2045 (0.1694)  loss_box_reg: 0.1627 (0.1532)  loss_objectness: 0.1062 (0.1237)  loss_rpn_box_reg: 0.0283 (0.0472)  time: 0.2683  data: 0.1314  max mem: 1709\n",
      "Training Epoch: [4]  [ 250/1229]  eta: 0:04:26  lr: 0.005000  loss: 0.6073 (0.4996)  loss_classifier: 0.2312 (0.1719)  loss_box_reg: 0.1990 (0.1554)  loss_objectness: 0.1281 (0.1248)  loss_rpn_box_reg: 0.0311 (0.0474)  time: 0.2648  data: 0.1341  max mem: 1709\n",
      "Training Epoch: [4]  [ 260/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.6073 (0.5013)  loss_classifier: 0.2310 (0.1727)  loss_box_reg: 0.2012 (0.1571)  loss_objectness: 0.1091 (0.1242)  loss_rpn_box_reg: 0.0315 (0.0472)  time: 0.2697  data: 0.1350  max mem: 1709\n",
      "Training Epoch: [4]  [ 270/1229]  eta: 0:04:20  lr: 0.005000  loss: 0.5852 (0.5037)  loss_classifier: 0.1941 (0.1742)  loss_box_reg: 0.1350 (0.1577)  loss_objectness: 0.1088 (0.1249)  loss_rpn_box_reg: 0.0304 (0.0469)  time: 0.2708  data: 0.1329  max mem: 1709\n",
      "Training Epoch: [4]  [ 280/1229]  eta: 0:04:17  lr: 0.005000  loss: 0.4991 (0.5021)  loss_classifier: 0.1887 (0.1741)  loss_box_reg: 0.1350 (0.1568)  loss_objectness: 0.1171 (0.1245)  loss_rpn_box_reg: 0.0304 (0.0466)  time: 0.2717  data: 0.1322  max mem: 1709\n",
      "Training Epoch: [4]  [ 290/1229]  eta: 0:04:15  lr: 0.005000  loss: 0.4587 (0.5021)  loss_classifier: 0.1859 (0.1742)  loss_box_reg: 0.1500 (0.1574)  loss_objectness: 0.1099 (0.1237)  loss_rpn_box_reg: 0.0261 (0.0468)  time: 0.2764  data: 0.1318  max mem: 1709\n",
      "Training Epoch: [4]  [ 300/1229]  eta: 0:04:12  lr: 0.005000  loss: 0.4442 (0.5013)  loss_classifier: 0.1702 (0.1742)  loss_box_reg: 0.1265 (0.1571)  loss_objectness: 0.0962 (0.1238)  loss_rpn_box_reg: 0.0200 (0.0462)  time: 0.2700  data: 0.1301  max mem: 1709\n",
      "Training Epoch: [4]  [ 310/1229]  eta: 0:04:09  lr: 0.005000  loss: 0.3787 (0.4997)  loss_classifier: 0.1466 (0.1733)  loss_box_reg: 0.1056 (0.1565)  loss_objectness: 0.0961 (0.1232)  loss_rpn_box_reg: 0.0237 (0.0466)  time: 0.2699  data: 0.1290  max mem: 1709\n",
      "Training Epoch: [4]  [ 320/1229]  eta: 0:04:07  lr: 0.005000  loss: 0.4734 (0.5038)  loss_classifier: 0.1705 (0.1745)  loss_box_reg: 0.1709 (0.1579)  loss_objectness: 0.1053 (0.1246)  loss_rpn_box_reg: 0.0262 (0.0469)  time: 0.2760  data: 0.1320  max mem: 1709\n",
      "Training Epoch: [4]  [ 330/1229]  eta: 0:04:04  lr: 0.005000  loss: 0.4646 (0.5010)  loss_classifier: 0.1786 (0.1739)  loss_box_reg: 0.1444 (0.1569)  loss_objectness: 0.1053 (0.1239)  loss_rpn_box_reg: 0.0261 (0.0464)  time: 0.2683  data: 0.1334  max mem: 1709\n",
      "Training Epoch: [4]  [ 340/1229]  eta: 0:04:01  lr: 0.005000  loss: 0.4172 (0.5017)  loss_classifier: 0.1527 (0.1732)  loss_box_reg: 0.0998 (0.1564)  loss_objectness: 0.1003 (0.1249)  loss_rpn_box_reg: 0.0261 (0.0472)  time: 0.2648  data: 0.1332  max mem: 1709\n",
      "Training Epoch: [4]  [ 350/1229]  eta: 0:03:58  lr: 0.005000  loss: 0.4585 (0.5005)  loss_classifier: 0.1399 (0.1729)  loss_box_reg: 0.1220 (0.1556)  loss_objectness: 0.1005 (0.1243)  loss_rpn_box_reg: 0.0281 (0.0476)  time: 0.2687  data: 0.1346  max mem: 1709\n",
      "Training Epoch: [4]  [ 360/1229]  eta: 0:03:56  lr: 0.005000  loss: 0.4383 (0.4978)  loss_classifier: 0.1399 (0.1718)  loss_box_reg: 0.1248 (0.1550)  loss_objectness: 0.0850 (0.1234)  loss_rpn_box_reg: 0.0274 (0.0476)  time: 0.2736  data: 0.1353  max mem: 1709\n",
      "Training Epoch: [4]  [ 370/1229]  eta: 0:03:53  lr: 0.005000  loss: 0.4216 (0.4943)  loss_classifier: 0.1055 (0.1705)  loss_box_reg: 0.0930 (0.1538)  loss_objectness: 0.0811 (0.1229)  loss_rpn_box_reg: 0.0207 (0.0471)  time: 0.2737  data: 0.1323  max mem: 1709\n",
      "Training Epoch: [4]  [ 380/1229]  eta: 0:03:50  lr: 0.005000  loss: 0.4934 (0.4979)  loss_classifier: 0.1440 (0.1715)  loss_box_reg: 0.1219 (0.1551)  loss_objectness: 0.1063 (0.1238)  loss_rpn_box_reg: 0.0236 (0.0476)  time: 0.2728  data: 0.1320  max mem: 1709\n",
      "Training Epoch: [4]  [ 390/1229]  eta: 0:03:48  lr: 0.005000  loss: 0.4919 (0.4942)  loss_classifier: 0.1440 (0.1703)  loss_box_reg: 0.1337 (0.1544)  loss_objectness: 0.0885 (0.1226)  loss_rpn_box_reg: 0.0347 (0.0470)  time: 0.2773  data: 0.1326  max mem: 1709\n",
      "Training Epoch: [4]  [ 400/1229]  eta: 0:03:45  lr: 0.005000  loss: 0.3500 (0.4936)  loss_classifier: 0.1194 (0.1697)  loss_box_reg: 0.1089 (0.1543)  loss_objectness: 0.0840 (0.1225)  loss_rpn_box_reg: 0.0250 (0.0471)  time: 0.2698  data: 0.1332  max mem: 1709\n",
      "Training Epoch: [4]  [ 410/1229]  eta: 0:03:42  lr: 0.005000  loss: 0.3500 (0.4913)  loss_classifier: 0.1134 (0.1687)  loss_box_reg: 0.0988 (0.1531)  loss_objectness: 0.1021 (0.1225)  loss_rpn_box_reg: 0.0250 (0.0470)  time: 0.2749  data: 0.1348  max mem: 1709\n",
      "Training Epoch: [4]  [ 420/1229]  eta: 0:03:40  lr: 0.005000  loss: 0.3634 (0.4947)  loss_classifier: 0.1434 (0.1700)  loss_box_reg: 0.1317 (0.1542)  loss_objectness: 0.1372 (0.1228)  loss_rpn_box_reg: 0.0316 (0.0477)  time: 0.2815  data: 0.1341  max mem: 1709\n",
      "Training Epoch: [4]  [ 430/1229]  eta: 0:03:37  lr: 0.005000  loss: 0.4846 (0.4927)  loss_classifier: 0.1311 (0.1687)  loss_box_reg: 0.1313 (0.1528)  loss_objectness: 0.1139 (0.1226)  loss_rpn_box_reg: 0.0367 (0.0486)  time: 0.2693  data: 0.1331  max mem: 1709\n",
      "Training Epoch: [4]  [ 440/1229]  eta: 0:03:34  lr: 0.005000  loss: 0.4227 (0.4930)  loss_classifier: 0.1251 (0.1685)  loss_box_reg: 0.0994 (0.1525)  loss_objectness: 0.1016 (0.1227)  loss_rpn_box_reg: 0.0480 (0.0493)  time: 0.2670  data: 0.1330  max mem: 1709\n",
      "Training Epoch: [4]  [ 450/1229]  eta: 0:03:31  lr: 0.005000  loss: 0.4227 (0.4926)  loss_classifier: 0.1454 (0.1683)  loss_box_reg: 0.1323 (0.1523)  loss_objectness: 0.1197 (0.1230)  loss_rpn_box_reg: 0.0410 (0.0490)  time: 0.2716  data: 0.1343  max mem: 1709\n",
      "Training Epoch: [4]  [ 460/1229]  eta: 0:03:29  lr: 0.005000  loss: 0.3796 (0.4910)  loss_classifier: 0.1404 (0.1679)  loss_box_reg: 0.0948 (0.1520)  loss_objectness: 0.1020 (0.1227)  loss_rpn_box_reg: 0.0176 (0.0485)  time: 0.2734  data: 0.1356  max mem: 1709\n",
      "Training Epoch: [4]  [ 470/1229]  eta: 0:03:26  lr: 0.005000  loss: 0.4148 (0.4918)  loss_classifier: 0.1404 (0.1680)  loss_box_reg: 0.1123 (0.1525)  loss_objectness: 0.0967 (0.1226)  loss_rpn_box_reg: 0.0237 (0.0487)  time: 0.2769  data: 0.1348  max mem: 1709\n",
      "Training Epoch: [4]  [ 480/1229]  eta: 0:03:23  lr: 0.005000  loss: 0.4244 (0.4892)  loss_classifier: 0.1257 (0.1669)  loss_box_reg: 0.1123 (0.1515)  loss_objectness: 0.0980 (0.1220)  loss_rpn_box_reg: 0.0305 (0.0489)  time: 0.2748  data: 0.1305  max mem: 1709\n",
      "Training Epoch: [4]  [ 490/1229]  eta: 0:03:21  lr: 0.005000  loss: 0.4244 (0.4901)  loss_classifier: 0.1387 (0.1671)  loss_box_reg: 0.1168 (0.1514)  loss_objectness: 0.0947 (0.1217)  loss_rpn_box_reg: 0.0366 (0.0499)  time: 0.2744  data: 0.1308  max mem: 1709\n",
      "Training Epoch: [4]  [ 500/1229]  eta: 0:03:18  lr: 0.005000  loss: 0.4474 (0.4879)  loss_classifier: 0.1416 (0.1665)  loss_box_reg: 0.1006 (0.1504)  loss_objectness: 0.0906 (0.1211)  loss_rpn_box_reg: 0.0490 (0.0501)  time: 0.2747  data: 0.1346  max mem: 1709\n",
      "Training Epoch: [4]  [ 510/1229]  eta: 0:03:15  lr: 0.005000  loss: 0.4360 (0.4875)  loss_classifier: 0.1293 (0.1664)  loss_box_reg: 0.0950 (0.1503)  loss_objectness: 0.0906 (0.1211)  loss_rpn_box_reg: 0.0276 (0.0496)  time: 0.2732  data: 0.1352  max mem: 1709\n",
      "Training Epoch: [4]  [ 520/1229]  eta: 0:03:13  lr: 0.005000  loss: 0.4472 (0.4882)  loss_classifier: 0.1547 (0.1667)  loss_box_reg: 0.1045 (0.1504)  loss_objectness: 0.1245 (0.1212)  loss_rpn_box_reg: 0.0341 (0.0500)  time: 0.2762  data: 0.1324  max mem: 1709\n",
      "Training Epoch: [4]  [ 530/1229]  eta: 0:03:10  lr: 0.005000  loss: 0.4052 (0.4888)  loss_classifier: 0.1504 (0.1672)  loss_box_reg: 0.1267 (0.1505)  loss_objectness: 0.1018 (0.1213)  loss_rpn_box_reg: 0.0396 (0.0497)  time: 0.2747  data: 0.1316  max mem: 1709\n",
      "Training Epoch: [4]  [ 540/1229]  eta: 0:03:07  lr: 0.005000  loss: 0.3274 (0.4885)  loss_classifier: 0.1141 (0.1666)  loss_box_reg: 0.1152 (0.1502)  loss_objectness: 0.1095 (0.1213)  loss_rpn_box_reg: 0.0197 (0.0505)  time: 0.2710  data: 0.1341  max mem: 1709\n",
      "Training Epoch: [4]  [ 550/1229]  eta: 0:03:04  lr: 0.005000  loss: 0.3774 (0.4876)  loss_classifier: 0.0938 (0.1661)  loss_box_reg: 0.0875 (0.1494)  loss_objectness: 0.1258 (0.1214)  loss_rpn_box_reg: 0.0197 (0.0507)  time: 0.2670  data: 0.1323  max mem: 1709\n",
      "Training Epoch: [4]  [ 560/1229]  eta: 0:03:02  lr: 0.005000  loss: 0.3916 (0.4880)  loss_classifier: 0.1241 (0.1661)  loss_box_reg: 0.1067 (0.1494)  loss_objectness: 0.1244 (0.1218)  loss_rpn_box_reg: 0.0302 (0.0508)  time: 0.2709  data: 0.1314  max mem: 1709\n",
      "Training Epoch: [4]  [ 570/1229]  eta: 0:02:59  lr: 0.005000  loss: 0.4917 (0.4879)  loss_classifier: 0.1427 (0.1659)  loss_box_reg: 0.1067 (0.1487)  loss_objectness: 0.1313 (0.1224)  loss_rpn_box_reg: 0.0302 (0.0508)  time: 0.2767  data: 0.1327  max mem: 1709\n",
      "Training Epoch: [4]  [ 580/1229]  eta: 0:02:56  lr: 0.005000  loss: 0.5031 (0.4901)  loss_classifier: 0.1676 (0.1668)  loss_box_reg: 0.1187 (0.1492)  loss_objectness: 0.1469 (0.1231)  loss_rpn_box_reg: 0.0372 (0.0510)  time: 0.2708  data: 0.1323  max mem: 1709\n",
      "Training Epoch: [4]  [ 590/1229]  eta: 0:02:53  lr: 0.005000  loss: 0.5997 (0.4912)  loss_classifier: 0.2007 (0.1672)  loss_box_reg: 0.1466 (0.1495)  loss_objectness: 0.1265 (0.1235)  loss_rpn_box_reg: 0.0433 (0.0511)  time: 0.2681  data: 0.1334  max mem: 1709\n",
      "Training Epoch: [4]  [ 600/1229]  eta: 0:02:51  lr: 0.005000  loss: 0.5211 (0.4906)  loss_classifier: 0.1588 (0.1669)  loss_box_reg: 0.1305 (0.1497)  loss_objectness: 0.1178 (0.1231)  loss_rpn_box_reg: 0.0375 (0.0509)  time: 0.2695  data: 0.1348  max mem: 1709\n",
      "Training Epoch: [4]  [ 610/1229]  eta: 0:02:48  lr: 0.005000  loss: 0.3904 (0.4892)  loss_classifier: 0.1334 (0.1665)  loss_box_reg: 0.1279 (0.1496)  loss_objectness: 0.0801 (0.1223)  loss_rpn_box_reg: 0.0368 (0.0508)  time: 0.2717  data: 0.1331  max mem: 1709\n",
      "Training Epoch: [4]  [ 620/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.4877 (0.4900)  loss_classifier: 0.1531 (0.1668)  loss_box_reg: 0.1515 (0.1502)  loss_objectness: 0.0747 (0.1222)  loss_rpn_box_reg: 0.0392 (0.0508)  time: 0.2767  data: 0.1339  max mem: 1709\n",
      "Training Epoch: [4]  [ 630/1229]  eta: 0:02:43  lr: 0.005000  loss: 0.5176 (0.4896)  loss_classifier: 0.1665 (0.1669)  loss_box_reg: 0.1537 (0.1503)  loss_objectness: 0.1045 (0.1220)  loss_rpn_box_reg: 0.0340 (0.0504)  time: 0.2718  data: 0.1354  max mem: 1709\n",
      "Training Epoch: [4]  [ 640/1229]  eta: 0:02:40  lr: 0.005000  loss: 0.4561 (0.4898)  loss_classifier: 0.1810 (0.1669)  loss_box_reg: 0.1256 (0.1503)  loss_objectness: 0.1186 (0.1221)  loss_rpn_box_reg: 0.0278 (0.0504)  time: 0.2703  data: 0.1340  max mem: 1709\n",
      "Training Epoch: [4]  [ 650/1229]  eta: 0:02:37  lr: 0.005000  loss: 0.4674 (0.4911)  loss_classifier: 0.1810 (0.1670)  loss_box_reg: 0.1268 (0.1507)  loss_objectness: 0.1185 (0.1226)  loss_rpn_box_reg: 0.0293 (0.0508)  time: 0.2750  data: 0.1339  max mem: 1709\n",
      "Training Epoch: [4]  [ 660/1229]  eta: 0:02:34  lr: 0.005000  loss: 0.4012 (0.4897)  loss_classifier: 0.1447 (0.1668)  loss_box_reg: 0.1234 (0.1503)  loss_objectness: 0.0937 (0.1223)  loss_rpn_box_reg: 0.0161 (0.0503)  time: 0.2740  data: 0.1332  max mem: 1709\n",
      "Training Epoch: [4]  [ 670/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.3441 (0.4883)  loss_classifier: 0.1219 (0.1662)  loss_box_reg: 0.1033 (0.1497)  loss_objectness: 0.0896 (0.1219)  loss_rpn_box_reg: 0.0163 (0.0505)  time: 0.2700  data: 0.1335  max mem: 1709\n",
      "Training Epoch: [4]  [ 680/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.3478 (0.4877)  loss_classifier: 0.1220 (0.1660)  loss_box_reg: 0.1017 (0.1493)  loss_objectness: 0.1013 (0.1217)  loss_rpn_box_reg: 0.0358 (0.0507)  time: 0.2729  data: 0.1343  max mem: 1709\n",
      "Training Epoch: [4]  [ 690/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.3478 (0.4865)  loss_classifier: 0.1216 (0.1655)  loss_box_reg: 0.1017 (0.1486)  loss_objectness: 0.1013 (0.1218)  loss_rpn_box_reg: 0.0373 (0.0505)  time: 0.2727  data: 0.1345  max mem: 1709\n",
      "Training Epoch: [4]  [ 700/1229]  eta: 0:02:24  lr: 0.005000  loss: 0.3668 (0.4872)  loss_classifier: 0.1216 (0.1653)  loss_box_reg: 0.0933 (0.1488)  loss_objectness: 0.1140 (0.1223)  loss_rpn_box_reg: 0.0390 (0.0508)  time: 0.2722  data: 0.1342  max mem: 1709\n",
      "Training Epoch: [4]  [ 710/1229]  eta: 0:02:21  lr: 0.005000  loss: 0.4065 (0.4867)  loss_classifier: 0.1294 (0.1651)  loss_box_reg: 0.1331 (0.1489)  loss_objectness: 0.1111 (0.1221)  loss_rpn_box_reg: 0.0390 (0.0505)  time: 0.2719  data: 0.1340  max mem: 1709\n",
      "Training Epoch: [4]  [ 720/1229]  eta: 0:02:18  lr: 0.005000  loss: 0.3582 (0.4860)  loss_classifier: 0.1221 (0.1653)  loss_box_reg: 0.1185 (0.1487)  loss_objectness: 0.0991 (0.1218)  loss_rpn_box_reg: 0.0260 (0.0502)  time: 0.2672  data: 0.1339  max mem: 1709\n",
      "Training Epoch: [4]  [ 730/1229]  eta: 0:02:15  lr: 0.005000  loss: 0.4046 (0.4862)  loss_classifier: 0.1322 (0.1650)  loss_box_reg: 0.0779 (0.1483)  loss_objectness: 0.1104 (0.1224)  loss_rpn_box_reg: 0.0281 (0.0504)  time: 0.2722  data: 0.1319  max mem: 1709\n",
      "Training Epoch: [4]  [ 740/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.4209 (0.4856)  loss_classifier: 0.1633 (0.1649)  loss_box_reg: 0.0883 (0.1482)  loss_objectness: 0.1129 (0.1224)  loss_rpn_box_reg: 0.0256 (0.0501)  time: 0.2729  data: 0.1314  max mem: 1709\n",
      "Training Epoch: [4]  [ 750/1229]  eta: 0:02:10  lr: 0.005000  loss: 0.3625 (0.4849)  loss_classifier: 0.1376 (0.1648)  loss_box_reg: 0.1370 (0.1482)  loss_objectness: 0.0899 (0.1220)  loss_rpn_box_reg: 0.0248 (0.0498)  time: 0.2655  data: 0.1321  max mem: 1709\n",
      "Training Epoch: [4]  [ 760/1229]  eta: 0:02:07  lr: 0.005000  loss: 0.3586 (0.4849)  loss_classifier: 0.1282 (0.1646)  loss_box_reg: 0.1045 (0.1478)  loss_objectness: 0.0942 (0.1222)  loss_rpn_box_reg: 0.0235 (0.0503)  time: 0.2730  data: 0.1318  max mem: 1709\n",
      "Training Epoch: [4]  [ 770/1229]  eta: 0:02:04  lr: 0.005000  loss: 0.4526 (0.4878)  loss_classifier: 0.1455 (0.1655)  loss_box_reg: 0.1173 (0.1487)  loss_objectness: 0.0996 (0.1225)  loss_rpn_box_reg: 0.0335 (0.0512)  time: 0.2772  data: 0.1328  max mem: 1709\n",
      "Training Epoch: [4]  [ 780/1229]  eta: 0:02:02  lr: 0.005000  loss: 0.5986 (0.4887)  loss_classifier: 0.1797 (0.1654)  loss_box_reg: 0.1823 (0.1487)  loss_objectness: 0.1148 (0.1227)  loss_rpn_box_reg: 0.0547 (0.0519)  time: 0.2679  data: 0.1332  max mem: 1709\n",
      "Training Epoch: [4]  [ 790/1229]  eta: 0:01:59  lr: 0.005000  loss: 0.5723 (0.4902)  loss_classifier: 0.1624 (0.1658)  loss_box_reg: 0.1823 (0.1493)  loss_objectness: 0.1186 (0.1230)  loss_rpn_box_reg: 0.0478 (0.0520)  time: 0.2718  data: 0.1325  max mem: 1709\n",
      "Training Epoch: [4]  [ 800/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.3588 (0.4889)  loss_classifier: 0.1223 (0.1654)  loss_box_reg: 0.1137 (0.1489)  loss_objectness: 0.0956 (0.1225)  loss_rpn_box_reg: 0.0304 (0.0521)  time: 0.2795  data: 0.1321  max mem: 1709\n",
      "Training Epoch: [4]  [ 810/1229]  eta: 0:01:54  lr: 0.005000  loss: 0.3680 (0.4910)  loss_classifier: 0.1309 (0.1659)  loss_box_reg: 0.1207 (0.1493)  loss_objectness: 0.0803 (0.1229)  loss_rpn_box_reg: 0.0233 (0.0528)  time: 0.2754  data: 0.1316  max mem: 1709\n",
      "Training Epoch: [4]  [ 820/1229]  eta: 0:01:51  lr: 0.005000  loss: 0.5464 (0.4924)  loss_classifier: 0.2042 (0.1664)  loss_box_reg: 0.1862 (0.1499)  loss_objectness: 0.1138 (0.1232)  loss_rpn_box_reg: 0.0282 (0.0528)  time: 0.2747  data: 0.1335  max mem: 1709\n",
      "Training Epoch: [4]  [ 830/1229]  eta: 0:01:48  lr: 0.005000  loss: 0.5464 (0.4937)  loss_classifier: 0.1803 (0.1667)  loss_box_reg: 0.1907 (0.1504)  loss_objectness: 0.1138 (0.1232)  loss_rpn_box_reg: 0.0298 (0.0534)  time: 0.2814  data: 0.1328  max mem: 1709\n",
      "Training Epoch: [4]  [ 840/1229]  eta: 0:01:45  lr: 0.005000  loss: 0.5241 (0.4944)  loss_classifier: 0.1672 (0.1670)  loss_box_reg: 0.1558 (0.1504)  loss_objectness: 0.1105 (0.1234)  loss_rpn_box_reg: 0.0376 (0.0537)  time: 0.2798  data: 0.1333  max mem: 1709\n",
      "Training Epoch: [4]  [ 850/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.4947 (0.4944)  loss_classifier: 0.1613 (0.1670)  loss_box_reg: 0.1311 (0.1505)  loss_objectness: 0.1082 (0.1232)  loss_rpn_box_reg: 0.0376 (0.0538)  time: 0.2761  data: 0.1352  max mem: 1709\n",
      "Training Epoch: [4]  [ 860/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.5894 (0.4963)  loss_classifier: 0.1608 (0.1675)  loss_box_reg: 0.1092 (0.1509)  loss_objectness: 0.1245 (0.1237)  loss_rpn_box_reg: 0.0463 (0.0542)  time: 0.2748  data: 0.1358  max mem: 1709\n",
      "Training Epoch: [4]  [ 870/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.5610 (0.4967)  loss_classifier: 0.1732 (0.1677)  loss_box_reg: 0.1539 (0.1510)  loss_objectness: 0.1429 (0.1240)  loss_rpn_box_reg: 0.0395 (0.0541)  time: 0.2700  data: 0.1362  max mem: 1709\n",
      "Training Epoch: [4]  [ 880/1229]  eta: 0:01:35  lr: 0.005000  loss: 0.3972 (0.4954)  loss_classifier: 0.1405 (0.1673)  loss_box_reg: 0.1384 (0.1509)  loss_objectness: 0.0868 (0.1235)  loss_rpn_box_reg: 0.0264 (0.0537)  time: 0.2677  data: 0.1333  max mem: 1709\n",
      "Training Epoch: [4]  [ 890/1229]  eta: 0:01:32  lr: 0.005000  loss: 0.3929 (0.4958)  loss_classifier: 0.1405 (0.1674)  loss_box_reg: 0.1339 (0.1510)  loss_objectness: 0.0951 (0.1235)  loss_rpn_box_reg: 0.0236 (0.0539)  time: 0.2680  data: 0.1306  max mem: 1709\n",
      "Training Epoch: [4]  [ 900/1229]  eta: 0:01:29  lr: 0.005000  loss: 0.3936 (0.4958)  loss_classifier: 0.1406 (0.1673)  loss_box_reg: 0.1213 (0.1508)  loss_objectness: 0.1052 (0.1235)  loss_rpn_box_reg: 0.0424 (0.0542)  time: 0.2738  data: 0.1311  max mem: 1709\n",
      "Training Epoch: [4]  [ 910/1229]  eta: 0:01:26  lr: 0.005000  loss: 0.3927 (0.4949)  loss_classifier: 0.1235 (0.1670)  loss_box_reg: 0.1040 (0.1505)  loss_objectness: 0.0937 (0.1232)  loss_rpn_box_reg: 0.0320 (0.0542)  time: 0.2754  data: 0.1326  max mem: 1709\n",
      "Training Epoch: [4]  [ 920/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.4913 (0.4965)  loss_classifier: 0.1810 (0.1676)  loss_box_reg: 0.1356 (0.1510)  loss_objectness: 0.0997 (0.1233)  loss_rpn_box_reg: 0.0362 (0.0546)  time: 0.2683  data: 0.1335  max mem: 1709\n",
      "Training Epoch: [4]  [ 930/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.5319 (0.4964)  loss_classifier: 0.2012 (0.1676)  loss_box_reg: 0.1548 (0.1510)  loss_objectness: 0.1022 (0.1230)  loss_rpn_box_reg: 0.0364 (0.0548)  time: 0.2686  data: 0.1339  max mem: 1709\n",
      "Training Epoch: [4]  [ 940/1229]  eta: 0:01:18  lr: 0.005000  loss: 0.3270 (0.4963)  loss_classifier: 0.1019 (0.1675)  loss_box_reg: 0.0854 (0.1510)  loss_objectness: 0.1047 (0.1230)  loss_rpn_box_reg: 0.0296 (0.0548)  time: 0.2704  data: 0.1312  max mem: 1709\n",
      "Training Epoch: [4]  [ 950/1229]  eta: 0:01:15  lr: 0.005000  loss: 0.4839 (0.4969)  loss_classifier: 0.1193 (0.1674)  loss_box_reg: 0.1251 (0.1513)  loss_objectness: 0.1172 (0.1231)  loss_rpn_box_reg: 0.0326 (0.0551)  time: 0.2720  data: 0.1296  max mem: 1709\n",
      "Training Epoch: [4]  [ 960/1229]  eta: 0:01:13  lr: 0.005000  loss: 0.4980 (0.4973)  loss_classifier: 0.1460 (0.1675)  loss_box_reg: 0.1401 (0.1517)  loss_objectness: 0.1065 (0.1230)  loss_rpn_box_reg: 0.0485 (0.0550)  time: 0.2688  data: 0.1307  max mem: 1709\n",
      "Training Epoch: [4]  [ 970/1229]  eta: 0:01:10  lr: 0.005000  loss: 0.5798 (0.4982)  loss_classifier: 0.1986 (0.1679)  loss_box_reg: 0.1753 (0.1523)  loss_objectness: 0.1065 (0.1228)  loss_rpn_box_reg: 0.0485 (0.0552)  time: 0.2679  data: 0.1310  max mem: 1709\n",
      "Training Epoch: [4]  [ 980/1229]  eta: 0:01:07  lr: 0.005000  loss: 0.6062 (0.4993)  loss_classifier: 0.1986 (0.1682)  loss_box_reg: 0.1506 (0.1527)  loss_objectness: 0.1173 (0.1231)  loss_rpn_box_reg: 0.0493 (0.0552)  time: 0.2678  data: 0.1285  max mem: 1709\n",
      "Training Epoch: [4]  [ 990/1229]  eta: 0:01:05  lr: 0.005000  loss: 0.4731 (0.4982)  loss_classifier: 0.1592 (0.1680)  loss_box_reg: 0.1137 (0.1524)  loss_objectness: 0.1036 (0.1229)  loss_rpn_box_reg: 0.0224 (0.0549)  time: 0.2685  data: 0.1295  max mem: 1709\n",
      "Training Epoch: [4]  [1000/1229]  eta: 0:01:02  lr: 0.005000  loss: 0.3409 (0.4971)  loss_classifier: 0.1215 (0.1676)  loss_box_reg: 0.1039 (0.1520)  loss_objectness: 0.0868 (0.1228)  loss_rpn_box_reg: 0.0164 (0.0546)  time: 0.2739  data: 0.1323  max mem: 1709\n",
      "Training Epoch: [4]  [1010/1229]  eta: 0:00:59  lr: 0.005000  loss: 0.4077 (0.4975)  loss_classifier: 0.1348 (0.1679)  loss_box_reg: 0.0977 (0.1523)  loss_objectness: 0.0868 (0.1229)  loss_rpn_box_reg: 0.0193 (0.0544)  time: 0.2783  data: 0.1340  max mem: 1709\n",
      "Training Epoch: [4]  [1020/1229]  eta: 0:00:56  lr: 0.005000  loss: 0.4782 (0.4974)  loss_classifier: 0.1388 (0.1678)  loss_box_reg: 0.0898 (0.1521)  loss_objectness: 0.1293 (0.1230)  loss_rpn_box_reg: 0.0304 (0.0545)  time: 0.2755  data: 0.1339  max mem: 1709\n",
      "Training Epoch: [4]  [1030/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.4342 (0.4977)  loss_classifier: 0.1388 (0.1680)  loss_box_reg: 0.0949 (0.1524)  loss_objectness: 0.1204 (0.1227)  loss_rpn_box_reg: 0.0432 (0.0546)  time: 0.2686  data: 0.1338  max mem: 1709\n",
      "Training Epoch: [4]  [1040/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.5150 (0.4975)  loss_classifier: 0.1768 (0.1681)  loss_box_reg: 0.1290 (0.1523)  loss_objectness: 0.0895 (0.1227)  loss_rpn_box_reg: 0.0295 (0.0545)  time: 0.2712  data: 0.1341  max mem: 1709\n",
      "Training Epoch: [4]  [1050/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.5190 (0.4985)  loss_classifier: 0.2063 (0.1685)  loss_box_reg: 0.1849 (0.1527)  loss_objectness: 0.0967 (0.1228)  loss_rpn_box_reg: 0.0295 (0.0546)  time: 0.2691  data: 0.1335  max mem: 1709\n",
      "Training Epoch: [4]  [1060/1229]  eta: 0:00:46  lr: 0.005000  loss: 0.4908 (0.4981)  loss_classifier: 0.2047 (0.1685)  loss_box_reg: 0.1400 (0.1525)  loss_objectness: 0.1179 (0.1228)  loss_rpn_box_reg: 0.0200 (0.0544)  time: 0.2706  data: 0.1344  max mem: 1709\n",
      "Training Epoch: [4]  [1070/1229]  eta: 0:00:43  lr: 0.005000  loss: 0.3158 (0.4967)  loss_classifier: 0.1216 (0.1680)  loss_box_reg: 0.0915 (0.1521)  loss_objectness: 0.0721 (0.1223)  loss_rpn_box_reg: 0.0189 (0.0542)  time: 0.2756  data: 0.1363  max mem: 1709\n",
      "Training Epoch: [4]  [1080/1229]  eta: 0:00:40  lr: 0.005000  loss: 0.3639 (0.4961)  loss_classifier: 0.0919 (0.1677)  loss_box_reg: 0.1013 (0.1519)  loss_objectness: 0.0721 (0.1222)  loss_rpn_box_reg: 0.0373 (0.0543)  time: 0.2779  data: 0.1359  max mem: 1709\n",
      "Training Epoch: [4]  [1090/1229]  eta: 0:00:37  lr: 0.005000  loss: 0.3697 (0.4962)  loss_classifier: 0.1489 (0.1679)  loss_box_reg: 0.1182 (0.1522)  loss_objectness: 0.0819 (0.1220)  loss_rpn_box_reg: 0.0373 (0.0541)  time: 0.2765  data: 0.1327  max mem: 1709\n",
      "Training Epoch: [4]  [1100/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.3747 (0.4956)  loss_classifier: 0.1489 (0.1677)  loss_box_reg: 0.1186 (0.1520)  loss_objectness: 0.1053 (0.1219)  loss_rpn_box_reg: 0.0291 (0.0539)  time: 0.2727  data: 0.1331  max mem: 1709\n",
      "Training Epoch: [4]  [1110/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.4564 (0.4975)  loss_classifier: 0.1652 (0.1683)  loss_box_reg: 0.1661 (0.1527)  loss_objectness: 0.1078 (0.1225)  loss_rpn_box_reg: 0.0367 (0.0541)  time: 0.2744  data: 0.1345  max mem: 1709\n",
      "Training Epoch: [4]  [1120/1229]  eta: 0:00:29  lr: 0.005000  loss: 0.5335 (0.4978)  loss_classifier: 0.1984 (0.1684)  loss_box_reg: 0.1566 (0.1527)  loss_objectness: 0.1505 (0.1228)  loss_rpn_box_reg: 0.0381 (0.0539)  time: 0.2703  data: 0.1336  max mem: 1709\n",
      "Training Epoch: [4]  [1130/1229]  eta: 0:00:26  lr: 0.005000  loss: 0.4491 (0.4973)  loss_classifier: 0.1539 (0.1681)  loss_box_reg: 0.1219 (0.1524)  loss_objectness: 0.1389 (0.1229)  loss_rpn_box_reg: 0.0325 (0.0539)  time: 0.2678  data: 0.1298  max mem: 1709\n",
      "Training Epoch: [4]  [1140/1229]  eta: 0:00:24  lr: 0.005000  loss: 0.4196 (0.4973)  loss_classifier: 0.1428 (0.1682)  loss_box_reg: 0.1050 (0.1523)  loss_objectness: 0.1126 (0.1230)  loss_rpn_box_reg: 0.0329 (0.0539)  time: 0.2701  data: 0.1299  max mem: 1709\n",
      "Training Epoch: [4]  [1150/1229]  eta: 0:00:21  lr: 0.005000  loss: 0.4300 (0.4971)  loss_classifier: 0.1528 (0.1680)  loss_box_reg: 0.1069 (0.1521)  loss_objectness: 0.1281 (0.1231)  loss_rpn_box_reg: 0.0370 (0.0540)  time: 0.2715  data: 0.1339  max mem: 1709\n",
      "Training Epoch: [4]  [1160/1229]  eta: 0:00:18  lr: 0.005000  loss: 0.4973 (0.4975)  loss_classifier: 0.1481 (0.1680)  loss_box_reg: 0.1307 (0.1521)  loss_objectness: 0.1245 (0.1231)  loss_rpn_box_reg: 0.0390 (0.0543)  time: 0.2678  data: 0.1349  max mem: 1709\n",
      "Training Epoch: [4]  [1170/1229]  eta: 0:00:16  lr: 0.005000  loss: 0.4207 (0.4959)  loss_classifier: 0.1279 (0.1675)  loss_box_reg: 0.0950 (0.1514)  loss_objectness: 0.0992 (0.1229)  loss_rpn_box_reg: 0.0356 (0.0541)  time: 0.2657  data: 0.1320  max mem: 1709\n",
      "Training Epoch: [4]  [1180/1229]  eta: 0:00:13  lr: 0.005000  loss: 0.2517 (0.4955)  loss_classifier: 0.0900 (0.1674)  loss_box_reg: 0.0620 (0.1510)  loss_objectness: 0.0848 (0.1230)  loss_rpn_box_reg: 0.0356 (0.0541)  time: 0.2724  data: 0.1312  max mem: 1709\n",
      "Training Epoch: [4]  [1190/1229]  eta: 0:00:10  lr: 0.005000  loss: 0.2994 (0.4944)  loss_classifier: 0.0939 (0.1669)  loss_box_reg: 0.0710 (0.1504)  loss_objectness: 0.1177 (0.1229)  loss_rpn_box_reg: 0.0494 (0.0542)  time: 0.2790  data: 0.1331  max mem: 1709\n",
      "Training Epoch: [4]  [1200/1229]  eta: 0:00:07  lr: 0.005000  loss: 0.4485 (0.4945)  loss_classifier: 0.1099 (0.1670)  loss_box_reg: 0.0977 (0.1506)  loss_objectness: 0.1216 (0.1228)  loss_rpn_box_reg: 0.0330 (0.0541)  time: 0.2807  data: 0.1334  max mem: 1709\n",
      "Training Epoch: [4]  [1210/1229]  eta: 0:00:05  lr: 0.005000  loss: 0.4358 (0.4936)  loss_classifier: 0.1438 (0.1668)  loss_box_reg: 0.1124 (0.1503)  loss_objectness: 0.0964 (0.1227)  loss_rpn_box_reg: 0.0254 (0.0539)  time: 0.2791  data: 0.1308  max mem: 1709\n",
      "Training Epoch: [4]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.3617 (0.4932)  loss_classifier: 0.1365 (0.1667)  loss_box_reg: 0.0964 (0.1499)  loss_objectness: 0.0964 (0.1227)  loss_rpn_box_reg: 0.0230 (0.0538)  time: 0.2748  data: 0.1302  max mem: 1709\n",
      "Training Epoch: [4]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4550 (0.4938)  loss_classifier: 0.1537 (0.1670)  loss_box_reg: 0.0982 (0.1505)  loss_objectness: 0.0964 (0.1226)  loss_rpn_box_reg: 0.0230 (0.0538)  time: 0.2749  data: 0.1327  max mem: 1709\n",
      "Training Epoch: [4] Total time: 0:05:34 (0.2725 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:55  model_time: 0.3420 (0.3420)  evaluator_time: 0.0030 (0.0030)  time: 0.3760  data: 0.0290  max mem: 1709\n",
      "Test:  [100/308]  eta: 0:00:27  model_time: 0.0790 (0.0841)  evaluator_time: 0.0080 (0.0107)  time: 0.1354  data: 0.0408  max mem: 1709\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0850 (0.0832)  evaluator_time: 0.0040 (0.0098)  time: 0.1243  data: 0.0306  max mem: 1709\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0740 (0.0822)  evaluator_time: 0.0050 (0.0095)  time: 0.1231  data: 0.0346  max mem: 1709\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0740 (0.0821)  evaluator_time: 0.0040 (0.0095)  time: 0.1187  data: 0.0330  max mem: 1709\n",
      "Test: Total time: 0:00:39 (0.1279 s / it)\n",
      "Averaged stats: model_time: 0.0740 (0.0821)  evaluator_time: 0.0040 (0.0095)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.20s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.134\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.034\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.290\n",
      "Testing Epoch: [4]  [  0/308]  eta: 0:00:37  lr: 0.005000  loss: 0.1748 (0.1748)  loss_classifier: 0.0686 (0.0686)  loss_box_reg: 0.0632 (0.0632)  loss_objectness: 0.0290 (0.0290)  loss_rpn_box_reg: 0.0139 (0.0139)  time: 0.1230  data: 0.0290  max mem: 1709\n",
      "Testing Epoch: [4]  [100/308]  eta: 0:00:28  lr: 0.005000  loss: 0.3147 (0.4873)  loss_classifier: 0.1273 (0.1558)  loss_box_reg: 0.1287 (0.1648)  loss_objectness: 0.0582 (0.1098)  loss_rpn_box_reg: 0.0222 (0.0569)  time: 0.1400  data: 0.0376  max mem: 1714\n",
      "Testing Epoch: [4]  [200/308]  eta: 0:00:14  lr: 0.005000  loss: 0.3621 (0.4626)  loss_classifier: 0.1306 (0.1501)  loss_box_reg: 0.1353 (0.1562)  loss_objectness: 0.0729 (0.1017)  loss_rpn_box_reg: 0.0202 (0.0545)  time: 0.1373  data: 0.0320  max mem: 1714\n",
      "Testing Epoch: [4]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.4988 (0.4627)  loss_classifier: 0.1544 (0.1510)  loss_box_reg: 0.1216 (0.1593)  loss_objectness: 0.0926 (0.0994)  loss_rpn_box_reg: 0.0311 (0.0530)  time: 0.1340  data: 0.0375  max mem: 1751\n",
      "Testing Epoch: [4]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.4549 (0.4625)  loss_classifier: 0.1544 (0.1512)  loss_box_reg: 0.1482 (0.1594)  loss_objectness: 0.0849 (0.0994)  loss_rpn_box_reg: 0.0311 (0.0526)  time: 0.1315  data: 0.0355  max mem: 1751\n",
      "Testing Epoch: [4] Total time: 0:00:42 (0.1379 s / it)\n",
      "Training Epoch: [5]  [   0/1229]  eta: 0:05:44  lr: 0.005000  loss: 0.2675 (0.2675)  loss_classifier: 0.0948 (0.0948)  loss_box_reg: 0.1002 (0.1002)  loss_objectness: 0.0668 (0.0668)  loss_rpn_box_reg: 0.0057 (0.0057)  time: 0.2800  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [5]  [  10/1229]  eta: 0:05:58  lr: 0.005000  loss: 0.4629 (0.4478)  loss_classifier: 0.1436 (0.1526)  loss_box_reg: 0.1002 (0.1181)  loss_objectness: 0.1096 (0.1257)  loss_rpn_box_reg: 0.0287 (0.0513)  time: 0.2940  data: 0.1494  max mem: 1751\n",
      "Training Epoch: [5]  [  20/1229]  eta: 0:05:57  lr: 0.005000  loss: 0.4601 (0.4550)  loss_classifier: 0.1521 (0.1601)  loss_box_reg: 0.1346 (0.1274)  loss_objectness: 0.0963 (0.1134)  loss_rpn_box_reg: 0.0311 (0.0540)  time: 0.2962  data: 0.1502  max mem: 1751\n",
      "Training Epoch: [5]  [  30/1229]  eta: 0:05:56  lr: 0.005000  loss: 0.3847 (0.4324)  loss_classifier: 0.1454 (0.1496)  loss_box_reg: 0.1072 (0.1188)  loss_objectness: 0.0909 (0.1091)  loss_rpn_box_reg: 0.0311 (0.0550)  time: 0.2987  data: 0.1531  max mem: 1751\n",
      "Training Epoch: [5]  [  40/1229]  eta: 0:05:53  lr: 0.005000  loss: 0.3929 (0.4627)  loss_classifier: 0.1421 (0.1587)  loss_box_reg: 0.1031 (0.1365)  loss_objectness: 0.0945 (0.1122)  loss_rpn_box_reg: 0.0310 (0.0553)  time: 0.2987  data: 0.1591  max mem: 1751\n",
      "Training Epoch: [5]  [  50/1229]  eta: 0:05:51  lr: 0.005000  loss: 0.4010 (0.4743)  loss_classifier: 0.1465 (0.1590)  loss_box_reg: 0.1459 (0.1424)  loss_objectness: 0.0922 (0.1149)  loss_rpn_box_reg: 0.0310 (0.0581)  time: 0.2992  data: 0.1592  max mem: 1751\n",
      "Training Epoch: [5]  [  60/1229]  eta: 0:05:47  lr: 0.005000  loss: 0.4323 (0.4835)  loss_classifier: 0.1774 (0.1649)  loss_box_reg: 0.1172 (0.1460)  loss_objectness: 0.0922 (0.1160)  loss_rpn_box_reg: 0.0299 (0.0565)  time: 0.2968  data: 0.1582  max mem: 1751\n",
      "Training Epoch: [5]  [  70/1229]  eta: 0:05:44  lr: 0.005000  loss: 0.4323 (0.4778)  loss_classifier: 0.1774 (0.1639)  loss_box_reg: 0.1172 (0.1447)  loss_objectness: 0.1024 (0.1154)  loss_rpn_box_reg: 0.0272 (0.0538)  time: 0.2962  data: 0.1601  max mem: 1751\n",
      "Training Epoch: [5]  [  80/1229]  eta: 0:05:41  lr: 0.005000  loss: 0.6021 (0.5046)  loss_classifier: 0.2057 (0.1733)  loss_box_reg: 0.1747 (0.1577)  loss_objectness: 0.1287 (0.1176)  loss_rpn_box_reg: 0.0272 (0.0560)  time: 0.2987  data: 0.1620  max mem: 1751\n",
      "Training Epoch: [5]  [  90/1229]  eta: 0:05:39  lr: 0.005000  loss: 0.6576 (0.5164)  loss_classifier: 0.2166 (0.1765)  loss_box_reg: 0.2065 (0.1584)  loss_objectness: 0.1470 (0.1228)  loss_rpn_box_reg: 0.0482 (0.0586)  time: 0.3001  data: 0.1643  max mem: 1751\n",
      "Training Epoch: [5]  [ 100/1229]  eta: 0:05:36  lr: 0.005000  loss: 0.5699 (0.5187)  loss_classifier: 0.1794 (0.1781)  loss_box_reg: 0.1566 (0.1601)  loss_objectness: 0.1181 (0.1221)  loss_rpn_box_reg: 0.0497 (0.0583)  time: 0.3024  data: 0.1662  max mem: 1751\n",
      "Training Epoch: [5]  [ 110/1229]  eta: 0:05:34  lr: 0.005000  loss: 0.4825 (0.5272)  loss_classifier: 0.1686 (0.1805)  loss_box_reg: 0.1566 (0.1617)  loss_objectness: 0.1204 (0.1247)  loss_rpn_box_reg: 0.0509 (0.0602)  time: 0.3015  data: 0.1656  max mem: 1751\n",
      "Training Epoch: [5]  [ 120/1229]  eta: 0:05:29  lr: 0.005000  loss: 0.4454 (0.5157)  loss_classifier: 0.1493 (0.1771)  loss_box_reg: 0.1515 (0.1590)  loss_objectness: 0.1160 (0.1222)  loss_rpn_box_reg: 0.0415 (0.0573)  time: 0.2928  data: 0.1583  max mem: 1751\n",
      "Training Epoch: [5]  [ 130/1229]  eta: 0:05:26  lr: 0.005000  loss: 0.3280 (0.5050)  loss_classifier: 0.1268 (0.1739)  loss_box_reg: 0.0944 (0.1537)  loss_objectness: 0.0951 (0.1210)  loss_rpn_box_reg: 0.0151 (0.0563)  time: 0.2880  data: 0.1519  max mem: 1751\n",
      "Training Epoch: [5]  [ 140/1229]  eta: 0:05:22  lr: 0.005000  loss: 0.3539 (0.5057)  loss_classifier: 0.1179 (0.1743)  loss_box_reg: 0.0995 (0.1558)  loss_objectness: 0.0951 (0.1202)  loss_rpn_box_reg: 0.0199 (0.0554)  time: 0.2869  data: 0.1503  max mem: 1751\n",
      "Training Epoch: [5]  [ 150/1229]  eta: 0:05:19  lr: 0.005000  loss: 0.4220 (0.5085)  loss_classifier: 0.1534 (0.1764)  loss_box_reg: 0.1360 (0.1583)  loss_objectness: 0.1047 (0.1196)  loss_rpn_box_reg: 0.0252 (0.0542)  time: 0.2892  data: 0.1507  max mem: 1751\n",
      "Training Epoch: [5]  [ 160/1229]  eta: 0:05:15  lr: 0.005000  loss: 0.3966 (0.5063)  loss_classifier: 0.1534 (0.1762)  loss_box_reg: 0.1212 (0.1572)  loss_objectness: 0.1132 (0.1201)  loss_rpn_box_reg: 0.0255 (0.0528)  time: 0.2909  data: 0.1523  max mem: 1751\n",
      "Training Epoch: [5]  [ 170/1229]  eta: 0:05:12  lr: 0.005000  loss: 0.3966 (0.5067)  loss_classifier: 0.1493 (0.1768)  loss_box_reg: 0.1310 (0.1570)  loss_objectness: 0.0938 (0.1211)  loss_rpn_box_reg: 0.0203 (0.0518)  time: 0.2904  data: 0.1534  max mem: 1751\n",
      "Training Epoch: [5]  [ 180/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.4441 (0.5082)  loss_classifier: 0.1740 (0.1772)  loss_box_reg: 0.1373 (0.1575)  loss_objectness: 0.0938 (0.1212)  loss_rpn_box_reg: 0.0213 (0.0523)  time: 0.2980  data: 0.1562  max mem: 1751\n",
      "Training Epoch: [5]  [ 190/1229]  eta: 0:05:07  lr: 0.005000  loss: 0.4364 (0.5068)  loss_classifier: 0.1666 (0.1762)  loss_box_reg: 0.1354 (0.1573)  loss_objectness: 0.1077 (0.1211)  loss_rpn_box_reg: 0.0300 (0.0521)  time: 0.2984  data: 0.1563  max mem: 1751\n",
      "Training Epoch: [5]  [ 200/1229]  eta: 0:05:03  lr: 0.005000  loss: 0.3920 (0.5069)  loss_classifier: 0.1462 (0.1763)  loss_box_reg: 0.1057 (0.1586)  loss_objectness: 0.0947 (0.1204)  loss_rpn_box_reg: 0.0284 (0.0515)  time: 0.2924  data: 0.1558  max mem: 1751\n",
      "Training Epoch: [5]  [ 210/1229]  eta: 0:05:00  lr: 0.005000  loss: 0.4841 (0.5098)  loss_classifier: 0.1530 (0.1775)  loss_box_reg: 0.1210 (0.1594)  loss_objectness: 0.1271 (0.1212)  loss_rpn_box_reg: 0.0319 (0.0517)  time: 0.2891  data: 0.1549  max mem: 1751\n",
      "Training Epoch: [5]  [ 220/1229]  eta: 0:04:57  lr: 0.005000  loss: 0.4715 (0.5047)  loss_classifier: 0.1410 (0.1751)  loss_box_reg: 0.1278 (0.1583)  loss_objectness: 0.1004 (0.1200)  loss_rpn_box_reg: 0.0319 (0.0514)  time: 0.2895  data: 0.1527  max mem: 1751\n",
      "Training Epoch: [5]  [ 230/1229]  eta: 0:04:55  lr: 0.005000  loss: 0.3963 (0.5049)  loss_classifier: 0.1089 (0.1741)  loss_box_reg: 0.0990 (0.1576)  loss_objectness: 0.0780 (0.1207)  loss_rpn_box_reg: 0.0365 (0.0525)  time: 0.2995  data: 0.1517  max mem: 1751\n",
      "Training Epoch: [5]  [ 240/1229]  eta: 0:04:51  lr: 0.005000  loss: 0.4270 (0.5021)  loss_classifier: 0.1351 (0.1729)  loss_box_reg: 0.0917 (0.1559)  loss_objectness: 0.0985 (0.1208)  loss_rpn_box_reg: 0.0290 (0.0526)  time: 0.2982  data: 0.1515  max mem: 1751\n",
      "Training Epoch: [5]  [ 250/1229]  eta: 0:04:48  lr: 0.005000  loss: 0.4654 (0.5015)  loss_classifier: 0.1367 (0.1722)  loss_box_reg: 0.1104 (0.1556)  loss_objectness: 0.0985 (0.1207)  loss_rpn_box_reg: 0.0287 (0.0529)  time: 0.2874  data: 0.1519  max mem: 1751\n",
      "Training Epoch: [5]  [ 260/1229]  eta: 0:04:45  lr: 0.005000  loss: 0.4823 (0.5007)  loss_classifier: 0.1497 (0.1716)  loss_box_reg: 0.1140 (0.1554)  loss_objectness: 0.1236 (0.1211)  loss_rpn_box_reg: 0.0219 (0.0527)  time: 0.2880  data: 0.1544  max mem: 1751\n",
      "Training Epoch: [5]  [ 270/1229]  eta: 0:04:42  lr: 0.005000  loss: 0.4715 (0.4992)  loss_classifier: 0.1461 (0.1712)  loss_box_reg: 0.1140 (0.1552)  loss_objectness: 0.1186 (0.1202)  loss_rpn_box_reg: 0.0219 (0.0527)  time: 0.2914  data: 0.1549  max mem: 1751\n",
      "Training Epoch: [5]  [ 280/1229]  eta: 0:04:39  lr: 0.005000  loss: 0.3488 (0.4942)  loss_classifier: 0.1235 (0.1693)  loss_box_reg: 0.1031 (0.1532)  loss_objectness: 0.0865 (0.1193)  loss_rpn_box_reg: 0.0253 (0.0524)  time: 0.2915  data: 0.1512  max mem: 1751\n",
      "Training Epoch: [5]  [ 290/1229]  eta: 0:04:36  lr: 0.005000  loss: 0.3425 (0.4946)  loss_classifier: 0.1235 (0.1699)  loss_box_reg: 0.1000 (0.1537)  loss_objectness: 0.0865 (0.1190)  loss_rpn_box_reg: 0.0249 (0.0520)  time: 0.2937  data: 0.1544  max mem: 1751\n",
      "Training Epoch: [5]  [ 300/1229]  eta: 0:04:33  lr: 0.005000  loss: 0.4040 (0.4934)  loss_classifier: 0.1193 (0.1691)  loss_box_reg: 0.1208 (0.1539)  loss_objectness: 0.0933 (0.1185)  loss_rpn_box_reg: 0.0248 (0.0518)  time: 0.2968  data: 0.1593  max mem: 1751\n",
      "Training Epoch: [5]  [ 310/1229]  eta: 0:04:30  lr: 0.005000  loss: 0.3795 (0.4916)  loss_classifier: 0.1170 (0.1685)  loss_box_reg: 0.1091 (0.1534)  loss_objectness: 0.1116 (0.1183)  loss_rpn_box_reg: 0.0238 (0.0514)  time: 0.2956  data: 0.1600  max mem: 1751\n",
      "Training Epoch: [5]  [ 320/1229]  eta: 0:04:27  lr: 0.005000  loss: 0.4465 (0.4937)  loss_classifier: 0.1638 (0.1694)  loss_box_reg: 0.1165 (0.1536)  loss_objectness: 0.1168 (0.1192)  loss_rpn_box_reg: 0.0286 (0.0515)  time: 0.2963  data: 0.1577  max mem: 1751\n",
      "Training Epoch: [5]  [ 330/1229]  eta: 0:04:24  lr: 0.005000  loss: 0.4722 (0.4960)  loss_classifier: 0.1674 (0.1697)  loss_box_reg: 0.1461 (0.1545)  loss_objectness: 0.1440 (0.1202)  loss_rpn_box_reg: 0.0291 (0.0516)  time: 0.2898  data: 0.1521  max mem: 1751\n",
      "Training Epoch: [5]  [ 340/1229]  eta: 0:04:21  lr: 0.005000  loss: 0.4483 (0.4960)  loss_classifier: 0.1501 (0.1699)  loss_box_reg: 0.1543 (0.1552)  loss_objectness: 0.0978 (0.1200)  loss_rpn_box_reg: 0.0257 (0.0509)  time: 0.2827  data: 0.1476  max mem: 1751\n",
      "Training Epoch: [5]  [ 350/1229]  eta: 0:04:17  lr: 0.005000  loss: 0.3795 (0.4933)  loss_classifier: 0.1231 (0.1688)  loss_box_reg: 0.1112 (0.1532)  loss_objectness: 0.0966 (0.1205)  loss_rpn_box_reg: 0.0234 (0.0507)  time: 0.2741  data: 0.1422  max mem: 1751\n",
      "Training Epoch: [5]  [ 360/1229]  eta: 0:04:14  lr: 0.005000  loss: 0.3795 (0.4920)  loss_classifier: 0.1357 (0.1684)  loss_box_reg: 0.0883 (0.1523)  loss_objectness: 0.1063 (0.1206)  loss_rpn_box_reg: 0.0200 (0.0508)  time: 0.2745  data: 0.1434  max mem: 1751\n",
      "Training Epoch: [5]  [ 370/1229]  eta: 0:04:11  lr: 0.005000  loss: 0.4290 (0.4946)  loss_classifier: 0.1526 (0.1685)  loss_box_reg: 0.1261 (0.1521)  loss_objectness: 0.1199 (0.1217)  loss_rpn_box_reg: 0.0257 (0.0523)  time: 0.2836  data: 0.1460  max mem: 1751\n",
      "Training Epoch: [5]  [ 380/1229]  eta: 0:04:08  lr: 0.005000  loss: 0.5114 (0.4930)  loss_classifier: 0.1530 (0.1682)  loss_box_reg: 0.1350 (0.1516)  loss_objectness: 0.1275 (0.1214)  loss_rpn_box_reg: 0.0257 (0.0518)  time: 0.2856  data: 0.1448  max mem: 1751\n",
      "Training Epoch: [5]  [ 390/1229]  eta: 0:04:05  lr: 0.005000  loss: 0.4047 (0.4919)  loss_classifier: 0.1189 (0.1676)  loss_box_reg: 0.1218 (0.1515)  loss_objectness: 0.0809 (0.1204)  loss_rpn_box_reg: 0.0234 (0.0523)  time: 0.2832  data: 0.1450  max mem: 1751\n",
      "Training Epoch: [5]  [ 400/1229]  eta: 0:04:01  lr: 0.005000  loss: 0.4201 (0.4899)  loss_classifier: 0.1575 (0.1671)  loss_box_reg: 0.1414 (0.1511)  loss_objectness: 0.0941 (0.1201)  loss_rpn_box_reg: 0.0225 (0.0516)  time: 0.2819  data: 0.1430  max mem: 1751\n",
      "Training Epoch: [5]  [ 410/1229]  eta: 0:03:58  lr: 0.005000  loss: 0.4527 (0.4906)  loss_classifier: 0.1613 (0.1674)  loss_box_reg: 0.1517 (0.1517)  loss_objectness: 0.0988 (0.1202)  loss_rpn_box_reg: 0.0200 (0.0513)  time: 0.2827  data: 0.1411  max mem: 1751\n",
      "Training Epoch: [5]  [ 420/1229]  eta: 0:03:55  lr: 0.005000  loss: 0.4539 (0.4902)  loss_classifier: 0.1523 (0.1671)  loss_box_reg: 0.1519 (0.1520)  loss_objectness: 0.1032 (0.1201)  loss_rpn_box_reg: 0.0248 (0.0509)  time: 0.2776  data: 0.1426  max mem: 1751\n",
      "Training Epoch: [5]  [ 430/1229]  eta: 0:03:52  lr: 0.005000  loss: 0.4813 (0.4912)  loss_classifier: 0.1523 (0.1675)  loss_box_reg: 0.1384 (0.1520)  loss_objectness: 0.1032 (0.1204)  loss_rpn_box_reg: 0.0233 (0.0513)  time: 0.2767  data: 0.1421  max mem: 1751\n",
      "Training Epoch: [5]  [ 440/1229]  eta: 0:03:49  lr: 0.005000  loss: 0.5059 (0.4912)  loss_classifier: 0.1625 (0.1673)  loss_box_reg: 0.1155 (0.1515)  loss_objectness: 0.0908 (0.1205)  loss_rpn_box_reg: 0.0304 (0.0518)  time: 0.2805  data: 0.1412  max mem: 1751\n",
      "Training Epoch: [5]  [ 450/1229]  eta: 0:03:46  lr: 0.005000  loss: 0.5562 (0.4920)  loss_classifier: 0.2001 (0.1680)  loss_box_reg: 0.1376 (0.1516)  loss_objectness: 0.0908 (0.1207)  loss_rpn_box_reg: 0.0304 (0.0517)  time: 0.2809  data: 0.1444  max mem: 1751\n",
      "Training Epoch: [5]  [ 460/1229]  eta: 0:03:43  lr: 0.005000  loss: 0.5671 (0.4931)  loss_classifier: 0.2120 (0.1686)  loss_box_reg: 0.1376 (0.1524)  loss_objectness: 0.1217 (0.1207)  loss_rpn_box_reg: 0.0235 (0.0514)  time: 0.2834  data: 0.1429  max mem: 1751\n",
      "Training Epoch: [5]  [ 470/1229]  eta: 0:03:40  lr: 0.005000  loss: 0.5943 (0.4961)  loss_classifier: 0.2008 (0.1693)  loss_box_reg: 0.1953 (0.1532)  loss_objectness: 0.1217 (0.1209)  loss_rpn_box_reg: 0.0392 (0.0528)  time: 0.2818  data: 0.1414  max mem: 1751\n",
      "Training Epoch: [5]  [ 480/1229]  eta: 0:03:37  lr: 0.005000  loss: 0.4864 (0.4948)  loss_classifier: 0.1698 (0.1689)  loss_box_reg: 0.1525 (0.1530)  loss_objectness: 0.0937 (0.1201)  loss_rpn_box_reg: 0.0409 (0.0528)  time: 0.2787  data: 0.1433  max mem: 1751\n",
      "Training Epoch: [5]  [ 490/1229]  eta: 0:03:34  lr: 0.005000  loss: 0.4013 (0.4938)  loss_classifier: 0.1337 (0.1687)  loss_box_reg: 0.1405 (0.1529)  loss_objectness: 0.0808 (0.1199)  loss_rpn_box_reg: 0.0351 (0.0523)  time: 0.2803  data: 0.1453  max mem: 1751\n",
      "Training Epoch: [5]  [ 500/1229]  eta: 0:03:31  lr: 0.005000  loss: 0.4013 (0.4940)  loss_classifier: 0.1394 (0.1682)  loss_box_reg: 0.1268 (0.1530)  loss_objectness: 0.0808 (0.1201)  loss_rpn_box_reg: 0.0270 (0.0527)  time: 0.2807  data: 0.1462  max mem: 1751\n",
      "Training Epoch: [5]  [ 510/1229]  eta: 0:03:28  lr: 0.005000  loss: 0.4145 (0.4944)  loss_classifier: 0.1438 (0.1682)  loss_box_reg: 0.1182 (0.1530)  loss_objectness: 0.1117 (0.1201)  loss_rpn_box_reg: 0.0244 (0.0531)  time: 0.2802  data: 0.1466  max mem: 1751\n",
      "Training Epoch: [5]  [ 520/1229]  eta: 0:03:25  lr: 0.005000  loss: 0.6232 (0.4974)  loss_classifier: 0.1890 (0.1692)  loss_box_reg: 0.1511 (0.1538)  loss_objectness: 0.1179 (0.1210)  loss_rpn_box_reg: 0.0390 (0.0534)  time: 0.2846  data: 0.1474  max mem: 1751\n",
      "Training Epoch: [5]  [ 530/1229]  eta: 0:03:22  lr: 0.005000  loss: 0.5712 (0.4973)  loss_classifier: 0.1746 (0.1693)  loss_box_reg: 0.1582 (0.1540)  loss_objectness: 0.1118 (0.1206)  loss_rpn_box_reg: 0.0390 (0.0535)  time: 0.2862  data: 0.1452  max mem: 1751\n",
      "Training Epoch: [5]  [ 540/1229]  eta: 0:03:19  lr: 0.005000  loss: 0.4227 (0.4964)  loss_classifier: 0.1533 (0.1691)  loss_box_reg: 0.1392 (0.1540)  loss_objectness: 0.0969 (0.1203)  loss_rpn_box_reg: 0.0304 (0.0530)  time: 0.2794  data: 0.1423  max mem: 1751\n",
      "Training Epoch: [5]  [ 550/1229]  eta: 0:03:16  lr: 0.005000  loss: 0.3529 (0.4940)  loss_classifier: 0.1240 (0.1683)  loss_box_reg: 0.1086 (0.1531)  loss_objectness: 0.0807 (0.1199)  loss_rpn_box_reg: 0.0234 (0.0527)  time: 0.2761  data: 0.1391  max mem: 1751\n",
      "Training Epoch: [5]  [ 560/1229]  eta: 0:03:13  lr: 0.005000  loss: 0.4421 (0.4952)  loss_classifier: 0.1519 (0.1688)  loss_box_reg: 0.1212 (0.1539)  loss_objectness: 0.0860 (0.1200)  loss_rpn_box_reg: 0.0288 (0.0526)  time: 0.2815  data: 0.1384  max mem: 1751\n",
      "Training Epoch: [5]  [ 570/1229]  eta: 0:03:10  lr: 0.005000  loss: 0.5775 (0.4977)  loss_classifier: 0.2032 (0.1698)  loss_box_reg: 0.1766 (0.1549)  loss_objectness: 0.1107 (0.1203)  loss_rpn_box_reg: 0.0443 (0.0527)  time: 0.2853  data: 0.1416  max mem: 1751\n",
      "Training Epoch: [5]  [ 580/1229]  eta: 0:03:07  lr: 0.005000  loss: 0.5178 (0.4980)  loss_classifier: 0.1937 (0.1701)  loss_box_reg: 0.1564 (0.1548)  loss_objectness: 0.1252 (0.1206)  loss_rpn_box_reg: 0.0314 (0.0524)  time: 0.2809  data: 0.1421  max mem: 1751\n",
      "Training Epoch: [5]  [ 590/1229]  eta: 0:03:04  lr: 0.005000  loss: 0.4114 (0.4971)  loss_classifier: 0.1567 (0.1700)  loss_box_reg: 0.1131 (0.1547)  loss_objectness: 0.0977 (0.1204)  loss_rpn_box_reg: 0.0221 (0.0520)  time: 0.2828  data: 0.1428  max mem: 1751\n",
      "Training Epoch: [5]  [ 600/1229]  eta: 0:03:01  lr: 0.005000  loss: 0.4114 (0.4971)  loss_classifier: 0.1624 (0.1699)  loss_box_reg: 0.1095 (0.1545)  loss_objectness: 0.0990 (0.1206)  loss_rpn_box_reg: 0.0248 (0.0521)  time: 0.2808  data: 0.1429  max mem: 1751\n",
      "Training Epoch: [5]  [ 610/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.3599 (0.4940)  loss_classifier: 0.1270 (0.1688)  loss_box_reg: 0.0919 (0.1533)  loss_objectness: 0.0980 (0.1201)  loss_rpn_box_reg: 0.0292 (0.0519)  time: 0.2734  data: 0.1401  max mem: 1751\n",
      "Training Epoch: [5]  [ 620/1229]  eta: 0:02:55  lr: 0.005000  loss: 0.3122 (0.4934)  loss_classifier: 0.1270 (0.1686)  loss_box_reg: 0.0677 (0.1533)  loss_objectness: 0.0875 (0.1197)  loss_rpn_box_reg: 0.0191 (0.0517)  time: 0.2776  data: 0.1401  max mem: 1751\n",
      "Training Epoch: [5]  [ 630/1229]  eta: 0:02:52  lr: 0.005000  loss: 0.4011 (0.4934)  loss_classifier: 0.1462 (0.1684)  loss_box_reg: 0.1108 (0.1531)  loss_objectness: 0.0990 (0.1200)  loss_rpn_box_reg: 0.0214 (0.0519)  time: 0.2840  data: 0.1425  max mem: 1751\n",
      "Training Epoch: [5]  [ 640/1229]  eta: 0:02:49  lr: 0.005000  loss: 0.5129 (0.4938)  loss_classifier: 0.1635 (0.1686)  loss_box_reg: 0.1290 (0.1533)  loss_objectness: 0.1121 (0.1200)  loss_rpn_box_reg: 0.0313 (0.0519)  time: 0.2776  data: 0.1408  max mem: 1751\n",
      "Training Epoch: [5]  [ 650/1229]  eta: 0:02:46  lr: 0.005000  loss: 0.5129 (0.4931)  loss_classifier: 0.1920 (0.1683)  loss_box_reg: 0.1372 (0.1528)  loss_objectness: 0.1121 (0.1201)  loss_rpn_box_reg: 0.0297 (0.0519)  time: 0.2740  data: 0.1403  max mem: 1751\n",
      "Training Epoch: [5]  [ 660/1229]  eta: 0:02:43  lr: 0.005000  loss: 0.4346 (0.4924)  loss_classifier: 0.1270 (0.1682)  loss_box_reg: 0.1079 (0.1524)  loss_objectness: 0.1137 (0.1200)  loss_rpn_box_reg: 0.0293 (0.0519)  time: 0.2794  data: 0.1422  max mem: 1751\n",
      "Training Epoch: [5]  [ 670/1229]  eta: 0:02:40  lr: 0.005000  loss: 0.3424 (0.4925)  loss_classifier: 0.1270 (0.1682)  loss_box_reg: 0.1044 (0.1526)  loss_objectness: 0.1077 (0.1202)  loss_rpn_box_reg: 0.0203 (0.0515)  time: 0.2812  data: 0.1421  max mem: 1751\n",
      "Training Epoch: [5]  [ 680/1229]  eta: 0:02:37  lr: 0.005000  loss: 0.3866 (0.4920)  loss_classifier: 0.1338 (0.1681)  loss_box_reg: 0.1103 (0.1520)  loss_objectness: 0.1077 (0.1203)  loss_rpn_box_reg: 0.0314 (0.0516)  time: 0.2832  data: 0.1403  max mem: 1751\n",
      "Training Epoch: [5]  [ 690/1229]  eta: 0:02:34  lr: 0.005000  loss: 0.3908 (0.4910)  loss_classifier: 0.1238 (0.1678)  loss_box_reg: 0.0864 (0.1515)  loss_objectness: 0.0926 (0.1202)  loss_rpn_box_reg: 0.0364 (0.0515)  time: 0.2772  data: 0.1391  max mem: 1751\n",
      "Training Epoch: [5]  [ 700/1229]  eta: 0:02:31  lr: 0.005000  loss: 0.3779 (0.4907)  loss_classifier: 0.1371 (0.1677)  loss_box_reg: 0.0934 (0.1516)  loss_objectness: 0.0900 (0.1200)  loss_rpn_box_reg: 0.0418 (0.0515)  time: 0.2803  data: 0.1405  max mem: 1751\n",
      "Training Epoch: [5]  [ 710/1229]  eta: 0:02:28  lr: 0.005000  loss: 0.3426 (0.4890)  loss_classifier: 0.1471 (0.1673)  loss_box_reg: 0.1127 (0.1511)  loss_objectness: 0.0700 (0.1193)  loss_rpn_box_reg: 0.0238 (0.0512)  time: 0.2860  data: 0.1400  max mem: 1751\n",
      "Training Epoch: [5]  [ 720/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.3322 (0.4884)  loss_classifier: 0.1194 (0.1671)  loss_box_reg: 0.0975 (0.1506)  loss_objectness: 0.0722 (0.1196)  loss_rpn_box_reg: 0.0236 (0.0511)  time: 0.2846  data: 0.1428  max mem: 1751\n",
      "Training Epoch: [5]  [ 730/1229]  eta: 0:02:23  lr: 0.005000  loss: 0.4077 (0.4878)  loss_classifier: 0.1508 (0.1670)  loss_box_reg: 0.0975 (0.1503)  loss_objectness: 0.0978 (0.1196)  loss_rpn_box_reg: 0.0284 (0.0508)  time: 0.2879  data: 0.1431  max mem: 1751\n",
      "Training Epoch: [5]  [ 740/1229]  eta: 0:02:20  lr: 0.005000  loss: 0.4077 (0.4878)  loss_classifier: 0.1367 (0.1669)  loss_box_reg: 0.1120 (0.1503)  loss_objectness: 0.1083 (0.1198)  loss_rpn_box_reg: 0.0212 (0.0508)  time: 0.2894  data: 0.1401  max mem: 1751\n",
      "Training Epoch: [5]  [ 750/1229]  eta: 0:02:17  lr: 0.005000  loss: 0.3742 (0.4864)  loss_classifier: 0.1248 (0.1664)  loss_box_reg: 0.0993 (0.1495)  loss_objectness: 0.1083 (0.1197)  loss_rpn_box_reg: 0.0302 (0.0508)  time: 0.2872  data: 0.1421  max mem: 1751\n",
      "Training Epoch: [5]  [ 760/1229]  eta: 0:02:14  lr: 0.005000  loss: 0.3835 (0.4860)  loss_classifier: 0.1477 (0.1663)  loss_box_reg: 0.1084 (0.1496)  loss_objectness: 0.0924 (0.1195)  loss_rpn_box_reg: 0.0313 (0.0506)  time: 0.2825  data: 0.1432  max mem: 1751\n",
      "Training Epoch: [5]  [ 770/1229]  eta: 0:02:11  lr: 0.005000  loss: 0.4125 (0.4852)  loss_classifier: 0.1375 (0.1660)  loss_box_reg: 0.1305 (0.1497)  loss_objectness: 0.0930 (0.1192)  loss_rpn_box_reg: 0.0306 (0.0503)  time: 0.2798  data: 0.1432  max mem: 1751\n",
      "Training Epoch: [5]  [ 780/1229]  eta: 0:02:08  lr: 0.005000  loss: 0.3757 (0.4850)  loss_classifier: 0.1359 (0.1659)  loss_box_reg: 0.1213 (0.1494)  loss_objectness: 0.0930 (0.1195)  loss_rpn_box_reg: 0.0216 (0.0501)  time: 0.2824  data: 0.1418  max mem: 1751\n",
      "Training Epoch: [5]  [ 790/1229]  eta: 0:02:05  lr: 0.005000  loss: 0.3409 (0.4837)  loss_classifier: 0.1224 (0.1655)  loss_box_reg: 0.1184 (0.1491)  loss_objectness: 0.0890 (0.1192)  loss_rpn_box_reg: 0.0277 (0.0499)  time: 0.2830  data: 0.1402  max mem: 1751\n",
      "Training Epoch: [5]  [ 800/1229]  eta: 0:02:02  lr: 0.005000  loss: 0.3966 (0.4838)  loss_classifier: 0.1152 (0.1655)  loss_box_reg: 0.1184 (0.1494)  loss_objectness: 0.0873 (0.1190)  loss_rpn_box_reg: 0.0322 (0.0500)  time: 0.2825  data: 0.1401  max mem: 1751\n",
      "Training Epoch: [5]  [ 810/1229]  eta: 0:02:00  lr: 0.005000  loss: 0.4164 (0.4838)  loss_classifier: 0.1317 (0.1655)  loss_box_reg: 0.1412 (0.1495)  loss_objectness: 0.0873 (0.1188)  loss_rpn_box_reg: 0.0225 (0.0499)  time: 0.2856  data: 0.1402  max mem: 1751\n",
      "Training Epoch: [5]  [ 820/1229]  eta: 0:01:57  lr: 0.005000  loss: 0.4153 (0.4831)  loss_classifier: 0.1295 (0.1653)  loss_box_reg: 0.1243 (0.1491)  loss_objectness: 0.1009 (0.1187)  loss_rpn_box_reg: 0.0225 (0.0499)  time: 0.2833  data: 0.1419  max mem: 1751\n",
      "Training Epoch: [5]  [ 830/1229]  eta: 0:01:54  lr: 0.005000  loss: 0.3893 (0.4818)  loss_classifier: 0.1183 (0.1649)  loss_box_reg: 0.0995 (0.1489)  loss_objectness: 0.1029 (0.1184)  loss_rpn_box_reg: 0.0184 (0.0496)  time: 0.2825  data: 0.1427  max mem: 1751\n",
      "Training Epoch: [5]  [ 840/1229]  eta: 0:01:51  lr: 0.005000  loss: 0.3645 (0.4825)  loss_classifier: 0.1170 (0.1649)  loss_box_reg: 0.0957 (0.1493)  loss_objectness: 0.1030 (0.1185)  loss_rpn_box_reg: 0.0134 (0.0499)  time: 0.2790  data: 0.1418  max mem: 1751\n",
      "Training Epoch: [5]  [ 850/1229]  eta: 0:01:48  lr: 0.005000  loss: 0.4518 (0.4818)  loss_classifier: 0.1344 (0.1647)  loss_box_reg: 0.1086 (0.1491)  loss_objectness: 0.1066 (0.1183)  loss_rpn_box_reg: 0.0274 (0.0496)  time: 0.2807  data: 0.1403  max mem: 1751\n",
      "Training Epoch: [5]  [ 860/1229]  eta: 0:01:45  lr: 0.005000  loss: 0.3427 (0.4814)  loss_classifier: 0.1207 (0.1646)  loss_box_reg: 0.1219 (0.1496)  loss_objectness: 0.0822 (0.1179)  loss_rpn_box_reg: 0.0230 (0.0494)  time: 0.2848  data: 0.1403  max mem: 1751\n",
      "Training Epoch: [5]  [ 870/1229]  eta: 0:01:42  lr: 0.005000  loss: 0.4931 (0.4824)  loss_classifier: 0.1725 (0.1650)  loss_box_reg: 0.1492 (0.1499)  loss_objectness: 0.0862 (0.1180)  loss_rpn_box_reg: 0.0326 (0.0494)  time: 0.2804  data: 0.1416  max mem: 1751\n",
      "Training Epoch: [5]  [ 880/1229]  eta: 0:01:39  lr: 0.005000  loss: 0.4915 (0.4824)  loss_classifier: 0.1772 (0.1651)  loss_box_reg: 0.1263 (0.1497)  loss_objectness: 0.1078 (0.1182)  loss_rpn_box_reg: 0.0374 (0.0495)  time: 0.2802  data: 0.1407  max mem: 1751\n",
      "Training Epoch: [5]  [ 890/1229]  eta: 0:01:36  lr: 0.005000  loss: 0.3984 (0.4817)  loss_classifier: 0.1345 (0.1647)  loss_box_reg: 0.0964 (0.1492)  loss_objectness: 0.1055 (0.1181)  loss_rpn_box_reg: 0.0226 (0.0496)  time: 0.2786  data: 0.1415  max mem: 1751\n",
      "Training Epoch: [5]  [ 900/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.4307 (0.4820)  loss_classifier: 0.1345 (0.1648)  loss_box_reg: 0.1101 (0.1493)  loss_objectness: 0.0898 (0.1182)  loss_rpn_box_reg: 0.0190 (0.0497)  time: 0.2773  data: 0.1421  max mem: 1751\n",
      "Training Epoch: [5]  [ 910/1229]  eta: 0:01:31  lr: 0.005000  loss: 0.3647 (0.4812)  loss_classifier: 0.1197 (0.1645)  loss_box_reg: 0.1101 (0.1491)  loss_objectness: 0.0821 (0.1179)  loss_rpn_box_reg: 0.0217 (0.0497)  time: 0.2814  data: 0.1402  max mem: 1751\n",
      "Training Epoch: [5]  [ 920/1229]  eta: 0:01:28  lr: 0.005000  loss: 0.2992 (0.4805)  loss_classifier: 0.1083 (0.1643)  loss_box_reg: 0.0819 (0.1488)  loss_objectness: 0.0890 (0.1178)  loss_rpn_box_reg: 0.0238 (0.0496)  time: 0.2829  data: 0.1419  max mem: 1751\n",
      "Training Epoch: [5]  [ 930/1229]  eta: 0:01:25  lr: 0.005000  loss: 0.4052 (0.4802)  loss_classifier: 0.1357 (0.1643)  loss_box_reg: 0.0879 (0.1486)  loss_objectness: 0.1013 (0.1178)  loss_rpn_box_reg: 0.0315 (0.0495)  time: 0.2774  data: 0.1413  max mem: 1751\n",
      "Training Epoch: [5]  [ 940/1229]  eta: 0:01:22  lr: 0.005000  loss: 0.4283 (0.4798)  loss_classifier: 0.1589 (0.1641)  loss_box_reg: 0.1324 (0.1485)  loss_objectness: 0.0874 (0.1175)  loss_rpn_box_reg: 0.0312 (0.0497)  time: 0.2736  data: 0.1394  max mem: 1751\n",
      "Training Epoch: [5]  [ 950/1229]  eta: 0:01:19  lr: 0.005000  loss: 0.4198 (0.4798)  loss_classifier: 0.1556 (0.1642)  loss_box_reg: 0.1191 (0.1485)  loss_objectness: 0.0874 (0.1174)  loss_rpn_box_reg: 0.0369 (0.0497)  time: 0.2754  data: 0.1420  max mem: 1751\n",
      "Training Epoch: [5]  [ 960/1229]  eta: 0:01:16  lr: 0.005000  loss: 0.3775 (0.4794)  loss_classifier: 0.1370 (0.1640)  loss_box_reg: 0.1191 (0.1485)  loss_objectness: 0.0942 (0.1173)  loss_rpn_box_reg: 0.0369 (0.0495)  time: 0.2784  data: 0.1431  max mem: 1751\n",
      "Training Epoch: [5]  [ 970/1229]  eta: 0:01:13  lr: 0.005000  loss: 0.4195 (0.4800)  loss_classifier: 0.1459 (0.1641)  loss_box_reg: 0.1041 (0.1489)  loss_objectness: 0.0942 (0.1172)  loss_rpn_box_reg: 0.0320 (0.0499)  time: 0.2790  data: 0.1407  max mem: 1751\n",
      "Training Epoch: [5]  [ 980/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.3829 (0.4798)  loss_classifier: 0.1285 (0.1638)  loss_box_reg: 0.0845 (0.1484)  loss_objectness: 0.0902 (0.1175)  loss_rpn_box_reg: 0.0437 (0.0500)  time: 0.2815  data: 0.1428  max mem: 1751\n",
      "Training Epoch: [5]  [ 990/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.3829 (0.4802)  loss_classifier: 0.1403 (0.1640)  loss_box_reg: 0.0845 (0.1485)  loss_objectness: 0.1129 (0.1176)  loss_rpn_box_reg: 0.0317 (0.0500)  time: 0.2882  data: 0.1438  max mem: 1751\n",
      "Training Epoch: [5]  [1000/1229]  eta: 0:01:05  lr: 0.005000  loss: 0.4147 (0.4798)  loss_classifier: 0.1439 (0.1640)  loss_box_reg: 0.1035 (0.1485)  loss_objectness: 0.1009 (0.1175)  loss_rpn_box_reg: 0.0281 (0.0499)  time: 0.2861  data: 0.1413  max mem: 1751\n",
      "Training Epoch: [5]  [1010/1229]  eta: 0:01:02  lr: 0.005000  loss: 0.4108 (0.4801)  loss_classifier: 0.1508 (0.1640)  loss_box_reg: 0.1113 (0.1487)  loss_objectness: 0.0876 (0.1176)  loss_rpn_box_reg: 0.0257 (0.0498)  time: 0.2821  data: 0.1412  max mem: 1751\n",
      "Training Epoch: [5]  [1020/1229]  eta: 0:00:59  lr: 0.005000  loss: 0.4311 (0.4803)  loss_classifier: 0.1611 (0.1642)  loss_box_reg: 0.1360 (0.1489)  loss_objectness: 0.0936 (0.1176)  loss_rpn_box_reg: 0.0309 (0.0497)  time: 0.2858  data: 0.1424  max mem: 1751\n",
      "Training Epoch: [5]  [1030/1229]  eta: 0:00:56  lr: 0.005000  loss: 0.4102 (0.4795)  loss_classifier: 0.1555 (0.1640)  loss_box_reg: 0.1188 (0.1486)  loss_objectness: 0.0897 (0.1175)  loss_rpn_box_reg: 0.0309 (0.0495)  time: 0.2827  data: 0.1438  max mem: 1751\n",
      "Training Epoch: [5]  [1040/1229]  eta: 0:00:53  lr: 0.005000  loss: 0.2942 (0.4788)  loss_classifier: 0.1060 (0.1637)  loss_box_reg: 0.0784 (0.1481)  loss_objectness: 0.0989 (0.1174)  loss_rpn_box_reg: 0.0312 (0.0496)  time: 0.2774  data: 0.1411  max mem: 1751\n",
      "Training Epoch: [5]  [1050/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.3043 (0.4776)  loss_classifier: 0.0967 (0.1632)  loss_box_reg: 0.0653 (0.1476)  loss_objectness: 0.0989 (0.1172)  loss_rpn_box_reg: 0.0309 (0.0496)  time: 0.2811  data: 0.1407  max mem: 1751\n",
      "Training Epoch: [5]  [1060/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.3612 (0.4768)  loss_classifier: 0.1042 (0.1627)  loss_box_reg: 0.0828 (0.1472)  loss_objectness: 0.0930 (0.1170)  loss_rpn_box_reg: 0.0300 (0.0499)  time: 0.2787  data: 0.1409  max mem: 1751\n",
      "Training Epoch: [5]  [1070/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.3366 (0.4766)  loss_classifier: 0.1042 (0.1626)  loss_box_reg: 0.0870 (0.1470)  loss_objectness: 0.0994 (0.1171)  loss_rpn_box_reg: 0.0312 (0.0499)  time: 0.2781  data: 0.1386  max mem: 1751\n",
      "Training Epoch: [5]  [1080/1229]  eta: 0:00:42  lr: 0.005000  loss: 0.3117 (0.4765)  loss_classifier: 0.1113 (0.1626)  loss_box_reg: 0.0975 (0.1472)  loss_objectness: 0.0993 (0.1170)  loss_rpn_box_reg: 0.0230 (0.0497)  time: 0.2863  data: 0.1407  max mem: 1751\n",
      "Training Epoch: [5]  [1090/1229]  eta: 0:00:39  lr: 0.005000  loss: 0.4237 (0.4761)  loss_classifier: 0.1447 (0.1625)  loss_box_reg: 0.1378 (0.1471)  loss_objectness: 0.0822 (0.1168)  loss_rpn_box_reg: 0.0240 (0.0496)  time: 0.2869  data: 0.1421  max mem: 1751\n",
      "Training Epoch: [5]  [1100/1229]  eta: 0:00:36  lr: 0.005000  loss: 0.4327 (0.4770)  loss_classifier: 0.1605 (0.1627)  loss_box_reg: 0.1498 (0.1473)  loss_objectness: 0.0922 (0.1169)  loss_rpn_box_reg: 0.0325 (0.0502)  time: 0.2811  data: 0.1407  max mem: 1751\n",
      "Training Epoch: [5]  [1110/1229]  eta: 0:00:33  lr: 0.005000  loss: 0.4410 (0.4774)  loss_classifier: 0.1649 (0.1629)  loss_box_reg: 0.1505 (0.1477)  loss_objectness: 0.0891 (0.1168)  loss_rpn_box_reg: 0.0247 (0.0500)  time: 0.2815  data: 0.1421  max mem: 1751\n",
      "Training Epoch: [5]  [1120/1229]  eta: 0:00:31  lr: 0.005000  loss: 0.4190 (0.4767)  loss_classifier: 0.1361 (0.1626)  loss_box_reg: 0.1494 (0.1475)  loss_objectness: 0.0786 (0.1166)  loss_rpn_box_reg: 0.0324 (0.0500)  time: 0.2881  data: 0.1428  max mem: 1751\n",
      "Training Epoch: [5]  [1130/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.4393 (0.4775)  loss_classifier: 0.1471 (0.1629)  loss_box_reg: 0.1598 (0.1480)  loss_objectness: 0.0875 (0.1167)  loss_rpn_box_reg: 0.0344 (0.0498)  time: 0.2869  data: 0.1409  max mem: 1751\n",
      "Training Epoch: [5]  [1140/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.4868 (0.4780)  loss_classifier: 0.1849 (0.1631)  loss_box_reg: 0.1643 (0.1482)  loss_objectness: 0.0979 (0.1168)  loss_rpn_box_reg: 0.0297 (0.0498)  time: 0.2846  data: 0.1408  max mem: 1751\n",
      "Training Epoch: [5]  [1150/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.4164 (0.4776)  loss_classifier: 0.1663 (0.1630)  loss_box_reg: 0.1296 (0.1480)  loss_objectness: 0.0979 (0.1168)  loss_rpn_box_reg: 0.0262 (0.0497)  time: 0.2835  data: 0.1412  max mem: 1751\n",
      "Training Epoch: [5]  [1160/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.4164 (0.4781)  loss_classifier: 0.1519 (0.1632)  loss_box_reg: 0.1039 (0.1482)  loss_objectness: 0.1090 (0.1170)  loss_rpn_box_reg: 0.0227 (0.0497)  time: 0.2734  data: 0.1393  max mem: 1751\n",
      "Training Epoch: [5]  [1170/1229]  eta: 0:00:16  lr: 0.005000  loss: 0.5937 (0.4792)  loss_classifier: 0.1830 (0.1637)  loss_box_reg: 0.1536 (0.1488)  loss_objectness: 0.1438 (0.1171)  loss_rpn_box_reg: 0.0348 (0.0497)  time: 0.2718  data: 0.1391  max mem: 1751\n",
      "Training Epoch: [5]  [1180/1229]  eta: 0:00:13  lr: 0.005000  loss: 0.5937 (0.4799)  loss_classifier: 0.1835 (0.1639)  loss_box_reg: 0.1771 (0.1490)  loss_objectness: 0.1114 (0.1173)  loss_rpn_box_reg: 0.0379 (0.0497)  time: 0.2839  data: 0.1419  max mem: 1751\n",
      "Training Epoch: [5]  [1190/1229]  eta: 0:00:11  lr: 0.005000  loss: 0.4081 (0.4802)  loss_classifier: 0.1577 (0.1641)  loss_box_reg: 0.1423 (0.1491)  loss_objectness: 0.0996 (0.1173)  loss_rpn_box_reg: 0.0379 (0.0497)  time: 0.2832  data: 0.1437  max mem: 1751\n",
      "Training Epoch: [5]  [1200/1229]  eta: 0:00:08  lr: 0.005000  loss: 0.4822 (0.4809)  loss_classifier: 0.1642 (0.1644)  loss_box_reg: 0.1583 (0.1497)  loss_objectness: 0.0913 (0.1172)  loss_rpn_box_reg: 0.0309 (0.0496)  time: 0.2782  data: 0.1429  max mem: 1751\n",
      "Training Epoch: [5]  [1210/1229]  eta: 0:00:05  lr: 0.005000  loss: 0.5512 (0.4817)  loss_classifier: 0.1837 (0.1647)  loss_box_reg: 0.1832 (0.1502)  loss_objectness: 0.1024 (0.1173)  loss_rpn_box_reg: 0.0279 (0.0495)  time: 0.2811  data: 0.1437  max mem: 1751\n",
      "Training Epoch: [5]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.5514 (0.4824)  loss_classifier: 0.1987 (0.1649)  loss_box_reg: 0.1758 (0.1503)  loss_objectness: 0.1281 (0.1176)  loss_rpn_box_reg: 0.0325 (0.0496)  time: 0.2768  data: 0.1441  max mem: 1751\n",
      "Training Epoch: [5]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.5360 (0.4825)  loss_classifier: 0.2034 (0.1651)  loss_box_reg: 0.1458 (0.1501)  loss_objectness: 0.1417 (0.1178)  loss_rpn_box_reg: 0.0325 (0.0495)  time: 0.2765  data: 0.1417  max mem: 1751\n",
      "Training Epoch: [5] Total time: 0:05:50 (0.2848 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:19  model_time: 0.2240 (0.2240)  evaluator_time: 0.0020 (0.0020)  time: 0.2570  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0780 (0.0800)  evaluator_time: 0.0060 (0.0088)  time: 0.1256  data: 0.0352  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0820 (0.0790)  evaluator_time: 0.0030 (0.0083)  time: 0.1183  data: 0.0304  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0740 (0.0784)  evaluator_time: 0.0060 (0.0081)  time: 0.1189  data: 0.0347  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0740 (0.0783)  evaluator_time: 0.0030 (0.0081)  time: 0.1154  data: 0.0334  max mem: 1751\n",
      "Test: Total time: 0:00:37 (0.1224 s / it)\n",
      "Averaged stats: model_time: 0.0740 (0.0783)  evaluator_time: 0.0030 (0.0081)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.17s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.065\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.093\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.032\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.144\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292\n",
      "Testing Epoch: [5]  [  0/308]  eta: 0:00:40  lr: 0.005000  loss: 0.1844 (0.1844)  loss_classifier: 0.0750 (0.0750)  loss_box_reg: 0.0548 (0.0548)  loss_objectness: 0.0441 (0.0441)  loss_rpn_box_reg: 0.0105 (0.0105)  time: 0.1320  data: 0.0311  max mem: 1751\n",
      "Testing Epoch: [5]  [100/308]  eta: 0:00:28  lr: 0.005000  loss: 0.3296 (0.5187)  loss_classifier: 0.1340 (0.1776)  loss_box_reg: 0.1102 (0.1653)  loss_objectness: 0.0727 (0.1080)  loss_rpn_box_reg: 0.0338 (0.0677)  time: 0.1383  data: 0.0369  max mem: 1751\n",
      "Testing Epoch: [5]  [200/308]  eta: 0:00:14  lr: 0.005000  loss: 0.3829 (0.4992)  loss_classifier: 0.1454 (0.1727)  loss_box_reg: 0.1366 (0.1596)  loss_objectness: 0.0693 (0.1010)  loss_rpn_box_reg: 0.0267 (0.0659)  time: 0.1371  data: 0.0319  max mem: 1751\n",
      "Testing Epoch: [5]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5242 (0.4983)  loss_classifier: 0.1888 (0.1729)  loss_box_reg: 0.1663 (0.1615)  loss_objectness: 0.0862 (0.0985)  loss_rpn_box_reg: 0.0408 (0.0654)  time: 0.1310  data: 0.0369  max mem: 1751\n",
      "Testing Epoch: [5]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.5184 (0.4979)  loss_classifier: 0.1888 (0.1731)  loss_box_reg: 0.1471 (0.1617)  loss_objectness: 0.0782 (0.0983)  loss_rpn_box_reg: 0.0408 (0.0648)  time: 0.1290  data: 0.0352  max mem: 1751\n",
      "Testing Epoch: [5] Total time: 0:00:41 (0.1360 s / it)\n",
      "Training Epoch: [6]  [   0/1229]  eta: 0:05:33  lr: 0.005000  loss: 0.3232 (0.3232)  loss_classifier: 0.1218 (0.1218)  loss_box_reg: 0.0922 (0.0922)  loss_objectness: 0.0845 (0.0845)  loss_rpn_box_reg: 0.0247 (0.0247)  time: 0.2710  data: 0.1220  max mem: 1751\n",
      "Training Epoch: [6]  [  10/1229]  eta: 0:05:19  lr: 0.005000  loss: 0.3087 (0.3804)  loss_classifier: 0.1218 (0.1343)  loss_box_reg: 0.1041 (0.1173)  loss_objectness: 0.0845 (0.0924)  loss_rpn_box_reg: 0.0247 (0.0364)  time: 0.2618  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [6]  [  20/1229]  eta: 0:05:21  lr: 0.005000  loss: 0.3887 (0.4422)  loss_classifier: 0.1302 (0.1510)  loss_box_reg: 0.1097 (0.1333)  loss_objectness: 0.1016 (0.1142)  loss_rpn_box_reg: 0.0310 (0.0437)  time: 0.2653  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [6]  [  30/1229]  eta: 0:05:24  lr: 0.005000  loss: 0.5888 (0.5008)  loss_classifier: 0.1921 (0.1715)  loss_box_reg: 0.1780 (0.1651)  loss_objectness: 0.1149 (0.1159)  loss_rpn_box_reg: 0.0338 (0.0484)  time: 0.2752  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [6]  [  40/1229]  eta: 0:05:23  lr: 0.005000  loss: 0.5042 (0.4945)  loss_classifier: 0.1921 (0.1697)  loss_box_reg: 0.1780 (0.1639)  loss_objectness: 0.0914 (0.1136)  loss_rpn_box_reg: 0.0242 (0.0473)  time: 0.2783  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [6]  [  50/1229]  eta: 0:05:21  lr: 0.005000  loss: 0.3888 (0.4735)  loss_classifier: 0.1088 (0.1614)  loss_box_reg: 0.0840 (0.1532)  loss_objectness: 0.0931 (0.1109)  loss_rpn_box_reg: 0.0166 (0.0480)  time: 0.2763  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [6]  [  60/1229]  eta: 0:05:17  lr: 0.005000  loss: 0.3349 (0.4922)  loss_classifier: 0.1110 (0.1645)  loss_box_reg: 0.0850 (0.1552)  loss_objectness: 0.0892 (0.1162)  loss_rpn_box_reg: 0.0236 (0.0564)  time: 0.2703  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [6]  [  70/1229]  eta: 0:05:14  lr: 0.005000  loss: 0.5017 (0.4988)  loss_classifier: 0.1771 (0.1685)  loss_box_reg: 0.1669 (0.1570)  loss_objectness: 0.1174 (0.1185)  loss_rpn_box_reg: 0.0286 (0.0548)  time: 0.2689  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [6]  [  80/1229]  eta: 0:05:11  lr: 0.005000  loss: 0.4269 (0.4873)  loss_classifier: 0.1771 (0.1667)  loss_box_reg: 0.1272 (0.1522)  loss_objectness: 0.1164 (0.1154)  loss_rpn_box_reg: 0.0259 (0.0531)  time: 0.2700  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [6]  [  90/1229]  eta: 0:05:09  lr: 0.005000  loss: 0.3239 (0.4742)  loss_classifier: 0.1077 (0.1621)  loss_box_reg: 0.0807 (0.1481)  loss_objectness: 0.0653 (0.1138)  loss_rpn_box_reg: 0.0160 (0.0502)  time: 0.2719  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [6]  [ 100/1229]  eta: 0:05:08  lr: 0.005000  loss: 0.3899 (0.4825)  loss_classifier: 0.1467 (0.1637)  loss_box_reg: 0.1099 (0.1527)  loss_objectness: 0.0810 (0.1129)  loss_rpn_box_reg: 0.0225 (0.0531)  time: 0.2804  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [6]  [ 110/1229]  eta: 0:05:05  lr: 0.005000  loss: 0.4049 (0.4716)  loss_classifier: 0.1388 (0.1606)  loss_box_reg: 0.1193 (0.1471)  loss_objectness: 0.0940 (0.1129)  loss_rpn_box_reg: 0.0374 (0.0511)  time: 0.2793  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [6]  [ 120/1229]  eta: 0:05:02  lr: 0.005000  loss: 0.3032 (0.4689)  loss_classifier: 0.1140 (0.1606)  loss_box_reg: 0.0886 (0.1468)  loss_objectness: 0.0759 (0.1121)  loss_rpn_box_reg: 0.0290 (0.0494)  time: 0.2696  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [6]  [ 130/1229]  eta: 0:04:58  lr: 0.005000  loss: 0.3453 (0.4664)  loss_classifier: 0.1267 (0.1589)  loss_box_reg: 0.1016 (0.1457)  loss_objectness: 0.0731 (0.1125)  loss_rpn_box_reg: 0.0290 (0.0493)  time: 0.2663  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [6]  [ 140/1229]  eta: 0:04:56  lr: 0.005000  loss: 0.3688 (0.4679)  loss_classifier: 0.1210 (0.1590)  loss_box_reg: 0.1118 (0.1466)  loss_objectness: 0.0731 (0.1115)  loss_rpn_box_reg: 0.0255 (0.0509)  time: 0.2716  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [6]  [ 150/1229]  eta: 0:04:53  lr: 0.005000  loss: 0.4064 (0.4661)  loss_classifier: 0.1267 (0.1584)  loss_box_reg: 0.1148 (0.1455)  loss_objectness: 0.0897 (0.1117)  loss_rpn_box_reg: 0.0308 (0.0505)  time: 0.2714  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [6]  [ 160/1229]  eta: 0:04:51  lr: 0.005000  loss: 0.4395 (0.4737)  loss_classifier: 0.1591 (0.1604)  loss_box_reg: 0.1295 (0.1469)  loss_objectness: 0.0981 (0.1135)  loss_rpn_box_reg: 0.0310 (0.0530)  time: 0.2722  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [6]  [ 170/1229]  eta: 0:04:48  lr: 0.005000  loss: 0.4682 (0.4704)  loss_classifier: 0.1426 (0.1589)  loss_box_reg: 0.1335 (0.1455)  loss_objectness: 0.0981 (0.1127)  loss_rpn_box_reg: 0.0427 (0.0533)  time: 0.2750  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [6]  [ 180/1229]  eta: 0:04:45  lr: 0.005000  loss: 0.4197 (0.4695)  loss_classifier: 0.1096 (0.1587)  loss_box_reg: 0.1163 (0.1467)  loss_objectness: 0.1046 (0.1120)  loss_rpn_box_reg: 0.0409 (0.0521)  time: 0.2746  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [6]  [ 190/1229]  eta: 0:04:44  lr: 0.005000  loss: 0.3663 (0.4729)  loss_classifier: 0.1078 (0.1603)  loss_box_reg: 0.1163 (0.1497)  loss_objectness: 0.1027 (0.1121)  loss_rpn_box_reg: 0.0246 (0.0509)  time: 0.2832  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [6]  [ 200/1229]  eta: 0:04:42  lr: 0.005000  loss: 0.4103 (0.4749)  loss_classifier: 0.1321 (0.1611)  loss_box_reg: 0.1257 (0.1521)  loss_objectness: 0.0792 (0.1112)  loss_rpn_box_reg: 0.0268 (0.0505)  time: 0.2882  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [6]  [ 210/1229]  eta: 0:04:39  lr: 0.005000  loss: 0.3508 (0.4716)  loss_classifier: 0.1224 (0.1604)  loss_box_reg: 0.1021 (0.1503)  loss_objectness: 0.0872 (0.1113)  loss_rpn_box_reg: 0.0260 (0.0495)  time: 0.2787  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [6]  [ 220/1229]  eta: 0:04:36  lr: 0.005000  loss: 0.3414 (0.4687)  loss_classifier: 0.1096 (0.1589)  loss_box_reg: 0.0871 (0.1487)  loss_objectness: 0.0872 (0.1111)  loss_rpn_box_reg: 0.0175 (0.0501)  time: 0.2733  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [6]  [ 230/1229]  eta: 0:04:33  lr: 0.005000  loss: 0.3465 (0.4664)  loss_classifier: 0.1296 (0.1587)  loss_box_reg: 0.1124 (0.1479)  loss_objectness: 0.0825 (0.1104)  loss_rpn_box_reg: 0.0211 (0.0493)  time: 0.2716  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [6]  [ 240/1229]  eta: 0:04:30  lr: 0.005000  loss: 0.3700 (0.4655)  loss_classifier: 0.1390 (0.1581)  loss_box_reg: 0.1254 (0.1483)  loss_objectness: 0.0950 (0.1099)  loss_rpn_box_reg: 0.0371 (0.0492)  time: 0.2722  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [6]  [ 250/1229]  eta: 0:04:27  lr: 0.005000  loss: 0.4634 (0.4683)  loss_classifier: 0.1492 (0.1592)  loss_box_reg: 0.1417 (0.1499)  loss_objectness: 0.0991 (0.1104)  loss_rpn_box_reg: 0.0371 (0.0488)  time: 0.2723  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [6]  [ 260/1229]  eta: 0:04:25  lr: 0.005000  loss: 0.5047 (0.4693)  loss_classifier: 0.1600 (0.1595)  loss_box_reg: 0.1389 (0.1494)  loss_objectness: 0.1107 (0.1108)  loss_rpn_box_reg: 0.0289 (0.0495)  time: 0.2696  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [6]  [ 270/1229]  eta: 0:04:21  lr: 0.005000  loss: 0.5002 (0.4706)  loss_classifier: 0.1735 (0.1600)  loss_box_reg: 0.1206 (0.1497)  loss_objectness: 0.1128 (0.1114)  loss_rpn_box_reg: 0.0289 (0.0495)  time: 0.2653  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [6]  [ 280/1229]  eta: 0:04:19  lr: 0.005000  loss: 0.4551 (0.4706)  loss_classifier: 0.1735 (0.1603)  loss_box_reg: 0.1637 (0.1505)  loss_objectness: 0.1066 (0.1109)  loss_rpn_box_reg: 0.0262 (0.0488)  time: 0.2676  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [6]  [ 290/1229]  eta: 0:04:16  lr: 0.005000  loss: 0.4275 (0.4758)  loss_classifier: 0.1711 (0.1620)  loss_box_reg: 0.1406 (0.1522)  loss_objectness: 0.1116 (0.1124)  loss_rpn_box_reg: 0.0332 (0.0492)  time: 0.2724  data: 0.1303  max mem: 1751\n",
      "Training Epoch: [6]  [ 300/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.4275 (0.4743)  loss_classifier: 0.1643 (0.1615)  loss_box_reg: 0.1159 (0.1516)  loss_objectness: 0.1090 (0.1122)  loss_rpn_box_reg: 0.0386 (0.0490)  time: 0.2677  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [6]  [ 310/1229]  eta: 0:04:10  lr: 0.005000  loss: 0.3907 (0.4737)  loss_classifier: 0.1460 (0.1617)  loss_box_reg: 0.1127 (0.1513)  loss_objectness: 0.0983 (0.1120)  loss_rpn_box_reg: 0.0280 (0.0487)  time: 0.2647  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [6]  [ 320/1229]  eta: 0:04:07  lr: 0.005000  loss: 0.4609 (0.4770)  loss_classifier: 0.1619 (0.1629)  loss_box_reg: 0.1384 (0.1519)  loss_objectness: 0.1057 (0.1131)  loss_rpn_box_reg: 0.0310 (0.0491)  time: 0.2642  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [6]  [ 330/1229]  eta: 0:04:04  lr: 0.005000  loss: 0.4700 (0.4773)  loss_classifier: 0.1710 (0.1629)  loss_box_reg: 0.1635 (0.1518)  loss_objectness: 0.1207 (0.1133)  loss_rpn_box_reg: 0.0310 (0.0493)  time: 0.2696  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [6]  [ 340/1229]  eta: 0:04:01  lr: 0.005000  loss: 0.5057 (0.4799)  loss_classifier: 0.1562 (0.1637)  loss_box_reg: 0.1635 (0.1528)  loss_objectness: 0.1287 (0.1139)  loss_rpn_box_reg: 0.0371 (0.0495)  time: 0.2712  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [6]  [ 350/1229]  eta: 0:03:59  lr: 0.005000  loss: 0.4407 (0.4765)  loss_classifier: 0.1283 (0.1624)  loss_box_reg: 0.1020 (0.1517)  loss_objectness: 0.1045 (0.1131)  loss_rpn_box_reg: 0.0304 (0.0494)  time: 0.2683  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [6]  [ 360/1229]  eta: 0:03:56  lr: 0.005000  loss: 0.3493 (0.4791)  loss_classifier: 0.1204 (0.1632)  loss_box_reg: 0.1007 (0.1524)  loss_objectness: 0.0967 (0.1141)  loss_rpn_box_reg: 0.0262 (0.0494)  time: 0.2727  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [6]  [ 370/1229]  eta: 0:03:53  lr: 0.005000  loss: 0.5861 (0.4816)  loss_classifier: 0.1843 (0.1640)  loss_box_reg: 0.1478 (0.1529)  loss_objectness: 0.1093 (0.1144)  loss_rpn_box_reg: 0.0282 (0.0503)  time: 0.2736  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [6]  [ 380/1229]  eta: 0:03:50  lr: 0.005000  loss: 0.5861 (0.4831)  loss_classifier: 0.1667 (0.1638)  loss_box_reg: 0.1478 (0.1525)  loss_objectness: 0.1145 (0.1155)  loss_rpn_box_reg: 0.0357 (0.0514)  time: 0.2702  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [6]  [ 390/1229]  eta: 0:03:48  lr: 0.005000  loss: 0.4183 (0.4818)  loss_classifier: 0.1276 (0.1635)  loss_box_reg: 0.0943 (0.1512)  loss_objectness: 0.1313 (0.1158)  loss_rpn_box_reg: 0.0340 (0.0513)  time: 0.2716  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [6]  [ 400/1229]  eta: 0:03:45  lr: 0.005000  loss: 0.3495 (0.4812)  loss_classifier: 0.1542 (0.1634)  loss_box_reg: 0.0943 (0.1507)  loss_objectness: 0.1094 (0.1159)  loss_rpn_box_reg: 0.0260 (0.0511)  time: 0.2728  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [6]  [ 410/1229]  eta: 0:03:42  lr: 0.005000  loss: 0.4753 (0.4813)  loss_classifier: 0.1709 (0.1636)  loss_box_reg: 0.1637 (0.1508)  loss_objectness: 0.1094 (0.1158)  loss_rpn_box_reg: 0.0265 (0.0512)  time: 0.2720  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [6]  [ 420/1229]  eta: 0:03:39  lr: 0.005000  loss: 0.4516 (0.4781)  loss_classifier: 0.1635 (0.1627)  loss_box_reg: 0.1149 (0.1495)  loss_objectness: 0.1014 (0.1152)  loss_rpn_box_reg: 0.0293 (0.0506)  time: 0.2674  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [6]  [ 430/1229]  eta: 0:03:37  lr: 0.005000  loss: 0.4390 (0.4803)  loss_classifier: 0.1127 (0.1628)  loss_box_reg: 0.0923 (0.1502)  loss_objectness: 0.1115 (0.1155)  loss_rpn_box_reg: 0.0319 (0.0518)  time: 0.2741  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [6]  [ 440/1229]  eta: 0:03:34  lr: 0.005000  loss: 0.4314 (0.4785)  loss_classifier: 0.1476 (0.1625)  loss_box_reg: 0.1042 (0.1495)  loss_objectness: 0.1044 (0.1151)  loss_rpn_box_reg: 0.0401 (0.0514)  time: 0.2828  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [6]  [ 450/1229]  eta: 0:03:32  lr: 0.005000  loss: 0.3666 (0.4771)  loss_classifier: 0.1216 (0.1620)  loss_box_reg: 0.1107 (0.1494)  loss_objectness: 0.0795 (0.1145)  loss_rpn_box_reg: 0.0289 (0.0512)  time: 0.2765  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [6]  [ 460/1229]  eta: 0:03:29  lr: 0.005000  loss: 0.4085 (0.4796)  loss_classifier: 0.1375 (0.1628)  loss_box_reg: 0.1508 (0.1516)  loss_objectness: 0.0787 (0.1139)  loss_rpn_box_reg: 0.0420 (0.0512)  time: 0.2778  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [6]  [ 470/1229]  eta: 0:03:26  lr: 0.005000  loss: 0.5435 (0.4798)  loss_classifier: 0.1866 (0.1629)  loss_box_reg: 0.1583 (0.1519)  loss_objectness: 0.0866 (0.1140)  loss_rpn_box_reg: 0.0439 (0.0510)  time: 0.2779  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [6]  [ 480/1229]  eta: 0:03:24  lr: 0.005000  loss: 0.4752 (0.4829)  loss_classifier: 0.1698 (0.1636)  loss_box_reg: 0.1416 (0.1528)  loss_objectness: 0.1108 (0.1143)  loss_rpn_box_reg: 0.0291 (0.0522)  time: 0.2677  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [6]  [ 490/1229]  eta: 0:03:21  lr: 0.005000  loss: 0.4114 (0.4805)  loss_classifier: 0.1311 (0.1629)  loss_box_reg: 0.1006 (0.1516)  loss_objectness: 0.1108 (0.1141)  loss_rpn_box_reg: 0.0250 (0.0518)  time: 0.2657  data: 0.1295  max mem: 1751\n",
      "Training Epoch: [6]  [ 500/1229]  eta: 0:03:18  lr: 0.005000  loss: 0.4149 (0.4833)  loss_classifier: 0.1683 (0.1639)  loss_box_reg: 0.1151 (0.1523)  loss_objectness: 0.1169 (0.1148)  loss_rpn_box_reg: 0.0250 (0.0523)  time: 0.2705  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [6]  [ 510/1229]  eta: 0:03:15  lr: 0.005000  loss: 0.6291 (0.4860)  loss_classifier: 0.2063 (0.1650)  loss_box_reg: 0.1931 (0.1532)  loss_objectness: 0.1026 (0.1146)  loss_rpn_box_reg: 0.0649 (0.0532)  time: 0.2742  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [6]  [ 520/1229]  eta: 0:03:13  lr: 0.005000  loss: 0.6009 (0.4874)  loss_classifier: 0.2048 (0.1648)  loss_box_reg: 0.1998 (0.1535)  loss_objectness: 0.0801 (0.1148)  loss_rpn_box_reg: 0.0480 (0.0543)  time: 0.2724  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [6]  [ 530/1229]  eta: 0:03:10  lr: 0.005000  loss: 0.4004 (0.4858)  loss_classifier: 0.1211 (0.1641)  loss_box_reg: 0.1049 (0.1530)  loss_objectness: 0.0801 (0.1143)  loss_rpn_box_reg: 0.0308 (0.0544)  time: 0.2682  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [6]  [ 540/1229]  eta: 0:03:07  lr: 0.005000  loss: 0.3692 (0.4852)  loss_classifier: 0.1091 (0.1637)  loss_box_reg: 0.0877 (0.1527)  loss_objectness: 0.0764 (0.1145)  loss_rpn_box_reg: 0.0336 (0.0543)  time: 0.2733  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [6]  [ 550/1229]  eta: 0:03:04  lr: 0.005000  loss: 0.4188 (0.4862)  loss_classifier: 0.1403 (0.1639)  loss_box_reg: 0.0942 (0.1533)  loss_objectness: 0.1035 (0.1145)  loss_rpn_box_reg: 0.0477 (0.0545)  time: 0.2752  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [6]  [ 560/1229]  eta: 0:03:02  lr: 0.005000  loss: 0.4979 (0.4859)  loss_classifier: 0.1786 (0.1638)  loss_box_reg: 0.1460 (0.1531)  loss_objectness: 0.1114 (0.1145)  loss_rpn_box_reg: 0.0477 (0.0544)  time: 0.2746  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [6]  [ 570/1229]  eta: 0:02:59  lr: 0.005000  loss: 0.3982 (0.4851)  loss_classifier: 0.1486 (0.1638)  loss_box_reg: 0.1281 (0.1527)  loss_objectness: 0.1102 (0.1143)  loss_rpn_box_reg: 0.0278 (0.0543)  time: 0.2705  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [6]  [ 580/1229]  eta: 0:02:56  lr: 0.005000  loss: 0.4151 (0.4851)  loss_classifier: 0.1516 (0.1640)  loss_box_reg: 0.1248 (0.1525)  loss_objectness: 0.0940 (0.1144)  loss_rpn_box_reg: 0.0233 (0.0542)  time: 0.2642  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [6]  [ 590/1229]  eta: 0:02:53  lr: 0.005000  loss: 0.4287 (0.4854)  loss_classifier: 0.1489 (0.1641)  loss_box_reg: 0.1394 (0.1526)  loss_objectness: 0.0952 (0.1145)  loss_rpn_box_reg: 0.0301 (0.0542)  time: 0.2675  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [6]  [ 600/1229]  eta: 0:02:51  lr: 0.005000  loss: 0.4453 (0.4849)  loss_classifier: 0.1447 (0.1637)  loss_box_reg: 0.1103 (0.1517)  loss_objectness: 0.1103 (0.1153)  loss_rpn_box_reg: 0.0231 (0.0543)  time: 0.2704  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [6]  [ 610/1229]  eta: 0:02:48  lr: 0.005000  loss: 0.4453 (0.4853)  loss_classifier: 0.1415 (0.1637)  loss_box_reg: 0.0936 (0.1518)  loss_objectness: 0.1047 (0.1156)  loss_rpn_box_reg: 0.0275 (0.0542)  time: 0.2730  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [6]  [ 620/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.4406 (0.4853)  loss_classifier: 0.1666 (0.1639)  loss_box_reg: 0.1318 (0.1518)  loss_objectness: 0.0881 (0.1155)  loss_rpn_box_reg: 0.0291 (0.0540)  time: 0.2768  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [6]  [ 630/1229]  eta: 0:02:43  lr: 0.005000  loss: 0.3844 (0.4835)  loss_classifier: 0.1399 (0.1636)  loss_box_reg: 0.1221 (0.1513)  loss_objectness: 0.0874 (0.1150)  loss_rpn_box_reg: 0.0159 (0.0536)  time: 0.2790  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [6]  [ 640/1229]  eta: 0:02:40  lr: 0.005000  loss: 0.3326 (0.4805)  loss_classifier: 0.1290 (0.1628)  loss_box_reg: 0.0985 (0.1503)  loss_objectness: 0.0706 (0.1144)  loss_rpn_box_reg: 0.0159 (0.0531)  time: 0.2727  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [6]  [ 650/1229]  eta: 0:02:37  lr: 0.005000  loss: 0.3133 (0.4790)  loss_classifier: 0.1237 (0.1622)  loss_box_reg: 0.1041 (0.1499)  loss_objectness: 0.0701 (0.1139)  loss_rpn_box_reg: 0.0257 (0.0530)  time: 0.2715  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [6]  [ 660/1229]  eta: 0:02:34  lr: 0.005000  loss: 0.3417 (0.4782)  loss_classifier: 0.1237 (0.1620)  loss_box_reg: 0.1041 (0.1493)  loss_objectness: 0.0730 (0.1140)  loss_rpn_box_reg: 0.0301 (0.0529)  time: 0.2738  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [6]  [ 670/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.4082 (0.4773)  loss_classifier: 0.1334 (0.1619)  loss_box_reg: 0.0995 (0.1491)  loss_objectness: 0.1090 (0.1139)  loss_rpn_box_reg: 0.0243 (0.0525)  time: 0.2698  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [6]  [ 680/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.4082 (0.4773)  loss_classifier: 0.1334 (0.1620)  loss_box_reg: 0.1224 (0.1495)  loss_objectness: 0.1052 (0.1136)  loss_rpn_box_reg: 0.0171 (0.0521)  time: 0.2704  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [6]  [ 690/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.3451 (0.4759)  loss_classifier: 0.1121 (0.1616)  loss_box_reg: 0.1108 (0.1491)  loss_objectness: 0.0676 (0.1133)  loss_rpn_box_reg: 0.0223 (0.0519)  time: 0.2718  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [6]  [ 700/1229]  eta: 0:02:24  lr: 0.005000  loss: 0.3543 (0.4756)  loss_classifier: 0.1038 (0.1616)  loss_box_reg: 0.0804 (0.1488)  loss_objectness: 0.1118 (0.1135)  loss_rpn_box_reg: 0.0243 (0.0517)  time: 0.2759  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [6]  [ 710/1229]  eta: 0:02:21  lr: 0.005000  loss: 0.4194 (0.4761)  loss_classifier: 0.1487 (0.1617)  loss_box_reg: 0.1082 (0.1490)  loss_objectness: 0.1118 (0.1137)  loss_rpn_box_reg: 0.0283 (0.0518)  time: 0.2723  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [6]  [ 720/1229]  eta: 0:02:18  lr: 0.005000  loss: 0.3676 (0.4755)  loss_classifier: 0.1399 (0.1615)  loss_box_reg: 0.1071 (0.1487)  loss_objectness: 0.1064 (0.1138)  loss_rpn_box_reg: 0.0283 (0.0516)  time: 0.2628  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [6]  [ 730/1229]  eta: 0:02:15  lr: 0.005000  loss: 0.4349 (0.4765)  loss_classifier: 0.1713 (0.1620)  loss_box_reg: 0.1364 (0.1493)  loss_objectness: 0.1044 (0.1138)  loss_rpn_box_reg: 0.0338 (0.0514)  time: 0.2710  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [6]  [ 740/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.4773 (0.4763)  loss_classifier: 0.1716 (0.1618)  loss_box_reg: 0.1302 (0.1492)  loss_objectness: 0.1000 (0.1139)  loss_rpn_box_reg: 0.0347 (0.0513)  time: 0.2776  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [6]  [ 750/1229]  eta: 0:02:10  lr: 0.005000  loss: 0.3295 (0.4762)  loss_classifier: 0.1155 (0.1619)  loss_box_reg: 0.1161 (0.1491)  loss_objectness: 0.0964 (0.1139)  loss_rpn_box_reg: 0.0281 (0.0513)  time: 0.2752  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [6]  [ 760/1229]  eta: 0:02:07  lr: 0.005000  loss: 0.4372 (0.4762)  loss_classifier: 0.1708 (0.1618)  loss_box_reg: 0.1176 (0.1488)  loss_objectness: 0.0978 (0.1141)  loss_rpn_box_reg: 0.0281 (0.0514)  time: 0.2695  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [6]  [ 770/1229]  eta: 0:02:04  lr: 0.005000  loss: 0.4142 (0.4758)  loss_classifier: 0.1620 (0.1617)  loss_box_reg: 0.1155 (0.1487)  loss_objectness: 0.1003 (0.1139)  loss_rpn_box_reg: 0.0280 (0.0515)  time: 0.2695  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [6]  [ 780/1229]  eta: 0:02:02  lr: 0.005000  loss: 0.3990 (0.4756)  loss_classifier: 0.1454 (0.1616)  loss_box_reg: 0.1495 (0.1488)  loss_objectness: 0.0897 (0.1137)  loss_rpn_box_reg: 0.0280 (0.0514)  time: 0.2760  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [6]  [ 790/1229]  eta: 0:01:59  lr: 0.005000  loss: 0.4239 (0.4751)  loss_classifier: 0.1538 (0.1616)  loss_box_reg: 0.1658 (0.1490)  loss_objectness: 0.0710 (0.1133)  loss_rpn_box_reg: 0.0268 (0.0512)  time: 0.2714  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [6]  [ 800/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.4277 (0.4748)  loss_classifier: 0.1427 (0.1613)  loss_box_reg: 0.1169 (0.1487)  loss_objectness: 0.0710 (0.1136)  loss_rpn_box_reg: 0.0268 (0.0513)  time: 0.2675  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [6]  [ 810/1229]  eta: 0:01:54  lr: 0.005000  loss: 0.4372 (0.4735)  loss_classifier: 0.1168 (0.1608)  loss_box_reg: 0.0919 (0.1478)  loss_objectness: 0.1267 (0.1139)  loss_rpn_box_reg: 0.0330 (0.0510)  time: 0.2684  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [6]  [ 820/1229]  eta: 0:01:51  lr: 0.005000  loss: 0.3735 (0.4740)  loss_classifier: 0.1149 (0.1608)  loss_box_reg: 0.0842 (0.1477)  loss_objectness: 0.1141 (0.1141)  loss_rpn_box_reg: 0.0369 (0.0513)  time: 0.2722  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [6]  [ 830/1229]  eta: 0:01:48  lr: 0.005000  loss: 0.3453 (0.4723)  loss_classifier: 0.1149 (0.1602)  loss_box_reg: 0.0842 (0.1470)  loss_objectness: 0.1044 (0.1139)  loss_rpn_box_reg: 0.0318 (0.0512)  time: 0.2769  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [6]  [ 840/1229]  eta: 0:01:45  lr: 0.005000  loss: 0.3097 (0.4708)  loss_classifier: 0.1131 (0.1598)  loss_box_reg: 0.0651 (0.1463)  loss_objectness: 0.0826 (0.1138)  loss_rpn_box_reg: 0.0264 (0.0508)  time: 0.2792  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [6]  [ 850/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.3497 (0.4699)  loss_classifier: 0.1131 (0.1597)  loss_box_reg: 0.0793 (0.1459)  loss_objectness: 0.0897 (0.1138)  loss_rpn_box_reg: 0.0158 (0.0505)  time: 0.2752  data: 0.1377  max mem: 1751\n",
      "Training Epoch: [6]  [ 860/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.4413 (0.4717)  loss_classifier: 0.1498 (0.1601)  loss_box_reg: 0.1271 (0.1465)  loss_objectness: 0.1173 (0.1141)  loss_rpn_box_reg: 0.0283 (0.0509)  time: 0.2710  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [6]  [ 870/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.4981 (0.4723)  loss_classifier: 0.1562 (0.1602)  loss_box_reg: 0.1512 (0.1469)  loss_objectness: 0.1173 (0.1141)  loss_rpn_box_reg: 0.0391 (0.0511)  time: 0.2716  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [6]  [ 880/1229]  eta: 0:01:35  lr: 0.005000  loss: 0.4994 (0.4720)  loss_classifier: 0.1814 (0.1602)  loss_box_reg: 0.1390 (0.1468)  loss_objectness: 0.0977 (0.1140)  loss_rpn_box_reg: 0.0391 (0.0510)  time: 0.2754  data: 0.1303  max mem: 1751\n",
      "Training Epoch: [6]  [ 890/1229]  eta: 0:01:32  lr: 0.005000  loss: 0.3860 (0.4724)  loss_classifier: 0.1599 (0.1604)  loss_box_reg: 0.1361 (0.1472)  loss_objectness: 0.0884 (0.1139)  loss_rpn_box_reg: 0.0324 (0.0509)  time: 0.2781  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [6]  [ 900/1229]  eta: 0:01:29  lr: 0.005000  loss: 0.3860 (0.4734)  loss_classifier: 0.1599 (0.1606)  loss_box_reg: 0.1172 (0.1473)  loss_objectness: 0.1032 (0.1144)  loss_rpn_box_reg: 0.0525 (0.0512)  time: 0.2758  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [6]  [ 910/1229]  eta: 0:01:26  lr: 0.005000  loss: 0.4623 (0.4740)  loss_classifier: 0.1686 (0.1611)  loss_box_reg: 0.1212 (0.1476)  loss_objectness: 0.1154 (0.1144)  loss_rpn_box_reg: 0.0362 (0.0509)  time: 0.2739  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [6]  [ 920/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.4623 (0.4741)  loss_classifier: 0.1934 (0.1613)  loss_box_reg: 0.1443 (0.1479)  loss_objectness: 0.0933 (0.1141)  loss_rpn_box_reg: 0.0265 (0.0508)  time: 0.2735  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [6]  [ 930/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.4861 (0.4750)  loss_classifier: 0.1913 (0.1617)  loss_box_reg: 0.1783 (0.1482)  loss_objectness: 0.0779 (0.1143)  loss_rpn_box_reg: 0.0331 (0.0508)  time: 0.2751  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [6]  [ 940/1229]  eta: 0:01:18  lr: 0.005000  loss: 0.4193 (0.4751)  loss_classifier: 0.1534 (0.1616)  loss_box_reg: 0.1169 (0.1484)  loss_objectness: 0.1031 (0.1142)  loss_rpn_box_reg: 0.0291 (0.0508)  time: 0.2710  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [6]  [ 950/1229]  eta: 0:01:16  lr: 0.005000  loss: 0.4193 (0.4754)  loss_classifier: 0.1534 (0.1618)  loss_box_reg: 0.1235 (0.1484)  loss_objectness: 0.1037 (0.1144)  loss_rpn_box_reg: 0.0250 (0.0508)  time: 0.2713  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [6]  [ 960/1229]  eta: 0:01:13  lr: 0.005000  loss: 0.4934 (0.4759)  loss_classifier: 0.1656 (0.1621)  loss_box_reg: 0.1115 (0.1485)  loss_objectness: 0.1102 (0.1146)  loss_rpn_box_reg: 0.0268 (0.0507)  time: 0.2763  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [6]  [ 970/1229]  eta: 0:01:10  lr: 0.005000  loss: 0.3912 (0.4749)  loss_classifier: 0.1490 (0.1618)  loss_box_reg: 0.1064 (0.1482)  loss_objectness: 0.1072 (0.1144)  loss_rpn_box_reg: 0.0229 (0.0505)  time: 0.2722  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [6]  [ 980/1229]  eta: 0:01:07  lr: 0.005000  loss: 0.3912 (0.4762)  loss_classifier: 0.1500 (0.1624)  loss_box_reg: 0.1298 (0.1487)  loss_objectness: 0.1077 (0.1147)  loss_rpn_box_reg: 0.0233 (0.0504)  time: 0.2738  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [6]  [ 990/1229]  eta: 0:01:05  lr: 0.005000  loss: 0.5156 (0.4763)  loss_classifier: 0.1270 (0.1625)  loss_box_reg: 0.1150 (0.1487)  loss_objectness: 0.1077 (0.1147)  loss_rpn_box_reg: 0.0258 (0.0504)  time: 0.2752  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [6]  [1000/1229]  eta: 0:01:02  lr: 0.005000  loss: 0.4258 (0.4758)  loss_classifier: 0.1342 (0.1624)  loss_box_reg: 0.1150 (0.1485)  loss_objectness: 0.0802 (0.1146)  loss_rpn_box_reg: 0.0171 (0.0503)  time: 0.2709  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [6]  [1010/1229]  eta: 0:00:59  lr: 0.005000  loss: 0.4258 (0.4753)  loss_classifier: 0.1406 (0.1622)  loss_box_reg: 0.1268 (0.1482)  loss_objectness: 0.0802 (0.1145)  loss_rpn_box_reg: 0.0336 (0.0504)  time: 0.2699  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [6]  [1020/1229]  eta: 0:00:56  lr: 0.005000  loss: 0.4353 (0.4764)  loss_classifier: 0.1493 (0.1626)  loss_box_reg: 0.1340 (0.1488)  loss_objectness: 0.0927 (0.1146)  loss_rpn_box_reg: 0.0326 (0.0504)  time: 0.2686  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [6]  [1030/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.6611 (0.4792)  loss_classifier: 0.2397 (0.1634)  loss_box_reg: 0.2908 (0.1502)  loss_objectness: 0.1102 (0.1148)  loss_rpn_box_reg: 0.0326 (0.0509)  time: 0.2670  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [6]  [1040/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.6529 (0.4797)  loss_classifier: 0.2020 (0.1636)  loss_box_reg: 0.2358 (0.1506)  loss_objectness: 0.1079 (0.1146)  loss_rpn_box_reg: 0.0397 (0.0509)  time: 0.2728  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [6]  [1050/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.5182 (0.4795)  loss_classifier: 0.1692 (0.1634)  loss_box_reg: 0.1519 (0.1505)  loss_objectness: 0.0947 (0.1146)  loss_rpn_box_reg: 0.0376 (0.0510)  time: 0.2792  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [6]  [1060/1229]  eta: 0:00:46  lr: 0.005000  loss: 0.4102 (0.4794)  loss_classifier: 0.1224 (0.1634)  loss_box_reg: 0.1028 (0.1503)  loss_objectness: 0.1065 (0.1147)  loss_rpn_box_reg: 0.0356 (0.0509)  time: 0.2763  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [6]  [1070/1229]  eta: 0:00:43  lr: 0.005000  loss: 0.4047 (0.4796)  loss_classifier: 0.1224 (0.1635)  loss_box_reg: 0.1028 (0.1504)  loss_objectness: 0.0860 (0.1149)  loss_rpn_box_reg: 0.0293 (0.0508)  time: 0.2685  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [6]  [1080/1229]  eta: 0:00:40  lr: 0.005000  loss: 0.4047 (0.4796)  loss_classifier: 0.1447 (0.1635)  loss_box_reg: 0.1475 (0.1505)  loss_objectness: 0.0860 (0.1147)  loss_rpn_box_reg: 0.0295 (0.0509)  time: 0.2699  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [6]  [1090/1229]  eta: 0:00:37  lr: 0.005000  loss: 0.4267 (0.4803)  loss_classifier: 0.1577 (0.1638)  loss_box_reg: 0.1433 (0.1506)  loss_objectness: 0.0957 (0.1148)  loss_rpn_box_reg: 0.0299 (0.0510)  time: 0.2746  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [6]  [1100/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.5346 (0.4810)  loss_classifier: 0.1719 (0.1642)  loss_box_reg: 0.1433 (0.1510)  loss_objectness: 0.1135 (0.1148)  loss_rpn_box_reg: 0.0324 (0.0510)  time: 0.2728  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [6]  [1110/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.4158 (0.4803)  loss_classifier: 0.1616 (0.1640)  loss_box_reg: 0.1282 (0.1508)  loss_objectness: 0.0966 (0.1146)  loss_rpn_box_reg: 0.0271 (0.0509)  time: 0.2791  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [6]  [1120/1229]  eta: 0:00:29  lr: 0.005000  loss: 0.3799 (0.4795)  loss_classifier: 0.1113 (0.1637)  loss_box_reg: 0.1202 (0.1505)  loss_objectness: 0.0966 (0.1146)  loss_rpn_box_reg: 0.0220 (0.0507)  time: 0.2727  data: 0.1297  max mem: 1751\n",
      "Training Epoch: [6]  [1130/1229]  eta: 0:00:26  lr: 0.005000  loss: 0.3792 (0.4801)  loss_classifier: 0.1152 (0.1638)  loss_box_reg: 0.1202 (0.1506)  loss_objectness: 0.0916 (0.1147)  loss_rpn_box_reg: 0.0262 (0.0509)  time: 0.2658  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [6]  [1140/1229]  eta: 0:00:24  lr: 0.005000  loss: 0.4054 (0.4801)  loss_classifier: 0.1655 (0.1639)  loss_box_reg: 0.1558 (0.1507)  loss_objectness: 0.0916 (0.1147)  loss_rpn_box_reg: 0.0269 (0.0508)  time: 0.2732  data: 0.1386  max mem: 1751\n",
      "Training Epoch: [6]  [1150/1229]  eta: 0:00:21  lr: 0.005000  loss: 0.4054 (0.4796)  loss_classifier: 0.1567 (0.1638)  loss_box_reg: 0.1588 (0.1507)  loss_objectness: 0.0830 (0.1144)  loss_rpn_box_reg: 0.0216 (0.0506)  time: 0.2713  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [6]  [1160/1229]  eta: 0:00:18  lr: 0.005000  loss: 0.4031 (0.4796)  loss_classifier: 0.1503 (0.1639)  loss_box_reg: 0.0860 (0.1507)  loss_objectness: 0.0830 (0.1142)  loss_rpn_box_reg: 0.0218 (0.0507)  time: 0.2706  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [6]  [1170/1229]  eta: 0:00:16  lr: 0.005000  loss: 0.3721 (0.4788)  loss_classifier: 0.1135 (0.1634)  loss_box_reg: 0.0834 (0.1501)  loss_objectness: 0.0896 (0.1144)  loss_rpn_box_reg: 0.0216 (0.0509)  time: 0.2742  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [6]  [1180/1229]  eta: 0:00:13  lr: 0.005000  loss: 0.3242 (0.4782)  loss_classifier: 0.0883 (0.1631)  loss_box_reg: 0.0804 (0.1498)  loss_objectness: 0.1004 (0.1144)  loss_rpn_box_reg: 0.0138 (0.0509)  time: 0.2726  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [6]  [1190/1229]  eta: 0:00:10  lr: 0.005000  loss: 0.3168 (0.4776)  loss_classifier: 0.1063 (0.1629)  loss_box_reg: 0.0804 (0.1498)  loss_objectness: 0.0721 (0.1141)  loss_rpn_box_reg: 0.0167 (0.0507)  time: 0.2693  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [6]  [1200/1229]  eta: 0:00:07  lr: 0.005000  loss: 0.3486 (0.4774)  loss_classifier: 0.1166 (0.1628)  loss_box_reg: 0.1281 (0.1499)  loss_objectness: 0.0752 (0.1140)  loss_rpn_box_reg: 0.0228 (0.0507)  time: 0.2707  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [6]  [1210/1229]  eta: 0:00:05  lr: 0.005000  loss: 0.3486 (0.4760)  loss_classifier: 0.1141 (0.1623)  loss_box_reg: 0.1088 (0.1493)  loss_objectness: 0.0789 (0.1138)  loss_rpn_box_reg: 0.0302 (0.0506)  time: 0.2686  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [6]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.3176 (0.4756)  loss_classifier: 0.1031 (0.1620)  loss_box_reg: 0.0716 (0.1493)  loss_objectness: 0.0779 (0.1137)  loss_rpn_box_reg: 0.0173 (0.0506)  time: 0.2688  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [6]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.3752 (0.4762)  loss_classifier: 0.1134 (0.1622)  loss_box_reg: 0.1235 (0.1495)  loss_objectness: 0.1001 (0.1139)  loss_rpn_box_reg: 0.0291 (0.0506)  time: 0.2747  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [6] Total time: 0:05:34 (0.2725 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:43  model_time: 0.3010 (0.3010)  evaluator_time: 0.0030 (0.0030)  time: 0.3350  data: 0.0280  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0760 (0.0817)  evaluator_time: 0.0060 (0.0087)  time: 0.1268  data: 0.0354  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0820 (0.0806)  evaluator_time: 0.0030 (0.0081)  time: 0.1202  data: 0.0306  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0730 (0.0796)  evaluator_time: 0.0050 (0.0080)  time: 0.1244  data: 0.0404  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0720 (0.0795)  evaluator_time: 0.0030 (0.0079)  time: 0.1213  data: 0.0388  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1238 s / it)\n",
      "Averaged stats: model_time: 0.0720 (0.0795)  evaluator_time: 0.0030 (0.0079)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.242\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.094\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.152\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262\n",
      "Testing Epoch: [6]  [  0/308]  eta: 0:00:38  lr: 0.005000  loss: 0.1843 (0.1843)  loss_classifier: 0.0642 (0.0642)  loss_box_reg: 0.0810 (0.0810)  loss_objectness: 0.0303 (0.0303)  loss_rpn_box_reg: 0.0088 (0.0088)  time: 0.1250  data: 0.0310  max mem: 1751\n",
      "Testing Epoch: [6]  [100/308]  eta: 0:00:28  lr: 0.005000  loss: 0.3213 (0.4972)  loss_classifier: 0.1298 (0.1567)  loss_box_reg: 0.1309 (0.1699)  loss_objectness: 0.0633 (0.1036)  loss_rpn_box_reg: 0.0188 (0.0671)  time: 0.1382  data: 0.0375  max mem: 1751\n",
      "Testing Epoch: [6]  [200/308]  eta: 0:00:14  lr: 0.005000  loss: 0.3780 (0.4683)  loss_classifier: 0.1398 (0.1478)  loss_box_reg: 0.1237 (0.1589)  loss_objectness: 0.0777 (0.0986)  loss_rpn_box_reg: 0.0230 (0.0629)  time: 0.1371  data: 0.0321  max mem: 1751\n",
      "Testing Epoch: [6]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5531 (0.4689)  loss_classifier: 0.1512 (0.1486)  loss_box_reg: 0.1367 (0.1617)  loss_objectness: 0.0848 (0.0968)  loss_rpn_box_reg: 0.0299 (0.0618)  time: 0.1326  data: 0.0373  max mem: 1751\n",
      "Testing Epoch: [6]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.5442 (0.4692)  loss_classifier: 0.1617 (0.1490)  loss_box_reg: 0.1528 (0.1623)  loss_objectness: 0.0848 (0.0968)  loss_rpn_box_reg: 0.0240 (0.0611)  time: 0.1306  data: 0.0349  max mem: 1751\n",
      "Testing Epoch: [6] Total time: 0:00:42 (0.1364 s / it)\n",
      "Training Epoch: [7]  [   0/1229]  eta: 0:05:51  lr: 0.005000  loss: 0.8970 (0.8970)  loss_classifier: 0.2593 (0.2593)  loss_box_reg: 0.2661 (0.2661)  loss_objectness: 0.1070 (0.1070)  loss_rpn_box_reg: 0.2645 (0.2645)  time: 0.2860  data: 0.1290  max mem: 1751\n",
      "Training Epoch: [7]  [  10/1229]  eta: 0:05:34  lr: 0.005000  loss: 0.4249 (0.5027)  loss_classifier: 0.1434 (0.1661)  loss_box_reg: 0.1104 (0.1282)  loss_objectness: 0.0994 (0.1151)  loss_rpn_box_reg: 0.0370 (0.0933)  time: 0.2746  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [7]  [  20/1229]  eta: 0:05:28  lr: 0.005000  loss: 0.4107 (0.4875)  loss_classifier: 0.1434 (0.1648)  loss_box_reg: 0.1104 (0.1201)  loss_objectness: 0.1137 (0.1318)  loss_rpn_box_reg: 0.0320 (0.0706)  time: 0.2713  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [7]  [  30/1229]  eta: 0:05:26  lr: 0.005000  loss: 0.4292 (0.4785)  loss_classifier: 0.1616 (0.1636)  loss_box_reg: 0.1237 (0.1256)  loss_objectness: 0.1137 (0.1287)  loss_rpn_box_reg: 0.0268 (0.0606)  time: 0.2707  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [7]  [  40/1229]  eta: 0:05:23  lr: 0.005000  loss: 0.3860 (0.4536)  loss_classifier: 0.1473 (0.1592)  loss_box_reg: 0.0912 (0.1221)  loss_objectness: 0.0921 (0.1175)  loss_rpn_box_reg: 0.0236 (0.0546)  time: 0.2719  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [7]  [  50/1229]  eta: 0:05:21  lr: 0.005000  loss: 0.3631 (0.4380)  loss_classifier: 0.1224 (0.1528)  loss_box_reg: 0.0792 (0.1200)  loss_objectness: 0.0921 (0.1135)  loss_rpn_box_reg: 0.0236 (0.0517)  time: 0.2732  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [7]  [  60/1229]  eta: 0:05:17  lr: 0.005000  loss: 0.3495 (0.4306)  loss_classifier: 0.0986 (0.1490)  loss_box_reg: 0.0792 (0.1204)  loss_objectness: 0.0758 (0.1095)  loss_rpn_box_reg: 0.0255 (0.0517)  time: 0.2716  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [7]  [  70/1229]  eta: 0:05:14  lr: 0.005000  loss: 0.3209 (0.4303)  loss_classifier: 0.0986 (0.1466)  loss_box_reg: 0.0859 (0.1218)  loss_objectness: 0.0992 (0.1108)  loss_rpn_box_reg: 0.0255 (0.0510)  time: 0.2668  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [7]  [  80/1229]  eta: 0:05:11  lr: 0.005000  loss: 0.3947 (0.4383)  loss_classifier: 0.1370 (0.1504)  loss_box_reg: 0.1164 (0.1268)  loss_objectness: 0.1140 (0.1120)  loss_rpn_box_reg: 0.0257 (0.0491)  time: 0.2695  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [7]  [  90/1229]  eta: 0:05:11  lr: 0.005000  loss: 0.3924 (0.4316)  loss_classifier: 0.1444 (0.1488)  loss_box_reg: 0.1377 (0.1265)  loss_objectness: 0.1099 (0.1095)  loss_rpn_box_reg: 0.0257 (0.0468)  time: 0.2809  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [7]  [ 100/1229]  eta: 0:05:07  lr: 0.005000  loss: 0.3568 (0.4287)  loss_classifier: 0.1025 (0.1478)  loss_box_reg: 0.0993 (0.1278)  loss_objectness: 0.0735 (0.1076)  loss_rpn_box_reg: 0.0162 (0.0455)  time: 0.2754  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [7]  [ 110/1229]  eta: 0:05:04  lr: 0.005000  loss: 0.3671 (0.4418)  loss_classifier: 0.1484 (0.1532)  loss_box_reg: 0.1169 (0.1334)  loss_objectness: 0.0788 (0.1086)  loss_rpn_box_reg: 0.0140 (0.0466)  time: 0.2691  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [7]  [ 120/1229]  eta: 0:05:01  lr: 0.005000  loss: 0.4431 (0.4490)  loss_classifier: 0.1725 (0.1558)  loss_box_reg: 0.1548 (0.1362)  loss_objectness: 0.0992 (0.1101)  loss_rpn_box_reg: 0.0237 (0.0469)  time: 0.2720  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [7]  [ 130/1229]  eta: 0:04:59  lr: 0.005000  loss: 0.3612 (0.4456)  loss_classifier: 0.1304 (0.1542)  loss_box_reg: 0.1239 (0.1354)  loss_objectness: 0.0972 (0.1100)  loss_rpn_box_reg: 0.0204 (0.0460)  time: 0.2712  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [7]  [ 140/1229]  eta: 0:04:56  lr: 0.005000  loss: 0.3706 (0.4449)  loss_classifier: 0.1197 (0.1531)  loss_box_reg: 0.1093 (0.1354)  loss_objectness: 0.0664 (0.1083)  loss_rpn_box_reg: 0.0179 (0.0482)  time: 0.2714  data: 0.1284  max mem: 1751\n",
      "Training Epoch: [7]  [ 150/1229]  eta: 0:04:53  lr: 0.005000  loss: 0.4490 (0.4535)  loss_classifier: 0.1495 (0.1551)  loss_box_reg: 0.1278 (0.1382)  loss_objectness: 0.0914 (0.1105)  loss_rpn_box_reg: 0.0408 (0.0496)  time: 0.2706  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [7]  [ 160/1229]  eta: 0:04:51  lr: 0.005000  loss: 0.4490 (0.4536)  loss_classifier: 0.1501 (0.1557)  loss_box_reg: 0.1278 (0.1381)  loss_objectness: 0.1156 (0.1106)  loss_rpn_box_reg: 0.0313 (0.0491)  time: 0.2751  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [7]  [ 170/1229]  eta: 0:04:47  lr: 0.005000  loss: 0.3609 (0.4496)  loss_classifier: 0.1331 (0.1535)  loss_box_reg: 0.0994 (0.1355)  loss_objectness: 0.0715 (0.1109)  loss_rpn_box_reg: 0.0238 (0.0496)  time: 0.2707  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [7]  [ 180/1229]  eta: 0:04:45  lr: 0.005000  loss: 0.2629 (0.4440)  loss_classifier: 0.1079 (0.1512)  loss_box_reg: 0.0800 (0.1332)  loss_objectness: 0.0662 (0.1097)  loss_rpn_box_reg: 0.0196 (0.0499)  time: 0.2707  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [7]  [ 190/1229]  eta: 0:04:43  lr: 0.005000  loss: 0.3875 (0.4448)  loss_classifier: 0.1081 (0.1519)  loss_box_reg: 0.0971 (0.1345)  loss_objectness: 0.0769 (0.1087)  loss_rpn_box_reg: 0.0233 (0.0498)  time: 0.2769  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [7]  [ 200/1229]  eta: 0:04:40  lr: 0.005000  loss: 0.4235 (0.4452)  loss_classifier: 0.1357 (0.1518)  loss_box_reg: 0.1365 (0.1342)  loss_objectness: 0.0941 (0.1099)  loss_rpn_box_reg: 0.0266 (0.0494)  time: 0.2737  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [7]  [ 210/1229]  eta: 0:04:37  lr: 0.005000  loss: 0.4235 (0.4486)  loss_classifier: 0.1602 (0.1533)  loss_box_reg: 0.1365 (0.1366)  loss_objectness: 0.0982 (0.1092)  loss_rpn_box_reg: 0.0275 (0.0494)  time: 0.2673  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [7]  [ 220/1229]  eta: 0:04:34  lr: 0.005000  loss: 0.4353 (0.4480)  loss_classifier: 0.1602 (0.1533)  loss_box_reg: 0.1317 (0.1356)  loss_objectness: 0.0914 (0.1094)  loss_rpn_box_reg: 0.0348 (0.0497)  time: 0.2690  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [7]  [ 230/1229]  eta: 0:04:31  lr: 0.005000  loss: 0.4114 (0.4470)  loss_classifier: 0.1278 (0.1531)  loss_box_reg: 0.0983 (0.1348)  loss_objectness: 0.0931 (0.1093)  loss_rpn_box_reg: 0.0341 (0.0499)  time: 0.2729  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [7]  [ 240/1229]  eta: 0:04:29  lr: 0.005000  loss: 0.4400 (0.4507)  loss_classifier: 0.1482 (0.1545)  loss_box_reg: 0.1364 (0.1368)  loss_objectness: 0.0935 (0.1096)  loss_rpn_box_reg: 0.0319 (0.0498)  time: 0.2724  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [7]  [ 250/1229]  eta: 0:04:26  lr: 0.005000  loss: 0.4639 (0.4502)  loss_classifier: 0.1617 (0.1546)  loss_box_reg: 0.1350 (0.1365)  loss_objectness: 0.1126 (0.1099)  loss_rpn_box_reg: 0.0312 (0.0492)  time: 0.2714  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [7]  [ 260/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.4428 (0.4505)  loss_classifier: 0.1569 (0.1546)  loss_box_reg: 0.1124 (0.1364)  loss_objectness: 0.1055 (0.1104)  loss_rpn_box_reg: 0.0217 (0.0491)  time: 0.2749  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [7]  [ 270/1229]  eta: 0:04:21  lr: 0.005000  loss: 0.4428 (0.4519)  loss_classifier: 0.1569 (0.1550)  loss_box_reg: 0.1061 (0.1374)  loss_objectness: 0.0972 (0.1102)  loss_rpn_box_reg: 0.0292 (0.0494)  time: 0.2797  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [7]  [ 280/1229]  eta: 0:04:18  lr: 0.005000  loss: 0.3913 (0.4508)  loss_classifier: 0.1420 (0.1547)  loss_box_reg: 0.1021 (0.1378)  loss_objectness: 0.0904 (0.1095)  loss_rpn_box_reg: 0.0159 (0.0487)  time: 0.2788  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [7]  [ 290/1229]  eta: 0:04:16  lr: 0.005000  loss: 0.4517 (0.4557)  loss_classifier: 0.1500 (0.1555)  loss_box_reg: 0.1802 (0.1398)  loss_objectness: 0.0961 (0.1100)  loss_rpn_box_reg: 0.0270 (0.0504)  time: 0.2785  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [7]  [ 300/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.5383 (0.4590)  loss_classifier: 0.1898 (0.1569)  loss_box_reg: 0.1940 (0.1413)  loss_objectness: 0.1118 (0.1105)  loss_rpn_box_reg: 0.0449 (0.0503)  time: 0.2814  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [7]  [ 310/1229]  eta: 0:04:11  lr: 0.005000  loss: 0.5383 (0.4620)  loss_classifier: 0.1898 (0.1586)  loss_box_reg: 0.1984 (0.1429)  loss_objectness: 0.1094 (0.1109)  loss_rpn_box_reg: 0.0370 (0.0496)  time: 0.2795  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [7]  [ 320/1229]  eta: 0:04:08  lr: 0.005000  loss: 0.4529 (0.4618)  loss_classifier: 0.1703 (0.1585)  loss_box_reg: 0.1364 (0.1430)  loss_objectness: 0.1031 (0.1107)  loss_rpn_box_reg: 0.0244 (0.0496)  time: 0.2702  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [7]  [ 330/1229]  eta: 0:04:05  lr: 0.005000  loss: 0.3621 (0.4635)  loss_classifier: 0.1248 (0.1590)  loss_box_reg: 0.1170 (0.1437)  loss_objectness: 0.0893 (0.1109)  loss_rpn_box_reg: 0.0441 (0.0499)  time: 0.2686  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [7]  [ 340/1229]  eta: 0:04:02  lr: 0.005000  loss: 0.4119 (0.4657)  loss_classifier: 0.1417 (0.1595)  loss_box_reg: 0.1170 (0.1444)  loss_objectness: 0.0923 (0.1122)  loss_rpn_box_reg: 0.0373 (0.0496)  time: 0.2703  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [7]  [ 350/1229]  eta: 0:03:59  lr: 0.005000  loss: 0.3498 (0.4617)  loss_classifier: 0.1132 (0.1581)  loss_box_reg: 0.1106 (0.1433)  loss_objectness: 0.0818 (0.1114)  loss_rpn_box_reg: 0.0247 (0.0488)  time: 0.2698  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [7]  [ 360/1229]  eta: 0:03:57  lr: 0.005000  loss: 0.3323 (0.4601)  loss_classifier: 0.1034 (0.1575)  loss_box_reg: 0.1020 (0.1423)  loss_objectness: 0.0766 (0.1119)  loss_rpn_box_reg: 0.0235 (0.0484)  time: 0.2712  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [7]  [ 370/1229]  eta: 0:03:54  lr: 0.005000  loss: 0.3323 (0.4575)  loss_classifier: 0.1092 (0.1569)  loss_box_reg: 0.1016 (0.1417)  loss_objectness: 0.0790 (0.1112)  loss_rpn_box_reg: 0.0189 (0.0477)  time: 0.2731  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [7]  [ 380/1229]  eta: 0:03:51  lr: 0.005000  loss: 0.4093 (0.4582)  loss_classifier: 0.1442 (0.1575)  loss_box_reg: 0.1339 (0.1424)  loss_objectness: 0.0881 (0.1109)  loss_rpn_box_reg: 0.0244 (0.0475)  time: 0.2735  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [7]  [ 390/1229]  eta: 0:03:49  lr: 0.005000  loss: 0.4724 (0.4596)  loss_classifier: 0.1644 (0.1582)  loss_box_reg: 0.1473 (0.1431)  loss_objectness: 0.0931 (0.1110)  loss_rpn_box_reg: 0.0258 (0.0473)  time: 0.2752  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [7]  [ 400/1229]  eta: 0:03:46  lr: 0.005000  loss: 0.5136 (0.4610)  loss_classifier: 0.1702 (0.1587)  loss_box_reg: 0.1326 (0.1434)  loss_objectness: 0.0931 (0.1113)  loss_rpn_box_reg: 0.0396 (0.0476)  time: 0.2772  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [7]  [ 410/1229]  eta: 0:03:43  lr: 0.005000  loss: 0.5242 (0.4621)  loss_classifier: 0.1720 (0.1588)  loss_box_reg: 0.1322 (0.1435)  loss_objectness: 0.1123 (0.1118)  loss_rpn_box_reg: 0.0321 (0.0479)  time: 0.2722  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [7]  [ 420/1229]  eta: 0:03:40  lr: 0.005000  loss: 0.4718 (0.4621)  loss_classifier: 0.1332 (0.1583)  loss_box_reg: 0.1220 (0.1429)  loss_objectness: 0.1117 (0.1123)  loss_rpn_box_reg: 0.0315 (0.0486)  time: 0.2736  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [7]  [ 430/1229]  eta: 0:03:38  lr: 0.005000  loss: 0.3803 (0.4620)  loss_classifier: 0.1049 (0.1581)  loss_box_reg: 0.0908 (0.1427)  loss_objectness: 0.1039 (0.1125)  loss_rpn_box_reg: 0.0477 (0.0488)  time: 0.2747  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [7]  [ 440/1229]  eta: 0:03:35  lr: 0.005000  loss: 0.3766 (0.4600)  loss_classifier: 0.1226 (0.1573)  loss_box_reg: 0.0923 (0.1421)  loss_objectness: 0.0845 (0.1118)  loss_rpn_box_reg: 0.0299 (0.0487)  time: 0.2678  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [7]  [ 450/1229]  eta: 0:03:32  lr: 0.005000  loss: 0.3766 (0.4602)  loss_classifier: 0.1278 (0.1571)  loss_box_reg: 0.1100 (0.1421)  loss_objectness: 0.0869 (0.1119)  loss_rpn_box_reg: 0.0194 (0.0491)  time: 0.2684  data: 0.1300  max mem: 1751\n",
      "Training Epoch: [7]  [ 460/1229]  eta: 0:03:29  lr: 0.005000  loss: 0.4362 (0.4608)  loss_classifier: 0.1725 (0.1573)  loss_box_reg: 0.1143 (0.1423)  loss_objectness: 0.0981 (0.1117)  loss_rpn_box_reg: 0.0288 (0.0494)  time: 0.2716  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [7]  [ 470/1229]  eta: 0:03:27  lr: 0.005000  loss: 0.4362 (0.4614)  loss_classifier: 0.1467 (0.1572)  loss_box_reg: 0.1024 (0.1424)  loss_objectness: 0.0747 (0.1121)  loss_rpn_box_reg: 0.0384 (0.0497)  time: 0.2723  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [7]  [ 480/1229]  eta: 0:03:24  lr: 0.005000  loss: 0.4565 (0.4632)  loss_classifier: 0.1467 (0.1577)  loss_box_reg: 0.1455 (0.1435)  loss_objectness: 0.0806 (0.1120)  loss_rpn_box_reg: 0.0473 (0.0500)  time: 0.2728  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [7]  [ 490/1229]  eta: 0:03:21  lr: 0.005000  loss: 0.4197 (0.4618)  loss_classifier: 0.1492 (0.1573)  loss_box_reg: 0.1469 (0.1431)  loss_objectness: 0.0781 (0.1115)  loss_rpn_box_reg: 0.0286 (0.0499)  time: 0.2767  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [7]  [ 500/1229]  eta: 0:03:19  lr: 0.005000  loss: 0.3840 (0.4650)  loss_classifier: 0.1373 (0.1586)  loss_box_reg: 0.1355 (0.1442)  loss_objectness: 0.1001 (0.1123)  loss_rpn_box_reg: 0.0344 (0.0500)  time: 0.2778  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [7]  [ 510/1229]  eta: 0:03:16  lr: 0.005000  loss: 0.3909 (0.4654)  loss_classifier: 0.1422 (0.1586)  loss_box_reg: 0.1270 (0.1444)  loss_objectness: 0.1001 (0.1121)  loss_rpn_box_reg: 0.0377 (0.0502)  time: 0.2709  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [7]  [ 520/1229]  eta: 0:03:13  lr: 0.005000  loss: 0.4697 (0.4665)  loss_classifier: 0.1492 (0.1590)  loss_box_reg: 0.1163 (0.1446)  loss_objectness: 0.0844 (0.1121)  loss_rpn_box_reg: 0.0401 (0.0508)  time: 0.2686  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [7]  [ 530/1229]  eta: 0:03:10  lr: 0.005000  loss: 0.4736 (0.4688)  loss_classifier: 0.1656 (0.1597)  loss_box_reg: 0.1406 (0.1455)  loss_objectness: 0.0946 (0.1126)  loss_rpn_box_reg: 0.0389 (0.0509)  time: 0.2760  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [7]  [ 540/1229]  eta: 0:03:08  lr: 0.005000  loss: 0.4208 (0.4700)  loss_classifier: 0.1565 (0.1596)  loss_box_reg: 0.1144 (0.1450)  loss_objectness: 0.1129 (0.1135)  loss_rpn_box_reg: 0.0305 (0.0518)  time: 0.2783  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [7]  [ 550/1229]  eta: 0:03:05  lr: 0.005000  loss: 0.3532 (0.4687)  loss_classifier: 0.1176 (0.1590)  loss_box_reg: 0.0859 (0.1446)  loss_objectness: 0.1129 (0.1134)  loss_rpn_box_reg: 0.0365 (0.0517)  time: 0.2768  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [7]  [ 560/1229]  eta: 0:03:02  lr: 0.005000  loss: 0.3114 (0.4665)  loss_classifier: 0.0927 (0.1583)  loss_box_reg: 0.0859 (0.1438)  loss_objectness: 0.0920 (0.1129)  loss_rpn_box_reg: 0.0250 (0.0515)  time: 0.2800  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [7]  [ 570/1229]  eta: 0:03:00  lr: 0.005000  loss: 0.2856 (0.4657)  loss_classifier: 0.0997 (0.1580)  loss_box_reg: 0.0852 (0.1437)  loss_objectness: 0.0758 (0.1128)  loss_rpn_box_reg: 0.0211 (0.0513)  time: 0.2755  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [7]  [ 580/1229]  eta: 0:02:57  lr: 0.005000  loss: 0.3046 (0.4664)  loss_classifier: 0.1138 (0.1583)  loss_box_reg: 0.1050 (0.1445)  loss_objectness: 0.0712 (0.1126)  loss_rpn_box_reg: 0.0294 (0.0511)  time: 0.2691  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [7]  [ 590/1229]  eta: 0:02:54  lr: 0.005000  loss: 0.4852 (0.4674)  loss_classifier: 0.1276 (0.1585)  loss_box_reg: 0.1370 (0.1451)  loss_objectness: 0.0768 (0.1129)  loss_rpn_box_reg: 0.0294 (0.0509)  time: 0.2723  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [7]  [ 600/1229]  eta: 0:02:51  lr: 0.005000  loss: 0.5122 (0.4684)  loss_classifier: 0.1816 (0.1591)  loss_box_reg: 0.1781 (0.1459)  loss_objectness: 0.0987 (0.1125)  loss_rpn_box_reg: 0.0233 (0.0508)  time: 0.2794  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [7]  [ 610/1229]  eta: 0:02:49  lr: 0.005000  loss: 0.4428 (0.4690)  loss_classifier: 0.1584 (0.1593)  loss_box_reg: 0.1456 (0.1461)  loss_objectness: 0.0986 (0.1127)  loss_rpn_box_reg: 0.0233 (0.0509)  time: 0.2782  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [7]  [ 620/1229]  eta: 0:02:46  lr: 0.005000  loss: 0.4428 (0.4717)  loss_classifier: 0.1444 (0.1600)  loss_box_reg: 0.1196 (0.1470)  loss_objectness: 0.1193 (0.1134)  loss_rpn_box_reg: 0.0498 (0.0512)  time: 0.2735  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [7]  [ 630/1229]  eta: 0:02:43  lr: 0.005000  loss: 0.5489 (0.4738)  loss_classifier: 0.1960 (0.1610)  loss_box_reg: 0.1528 (0.1480)  loss_objectness: 0.1166 (0.1138)  loss_rpn_box_reg: 0.0366 (0.0510)  time: 0.2741  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [7]  [ 640/1229]  eta: 0:02:41  lr: 0.005000  loss: 0.4666 (0.4720)  loss_classifier: 0.1724 (0.1605)  loss_box_reg: 0.1223 (0.1473)  loss_objectness: 0.1051 (0.1135)  loss_rpn_box_reg: 0.0235 (0.0507)  time: 0.2747  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [7]  [ 650/1229]  eta: 0:02:38  lr: 0.005000  loss: 0.3876 (0.4715)  loss_classifier: 0.1242 (0.1601)  loss_box_reg: 0.1190 (0.1471)  loss_objectness: 0.0845 (0.1135)  loss_rpn_box_reg: 0.0232 (0.0508)  time: 0.2738  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [7]  [ 660/1229]  eta: 0:02:35  lr: 0.005000  loss: 0.4269 (0.4703)  loss_classifier: 0.1340 (0.1598)  loss_box_reg: 0.1353 (0.1468)  loss_objectness: 0.0828 (0.1132)  loss_rpn_box_reg: 0.0205 (0.0505)  time: 0.2686  data: 0.1294  max mem: 1751\n",
      "Training Epoch: [7]  [ 670/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.4269 (0.4712)  loss_classifier: 0.1517 (0.1603)  loss_box_reg: 0.1497 (0.1478)  loss_objectness: 0.0879 (0.1128)  loss_rpn_box_reg: 0.0280 (0.0503)  time: 0.2657  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [7]  [ 680/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.4220 (0.4713)  loss_classifier: 0.1305 (0.1602)  loss_box_reg: 0.1301 (0.1478)  loss_objectness: 0.0954 (0.1126)  loss_rpn_box_reg: 0.0362 (0.0507)  time: 0.2701  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [7]  [ 690/1229]  eta: 0:02:27  lr: 0.005000  loss: 0.3988 (0.4708)  loss_classifier: 0.1262 (0.1599)  loss_box_reg: 0.0982 (0.1474)  loss_objectness: 0.1014 (0.1127)  loss_rpn_box_reg: 0.0328 (0.0507)  time: 0.2727  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [7]  [ 700/1229]  eta: 0:02:24  lr: 0.005000  loss: 0.4077 (0.4707)  loss_classifier: 0.1486 (0.1601)  loss_box_reg: 0.0853 (0.1473)  loss_objectness: 0.1095 (0.1129)  loss_rpn_box_reg: 0.0251 (0.0504)  time: 0.2679  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [7]  [ 710/1229]  eta: 0:02:21  lr: 0.005000  loss: 0.4300 (0.4717)  loss_classifier: 0.1573 (0.1601)  loss_box_reg: 0.1034 (0.1474)  loss_objectness: 0.1092 (0.1131)  loss_rpn_box_reg: 0.0251 (0.0511)  time: 0.2717  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [7]  [ 720/1229]  eta: 0:02:18  lr: 0.005000  loss: 0.4211 (0.4718)  loss_classifier: 0.1449 (0.1601)  loss_box_reg: 0.1111 (0.1478)  loss_objectness: 0.1092 (0.1132)  loss_rpn_box_reg: 0.0267 (0.0508)  time: 0.2713  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [7]  [ 730/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.4167 (0.4708)  loss_classifier: 0.1237 (0.1596)  loss_box_reg: 0.0962 (0.1471)  loss_objectness: 0.1079 (0.1132)  loss_rpn_box_reg: 0.0267 (0.0510)  time: 0.2639  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [7]  [ 740/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.4043 (0.4697)  loss_classifier: 0.1107 (0.1592)  loss_box_reg: 0.0757 (0.1467)  loss_objectness: 0.0973 (0.1129)  loss_rpn_box_reg: 0.0196 (0.0509)  time: 0.2652  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [7]  [ 750/1229]  eta: 0:02:10  lr: 0.005000  loss: 0.4508 (0.4716)  loss_classifier: 0.1586 (0.1599)  loss_box_reg: 0.1621 (0.1475)  loss_objectness: 0.0973 (0.1132)  loss_rpn_box_reg: 0.0219 (0.0510)  time: 0.2756  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [7]  [ 760/1229]  eta: 0:02:08  lr: 0.005000  loss: 0.4508 (0.4695)  loss_classifier: 0.1394 (0.1593)  loss_box_reg: 0.1278 (0.1466)  loss_objectness: 0.0943 (0.1129)  loss_rpn_box_reg: 0.0238 (0.0506)  time: 0.2786  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [7]  [ 770/1229]  eta: 0:02:05  lr: 0.005000  loss: 0.3272 (0.4699)  loss_classifier: 0.1121 (0.1596)  loss_box_reg: 0.0931 (0.1468)  loss_objectness: 0.0850 (0.1130)  loss_rpn_box_reg: 0.0284 (0.0505)  time: 0.2725  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [7]  [ 780/1229]  eta: 0:02:02  lr: 0.005000  loss: 0.4537 (0.4701)  loss_classifier: 0.1455 (0.1597)  loss_box_reg: 0.1104 (0.1470)  loss_objectness: 0.1124 (0.1132)  loss_rpn_box_reg: 0.0395 (0.0503)  time: 0.2729  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [7]  [ 790/1229]  eta: 0:01:59  lr: 0.005000  loss: 0.4018 (0.4689)  loss_classifier: 0.1405 (0.1593)  loss_box_reg: 0.1169 (0.1466)  loss_objectness: 0.0983 (0.1131)  loss_rpn_box_reg: 0.0252 (0.0499)  time: 0.2720  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [7]  [ 800/1229]  eta: 0:01:57  lr: 0.005000  loss: 0.4018 (0.4690)  loss_classifier: 0.1461 (0.1596)  loss_box_reg: 0.1093 (0.1467)  loss_objectness: 0.0829 (0.1130)  loss_rpn_box_reg: 0.0223 (0.0497)  time: 0.2744  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [7]  [ 810/1229]  eta: 0:01:54  lr: 0.005000  loss: 0.4455 (0.4700)  loss_classifier: 0.1619 (0.1599)  loss_box_reg: 0.1531 (0.1470)  loss_objectness: 0.1078 (0.1134)  loss_rpn_box_reg: 0.0313 (0.0497)  time: 0.2791  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [7]  [ 820/1229]  eta: 0:01:51  lr: 0.005000  loss: 0.4488 (0.4709)  loss_classifier: 0.1553 (0.1601)  loss_box_reg: 0.1750 (0.1476)  loss_objectness: 0.1078 (0.1132)  loss_rpn_box_reg: 0.0353 (0.0500)  time: 0.2814  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [7]  [ 830/1229]  eta: 0:01:49  lr: 0.005000  loss: 0.4407 (0.4713)  loss_classifier: 0.1421 (0.1600)  loss_box_reg: 0.1240 (0.1475)  loss_objectness: 0.0850 (0.1133)  loss_rpn_box_reg: 0.0657 (0.0506)  time: 0.2796  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [7]  [ 840/1229]  eta: 0:01:46  lr: 0.005000  loss: 0.3807 (0.4704)  loss_classifier: 0.1183 (0.1597)  loss_box_reg: 0.1240 (0.1475)  loss_objectness: 0.0850 (0.1128)  loss_rpn_box_reg: 0.0327 (0.0503)  time: 0.2763  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [7]  [ 850/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.3751 (0.4707)  loss_classifier: 0.1226 (0.1596)  loss_box_reg: 0.1224 (0.1476)  loss_objectness: 0.0872 (0.1131)  loss_rpn_box_reg: 0.0263 (0.0503)  time: 0.2775  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [7]  [ 860/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.3751 (0.4696)  loss_classifier: 0.1230 (0.1592)  loss_box_reg: 0.0900 (0.1469)  loss_objectness: 0.1010 (0.1131)  loss_rpn_box_reg: 0.0263 (0.0503)  time: 0.2785  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [7]  [ 870/1229]  eta: 0:01:38  lr: 0.005000  loss: 0.3576 (0.4694)  loss_classifier: 0.1248 (0.1593)  loss_box_reg: 0.0908 (0.1469)  loss_objectness: 0.1010 (0.1131)  loss_rpn_box_reg: 0.0197 (0.0501)  time: 0.2751  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [7]  [ 880/1229]  eta: 0:01:35  lr: 0.005000  loss: 0.5046 (0.4703)  loss_classifier: 0.1731 (0.1594)  loss_box_reg: 0.1528 (0.1472)  loss_objectness: 0.1015 (0.1135)  loss_rpn_box_reg: 0.0276 (0.0501)  time: 0.2721  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [7]  [ 890/1229]  eta: 0:01:32  lr: 0.005000  loss: 0.4169 (0.4691)  loss_classifier: 0.1470 (0.1592)  loss_box_reg: 0.1159 (0.1470)  loss_objectness: 0.0894 (0.1132)  loss_rpn_box_reg: 0.0237 (0.0498)  time: 0.2722  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [7]  [ 900/1229]  eta: 0:01:29  lr: 0.005000  loss: 0.4597 (0.4715)  loss_classifier: 0.1820 (0.1599)  loss_box_reg: 0.1159 (0.1476)  loss_objectness: 0.1191 (0.1138)  loss_rpn_box_reg: 0.0266 (0.0502)  time: 0.2670  data: 0.1298  max mem: 1751\n",
      "Training Epoch: [7]  [ 910/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.6172 (0.4719)  loss_classifier: 0.1912 (0.1599)  loss_box_reg: 0.1562 (0.1476)  loss_objectness: 0.1353 (0.1140)  loss_rpn_box_reg: 0.0449 (0.0505)  time: 0.2677  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [7]  [ 920/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.4997 (0.4722)  loss_classifier: 0.1691 (0.1601)  loss_box_reg: 0.1246 (0.1475)  loss_objectness: 0.1104 (0.1139)  loss_rpn_box_reg: 0.0520 (0.0507)  time: 0.2752  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [7]  [ 930/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.3821 (0.4714)  loss_classifier: 0.1320 (0.1599)  loss_box_reg: 0.1246 (0.1472)  loss_objectness: 0.0851 (0.1138)  loss_rpn_box_reg: 0.0286 (0.0504)  time: 0.2722  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [7]  [ 940/1229]  eta: 0:01:19  lr: 0.005000  loss: 0.3843 (0.4715)  loss_classifier: 0.1329 (0.1600)  loss_box_reg: 0.1022 (0.1471)  loss_objectness: 0.0967 (0.1139)  loss_rpn_box_reg: 0.0187 (0.0505)  time: 0.2801  data: 0.1368  max mem: 1751\n",
      "Training Epoch: [7]  [ 950/1229]  eta: 0:01:16  lr: 0.005000  loss: 0.4349 (0.4712)  loss_classifier: 0.1626 (0.1600)  loss_box_reg: 0.1261 (0.1468)  loss_objectness: 0.1027 (0.1138)  loss_rpn_box_reg: 0.0394 (0.0507)  time: 0.2862  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [7]  [ 960/1229]  eta: 0:01:13  lr: 0.005000  loss: 0.3848 (0.4703)  loss_classifier: 0.1370 (0.1596)  loss_box_reg: 0.1261 (0.1464)  loss_objectness: 0.0999 (0.1136)  loss_rpn_box_reg: 0.0257 (0.0506)  time: 0.2773  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [7]  [ 970/1229]  eta: 0:01:10  lr: 0.005000  loss: 0.3848 (0.4706)  loss_classifier: 0.1334 (0.1597)  loss_box_reg: 0.1221 (0.1467)  loss_objectness: 0.1061 (0.1137)  loss_rpn_box_reg: 0.0260 (0.0505)  time: 0.2725  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [7]  [ 980/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.3848 (0.4698)  loss_classifier: 0.1335 (0.1594)  loss_box_reg: 0.1076 (0.1464)  loss_objectness: 0.1061 (0.1137)  loss_rpn_box_reg: 0.0283 (0.0503)  time: 0.2722  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [7]  [ 990/1229]  eta: 0:01:05  lr: 0.005000  loss: 0.3848 (0.4700)  loss_classifier: 0.1335 (0.1596)  loss_box_reg: 0.1130 (0.1465)  loss_objectness: 0.1121 (0.1137)  loss_rpn_box_reg: 0.0254 (0.0501)  time: 0.2750  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [7]  [1000/1229]  eta: 0:01:02  lr: 0.005000  loss: 0.4750 (0.4702)  loss_classifier: 0.1644 (0.1596)  loss_box_reg: 0.1685 (0.1466)  loss_objectness: 0.1154 (0.1138)  loss_rpn_box_reg: 0.0267 (0.0502)  time: 0.2781  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [7]  [1010/1229]  eta: 0:00:59  lr: 0.005000  loss: 0.4056 (0.4698)  loss_classifier: 0.1417 (0.1596)  loss_box_reg: 0.1205 (0.1466)  loss_objectness: 0.0950 (0.1136)  loss_rpn_box_reg: 0.0305 (0.0500)  time: 0.2767  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [7]  [1020/1229]  eta: 0:00:57  lr: 0.005000  loss: 0.4019 (0.4694)  loss_classifier: 0.1385 (0.1594)  loss_box_reg: 0.1251 (0.1464)  loss_objectness: 0.0931 (0.1137)  loss_rpn_box_reg: 0.0284 (0.0499)  time: 0.2728  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [7]  [1030/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.4061 (0.4688)  loss_classifier: 0.1296 (0.1593)  loss_box_reg: 0.1126 (0.1462)  loss_objectness: 0.0937 (0.1137)  loss_rpn_box_reg: 0.0279 (0.0497)  time: 0.2750  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [7]  [1040/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.4077 (0.4696)  loss_classifier: 0.1230 (0.1595)  loss_box_reg: 0.1045 (0.1463)  loss_objectness: 0.1396 (0.1139)  loss_rpn_box_reg: 0.0206 (0.0498)  time: 0.2716  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [7]  [1050/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.5044 (0.4698)  loss_classifier: 0.1337 (0.1595)  loss_box_reg: 0.1227 (0.1463)  loss_objectness: 0.1048 (0.1137)  loss_rpn_box_reg: 0.0235 (0.0502)  time: 0.2671  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [7]  [1060/1229]  eta: 0:00:46  lr: 0.005000  loss: 0.5044 (0.4705)  loss_classifier: 0.1532 (0.1599)  loss_box_reg: 0.1298 (0.1466)  loss_objectness: 0.0823 (0.1138)  loss_rpn_box_reg: 0.0273 (0.0502)  time: 0.2731  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [7]  [1070/1229]  eta: 0:00:43  lr: 0.005000  loss: 0.5015 (0.4720)  loss_classifier: 0.1752 (0.1602)  loss_box_reg: 0.1453 (0.1471)  loss_objectness: 0.1421 (0.1144)  loss_rpn_box_reg: 0.0394 (0.0504)  time: 0.2724  data: 0.1376  max mem: 1751\n",
      "Training Epoch: [7]  [1080/1229]  eta: 0:00:40  lr: 0.005000  loss: 0.3382 (0.4707)  loss_classifier: 0.1354 (0.1599)  loss_box_reg: 0.1179 (0.1467)  loss_objectness: 0.0984 (0.1140)  loss_rpn_box_reg: 0.0253 (0.0501)  time: 0.2736  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [7]  [1090/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.3382 (0.4705)  loss_classifier: 0.1254 (0.1597)  loss_box_reg: 0.1177 (0.1468)  loss_objectness: 0.0894 (0.1139)  loss_rpn_box_reg: 0.0239 (0.0501)  time: 0.2713  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [7]  [1100/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4141 (0.4703)  loss_classifier: 0.1456 (0.1597)  loss_box_reg: 0.1077 (0.1467)  loss_objectness: 0.0968 (0.1140)  loss_rpn_box_reg: 0.0185 (0.0499)  time: 0.2674  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [7]  [1110/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.3192 (0.4700)  loss_classifier: 0.1249 (0.1596)  loss_box_reg: 0.0963 (0.1468)  loss_objectness: 0.0891 (0.1138)  loss_rpn_box_reg: 0.0165 (0.0497)  time: 0.2732  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [7]  [1120/1229]  eta: 0:00:29  lr: 0.005000  loss: 0.3867 (0.4704)  loss_classifier: 0.1495 (0.1598)  loss_box_reg: 0.1074 (0.1470)  loss_objectness: 0.0906 (0.1139)  loss_rpn_box_reg: 0.0261 (0.0497)  time: 0.2704  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [7]  [1130/1229]  eta: 0:00:27  lr: 0.005000  loss: 0.4562 (0.4710)  loss_classifier: 0.1715 (0.1603)  loss_box_reg: 0.1304 (0.1472)  loss_objectness: 0.1291 (0.1139)  loss_rpn_box_reg: 0.0258 (0.0496)  time: 0.2671  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [7]  [1140/1229]  eta: 0:00:24  lr: 0.005000  loss: 0.3961 (0.4701)  loss_classifier: 0.1407 (0.1599)  loss_box_reg: 0.0923 (0.1467)  loss_objectness: 0.1217 (0.1141)  loss_rpn_box_reg: 0.0210 (0.0494)  time: 0.2701  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [7]  [1150/1229]  eta: 0:00:21  lr: 0.005000  loss: 0.3475 (0.4709)  loss_classifier: 0.1327 (0.1602)  loss_box_reg: 0.0981 (0.1470)  loss_objectness: 0.0906 (0.1140)  loss_rpn_box_reg: 0.0169 (0.0496)  time: 0.2736  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [7]  [1160/1229]  eta: 0:00:18  lr: 0.005000  loss: 0.3475 (0.4701)  loss_classifier: 0.1317 (0.1600)  loss_box_reg: 0.0981 (0.1466)  loss_objectness: 0.0885 (0.1139)  loss_rpn_box_reg: 0.0174 (0.0495)  time: 0.2732  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [7]  [1170/1229]  eta: 0:00:16  lr: 0.005000  loss: 0.3894 (0.4699)  loss_classifier: 0.1317 (0.1599)  loss_box_reg: 0.0932 (0.1466)  loss_objectness: 0.0919 (0.1139)  loss_rpn_box_reg: 0.0257 (0.0496)  time: 0.2728  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [7]  [1180/1229]  eta: 0:00:13  lr: 0.005000  loss: 0.5057 (0.4709)  loss_classifier: 0.1427 (0.1602)  loss_box_reg: 0.1158 (0.1473)  loss_objectness: 0.1116 (0.1140)  loss_rpn_box_reg: 0.0262 (0.0494)  time: 0.2716  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [7]  [1190/1229]  eta: 0:00:10  lr: 0.005000  loss: 0.5623 (0.4715)  loss_classifier: 0.2054 (0.1604)  loss_box_reg: 0.1908 (0.1476)  loss_objectness: 0.1115 (0.1141)  loss_rpn_box_reg: 0.0257 (0.0494)  time: 0.2730  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [7]  [1200/1229]  eta: 0:00:07  lr: 0.005000  loss: 0.4907 (0.4715)  loss_classifier: 0.1815 (0.1604)  loss_box_reg: 0.1054 (0.1473)  loss_objectness: 0.1115 (0.1143)  loss_rpn_box_reg: 0.0298 (0.0494)  time: 0.2740  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [7]  [1210/1229]  eta: 0:00:05  lr: 0.005000  loss: 0.3270 (0.4705)  loss_classifier: 0.1044 (0.1601)  loss_box_reg: 0.0753 (0.1470)  loss_objectness: 0.0875 (0.1142)  loss_rpn_box_reg: 0.0226 (0.0492)  time: 0.2755  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [7]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.3425 (0.4706)  loss_classifier: 0.1359 (0.1602)  loss_box_reg: 0.1229 (0.1472)  loss_objectness: 0.0725 (0.1141)  loss_rpn_box_reg: 0.0197 (0.0491)  time: 0.2775  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [7]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.3619 (0.4702)  loss_classifier: 0.1444 (0.1602)  loss_box_reg: 0.1355 (0.1471)  loss_objectness: 0.0770 (0.1140)  loss_rpn_box_reg: 0.0231 (0.0489)  time: 0.2778  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [7] Total time: 0:05:36 (0.2734 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:20  model_time: 0.2290 (0.2290)  evaluator_time: 0.0010 (0.0010)  time: 0.2600  data: 0.0280  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0800 (0.0823)  evaluator_time: 0.0050 (0.0089)  time: 0.1278  data: 0.0355  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0860 (0.0817)  evaluator_time: 0.0030 (0.0081)  time: 0.1265  data: 0.0355  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0740 (0.0811)  evaluator_time: 0.0050 (0.0078)  time: 0.1254  data: 0.0403  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0730 (0.0809)  evaluator_time: 0.0030 (0.0078)  time: 0.1220  data: 0.0386  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1250 s / it)\n",
      "Averaged stats: model_time: 0.0730 (0.0809)  evaluator_time: 0.0030 (0.0078)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.046\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.031\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n",
      "Testing Epoch: [7]  [  0/308]  eta: 0:00:38  lr: 0.005000  loss: 0.1753 (0.1753)  loss_classifier: 0.0653 (0.0653)  loss_box_reg: 0.0740 (0.0740)  loss_objectness: 0.0261 (0.0261)  loss_rpn_box_reg: 0.0099 (0.0099)  time: 0.1240  data: 0.0300  max mem: 1751\n",
      "Testing Epoch: [7]  [100/308]  eta: 0:00:28  lr: 0.005000  loss: 0.3421 (0.4985)  loss_classifier: 0.1411 (0.1536)  loss_box_reg: 0.1395 (0.1789)  loss_objectness: 0.0506 (0.1089)  loss_rpn_box_reg: 0.0157 (0.0571)  time: 0.1448  data: 0.0434  max mem: 1751\n",
      "Testing Epoch: [7]  [200/308]  eta: 0:00:14  lr: 0.005000  loss: 0.3632 (0.4673)  loss_classifier: 0.1392 (0.1458)  loss_box_reg: 0.1395 (0.1664)  loss_objectness: 0.0673 (0.1012)  loss_rpn_box_reg: 0.0299 (0.0539)  time: 0.1382  data: 0.0322  max mem: 1751\n",
      "Testing Epoch: [7]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5055 (0.4646)  loss_classifier: 0.1619 (0.1462)  loss_box_reg: 0.1552 (0.1677)  loss_objectness: 0.0759 (0.0985)  loss_rpn_box_reg: 0.0303 (0.0522)  time: 0.1325  data: 0.0368  max mem: 1751\n",
      "Testing Epoch: [7]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.5055 (0.4642)  loss_classifier: 0.1633 (0.1464)  loss_box_reg: 0.1552 (0.1677)  loss_objectness: 0.0732 (0.0985)  loss_rpn_box_reg: 0.0297 (0.0517)  time: 0.1316  data: 0.0354  max mem: 1751\n",
      "Testing Epoch: [7] Total time: 0:00:42 (0.1371 s / it)\n",
      "Training Epoch: [8]  [   0/1229]  eta: 0:06:19  lr: 0.005000  loss: 0.5209 (0.5209)  loss_classifier: 0.1880 (0.1880)  loss_box_reg: 0.2290 (0.2290)  loss_objectness: 0.0794 (0.0794)  loss_rpn_box_reg: 0.0245 (0.0245)  time: 0.3090  data: 0.1420  max mem: 1751\n",
      "Training Epoch: [8]  [  10/1229]  eta: 0:05:49  lr: 0.005000  loss: 0.4146 (0.4592)  loss_classifier: 0.1404 (0.1752)  loss_box_reg: 0.1527 (0.1646)  loss_objectness: 0.0794 (0.0959)  loss_rpn_box_reg: 0.0155 (0.0235)  time: 0.2866  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [8]  [  20/1229]  eta: 0:05:35  lr: 0.005000  loss: 0.4796 (0.5343)  loss_classifier: 0.1866 (0.1940)  loss_box_reg: 0.1599 (0.1795)  loss_objectness: 0.1174 (0.1261)  loss_rpn_box_reg: 0.0207 (0.0348)  time: 0.2762  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [8]  [  30/1229]  eta: 0:05:29  lr: 0.005000  loss: 0.5370 (0.5444)  loss_classifier: 0.1938 (0.1977)  loss_box_reg: 0.1713 (0.1979)  loss_objectness: 0.1120 (0.1146)  loss_rpn_box_reg: 0.0336 (0.0343)  time: 0.2683  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [8]  [  40/1229]  eta: 0:05:25  lr: 0.005000  loss: 0.4748 (0.5355)  loss_classifier: 0.1685 (0.1939)  loss_box_reg: 0.1702 (0.1911)  loss_objectness: 0.0888 (0.1151)  loss_rpn_box_reg: 0.0261 (0.0354)  time: 0.2689  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [8]  [  50/1229]  eta: 0:05:22  lr: 0.005000  loss: 0.4168 (0.5258)  loss_classifier: 0.1619 (0.1920)  loss_box_reg: 0.1477 (0.1886)  loss_objectness: 0.0906 (0.1114)  loss_rpn_box_reg: 0.0222 (0.0339)  time: 0.2718  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [8]  [  60/1229]  eta: 0:05:20  lr: 0.005000  loss: 0.4077 (0.5099)  loss_classifier: 0.1589 (0.1851)  loss_box_reg: 0.1270 (0.1794)  loss_objectness: 0.0906 (0.1126)  loss_rpn_box_reg: 0.0193 (0.0328)  time: 0.2754  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [8]  [  70/1229]  eta: 0:05:18  lr: 0.005000  loss: 0.3495 (0.4995)  loss_classifier: 0.1340 (0.1804)  loss_box_reg: 0.0889 (0.1726)  loss_objectness: 0.0975 (0.1129)  loss_rpn_box_reg: 0.0180 (0.0337)  time: 0.2769  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [8]  [  80/1229]  eta: 0:05:14  lr: 0.005000  loss: 0.3327 (0.4815)  loss_classifier: 0.1226 (0.1735)  loss_box_reg: 0.0861 (0.1623)  loss_objectness: 0.0975 (0.1129)  loss_rpn_box_reg: 0.0178 (0.0328)  time: 0.2718  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [8]  [  90/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.3603 (0.4755)  loss_classifier: 0.1226 (0.1706)  loss_box_reg: 0.0876 (0.1563)  loss_objectness: 0.0909 (0.1128)  loss_rpn_box_reg: 0.0224 (0.0358)  time: 0.2675  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [8]  [ 100/1229]  eta: 0:05:07  lr: 0.005000  loss: 0.3820 (0.4723)  loss_classifier: 0.1416 (0.1699)  loss_box_reg: 0.0977 (0.1557)  loss_objectness: 0.0972 (0.1113)  loss_rpn_box_reg: 0.0224 (0.0354)  time: 0.2685  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [8]  [ 110/1229]  eta: 0:05:05  lr: 0.005000  loss: 0.3820 (0.4714)  loss_classifier: 0.1445 (0.1684)  loss_box_reg: 0.1187 (0.1560)  loss_objectness: 0.0880 (0.1092)  loss_rpn_box_reg: 0.0370 (0.0378)  time: 0.2716  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [8]  [ 120/1229]  eta: 0:05:02  lr: 0.005000  loss: 0.3886 (0.4648)  loss_classifier: 0.1445 (0.1657)  loss_box_reg: 0.1187 (0.1535)  loss_objectness: 0.0880 (0.1078)  loss_rpn_box_reg: 0.0377 (0.0379)  time: 0.2756  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [8]  [ 130/1229]  eta: 0:05:00  lr: 0.005000  loss: 0.4330 (0.4615)  loss_classifier: 0.1361 (0.1639)  loss_box_reg: 0.0923 (0.1514)  loss_objectness: 0.0948 (0.1076)  loss_rpn_box_reg: 0.0293 (0.0387)  time: 0.2746  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [8]  [ 140/1229]  eta: 0:04:56  lr: 0.005000  loss: 0.4875 (0.4706)  loss_classifier: 0.1610 (0.1668)  loss_box_reg: 0.1228 (0.1542)  loss_objectness: 0.1058 (0.1083)  loss_rpn_box_reg: 0.0293 (0.0412)  time: 0.2696  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [8]  [ 150/1229]  eta: 0:04:54  lr: 0.005000  loss: 0.5206 (0.4683)  loss_classifier: 0.1730 (0.1657)  loss_box_reg: 0.1559 (0.1522)  loss_objectness: 0.1093 (0.1084)  loss_rpn_box_reg: 0.0292 (0.0420)  time: 0.2709  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [8]  [ 160/1229]  eta: 0:04:51  lr: 0.005000  loss: 0.3344 (0.4609)  loss_classifier: 0.1053 (0.1627)  loss_box_reg: 0.0667 (0.1490)  loss_objectness: 0.1021 (0.1073)  loss_rpn_box_reg: 0.0212 (0.0419)  time: 0.2755  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [8]  [ 170/1229]  eta: 0:04:49  lr: 0.005000  loss: 0.2888 (0.4563)  loss_classifier: 0.1031 (0.1611)  loss_box_reg: 0.0667 (0.1480)  loss_objectness: 0.0909 (0.1065)  loss_rpn_box_reg: 0.0153 (0.0407)  time: 0.2755  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [8]  [ 180/1229]  eta: 0:04:46  lr: 0.005000  loss: 0.3354 (0.4621)  loss_classifier: 0.1122 (0.1612)  loss_box_reg: 0.1050 (0.1484)  loss_objectness: 0.0935 (0.1083)  loss_rpn_box_reg: 0.0313 (0.0442)  time: 0.2711  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [8]  [ 190/1229]  eta: 0:04:42  lr: 0.005000  loss: 0.5222 (0.4673)  loss_classifier: 0.1708 (0.1635)  loss_box_reg: 0.1390 (0.1506)  loss_objectness: 0.1178 (0.1087)  loss_rpn_box_reg: 0.0314 (0.0444)  time: 0.2617  data: 0.1303  max mem: 1751\n",
      "Training Epoch: [8]  [ 200/1229]  eta: 0:04:39  lr: 0.005000  loss: 0.3647 (0.4638)  loss_classifier: 0.1365 (0.1624)  loss_box_reg: 0.1115 (0.1484)  loss_objectness: 0.1069 (0.1089)  loss_rpn_box_reg: 0.0212 (0.0441)  time: 0.2607  data: 0.1303  max mem: 1751\n",
      "Training Epoch: [8]  [ 210/1229]  eta: 0:04:36  lr: 0.005000  loss: 0.3647 (0.4636)  loss_classifier: 0.1365 (0.1619)  loss_box_reg: 0.0982 (0.1489)  loss_objectness: 0.0890 (0.1087)  loss_rpn_box_reg: 0.0267 (0.0442)  time: 0.2684  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [8]  [ 220/1229]  eta: 0:04:33  lr: 0.005000  loss: 0.3812 (0.4622)  loss_classifier: 0.1512 (0.1620)  loss_box_reg: 0.1039 (0.1479)  loss_objectness: 0.0855 (0.1085)  loss_rpn_box_reg: 0.0250 (0.0438)  time: 0.2701  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [8]  [ 230/1229]  eta: 0:04:31  lr: 0.005000  loss: 0.4603 (0.4649)  loss_classifier: 0.1512 (0.1628)  loss_box_reg: 0.1300 (0.1493)  loss_objectness: 0.0901 (0.1092)  loss_rpn_box_reg: 0.0236 (0.0436)  time: 0.2687  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [8]  [ 240/1229]  eta: 0:04:28  lr: 0.005000  loss: 0.4042 (0.4651)  loss_classifier: 0.1274 (0.1623)  loss_box_reg: 0.1371 (0.1501)  loss_objectness: 0.0838 (0.1086)  loss_rpn_box_reg: 0.0337 (0.0441)  time: 0.2740  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [8]  [ 250/1229]  eta: 0:04:25  lr: 0.005000  loss: 0.4082 (0.4656)  loss_classifier: 0.1282 (0.1625)  loss_box_reg: 0.1372 (0.1498)  loss_objectness: 0.0982 (0.1092)  loss_rpn_box_reg: 0.0331 (0.0440)  time: 0.2756  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [8]  [ 260/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.3921 (0.4655)  loss_classifier: 0.1390 (0.1625)  loss_box_reg: 0.1398 (0.1513)  loss_objectness: 0.0906 (0.1081)  loss_rpn_box_reg: 0.0244 (0.0435)  time: 0.2731  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [8]  [ 270/1229]  eta: 0:04:20  lr: 0.005000  loss: 0.3552 (0.4630)  loss_classifier: 0.1268 (0.1612)  loss_box_reg: 0.1364 (0.1504)  loss_objectness: 0.0753 (0.1077)  loss_rpn_box_reg: 0.0254 (0.0436)  time: 0.2733  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [8]  [ 280/1229]  eta: 0:04:17  lr: 0.005000  loss: 0.3961 (0.4645)  loss_classifier: 0.1356 (0.1616)  loss_box_reg: 0.1116 (0.1509)  loss_objectness: 0.0895 (0.1083)  loss_rpn_box_reg: 0.0349 (0.0437)  time: 0.2722  data: 0.1377  max mem: 1751\n",
      "Training Epoch: [8]  [ 290/1229]  eta: 0:04:14  lr: 0.005000  loss: 0.4451 (0.4694)  loss_classifier: 0.1616 (0.1628)  loss_box_reg: 0.1464 (0.1533)  loss_objectness: 0.1188 (0.1090)  loss_rpn_box_reg: 0.0370 (0.0442)  time: 0.2678  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [8]  [ 300/1229]  eta: 0:04:12  lr: 0.005000  loss: 0.4451 (0.4690)  loss_classifier: 0.1616 (0.1626)  loss_box_reg: 0.1342 (0.1529)  loss_objectness: 0.1071 (0.1093)  loss_rpn_box_reg: 0.0269 (0.0442)  time: 0.2754  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [8]  [ 310/1229]  eta: 0:04:09  lr: 0.005000  loss: 0.4606 (0.4707)  loss_classifier: 0.1556 (0.1631)  loss_box_reg: 0.1390 (0.1533)  loss_objectness: 0.0922 (0.1091)  loss_rpn_box_reg: 0.0256 (0.0451)  time: 0.2777  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [8]  [ 320/1229]  eta: 0:04:07  lr: 0.005000  loss: 0.4095 (0.4732)  loss_classifier: 0.1516 (0.1638)  loss_box_reg: 0.1390 (0.1534)  loss_objectness: 0.0810 (0.1098)  loss_rpn_box_reg: 0.0335 (0.0462)  time: 0.2686  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [8]  [ 330/1229]  eta: 0:04:04  lr: 0.005000  loss: 0.7197 (0.4839)  loss_classifier: 0.2322 (0.1669)  loss_box_reg: 0.1880 (0.1580)  loss_objectness: 0.1047 (0.1103)  loss_rpn_box_reg: 0.0575 (0.0487)  time: 0.2727  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [8]  [ 340/1229]  eta: 0:04:01  lr: 0.005000  loss: 0.5489 (0.4841)  loss_classifier: 0.1967 (0.1666)  loss_box_reg: 0.1597 (0.1580)  loss_objectness: 0.1129 (0.1106)  loss_rpn_box_reg: 0.0494 (0.0489)  time: 0.2723  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [8]  [ 350/1229]  eta: 0:03:59  lr: 0.005000  loss: 0.4272 (0.4855)  loss_classifier: 0.1404 (0.1671)  loss_box_reg: 0.0995 (0.1580)  loss_objectness: 0.1129 (0.1110)  loss_rpn_box_reg: 0.0415 (0.0494)  time: 0.2715  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [8]  [ 360/1229]  eta: 0:03:56  lr: 0.005000  loss: 0.4723 (0.4858)  loss_classifier: 0.1528 (0.1673)  loss_box_reg: 0.1372 (0.1584)  loss_objectness: 0.1080 (0.1110)  loss_rpn_box_reg: 0.0375 (0.0491)  time: 0.2790  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [8]  [ 370/1229]  eta: 0:03:54  lr: 0.005000  loss: 0.4762 (0.4876)  loss_classifier: 0.1863 (0.1680)  loss_box_reg: 0.1372 (0.1585)  loss_objectness: 0.1197 (0.1116)  loss_rpn_box_reg: 0.0375 (0.0495)  time: 0.2853  data: 0.1390  max mem: 1751\n",
      "Training Epoch: [8]  [ 380/1229]  eta: 0:03:51  lr: 0.005000  loss: 0.4681 (0.4864)  loss_classifier: 0.1638 (0.1675)  loss_box_reg: 0.1348 (0.1579)  loss_objectness: 0.1193 (0.1117)  loss_rpn_box_reg: 0.0231 (0.0493)  time: 0.2822  data: 0.1370  max mem: 1751\n",
      "Training Epoch: [8]  [ 390/1229]  eta: 0:03:49  lr: 0.005000  loss: 0.4393 (0.4873)  loss_classifier: 0.1449 (0.1681)  loss_box_reg: 0.1135 (0.1583)  loss_objectness: 0.0867 (0.1116)  loss_rpn_box_reg: 0.0231 (0.0493)  time: 0.2784  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [8]  [ 400/1229]  eta: 0:03:46  lr: 0.005000  loss: 0.5179 (0.4906)  loss_classifier: 0.1948 (0.1690)  loss_box_reg: 0.2186 (0.1601)  loss_objectness: 0.0867 (0.1122)  loss_rpn_box_reg: 0.0303 (0.0493)  time: 0.2753  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [8]  [ 410/1229]  eta: 0:03:43  lr: 0.005000  loss: 0.5357 (0.4906)  loss_classifier: 0.2032 (0.1690)  loss_box_reg: 0.1987 (0.1599)  loss_objectness: 0.1234 (0.1123)  loss_rpn_box_reg: 0.0330 (0.0494)  time: 0.2751  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [8]  [ 420/1229]  eta: 0:03:40  lr: 0.005000  loss: 0.4658 (0.4905)  loss_classifier: 0.1548 (0.1689)  loss_box_reg: 0.1357 (0.1601)  loss_objectness: 0.0970 (0.1119)  loss_rpn_box_reg: 0.0283 (0.0496)  time: 0.2789  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [8]  [ 430/1229]  eta: 0:03:38  lr: 0.005000  loss: 0.4222 (0.4903)  loss_classifier: 0.1525 (0.1690)  loss_box_reg: 0.1357 (0.1599)  loss_objectness: 0.0854 (0.1122)  loss_rpn_box_reg: 0.0261 (0.0492)  time: 0.2768  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [8]  [ 440/1229]  eta: 0:03:35  lr: 0.005000  loss: 0.4000 (0.4889)  loss_classifier: 0.1519 (0.1688)  loss_box_reg: 0.1346 (0.1593)  loss_objectness: 0.0911 (0.1120)  loss_rpn_box_reg: 0.0236 (0.0487)  time: 0.2723  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [8]  [ 450/1229]  eta: 0:03:32  lr: 0.005000  loss: 0.3697 (0.4868)  loss_classifier: 0.1194 (0.1682)  loss_box_reg: 0.1075 (0.1584)  loss_objectness: 0.0773 (0.1119)  loss_rpn_box_reg: 0.0198 (0.0483)  time: 0.2728  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [8]  [ 460/1229]  eta: 0:03:30  lr: 0.005000  loss: 0.3530 (0.4873)  loss_classifier: 0.1194 (0.1680)  loss_box_reg: 0.1057 (0.1580)  loss_objectness: 0.1060 (0.1128)  loss_rpn_box_reg: 0.0261 (0.0484)  time: 0.2796  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [8]  [ 470/1229]  eta: 0:03:27  lr: 0.005000  loss: 0.4790 (0.4877)  loss_classifier: 0.1582 (0.1680)  loss_box_reg: 0.1445 (0.1577)  loss_objectness: 0.1236 (0.1133)  loss_rpn_box_reg: 0.0367 (0.0487)  time: 0.2768  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [8]  [ 480/1229]  eta: 0:03:24  lr: 0.005000  loss: 0.4430 (0.4862)  loss_classifier: 0.1420 (0.1676)  loss_box_reg: 0.1439 (0.1573)  loss_objectness: 0.1139 (0.1131)  loss_rpn_box_reg: 0.0257 (0.0483)  time: 0.2737  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [8]  [ 490/1229]  eta: 0:03:22  lr: 0.005000  loss: 0.3860 (0.4852)  loss_classifier: 0.1420 (0.1673)  loss_box_reg: 0.1238 (0.1570)  loss_objectness: 0.0807 (0.1127)  loss_rpn_box_reg: 0.0245 (0.0481)  time: 0.2774  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [8]  [ 500/1229]  eta: 0:03:19  lr: 0.005000  loss: 0.3681 (0.4844)  loss_classifier: 0.1505 (0.1668)  loss_box_reg: 0.1147 (0.1565)  loss_objectness: 0.0807 (0.1129)  loss_rpn_box_reg: 0.0251 (0.0482)  time: 0.2750  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [8]  [ 510/1229]  eta: 0:03:16  lr: 0.005000  loss: 0.3439 (0.4850)  loss_classifier: 0.1125 (0.1671)  loss_box_reg: 0.0883 (0.1570)  loss_objectness: 0.1059 (0.1129)  loss_rpn_box_reg: 0.0231 (0.0481)  time: 0.2727  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [8]  [ 520/1229]  eta: 0:03:13  lr: 0.005000  loss: 0.3835 (0.4842)  loss_classifier: 0.1300 (0.1668)  loss_box_reg: 0.1180 (0.1566)  loss_objectness: 0.1097 (0.1128)  loss_rpn_box_reg: 0.0231 (0.0480)  time: 0.2739  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [8]  [ 530/1229]  eta: 0:03:11  lr: 0.005000  loss: 0.3847 (0.4831)  loss_classifier: 0.1227 (0.1665)  loss_box_reg: 0.1006 (0.1558)  loss_objectness: 0.1182 (0.1127)  loss_rpn_box_reg: 0.0442 (0.0482)  time: 0.2761  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [8]  [ 540/1229]  eta: 0:03:08  lr: 0.005000  loss: 0.3900 (0.4836)  loss_classifier: 0.1194 (0.1664)  loss_box_reg: 0.1006 (0.1559)  loss_objectness: 0.0857 (0.1127)  loss_rpn_box_reg: 0.0297 (0.0486)  time: 0.2717  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [8]  [ 550/1229]  eta: 0:03:05  lr: 0.005000  loss: 0.3519 (0.4818)  loss_classifier: 0.1249 (0.1659)  loss_box_reg: 0.1091 (0.1554)  loss_objectness: 0.0822 (0.1123)  loss_rpn_box_reg: 0.0179 (0.0482)  time: 0.2675  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [8]  [ 560/1229]  eta: 0:03:02  lr: 0.005000  loss: 0.3519 (0.4812)  loss_classifier: 0.1270 (0.1657)  loss_box_reg: 0.1101 (0.1553)  loss_objectness: 0.0871 (0.1122)  loss_rpn_box_reg: 0.0179 (0.0480)  time: 0.2714  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [8]  [ 570/1229]  eta: 0:03:00  lr: 0.005000  loss: 0.4071 (0.4798)  loss_classifier: 0.1495 (0.1653)  loss_box_reg: 0.0904 (0.1545)  loss_objectness: 0.0894 (0.1122)  loss_rpn_box_reg: 0.0235 (0.0478)  time: 0.2759  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [8]  [ 580/1229]  eta: 0:02:57  lr: 0.005000  loss: 0.4211 (0.4799)  loss_classifier: 0.1416 (0.1654)  loss_box_reg: 0.0997 (0.1548)  loss_objectness: 0.0950 (0.1121)  loss_rpn_box_reg: 0.0247 (0.0476)  time: 0.2777  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [8]  [ 590/1229]  eta: 0:02:54  lr: 0.005000  loss: 0.4367 (0.4804)  loss_classifier: 0.1786 (0.1657)  loss_box_reg: 0.1643 (0.1549)  loss_objectness: 0.0994 (0.1121)  loss_rpn_box_reg: 0.0258 (0.0477)  time: 0.2820  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [8]  [ 600/1229]  eta: 0:02:52  lr: 0.005000  loss: 0.4367 (0.4812)  loss_classifier: 0.1786 (0.1660)  loss_box_reg: 0.1643 (0.1555)  loss_objectness: 0.1079 (0.1122)  loss_rpn_box_reg: 0.0252 (0.0475)  time: 0.2836  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [8]  [ 610/1229]  eta: 0:02:49  lr: 0.005000  loss: 0.5189 (0.4818)  loss_classifier: 0.1584 (0.1661)  loss_box_reg: 0.1598 (0.1558)  loss_objectness: 0.0960 (0.1124)  loss_rpn_box_reg: 0.0249 (0.0475)  time: 0.2715  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [8]  [ 620/1229]  eta: 0:02:46  lr: 0.005000  loss: 0.4798 (0.4806)  loss_classifier: 0.1364 (0.1655)  loss_box_reg: 0.1194 (0.1547)  loss_objectness: 0.0929 (0.1124)  loss_rpn_box_reg: 0.0308 (0.0480)  time: 0.2678  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [8]  [ 630/1229]  eta: 0:02:43  lr: 0.005000  loss: 0.4777 (0.4809)  loss_classifier: 0.1023 (0.1651)  loss_box_reg: 0.0936 (0.1543)  loss_objectness: 0.0912 (0.1124)  loss_rpn_box_reg: 0.0512 (0.0490)  time: 0.2685  data: 0.1288  max mem: 1751\n",
      "Training Epoch: [8]  [ 640/1229]  eta: 0:02:41  lr: 0.005000  loss: 0.4299 (0.4793)  loss_classifier: 0.1387 (0.1645)  loss_box_reg: 0.0955 (0.1536)  loss_objectness: 0.0912 (0.1123)  loss_rpn_box_reg: 0.0356 (0.0489)  time: 0.2659  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [8]  [ 650/1229]  eta: 0:02:38  lr: 0.005000  loss: 0.3115 (0.4775)  loss_classifier: 0.1064 (0.1639)  loss_box_reg: 0.0978 (0.1533)  loss_objectness: 0.0689 (0.1117)  loss_rpn_box_reg: 0.0214 (0.0485)  time: 0.2712  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [8]  [ 660/1229]  eta: 0:02:35  lr: 0.005000  loss: 0.3471 (0.4774)  loss_classifier: 0.1148 (0.1639)  loss_box_reg: 0.1356 (0.1537)  loss_objectness: 0.0617 (0.1114)  loss_rpn_box_reg: 0.0251 (0.0484)  time: 0.2773  data: 0.1300  max mem: 1751\n",
      "Training Epoch: [8]  [ 670/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.3471 (0.4770)  loss_classifier: 0.1315 (0.1639)  loss_box_reg: 0.1476 (0.1536)  loss_objectness: 0.0798 (0.1113)  loss_rpn_box_reg: 0.0255 (0.0482)  time: 0.2786  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [8]  [ 680/1229]  eta: 0:02:30  lr: 0.005000  loss: 0.3272 (0.4750)  loss_classifier: 0.1248 (0.1633)  loss_box_reg: 0.1243 (0.1530)  loss_objectness: 0.0737 (0.1110)  loss_rpn_box_reg: 0.0155 (0.0477)  time: 0.2765  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [8]  [ 690/1229]  eta: 0:02:27  lr: 0.005000  loss: 0.3266 (0.4749)  loss_classifier: 0.1210 (0.1633)  loss_box_reg: 0.0908 (0.1527)  loss_objectness: 0.0737 (0.1112)  loss_rpn_box_reg: 0.0200 (0.0477)  time: 0.2765  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [8]  [ 700/1229]  eta: 0:02:24  lr: 0.005000  loss: 0.4884 (0.4757)  loss_classifier: 0.1494 (0.1634)  loss_box_reg: 0.1181 (0.1532)  loss_objectness: 0.0950 (0.1111)  loss_rpn_box_reg: 0.0329 (0.0479)  time: 0.2764  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [8]  [ 710/1229]  eta: 0:02:22  lr: 0.005000  loss: 0.4884 (0.4762)  loss_classifier: 0.1604 (0.1636)  loss_box_reg: 0.1543 (0.1536)  loss_objectness: 0.1033 (0.1110)  loss_rpn_box_reg: 0.0329 (0.0480)  time: 0.2736  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [8]  [ 720/1229]  eta: 0:02:19  lr: 0.005000  loss: 0.3658 (0.4745)  loss_classifier: 0.1461 (0.1632)  loss_box_reg: 0.1006 (0.1531)  loss_objectness: 0.0799 (0.1105)  loss_rpn_box_reg: 0.0181 (0.0477)  time: 0.2696  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [8]  [ 730/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.4348 (0.4761)  loss_classifier: 0.1700 (0.1637)  loss_box_reg: 0.1006 (0.1534)  loss_objectness: 0.0883 (0.1109)  loss_rpn_box_reg: 0.0206 (0.0481)  time: 0.2705  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [8]  [ 740/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.4348 (0.4753)  loss_classifier: 0.1772 (0.1634)  loss_box_reg: 0.1121 (0.1528)  loss_objectness: 0.1138 (0.1109)  loss_rpn_box_reg: 0.0381 (0.0481)  time: 0.2751  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [8]  [ 750/1229]  eta: 0:02:11  lr: 0.005000  loss: 0.3449 (0.4738)  loss_classifier: 0.1107 (0.1627)  loss_box_reg: 0.0991 (0.1520)  loss_objectness: 0.1075 (0.1109)  loss_rpn_box_reg: 0.0310 (0.0482)  time: 0.2754  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [8]  [ 760/1229]  eta: 0:02:08  lr: 0.005000  loss: 0.2916 (0.4715)  loss_classifier: 0.1042 (0.1619)  loss_box_reg: 0.0627 (0.1510)  loss_objectness: 0.0992 (0.1107)  loss_rpn_box_reg: 0.0205 (0.0478)  time: 0.2747  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [8]  [ 770/1229]  eta: 0:02:05  lr: 0.005000  loss: 0.3242 (0.4718)  loss_classifier: 0.1215 (0.1618)  loss_box_reg: 0.0781 (0.1512)  loss_objectness: 0.0924 (0.1109)  loss_rpn_box_reg: 0.0217 (0.0480)  time: 0.2748  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [8]  [ 780/1229]  eta: 0:02:02  lr: 0.005000  loss: 0.4280 (0.4729)  loss_classifier: 0.1362 (0.1621)  loss_box_reg: 0.1143 (0.1515)  loss_objectness: 0.1094 (0.1112)  loss_rpn_box_reg: 0.0332 (0.0480)  time: 0.2699  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [8]  [ 790/1229]  eta: 0:02:00  lr: 0.005000  loss: 0.4571 (0.4734)  loss_classifier: 0.1460 (0.1622)  loss_box_reg: 0.1368 (0.1517)  loss_objectness: 0.1239 (0.1114)  loss_rpn_box_reg: 0.0332 (0.0481)  time: 0.2709  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [8]  [ 800/1229]  eta: 0:01:57  lr: 0.005000  loss: 0.3982 (0.4727)  loss_classifier: 0.1434 (0.1618)  loss_box_reg: 0.1014 (0.1515)  loss_objectness: 0.1069 (0.1113)  loss_rpn_box_reg: 0.0302 (0.0479)  time: 0.2710  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [8]  [ 810/1229]  eta: 0:01:54  lr: 0.005000  loss: 0.2806 (0.4715)  loss_classifier: 0.0997 (0.1615)  loss_box_reg: 0.0862 (0.1512)  loss_objectness: 0.0936 (0.1110)  loss_rpn_box_reg: 0.0205 (0.0478)  time: 0.2680  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [8]  [ 820/1229]  eta: 0:01:51  lr: 0.005000  loss: 0.3039 (0.4715)  loss_classifier: 0.1104 (0.1614)  loss_box_reg: 0.0955 (0.1510)  loss_objectness: 0.0848 (0.1110)  loss_rpn_box_reg: 0.0204 (0.0481)  time: 0.2677  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [8]  [ 830/1229]  eta: 0:01:49  lr: 0.005000  loss: 0.4435 (0.4720)  loss_classifier: 0.1631 (0.1616)  loss_box_reg: 0.1179 (0.1511)  loss_objectness: 0.1041 (0.1111)  loss_rpn_box_reg: 0.0223 (0.0482)  time: 0.2664  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [8]  [ 840/1229]  eta: 0:01:46  lr: 0.005000  loss: 0.4135 (0.4708)  loss_classifier: 0.1356 (0.1610)  loss_box_reg: 0.1138 (0.1505)  loss_objectness: 0.1041 (0.1110)  loss_rpn_box_reg: 0.0255 (0.0482)  time: 0.2703  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [8]  [ 850/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.3753 (0.4695)  loss_classifier: 0.1060 (0.1605)  loss_box_reg: 0.0963 (0.1499)  loss_objectness: 0.0929 (0.1108)  loss_rpn_box_reg: 0.0170 (0.0482)  time: 0.2728  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [8]  [ 860/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.4550 (0.4696)  loss_classifier: 0.1494 (0.1605)  loss_box_reg: 0.1101 (0.1499)  loss_objectness: 0.0978 (0.1111)  loss_rpn_box_reg: 0.0258 (0.0481)  time: 0.2732  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [8]  [ 870/1229]  eta: 0:01:38  lr: 0.005000  loss: 0.4657 (0.4698)  loss_classifier: 0.1688 (0.1607)  loss_box_reg: 0.1132 (0.1498)  loss_objectness: 0.1067 (0.1113)  loss_rpn_box_reg: 0.0273 (0.0481)  time: 0.2750  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [8]  [ 880/1229]  eta: 0:01:35  lr: 0.005000  loss: 0.3682 (0.4687)  loss_classifier: 0.1423 (0.1605)  loss_box_reg: 0.0958 (0.1494)  loss_objectness: 0.0793 (0.1110)  loss_rpn_box_reg: 0.0161 (0.0478)  time: 0.2739  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [8]  [ 890/1229]  eta: 0:01:32  lr: 0.005000  loss: 0.3783 (0.4687)  loss_classifier: 0.1134 (0.1603)  loss_box_reg: 0.0825 (0.1491)  loss_objectness: 0.0854 (0.1112)  loss_rpn_box_reg: 0.0234 (0.0481)  time: 0.2734  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [8]  [ 900/1229]  eta: 0:01:29  lr: 0.005000  loss: 0.4124 (0.4682)  loss_classifier: 0.1278 (0.1602)  loss_box_reg: 0.0894 (0.1487)  loss_objectness: 0.1142 (0.1113)  loss_rpn_box_reg: 0.0429 (0.0481)  time: 0.2824  data: 0.1416  max mem: 1751\n",
      "Training Epoch: [8]  [ 910/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.4720 (0.4700)  loss_classifier: 0.1523 (0.1610)  loss_box_reg: 0.1559 (0.1492)  loss_objectness: 0.1116 (0.1113)  loss_rpn_box_reg: 0.0531 (0.0484)  time: 0.2898  data: 0.1515  max mem: 1751\n",
      "Training Epoch: [8]  [ 920/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.4455 (0.4685)  loss_classifier: 0.1445 (0.1605)  loss_box_reg: 0.1550 (0.1487)  loss_objectness: 0.0851 (0.1110)  loss_rpn_box_reg: 0.0379 (0.0483)  time: 0.2879  data: 0.1498  max mem: 1751\n",
      "Training Epoch: [8]  [ 930/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.3888 (0.4693)  loss_classifier: 0.1320 (0.1606)  loss_box_reg: 0.0934 (0.1488)  loss_objectness: 0.0901 (0.1112)  loss_rpn_box_reg: 0.0336 (0.0487)  time: 0.2780  data: 0.1437  max mem: 1751\n",
      "Training Epoch: [8]  [ 940/1229]  eta: 0:01:19  lr: 0.005000  loss: 0.5445 (0.4714)  loss_classifier: 0.1714 (0.1612)  loss_box_reg: 0.1506 (0.1497)  loss_objectness: 0.1419 (0.1117)  loss_rpn_box_reg: 0.0438 (0.0488)  time: 0.2741  data: 0.1392  max mem: 1751\n",
      "Training Epoch: [8]  [ 950/1229]  eta: 0:01:16  lr: 0.005000  loss: 0.4959 (0.4716)  loss_classifier: 0.1714 (0.1613)  loss_box_reg: 0.1788 (0.1500)  loss_objectness: 0.1094 (0.1116)  loss_rpn_box_reg: 0.0362 (0.0487)  time: 0.2769  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [8]  [ 960/1229]  eta: 0:01:13  lr: 0.005000  loss: 0.4710 (0.4716)  loss_classifier: 0.1611 (0.1613)  loss_box_reg: 0.1537 (0.1499)  loss_objectness: 0.1037 (0.1117)  loss_rpn_box_reg: 0.0294 (0.0487)  time: 0.2781  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [8]  [ 970/1229]  eta: 0:01:10  lr: 0.005000  loss: 0.4119 (0.4710)  loss_classifier: 0.1431 (0.1611)  loss_box_reg: 0.1031 (0.1496)  loss_objectness: 0.0920 (0.1116)  loss_rpn_box_reg: 0.0241 (0.0488)  time: 0.2782  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [8]  [ 980/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.3727 (0.4713)  loss_classifier: 0.1415 (0.1612)  loss_box_reg: 0.0989 (0.1499)  loss_objectness: 0.0856 (0.1116)  loss_rpn_box_reg: 0.0222 (0.0486)  time: 0.2747  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [8]  [ 990/1229]  eta: 0:01:05  lr: 0.005000  loss: 0.3940 (0.4711)  loss_classifier: 0.1453 (0.1612)  loss_box_reg: 0.1256 (0.1497)  loss_objectness: 0.0972 (0.1116)  loss_rpn_box_reg: 0.0237 (0.0486)  time: 0.2728  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [8]  [1000/1229]  eta: 0:01:02  lr: 0.005000  loss: 0.4875 (0.4722)  loss_classifier: 0.1696 (0.1615)  loss_box_reg: 0.1490 (0.1502)  loss_objectness: 0.1093 (0.1118)  loss_rpn_box_reg: 0.0324 (0.0486)  time: 0.2697  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [8]  [1010/1229]  eta: 0:00:59  lr: 0.005000  loss: 0.5588 (0.4729)  loss_classifier: 0.1696 (0.1618)  loss_box_reg: 0.1782 (0.1502)  loss_objectness: 0.1133 (0.1121)  loss_rpn_box_reg: 0.0391 (0.0489)  time: 0.2684  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [8]  [1020/1229]  eta: 0:00:57  lr: 0.005000  loss: 0.3449 (0.4717)  loss_classifier: 0.1263 (0.1615)  loss_box_reg: 0.0924 (0.1497)  loss_objectness: 0.0967 (0.1119)  loss_rpn_box_reg: 0.0187 (0.0486)  time: 0.2747  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [8]  [1030/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.3405 (0.4722)  loss_classifier: 0.1263 (0.1615)  loss_box_reg: 0.0930 (0.1496)  loss_objectness: 0.0946 (0.1122)  loss_rpn_box_reg: 0.0216 (0.0489)  time: 0.2755  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [8]  [1040/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.3767 (0.4717)  loss_classifier: 0.1224 (0.1613)  loss_box_reg: 0.0930 (0.1495)  loss_objectness: 0.1172 (0.1121)  loss_rpn_box_reg: 0.0303 (0.0487)  time: 0.2687  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [8]  [1050/1229]  eta: 0:00:49  lr: 0.005000  loss: 0.3324 (0.4719)  loss_classifier: 0.1224 (0.1614)  loss_box_reg: 0.0893 (0.1495)  loss_objectness: 0.1174 (0.1121)  loss_rpn_box_reg: 0.0262 (0.0489)  time: 0.2734  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [8]  [1060/1229]  eta: 0:00:46  lr: 0.005000  loss: 0.4367 (0.4724)  loss_classifier: 0.1655 (0.1617)  loss_box_reg: 0.1764 (0.1498)  loss_objectness: 0.0998 (0.1121)  loss_rpn_box_reg: 0.0214 (0.0488)  time: 0.2782  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [8]  [1070/1229]  eta: 0:00:43  lr: 0.005000  loss: 0.4295 (0.4714)  loss_classifier: 0.1503 (0.1614)  loss_box_reg: 0.1840 (0.1496)  loss_objectness: 0.0802 (0.1118)  loss_rpn_box_reg: 0.0179 (0.0486)  time: 0.2791  data: 0.1386  max mem: 1751\n",
      "Training Epoch: [8]  [1080/1229]  eta: 0:00:40  lr: 0.005000  loss: 0.3532 (0.4713)  loss_classifier: 0.1058 (0.1612)  loss_box_reg: 0.0966 (0.1495)  loss_objectness: 0.0884 (0.1118)  loss_rpn_box_reg: 0.0175 (0.0489)  time: 0.2769  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [8]  [1090/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.3528 (0.4705)  loss_classifier: 0.1090 (0.1608)  loss_box_reg: 0.0966 (0.1491)  loss_objectness: 0.0853 (0.1116)  loss_rpn_box_reg: 0.0332 (0.0490)  time: 0.2780  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [8]  [1100/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.3412 (0.4695)  loss_classifier: 0.1094 (0.1605)  loss_box_reg: 0.1005 (0.1488)  loss_objectness: 0.0760 (0.1114)  loss_rpn_box_reg: 0.0318 (0.0488)  time: 0.2808  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [8]  [1110/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.2677 (0.4682)  loss_classifier: 0.0891 (0.1601)  loss_box_reg: 0.1005 (0.1484)  loss_objectness: 0.0672 (0.1111)  loss_rpn_box_reg: 0.0204 (0.0486)  time: 0.2737  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [8]  [1120/1229]  eta: 0:00:29  lr: 0.005000  loss: 0.3651 (0.4690)  loss_classifier: 0.1134 (0.1602)  loss_box_reg: 0.1098 (0.1488)  loss_objectness: 0.0747 (0.1113)  loss_rpn_box_reg: 0.0258 (0.0487)  time: 0.2748  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [8]  [1130/1229]  eta: 0:00:27  lr: 0.005000  loss: 0.5063 (0.4699)  loss_classifier: 0.1470 (0.1606)  loss_box_reg: 0.1685 (0.1493)  loss_objectness: 0.0963 (0.1112)  loss_rpn_box_reg: 0.0367 (0.0488)  time: 0.2774  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [8]  [1140/1229]  eta: 0:00:24  lr: 0.005000  loss: 0.4938 (0.4697)  loss_classifier: 0.1470 (0.1606)  loss_box_reg: 0.1316 (0.1492)  loss_objectness: 0.0963 (0.1111)  loss_rpn_box_reg: 0.0324 (0.0488)  time: 0.2793  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [8]  [1150/1229]  eta: 0:00:21  lr: 0.005000  loss: 0.3846 (0.4689)  loss_classifier: 0.1232 (0.1603)  loss_box_reg: 0.0740 (0.1486)  loss_objectness: 0.0955 (0.1110)  loss_rpn_box_reg: 0.0260 (0.0489)  time: 0.2788  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [8]  [1160/1229]  eta: 0:00:18  lr: 0.005000  loss: 0.3281 (0.4683)  loss_classifier: 0.1152 (0.1601)  loss_box_reg: 0.0683 (0.1484)  loss_objectness: 0.0962 (0.1110)  loss_rpn_box_reg: 0.0219 (0.0488)  time: 0.2742  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [8]  [1170/1229]  eta: 0:00:16  lr: 0.005000  loss: 0.3251 (0.4688)  loss_classifier: 0.1152 (0.1602)  loss_box_reg: 0.0978 (0.1485)  loss_objectness: 0.1026 (0.1112)  loss_rpn_box_reg: 0.0353 (0.0489)  time: 0.2725  data: 0.1377  max mem: 1751\n",
      "Training Epoch: [8]  [1180/1229]  eta: 0:00:13  lr: 0.005000  loss: 0.3622 (0.4681)  loss_classifier: 0.1203 (0.1598)  loss_box_reg: 0.0978 (0.1480)  loss_objectness: 0.0998 (0.1114)  loss_rpn_box_reg: 0.0275 (0.0489)  time: 0.2703  data: 0.1386  max mem: 1751\n",
      "Training Epoch: [8]  [1190/1229]  eta: 0:00:10  lr: 0.005000  loss: 0.3622 (0.4677)  loss_classifier: 0.1203 (0.1597)  loss_box_reg: 0.0883 (0.1478)  loss_objectness: 0.0970 (0.1114)  loss_rpn_box_reg: 0.0134 (0.0488)  time: 0.2700  data: 0.1390  max mem: 1751\n",
      "Training Epoch: [8]  [1200/1229]  eta: 0:00:07  lr: 0.005000  loss: 0.3803 (0.4674)  loss_classifier: 0.1538 (0.1597)  loss_box_reg: 0.1317 (0.1480)  loss_objectness: 0.0857 (0.1111)  loss_rpn_box_reg: 0.0193 (0.0486)  time: 0.2699  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [8]  [1210/1229]  eta: 0:00:05  lr: 0.005000  loss: 0.4306 (0.4676)  loss_classifier: 0.1448 (0.1599)  loss_box_reg: 0.1411 (0.1480)  loss_objectness: 0.0872 (0.1111)  loss_rpn_box_reg: 0.0203 (0.0485)  time: 0.2671  data: 0.1386  max mem: 1751\n",
      "Training Epoch: [8]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.3943 (0.4672)  loss_classifier: 0.1355 (0.1598)  loss_box_reg: 0.1155 (0.1479)  loss_objectness: 0.0912 (0.1109)  loss_rpn_box_reg: 0.0261 (0.0485)  time: 0.2768  data: 0.1383  max mem: 1751\n",
      "Training Epoch: [8]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.3882 (0.4669)  loss_classifier: 0.1091 (0.1598)  loss_box_reg: 0.1052 (0.1479)  loss_objectness: 0.0630 (0.1107)  loss_rpn_box_reg: 0.0211 (0.0484)  time: 0.2783  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [8] Total time: 0:05:36 (0.2741 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:27  model_time: 0.2480 (0.2480)  evaluator_time: 0.0020 (0.0020)  time: 0.2830  data: 0.0310  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0800 (0.0815)  evaluator_time: 0.0050 (0.0078)  time: 0.1273  data: 0.0374  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0820 (0.0805)  evaluator_time: 0.0030 (0.0072)  time: 0.1204  data: 0.0320  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0740 (0.0797)  evaluator_time: 0.0030 (0.0071)  time: 0.1205  data: 0.0364  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0740 (0.0796)  evaluator_time: 0.0020 (0.0071)  time: 0.1174  data: 0.0350  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1243 s / it)\n",
      "Averaged stats: model_time: 0.0740 (0.0796)  evaluator_time: 0.0020 (0.0071)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.308\n",
      "Testing Epoch: [8]  [  0/308]  eta: 0:00:38  lr: 0.005000  loss: 0.1570 (0.1570)  loss_classifier: 0.0628 (0.0628)  loss_box_reg: 0.0636 (0.0636)  loss_objectness: 0.0246 (0.0246)  loss_rpn_box_reg: 0.0059 (0.0059)  time: 0.1260  data: 0.0290  max mem: 1751\n",
      "Testing Epoch: [8]  [100/308]  eta: 0:00:29  lr: 0.005000  loss: 0.3144 (0.5083)  loss_classifier: 0.1290 (0.1632)  loss_box_reg: 0.1168 (0.1815)  loss_objectness: 0.0517 (0.1060)  loss_rpn_box_reg: 0.0197 (0.0576)  time: 0.1424  data: 0.0398  max mem: 1751\n",
      "Testing Epoch: [8]  [200/308]  eta: 0:00:15  lr: 0.005000  loss: 0.3662 (0.4815)  loss_classifier: 0.1385 (0.1559)  loss_box_reg: 0.1555 (0.1724)  loss_objectness: 0.0685 (0.0979)  loss_rpn_box_reg: 0.0198 (0.0552)  time: 0.1388  data: 0.0339  max mem: 1751\n",
      "Testing Epoch: [8]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.4707 (0.4786)  loss_classifier: 0.1547 (0.1559)  loss_box_reg: 0.1481 (0.1738)  loss_objectness: 0.0772 (0.0948)  loss_rpn_box_reg: 0.0273 (0.0540)  time: 0.1339  data: 0.0380  max mem: 1751\n",
      "Testing Epoch: [8]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.4685 (0.4784)  loss_classifier: 0.1638 (0.1562)  loss_box_reg: 0.1530 (0.1739)  loss_objectness: 0.0803 (0.0947)  loss_rpn_box_reg: 0.0273 (0.0536)  time: 0.1324  data: 0.0368  max mem: 1751\n",
      "Testing Epoch: [8] Total time: 0:00:42 (0.1388 s / it)\n",
      "Training Epoch: [9]  [   0/1229]  eta: 0:05:17  lr: 0.000500  loss: 0.1774 (0.1774)  loss_classifier: 0.0602 (0.0602)  loss_box_reg: 0.0610 (0.0610)  loss_objectness: 0.0484 (0.0484)  loss_rpn_box_reg: 0.0078 (0.0078)  time: 0.2580  data: 0.1210  max mem: 1751\n",
      "Training Epoch: [9]  [  10/1229]  eta: 0:05:33  lr: 0.000500  loss: 0.4537 (0.4588)  loss_classifier: 0.1139 (0.1545)  loss_box_reg: 0.1085 (0.1462)  loss_objectness: 0.1296 (0.1175)  loss_rpn_box_reg: 0.0293 (0.0405)  time: 0.2733  data: 0.1381  max mem: 1751\n",
      "Training Epoch: [9]  [  20/1229]  eta: 0:05:33  lr: 0.000500  loss: 0.3562 (0.4393)  loss_classifier: 0.1237 (0.1568)  loss_box_reg: 0.1085 (0.1448)  loss_objectness: 0.1062 (0.1071)  loss_rpn_box_reg: 0.0255 (0.0305)  time: 0.2768  data: 0.1400  max mem: 1751\n",
      "Training Epoch: [9]  [  30/1229]  eta: 0:05:39  lr: 0.000500  loss: 0.3562 (0.4266)  loss_classifier: 0.1208 (0.1526)  loss_box_reg: 0.0892 (0.1350)  loss_objectness: 0.0744 (0.1089)  loss_rpn_box_reg: 0.0237 (0.0301)  time: 0.2882  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [9]  [  40/1229]  eta: 0:05:33  lr: 0.000500  loss: 0.4186 (0.4394)  loss_classifier: 0.1405 (0.1558)  loss_box_reg: 0.1097 (0.1363)  loss_objectness: 0.1181 (0.1150)  loss_rpn_box_reg: 0.0232 (0.0322)  time: 0.2849  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [9]  [  50/1229]  eta: 0:05:30  lr: 0.000500  loss: 0.4498 (0.4567)  loss_classifier: 0.1738 (0.1637)  loss_box_reg: 0.1411 (0.1488)  loss_objectness: 0.1172 (0.1140)  loss_rpn_box_reg: 0.0216 (0.0302)  time: 0.2774  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [9]  [  60/1229]  eta: 0:05:28  lr: 0.000500  loss: 0.3134 (0.4378)  loss_classifier: 0.1178 (0.1577)  loss_box_reg: 0.1151 (0.1438)  loss_objectness: 0.0622 (0.1066)  loss_rpn_box_reg: 0.0180 (0.0298)  time: 0.2824  data: 0.1375  max mem: 1751\n",
      "Training Epoch: [9]  [  70/1229]  eta: 0:05:26  lr: 0.000500  loss: 0.3301 (0.4366)  loss_classifier: 0.1178 (0.1564)  loss_box_reg: 0.1153 (0.1437)  loss_objectness: 0.0812 (0.1050)  loss_rpn_box_reg: 0.0212 (0.0316)  time: 0.2839  data: 0.1395  max mem: 1751\n",
      "Training Epoch: [9]  [  80/1229]  eta: 0:05:23  lr: 0.000500  loss: 0.3654 (0.4340)  loss_classifier: 0.1274 (0.1556)  loss_box_reg: 0.1194 (0.1439)  loss_objectness: 0.0910 (0.1042)  loss_rpn_box_reg: 0.0204 (0.0302)  time: 0.2830  data: 0.1389  max mem: 1751\n",
      "Training Epoch: [9]  [  90/1229]  eta: 0:05:19  lr: 0.000500  loss: 0.3654 (0.4415)  loss_classifier: 0.1464 (0.1568)  loss_box_reg: 0.1184 (0.1456)  loss_objectness: 0.1120 (0.1070)  loss_rpn_box_reg: 0.0204 (0.0321)  time: 0.2763  data: 0.1385  max mem: 1751\n",
      "Training Epoch: [9]  [ 100/1229]  eta: 0:05:16  lr: 0.000500  loss: 0.4104 (0.4389)  loss_classifier: 0.1464 (0.1559)  loss_box_reg: 0.1302 (0.1441)  loss_objectness: 0.1156 (0.1073)  loss_rpn_box_reg: 0.0323 (0.0317)  time: 0.2735  data: 0.1380  max mem: 1751\n",
      "Training Epoch: [9]  [ 110/1229]  eta: 0:05:12  lr: 0.000500  loss: 0.4072 (0.4376)  loss_classifier: 0.1565 (0.1560)  loss_box_reg: 0.1242 (0.1425)  loss_objectness: 0.1177 (0.1081)  loss_rpn_box_reg: 0.0201 (0.0310)  time: 0.2714  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [9]  [ 120/1229]  eta: 0:05:09  lr: 0.000500  loss: 0.3665 (0.4323)  loss_classifier: 0.1311 (0.1547)  loss_box_reg: 0.1242 (0.1403)  loss_objectness: 0.1011 (0.1067)  loss_rpn_box_reg: 0.0182 (0.0307)  time: 0.2728  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [9]  [ 130/1229]  eta: 0:05:05  lr: 0.000500  loss: 0.3595 (0.4349)  loss_classifier: 0.1311 (0.1552)  loss_box_reg: 0.0918 (0.1399)  loss_objectness: 0.0928 (0.1079)  loss_rpn_box_reg: 0.0224 (0.0319)  time: 0.2756  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [9]  [ 140/1229]  eta: 0:05:02  lr: 0.000500  loss: 0.4046 (0.4316)  loss_classifier: 0.1444 (0.1536)  loss_box_reg: 0.1493 (0.1399)  loss_objectness: 0.0905 (0.1068)  loss_rpn_box_reg: 0.0224 (0.0313)  time: 0.2732  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [9]  [ 150/1229]  eta: 0:04:59  lr: 0.000500  loss: 0.4046 (0.4307)  loss_classifier: 0.1444 (0.1523)  loss_box_reg: 0.1526 (0.1387)  loss_objectness: 0.0833 (0.1062)  loss_rpn_box_reg: 0.0258 (0.0334)  time: 0.2715  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [9]  [ 160/1229]  eta: 0:04:56  lr: 0.000500  loss: 0.4817 (0.4348)  loss_classifier: 0.1532 (0.1538)  loss_box_reg: 0.1407 (0.1417)  loss_objectness: 0.0855 (0.1058)  loss_rpn_box_reg: 0.0258 (0.0334)  time: 0.2702  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [9]  [ 170/1229]  eta: 0:04:53  lr: 0.000500  loss: 0.5163 (0.4377)  loss_classifier: 0.1677 (0.1548)  loss_box_reg: 0.1562 (0.1423)  loss_objectness: 0.0902 (0.1064)  loss_rpn_box_reg: 0.0197 (0.0341)  time: 0.2740  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [9]  [ 180/1229]  eta: 0:04:50  lr: 0.000500  loss: 0.3031 (0.4367)  loss_classifier: 0.1237 (0.1536)  loss_box_reg: 0.0786 (0.1415)  loss_objectness: 0.0886 (0.1057)  loss_rpn_box_reg: 0.0306 (0.0360)  time: 0.2731  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [9]  [ 190/1229]  eta: 0:04:47  lr: 0.000500  loss: 0.3488 (0.4345)  loss_classifier: 0.1249 (0.1528)  loss_box_reg: 0.1011 (0.1412)  loss_objectness: 0.0838 (0.1046)  loss_rpn_box_reg: 0.0344 (0.0359)  time: 0.2733  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [9]  [ 200/1229]  eta: 0:04:45  lr: 0.000500  loss: 0.3807 (0.4342)  loss_classifier: 0.1313 (0.1530)  loss_box_reg: 0.1248 (0.1404)  loss_objectness: 0.0860 (0.1047)  loss_rpn_box_reg: 0.0250 (0.0361)  time: 0.2814  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [9]  [ 210/1229]  eta: 0:04:41  lr: 0.000500  loss: 0.4051 (0.4334)  loss_classifier: 0.1331 (0.1524)  loss_box_reg: 0.1163 (0.1392)  loss_objectness: 0.0990 (0.1053)  loss_rpn_box_reg: 0.0231 (0.0365)  time: 0.2736  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [9]  [ 220/1229]  eta: 0:04:38  lr: 0.000500  loss: 0.3903 (0.4334)  loss_classifier: 0.1318 (0.1527)  loss_box_reg: 0.1033 (0.1397)  loss_objectness: 0.0952 (0.1049)  loss_rpn_box_reg: 0.0165 (0.0362)  time: 0.2667  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [9]  [ 230/1229]  eta: 0:04:35  lr: 0.000500  loss: 0.3941 (0.4385)  loss_classifier: 0.1471 (0.1537)  loss_box_reg: 0.1115 (0.1419)  loss_objectness: 0.0895 (0.1053)  loss_rpn_box_reg: 0.0161 (0.0377)  time: 0.2730  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [9]  [ 240/1229]  eta: 0:04:32  lr: 0.000500  loss: 0.3985 (0.4394)  loss_classifier: 0.1471 (0.1538)  loss_box_reg: 0.1194 (0.1421)  loss_objectness: 0.0940 (0.1058)  loss_rpn_box_reg: 0.0283 (0.0377)  time: 0.2735  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [9]  [ 250/1229]  eta: 0:04:30  lr: 0.000500  loss: 0.4106 (0.4405)  loss_classifier: 0.1538 (0.1545)  loss_box_reg: 0.1184 (0.1417)  loss_objectness: 0.0940 (0.1062)  loss_rpn_box_reg: 0.0303 (0.0380)  time: 0.2767  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [9]  [ 260/1229]  eta: 0:04:27  lr: 0.000500  loss: 0.4047 (0.4388)  loss_classifier: 0.1392 (0.1539)  loss_box_reg: 0.1003 (0.1416)  loss_objectness: 0.0726 (0.1054)  loss_rpn_box_reg: 0.0239 (0.0380)  time: 0.2765  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [9]  [ 270/1229]  eta: 0:04:24  lr: 0.000500  loss: 0.3816 (0.4405)  loss_classifier: 0.1353 (0.1546)  loss_box_reg: 0.1075 (0.1430)  loss_objectness: 0.0778 (0.1050)  loss_rpn_box_reg: 0.0272 (0.0379)  time: 0.2760  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [9]  [ 280/1229]  eta: 0:04:21  lr: 0.000500  loss: 0.4465 (0.4415)  loss_classifier: 0.1469 (0.1547)  loss_box_reg: 0.1384 (0.1431)  loss_objectness: 0.1063 (0.1053)  loss_rpn_box_reg: 0.0272 (0.0384)  time: 0.2738  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [9]  [ 290/1229]  eta: 0:04:18  lr: 0.000500  loss: 0.4465 (0.4445)  loss_classifier: 0.1520 (0.1556)  loss_box_reg: 0.1527 (0.1447)  loss_objectness: 0.1102 (0.1059)  loss_rpn_box_reg: 0.0327 (0.0383)  time: 0.2681  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [9]  [ 300/1229]  eta: 0:04:16  lr: 0.000500  loss: 0.3880 (0.4430)  loss_classifier: 0.1522 (0.1552)  loss_box_reg: 0.1292 (0.1434)  loss_objectness: 0.1221 (0.1059)  loss_rpn_box_reg: 0.0248 (0.0385)  time: 0.2726  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [9]  [ 310/1229]  eta: 0:04:13  lr: 0.000500  loss: 0.3045 (0.4409)  loss_classifier: 0.1155 (0.1545)  loss_box_reg: 0.0663 (0.1424)  loss_objectness: 0.1069 (0.1061)  loss_rpn_box_reg: 0.0158 (0.0379)  time: 0.2728  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [9]  [ 320/1229]  eta: 0:04:10  lr: 0.000500  loss: 0.3377 (0.4404)  loss_classifier: 0.1160 (0.1545)  loss_box_reg: 0.1046 (0.1422)  loss_objectness: 0.0998 (0.1063)  loss_rpn_box_reg: 0.0161 (0.0374)  time: 0.2706  data: 0.1300  max mem: 1751\n",
      "Training Epoch: [9]  [ 330/1229]  eta: 0:04:07  lr: 0.000500  loss: 0.3295 (0.4387)  loss_classifier: 0.1251 (0.1539)  loss_box_reg: 0.1046 (0.1412)  loss_objectness: 0.0759 (0.1064)  loss_rpn_box_reg: 0.0249 (0.0372)  time: 0.2725  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [9]  [ 340/1229]  eta: 0:04:04  lr: 0.000500  loss: 0.3393 (0.4382)  loss_classifier: 0.1251 (0.1536)  loss_box_reg: 0.0842 (0.1410)  loss_objectness: 0.0713 (0.1062)  loss_rpn_box_reg: 0.0249 (0.0374)  time: 0.2693  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [9]  [ 350/1229]  eta: 0:04:01  lr: 0.000500  loss: 0.3031 (0.4350)  loss_classifier: 0.1154 (0.1525)  loss_box_reg: 0.0814 (0.1400)  loss_objectness: 0.0733 (0.1053)  loss_rpn_box_reg: 0.0161 (0.0371)  time: 0.2695  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [9]  [ 360/1229]  eta: 0:03:58  lr: 0.000500  loss: 0.3031 (0.4375)  loss_classifier: 0.1194 (0.1532)  loss_box_reg: 0.1324 (0.1421)  loss_objectness: 0.0743 (0.1048)  loss_rpn_box_reg: 0.0212 (0.0375)  time: 0.2747  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [9]  [ 370/1229]  eta: 0:03:56  lr: 0.000500  loss: 0.5569 (0.4420)  loss_classifier: 0.1847 (0.1547)  loss_box_reg: 0.1853 (0.1429)  loss_objectness: 0.0941 (0.1061)  loss_rpn_box_reg: 0.0353 (0.0383)  time: 0.2736  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [9]  [ 380/1229]  eta: 0:03:53  lr: 0.000500  loss: 0.5065 (0.4413)  loss_classifier: 0.1558 (0.1544)  loss_box_reg: 0.1257 (0.1422)  loss_objectness: 0.1174 (0.1064)  loss_rpn_box_reg: 0.0426 (0.0383)  time: 0.2701  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [9]  [ 390/1229]  eta: 0:03:50  lr: 0.000500  loss: 0.4127 (0.4413)  loss_classifier: 0.1438 (0.1546)  loss_box_reg: 0.1013 (0.1420)  loss_objectness: 0.1062 (0.1066)  loss_rpn_box_reg: 0.0232 (0.0381)  time: 0.2750  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [9]  [ 400/1229]  eta: 0:03:47  lr: 0.000500  loss: 0.4603 (0.4418)  loss_classifier: 0.1726 (0.1547)  loss_box_reg: 0.1182 (0.1425)  loss_objectness: 0.1057 (0.1066)  loss_rpn_box_reg: 0.0209 (0.0381)  time: 0.2762  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [9]  [ 410/1229]  eta: 0:03:44  lr: 0.000500  loss: 0.3598 (0.4397)  loss_classifier: 0.1345 (0.1541)  loss_box_reg: 0.1164 (0.1419)  loss_objectness: 0.0909 (0.1058)  loss_rpn_box_reg: 0.0221 (0.0379)  time: 0.2713  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [9]  [ 420/1229]  eta: 0:03:42  lr: 0.000500  loss: 0.3261 (0.4380)  loss_classifier: 0.1116 (0.1537)  loss_box_reg: 0.1124 (0.1416)  loss_objectness: 0.0617 (0.1053)  loss_rpn_box_reg: 0.0210 (0.0374)  time: 0.2694  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [9]  [ 430/1229]  eta: 0:03:39  lr: 0.000500  loss: 0.3408 (0.4392)  loss_classifier: 0.1116 (0.1541)  loss_box_reg: 0.1225 (0.1424)  loss_objectness: 0.0680 (0.1051)  loss_rpn_box_reg: 0.0169 (0.0377)  time: 0.2746  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [9]  [ 440/1229]  eta: 0:03:36  lr: 0.000500  loss: 0.4057 (0.4408)  loss_classifier: 0.1528 (0.1549)  loss_box_reg: 0.1298 (0.1430)  loss_objectness: 0.0871 (0.1053)  loss_rpn_box_reg: 0.0198 (0.0375)  time: 0.2768  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [9]  [ 450/1229]  eta: 0:03:34  lr: 0.000500  loss: 0.3771 (0.4409)  loss_classifier: 0.1593 (0.1550)  loss_box_reg: 0.1224 (0.1430)  loss_objectness: 0.0845 (0.1051)  loss_rpn_box_reg: 0.0203 (0.0377)  time: 0.2762  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [9]  [ 460/1229]  eta: 0:03:31  lr: 0.000500  loss: 0.3771 (0.4406)  loss_classifier: 0.1263 (0.1548)  loss_box_reg: 0.1083 (0.1431)  loss_objectness: 0.0907 (0.1049)  loss_rpn_box_reg: 0.0240 (0.0377)  time: 0.2770  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [9]  [ 470/1229]  eta: 0:03:28  lr: 0.000500  loss: 0.3115 (0.4388)  loss_classifier: 0.1119 (0.1541)  loss_box_reg: 0.0908 (0.1422)  loss_objectness: 0.0956 (0.1047)  loss_rpn_box_reg: 0.0248 (0.0378)  time: 0.2746  data: 0.1376  max mem: 1751\n",
      "Training Epoch: [9]  [ 480/1229]  eta: 0:03:25  lr: 0.000500  loss: 0.3213 (0.4385)  loss_classifier: 0.1007 (0.1537)  loss_box_reg: 0.0791 (0.1420)  loss_objectness: 0.0956 (0.1045)  loss_rpn_box_reg: 0.0233 (0.0383)  time: 0.2712  data: 0.1367  max mem: 1751\n",
      "Training Epoch: [9]  [ 490/1229]  eta: 0:03:22  lr: 0.000500  loss: 0.3379 (0.4398)  loss_classifier: 0.1055 (0.1541)  loss_box_reg: 0.0994 (0.1422)  loss_objectness: 0.1016 (0.1051)  loss_rpn_box_reg: 0.0245 (0.0384)  time: 0.2674  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [9]  [ 500/1229]  eta: 0:03:20  lr: 0.000500  loss: 0.2414 (0.4385)  loss_classifier: 0.0885 (0.1540)  loss_box_reg: 0.0895 (0.1418)  loss_objectness: 0.0901 (0.1045)  loss_rpn_box_reg: 0.0159 (0.0382)  time: 0.2752  data: 0.1376  max mem: 1751\n",
      "Training Epoch: [9]  [ 510/1229]  eta: 0:03:17  lr: 0.000500  loss: 0.3186 (0.4383)  loss_classifier: 0.1465 (0.1540)  loss_box_reg: 0.0930 (0.1417)  loss_objectness: 0.0749 (0.1044)  loss_rpn_box_reg: 0.0157 (0.0382)  time: 0.2767  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [9]  [ 520/1229]  eta: 0:03:14  lr: 0.000500  loss: 0.4488 (0.4395)  loss_classifier: 0.1495 (0.1541)  loss_box_reg: 0.1192 (0.1420)  loss_objectness: 0.0959 (0.1046)  loss_rpn_box_reg: 0.0239 (0.0388)  time: 0.2752  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [9]  [ 530/1229]  eta: 0:03:11  lr: 0.000500  loss: 0.4865 (0.4403)  loss_classifier: 0.1517 (0.1543)  loss_box_reg: 0.1146 (0.1420)  loss_objectness: 0.1035 (0.1052)  loss_rpn_box_reg: 0.0239 (0.0388)  time: 0.2747  data: 0.1379  max mem: 1751\n",
      "Training Epoch: [9]  [ 540/1229]  eta: 0:03:09  lr: 0.000500  loss: 0.4865 (0.4418)  loss_classifier: 0.1708 (0.1549)  loss_box_reg: 0.1208 (0.1425)  loss_objectness: 0.1033 (0.1051)  loss_rpn_box_reg: 0.0229 (0.0393)  time: 0.2700  data: 0.1385  max mem: 1751\n",
      "Training Epoch: [9]  [ 550/1229]  eta: 0:03:06  lr: 0.000500  loss: 0.4470 (0.4408)  loss_classifier: 0.1509 (0.1547)  loss_box_reg: 0.1362 (0.1423)  loss_objectness: 0.0851 (0.1047)  loss_rpn_box_reg: 0.0190 (0.0391)  time: 0.2765  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [9]  [ 560/1229]  eta: 0:03:03  lr: 0.000500  loss: 0.4550 (0.4420)  loss_classifier: 0.1509 (0.1553)  loss_box_reg: 0.1362 (0.1429)  loss_objectness: 0.0944 (0.1047)  loss_rpn_box_reg: 0.0168 (0.0391)  time: 0.2718  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [9]  [ 570/1229]  eta: 0:03:00  lr: 0.000500  loss: 0.4881 (0.4432)  loss_classifier: 0.1667 (0.1557)  loss_box_reg: 0.1733 (0.1439)  loss_objectness: 0.0944 (0.1048)  loss_rpn_box_reg: 0.0246 (0.0389)  time: 0.2679  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [9]  [ 580/1229]  eta: 0:02:58  lr: 0.000500  loss: 0.4924 (0.4451)  loss_classifier: 0.1667 (0.1564)  loss_box_reg: 0.1332 (0.1444)  loss_objectness: 0.1108 (0.1052)  loss_rpn_box_reg: 0.0246 (0.0391)  time: 0.2801  data: 0.1394  max mem: 1751\n",
      "Training Epoch: [9]  [ 590/1229]  eta: 0:02:55  lr: 0.000500  loss: 0.4486 (0.4460)  loss_classifier: 0.1643 (0.1570)  loss_box_reg: 0.1240 (0.1450)  loss_objectness: 0.1108 (0.1052)  loss_rpn_box_reg: 0.0258 (0.0389)  time: 0.2793  data: 0.1388  max mem: 1751\n",
      "Training Epoch: [9]  [ 600/1229]  eta: 0:02:52  lr: 0.000500  loss: 0.4023 (0.4474)  loss_classifier: 0.1566 (0.1576)  loss_box_reg: 0.1142 (0.1455)  loss_objectness: 0.1055 (0.1057)  loss_rpn_box_reg: 0.0235 (0.0387)  time: 0.2751  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [9]  [ 610/1229]  eta: 0:02:50  lr: 0.000500  loss: 0.4917 (0.4489)  loss_classifier: 0.1807 (0.1581)  loss_box_reg: 0.1418 (0.1463)  loss_objectness: 0.1039 (0.1058)  loss_rpn_box_reg: 0.0213 (0.0386)  time: 0.2821  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [9]  [ 620/1229]  eta: 0:02:47  lr: 0.000500  loss: 0.4627 (0.4487)  loss_classifier: 0.1548 (0.1577)  loss_box_reg: 0.1366 (0.1458)  loss_objectness: 0.0861 (0.1058)  loss_rpn_box_reg: 0.0213 (0.0394)  time: 0.2799  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [9]  [ 630/1229]  eta: 0:02:44  lr: 0.000500  loss: 0.3926 (0.4473)  loss_classifier: 0.1450 (0.1573)  loss_box_reg: 0.1061 (0.1451)  loss_objectness: 0.1009 (0.1056)  loss_rpn_box_reg: 0.0188 (0.0393)  time: 0.2749  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [9]  [ 640/1229]  eta: 0:02:41  lr: 0.000500  loss: 0.3875 (0.4472)  loss_classifier: 0.1473 (0.1574)  loss_box_reg: 0.1021 (0.1448)  loss_objectness: 0.1086 (0.1057)  loss_rpn_box_reg: 0.0316 (0.0394)  time: 0.2826  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [9]  [ 650/1229]  eta: 0:02:39  lr: 0.000500  loss: 0.2803 (0.4445)  loss_classifier: 0.1129 (0.1565)  loss_box_reg: 0.0662 (0.1436)  loss_objectness: 0.0807 (0.1053)  loss_rpn_box_reg: 0.0256 (0.0391)  time: 0.2805  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [9]  [ 660/1229]  eta: 0:02:36  lr: 0.000500  loss: 0.3349 (0.4456)  loss_classifier: 0.1089 (0.1568)  loss_box_reg: 0.0662 (0.1439)  loss_objectness: 0.0915 (0.1055)  loss_rpn_box_reg: 0.0256 (0.0394)  time: 0.2715  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [9]  [ 670/1229]  eta: 0:02:33  lr: 0.000500  loss: 0.3566 (0.4443)  loss_classifier: 0.1058 (0.1562)  loss_box_reg: 0.1141 (0.1433)  loss_objectness: 0.1085 (0.1055)  loss_rpn_box_reg: 0.0324 (0.0393)  time: 0.2705  data: 0.1370  max mem: 1751\n",
      "Training Epoch: [9]  [ 680/1229]  eta: 0:02:30  lr: 0.000500  loss: 0.2849 (0.4439)  loss_classifier: 0.0906 (0.1560)  loss_box_reg: 0.0833 (0.1433)  loss_objectness: 0.0883 (0.1054)  loss_rpn_box_reg: 0.0186 (0.0392)  time: 0.2725  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [9]  [ 690/1229]  eta: 0:02:28  lr: 0.000500  loss: 0.2849 (0.4447)  loss_classifier: 0.1082 (0.1563)  loss_box_reg: 0.0870 (0.1440)  loss_objectness: 0.0949 (0.1053)  loss_rpn_box_reg: 0.0211 (0.0391)  time: 0.2719  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [9]  [ 700/1229]  eta: 0:02:25  lr: 0.000500  loss: 0.3585 (0.4447)  loss_classifier: 0.1310 (0.1562)  loss_box_reg: 0.1251 (0.1439)  loss_objectness: 0.0949 (0.1055)  loss_rpn_box_reg: 0.0207 (0.0391)  time: 0.2736  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [9]  [ 710/1229]  eta: 0:02:22  lr: 0.000500  loss: 0.3950 (0.4436)  loss_classifier: 0.1326 (0.1558)  loss_box_reg: 0.1178 (0.1433)  loss_objectness: 0.0879 (0.1051)  loss_rpn_box_reg: 0.0207 (0.0393)  time: 0.2732  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [9]  [ 720/1229]  eta: 0:02:19  lr: 0.000500  loss: 0.3603 (0.4427)  loss_classifier: 0.1150 (0.1555)  loss_box_reg: 0.0889 (0.1430)  loss_objectness: 0.0879 (0.1050)  loss_rpn_box_reg: 0.0349 (0.0393)  time: 0.2749  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [9]  [ 730/1229]  eta: 0:02:17  lr: 0.000500  loss: 0.3306 (0.4427)  loss_classifier: 0.1152 (0.1553)  loss_box_reg: 0.1157 (0.1429)  loss_objectness: 0.0860 (0.1050)  loss_rpn_box_reg: 0.0331 (0.0395)  time: 0.2745  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [9]  [ 740/1229]  eta: 0:02:14  lr: 0.000500  loss: 0.3306 (0.4413)  loss_classifier: 0.1063 (0.1547)  loss_box_reg: 0.0816 (0.1423)  loss_objectness: 0.0757 (0.1049)  loss_rpn_box_reg: 0.0169 (0.0395)  time: 0.2748  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [9]  [ 750/1229]  eta: 0:02:11  lr: 0.000500  loss: 0.3564 (0.4415)  loss_classifier: 0.1245 (0.1549)  loss_box_reg: 0.0825 (0.1427)  loss_objectness: 0.0790 (0.1046)  loss_rpn_box_reg: 0.0171 (0.0393)  time: 0.2770  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [9]  [ 760/1229]  eta: 0:02:08  lr: 0.000500  loss: 0.4034 (0.4411)  loss_classifier: 0.1536 (0.1549)  loss_box_reg: 0.1326 (0.1426)  loss_objectness: 0.0737 (0.1045)  loss_rpn_box_reg: 0.0175 (0.0392)  time: 0.2742  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [9]  [ 770/1229]  eta: 0:02:06  lr: 0.000500  loss: 0.3554 (0.4405)  loss_classifier: 0.1377 (0.1547)  loss_box_reg: 0.1168 (0.1426)  loss_objectness: 0.0680 (0.1042)  loss_rpn_box_reg: 0.0178 (0.0390)  time: 0.2765  data: 0.1387  max mem: 1751\n",
      "Training Epoch: [9]  [ 780/1229]  eta: 0:02:03  lr: 0.000500  loss: 0.4808 (0.4419)  loss_classifier: 0.1580 (0.1550)  loss_box_reg: 0.1193 (0.1428)  loss_objectness: 0.0872 (0.1048)  loss_rpn_box_reg: 0.0322 (0.0393)  time: 0.2714  data: 0.1382  max mem: 1751\n",
      "Training Epoch: [9]  [ 790/1229]  eta: 0:02:00  lr: 0.000500  loss: 0.5452 (0.4425)  loss_classifier: 0.1633 (0.1553)  loss_box_reg: 0.1193 (0.1429)  loss_objectness: 0.1110 (0.1050)  loss_rpn_box_reg: 0.0301 (0.0393)  time: 0.2705  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [9]  [ 800/1229]  eta: 0:01:57  lr: 0.000500  loss: 0.3869 (0.4434)  loss_classifier: 0.1577 (0.1557)  loss_box_reg: 0.1296 (0.1433)  loss_objectness: 0.1083 (0.1051)  loss_rpn_box_reg: 0.0253 (0.0393)  time: 0.2788  data: 0.1383  max mem: 1751\n",
      "Training Epoch: [9]  [ 810/1229]  eta: 0:01:55  lr: 0.000500  loss: 0.3052 (0.4423)  loss_classifier: 0.1188 (0.1551)  loss_box_reg: 0.0952 (0.1425)  loss_objectness: 0.0923 (0.1054)  loss_rpn_box_reg: 0.0266 (0.0392)  time: 0.2819  data: 0.1378  max mem: 1751\n",
      "Training Epoch: [9]  [ 820/1229]  eta: 0:01:52  lr: 0.000500  loss: 0.2915 (0.4413)  loss_classifier: 0.0949 (0.1549)  loss_box_reg: 0.0782 (0.1423)  loss_objectness: 0.0690 (0.1050)  loss_rpn_box_reg: 0.0183 (0.0392)  time: 0.2853  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [9]  [ 830/1229]  eta: 0:01:49  lr: 0.000500  loss: 0.3327 (0.4416)  loss_classifier: 0.1287 (0.1550)  loss_box_reg: 0.1506 (0.1424)  loss_objectness: 0.0709 (0.1051)  loss_rpn_box_reg: 0.0145 (0.0391)  time: 0.2876  data: 0.1389  max mem: 1751\n",
      "Training Epoch: [9]  [ 840/1229]  eta: 0:01:46  lr: 0.000500  loss: 0.4452 (0.4420)  loss_classifier: 0.1433 (0.1552)  loss_box_reg: 0.1471 (0.1426)  loss_objectness: 0.1113 (0.1052)  loss_rpn_box_reg: 0.0196 (0.0390)  time: 0.2760  data: 0.1390  max mem: 1751\n",
      "Training Epoch: [9]  [ 850/1229]  eta: 0:01:44  lr: 0.000500  loss: 0.3293 (0.4414)  loss_classifier: 0.1281 (0.1550)  loss_box_reg: 0.1022 (0.1426)  loss_objectness: 0.0994 (0.1048)  loss_rpn_box_reg: 0.0188 (0.0390)  time: 0.2808  data: 0.1385  max mem: 1751\n",
      "Training Epoch: [9]  [ 860/1229]  eta: 0:01:41  lr: 0.000500  loss: 0.3486 (0.4406)  loss_classifier: 0.1122 (0.1546)  loss_box_reg: 0.0894 (0.1422)  loss_objectness: 0.0873 (0.1048)  loss_rpn_box_reg: 0.0188 (0.0390)  time: 0.2842  data: 0.1375  max mem: 1751\n",
      "Training Epoch: [9]  [ 870/1229]  eta: 0:01:38  lr: 0.000500  loss: 0.3285 (0.4389)  loss_classifier: 0.1088 (0.1540)  loss_box_reg: 0.0974 (0.1417)  loss_objectness: 0.0831 (0.1044)  loss_rpn_box_reg: 0.0182 (0.0388)  time: 0.2741  data: 0.1367  max mem: 1751\n",
      "Training Epoch: [9]  [ 880/1229]  eta: 0:01:36  lr: 0.000500  loss: 0.2850 (0.4386)  loss_classifier: 0.1002 (0.1539)  loss_box_reg: 0.0974 (0.1416)  loss_objectness: 0.0746 (0.1043)  loss_rpn_box_reg: 0.0179 (0.0388)  time: 0.2756  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [9]  [ 890/1229]  eta: 0:01:33  lr: 0.000500  loss: 0.4197 (0.4395)  loss_classifier: 0.1637 (0.1542)  loss_box_reg: 0.1394 (0.1419)  loss_objectness: 0.0995 (0.1044)  loss_rpn_box_reg: 0.0266 (0.0389)  time: 0.2762  data: 0.1367  max mem: 1751\n",
      "Training Epoch: [9]  [ 900/1229]  eta: 0:01:30  lr: 0.000500  loss: 0.4169 (0.4387)  loss_classifier: 0.1591 (0.1539)  loss_box_reg: 0.1194 (0.1415)  loss_objectness: 0.1075 (0.1045)  loss_rpn_box_reg: 0.0233 (0.0387)  time: 0.2726  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [9]  [ 910/1229]  eta: 0:01:27  lr: 0.000500  loss: 0.4079 (0.4388)  loss_classifier: 0.1320 (0.1541)  loss_box_reg: 0.1240 (0.1418)  loss_objectness: 0.1012 (0.1044)  loss_rpn_box_reg: 0.0222 (0.0386)  time: 0.2711  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [9]  [ 920/1229]  eta: 0:01:25  lr: 0.000500  loss: 0.4631 (0.4399)  loss_classifier: 0.1664 (0.1545)  loss_box_reg: 0.1394 (0.1422)  loss_objectness: 0.0839 (0.1045)  loss_rpn_box_reg: 0.0225 (0.0387)  time: 0.2732  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [9]  [ 930/1229]  eta: 0:01:22  lr: 0.000500  loss: 0.4010 (0.4398)  loss_classifier: 0.1525 (0.1545)  loss_box_reg: 0.1068 (0.1424)  loss_objectness: 0.0824 (0.1043)  loss_rpn_box_reg: 0.0225 (0.0386)  time: 0.2714  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [9]  [ 940/1229]  eta: 0:01:19  lr: 0.000500  loss: 0.3154 (0.4398)  loss_classifier: 0.1035 (0.1545)  loss_box_reg: 0.0981 (0.1423)  loss_objectness: 0.0771 (0.1045)  loss_rpn_box_reg: 0.0317 (0.0385)  time: 0.2709  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [9]  [ 950/1229]  eta: 0:01:16  lr: 0.000500  loss: 0.4766 (0.4406)  loss_classifier: 0.1561 (0.1548)  loss_box_reg: 0.1395 (0.1428)  loss_objectness: 0.0709 (0.1044)  loss_rpn_box_reg: 0.0394 (0.0386)  time: 0.2775  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [9]  [ 960/1229]  eta: 0:01:14  lr: 0.000500  loss: 0.4979 (0.4411)  loss_classifier: 0.1697 (0.1550)  loss_box_reg: 0.1726 (0.1431)  loss_objectness: 0.0787 (0.1045)  loss_rpn_box_reg: 0.0337 (0.0385)  time: 0.2773  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [9]  [ 970/1229]  eta: 0:01:11  lr: 0.000500  loss: 0.4435 (0.4423)  loss_classifier: 0.1697 (0.1555)  loss_box_reg: 0.1710 (0.1438)  loss_objectness: 0.0801 (0.1045)  loss_rpn_box_reg: 0.0308 (0.0385)  time: 0.2727  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [9]  [ 980/1229]  eta: 0:01:08  lr: 0.000500  loss: 0.4026 (0.4422)  loss_classifier: 0.1558 (0.1556)  loss_box_reg: 0.1361 (0.1436)  loss_objectness: 0.0759 (0.1045)  loss_rpn_box_reg: 0.0296 (0.0385)  time: 0.2790  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [9]  [ 990/1229]  eta: 0:01:05  lr: 0.000500  loss: 0.3542 (0.4420)  loss_classifier: 0.1433 (0.1555)  loss_box_reg: 0.1036 (0.1435)  loss_objectness: 0.0884 (0.1046)  loss_rpn_box_reg: 0.0197 (0.0383)  time: 0.2770  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [9]  [1000/1229]  eta: 0:01:03  lr: 0.000500  loss: 0.3542 (0.4421)  loss_classifier: 0.1218 (0.1556)  loss_box_reg: 0.0961 (0.1436)  loss_objectness: 0.0930 (0.1047)  loss_rpn_box_reg: 0.0171 (0.0383)  time: 0.2709  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [9]  [1010/1229]  eta: 0:01:00  lr: 0.000500  loss: 0.2860 (0.4424)  loss_classifier: 0.1159 (0.1557)  loss_box_reg: 0.0768 (0.1435)  loss_objectness: 0.0864 (0.1049)  loss_rpn_box_reg: 0.0189 (0.0382)  time: 0.2739  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [9]  [1020/1229]  eta: 0:00:57  lr: 0.000500  loss: 0.2706 (0.4427)  loss_classifier: 0.0959 (0.1559)  loss_box_reg: 0.0870 (0.1438)  loss_objectness: 0.0864 (0.1049)  loss_rpn_box_reg: 0.0161 (0.0381)  time: 0.2783  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [9]  [1030/1229]  eta: 0:00:54  lr: 0.000500  loss: 0.3678 (0.4425)  loss_classifier: 0.1390 (0.1558)  loss_box_reg: 0.1096 (0.1437)  loss_objectness: 0.0744 (0.1048)  loss_rpn_box_reg: 0.0161 (0.0382)  time: 0.2773  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [9]  [1040/1229]  eta: 0:00:52  lr: 0.000500  loss: 0.4135 (0.4420)  loss_classifier: 0.1482 (0.1557)  loss_box_reg: 0.1096 (0.1434)  loss_objectness: 0.0744 (0.1048)  loss_rpn_box_reg: 0.0192 (0.0381)  time: 0.2744  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [9]  [1050/1229]  eta: 0:00:49  lr: 0.000500  loss: 0.4135 (0.4417)  loss_classifier: 0.1482 (0.1557)  loss_box_reg: 0.1152 (0.1435)  loss_objectness: 0.0873 (0.1047)  loss_rpn_box_reg: 0.0186 (0.0380)  time: 0.2715  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [9]  [1060/1229]  eta: 0:00:46  lr: 0.000500  loss: 0.3530 (0.4405)  loss_classifier: 0.1250 (0.1553)  loss_box_reg: 0.1099 (0.1432)  loss_objectness: 0.0757 (0.1043)  loss_rpn_box_reg: 0.0132 (0.0377)  time: 0.2725  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [9]  [1070/1229]  eta: 0:00:43  lr: 0.000500  loss: 0.3530 (0.4403)  loss_classifier: 0.1180 (0.1552)  loss_box_reg: 0.0963 (0.1432)  loss_objectness: 0.0685 (0.1041)  loss_rpn_box_reg: 0.0141 (0.0377)  time: 0.2786  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [9]  [1080/1229]  eta: 0:00:40  lr: 0.000500  loss: 0.4733 (0.4403)  loss_classifier: 0.1453 (0.1552)  loss_box_reg: 0.1628 (0.1435)  loss_objectness: 0.0750 (0.1039)  loss_rpn_box_reg: 0.0240 (0.0377)  time: 0.2757  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [9]  [1090/1229]  eta: 0:00:38  lr: 0.000500  loss: 0.4257 (0.4412)  loss_classifier: 0.1486 (0.1554)  loss_box_reg: 0.1759 (0.1441)  loss_objectness: 0.0750 (0.1038)  loss_rpn_box_reg: 0.0240 (0.0378)  time: 0.2728  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [9]  [1100/1229]  eta: 0:00:35  lr: 0.000500  loss: 0.3705 (0.4416)  loss_classifier: 0.1461 (0.1556)  loss_box_reg: 0.1333 (0.1442)  loss_objectness: 0.0918 (0.1038)  loss_rpn_box_reg: 0.0157 (0.0380)  time: 0.2762  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [9]  [1110/1229]  eta: 0:00:32  lr: 0.000500  loss: 0.3400 (0.4422)  loss_classifier: 0.1252 (0.1558)  loss_box_reg: 0.1163 (0.1444)  loss_objectness: 0.0965 (0.1039)  loss_rpn_box_reg: 0.0223 (0.0381)  time: 0.2732  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [9]  [1120/1229]  eta: 0:00:29  lr: 0.000500  loss: 0.3784 (0.4428)  loss_classifier: 0.1649 (0.1559)  loss_box_reg: 0.1184 (0.1446)  loss_objectness: 0.1064 (0.1041)  loss_rpn_box_reg: 0.0296 (0.0383)  time: 0.2709  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [9]  [1130/1229]  eta: 0:00:27  lr: 0.000500  loss: 0.4597 (0.4434)  loss_classifier: 0.1649 (0.1560)  loss_box_reg: 0.1133 (0.1446)  loss_objectness: 0.1116 (0.1044)  loss_rpn_box_reg: 0.0292 (0.0384)  time: 0.2788  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [9]  [1140/1229]  eta: 0:00:24  lr: 0.000500  loss: 0.4597 (0.4436)  loss_classifier: 0.1577 (0.1561)  loss_box_reg: 0.1143 (0.1446)  loss_objectness: 0.1211 (0.1045)  loss_rpn_box_reg: 0.0219 (0.0383)  time: 0.2784  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [9]  [1150/1229]  eta: 0:00:21  lr: 0.000500  loss: 0.4611 (0.4442)  loss_classifier: 0.1643 (0.1563)  loss_box_reg: 0.1447 (0.1451)  loss_objectness: 0.0950 (0.1044)  loss_rpn_box_reg: 0.0158 (0.0384)  time: 0.2740  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [9]  [1160/1229]  eta: 0:00:18  lr: 0.000500  loss: 0.3308 (0.4431)  loss_classifier: 0.1112 (0.1560)  loss_box_reg: 0.1362 (0.1448)  loss_objectness: 0.0761 (0.1041)  loss_rpn_box_reg: 0.0158 (0.0382)  time: 0.2739  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [9]  [1170/1229]  eta: 0:00:16  lr: 0.000500  loss: 0.3472 (0.4429)  loss_classifier: 0.1193 (0.1559)  loss_box_reg: 0.1298 (0.1447)  loss_objectness: 0.0761 (0.1042)  loss_rpn_box_reg: 0.0174 (0.0381)  time: 0.2737  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [9]  [1180/1229]  eta: 0:00:13  lr: 0.000500  loss: 0.4111 (0.4437)  loss_classifier: 0.1609 (0.1561)  loss_box_reg: 0.1481 (0.1450)  loss_objectness: 0.1083 (0.1044)  loss_rpn_box_reg: 0.0244 (0.0382)  time: 0.2734  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [9]  [1190/1229]  eta: 0:00:10  lr: 0.000500  loss: 0.3018 (0.4433)  loss_classifier: 0.1164 (0.1559)  loss_box_reg: 0.1046 (0.1449)  loss_objectness: 0.0967 (0.1043)  loss_rpn_box_reg: 0.0249 (0.0382)  time: 0.2739  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [9]  [1200/1229]  eta: 0:00:07  lr: 0.000500  loss: 0.4217 (0.4444)  loss_classifier: 0.1346 (0.1563)  loss_box_reg: 0.1422 (0.1452)  loss_objectness: 0.0789 (0.1045)  loss_rpn_box_reg: 0.0286 (0.0384)  time: 0.2733  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [9]  [1210/1229]  eta: 0:00:05  lr: 0.000500  loss: 0.4741 (0.4452)  loss_classifier: 0.1844 (0.1566)  loss_box_reg: 0.1494 (0.1457)  loss_objectness: 0.0915 (0.1046)  loss_rpn_box_reg: 0.0303 (0.0383)  time: 0.2698  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [9]  [1220/1229]  eta: 0:00:02  lr: 0.000500  loss: 0.3848 (0.4444)  loss_classifier: 0.1377 (0.1563)  loss_box_reg: 0.1421 (0.1454)  loss_objectness: 0.0867 (0.1044)  loss_rpn_box_reg: 0.0256 (0.0382)  time: 0.2685  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [9]  [1228/1229]  eta: 0:00:00  lr: 0.000500  loss: 0.3901 (0.4450)  loss_classifier: 0.1488 (0.1566)  loss_box_reg: 0.1317 (0.1457)  loss_objectness: 0.0867 (0.1045)  loss_rpn_box_reg: 0.0262 (0.0382)  time: 0.2691  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [9] Total time: 0:05:37 (0.2750 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:21  model_time: 0.2300 (0.2300)  evaluator_time: 0.0020 (0.0020)  time: 0.2640  data: 0.0300  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0800 (0.0806)  evaluator_time: 0.0050 (0.0084)  time: 0.1257  data: 0.0354  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0820 (0.0797)  evaluator_time: 0.0030 (0.0077)  time: 0.1190  data: 0.0304  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0740 (0.0790)  evaluator_time: 0.0040 (0.0075)  time: 0.1183  data: 0.0349  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0720 (0.0788)  evaluator_time: 0.0030 (0.0075)  time: 0.1202  data: 0.0386  max mem: 1751\n",
      "Test: Total time: 0:00:37 (0.1226 s / it)\n",
      "Averaged stats: model_time: 0.0720 (0.0788)  evaluator_time: 0.0030 (0.0075)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.122\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.300\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.121\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
      "Testing Epoch: [9]  [  0/308]  eta: 0:00:38  lr: 0.000500  loss: 0.1887 (0.1887)  loss_classifier: 0.0723 (0.0723)  loss_box_reg: 0.0770 (0.0770)  loss_objectness: 0.0273 (0.0273)  loss_rpn_box_reg: 0.0120 (0.0120)  time: 0.1240  data: 0.0290  max mem: 1751\n",
      "Testing Epoch: [9]  [100/308]  eta: 0:00:28  lr: 0.000500  loss: 0.3310 (0.4875)  loss_classifier: 0.1306 (0.1597)  loss_box_reg: 0.1066 (0.1750)  loss_objectness: 0.0649 (0.1004)  loss_rpn_box_reg: 0.0189 (0.0524)  time: 0.1396  data: 0.0377  max mem: 1751\n",
      "Testing Epoch: [9]  [200/308]  eta: 0:00:14  lr: 0.000500  loss: 0.3719 (0.4649)  loss_classifier: 0.1486 (0.1537)  loss_box_reg: 0.1383 (0.1663)  loss_objectness: 0.0715 (0.0952)  loss_rpn_box_reg: 0.0208 (0.0498)  time: 0.1373  data: 0.0326  max mem: 1751\n",
      "Testing Epoch: [9]  [300/308]  eta: 0:00:01  lr: 0.000500  loss: 0.4755 (0.4625)  loss_classifier: 0.1686 (0.1538)  loss_box_reg: 0.1782 (0.1674)  loss_objectness: 0.0778 (0.0930)  loss_rpn_box_reg: 0.0263 (0.0483)  time: 0.1334  data: 0.0383  max mem: 1751\n",
      "Testing Epoch: [9]  [307/308]  eta: 0:00:00  lr: 0.000500  loss: 0.4613 (0.4624)  loss_classifier: 0.1765 (0.1540)  loss_box_reg: 0.1774 (0.1676)  loss_objectness: 0.0752 (0.0930)  loss_rpn_box_reg: 0.0280 (0.0478)  time: 0.1304  data: 0.0358  max mem: 1751\n",
      "Testing Epoch: [9] Total time: 0:00:42 (0.1367 s / it)\n",
      "Training Epoch: [10]  [   0/1229]  eta: 0:05:39  lr: 0.000500  loss: 0.3579 (0.3579)  loss_classifier: 0.1344 (0.1344)  loss_box_reg: 0.1736 (0.1736)  loss_objectness: 0.0367 (0.0367)  loss_rpn_box_reg: 0.0130 (0.0130)  time: 0.2760  data: 0.1220  max mem: 1751\n",
      "Training Epoch: [10]  [  10/1229]  eta: 0:05:28  lr: 0.000500  loss: 0.3680 (0.3665)  loss_classifier: 0.1212 (0.1276)  loss_box_reg: 0.0844 (0.1194)  loss_objectness: 0.0839 (0.0827)  loss_rpn_box_reg: 0.0190 (0.0368)  time: 0.2693  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [10]  [  20/1229]  eta: 0:05:34  lr: 0.000500  loss: 0.3680 (0.3723)  loss_classifier: 0.0986 (0.1307)  loss_box_reg: 0.0844 (0.1255)  loss_objectness: 0.0820 (0.0830)  loss_rpn_box_reg: 0.0190 (0.0330)  time: 0.2767  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [10]  [  30/1229]  eta: 0:05:29  lr: 0.000500  loss: 0.3717 (0.3878)  loss_classifier: 0.1390 (0.1352)  loss_box_reg: 0.1050 (0.1297)  loss_objectness: 0.0738 (0.0868)  loss_rpn_box_reg: 0.0225 (0.0361)  time: 0.2780  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [10]  [  40/1229]  eta: 0:05:27  lr: 0.000500  loss: 0.3074 (0.3906)  loss_classifier: 0.1148 (0.1395)  loss_box_reg: 0.0837 (0.1297)  loss_objectness: 0.0738 (0.0900)  loss_rpn_box_reg: 0.0200 (0.0315)  time: 0.2745  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [10]  [  50/1229]  eta: 0:05:25  lr: 0.000500  loss: 0.2776 (0.3870)  loss_classifier: 0.1040 (0.1371)  loss_box_reg: 0.0837 (0.1277)  loss_objectness: 0.0833 (0.0886)  loss_rpn_box_reg: 0.0139 (0.0335)  time: 0.2778  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [10]  [  60/1229]  eta: 0:05:22  lr: 0.000500  loss: 0.3076 (0.3970)  loss_classifier: 0.1148 (0.1414)  loss_box_reg: 0.0947 (0.1338)  loss_objectness: 0.0876 (0.0889)  loss_rpn_box_reg: 0.0196 (0.0329)  time: 0.2758  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [10]  [  70/1229]  eta: 0:05:19  lr: 0.000500  loss: 0.3750 (0.4036)  loss_classifier: 0.1423 (0.1451)  loss_box_reg: 0.1100 (0.1363)  loss_objectness: 0.1049 (0.0907)  loss_rpn_box_reg: 0.0162 (0.0315)  time: 0.2758  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [10]  [  80/1229]  eta: 0:05:16  lr: 0.000500  loss: 0.3473 (0.4032)  loss_classifier: 0.1318 (0.1443)  loss_box_reg: 0.1232 (0.1345)  loss_objectness: 0.0964 (0.0925)  loss_rpn_box_reg: 0.0159 (0.0319)  time: 0.2748  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [10]  [  90/1229]  eta: 0:05:14  lr: 0.000500  loss: 0.4228 (0.4115)  loss_classifier: 0.1307 (0.1466)  loss_box_reg: 0.1323 (0.1356)  loss_objectness: 0.0898 (0.0945)  loss_rpn_box_reg: 0.0338 (0.0348)  time: 0.2748  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [10]  [ 100/1229]  eta: 0:05:10  lr: 0.000500  loss: 0.4829 (0.4225)  loss_classifier: 0.1519 (0.1499)  loss_box_reg: 0.1605 (0.1423)  loss_objectness: 0.0898 (0.0952)  loss_rpn_box_reg: 0.0337 (0.0351)  time: 0.2743  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [10]  [ 110/1229]  eta: 0:05:07  lr: 0.000500  loss: 0.3766 (0.4173)  loss_classifier: 0.1304 (0.1491)  loss_box_reg: 0.1247 (0.1399)  loss_objectness: 0.0803 (0.0942)  loss_rpn_box_reg: 0.0243 (0.0341)  time: 0.2706  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [10]  [ 120/1229]  eta: 0:05:04  lr: 0.000500  loss: 0.4011 (0.4286)  loss_classifier: 0.1639 (0.1527)  loss_box_reg: 0.1247 (0.1448)  loss_objectness: 0.0864 (0.0974)  loss_rpn_box_reg: 0.0208 (0.0337)  time: 0.2701  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [10]  [ 130/1229]  eta: 0:05:02  lr: 0.000500  loss: 0.4609 (0.4281)  loss_classifier: 0.1759 (0.1531)  loss_box_reg: 0.1472 (0.1451)  loss_objectness: 0.0864 (0.0970)  loss_rpn_box_reg: 0.0237 (0.0329)  time: 0.2757  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [10]  [ 140/1229]  eta: 0:04:59  lr: 0.000500  loss: 0.3858 (0.4303)  loss_classifier: 0.1451 (0.1534)  loss_box_reg: 0.0891 (0.1454)  loss_objectness: 0.0757 (0.0977)  loss_rpn_box_reg: 0.0240 (0.0339)  time: 0.2763  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [10]  [ 150/1229]  eta: 0:04:55  lr: 0.000500  loss: 0.3437 (0.4276)  loss_classifier: 0.1130 (0.1517)  loss_box_reg: 0.0895 (0.1437)  loss_objectness: 0.0802 (0.0989)  loss_rpn_box_reg: 0.0229 (0.0332)  time: 0.2673  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [10]  [ 160/1229]  eta: 0:04:53  lr: 0.000500  loss: 0.3786 (0.4306)  loss_classifier: 0.1318 (0.1529)  loss_box_reg: 0.1065 (0.1456)  loss_objectness: 0.0766 (0.0985)  loss_rpn_box_reg: 0.0198 (0.0336)  time: 0.2760  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [10]  [ 170/1229]  eta: 0:04:51  lr: 0.000500  loss: 0.4929 (0.4388)  loss_classifier: 0.1642 (0.1550)  loss_box_reg: 0.1448 (0.1466)  loss_objectness: 0.0778 (0.1011)  loss_rpn_box_reg: 0.0290 (0.0361)  time: 0.2834  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [10]  [ 180/1229]  eta: 0:04:48  lr: 0.000500  loss: 0.5555 (0.4415)  loss_classifier: 0.1642 (0.1553)  loss_box_reg: 0.1667 (0.1482)  loss_objectness: 0.1187 (0.1016)  loss_rpn_box_reg: 0.0326 (0.0363)  time: 0.2739  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [10]  [ 190/1229]  eta: 0:04:45  lr: 0.000500  loss: 0.5668 (0.4479)  loss_classifier: 0.1985 (0.1573)  loss_box_reg: 0.1707 (0.1502)  loss_objectness: 0.1180 (0.1036)  loss_rpn_box_reg: 0.0273 (0.0368)  time: 0.2688  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [10]  [ 200/1229]  eta: 0:04:41  lr: 0.000500  loss: 0.5530 (0.4506)  loss_classifier: 0.1886 (0.1581)  loss_box_reg: 0.1707 (0.1517)  loss_objectness: 0.1188 (0.1043)  loss_rpn_box_reg: 0.0307 (0.0366)  time: 0.2678  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [10]  [ 210/1229]  eta: 0:04:38  lr: 0.000500  loss: 0.4599 (0.4531)  loss_classifier: 0.1573 (0.1589)  loss_box_reg: 0.1561 (0.1526)  loss_objectness: 0.1041 (0.1050)  loss_rpn_box_reg: 0.0301 (0.0366)  time: 0.2680  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [10]  [ 220/1229]  eta: 0:04:36  lr: 0.000500  loss: 0.3411 (0.4505)  loss_classifier: 0.1149 (0.1581)  loss_box_reg: 0.1182 (0.1521)  loss_objectness: 0.0816 (0.1042)  loss_rpn_box_reg: 0.0199 (0.0360)  time: 0.2731  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [10]  [ 230/1229]  eta: 0:04:33  lr: 0.000500  loss: 0.3071 (0.4459)  loss_classifier: 0.1041 (0.1564)  loss_box_reg: 0.0959 (0.1502)  loss_objectness: 0.0821 (0.1036)  loss_rpn_box_reg: 0.0198 (0.0358)  time: 0.2761  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [10]  [ 240/1229]  eta: 0:04:30  lr: 0.000500  loss: 0.3366 (0.4458)  loss_classifier: 0.1274 (0.1566)  loss_box_reg: 0.0959 (0.1491)  loss_objectness: 0.0887 (0.1048)  loss_rpn_box_reg: 0.0179 (0.0353)  time: 0.2727  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [10]  [ 250/1229]  eta: 0:04:27  lr: 0.000500  loss: 0.3798 (0.4512)  loss_classifier: 0.1575 (0.1588)  loss_box_reg: 0.1086 (0.1504)  loss_objectness: 0.1068 (0.1064)  loss_rpn_box_reg: 0.0205 (0.0356)  time: 0.2706  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [10]  [ 260/1229]  eta: 0:04:25  lr: 0.000500  loss: 0.3778 (0.4507)  loss_classifier: 0.1589 (0.1585)  loss_box_reg: 0.1169 (0.1502)  loss_objectness: 0.0994 (0.1055)  loss_rpn_box_reg: 0.0163 (0.0366)  time: 0.2712  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [10]  [ 270/1229]  eta: 0:04:22  lr: 0.000500  loss: 0.3621 (0.4519)  loss_classifier: 0.1233 (0.1587)  loss_box_reg: 0.0995 (0.1498)  loss_objectness: 0.0971 (0.1066)  loss_rpn_box_reg: 0.0284 (0.0367)  time: 0.2713  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [10]  [ 280/1229]  eta: 0:04:19  lr: 0.000500  loss: 0.4320 (0.4531)  loss_classifier: 0.1495 (0.1590)  loss_box_reg: 0.1161 (0.1500)  loss_objectness: 0.1297 (0.1070)  loss_rpn_box_reg: 0.0249 (0.0371)  time: 0.2687  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [10]  [ 290/1229]  eta: 0:04:16  lr: 0.000500  loss: 0.4527 (0.4538)  loss_classifier: 0.1667 (0.1591)  loss_box_reg: 0.1510 (0.1501)  loss_objectness: 0.1247 (0.1074)  loss_rpn_box_reg: 0.0229 (0.0372)  time: 0.2753  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [10]  [ 300/1229]  eta: 0:04:14  lr: 0.000500  loss: 0.4590 (0.4568)  loss_classifier: 0.1689 (0.1598)  loss_box_reg: 0.1510 (0.1509)  loss_objectness: 0.1051 (0.1080)  loss_rpn_box_reg: 0.0282 (0.0382)  time: 0.2822  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [10]  [ 310/1229]  eta: 0:04:11  lr: 0.000500  loss: 0.4142 (0.4587)  loss_classifier: 0.1594 (0.1605)  loss_box_reg: 0.1272 (0.1513)  loss_objectness: 0.1011 (0.1091)  loss_rpn_box_reg: 0.0259 (0.0378)  time: 0.2741  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [10]  [ 320/1229]  eta: 0:04:08  lr: 0.000500  loss: 0.4142 (0.4579)  loss_classifier: 0.1543 (0.1604)  loss_box_reg: 0.1223 (0.1509)  loss_objectness: 0.1128 (0.1089)  loss_rpn_box_reg: 0.0204 (0.0377)  time: 0.2680  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [10]  [ 330/1229]  eta: 0:04:05  lr: 0.000500  loss: 0.3997 (0.4547)  loss_classifier: 0.1428 (0.1595)  loss_box_reg: 0.1188 (0.1497)  loss_objectness: 0.0803 (0.1083)  loss_rpn_box_reg: 0.0189 (0.0372)  time: 0.2689  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [10]  [ 340/1229]  eta: 0:04:02  lr: 0.000500  loss: 0.3141 (0.4522)  loss_classifier: 0.1088 (0.1586)  loss_box_reg: 0.1065 (0.1493)  loss_objectness: 0.0768 (0.1072)  loss_rpn_box_reg: 0.0161 (0.0371)  time: 0.2650  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [10]  [ 350/1229]  eta: 0:04:00  lr: 0.000500  loss: 0.3625 (0.4527)  loss_classifier: 0.1213 (0.1592)  loss_box_reg: 0.1256 (0.1495)  loss_objectness: 0.0831 (0.1071)  loss_rpn_box_reg: 0.0161 (0.0369)  time: 0.2685  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [10]  [ 360/1229]  eta: 0:03:57  lr: 0.000500  loss: 0.4376 (0.4541)  loss_classifier: 0.1772 (0.1602)  loss_box_reg: 0.1785 (0.1501)  loss_objectness: 0.1047 (0.1072)  loss_rpn_box_reg: 0.0195 (0.0367)  time: 0.2734  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [10]  [ 370/1229]  eta: 0:03:54  lr: 0.000500  loss: 0.4121 (0.4539)  loss_classifier: 0.1482 (0.1603)  loss_box_reg: 0.1539 (0.1505)  loss_objectness: 0.0917 (0.1066)  loss_rpn_box_reg: 0.0185 (0.0365)  time: 0.2754  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [10]  [ 380/1229]  eta: 0:03:51  lr: 0.000500  loss: 0.3588 (0.4538)  loss_classifier: 0.1339 (0.1601)  loss_box_reg: 0.1198 (0.1500)  loss_objectness: 0.0828 (0.1067)  loss_rpn_box_reg: 0.0280 (0.0369)  time: 0.2747  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [10]  [ 390/1229]  eta: 0:03:49  lr: 0.000500  loss: 0.4003 (0.4514)  loss_classifier: 0.1278 (0.1592)  loss_box_reg: 0.1127 (0.1497)  loss_objectness: 0.0813 (0.1059)  loss_rpn_box_reg: 0.0271 (0.0366)  time: 0.2726  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [10]  [ 400/1229]  eta: 0:03:46  lr: 0.000500  loss: 0.3569 (0.4504)  loss_classifier: 0.1315 (0.1590)  loss_box_reg: 0.1318 (0.1501)  loss_objectness: 0.0527 (0.1053)  loss_rpn_box_reg: 0.0126 (0.0361)  time: 0.2799  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [10]  [ 410/1229]  eta: 0:03:43  lr: 0.000500  loss: 0.3604 (0.4488)  loss_classifier: 0.1353 (0.1586)  loss_box_reg: 0.1122 (0.1492)  loss_objectness: 0.0716 (0.1053)  loss_rpn_box_reg: 0.0131 (0.0358)  time: 0.2752  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [10]  [ 420/1229]  eta: 0:03:41  lr: 0.000500  loss: 0.3776 (0.4494)  loss_classifier: 0.1353 (0.1588)  loss_box_reg: 0.1122 (0.1494)  loss_objectness: 0.0993 (0.1056)  loss_rpn_box_reg: 0.0198 (0.0356)  time: 0.2716  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [10]  [ 430/1229]  eta: 0:03:38  lr: 0.000500  loss: 0.4067 (0.4497)  loss_classifier: 0.1411 (0.1589)  loss_box_reg: 0.1127 (0.1491)  loss_objectness: 0.1135 (0.1059)  loss_rpn_box_reg: 0.0238 (0.0357)  time: 0.2772  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [10]  [ 440/1229]  eta: 0:03:35  lr: 0.000500  loss: 0.3811 (0.4473)  loss_classifier: 0.1271 (0.1580)  loss_box_reg: 0.1063 (0.1479)  loss_objectness: 0.0942 (0.1057)  loss_rpn_box_reg: 0.0169 (0.0356)  time: 0.2728  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [10]  [ 450/1229]  eta: 0:03:32  lr: 0.000500  loss: 0.4135 (0.4513)  loss_classifier: 0.1332 (0.1593)  loss_box_reg: 0.1396 (0.1497)  loss_objectness: 0.1005 (0.1063)  loss_rpn_box_reg: 0.0233 (0.0361)  time: 0.2712  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [10]  [ 460/1229]  eta: 0:03:30  lr: 0.000500  loss: 0.5144 (0.4534)  loss_classifier: 0.1741 (0.1599)  loss_box_reg: 0.1744 (0.1509)  loss_objectness: 0.1005 (0.1063)  loss_rpn_box_reg: 0.0343 (0.0362)  time: 0.2732  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [10]  [ 470/1229]  eta: 0:03:27  lr: 0.000500  loss: 0.4109 (0.4530)  loss_classifier: 0.1506 (0.1600)  loss_box_reg: 0.1292 (0.1509)  loss_objectness: 0.0795 (0.1062)  loss_rpn_box_reg: 0.0186 (0.0359)  time: 0.2752  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [10]  [ 480/1229]  eta: 0:03:24  lr: 0.000500  loss: 0.4318 (0.4541)  loss_classifier: 0.1600 (0.1604)  loss_box_reg: 0.1274 (0.1518)  loss_objectness: 0.0743 (0.1057)  loss_rpn_box_reg: 0.0186 (0.0363)  time: 0.2808  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [10]  [ 490/1229]  eta: 0:03:22  lr: 0.000500  loss: 0.3762 (0.4532)  loss_classifier: 0.1331 (0.1600)  loss_box_reg: 0.1110 (0.1515)  loss_objectness: 0.0870 (0.1055)  loss_rpn_box_reg: 0.0209 (0.0362)  time: 0.2729  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [10]  [ 500/1229]  eta: 0:03:19  lr: 0.000500  loss: 0.3734 (0.4526)  loss_classifier: 0.1311 (0.1601)  loss_box_reg: 0.1083 (0.1511)  loss_objectness: 0.0870 (0.1053)  loss_rpn_box_reg: 0.0199 (0.0361)  time: 0.2683  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [10]  [ 510/1229]  eta: 0:03:16  lr: 0.000500  loss: 0.3138 (0.4502)  loss_classifier: 0.1136 (0.1593)  loss_box_reg: 0.0934 (0.1504)  loss_objectness: 0.0743 (0.1046)  loss_rpn_box_reg: 0.0175 (0.0359)  time: 0.2738  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [10]  [ 520/1229]  eta: 0:03:13  lr: 0.000500  loss: 0.2887 (0.4488)  loss_classifier: 0.1133 (0.1591)  loss_box_reg: 0.1096 (0.1502)  loss_objectness: 0.0504 (0.1038)  loss_rpn_box_reg: 0.0175 (0.0357)  time: 0.2763  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [10]  [ 530/1229]  eta: 0:03:11  lr: 0.000500  loss: 0.3381 (0.4488)  loss_classifier: 0.1271 (0.1592)  loss_box_reg: 0.1241 (0.1503)  loss_objectness: 0.0517 (0.1035)  loss_rpn_box_reg: 0.0185 (0.0358)  time: 0.2726  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [10]  [ 540/1229]  eta: 0:03:08  lr: 0.000500  loss: 0.4075 (0.4492)  loss_classifier: 0.1461 (0.1593)  loss_box_reg: 0.1403 (0.1506)  loss_objectness: 0.0811 (0.1032)  loss_rpn_box_reg: 0.0263 (0.0361)  time: 0.2712  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [10]  [ 550/1229]  eta: 0:03:05  lr: 0.000500  loss: 0.5021 (0.4501)  loss_classifier: 0.1890 (0.1596)  loss_box_reg: 0.1826 (0.1512)  loss_objectness: 0.0926 (0.1032)  loss_rpn_box_reg: 0.0263 (0.0362)  time: 0.2756  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [10]  [ 560/1229]  eta: 0:03:03  lr: 0.000500  loss: 0.4941 (0.4510)  loss_classifier: 0.1888 (0.1599)  loss_box_reg: 0.1677 (0.1510)  loss_objectness: 0.1076 (0.1034)  loss_rpn_box_reg: 0.0289 (0.0367)  time: 0.2790  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [10]  [ 570/1229]  eta: 0:03:00  lr: 0.000500  loss: 0.4564 (0.4522)  loss_classifier: 0.1471 (0.1602)  loss_box_reg: 0.1213 (0.1517)  loss_objectness: 0.0968 (0.1034)  loss_rpn_box_reg: 0.0289 (0.0370)  time: 0.2803  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [10]  [ 580/1229]  eta: 0:02:57  lr: 0.000500  loss: 0.4486 (0.4527)  loss_classifier: 0.1423 (0.1602)  loss_box_reg: 0.1216 (0.1518)  loss_objectness: 0.0968 (0.1034)  loss_rpn_box_reg: 0.0281 (0.0373)  time: 0.2746  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [10]  [ 590/1229]  eta: 0:02:54  lr: 0.000500  loss: 0.4486 (0.4533)  loss_classifier: 0.1221 (0.1604)  loss_box_reg: 0.1225 (0.1520)  loss_objectness: 0.1100 (0.1038)  loss_rpn_box_reg: 0.0264 (0.0371)  time: 0.2730  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [10]  [ 600/1229]  eta: 0:02:52  lr: 0.000500  loss: 0.3465 (0.4523)  loss_classifier: 0.1144 (0.1600)  loss_box_reg: 0.1218 (0.1513)  loss_objectness: 0.0884 (0.1039)  loss_rpn_box_reg: 0.0182 (0.0371)  time: 0.2797  data: 0.1391  max mem: 1751\n",
      "Training Epoch: [10]  [ 610/1229]  eta: 0:02:49  lr: 0.000500  loss: 0.3465 (0.4537)  loss_classifier: 0.1541 (0.1606)  loss_box_reg: 0.1218 (0.1522)  loss_objectness: 0.0923 (0.1039)  loss_rpn_box_reg: 0.0197 (0.0369)  time: 0.2836  data: 0.1442  max mem: 1751\n",
      "Training Epoch: [10]  [ 620/1229]  eta: 0:02:46  lr: 0.000500  loss: 0.4622 (0.4548)  loss_classifier: 0.1799 (0.1610)  loss_box_reg: 0.1749 (0.1529)  loss_objectness: 0.1004 (0.1041)  loss_rpn_box_reg: 0.0204 (0.0368)  time: 0.2811  data: 0.1415  max mem: 1751\n",
      "Training Epoch: [10]  [ 630/1229]  eta: 0:02:44  lr: 0.000500  loss: 0.4397 (0.4558)  loss_classifier: 0.1449 (0.1610)  loss_box_reg: 0.1324 (0.1532)  loss_objectness: 0.1076 (0.1043)  loss_rpn_box_reg: 0.0215 (0.0374)  time: 0.2754  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [10]  [ 640/1229]  eta: 0:02:41  lr: 0.000500  loss: 0.4107 (0.4546)  loss_classifier: 0.1448 (0.1607)  loss_box_reg: 0.1222 (0.1527)  loss_objectness: 0.0773 (0.1041)  loss_rpn_box_reg: 0.0240 (0.0371)  time: 0.2708  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [10]  [ 650/1229]  eta: 0:02:38  lr: 0.000500  loss: 0.3897 (0.4549)  loss_classifier: 0.1377 (0.1608)  loss_box_reg: 0.0936 (0.1527)  loss_objectness: 0.0775 (0.1040)  loss_rpn_box_reg: 0.0193 (0.0374)  time: 0.2698  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [10]  [ 660/1229]  eta: 0:02:35  lr: 0.000500  loss: 0.3897 (0.4530)  loss_classifier: 0.1365 (0.1603)  loss_box_reg: 0.0991 (0.1520)  loss_objectness: 0.0833 (0.1036)  loss_rpn_box_reg: 0.0204 (0.0372)  time: 0.2696  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [10]  [ 670/1229]  eta: 0:02:33  lr: 0.000500  loss: 0.3294 (0.4534)  loss_classifier: 0.1183 (0.1603)  loss_box_reg: 0.0909 (0.1517)  loss_objectness: 0.0823 (0.1038)  loss_rpn_box_reg: 0.0250 (0.0376)  time: 0.2714  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [10]  [ 680/1229]  eta: 0:02:30  lr: 0.000500  loss: 0.3652 (0.4530)  loss_classifier: 0.1481 (0.1602)  loss_box_reg: 0.1047 (0.1515)  loss_objectness: 0.0902 (0.1038)  loss_rpn_box_reg: 0.0301 (0.0375)  time: 0.2727  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [10]  [ 690/1229]  eta: 0:02:27  lr: 0.000500  loss: 0.3652 (0.4519)  loss_classifier: 0.1135 (0.1599)  loss_box_reg: 0.1047 (0.1511)  loss_objectness: 0.0878 (0.1036)  loss_rpn_box_reg: 0.0264 (0.0373)  time: 0.2733  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [10]  [ 700/1229]  eta: 0:02:24  lr: 0.000500  loss: 0.4498 (0.4540)  loss_classifier: 0.1770 (0.1605)  loss_box_reg: 0.1246 (0.1518)  loss_objectness: 0.1007 (0.1041)  loss_rpn_box_reg: 0.0309 (0.0377)  time: 0.2730  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [10]  [ 710/1229]  eta: 0:02:22  lr: 0.000500  loss: 0.4036 (0.4518)  loss_classifier: 0.1498 (0.1599)  loss_box_reg: 0.1196 (0.1510)  loss_objectness: 0.0846 (0.1035)  loss_rpn_box_reg: 0.0185 (0.0374)  time: 0.2745  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [10]  [ 720/1229]  eta: 0:02:19  lr: 0.000500  loss: 0.3305 (0.4516)  loss_classifier: 0.1447 (0.1599)  loss_box_reg: 0.0972 (0.1510)  loss_objectness: 0.0846 (0.1036)  loss_rpn_box_reg: 0.0145 (0.0372)  time: 0.2727  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [10]  [ 730/1229]  eta: 0:02:16  lr: 0.000500  loss: 0.4450 (0.4520)  loss_classifier: 0.1735 (0.1602)  loss_box_reg: 0.1505 (0.1514)  loss_objectness: 0.0927 (0.1034)  loss_rpn_box_reg: 0.0236 (0.0370)  time: 0.2787  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [10]  [ 740/1229]  eta: 0:02:13  lr: 0.000500  loss: 0.3781 (0.4516)  loss_classifier: 0.1492 (0.1602)  loss_box_reg: 0.1179 (0.1513)  loss_objectness: 0.0894 (0.1032)  loss_rpn_box_reg: 0.0236 (0.0369)  time: 0.2803  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [10]  [ 750/1229]  eta: 0:02:11  lr: 0.000500  loss: 0.3602 (0.4516)  loss_classifier: 0.1572 (0.1604)  loss_box_reg: 0.1179 (0.1514)  loss_objectness: 0.0853 (0.1030)  loss_rpn_box_reg: 0.0237 (0.0368)  time: 0.2705  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [10]  [ 760/1229]  eta: 0:02:08  lr: 0.000500  loss: 0.4468 (0.4516)  loss_classifier: 0.1550 (0.1603)  loss_box_reg: 0.1700 (0.1514)  loss_objectness: 0.0853 (0.1029)  loss_rpn_box_reg: 0.0301 (0.0370)  time: 0.2682  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [10]  [ 770/1229]  eta: 0:02:05  lr: 0.000500  loss: 0.3216 (0.4503)  loss_classifier: 0.1180 (0.1598)  loss_box_reg: 0.1102 (0.1509)  loss_objectness: 0.0824 (0.1028)  loss_rpn_box_reg: 0.0189 (0.0368)  time: 0.2674  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [10]  [ 780/1229]  eta: 0:02:02  lr: 0.000500  loss: 0.3085 (0.4499)  loss_classifier: 0.1102 (0.1596)  loss_box_reg: 0.1167 (0.1508)  loss_objectness: 0.0688 (0.1027)  loss_rpn_box_reg: 0.0154 (0.0368)  time: 0.2712  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [10]  [ 790/1229]  eta: 0:02:00  lr: 0.000500  loss: 0.3601 (0.4495)  loss_classifier: 0.1328 (0.1596)  loss_box_reg: 0.1215 (0.1507)  loss_objectness: 0.0741 (0.1026)  loss_rpn_box_reg: 0.0159 (0.0366)  time: 0.2718  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [10]  [ 800/1229]  eta: 0:01:57  lr: 0.000500  loss: 0.3935 (0.4495)  loss_classifier: 0.1404 (0.1594)  loss_box_reg: 0.1149 (0.1504)  loss_objectness: 0.1115 (0.1027)  loss_rpn_box_reg: 0.0168 (0.0370)  time: 0.2740  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [10]  [ 810/1229]  eta: 0:01:54  lr: 0.000500  loss: 0.3719 (0.4489)  loss_classifier: 0.1219 (0.1591)  loss_box_reg: 0.1083 (0.1505)  loss_objectness: 0.1072 (0.1024)  loss_rpn_box_reg: 0.0164 (0.0368)  time: 0.2738  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [10]  [ 820/1229]  eta: 0:01:51  lr: 0.000500  loss: 0.3645 (0.4493)  loss_classifier: 0.1171 (0.1593)  loss_box_reg: 0.1240 (0.1507)  loss_objectness: 0.0735 (0.1025)  loss_rpn_box_reg: 0.0164 (0.0368)  time: 0.2704  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [10]  [ 830/1229]  eta: 0:01:49  lr: 0.000500  loss: 0.3357 (0.4484)  loss_classifier: 0.1111 (0.1589)  loss_box_reg: 0.0983 (0.1502)  loss_objectness: 0.0844 (0.1025)  loss_rpn_box_reg: 0.0195 (0.0368)  time: 0.2689  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [10]  [ 840/1229]  eta: 0:01:46  lr: 0.000500  loss: 0.3775 (0.4488)  loss_classifier: 0.1224 (0.1589)  loss_box_reg: 0.1158 (0.1505)  loss_objectness: 0.0844 (0.1025)  loss_rpn_box_reg: 0.0234 (0.0369)  time: 0.2686  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [10]  [ 850/1229]  eta: 0:01:43  lr: 0.000500  loss: 0.3775 (0.4481)  loss_classifier: 0.1224 (0.1586)  loss_box_reg: 0.1074 (0.1502)  loss_objectness: 0.0884 (0.1024)  loss_rpn_box_reg: 0.0149 (0.0369)  time: 0.2728  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [10]  [ 860/1229]  eta: 0:01:40  lr: 0.000500  loss: 0.3479 (0.4483)  loss_classifier: 0.1139 (0.1586)  loss_box_reg: 0.1099 (0.1503)  loss_objectness: 0.0788 (0.1023)  loss_rpn_box_reg: 0.0168 (0.0371)  time: 0.2718  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [10]  [ 870/1229]  eta: 0:01:38  lr: 0.000500  loss: 0.4259 (0.4489)  loss_classifier: 0.1620 (0.1589)  loss_box_reg: 0.1299 (0.1505)  loss_objectness: 0.0979 (0.1025)  loss_rpn_box_reg: 0.0240 (0.0370)  time: 0.2731  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [10]  [ 880/1229]  eta: 0:01:35  lr: 0.000500  loss: 0.3809 (0.4484)  loss_classifier: 0.1459 (0.1588)  loss_box_reg: 0.1268 (0.1505)  loss_objectness: 0.0929 (0.1022)  loss_rpn_box_reg: 0.0197 (0.0368)  time: 0.2786  data: 0.1368  max mem: 1751\n",
      "Training Epoch: [10]  [ 890/1229]  eta: 0:01:32  lr: 0.000500  loss: 0.3172 (0.4484)  loss_classifier: 0.1202 (0.1587)  loss_box_reg: 0.1002 (0.1507)  loss_objectness: 0.0811 (0.1021)  loss_rpn_box_reg: 0.0191 (0.0368)  time: 0.2740  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [10]  [ 900/1229]  eta: 0:01:30  lr: 0.000500  loss: 0.3785 (0.4481)  loss_classifier: 0.1229 (0.1586)  loss_box_reg: 0.1002 (0.1506)  loss_objectness: 0.0815 (0.1020)  loss_rpn_box_reg: 0.0217 (0.0369)  time: 0.2732  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [10]  [ 910/1229]  eta: 0:01:27  lr: 0.000500  loss: 0.3356 (0.4461)  loss_classifier: 0.1132 (0.1579)  loss_box_reg: 0.1041 (0.1498)  loss_objectness: 0.0778 (0.1015)  loss_rpn_box_reg: 0.0249 (0.0368)  time: 0.2756  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [10]  [ 920/1229]  eta: 0:01:24  lr: 0.000500  loss: 0.3014 (0.4459)  loss_classifier: 0.0974 (0.1578)  loss_box_reg: 0.0814 (0.1499)  loss_objectness: 0.0683 (0.1014)  loss_rpn_box_reg: 0.0176 (0.0368)  time: 0.2709  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [10]  [ 930/1229]  eta: 0:01:21  lr: 0.000500  loss: 0.3160 (0.4468)  loss_classifier: 0.1121 (0.1581)  loss_box_reg: 0.1085 (0.1502)  loss_objectness: 0.0803 (0.1016)  loss_rpn_box_reg: 0.0205 (0.0370)  time: 0.2686  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [10]  [ 940/1229]  eta: 0:01:19  lr: 0.000500  loss: 0.4650 (0.4466)  loss_classifier: 0.1689 (0.1580)  loss_box_reg: 0.1339 (0.1501)  loss_objectness: 0.0984 (0.1017)  loss_rpn_box_reg: 0.0144 (0.0368)  time: 0.2704  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [10]  [ 950/1229]  eta: 0:01:16  lr: 0.000500  loss: 0.4231 (0.4469)  loss_classifier: 0.1365 (0.1580)  loss_box_reg: 0.1315 (0.1501)  loss_objectness: 0.0921 (0.1020)  loss_rpn_box_reg: 0.0196 (0.0368)  time: 0.2723  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [10]  [ 960/1229]  eta: 0:01:13  lr: 0.000500  loss: 0.3845 (0.4464)  loss_classifier: 0.1311 (0.1577)  loss_box_reg: 0.1194 (0.1498)  loss_objectness: 0.0864 (0.1021)  loss_rpn_box_reg: 0.0241 (0.0368)  time: 0.2680  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [10]  [ 970/1229]  eta: 0:01:10  lr: 0.000500  loss: 0.3195 (0.4465)  loss_classifier: 0.1219 (0.1577)  loss_box_reg: 0.1013 (0.1498)  loss_objectness: 0.0791 (0.1022)  loss_rpn_box_reg: 0.0316 (0.0368)  time: 0.2631  data: 0.1293  max mem: 1751\n",
      "Training Epoch: [10]  [ 980/1229]  eta: 0:01:08  lr: 0.000500  loss: 0.4288 (0.4466)  loss_classifier: 0.1381 (0.1577)  loss_box_reg: 0.1212 (0.1499)  loss_objectness: 0.0778 (0.1019)  loss_rpn_box_reg: 0.0318 (0.0370)  time: 0.2665  data: 0.1289  max mem: 1751\n",
      "Training Epoch: [10]  [ 990/1229]  eta: 0:01:05  lr: 0.000500  loss: 0.3553 (0.4456)  loss_classifier: 0.1279 (0.1573)  loss_box_reg: 0.1395 (0.1497)  loss_objectness: 0.0775 (0.1017)  loss_rpn_box_reg: 0.0212 (0.0369)  time: 0.2682  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [10]  [1000/1229]  eta: 0:01:02  lr: 0.000500  loss: 0.3334 (0.4445)  loss_classifier: 0.1054 (0.1569)  loss_box_reg: 0.0977 (0.1494)  loss_objectness: 0.0775 (0.1015)  loss_rpn_box_reg: 0.0156 (0.0367)  time: 0.2767  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [10]  [1010/1229]  eta: 0:00:59  lr: 0.000500  loss: 0.3627 (0.4447)  loss_classifier: 0.1290 (0.1571)  loss_box_reg: 0.1075 (0.1496)  loss_objectness: 0.0739 (0.1013)  loss_rpn_box_reg: 0.0156 (0.0367)  time: 0.2781  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [10]  [1020/1229]  eta: 0:00:57  lr: 0.000500  loss: 0.4836 (0.4452)  loss_classifier: 0.1759 (0.1572)  loss_box_reg: 0.1377 (0.1499)  loss_objectness: 0.0834 (0.1013)  loss_rpn_box_reg: 0.0275 (0.0368)  time: 0.2698  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [10]  [1030/1229]  eta: 0:00:54  lr: 0.000500  loss: 0.4031 (0.4453)  loss_classifier: 0.1680 (0.1572)  loss_box_reg: 0.1377 (0.1498)  loss_objectness: 0.1008 (0.1015)  loss_rpn_box_reg: 0.0310 (0.0368)  time: 0.2673  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [10]  [1040/1229]  eta: 0:00:51  lr: 0.000500  loss: 0.4273 (0.4457)  loss_classifier: 0.1661 (0.1573)  loss_box_reg: 0.1375 (0.1501)  loss_objectness: 0.1027 (0.1015)  loss_rpn_box_reg: 0.0274 (0.0368)  time: 0.2673  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [10]  [1050/1229]  eta: 0:00:48  lr: 0.000500  loss: 0.3622 (0.4445)  loss_classifier: 0.1283 (0.1569)  loss_box_reg: 0.1020 (0.1498)  loss_objectness: 0.0755 (0.1012)  loss_rpn_box_reg: 0.0180 (0.0366)  time: 0.2736  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [10]  [1060/1229]  eta: 0:00:46  lr: 0.000500  loss: 0.3622 (0.4444)  loss_classifier: 0.1248 (0.1570)  loss_box_reg: 0.1263 (0.1498)  loss_objectness: 0.0687 (0.1012)  loss_rpn_box_reg: 0.0186 (0.0365)  time: 0.2764  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [10]  [1070/1229]  eta: 0:00:43  lr: 0.000500  loss: 0.3960 (0.4450)  loss_classifier: 0.1631 (0.1572)  loss_box_reg: 0.1312 (0.1500)  loss_objectness: 0.0959 (0.1013)  loss_rpn_box_reg: 0.0281 (0.0365)  time: 0.2758  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [10]  [1080/1229]  eta: 0:00:40  lr: 0.000500  loss: 0.4115 (0.4444)  loss_classifier: 0.1639 (0.1571)  loss_box_reg: 0.1349 (0.1498)  loss_objectness: 0.0755 (0.1011)  loss_rpn_box_reg: 0.0288 (0.0364)  time: 0.2769  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [10]  [1090/1229]  eta: 0:00:37  lr: 0.000500  loss: 0.4115 (0.4438)  loss_classifier: 0.1379 (0.1568)  loss_box_reg: 0.0999 (0.1495)  loss_objectness: 0.0699 (0.1012)  loss_rpn_box_reg: 0.0169 (0.0363)  time: 0.2758  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [10]  [1100/1229]  eta: 0:00:35  lr: 0.000500  loss: 0.3868 (0.4437)  loss_classifier: 0.1328 (0.1567)  loss_box_reg: 0.0999 (0.1496)  loss_objectness: 0.0713 (0.1012)  loss_rpn_box_reg: 0.0169 (0.0363)  time: 0.2731  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [10]  [1110/1229]  eta: 0:00:32  lr: 0.000500  loss: 0.3923 (0.4439)  loss_classifier: 0.1289 (0.1567)  loss_box_reg: 0.1234 (0.1495)  loss_objectness: 0.0713 (0.1013)  loss_rpn_box_reg: 0.0198 (0.0364)  time: 0.2738  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [10]  [1120/1229]  eta: 0:00:29  lr: 0.000500  loss: 0.4020 (0.4434)  loss_classifier: 0.1246 (0.1564)  loss_box_reg: 0.0767 (0.1490)  loss_objectness: 0.1044 (0.1015)  loss_rpn_box_reg: 0.0261 (0.0366)  time: 0.2747  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [10]  [1130/1229]  eta: 0:00:27  lr: 0.000500  loss: 0.3181 (0.4432)  loss_classifier: 0.1132 (0.1563)  loss_box_reg: 0.0838 (0.1487)  loss_objectness: 0.1121 (0.1017)  loss_rpn_box_reg: 0.0245 (0.0365)  time: 0.2695  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [10]  [1140/1229]  eta: 0:00:24  lr: 0.000500  loss: 0.3890 (0.4434)  loss_classifier: 0.1298 (0.1564)  loss_box_reg: 0.1074 (0.1491)  loss_objectness: 0.1007 (0.1015)  loss_rpn_box_reg: 0.0214 (0.0363)  time: 0.2692  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [10]  [1150/1229]  eta: 0:00:21  lr: 0.000500  loss: 0.4732 (0.4439)  loss_classifier: 0.1620 (0.1565)  loss_box_reg: 0.1195 (0.1492)  loss_objectness: 0.0860 (0.1017)  loss_rpn_box_reg: 0.0214 (0.0365)  time: 0.2738  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [10]  [1160/1229]  eta: 0:00:18  lr: 0.000500  loss: 0.3843 (0.4438)  loss_classifier: 0.1514 (0.1565)  loss_box_reg: 0.1243 (0.1493)  loss_objectness: 0.0947 (0.1015)  loss_rpn_box_reg: 0.0264 (0.0364)  time: 0.2766  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [10]  [1170/1229]  eta: 0:00:16  lr: 0.000500  loss: 0.3692 (0.4445)  loss_classifier: 0.1425 (0.1567)  loss_box_reg: 0.1290 (0.1496)  loss_objectness: 0.0653 (0.1016)  loss_rpn_box_reg: 0.0327 (0.0366)  time: 0.2765  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [10]  [1180/1229]  eta: 0:00:13  lr: 0.000500  loss: 0.3602 (0.4443)  loss_classifier: 0.1392 (0.1567)  loss_box_reg: 0.1350 (0.1496)  loss_objectness: 0.0855 (0.1014)  loss_rpn_box_reg: 0.0198 (0.0366)  time: 0.2729  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [10]  [1190/1229]  eta: 0:00:10  lr: 0.000500  loss: 0.3549 (0.4440)  loss_classifier: 0.1501 (0.1567)  loss_box_reg: 0.1361 (0.1496)  loss_objectness: 0.0821 (0.1012)  loss_rpn_box_reg: 0.0158 (0.0365)  time: 0.2750  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [10]  [1200/1229]  eta: 0:00:07  lr: 0.000500  loss: 0.3669 (0.4433)  loss_classifier: 0.1403 (0.1565)  loss_box_reg: 0.1340 (0.1493)  loss_objectness: 0.0734 (0.1011)  loss_rpn_box_reg: 0.0178 (0.0364)  time: 0.2767  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [10]  [1210/1229]  eta: 0:00:05  lr: 0.000500  loss: 0.3824 (0.4435)  loss_classifier: 0.1403 (0.1566)  loss_box_reg: 0.1322 (0.1494)  loss_objectness: 0.0786 (0.1011)  loss_rpn_box_reg: 0.0234 (0.0364)  time: 0.2760  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [10]  [1220/1229]  eta: 0:00:02  lr: 0.000500  loss: 0.3460 (0.4429)  loss_classifier: 0.1376 (0.1563)  loss_box_reg: 0.1169 (0.1492)  loss_objectness: 0.0786 (0.1010)  loss_rpn_box_reg: 0.0191 (0.0363)  time: 0.2755  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [10]  [1228/1229]  eta: 0:00:00  lr: 0.000500  loss: 0.3256 (0.4422)  loss_classifier: 0.1019 (0.1561)  loss_box_reg: 0.0848 (0.1489)  loss_objectness: 0.0695 (0.1009)  loss_rpn_box_reg: 0.0198 (0.0363)  time: 0.2739  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [10] Total time: 0:05:36 (0.2734 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:02:06  model_time: 0.2770 (0.2770)  evaluator_time: 0.0020 (0.0020)  time: 0.4100  data: 0.1280  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0780 (0.0820)  evaluator_time: 0.0040 (0.0083)  time: 0.1319  data: 0.0410  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0840 (0.0809)  evaluator_time: 0.0030 (0.0076)  time: 0.1203  data: 0.0306  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0730 (0.0801)  evaluator_time: 0.0040 (0.0074)  time: 0.1192  data: 0.0352  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0730 (0.0800)  evaluator_time: 0.0020 (0.0074)  time: 0.1163  data: 0.0335  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1238 s / it)\n",
      "Averaged stats: model_time: 0.0730 (0.0800)  evaluator_time: 0.0020 (0.0074)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.299\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.342\n",
      "Testing Epoch: [10]  [  0/308]  eta: 0:00:36  lr: 0.000500  loss: 0.1527 (0.1527)  loss_classifier: 0.0535 (0.0535)  loss_box_reg: 0.0618 (0.0618)  loss_objectness: 0.0243 (0.0243)  loss_rpn_box_reg: 0.0130 (0.0130)  time: 0.1200  data: 0.0270  max mem: 1751\n",
      "Testing Epoch: [10]  [100/308]  eta: 0:00:28  lr: 0.000500  loss: 0.3342 (0.4820)  loss_classifier: 0.1309 (0.1566)  loss_box_reg: 0.1066 (0.1739)  loss_objectness: 0.0590 (0.1000)  loss_rpn_box_reg: 0.0191 (0.0515)  time: 0.1406  data: 0.0385  max mem: 1751\n",
      "Testing Epoch: [10]  [200/308]  eta: 0:00:14  lr: 0.000500  loss: 0.3693 (0.4581)  loss_classifier: 0.1376 (0.1504)  loss_box_reg: 0.1376 (0.1646)  loss_objectness: 0.0663 (0.0942)  loss_rpn_box_reg: 0.0208 (0.0489)  time: 0.1419  data: 0.0364  max mem: 1751\n",
      "Testing Epoch: [10]  [300/308]  eta: 0:00:01  lr: 0.000500  loss: 0.4680 (0.4549)  loss_classifier: 0.1537 (0.1501)  loss_box_reg: 0.1722 (0.1651)  loss_objectness: 0.0776 (0.0922)  loss_rpn_box_reg: 0.0267 (0.0475)  time: 0.1383  data: 0.0431  max mem: 1751\n",
      "Testing Epoch: [10]  [307/308]  eta: 0:00:00  lr: 0.000500  loss: 0.4441 (0.4553)  loss_classifier: 0.1801 (0.1504)  loss_box_reg: 0.1722 (0.1654)  loss_objectness: 0.0761 (0.0923)  loss_rpn_box_reg: 0.0287 (0.0470)  time: 0.1358  data: 0.0411  max mem: 1751\n",
      "Testing Epoch: [10] Total time: 0:00:42 (0.1374 s / it)\n",
      "Training Epoch: [11]  [   0/1229]  eta: 0:05:20  lr: 0.000500  loss: 0.3374 (0.3374)  loss_classifier: 0.1091 (0.1091)  loss_box_reg: 0.1296 (0.1296)  loss_objectness: 0.0837 (0.0837)  loss_rpn_box_reg: 0.0149 (0.0149)  time: 0.2610  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [11]  [  10/1229]  eta: 0:05:28  lr: 0.000500  loss: 0.3547 (0.3590)  loss_classifier: 0.1091 (0.1230)  loss_box_reg: 0.0963 (0.1072)  loss_objectness: 0.0903 (0.0913)  loss_rpn_box_reg: 0.0192 (0.0375)  time: 0.2696  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [11]  [  20/1229]  eta: 0:05:23  lr: 0.000500  loss: 0.3726 (0.4055)  loss_classifier: 0.1482 (0.1384)  loss_box_reg: 0.0926 (0.1287)  loss_objectness: 0.1015 (0.1031)  loss_rpn_box_reg: 0.0220 (0.0352)  time: 0.2682  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [11]  [  30/1229]  eta: 0:05:24  lr: 0.000500  loss: 0.4079 (0.4094)  loss_classifier: 0.1637 (0.1416)  loss_box_reg: 0.1324 (0.1285)  loss_objectness: 0.1015 (0.1060)  loss_rpn_box_reg: 0.0195 (0.0333)  time: 0.2706  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [11]  [  40/1229]  eta: 0:05:22  lr: 0.000500  loss: 0.4301 (0.4209)  loss_classifier: 0.1637 (0.1462)  loss_box_reg: 0.1371 (0.1350)  loss_objectness: 0.0959 (0.1055)  loss_rpn_box_reg: 0.0228 (0.0342)  time: 0.2756  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [11]  [  50/1229]  eta: 0:05:20  lr: 0.000500  loss: 0.3178 (0.4165)  loss_classifier: 0.1150 (0.1447)  loss_box_reg: 0.1137 (0.1359)  loss_objectness: 0.0571 (0.1040)  loss_rpn_box_reg: 0.0228 (0.0319)  time: 0.2749  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [11]  [  60/1229]  eta: 0:05:17  lr: 0.000500  loss: 0.3178 (0.4252)  loss_classifier: 0.1262 (0.1477)  loss_box_reg: 0.0937 (0.1355)  loss_objectness: 0.0886 (0.1053)  loss_rpn_box_reg: 0.0276 (0.0366)  time: 0.2729  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [11]  [  70/1229]  eta: 0:05:15  lr: 0.000500  loss: 0.4712 (0.4464)  loss_classifier: 0.1781 (0.1572)  loss_box_reg: 0.1456 (0.1438)  loss_objectness: 0.0886 (0.1072)  loss_rpn_box_reg: 0.0366 (0.0382)  time: 0.2715  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [11]  [  80/1229]  eta: 0:05:13  lr: 0.000500  loss: 0.3897 (0.4397)  loss_classifier: 0.1353 (0.1528)  loss_box_reg: 0.1323 (0.1390)  loss_objectness: 0.0953 (0.1067)  loss_rpn_box_reg: 0.0350 (0.0411)  time: 0.2760  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [11]  [  90/1229]  eta: 0:05:09  lr: 0.000500  loss: 0.3897 (0.4423)  loss_classifier: 0.1334 (0.1533)  loss_box_reg: 0.1163 (0.1410)  loss_objectness: 0.0959 (0.1069)  loss_rpn_box_reg: 0.0350 (0.0410)  time: 0.2717  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [11]  [ 100/1229]  eta: 0:05:05  lr: 0.000500  loss: 0.4222 (0.4530)  loss_classifier: 0.1476 (0.1587)  loss_box_reg: 0.1351 (0.1473)  loss_objectness: 0.0961 (0.1070)  loss_rpn_box_reg: 0.0239 (0.0400)  time: 0.2629  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [11]  [ 110/1229]  eta: 0:05:03  lr: 0.000500  loss: 0.4222 (0.4548)  loss_classifier: 0.1718 (0.1597)  loss_box_reg: 0.1257 (0.1463)  loss_objectness: 0.1099 (0.1079)  loss_rpn_box_reg: 0.0239 (0.0409)  time: 0.2680  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [11]  [ 120/1229]  eta: 0:05:00  lr: 0.000500  loss: 0.3577 (0.4448)  loss_classifier: 0.1276 (0.1560)  loss_box_reg: 0.0954 (0.1430)  loss_objectness: 0.0883 (0.1062)  loss_rpn_box_reg: 0.0209 (0.0395)  time: 0.2693  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [11]  [ 130/1229]  eta: 0:04:56  lr: 0.000500  loss: 0.4131 (0.4482)  loss_classifier: 0.1365 (0.1580)  loss_box_reg: 0.1250 (0.1463)  loss_objectness: 0.0883 (0.1051)  loss_rpn_box_reg: 0.0215 (0.0387)  time: 0.2647  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [11]  [ 140/1229]  eta: 0:04:54  lr: 0.000500  loss: 0.4087 (0.4428)  loss_classifier: 0.1482 (0.1560)  loss_box_reg: 0.1250 (0.1468)  loss_objectness: 0.0790 (0.1023)  loss_rpn_box_reg: 0.0216 (0.0378)  time: 0.2675  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [11]  [ 150/1229]  eta: 0:04:51  lr: 0.000500  loss: 0.3120 (0.4370)  loss_classifier: 0.1261 (0.1542)  loss_box_reg: 0.1052 (0.1445)  loss_objectness: 0.0659 (0.1011)  loss_rpn_box_reg: 0.0154 (0.0371)  time: 0.2724  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [11]  [ 160/1229]  eta: 0:04:50  lr: 0.000500  loss: 0.3311 (0.4446)  loss_classifier: 0.1281 (0.1580)  loss_box_reg: 0.1069 (0.1453)  loss_objectness: 0.0717 (0.1044)  loss_rpn_box_reg: 0.0165 (0.0368)  time: 0.2794  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [11]  [ 170/1229]  eta: 0:04:47  lr: 0.000500  loss: 0.3804 (0.4404)  loss_classifier: 0.1498 (0.1566)  loss_box_reg: 0.0978 (0.1436)  loss_objectness: 0.1004 (0.1044)  loss_rpn_box_reg: 0.0222 (0.0358)  time: 0.2820  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [11]  [ 180/1229]  eta: 0:04:45  lr: 0.000500  loss: 0.3804 (0.4373)  loss_classifier: 0.1500 (0.1558)  loss_box_reg: 0.0933 (0.1430)  loss_objectness: 0.0930 (0.1035)  loss_rpn_box_reg: 0.0186 (0.0349)  time: 0.2771  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [11]  [ 190/1229]  eta: 0:04:42  lr: 0.000500  loss: 0.4067 (0.4418)  loss_classifier: 0.1523 (0.1566)  loss_box_reg: 0.1584 (0.1441)  loss_objectness: 0.0912 (0.1042)  loss_rpn_box_reg: 0.0186 (0.0369)  time: 0.2719  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [11]  [ 200/1229]  eta: 0:04:40  lr: 0.000500  loss: 0.4115 (0.4409)  loss_classifier: 0.1473 (0.1562)  loss_box_reg: 0.1171 (0.1440)  loss_objectness: 0.0912 (0.1039)  loss_rpn_box_reg: 0.0244 (0.0369)  time: 0.2749  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [11]  [ 210/1229]  eta: 0:04:37  lr: 0.000500  loss: 0.3716 (0.4388)  loss_classifier: 0.1230 (0.1554)  loss_box_reg: 0.1029 (0.1427)  loss_objectness: 0.0704 (0.1033)  loss_rpn_box_reg: 0.0244 (0.0375)  time: 0.2783  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [11]  [ 220/1229]  eta: 0:04:35  lr: 0.000500  loss: 0.3716 (0.4400)  loss_classifier: 0.1371 (0.1555)  loss_box_reg: 0.0945 (0.1431)  loss_objectness: 0.0809 (0.1029)  loss_rpn_box_reg: 0.0241 (0.0385)  time: 0.2784  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [11]  [ 230/1229]  eta: 0:04:32  lr: 0.000500  loss: 0.3868 (0.4403)  loss_classifier: 0.1436 (0.1552)  loss_box_reg: 0.1161 (0.1428)  loss_objectness: 0.0809 (0.1032)  loss_rpn_box_reg: 0.0275 (0.0392)  time: 0.2780  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [11]  [ 240/1229]  eta: 0:04:29  lr: 0.000500  loss: 0.3921 (0.4380)  loss_classifier: 0.1426 (0.1544)  loss_box_reg: 0.1187 (0.1419)  loss_objectness: 0.1082 (0.1030)  loss_rpn_box_reg: 0.0251 (0.0387)  time: 0.2740  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [11]  [ 250/1229]  eta: 0:04:27  lr: 0.000500  loss: 0.4047 (0.4402)  loss_classifier: 0.1426 (0.1551)  loss_box_reg: 0.1427 (0.1441)  loss_objectness: 0.0904 (0.1023)  loss_rpn_box_reg: 0.0239 (0.0386)  time: 0.2751  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [11]  [ 260/1229]  eta: 0:04:25  lr: 0.000500  loss: 0.4434 (0.4428)  loss_classifier: 0.1460 (0.1561)  loss_box_reg: 0.1493 (0.1446)  loss_objectness: 0.0927 (0.1026)  loss_rpn_box_reg: 0.0248 (0.0395)  time: 0.2817  data: 0.1367  max mem: 1751\n",
      "Training Epoch: [11]  [ 270/1229]  eta: 0:04:22  lr: 0.000500  loss: 0.4557 (0.4429)  loss_classifier: 0.1571 (0.1560)  loss_box_reg: 0.1643 (0.1454)  loss_objectness: 0.0858 (0.1022)  loss_rpn_box_reg: 0.0236 (0.0393)  time: 0.2794  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [11]  [ 280/1229]  eta: 0:04:19  lr: 0.000500  loss: 0.4061 (0.4441)  loss_classifier: 0.1571 (0.1566)  loss_box_reg: 0.1600 (0.1463)  loss_objectness: 0.0862 (0.1023)  loss_rpn_box_reg: 0.0236 (0.0389)  time: 0.2756  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [11]  [ 290/1229]  eta: 0:04:17  lr: 0.000500  loss: 0.3196 (0.4394)  loss_classifier: 0.1039 (0.1549)  loss_box_reg: 0.1037 (0.1447)  loss_objectness: 0.0883 (0.1018)  loss_rpn_box_reg: 0.0151 (0.0381)  time: 0.2767  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [11]  [ 300/1229]  eta: 0:04:14  lr: 0.000500  loss: 0.2814 (0.4396)  loss_classifier: 0.0963 (0.1549)  loss_box_reg: 0.0815 (0.1451)  loss_objectness: 0.0883 (0.1018)  loss_rpn_box_reg: 0.0171 (0.0378)  time: 0.2798  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [11]  [ 310/1229]  eta: 0:04:11  lr: 0.000500  loss: 0.4291 (0.4438)  loss_classifier: 0.1503 (0.1563)  loss_box_reg: 0.1411 (0.1464)  loss_objectness: 0.1116 (0.1025)  loss_rpn_box_reg: 0.0375 (0.0385)  time: 0.2748  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [11]  [ 320/1229]  eta: 0:04:08  lr: 0.000500  loss: 0.3990 (0.4439)  loss_classifier: 0.1351 (0.1562)  loss_box_reg: 0.1261 (0.1470)  loss_objectness: 0.1095 (0.1024)  loss_rpn_box_reg: 0.0250 (0.0383)  time: 0.2682  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [11]  [ 330/1229]  eta: 0:04:06  lr: 0.000500  loss: 0.3798 (0.4454)  loss_classifier: 0.1324 (0.1571)  loss_box_reg: 0.1039 (0.1475)  loss_objectness: 0.0796 (0.1019)  loss_rpn_box_reg: 0.0223 (0.0388)  time: 0.2732  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [11]  [ 340/1229]  eta: 0:04:03  lr: 0.000500  loss: 0.3798 (0.4439)  loss_classifier: 0.1429 (0.1567)  loss_box_reg: 0.1039 (0.1465)  loss_objectness: 0.0873 (0.1021)  loss_rpn_box_reg: 0.0223 (0.0387)  time: 0.2712  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [11]  [ 350/1229]  eta: 0:04:00  lr: 0.000500  loss: 0.3959 (0.4452)  loss_classifier: 0.1429 (0.1571)  loss_box_reg: 0.1109 (0.1470)  loss_objectness: 0.1001 (0.1023)  loss_rpn_box_reg: 0.0219 (0.0389)  time: 0.2715  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [11]  [ 360/1229]  eta: 0:03:57  lr: 0.000500  loss: 0.3959 (0.4458)  loss_classifier: 0.1404 (0.1573)  loss_box_reg: 0.1300 (0.1473)  loss_objectness: 0.1001 (0.1025)  loss_rpn_box_reg: 0.0308 (0.0387)  time: 0.2702  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [11]  [ 370/1229]  eta: 0:03:55  lr: 0.000500  loss: 0.3784 (0.4476)  loss_classifier: 0.1300 (0.1579)  loss_box_reg: 0.1315 (0.1480)  loss_objectness: 0.1303 (0.1028)  loss_rpn_box_reg: 0.0321 (0.0388)  time: 0.2725  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [11]  [ 380/1229]  eta: 0:03:52  lr: 0.000500  loss: 0.4988 (0.4506)  loss_classifier: 0.1713 (0.1589)  loss_box_reg: 0.1703 (0.1501)  loss_objectness: 0.1043 (0.1030)  loss_rpn_box_reg: 0.0321 (0.0386)  time: 0.2812  data: 0.1383  max mem: 1751\n",
      "Training Epoch: [11]  [ 390/1229]  eta: 0:03:49  lr: 0.000500  loss: 0.5121 (0.4519)  loss_classifier: 0.1858 (0.1597)  loss_box_reg: 0.1613 (0.1507)  loss_objectness: 0.1043 (0.1033)  loss_rpn_box_reg: 0.0228 (0.0382)  time: 0.2756  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [11]  [ 400/1229]  eta: 0:03:46  lr: 0.000500  loss: 0.4661 (0.4526)  loss_classifier: 0.1832 (0.1603)  loss_box_reg: 0.1613 (0.1512)  loss_objectness: 0.0978 (0.1031)  loss_rpn_box_reg: 0.0225 (0.0380)  time: 0.2721  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [11]  [ 410/1229]  eta: 0:03:44  lr: 0.000500  loss: 0.3235 (0.4493)  loss_classifier: 0.1287 (0.1591)  loss_box_reg: 0.0908 (0.1497)  loss_objectness: 0.0675 (0.1026)  loss_rpn_box_reg: 0.0225 (0.0379)  time: 0.2715  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [11]  [ 420/1229]  eta: 0:03:41  lr: 0.000500  loss: 0.2898 (0.4463)  loss_classifier: 0.1061 (0.1581)  loss_box_reg: 0.0833 (0.1487)  loss_objectness: 0.0737 (0.1020)  loss_rpn_box_reg: 0.0094 (0.0375)  time: 0.2647  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [11]  [ 430/1229]  eta: 0:03:38  lr: 0.000500  loss: 0.3025 (0.4450)  loss_classifier: 0.1031 (0.1576)  loss_box_reg: 0.0906 (0.1480)  loss_objectness: 0.0846 (0.1022)  loss_rpn_box_reg: 0.0153 (0.0372)  time: 0.2651  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [11]  [ 440/1229]  eta: 0:03:35  lr: 0.000500  loss: 0.3834 (0.4448)  loss_classifier: 0.1465 (0.1576)  loss_box_reg: 0.1098 (0.1477)  loss_objectness: 0.0881 (0.1023)  loss_rpn_box_reg: 0.0202 (0.0371)  time: 0.2664  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [11]  [ 450/1229]  eta: 0:03:32  lr: 0.000500  loss: 0.4058 (0.4444)  loss_classifier: 0.1399 (0.1575)  loss_box_reg: 0.1243 (0.1472)  loss_objectness: 0.0950 (0.1022)  loss_rpn_box_reg: 0.0233 (0.0374)  time: 0.2677  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [11]  [ 460/1229]  eta: 0:03:30  lr: 0.000500  loss: 0.3556 (0.4441)  loss_classifier: 0.1142 (0.1571)  loss_box_reg: 0.1079 (0.1472)  loss_objectness: 0.0960 (0.1024)  loss_rpn_box_reg: 0.0201 (0.0374)  time: 0.2756  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [11]  [ 470/1229]  eta: 0:03:27  lr: 0.000500  loss: 0.3406 (0.4447)  loss_classifier: 0.1008 (0.1573)  loss_box_reg: 0.0737 (0.1472)  loss_objectness: 0.1009 (0.1026)  loss_rpn_box_reg: 0.0184 (0.0375)  time: 0.2809  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [11]  [ 480/1229]  eta: 0:03:24  lr: 0.000500  loss: 0.4346 (0.4445)  loss_classifier: 0.1227 (0.1569)  loss_box_reg: 0.0884 (0.1469)  loss_objectness: 0.0977 (0.1030)  loss_rpn_box_reg: 0.0338 (0.0376)  time: 0.2753  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [11]  [ 490/1229]  eta: 0:03:21  lr: 0.000500  loss: 0.4137 (0.4454)  loss_classifier: 0.1296 (0.1573)  loss_box_reg: 0.1096 (0.1471)  loss_objectness: 0.0976 (0.1033)  loss_rpn_box_reg: 0.0277 (0.0376)  time: 0.2667  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [11]  [ 500/1229]  eta: 0:03:19  lr: 0.000500  loss: 0.3632 (0.4448)  loss_classifier: 0.1257 (0.1570)  loss_box_reg: 0.1096 (0.1468)  loss_objectness: 0.0976 (0.1033)  loss_rpn_box_reg: 0.0192 (0.0377)  time: 0.2685  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [11]  [ 510/1229]  eta: 0:03:16  lr: 0.000500  loss: 0.4623 (0.4443)  loss_classifier: 0.1257 (0.1568)  loss_box_reg: 0.1237 (0.1466)  loss_objectness: 0.0774 (0.1034)  loss_rpn_box_reg: 0.0229 (0.0376)  time: 0.2717  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [11]  [ 520/1229]  eta: 0:03:13  lr: 0.000500  loss: 0.3416 (0.4436)  loss_classifier: 0.1292 (0.1565)  loss_box_reg: 0.1138 (0.1463)  loss_objectness: 0.0834 (0.1034)  loss_rpn_box_reg: 0.0180 (0.0373)  time: 0.2703  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [11]  [ 530/1229]  eta: 0:03:10  lr: 0.000500  loss: 0.3332 (0.4431)  loss_classifier: 0.1292 (0.1566)  loss_box_reg: 0.1078 (0.1463)  loss_objectness: 0.0825 (0.1032)  loss_rpn_box_reg: 0.0122 (0.0370)  time: 0.2727  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [11]  [ 540/1229]  eta: 0:03:08  lr: 0.000500  loss: 0.3332 (0.4424)  loss_classifier: 0.1346 (0.1564)  loss_box_reg: 0.0938 (0.1459)  loss_objectness: 0.0755 (0.1034)  loss_rpn_box_reg: 0.0203 (0.0367)  time: 0.2740  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [11]  [ 550/1229]  eta: 0:03:05  lr: 0.000500  loss: 0.3424 (0.4416)  loss_classifier: 0.1254 (0.1561)  loss_box_reg: 0.1157 (0.1460)  loss_objectness: 0.0762 (0.1029)  loss_rpn_box_reg: 0.0238 (0.0366)  time: 0.2720  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [11]  [ 560/1229]  eta: 0:03:02  lr: 0.000500  loss: 0.3424 (0.4408)  loss_classifier: 0.1248 (0.1558)  loss_box_reg: 0.1104 (0.1459)  loss_objectness: 0.0760 (0.1026)  loss_rpn_box_reg: 0.0244 (0.0365)  time: 0.2742  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [11]  [ 570/1229]  eta: 0:02:59  lr: 0.000500  loss: 0.3994 (0.4411)  loss_classifier: 0.1348 (0.1559)  loss_box_reg: 0.1104 (0.1461)  loss_objectness: 0.0848 (0.1028)  loss_rpn_box_reg: 0.0266 (0.0364)  time: 0.2710  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [11]  [ 580/1229]  eta: 0:02:57  lr: 0.000500  loss: 0.3577 (0.4391)  loss_classifier: 0.1340 (0.1553)  loss_box_reg: 0.1162 (0.1454)  loss_objectness: 0.0843 (0.1023)  loss_rpn_box_reg: 0.0177 (0.0361)  time: 0.2719  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [11]  [ 590/1229]  eta: 0:02:54  lr: 0.000500  loss: 0.2698 (0.4374)  loss_classifier: 0.1049 (0.1547)  loss_box_reg: 0.0909 (0.1443)  loss_objectness: 0.0626 (0.1025)  loss_rpn_box_reg: 0.0157 (0.0360)  time: 0.2749  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [11]  [ 600/1229]  eta: 0:02:51  lr: 0.000500  loss: 0.3861 (0.4376)  loss_classifier: 0.1462 (0.1547)  loss_box_reg: 0.0995 (0.1440)  loss_objectness: 0.0855 (0.1028)  loss_rpn_box_reg: 0.0224 (0.0361)  time: 0.2736  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [11]  [ 610/1229]  eta: 0:02:49  lr: 0.000500  loss: 0.4805 (0.4400)  loss_classifier: 0.1812 (0.1554)  loss_box_reg: 0.1719 (0.1452)  loss_objectness: 0.0860 (0.1026)  loss_rpn_box_reg: 0.0318 (0.0368)  time: 0.2762  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [11]  [ 620/1229]  eta: 0:02:46  lr: 0.000500  loss: 0.4592 (0.4397)  loss_classifier: 0.1566 (0.1551)  loss_box_reg: 0.2069 (0.1455)  loss_objectness: 0.0797 (0.1024)  loss_rpn_box_reg: 0.0230 (0.0366)  time: 0.2708  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [11]  [ 630/1229]  eta: 0:02:43  lr: 0.000500  loss: 0.3006 (0.4387)  loss_classifier: 0.0864 (0.1548)  loss_box_reg: 0.0917 (0.1453)  loss_objectness: 0.0689 (0.1021)  loss_rpn_box_reg: 0.0152 (0.0365)  time: 0.2744  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [11]  [ 640/1229]  eta: 0:02:40  lr: 0.000500  loss: 0.3341 (0.4387)  loss_classifier: 0.1177 (0.1548)  loss_box_reg: 0.0917 (0.1448)  loss_objectness: 0.0841 (0.1027)  loss_rpn_box_reg: 0.0152 (0.0365)  time: 0.2797  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [11]  [ 650/1229]  eta: 0:02:38  lr: 0.000500  loss: 0.4609 (0.4401)  loss_classifier: 0.1641 (0.1554)  loss_box_reg: 0.1357 (0.1456)  loss_objectness: 0.0994 (0.1025)  loss_rpn_box_reg: 0.0305 (0.0365)  time: 0.2764  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [11]  [ 660/1229]  eta: 0:02:35  lr: 0.000500  loss: 0.3889 (0.4385)  loss_classifier: 0.1637 (0.1548)  loss_box_reg: 0.1378 (0.1450)  loss_objectness: 0.0861 (0.1023)  loss_rpn_box_reg: 0.0286 (0.0364)  time: 0.2765  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [11]  [ 670/1229]  eta: 0:02:32  lr: 0.000500  loss: 0.3585 (0.4390)  loss_classifier: 0.1281 (0.1552)  loss_box_reg: 0.1149 (0.1454)  loss_objectness: 0.0861 (0.1022)  loss_rpn_box_reg: 0.0194 (0.0362)  time: 0.2741  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [11]  [ 680/1229]  eta: 0:02:29  lr: 0.000500  loss: 0.3469 (0.4373)  loss_classifier: 0.1155 (0.1545)  loss_box_reg: 0.1078 (0.1450)  loss_objectness: 0.0657 (0.1017)  loss_rpn_box_reg: 0.0179 (0.0360)  time: 0.2708  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [11]  [ 690/1229]  eta: 0:02:27  lr: 0.000500  loss: 0.3342 (0.4358)  loss_classifier: 0.1004 (0.1540)  loss_box_reg: 0.0983 (0.1447)  loss_objectness: 0.0585 (0.1014)  loss_rpn_box_reg: 0.0117 (0.0357)  time: 0.2695  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [11]  [ 700/1229]  eta: 0:02:24  lr: 0.000500  loss: 0.3137 (0.4348)  loss_classifier: 0.1002 (0.1538)  loss_box_reg: 0.0829 (0.1443)  loss_objectness: 0.0788 (0.1011)  loss_rpn_box_reg: 0.0111 (0.0355)  time: 0.2709  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [11]  [ 710/1229]  eta: 0:02:21  lr: 0.000500  loss: 0.3245 (0.4341)  loss_classifier: 0.1006 (0.1536)  loss_box_reg: 0.0829 (0.1438)  loss_objectness: 0.0769 (0.1010)  loss_rpn_box_reg: 0.0234 (0.0356)  time: 0.2750  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [11]  [ 720/1229]  eta: 0:02:18  lr: 0.000500  loss: 0.3519 (0.4346)  loss_classifier: 0.1237 (0.1539)  loss_box_reg: 0.1187 (0.1440)  loss_objectness: 0.1044 (0.1011)  loss_rpn_box_reg: 0.0234 (0.0355)  time: 0.2718  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [11]  [ 730/1229]  eta: 0:02:16  lr: 0.000500  loss: 0.3727 (0.4335)  loss_classifier: 0.1259 (0.1535)  loss_box_reg: 0.1166 (0.1435)  loss_objectness: 0.1044 (0.1009)  loss_rpn_box_reg: 0.0220 (0.0356)  time: 0.2688  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [11]  [ 740/1229]  eta: 0:02:13  lr: 0.000500  loss: 0.4172 (0.4336)  loss_classifier: 0.1274 (0.1536)  loss_box_reg: 0.1166 (0.1433)  loss_objectness: 0.1028 (0.1012)  loss_rpn_box_reg: 0.0153 (0.0355)  time: 0.2714  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [11]  [ 750/1229]  eta: 0:02:10  lr: 0.000500  loss: 0.4259 (0.4341)  loss_classifier: 0.1547 (0.1539)  loss_box_reg: 0.1322 (0.1434)  loss_objectness: 0.1107 (0.1012)  loss_rpn_box_reg: 0.0183 (0.0355)  time: 0.2676  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [11]  [ 760/1229]  eta: 0:02:07  lr: 0.000500  loss: 0.4728 (0.4358)  loss_classifier: 0.1764 (0.1543)  loss_box_reg: 0.1556 (0.1444)  loss_objectness: 0.1064 (0.1015)  loss_rpn_box_reg: 0.0272 (0.0356)  time: 0.2669  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [11]  [ 770/1229]  eta: 0:02:05  lr: 0.000500  loss: 0.4153 (0.4348)  loss_classifier: 0.1433 (0.1539)  loss_box_reg: 0.1265 (0.1439)  loss_objectness: 0.0988 (0.1014)  loss_rpn_box_reg: 0.0274 (0.0357)  time: 0.2674  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [11]  [ 780/1229]  eta: 0:02:02  lr: 0.000500  loss: 0.3098 (0.4342)  loss_classifier: 0.1094 (0.1537)  loss_box_reg: 0.0757 (0.1437)  loss_objectness: 0.0751 (0.1012)  loss_rpn_box_reg: 0.0186 (0.0355)  time: 0.2675  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [11]  [ 790/1229]  eta: 0:01:59  lr: 0.000500  loss: 0.3675 (0.4344)  loss_classifier: 0.1224 (0.1537)  loss_box_reg: 0.1337 (0.1440)  loss_objectness: 0.0831 (0.1011)  loss_rpn_box_reg: 0.0155 (0.0356)  time: 0.2741  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [11]  [ 800/1229]  eta: 0:01:56  lr: 0.000500  loss: 0.4858 (0.4359)  loss_classifier: 0.1664 (0.1541)  loss_box_reg: 0.1591 (0.1445)  loss_objectness: 0.0860 (0.1016)  loss_rpn_box_reg: 0.0202 (0.0356)  time: 0.2713  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [11]  [ 810/1229]  eta: 0:01:54  lr: 0.000500  loss: 0.4715 (0.4368)  loss_classifier: 0.1666 (0.1544)  loss_box_reg: 0.1591 (0.1450)  loss_objectness: 0.0748 (0.1016)  loss_rpn_box_reg: 0.0202 (0.0357)  time: 0.2666  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [11]  [ 820/1229]  eta: 0:01:51  lr: 0.000500  loss: 0.4270 (0.4369)  loss_classifier: 0.1719 (0.1545)  loss_box_reg: 0.1488 (0.1450)  loss_objectness: 0.0853 (0.1016)  loss_rpn_box_reg: 0.0233 (0.0358)  time: 0.2688  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [11]  [ 830/1229]  eta: 0:01:48  lr: 0.000500  loss: 0.4154 (0.4366)  loss_classifier: 0.1542 (0.1545)  loss_box_reg: 0.1450 (0.1449)  loss_objectness: 0.0817 (0.1014)  loss_rpn_box_reg: 0.0272 (0.0359)  time: 0.2688  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [11]  [ 840/1229]  eta: 0:01:46  lr: 0.000500  loss: 0.4136 (0.4367)  loss_classifier: 0.1542 (0.1545)  loss_box_reg: 0.1445 (0.1452)  loss_objectness: 0.0736 (0.1012)  loss_rpn_box_reg: 0.0237 (0.0359)  time: 0.2700  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [11]  [ 850/1229]  eta: 0:01:43  lr: 0.000500  loss: 0.5156 (0.4389)  loss_classifier: 0.1766 (0.1552)  loss_box_reg: 0.1718 (0.1458)  loss_objectness: 0.0879 (0.1015)  loss_rpn_box_reg: 0.0212 (0.0363)  time: 0.2755  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [11]  [ 860/1229]  eta: 0:01:40  lr: 0.000500  loss: 0.5624 (0.4413)  loss_classifier: 0.2228 (0.1561)  loss_box_reg: 0.1892 (0.1471)  loss_objectness: 0.1037 (0.1017)  loss_rpn_box_reg: 0.0273 (0.0365)  time: 0.2705  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [11]  [ 870/1229]  eta: 0:01:37  lr: 0.000500  loss: 0.5624 (0.4421)  loss_classifier: 0.2064 (0.1563)  loss_box_reg: 0.1892 (0.1477)  loss_objectness: 0.1087 (0.1017)  loss_rpn_box_reg: 0.0273 (0.0364)  time: 0.2697  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [11]  [ 880/1229]  eta: 0:01:35  lr: 0.000500  loss: 0.5132 (0.4422)  loss_classifier: 0.1647 (0.1563)  loss_box_reg: 0.1571 (0.1478)  loss_objectness: 0.0852 (0.1017)  loss_rpn_box_reg: 0.0183 (0.0364)  time: 0.2722  data: 0.1298  max mem: 1751\n",
      "Training Epoch: [11]  [ 890/1229]  eta: 0:01:32  lr: 0.000500  loss: 0.3544 (0.4428)  loss_classifier: 0.1357 (0.1566)  loss_box_reg: 0.1238 (0.1479)  loss_objectness: 0.0852 (0.1017)  loss_rpn_box_reg: 0.0297 (0.0365)  time: 0.2690  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [11]  [ 900/1229]  eta: 0:01:29  lr: 0.000500  loss: 0.5201 (0.4442)  loss_classifier: 0.1785 (0.1571)  loss_box_reg: 0.1680 (0.1487)  loss_objectness: 0.0970 (0.1018)  loss_rpn_box_reg: 0.0263 (0.0366)  time: 0.2723  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [11]  [ 910/1229]  eta: 0:01:26  lr: 0.000500  loss: 0.4922 (0.4444)  loss_classifier: 0.1614 (0.1571)  loss_box_reg: 0.1465 (0.1486)  loss_objectness: 0.1019 (0.1019)  loss_rpn_box_reg: 0.0273 (0.0369)  time: 0.2720  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [11]  [ 920/1229]  eta: 0:01:24  lr: 0.000500  loss: 0.4251 (0.4438)  loss_classifier: 0.1541 (0.1569)  loss_box_reg: 0.0922 (0.1482)  loss_objectness: 0.0954 (0.1019)  loss_rpn_box_reg: 0.0273 (0.0368)  time: 0.2696  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [11]  [ 930/1229]  eta: 0:01:21  lr: 0.000500  loss: 0.3831 (0.4438)  loss_classifier: 0.1133 (0.1569)  loss_box_reg: 0.1094 (0.1482)  loss_objectness: 0.0876 (0.1020)  loss_rpn_box_reg: 0.0163 (0.0367)  time: 0.2692  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [11]  [ 940/1229]  eta: 0:01:18  lr: 0.000500  loss: 0.3996 (0.4441)  loss_classifier: 0.1566 (0.1570)  loss_box_reg: 0.1372 (0.1483)  loss_objectness: 0.0830 (0.1021)  loss_rpn_box_reg: 0.0266 (0.0367)  time: 0.2740  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [11]  [ 950/1229]  eta: 0:01:16  lr: 0.000500  loss: 0.4968 (0.4449)  loss_classifier: 0.1770 (0.1573)  loss_box_reg: 0.1549 (0.1486)  loss_objectness: 0.1112 (0.1024)  loss_rpn_box_reg: 0.0238 (0.0366)  time: 0.2748  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [11]  [ 960/1229]  eta: 0:01:13  lr: 0.000500  loss: 0.3968 (0.4441)  loss_classifier: 0.1248 (0.1570)  loss_box_reg: 0.1335 (0.1481)  loss_objectness: 0.1112 (0.1026)  loss_rpn_box_reg: 0.0200 (0.0364)  time: 0.2685  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [11]  [ 970/1229]  eta: 0:01:10  lr: 0.000500  loss: 0.3531 (0.4442)  loss_classifier: 0.1248 (0.1570)  loss_box_reg: 0.1305 (0.1482)  loss_objectness: 0.0898 (0.1024)  loss_rpn_box_reg: 0.0201 (0.0366)  time: 0.2689  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [11]  [ 980/1229]  eta: 0:01:07  lr: 0.000500  loss: 0.3588 (0.4435)  loss_classifier: 0.1259 (0.1567)  loss_box_reg: 0.1359 (0.1480)  loss_objectness: 0.0715 (0.1024)  loss_rpn_box_reg: 0.0175 (0.0364)  time: 0.2693  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [11]  [ 990/1229]  eta: 0:01:05  lr: 0.000500  loss: 0.3637 (0.4432)  loss_classifier: 0.1440 (0.1567)  loss_box_reg: 0.1359 (0.1480)  loss_objectness: 0.0763 (0.1023)  loss_rpn_box_reg: 0.0144 (0.0363)  time: 0.2747  data: 0.1291  max mem: 1751\n",
      "Training Epoch: [11]  [1000/1229]  eta: 0:01:02  lr: 0.000500  loss: 0.3718 (0.4427)  loss_classifier: 0.1353 (0.1565)  loss_box_reg: 0.1127 (0.1476)  loss_objectness: 0.0767 (0.1024)  loss_rpn_box_reg: 0.0189 (0.0361)  time: 0.2741  data: 0.1289  max mem: 1751\n",
      "Training Epoch: [11]  [1010/1229]  eta: 0:00:59  lr: 0.000500  loss: 0.3762 (0.4427)  loss_classifier: 0.1343 (0.1566)  loss_box_reg: 0.1338 (0.1476)  loss_objectness: 0.0649 (0.1021)  loss_rpn_box_reg: 0.0244 (0.0363)  time: 0.2719  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [11]  [1020/1229]  eta: 0:00:56  lr: 0.000500  loss: 0.3773 (0.4419)  loss_classifier: 0.1254 (0.1564)  loss_box_reg: 0.1359 (0.1474)  loss_objectness: 0.0624 (0.1019)  loss_rpn_box_reg: 0.0244 (0.0361)  time: 0.2794  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [11]  [1030/1229]  eta: 0:00:54  lr: 0.000500  loss: 0.3139 (0.4411)  loss_classifier: 0.1154 (0.1561)  loss_box_reg: 0.0922 (0.1472)  loss_objectness: 0.0672 (0.1017)  loss_rpn_box_reg: 0.0132 (0.0361)  time: 0.2759  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [11]  [1040/1229]  eta: 0:00:51  lr: 0.000500  loss: 0.3305 (0.4403)  loss_classifier: 0.1224 (0.1558)  loss_box_reg: 0.0922 (0.1470)  loss_objectness: 0.0681 (0.1016)  loss_rpn_box_reg: 0.0142 (0.0360)  time: 0.2692  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [11]  [1050/1229]  eta: 0:00:48  lr: 0.000500  loss: 0.3426 (0.4399)  loss_classifier: 0.1241 (0.1556)  loss_box_reg: 0.0684 (0.1467)  loss_objectness: 0.0925 (0.1017)  loss_rpn_box_reg: 0.0142 (0.0358)  time: 0.2677  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [11]  [1060/1229]  eta: 0:00:46  lr: 0.000500  loss: 0.3426 (0.4395)  loss_classifier: 0.1315 (0.1555)  loss_box_reg: 0.0912 (0.1464)  loss_objectness: 0.0969 (0.1018)  loss_rpn_box_reg: 0.0168 (0.0358)  time: 0.2680  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [11]  [1070/1229]  eta: 0:00:43  lr: 0.000500  loss: 0.3375 (0.4392)  loss_classifier: 0.1315 (0.1554)  loss_box_reg: 0.1072 (0.1465)  loss_objectness: 0.0718 (0.1016)  loss_rpn_box_reg: 0.0152 (0.0357)  time: 0.2694  data: 0.1303  max mem: 1751\n",
      "Training Epoch: [11]  [1080/1229]  eta: 0:00:40  lr: 0.000500  loss: 0.4216 (0.4396)  loss_classifier: 0.1456 (0.1555)  loss_box_reg: 0.1079 (0.1467)  loss_objectness: 0.0748 (0.1017)  loss_rpn_box_reg: 0.0213 (0.0357)  time: 0.2686  data: 0.1292  max mem: 1751\n",
      "Training Epoch: [11]  [1090/1229]  eta: 0:00:37  lr: 0.000500  loss: 0.4957 (0.4404)  loss_classifier: 0.1646 (0.1558)  loss_box_reg: 0.1462 (0.1471)  loss_objectness: 0.0892 (0.1017)  loss_rpn_box_reg: 0.0260 (0.0357)  time: 0.2693  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [11]  [1100/1229]  eta: 0:00:35  lr: 0.000500  loss: 0.4957 (0.4404)  loss_classifier: 0.1649 (0.1560)  loss_box_reg: 0.1130 (0.1470)  loss_objectness: 0.0889 (0.1018)  loss_rpn_box_reg: 0.0189 (0.0356)  time: 0.2731  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [11]  [1110/1229]  eta: 0:00:32  lr: 0.000500  loss: 0.3353 (0.4398)  loss_classifier: 0.1192 (0.1558)  loss_box_reg: 0.0992 (0.1468)  loss_objectness: 0.0878 (0.1017)  loss_rpn_box_reg: 0.0226 (0.0355)  time: 0.2686  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [11]  [1120/1229]  eta: 0:00:29  lr: 0.000500  loss: 0.3414 (0.4393)  loss_classifier: 0.1175 (0.1555)  loss_box_reg: 0.0992 (0.1464)  loss_objectness: 0.0760 (0.1019)  loss_rpn_box_reg: 0.0234 (0.0355)  time: 0.2683  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [11]  [1130/1229]  eta: 0:00:26  lr: 0.000500  loss: 0.3656 (0.4391)  loss_classifier: 0.1242 (0.1555)  loss_box_reg: 0.0971 (0.1463)  loss_objectness: 0.0780 (0.1017)  loss_rpn_box_reg: 0.0193 (0.0356)  time: 0.2707  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [11]  [1140/1229]  eta: 0:00:24  lr: 0.000500  loss: 0.3811 (0.4397)  loss_classifier: 0.1569 (0.1557)  loss_box_reg: 0.1116 (0.1465)  loss_objectness: 0.0743 (0.1018)  loss_rpn_box_reg: 0.0248 (0.0356)  time: 0.2680  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [11]  [1150/1229]  eta: 0:00:21  lr: 0.000500  loss: 0.3715 (0.4396)  loss_classifier: 0.1276 (0.1556)  loss_box_reg: 0.1116 (0.1465)  loss_objectness: 0.0743 (0.1017)  loss_rpn_box_reg: 0.0251 (0.0357)  time: 0.2682  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [11]  [1160/1229]  eta: 0:00:18  lr: 0.000500  loss: 0.3221 (0.4388)  loss_classifier: 0.1250 (0.1554)  loss_box_reg: 0.1098 (0.1463)  loss_objectness: 0.0634 (0.1015)  loss_rpn_box_reg: 0.0210 (0.0356)  time: 0.2716  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [11]  [1170/1229]  eta: 0:00:16  lr: 0.000500  loss: 0.3507 (0.4390)  loss_classifier: 0.1261 (0.1555)  loss_box_reg: 0.1115 (0.1464)  loss_objectness: 0.0686 (0.1015)  loss_rpn_box_reg: 0.0218 (0.0356)  time: 0.2727  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [11]  [1180/1229]  eta: 0:00:13  lr: 0.000500  loss: 0.4022 (0.4391)  loss_classifier: 0.1438 (0.1555)  loss_box_reg: 0.1124 (0.1464)  loss_objectness: 0.1046 (0.1015)  loss_rpn_box_reg: 0.0213 (0.0357)  time: 0.2693  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [11]  [1190/1229]  eta: 0:00:10  lr: 0.000500  loss: 0.4364 (0.4392)  loss_classifier: 0.1705 (0.1556)  loss_box_reg: 0.1361 (0.1465)  loss_objectness: 0.0901 (0.1015)  loss_rpn_box_reg: 0.0174 (0.0356)  time: 0.2660  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [11]  [1200/1229]  eta: 0:00:07  lr: 0.000500  loss: 0.4412 (0.4399)  loss_classifier: 0.1615 (0.1556)  loss_box_reg: 0.1555 (0.1467)  loss_objectness: 0.0813 (0.1017)  loss_rpn_box_reg: 0.0228 (0.0358)  time: 0.2705  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [11]  [1210/1229]  eta: 0:00:05  lr: 0.000500  loss: 0.4106 (0.4401)  loss_classifier: 0.1393 (0.1557)  loss_box_reg: 0.1519 (0.1468)  loss_objectness: 0.0880 (0.1018)  loss_rpn_box_reg: 0.0228 (0.0357)  time: 0.2778  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [11]  [1220/1229]  eta: 0:00:02  lr: 0.000500  loss: 0.3672 (0.4399)  loss_classifier: 0.1393 (0.1557)  loss_box_reg: 0.1074 (0.1467)  loss_objectness: 0.0949 (0.1017)  loss_rpn_box_reg: 0.0234 (0.0357)  time: 0.2761  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [11]  [1228/1229]  eta: 0:00:00  lr: 0.000500  loss: 0.4000 (0.4400)  loss_classifier: 0.1411 (0.1558)  loss_box_reg: 0.1208 (0.1467)  loss_objectness: 0.0949 (0.1017)  loss_rpn_box_reg: 0.0283 (0.0357)  time: 0.2688  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [11] Total time: 0:05:34 (0.2722 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:52  model_time: 0.3270 (0.3270)  evaluator_time: 0.0020 (0.0020)  time: 0.3640  data: 0.0320  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0790 (0.0820)  evaluator_time: 0.0040 (0.0083)  time: 0.1258  data: 0.0355  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0820 (0.0806)  evaluator_time: 0.0030 (0.0076)  time: 0.1237  data: 0.0353  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0730 (0.0796)  evaluator_time: 0.0040 (0.0074)  time: 0.1236  data: 0.0403  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0720 (0.0795)  evaluator_time: 0.0020 (0.0074)  time: 0.1153  data: 0.0336  max mem: 1751\n",
      "Test: Total time: 0:00:37 (0.1232 s / it)\n",
      "Averaged stats: model_time: 0.0720 (0.0795)  evaluator_time: 0.0020 (0.0074)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.291\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.115\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.336\n",
      "Testing Epoch: [11]  [  0/308]  eta: 0:00:38  lr: 0.000500  loss: 0.1795 (0.1795)  loss_classifier: 0.0639 (0.0639)  loss_box_reg: 0.0682 (0.0682)  loss_objectness: 0.0355 (0.0355)  loss_rpn_box_reg: 0.0119 (0.0119)  time: 0.1250  data: 0.0290  max mem: 1751\n",
      "Testing Epoch: [11]  [100/308]  eta: 0:00:28  lr: 0.000500  loss: 0.3101 (0.4809)  loss_classifier: 0.1335 (0.1561)  loss_box_reg: 0.1093 (0.1732)  loss_objectness: 0.0535 (0.0993)  loss_rpn_box_reg: 0.0193 (0.0524)  time: 0.1387  data: 0.0370  max mem: 1751\n",
      "Testing Epoch: [11]  [200/308]  eta: 0:00:14  lr: 0.000500  loss: 0.3262 (0.4585)  loss_classifier: 0.1381 (0.1506)  loss_box_reg: 0.1224 (0.1651)  loss_objectness: 0.0619 (0.0934)  loss_rpn_box_reg: 0.0190 (0.0494)  time: 0.1367  data: 0.0321  max mem: 1751\n",
      "Testing Epoch: [11]  [300/308]  eta: 0:00:01  lr: 0.000500  loss: 0.4553 (0.4557)  loss_classifier: 0.1543 (0.1510)  loss_box_reg: 0.1731 (0.1658)  loss_objectness: 0.0715 (0.0912)  loss_rpn_box_reg: 0.0265 (0.0476)  time: 0.1369  data: 0.0420  max mem: 1751\n",
      "Testing Epoch: [11]  [307/308]  eta: 0:00:00  lr: 0.000500  loss: 0.4553 (0.4558)  loss_classifier: 0.1846 (0.1513)  loss_box_reg: 0.1691 (0.1660)  loss_objectness: 0.0762 (0.0913)  loss_rpn_box_reg: 0.0268 (0.0472)  time: 0.1299  data: 0.0354  max mem: 1751\n",
      "Testing Epoch: [11] Total time: 0:00:41 (0.1363 s / it)\n",
      "Training Epoch: [12]  [   0/1229]  eta: 0:06:05  lr: 0.000500  loss: 0.4793 (0.4793)  loss_classifier: 0.1063 (0.1063)  loss_box_reg: 0.0886 (0.0886)  loss_objectness: 0.1544 (0.1544)  loss_rpn_box_reg: 0.1301 (0.1301)  time: 0.2970  data: 0.1410  max mem: 1751\n",
      "Training Epoch: [12]  [  10/1229]  eta: 0:05:36  lr: 0.000500  loss: 0.3859 (0.4160)  loss_classifier: 0.1307 (0.1402)  loss_box_reg: 0.1260 (0.1385)  loss_objectness: 0.0924 (0.0853)  loss_rpn_box_reg: 0.0261 (0.0520)  time: 0.2764  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [12]  [  20/1229]  eta: 0:05:32  lr: 0.000500  loss: 0.3859 (0.4553)  loss_classifier: 0.1317 (0.1542)  loss_box_reg: 0.1342 (0.1485)  loss_objectness: 0.0894 (0.1071)  loss_rpn_box_reg: 0.0255 (0.0455)  time: 0.2738  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [12]  [  30/1229]  eta: 0:05:28  lr: 0.000500  loss: 0.4093 (0.4402)  loss_classifier: 0.1392 (0.1529)  loss_box_reg: 0.1185 (0.1411)  loss_objectness: 0.1097 (0.1066)  loss_rpn_box_reg: 0.0252 (0.0395)  time: 0.2720  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [12]  [  40/1229]  eta: 0:05:25  lr: 0.000500  loss: 0.4485 (0.4521)  loss_classifier: 0.1567 (0.1586)  loss_box_reg: 0.1249 (0.1517)  loss_objectness: 0.0976 (0.1054)  loss_rpn_box_reg: 0.0236 (0.0364)  time: 0.2734  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [12]  [  50/1229]  eta: 0:05:24  lr: 0.000500  loss: 0.4675 (0.4661)  loss_classifier: 0.1727 (0.1651)  loss_box_reg: 0.1571 (0.1601)  loss_objectness: 0.0969 (0.1067)  loss_rpn_box_reg: 0.0223 (0.0342)  time: 0.2782  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [12]  [  60/1229]  eta: 0:05:20  lr: 0.000500  loss: 0.4831 (0.4852)  loss_classifier: 0.1844 (0.1732)  loss_box_reg: 0.1709 (0.1671)  loss_objectness: 0.1217 (0.1123)  loss_rpn_box_reg: 0.0255 (0.0325)  time: 0.2753  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [12]  [  70/1229]  eta: 0:05:16  lr: 0.000500  loss: 0.4831 (0.4817)  loss_classifier: 0.1896 (0.1721)  loss_box_reg: 0.1652 (0.1662)  loss_objectness: 0.1013 (0.1123)  loss_rpn_box_reg: 0.0255 (0.0311)  time: 0.2662  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [12]  [  80/1229]  eta: 0:05:13  lr: 0.000500  loss: 0.4347 (0.4801)  loss_classifier: 0.1530 (0.1723)  loss_box_reg: 0.1195 (0.1621)  loss_objectness: 0.0857 (0.1125)  loss_rpn_box_reg: 0.0211 (0.0332)  time: 0.2663  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [12]  [  90/1229]  eta: 0:05:09  lr: 0.000500  loss: 0.4387 (0.4834)  loss_classifier: 0.1544 (0.1718)  loss_box_reg: 0.1306 (0.1636)  loss_objectness: 0.0804 (0.1133)  loss_rpn_box_reg: 0.0218 (0.0347)  time: 0.2697  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [12]  [ 100/1229]  eta: 0:05:07  lr: 0.000500  loss: 0.5163 (0.4826)  loss_classifier: 0.1652 (0.1721)  loss_box_reg: 0.1263 (0.1616)  loss_objectness: 0.1252 (0.1147)  loss_rpn_box_reg: 0.0246 (0.0341)  time: 0.2695  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [12]  [ 110/1229]  eta: 0:05:04  lr: 0.000500  loss: 0.3757 (0.4713)  loss_classifier: 0.1584 (0.1687)  loss_box_reg: 0.0975 (0.1573)  loss_objectness: 0.1006 (0.1126)  loss_rpn_box_reg: 0.0149 (0.0328)  time: 0.2699  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [12]  [ 120/1229]  eta: 0:05:02  lr: 0.000500  loss: 0.3334 (0.4648)  loss_classifier: 0.1265 (0.1674)  loss_box_reg: 0.0975 (0.1553)  loss_objectness: 0.0839 (0.1104)  loss_rpn_box_reg: 0.0149 (0.0317)  time: 0.2750  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [12]  [ 130/1229]  eta: 0:04:59  lr: 0.000500  loss: 0.3018 (0.4539)  loss_classifier: 0.1226 (0.1638)  loss_box_reg: 0.1076 (0.1512)  loss_objectness: 0.0778 (0.1085)  loss_rpn_box_reg: 0.0160 (0.0305)  time: 0.2767  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [12]  [ 140/1229]  eta: 0:04:56  lr: 0.000500  loss: 0.2866 (0.4501)  loss_classifier: 0.1049 (0.1613)  loss_box_reg: 0.0988 (0.1497)  loss_objectness: 0.0865 (0.1081)  loss_rpn_box_reg: 0.0136 (0.0309)  time: 0.2682  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [12]  [ 150/1229]  eta: 0:04:53  lr: 0.000500  loss: 0.2685 (0.4380)  loss_classifier: 0.0930 (0.1568)  loss_box_reg: 0.0912 (0.1450)  loss_objectness: 0.0870 (0.1066)  loss_rpn_box_reg: 0.0131 (0.0296)  time: 0.2685  data: 0.1286  max mem: 1751\n",
      "Training Epoch: [12]  [ 160/1229]  eta: 0:04:51  lr: 0.000500  loss: 0.2538 (0.4316)  loss_classifier: 0.0953 (0.1548)  loss_box_reg: 0.0775 (0.1426)  loss_objectness: 0.0647 (0.1042)  loss_rpn_box_reg: 0.0093 (0.0301)  time: 0.2761  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [12]  [ 170/1229]  eta: 0:04:48  lr: 0.000500  loss: 0.2538 (0.4241)  loss_classifier: 0.1017 (0.1519)  loss_box_reg: 0.0766 (0.1394)  loss_objectness: 0.0569 (0.1028)  loss_rpn_box_reg: 0.0153 (0.0300)  time: 0.2723  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [12]  [ 180/1229]  eta: 0:04:45  lr: 0.000500  loss: 0.2684 (0.4235)  loss_classifier: 0.1037 (0.1504)  loss_box_reg: 0.0780 (0.1377)  loss_objectness: 0.0853 (0.1040)  loss_rpn_box_reg: 0.0245 (0.0314)  time: 0.2667  data: 0.1288  max mem: 1751\n",
      "Training Epoch: [12]  [ 190/1229]  eta: 0:04:42  lr: 0.000500  loss: 0.3391 (0.4230)  loss_classifier: 0.1216 (0.1508)  loss_box_reg: 0.0959 (0.1376)  loss_objectness: 0.0930 (0.1034)  loss_rpn_box_reg: 0.0282 (0.0312)  time: 0.2679  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [12]  [ 200/1229]  eta: 0:04:39  lr: 0.000500  loss: 0.3408 (0.4219)  loss_classifier: 0.1168 (0.1505)  loss_box_reg: 0.0850 (0.1364)  loss_objectness: 0.0930 (0.1037)  loss_rpn_box_reg: 0.0172 (0.0312)  time: 0.2676  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [12]  [ 210/1229]  eta: 0:04:36  lr: 0.000500  loss: 0.3144 (0.4205)  loss_classifier: 0.1163 (0.1499)  loss_box_reg: 0.0963 (0.1368)  loss_objectness: 0.0881 (0.1026)  loss_rpn_box_reg: 0.0159 (0.0312)  time: 0.2734  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [12]  [ 220/1229]  eta: 0:04:34  lr: 0.000500  loss: 0.3253 (0.4262)  loss_classifier: 0.1295 (0.1519)  loss_box_reg: 0.1201 (0.1396)  loss_objectness: 0.0881 (0.1030)  loss_rpn_box_reg: 0.0181 (0.0318)  time: 0.2758  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [12]  [ 230/1229]  eta: 0:04:31  lr: 0.000500  loss: 0.4451 (0.4291)  loss_classifier: 0.1658 (0.1522)  loss_box_reg: 0.1351 (0.1412)  loss_objectness: 0.0926 (0.1028)  loss_rpn_box_reg: 0.0304 (0.0328)  time: 0.2741  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [12]  [ 240/1229]  eta: 0:04:28  lr: 0.000500  loss: 0.4671 (0.4299)  loss_classifier: 0.1555 (0.1524)  loss_box_reg: 0.1351 (0.1416)  loss_objectness: 0.0899 (0.1025)  loss_rpn_box_reg: 0.0342 (0.0333)  time: 0.2744  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [12]  [ 250/1229]  eta: 0:04:26  lr: 0.000500  loss: 0.4388 (0.4274)  loss_classifier: 0.1329 (0.1515)  loss_box_reg: 0.1271 (0.1417)  loss_objectness: 0.0695 (0.1015)  loss_rpn_box_reg: 0.0171 (0.0326)  time: 0.2697  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [12]  [ 260/1229]  eta: 0:04:23  lr: 0.000500  loss: 0.3033 (0.4234)  loss_classifier: 0.0995 (0.1501)  loss_box_reg: 0.0995 (0.1406)  loss_objectness: 0.0586 (0.1003)  loss_rpn_box_reg: 0.0171 (0.0324)  time: 0.2667  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [12]  [ 270/1229]  eta: 0:04:20  lr: 0.000500  loss: 0.3543 (0.4284)  loss_classifier: 0.1281 (0.1520)  loss_box_reg: 0.0995 (0.1421)  loss_objectness: 0.0724 (0.1009)  loss_rpn_box_reg: 0.0225 (0.0333)  time: 0.2667  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [12]  [ 280/1229]  eta: 0:04:17  lr: 0.000500  loss: 0.4139 (0.4309)  loss_classifier: 0.1702 (0.1521)  loss_box_reg: 0.1278 (0.1424)  loss_objectness: 0.0784 (0.1013)  loss_rpn_box_reg: 0.0296 (0.0351)  time: 0.2686  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [12]  [ 290/1229]  eta: 0:04:15  lr: 0.000500  loss: 0.5872 (0.4363)  loss_classifier: 0.1781 (0.1540)  loss_box_reg: 0.1396 (0.1444)  loss_objectness: 0.1252 (0.1023)  loss_rpn_box_reg: 0.0339 (0.0357)  time: 0.2748  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [12]  [ 300/1229]  eta: 0:04:12  lr: 0.000500  loss: 0.5872 (0.4404)  loss_classifier: 0.2152 (0.1553)  loss_box_reg: 0.1780 (0.1460)  loss_objectness: 0.1299 (0.1033)  loss_rpn_box_reg: 0.0284 (0.0358)  time: 0.2738  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [12]  [ 310/1229]  eta: 0:04:09  lr: 0.000500  loss: 0.5325 (0.4401)  loss_classifier: 0.1746 (0.1554)  loss_box_reg: 0.1580 (0.1464)  loss_objectness: 0.0982 (0.1030)  loss_rpn_box_reg: 0.0211 (0.0353)  time: 0.2698  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [12]  [ 320/1229]  eta: 0:04:06  lr: 0.000500  loss: 0.3999 (0.4381)  loss_classifier: 0.1465 (0.1548)  loss_box_reg: 0.1388 (0.1460)  loss_objectness: 0.0831 (0.1025)  loss_rpn_box_reg: 0.0159 (0.0348)  time: 0.2684  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [12]  [ 330/1229]  eta: 0:04:03  lr: 0.000500  loss: 0.3985 (0.4367)  loss_classifier: 0.1340 (0.1545)  loss_box_reg: 0.1154 (0.1452)  loss_objectness: 0.0909 (0.1026)  loss_rpn_box_reg: 0.0154 (0.0344)  time: 0.2695  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [12]  [ 340/1229]  eta: 0:04:01  lr: 0.000500  loss: 0.3836 (0.4383)  loss_classifier: 0.1334 (0.1549)  loss_box_reg: 0.1225 (0.1454)  loss_objectness: 0.0983 (0.1034)  loss_rpn_box_reg: 0.0223 (0.0346)  time: 0.2744  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [12]  [ 350/1229]  eta: 0:03:58  lr: 0.000500  loss: 0.3661 (0.4380)  loss_classifier: 0.1334 (0.1551)  loss_box_reg: 0.1240 (0.1458)  loss_objectness: 0.0769 (0.1028)  loss_rpn_box_reg: 0.0223 (0.0344)  time: 0.2755  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [12]  [ 360/1229]  eta: 0:03:56  lr: 0.000500  loss: 0.3757 (0.4415)  loss_classifier: 0.1445 (0.1563)  loss_box_reg: 0.1240 (0.1464)  loss_objectness: 0.0954 (0.1040)  loss_rpn_box_reg: 0.0293 (0.0347)  time: 0.2729  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [12]  [ 370/1229]  eta: 0:03:53  lr: 0.000500  loss: 0.4315 (0.4451)  loss_classifier: 0.1593 (0.1571)  loss_box_reg: 0.1298 (0.1476)  loss_objectness: 0.1181 (0.1048)  loss_rpn_box_reg: 0.0327 (0.0355)  time: 0.2703  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [12]  [ 380/1229]  eta: 0:03:50  lr: 0.000500  loss: 0.4305 (0.4453)  loss_classifier: 0.1418 (0.1574)  loss_box_reg: 0.1298 (0.1478)  loss_objectness: 0.0941 (0.1047)  loss_rpn_box_reg: 0.0160 (0.0353)  time: 0.2719  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [12]  [ 390/1229]  eta: 0:03:47  lr: 0.000500  loss: 0.3609 (0.4432)  loss_classifier: 0.1195 (0.1568)  loss_box_reg: 0.0793 (0.1464)  loss_objectness: 0.0890 (0.1047)  loss_rpn_box_reg: 0.0126 (0.0352)  time: 0.2719  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [12]  [ 400/1229]  eta: 0:03:45  lr: 0.000500  loss: 0.3543 (0.4442)  loss_classifier: 0.1215 (0.1574)  loss_box_reg: 0.0829 (0.1467)  loss_objectness: 0.0924 (0.1051)  loss_rpn_box_reg: 0.0234 (0.0350)  time: 0.2755  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [12]  [ 410/1229]  eta: 0:03:42  lr: 0.000500  loss: 0.2769 (0.4410)  loss_classifier: 0.0950 (0.1563)  loss_box_reg: 0.0897 (0.1454)  loss_objectness: 0.0616 (0.1042)  loss_rpn_box_reg: 0.0199 (0.0351)  time: 0.2809  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [12]  [ 420/1229]  eta: 0:03:39  lr: 0.000500  loss: 0.3585 (0.4425)  loss_classifier: 0.1283 (0.1568)  loss_box_reg: 0.1102 (0.1463)  loss_objectness: 0.0940 (0.1044)  loss_rpn_box_reg: 0.0199 (0.0349)  time: 0.2703  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [12]  [ 430/1229]  eta: 0:03:37  lr: 0.000500  loss: 0.4333 (0.4455)  loss_classifier: 0.1880 (0.1579)  loss_box_reg: 0.1479 (0.1475)  loss_objectness: 0.1042 (0.1048)  loss_rpn_box_reg: 0.0240 (0.0353)  time: 0.2648  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [12]  [ 440/1229]  eta: 0:03:34  lr: 0.000500  loss: 0.4060 (0.4443)  loss_classifier: 0.1453 (0.1575)  loss_box_reg: 0.1179 (0.1474)  loss_objectness: 0.0954 (0.1043)  loss_rpn_box_reg: 0.0246 (0.0351)  time: 0.2716  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [12]  [ 450/1229]  eta: 0:03:31  lr: 0.000500  loss: 0.4466 (0.4454)  loss_classifier: 0.1453 (0.1579)  loss_box_reg: 0.1311 (0.1477)  loss_objectness: 0.0961 (0.1047)  loss_rpn_box_reg: 0.0218 (0.0351)  time: 0.2701  data: 0.1303  max mem: 1751\n",
      "Training Epoch: [12]  [ 460/1229]  eta: 0:03:29  lr: 0.000500  loss: 0.3753 (0.4430)  loss_classifier: 0.1250 (0.1570)  loss_box_reg: 0.1207 (0.1465)  loss_objectness: 0.1059 (0.1045)  loss_rpn_box_reg: 0.0221 (0.0350)  time: 0.2734  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [12]  [ 470/1229]  eta: 0:03:26  lr: 0.000500  loss: 0.3082 (0.4410)  loss_classifier: 0.1086 (0.1565)  loss_box_reg: 0.0776 (0.1459)  loss_objectness: 0.0820 (0.1039)  loss_rpn_box_reg: 0.0221 (0.0347)  time: 0.2802  data: 0.1288  max mem: 1751\n",
      "Training Epoch: [12]  [ 480/1229]  eta: 0:03:23  lr: 0.000500  loss: 0.3050 (0.4407)  loss_classifier: 0.1124 (0.1563)  loss_box_reg: 0.1097 (0.1461)  loss_objectness: 0.0733 (0.1036)  loss_rpn_box_reg: 0.0230 (0.0347)  time: 0.2733  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [12]  [ 490/1229]  eta: 0:03:20  lr: 0.000500  loss: 0.3481 (0.4413)  loss_classifier: 0.1302 (0.1567)  loss_box_reg: 0.1195 (0.1463)  loss_objectness: 0.0713 (0.1037)  loss_rpn_box_reg: 0.0189 (0.0346)  time: 0.2665  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [12]  [ 500/1229]  eta: 0:03:17  lr: 0.000500  loss: 0.3668 (0.4413)  loss_classifier: 0.1449 (0.1568)  loss_box_reg: 0.1235 (0.1462)  loss_objectness: 0.0982 (0.1039)  loss_rpn_box_reg: 0.0179 (0.0344)  time: 0.2651  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [12]  [ 510/1229]  eta: 0:03:15  lr: 0.000500  loss: 0.4222 (0.4409)  loss_classifier: 0.1449 (0.1565)  loss_box_reg: 0.1271 (0.1462)  loss_objectness: 0.0751 (0.1038)  loss_rpn_box_reg: 0.0184 (0.0343)  time: 0.2683  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [12]  [ 520/1229]  eta: 0:03:12  lr: 0.000500  loss: 0.4443 (0.4405)  loss_classifier: 0.1503 (0.1564)  loss_box_reg: 0.1471 (0.1462)  loss_objectness: 0.0726 (0.1036)  loss_rpn_box_reg: 0.0234 (0.0342)  time: 0.2717  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [12]  [ 530/1229]  eta: 0:03:09  lr: 0.000500  loss: 0.4178 (0.4401)  loss_classifier: 0.1454 (0.1563)  loss_box_reg: 0.1575 (0.1463)  loss_objectness: 0.0823 (0.1034)  loss_rpn_box_reg: 0.0227 (0.0342)  time: 0.2693  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [12]  [ 540/1229]  eta: 0:03:07  lr: 0.000500  loss: 0.3020 (0.4383)  loss_classifier: 0.1018 (0.1557)  loss_box_reg: 0.0671 (0.1459)  loss_objectness: 0.0561 (0.1028)  loss_rpn_box_reg: 0.0125 (0.0338)  time: 0.2673  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [12]  [ 550/1229]  eta: 0:03:04  lr: 0.000500  loss: 0.2532 (0.4381)  loss_classifier: 0.0855 (0.1554)  loss_box_reg: 0.0671 (0.1459)  loss_objectness: 0.0611 (0.1026)  loss_rpn_box_reg: 0.0092 (0.0341)  time: 0.2704  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [12]  [ 560/1229]  eta: 0:03:01  lr: 0.000500  loss: 0.4033 (0.4398)  loss_classifier: 0.1553 (0.1559)  loss_box_reg: 0.1652 (0.1469)  loss_objectness: 0.0730 (0.1023)  loss_rpn_box_reg: 0.0189 (0.0347)  time: 0.2758  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [12]  [ 570/1229]  eta: 0:02:59  lr: 0.000500  loss: 0.4226 (0.4390)  loss_classifier: 0.1553 (0.1557)  loss_box_reg: 0.1100 (0.1461)  loss_objectness: 0.0916 (0.1027)  loss_rpn_box_reg: 0.0233 (0.0345)  time: 0.2753  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [12]  [ 580/1229]  eta: 0:02:56  lr: 0.000500  loss: 0.3230 (0.4375)  loss_classifier: 0.1229 (0.1552)  loss_box_reg: 0.0950 (0.1458)  loss_objectness: 0.0750 (0.1020)  loss_rpn_box_reg: 0.0115 (0.0345)  time: 0.2753  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [12]  [ 590/1229]  eta: 0:02:53  lr: 0.000500  loss: 0.3230 (0.4384)  loss_classifier: 0.1229 (0.1556)  loss_box_reg: 0.0994 (0.1462)  loss_objectness: 0.0685 (0.1022)  loss_rpn_box_reg: 0.0215 (0.0344)  time: 0.2722  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [12]  [ 600/1229]  eta: 0:02:50  lr: 0.000500  loss: 0.4477 (0.4402)  loss_classifier: 0.1721 (0.1562)  loss_box_reg: 0.1594 (0.1471)  loss_objectness: 0.0862 (0.1023)  loss_rpn_box_reg: 0.0279 (0.0346)  time: 0.2711  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [12]  [ 610/1229]  eta: 0:02:48  lr: 0.000500  loss: 0.4477 (0.4404)  loss_classifier: 0.1505 (0.1561)  loss_box_reg: 0.1700 (0.1471)  loss_objectness: 0.0818 (0.1025)  loss_rpn_box_reg: 0.0356 (0.0347)  time: 0.2722  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [12]  [ 620/1229]  eta: 0:02:45  lr: 0.000500  loss: 0.4148 (0.4415)  loss_classifier: 0.1482 (0.1564)  loss_box_reg: 0.1627 (0.1477)  loss_objectness: 0.0868 (0.1025)  loss_rpn_box_reg: 0.0197 (0.0348)  time: 0.2717  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [12]  [ 630/1229]  eta: 0:02:42  lr: 0.000500  loss: 0.3632 (0.4399)  loss_classifier: 0.1342 (0.1559)  loss_box_reg: 0.1331 (0.1470)  loss_objectness: 0.0864 (0.1023)  loss_rpn_box_reg: 0.0193 (0.0347)  time: 0.2716  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [12]  [ 640/1229]  eta: 0:02:40  lr: 0.000500  loss: 0.3606 (0.4413)  loss_classifier: 0.1342 (0.1562)  loss_box_reg: 0.1331 (0.1479)  loss_objectness: 0.0654 (0.1022)  loss_rpn_box_reg: 0.0191 (0.0349)  time: 0.2716  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [12]  [ 650/1229]  eta: 0:02:37  lr: 0.000500  loss: 0.4868 (0.4404)  loss_classifier: 0.1519 (0.1559)  loss_box_reg: 0.1366 (0.1473)  loss_objectness: 0.1033 (0.1022)  loss_rpn_box_reg: 0.0232 (0.0349)  time: 0.2771  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [12]  [ 660/1229]  eta: 0:02:34  lr: 0.000500  loss: 0.4017 (0.4401)  loss_classifier: 0.1267 (0.1559)  loss_box_reg: 0.1141 (0.1473)  loss_objectness: 0.0869 (0.1019)  loss_rpn_box_reg: 0.0236 (0.0350)  time: 0.2814  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [12]  [ 670/1229]  eta: 0:02:32  lr: 0.000500  loss: 0.4207 (0.4404)  loss_classifier: 0.1331 (0.1560)  loss_box_reg: 0.1187 (0.1475)  loss_objectness: 0.0798 (0.1018)  loss_rpn_box_reg: 0.0248 (0.0351)  time: 0.2798  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [12]  [ 680/1229]  eta: 0:02:29  lr: 0.000500  loss: 0.4487 (0.4418)  loss_classifier: 0.1768 (0.1565)  loss_box_reg: 0.1501 (0.1482)  loss_objectness: 0.1023 (0.1018)  loss_rpn_box_reg: 0.0322 (0.0352)  time: 0.2757  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [12]  [ 690/1229]  eta: 0:02:26  lr: 0.000500  loss: 0.4487 (0.4418)  loss_classifier: 0.1768 (0.1567)  loss_box_reg: 0.1501 (0.1482)  loss_objectness: 0.1023 (0.1020)  loss_rpn_box_reg: 0.0202 (0.0350)  time: 0.2790  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [12]  [ 700/1229]  eta: 0:02:24  lr: 0.000500  loss: 0.4354 (0.4433)  loss_classifier: 0.1561 (0.1573)  loss_box_reg: 0.1863 (0.1491)  loss_objectness: 0.0797 (0.1019)  loss_rpn_box_reg: 0.0190 (0.0350)  time: 0.2783  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [12]  [ 710/1229]  eta: 0:02:21  lr: 0.000500  loss: 0.4354 (0.4434)  loss_classifier: 0.1511 (0.1573)  loss_box_reg: 0.1367 (0.1489)  loss_objectness: 0.0779 (0.1020)  loss_rpn_box_reg: 0.0228 (0.0352)  time: 0.2696  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [12]  [ 720/1229]  eta: 0:02:18  lr: 0.000500  loss: 0.3034 (0.4424)  loss_classifier: 0.1232 (0.1571)  loss_box_reg: 0.1052 (0.1486)  loss_objectness: 0.0779 (0.1017)  loss_rpn_box_reg: 0.0169 (0.0350)  time: 0.2739  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [12]  [ 730/1229]  eta: 0:02:15  lr: 0.000500  loss: 0.3886 (0.4420)  loss_classifier: 0.1437 (0.1570)  loss_box_reg: 0.1096 (0.1488)  loss_objectness: 0.0819 (0.1014)  loss_rpn_box_reg: 0.0156 (0.0347)  time: 0.2780  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [12]  [ 740/1229]  eta: 0:02:13  lr: 0.000500  loss: 0.3966 (0.4415)  loss_classifier: 0.1425 (0.1566)  loss_box_reg: 0.1096 (0.1485)  loss_objectness: 0.0775 (0.1013)  loss_rpn_box_reg: 0.0177 (0.0350)  time: 0.2686  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [12]  [ 750/1229]  eta: 0:02:10  lr: 0.000500  loss: 0.3154 (0.4399)  loss_classifier: 0.0993 (0.1561)  loss_box_reg: 0.0950 (0.1480)  loss_objectness: 0.0746 (0.1011)  loss_rpn_box_reg: 0.0184 (0.0347)  time: 0.2634  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [12]  [ 760/1229]  eta: 0:02:07  lr: 0.000500  loss: 0.3665 (0.4411)  loss_classifier: 0.1299 (0.1566)  loss_box_reg: 0.1221 (0.1484)  loss_objectness: 0.0977 (0.1014)  loss_rpn_box_reg: 0.0194 (0.0347)  time: 0.2700  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [12]  [ 770/1229]  eta: 0:02:04  lr: 0.000500  loss: 0.4079 (0.4404)  loss_classifier: 0.1534 (0.1563)  loss_box_reg: 0.1276 (0.1482)  loss_objectness: 0.0927 (0.1011)  loss_rpn_box_reg: 0.0184 (0.0347)  time: 0.2772  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [12]  [ 780/1229]  eta: 0:02:02  lr: 0.000500  loss: 0.3419 (0.4397)  loss_classifier: 0.1305 (0.1562)  loss_box_reg: 0.0987 (0.1478)  loss_objectness: 0.0655 (0.1009)  loss_rpn_box_reg: 0.0176 (0.0349)  time: 0.2773  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [12]  [ 790/1229]  eta: 0:01:59  lr: 0.000500  loss: 0.3684 (0.4395)  loss_classifier: 0.1305 (0.1561)  loss_box_reg: 0.1011 (0.1481)  loss_objectness: 0.0760 (0.1007)  loss_rpn_box_reg: 0.0196 (0.0346)  time: 0.2717  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [12]  [ 800/1229]  eta: 0:01:56  lr: 0.000500  loss: 0.3166 (0.4391)  loss_classifier: 0.1206 (0.1558)  loss_box_reg: 0.0934 (0.1478)  loss_objectness: 0.0851 (0.1007)  loss_rpn_box_reg: 0.0179 (0.0347)  time: 0.2675  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [12]  [ 810/1229]  eta: 0:01:54  lr: 0.000500  loss: 0.3249 (0.4381)  loss_classifier: 0.1206 (0.1556)  loss_box_reg: 0.0946 (0.1474)  loss_objectness: 0.0851 (0.1005)  loss_rpn_box_reg: 0.0172 (0.0346)  time: 0.2662  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [12]  [ 820/1229]  eta: 0:01:51  lr: 0.000500  loss: 0.3813 (0.4386)  loss_classifier: 0.1431 (0.1558)  loss_box_reg: 0.1113 (0.1476)  loss_objectness: 0.0993 (0.1006)  loss_rpn_box_reg: 0.0221 (0.0346)  time: 0.2649  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [12]  [ 830/1229]  eta: 0:01:48  lr: 0.000500  loss: 0.4066 (0.4403)  loss_classifier: 0.1650 (0.1564)  loss_box_reg: 0.1370 (0.1484)  loss_objectness: 0.1116 (0.1009)  loss_rpn_box_reg: 0.0339 (0.0346)  time: 0.2672  data: 0.1300  max mem: 1751\n",
      "Training Epoch: [12]  [ 840/1229]  eta: 0:01:45  lr: 0.000500  loss: 0.5819 (0.4412)  loss_classifier: 0.1801 (0.1568)  loss_box_reg: 0.1758 (0.1486)  loss_objectness: 0.1165 (0.1011)  loss_rpn_box_reg: 0.0339 (0.0347)  time: 0.2670  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [12]  [ 850/1229]  eta: 0:01:43  lr: 0.000500  loss: 0.4234 (0.4414)  loss_classifier: 0.1611 (0.1570)  loss_box_reg: 0.1384 (0.1486)  loss_objectness: 0.1105 (0.1012)  loss_rpn_box_reg: 0.0271 (0.0346)  time: 0.2678  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [12]  [ 860/1229]  eta: 0:01:40  lr: 0.000500  loss: 0.4234 (0.4418)  loss_classifier: 0.1544 (0.1572)  loss_box_reg: 0.1011 (0.1484)  loss_objectness: 0.0926 (0.1013)  loss_rpn_box_reg: 0.0281 (0.0349)  time: 0.2723  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [12]  [ 870/1229]  eta: 0:01:37  lr: 0.000500  loss: 0.3830 (0.4402)  loss_classifier: 0.1335 (0.1567)  loss_box_reg: 0.0985 (0.1477)  loss_objectness: 0.0839 (0.1011)  loss_rpn_box_reg: 0.0216 (0.0347)  time: 0.2736  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [12]  [ 880/1229]  eta: 0:01:34  lr: 0.000500  loss: 0.3446 (0.4404)  loss_classifier: 0.1335 (0.1568)  loss_box_reg: 0.1058 (0.1477)  loss_objectness: 0.0821 (0.1012)  loss_rpn_box_reg: 0.0174 (0.0347)  time: 0.2678  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [12]  [ 890/1229]  eta: 0:01:32  lr: 0.000500  loss: 0.4173 (0.4401)  loss_classifier: 0.1509 (0.1567)  loss_box_reg: 0.1451 (0.1477)  loss_objectness: 0.0777 (0.1011)  loss_rpn_box_reg: 0.0247 (0.0346)  time: 0.2689  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [12]  [ 900/1229]  eta: 0:01:29  lr: 0.000500  loss: 0.3903 (0.4403)  loss_classifier: 0.1427 (0.1567)  loss_box_reg: 0.1451 (0.1477)  loss_objectness: 0.1018 (0.1013)  loss_rpn_box_reg: 0.0219 (0.0345)  time: 0.2753  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [12]  [ 910/1229]  eta: 0:01:26  lr: 0.000500  loss: 0.4010 (0.4405)  loss_classifier: 0.1448 (0.1569)  loss_box_reg: 0.1355 (0.1478)  loss_objectness: 0.1018 (0.1013)  loss_rpn_box_reg: 0.0226 (0.0345)  time: 0.2708  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [12]  [ 920/1229]  eta: 0:01:24  lr: 0.000500  loss: 0.3767 (0.4410)  loss_classifier: 0.1448 (0.1569)  loss_box_reg: 0.1316 (0.1479)  loss_objectness: 0.0767 (0.1014)  loss_rpn_box_reg: 0.0230 (0.0347)  time: 0.2740  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [12]  [ 930/1229]  eta: 0:01:21  lr: 0.000500  loss: 0.3997 (0.4409)  loss_classifier: 0.1400 (0.1568)  loss_box_reg: 0.1087 (0.1476)  loss_objectness: 0.0920 (0.1016)  loss_rpn_box_reg: 0.0259 (0.0348)  time: 0.2745  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [12]  [ 940/1229]  eta: 0:01:18  lr: 0.000500  loss: 0.4270 (0.4413)  loss_classifier: 0.1444 (0.1570)  loss_box_reg: 0.0982 (0.1476)  loss_objectness: 0.1166 (0.1019)  loss_rpn_box_reg: 0.0259 (0.0348)  time: 0.2671  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [12]  [ 950/1229]  eta: 0:01:15  lr: 0.000500  loss: 0.3655 (0.4407)  loss_classifier: 0.1302 (0.1568)  loss_box_reg: 0.0840 (0.1473)  loss_objectness: 0.0928 (0.1018)  loss_rpn_box_reg: 0.0224 (0.0348)  time: 0.2711  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [12]  [ 960/1229]  eta: 0:01:13  lr: 0.000500  loss: 0.3885 (0.4410)  loss_classifier: 0.1477 (0.1570)  loss_box_reg: 0.1284 (0.1474)  loss_objectness: 0.0894 (0.1019)  loss_rpn_box_reg: 0.0224 (0.0347)  time: 0.2722  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [12]  [ 970/1229]  eta: 0:01:10  lr: 0.000500  loss: 0.3472 (0.4408)  loss_classifier: 0.1404 (0.1568)  loss_box_reg: 0.1183 (0.1474)  loss_objectness: 0.0916 (0.1018)  loss_rpn_box_reg: 0.0198 (0.0347)  time: 0.2650  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [12]  [ 980/1229]  eta: 0:01:07  lr: 0.000500  loss: 0.3747 (0.4409)  loss_classifier: 0.1327 (0.1569)  loss_box_reg: 0.1157 (0.1476)  loss_objectness: 0.1008 (0.1018)  loss_rpn_box_reg: 0.0191 (0.0346)  time: 0.2669  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [12]  [ 990/1229]  eta: 0:01:04  lr: 0.000500  loss: 0.4023 (0.4414)  loss_classifier: 0.1209 (0.1571)  loss_box_reg: 0.1185 (0.1479)  loss_objectness: 0.0732 (0.1015)  loss_rpn_box_reg: 0.0245 (0.0349)  time: 0.2707  data: 0.1293  max mem: 1751\n",
      "Training Epoch: [12]  [1000/1229]  eta: 0:01:02  lr: 0.000500  loss: 0.3942 (0.4413)  loss_classifier: 0.1209 (0.1569)  loss_box_reg: 0.1185 (0.1477)  loss_objectness: 0.0786 (0.1016)  loss_rpn_box_reg: 0.0297 (0.0351)  time: 0.2695  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [12]  [1010/1229]  eta: 0:00:59  lr: 0.000500  loss: 0.3942 (0.4403)  loss_classifier: 0.1216 (0.1565)  loss_box_reg: 0.1017 (0.1472)  loss_objectness: 0.1016 (0.1016)  loss_rpn_box_reg: 0.0189 (0.0349)  time: 0.2665  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [12]  [1020/1229]  eta: 0:00:56  lr: 0.000500  loss: 0.3551 (0.4398)  loss_classifier: 0.1216 (0.1563)  loss_box_reg: 0.0870 (0.1468)  loss_objectness: 0.0775 (0.1014)  loss_rpn_box_reg: 0.0166 (0.0353)  time: 0.2683  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [12]  [1030/1229]  eta: 0:00:54  lr: 0.000500  loss: 0.3003 (0.4395)  loss_classifier: 0.1174 (0.1562)  loss_box_reg: 0.0859 (0.1470)  loss_objectness: 0.0721 (0.1012)  loss_rpn_box_reg: 0.0167 (0.0352)  time: 0.2752  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [12]  [1040/1229]  eta: 0:00:51  lr: 0.000500  loss: 0.3267 (0.4390)  loss_classifier: 0.1284 (0.1560)  loss_box_reg: 0.0925 (0.1466)  loss_objectness: 0.0742 (0.1012)  loss_rpn_box_reg: 0.0230 (0.0353)  time: 0.2754  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [12]  [1050/1229]  eta: 0:00:48  lr: 0.000500  loss: 0.3749 (0.4383)  loss_classifier: 0.1342 (0.1558)  loss_box_reg: 0.0980 (0.1464)  loss_objectness: 0.0718 (0.1009)  loss_rpn_box_reg: 0.0174 (0.0352)  time: 0.2805  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [12]  [1060/1229]  eta: 0:00:45  lr: 0.000500  loss: 0.4292 (0.4388)  loss_classifier: 0.1624 (0.1560)  loss_box_reg: 0.1210 (0.1464)  loss_objectness: 0.0800 (0.1011)  loss_rpn_box_reg: 0.0180 (0.0353)  time: 0.2819  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [12]  [1070/1229]  eta: 0:00:43  lr: 0.000500  loss: 0.3973 (0.4390)  loss_classifier: 0.1483 (0.1561)  loss_box_reg: 0.1210 (0.1462)  loss_objectness: 0.1023 (0.1015)  loss_rpn_box_reg: 0.0301 (0.0352)  time: 0.2716  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [12]  [1080/1229]  eta: 0:00:40  lr: 0.000500  loss: 0.3834 (0.4383)  loss_classifier: 0.1438 (0.1559)  loss_box_reg: 0.1025 (0.1458)  loss_objectness: 0.1023 (0.1015)  loss_rpn_box_reg: 0.0208 (0.0351)  time: 0.2710  data: 0.1296  max mem: 1751\n",
      "Training Epoch: [12]  [1090/1229]  eta: 0:00:37  lr: 0.000500  loss: 0.3957 (0.4388)  loss_classifier: 0.1366 (0.1560)  loss_box_reg: 0.1328 (0.1463)  loss_objectness: 0.0856 (0.1015)  loss_rpn_box_reg: 0.0172 (0.0350)  time: 0.2765  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [12]  [1100/1229]  eta: 0:00:35  lr: 0.000500  loss: 0.3744 (0.4385)  loss_classifier: 0.1366 (0.1559)  loss_box_reg: 0.1331 (0.1461)  loss_objectness: 0.0798 (0.1014)  loss_rpn_box_reg: 0.0188 (0.0350)  time: 0.2775  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [12]  [1110/1229]  eta: 0:00:32  lr: 0.000500  loss: 0.3744 (0.4390)  loss_classifier: 0.1410 (0.1561)  loss_box_reg: 0.1115 (0.1465)  loss_objectness: 0.0736 (0.1014)  loss_rpn_box_reg: 0.0230 (0.0350)  time: 0.2804  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [12]  [1120/1229]  eta: 0:00:29  lr: 0.000500  loss: 0.3103 (0.4376)  loss_classifier: 0.1287 (0.1557)  loss_box_reg: 0.1043 (0.1460)  loss_objectness: 0.0652 (0.1011)  loss_rpn_box_reg: 0.0230 (0.0349)  time: 0.2789  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [12]  [1130/1229]  eta: 0:00:26  lr: 0.000500  loss: 0.2857 (0.4373)  loss_classifier: 0.1097 (0.1556)  loss_box_reg: 0.0969 (0.1460)  loss_objectness: 0.0598 (0.1009)  loss_rpn_box_reg: 0.0135 (0.0347)  time: 0.2747  data: 0.1303  max mem: 1751\n",
      "Training Epoch: [12]  [1140/1229]  eta: 0:00:24  lr: 0.000500  loss: 0.3167 (0.4373)  loss_classifier: 0.1174 (0.1556)  loss_box_reg: 0.1137 (0.1460)  loss_objectness: 0.0752 (0.1010)  loss_rpn_box_reg: 0.0129 (0.0347)  time: 0.2708  data: 0.1294  max mem: 1751\n",
      "Training Epoch: [12]  [1150/1229]  eta: 0:00:21  lr: 0.000500  loss: 0.3593 (0.4369)  loss_classifier: 0.1427 (0.1555)  loss_box_reg: 0.1180 (0.1458)  loss_objectness: 0.0760 (0.1010)  loss_rpn_box_reg: 0.0180 (0.0347)  time: 0.2743  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [12]  [1160/1229]  eta: 0:00:18  lr: 0.000500  loss: 0.4049 (0.4375)  loss_classifier: 0.1469 (0.1557)  loss_box_reg: 0.1282 (0.1458)  loss_objectness: 0.0997 (0.1012)  loss_rpn_box_reg: 0.0255 (0.0348)  time: 0.2786  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [12]  [1170/1229]  eta: 0:00:16  lr: 0.000500  loss: 0.4580 (0.4382)  loss_classifier: 0.1735 (0.1560)  loss_box_reg: 0.1311 (0.1461)  loss_objectness: 0.1215 (0.1013)  loss_rpn_box_reg: 0.0422 (0.0348)  time: 0.2741  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [12]  [1180/1229]  eta: 0:00:13  lr: 0.000500  loss: 0.3693 (0.4379)  loss_classifier: 0.1265 (0.1558)  loss_box_reg: 0.1202 (0.1459)  loss_objectness: 0.0989 (0.1013)  loss_rpn_box_reg: 0.0309 (0.0349)  time: 0.2710  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [12]  [1190/1229]  eta: 0:00:10  lr: 0.000500  loss: 0.3510 (0.4374)  loss_classifier: 0.1236 (0.1557)  loss_box_reg: 0.1202 (0.1457)  loss_objectness: 0.0928 (0.1012)  loss_rpn_box_reg: 0.0256 (0.0348)  time: 0.2679  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [12]  [1200/1229]  eta: 0:00:07  lr: 0.000500  loss: 0.3747 (0.4388)  loss_classifier: 0.1466 (0.1561)  loss_box_reg: 0.1231 (0.1462)  loss_objectness: 0.0931 (0.1015)  loss_rpn_box_reg: 0.0273 (0.0350)  time: 0.2698  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [12]  [1210/1229]  eta: 0:00:05  lr: 0.000500  loss: 0.4280 (0.4391)  loss_classifier: 0.1696 (0.1562)  loss_box_reg: 0.1307 (0.1464)  loss_objectness: 0.0991 (0.1016)  loss_rpn_box_reg: 0.0204 (0.0349)  time: 0.2734  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [12]  [1220/1229]  eta: 0:00:02  lr: 0.000500  loss: 0.3625 (0.4391)  loss_classifier: 0.1464 (0.1562)  loss_box_reg: 0.1434 (0.1466)  loss_objectness: 0.0792 (0.1013)  loss_rpn_box_reg: 0.0203 (0.0349)  time: 0.2753  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [12]  [1228/1229]  eta: 0:00:00  lr: 0.000500  loss: 0.3857 (0.4386)  loss_classifier: 0.1371 (0.1560)  loss_box_reg: 0.1198 (0.1465)  loss_objectness: 0.0797 (0.1012)  loss_rpn_box_reg: 0.0209 (0.0349)  time: 0.2737  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [12] Total time: 0:05:34 (0.2722 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:56  model_time: 0.3430 (0.3430)  evaluator_time: 0.0010 (0.0010)  time: 0.3770  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0780 (0.0827)  evaluator_time: 0.0040 (0.0085)  time: 0.1267  data: 0.0356  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0820 (0.0810)  evaluator_time: 0.0030 (0.0077)  time: 0.1194  data: 0.0306  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0730 (0.0802)  evaluator_time: 0.0040 (0.0075)  time: 0.1194  data: 0.0351  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0730 (0.0800)  evaluator_time: 0.0020 (0.0075)  time: 0.1165  data: 0.0337  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1236 s / it)\n",
      "Averaged stats: model_time: 0.0730 (0.0800)  evaluator_time: 0.0020 (0.0075)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.284\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.118\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [12]  [  0/308]  eta: 0:00:40  lr: 0.000500  loss: 0.1717 (0.1717)  loss_classifier: 0.0615 (0.0615)  loss_box_reg: 0.0683 (0.0683)  loss_objectness: 0.0291 (0.0291)  loss_rpn_box_reg: 0.0127 (0.0127)  time: 0.1310  data: 0.0270  max mem: 1751\n",
      "Testing Epoch: [12]  [100/308]  eta: 0:00:28  lr: 0.000500  loss: 0.3148 (0.4844)  loss_classifier: 0.1333 (0.1558)  loss_box_reg: 0.1191 (0.1734)  loss_objectness: 0.0581 (0.1029)  loss_rpn_box_reg: 0.0190 (0.0523)  time: 0.1391  data: 0.0376  max mem: 1751\n",
      "Testing Epoch: [12]  [200/308]  eta: 0:00:14  lr: 0.000500  loss: 0.3447 (0.4582)  loss_classifier: 0.1461 (0.1502)  loss_box_reg: 0.1321 (0.1635)  loss_objectness: 0.0663 (0.0952)  loss_rpn_box_reg: 0.0201 (0.0494)  time: 0.1379  data: 0.0323  max mem: 1751\n",
      "Testing Epoch: [12]  [300/308]  eta: 0:00:01  lr: 0.000500  loss: 0.4745 (0.4555)  loss_classifier: 0.1534 (0.1505)  loss_box_reg: 0.1710 (0.1643)  loss_objectness: 0.0780 (0.0929)  loss_rpn_box_reg: 0.0261 (0.0478)  time: 0.1326  data: 0.0380  max mem: 1751\n",
      "Testing Epoch: [12]  [307/308]  eta: 0:00:00  lr: 0.000500  loss: 0.4745 (0.4558)  loss_classifier: 0.1927 (0.1507)  loss_box_reg: 0.1809 (0.1647)  loss_objectness: 0.0742 (0.0930)  loss_rpn_box_reg: 0.0281 (0.0473)  time: 0.1301  data: 0.0357  max mem: 1751\n",
      "Testing Epoch: [12] Total time: 0:00:42 (0.1370 s / it)\n",
      "Training Epoch: [13]  [   0/1229]  eta: 0:05:13  lr: 0.000050  loss: 0.4427 (0.4427)  loss_classifier: 0.1934 (0.1934)  loss_box_reg: 0.1428 (0.1428)  loss_objectness: 0.1004 (0.1004)  loss_rpn_box_reg: 0.0062 (0.0062)  time: 0.2550  data: 0.1230  max mem: 1751\n",
      "Training Epoch: [13]  [  10/1229]  eta: 0:05:21  lr: 0.000050  loss: 0.3062 (0.4230)  loss_classifier: 0.1266 (0.1617)  loss_box_reg: 0.1204 (0.1524)  loss_objectness: 0.0816 (0.0894)  loss_rpn_box_reg: 0.0146 (0.0195)  time: 0.2637  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [13]  [  20/1229]  eta: 0:05:23  lr: 0.000050  loss: 0.3596 (0.4387)  loss_classifier: 0.1421 (0.1662)  loss_box_reg: 0.1204 (0.1495)  loss_objectness: 0.0816 (0.0975)  loss_rpn_box_reg: 0.0169 (0.0256)  time: 0.2683  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [13]  [  30/1229]  eta: 0:05:24  lr: 0.000050  loss: 0.4600 (0.4431)  loss_classifier: 0.1593 (0.1622)  loss_box_reg: 0.1294 (0.1480)  loss_objectness: 0.1012 (0.1038)  loss_rpn_box_reg: 0.0234 (0.0291)  time: 0.2746  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [13]  [  40/1229]  eta: 0:05:22  lr: 0.000050  loss: 0.3621 (0.4545)  loss_classifier: 0.1329 (0.1602)  loss_box_reg: 0.1310 (0.1511)  loss_objectness: 0.0762 (0.1049)  loss_rpn_box_reg: 0.0234 (0.0383)  time: 0.2755  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [13]  [  50/1229]  eta: 0:05:20  lr: 0.000050  loss: 0.3745 (0.4446)  loss_classifier: 0.1284 (0.1587)  loss_box_reg: 0.1210 (0.1438)  loss_objectness: 0.1005 (0.1074)  loss_rpn_box_reg: 0.0191 (0.0348)  time: 0.2744  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [13]  [  60/1229]  eta: 0:05:17  lr: 0.000050  loss: 0.3693 (0.4379)  loss_classifier: 0.1233 (0.1562)  loss_box_reg: 0.0936 (0.1416)  loss_objectness: 0.0747 (0.1043)  loss_rpn_box_reg: 0.0161 (0.0358)  time: 0.2729  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [13]  [  70/1229]  eta: 0:05:14  lr: 0.000050  loss: 0.3384 (0.4286)  loss_classifier: 0.1183 (0.1530)  loss_box_reg: 0.1244 (0.1406)  loss_objectness: 0.0747 (0.1011)  loss_rpn_box_reg: 0.0161 (0.0339)  time: 0.2698  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [13]  [  80/1229]  eta: 0:05:12  lr: 0.000050  loss: 0.3125 (0.4302)  loss_classifier: 0.1136 (0.1537)  loss_box_reg: 0.1141 (0.1408)  loss_objectness: 0.0894 (0.1027)  loss_rpn_box_reg: 0.0159 (0.0330)  time: 0.2707  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [13]  [  90/1229]  eta: 0:05:08  lr: 0.000050  loss: 0.2722 (0.4136)  loss_classifier: 0.0974 (0.1482)  loss_box_reg: 0.0762 (0.1337)  loss_objectness: 0.0932 (0.1005)  loss_rpn_box_reg: 0.0140 (0.0313)  time: 0.2685  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [13]  [ 100/1229]  eta: 0:05:06  lr: 0.000050  loss: 0.3380 (0.4206)  loss_classifier: 0.1130 (0.1495)  loss_box_reg: 0.0985 (0.1375)  loss_objectness: 0.0932 (0.1003)  loss_rpn_box_reg: 0.0170 (0.0333)  time: 0.2700  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [13]  [ 110/1229]  eta: 0:05:03  lr: 0.000050  loss: 0.3946 (0.4245)  loss_classifier: 0.1520 (0.1508)  loss_box_reg: 0.1371 (0.1390)  loss_objectness: 0.0935 (0.1006)  loss_rpn_box_reg: 0.0296 (0.0342)  time: 0.2732  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [13]  [ 120/1229]  eta: 0:05:00  lr: 0.000050  loss: 0.4497 (0.4334)  loss_classifier: 0.1592 (0.1538)  loss_box_reg: 0.1431 (0.1421)  loss_objectness: 0.1008 (0.1031)  loss_rpn_box_reg: 0.0341 (0.0344)  time: 0.2690  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [13]  [ 130/1229]  eta: 0:04:57  lr: 0.000050  loss: 0.5075 (0.4378)  loss_classifier: 0.1570 (0.1537)  loss_box_reg: 0.1614 (0.1436)  loss_objectness: 0.1008 (0.1035)  loss_rpn_box_reg: 0.0285 (0.0370)  time: 0.2692  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [13]  [ 140/1229]  eta: 0:04:54  lr: 0.000050  loss: 0.3353 (0.4355)  loss_classifier: 0.1263 (0.1534)  loss_box_reg: 0.1169 (0.1424)  loss_objectness: 0.0840 (0.1036)  loss_rpn_box_reg: 0.0206 (0.0361)  time: 0.2695  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [13]  [ 150/1229]  eta: 0:04:52  lr: 0.000050  loss: 0.2748 (0.4307)  loss_classifier: 0.1000 (0.1520)  loss_box_reg: 0.0790 (0.1412)  loss_objectness: 0.0761 (0.1029)  loss_rpn_box_reg: 0.0122 (0.0346)  time: 0.2716  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [13]  [ 160/1229]  eta: 0:04:49  lr: 0.000050  loss: 0.3325 (0.4294)  loss_classifier: 0.1031 (0.1518)  loss_box_reg: 0.1119 (0.1413)  loss_objectness: 0.0761 (0.1025)  loss_rpn_box_reg: 0.0142 (0.0338)  time: 0.2698  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [13]  [ 170/1229]  eta: 0:04:47  lr: 0.000050  loss: 0.3489 (0.4270)  loss_classifier: 0.1068 (0.1508)  loss_box_reg: 0.0745 (0.1403)  loss_objectness: 0.0819 (0.1018)  loss_rpn_box_reg: 0.0249 (0.0341)  time: 0.2709  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [13]  [ 180/1229]  eta: 0:04:44  lr: 0.000050  loss: 0.3632 (0.4293)  loss_classifier: 0.1122 (0.1518)  loss_box_reg: 0.1197 (0.1422)  loss_objectness: 0.0806 (0.1013)  loss_rpn_box_reg: 0.0235 (0.0340)  time: 0.2772  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [13]  [ 190/1229]  eta: 0:04:41  lr: 0.000050  loss: 0.3839 (0.4297)  loss_classifier: 0.1122 (0.1514)  loss_box_reg: 0.1212 (0.1426)  loss_objectness: 0.0804 (0.1013)  loss_rpn_box_reg: 0.0170 (0.0343)  time: 0.2728  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [13]  [ 200/1229]  eta: 0:04:38  lr: 0.000050  loss: 0.2857 (0.4291)  loss_classifier: 0.1111 (0.1509)  loss_box_reg: 0.0975 (0.1423)  loss_objectness: 0.0775 (0.1009)  loss_rpn_box_reg: 0.0248 (0.0350)  time: 0.2671  data: 0.1297  max mem: 1751\n",
      "Training Epoch: [13]  [ 210/1229]  eta: 0:04:35  lr: 0.000050  loss: 0.3380 (0.4245)  loss_classifier: 0.1390 (0.1500)  loss_box_reg: 0.1201 (0.1410)  loss_objectness: 0.0614 (0.0993)  loss_rpn_box_reg: 0.0235 (0.0342)  time: 0.2666  data: 0.1295  max mem: 1751\n",
      "Training Epoch: [13]  [ 220/1229]  eta: 0:04:32  lr: 0.000050  loss: 0.3764 (0.4252)  loss_classifier: 0.1427 (0.1503)  loss_box_reg: 0.1284 (0.1408)  loss_objectness: 0.0891 (0.1003)  loss_rpn_box_reg: 0.0204 (0.0338)  time: 0.2660  data: 0.1284  max mem: 1751\n",
      "Training Epoch: [13]  [ 230/1229]  eta: 0:04:30  lr: 0.000050  loss: 0.4462 (0.4318)  loss_classifier: 0.1605 (0.1525)  loss_box_reg: 0.1348 (0.1444)  loss_objectness: 0.1221 (0.1007)  loss_rpn_box_reg: 0.0280 (0.0342)  time: 0.2696  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [13]  [ 240/1229]  eta: 0:04:28  lr: 0.000050  loss: 0.4335 (0.4305)  loss_classifier: 0.1614 (0.1521)  loss_box_reg: 0.1348 (0.1441)  loss_objectness: 0.0909 (0.1007)  loss_rpn_box_reg: 0.0218 (0.0336)  time: 0.2777  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [13]  [ 250/1229]  eta: 0:04:25  lr: 0.000050  loss: 0.4196 (0.4322)  loss_classifier: 0.1526 (0.1525)  loss_box_reg: 0.1249 (0.1446)  loss_objectness: 0.0887 (0.1009)  loss_rpn_box_reg: 0.0218 (0.0342)  time: 0.2808  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [13]  [ 260/1229]  eta: 0:04:22  lr: 0.000050  loss: 0.4196 (0.4316)  loss_classifier: 0.1428 (0.1529)  loss_box_reg: 0.1246 (0.1431)  loss_objectness: 0.0846 (0.1015)  loss_rpn_box_reg: 0.0265 (0.0340)  time: 0.2748  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [13]  [ 270/1229]  eta: 0:04:20  lr: 0.000050  loss: 0.3984 (0.4332)  loss_classifier: 0.1320 (0.1533)  loss_box_reg: 0.1249 (0.1437)  loss_objectness: 0.0963 (0.1022)  loss_rpn_box_reg: 0.0207 (0.0341)  time: 0.2762  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [13]  [ 280/1229]  eta: 0:04:17  lr: 0.000050  loss: 0.4402 (0.4352)  loss_classifier: 0.1417 (0.1542)  loss_box_reg: 0.1265 (0.1446)  loss_objectness: 0.1125 (0.1023)  loss_rpn_box_reg: 0.0260 (0.0342)  time: 0.2783  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [13]  [ 290/1229]  eta: 0:04:15  lr: 0.000050  loss: 0.4435 (0.4391)  loss_classifier: 0.1478 (0.1557)  loss_box_reg: 0.1310 (0.1458)  loss_objectness: 0.1164 (0.1035)  loss_rpn_box_reg: 0.0226 (0.0341)  time: 0.2735  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [13]  [ 300/1229]  eta: 0:04:12  lr: 0.000050  loss: 0.4514 (0.4405)  loss_classifier: 0.1495 (0.1562)  loss_box_reg: 0.1398 (0.1469)  loss_objectness: 0.1118 (0.1034)  loss_rpn_box_reg: 0.0224 (0.0340)  time: 0.2764  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [13]  [ 310/1229]  eta: 0:04:09  lr: 0.000050  loss: 0.4068 (0.4405)  loss_classifier: 0.1346 (0.1562)  loss_box_reg: 0.1398 (0.1465)  loss_objectness: 0.1016 (0.1037)  loss_rpn_box_reg: 0.0154 (0.0340)  time: 0.2693  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [13]  [ 320/1229]  eta: 0:04:07  lr: 0.000050  loss: 0.4068 (0.4423)  loss_classifier: 0.1359 (0.1564)  loss_box_reg: 0.1299 (0.1471)  loss_objectness: 0.1079 (0.1038)  loss_rpn_box_reg: 0.0208 (0.0350)  time: 0.2672  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [13]  [ 330/1229]  eta: 0:04:04  lr: 0.000050  loss: 0.4405 (0.4452)  loss_classifier: 0.1521 (0.1573)  loss_box_reg: 0.1299 (0.1483)  loss_objectness: 0.1102 (0.1044)  loss_rpn_box_reg: 0.0263 (0.0352)  time: 0.2673  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [13]  [ 340/1229]  eta: 0:04:01  lr: 0.000050  loss: 0.6115 (0.4500)  loss_classifier: 0.1694 (0.1590)  loss_box_reg: 0.2113 (0.1503)  loss_objectness: 0.1142 (0.1053)  loss_rpn_box_reg: 0.0348 (0.0354)  time: 0.2656  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [13]  [ 350/1229]  eta: 0:03:58  lr: 0.000050  loss: 0.4986 (0.4509)  loss_classifier: 0.1628 (0.1591)  loss_box_reg: 0.1801 (0.1514)  loss_objectness: 0.1142 (0.1052)  loss_rpn_box_reg: 0.0262 (0.0351)  time: 0.2682  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [13]  [ 360/1229]  eta: 0:03:55  lr: 0.000050  loss: 0.4979 (0.4521)  loss_classifier: 0.1656 (0.1594)  loss_box_reg: 0.1791 (0.1514)  loss_objectness: 0.1210 (0.1056)  loss_rpn_box_reg: 0.0334 (0.0357)  time: 0.2709  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [13]  [ 370/1229]  eta: 0:03:53  lr: 0.000050  loss: 0.4741 (0.4534)  loss_classifier: 0.1669 (0.1597)  loss_box_reg: 0.1528 (0.1514)  loss_objectness: 0.1251 (0.1067)  loss_rpn_box_reg: 0.0423 (0.0357)  time: 0.2769  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [13]  [ 380/1229]  eta: 0:03:50  lr: 0.000050  loss: 0.4576 (0.4536)  loss_classifier: 0.1639 (0.1597)  loss_box_reg: 0.1528 (0.1517)  loss_objectness: 0.0902 (0.1068)  loss_rpn_box_reg: 0.0241 (0.0354)  time: 0.2741  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [13]  [ 390/1229]  eta: 0:03:48  lr: 0.000050  loss: 0.4170 (0.4527)  loss_classifier: 0.1639 (0.1597)  loss_box_reg: 0.1503 (0.1519)  loss_objectness: 0.0857 (0.1062)  loss_rpn_box_reg: 0.0194 (0.0349)  time: 0.2746  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [13]  [ 400/1229]  eta: 0:03:45  lr: 0.000050  loss: 0.4261 (0.4536)  loss_classifier: 0.1567 (0.1601)  loss_box_reg: 0.1680 (0.1526)  loss_objectness: 0.0857 (0.1058)  loss_rpn_box_reg: 0.0195 (0.0351)  time: 0.2781  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [13]  [ 410/1229]  eta: 0:03:42  lr: 0.000050  loss: 0.3204 (0.4493)  loss_classifier: 0.1207 (0.1586)  loss_box_reg: 0.1027 (0.1506)  loss_objectness: 0.0900 (0.1054)  loss_rpn_box_reg: 0.0180 (0.0347)  time: 0.2698  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [13]  [ 420/1229]  eta: 0:03:39  lr: 0.000050  loss: 0.2915 (0.4478)  loss_classifier: 0.0981 (0.1580)  loss_box_reg: 0.0658 (0.1499)  loss_objectness: 0.0933 (0.1051)  loss_rpn_box_reg: 0.0167 (0.0348)  time: 0.2683  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [13]  [ 430/1229]  eta: 0:03:37  lr: 0.000050  loss: 0.3935 (0.4492)  loss_classifier: 0.1509 (0.1585)  loss_box_reg: 0.1227 (0.1502)  loss_objectness: 0.0887 (0.1049)  loss_rpn_box_reg: 0.0167 (0.0356)  time: 0.2744  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [13]  [ 440/1229]  eta: 0:03:34  lr: 0.000050  loss: 0.4038 (0.4479)  loss_classifier: 0.1509 (0.1580)  loss_box_reg: 0.1227 (0.1497)  loss_objectness: 0.0859 (0.1047)  loss_rpn_box_reg: 0.0215 (0.0355)  time: 0.2685  data: 0.1297  max mem: 1751\n",
      "Training Epoch: [13]  [ 450/1229]  eta: 0:03:31  lr: 0.000050  loss: 0.3663 (0.4475)  loss_classifier: 0.1094 (0.1574)  loss_box_reg: 0.1093 (0.1495)  loss_objectness: 0.0953 (0.1050)  loss_rpn_box_reg: 0.0215 (0.0357)  time: 0.2638  data: 0.1279  max mem: 1751\n",
      "Training Epoch: [13]  [ 460/1229]  eta: 0:03:28  lr: 0.000050  loss: 0.4533 (0.4475)  loss_classifier: 0.1324 (0.1573)  loss_box_reg: 0.1270 (0.1493)  loss_objectness: 0.0937 (0.1046)  loss_rpn_box_reg: 0.0293 (0.0363)  time: 0.2636  data: 0.1285  max mem: 1751\n",
      "Training Epoch: [13]  [ 470/1229]  eta: 0:03:25  lr: 0.000050  loss: 0.4030 (0.4466)  loss_classifier: 0.1384 (0.1568)  loss_box_reg: 0.1252 (0.1484)  loss_objectness: 0.0635 (0.1042)  loss_rpn_box_reg: 0.0293 (0.0371)  time: 0.2672  data: 0.1289  max mem: 1751\n",
      "Training Epoch: [13]  [ 480/1229]  eta: 0:03:23  lr: 0.000050  loss: 0.3107 (0.4455)  loss_classifier: 0.1030 (0.1562)  loss_box_reg: 0.1025 (0.1483)  loss_objectness: 0.0707 (0.1039)  loss_rpn_box_reg: 0.0233 (0.0370)  time: 0.2802  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [13]  [ 490/1229]  eta: 0:03:20  lr: 0.000050  loss: 0.3113 (0.4443)  loss_classifier: 0.1130 (0.1560)  loss_box_reg: 0.0999 (0.1477)  loss_objectness: 0.0837 (0.1038)  loss_rpn_box_reg: 0.0173 (0.0368)  time: 0.2820  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [13]  [ 500/1229]  eta: 0:03:18  lr: 0.000050  loss: 0.4108 (0.4445)  loss_classifier: 0.1351 (0.1561)  loss_box_reg: 0.0969 (0.1479)  loss_objectness: 0.0782 (0.1034)  loss_rpn_box_reg: 0.0173 (0.0371)  time: 0.2727  data: 0.1295  max mem: 1751\n",
      "Training Epoch: [13]  [ 510/1229]  eta: 0:03:15  lr: 0.000050  loss: 0.4108 (0.4436)  loss_classifier: 0.1453 (0.1556)  loss_box_reg: 0.1191 (0.1475)  loss_objectness: 0.0777 (0.1030)  loss_rpn_box_reg: 0.0258 (0.0375)  time: 0.2716  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [13]  [ 520/1229]  eta: 0:03:12  lr: 0.000050  loss: 0.2775 (0.4419)  loss_classifier: 0.1000 (0.1551)  loss_box_reg: 0.0846 (0.1468)  loss_objectness: 0.0777 (0.1028)  loss_rpn_box_reg: 0.0224 (0.0372)  time: 0.2737  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [13]  [ 530/1229]  eta: 0:03:09  lr: 0.000050  loss: 0.2898 (0.4422)  loss_classifier: 0.0980 (0.1552)  loss_box_reg: 0.0846 (0.1466)  loss_objectness: 0.0987 (0.1032)  loss_rpn_box_reg: 0.0194 (0.0371)  time: 0.2735  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [13]  [ 540/1229]  eta: 0:03:07  lr: 0.000050  loss: 0.4071 (0.4429)  loss_classifier: 0.1472 (0.1554)  loss_box_reg: 0.1605 (0.1472)  loss_objectness: 0.0973 (0.1032)  loss_rpn_box_reg: 0.0246 (0.0372)  time: 0.2728  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [13]  [ 550/1229]  eta: 0:03:04  lr: 0.000050  loss: 0.4437 (0.4422)  loss_classifier: 0.1528 (0.1552)  loss_box_reg: 0.1605 (0.1472)  loss_objectness: 0.0828 (0.1027)  loss_rpn_box_reg: 0.0254 (0.0370)  time: 0.2727  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [13]  [ 560/1229]  eta: 0:03:01  lr: 0.000050  loss: 0.3720 (0.4410)  loss_classifier: 0.1528 (0.1549)  loss_box_reg: 0.1213 (0.1472)  loss_objectness: 0.0613 (0.1022)  loss_rpn_box_reg: 0.0171 (0.0367)  time: 0.2684  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [13]  [ 570/1229]  eta: 0:02:59  lr: 0.000050  loss: 0.3720 (0.4411)  loss_classifier: 0.1570 (0.1550)  loss_box_reg: 0.1335 (0.1473)  loss_objectness: 0.0717 (0.1021)  loss_rpn_box_reg: 0.0255 (0.0366)  time: 0.2669  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [13]  [ 580/1229]  eta: 0:02:56  lr: 0.000050  loss: 0.4030 (0.4410)  loss_classifier: 0.1698 (0.1550)  loss_box_reg: 0.1212 (0.1471)  loss_objectness: 0.1012 (0.1022)  loss_rpn_box_reg: 0.0304 (0.0367)  time: 0.2688  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [13]  [ 590/1229]  eta: 0:02:53  lr: 0.000050  loss: 0.3797 (0.4418)  loss_classifier: 0.1288 (0.1551)  loss_box_reg: 0.1130 (0.1471)  loss_objectness: 0.1037 (0.1024)  loss_rpn_box_reg: 0.0322 (0.0372)  time: 0.2759  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [13]  [ 600/1229]  eta: 0:02:50  lr: 0.000050  loss: 0.3826 (0.4412)  loss_classifier: 0.1245 (0.1550)  loss_box_reg: 0.1187 (0.1471)  loss_objectness: 0.0968 (0.1022)  loss_rpn_box_reg: 0.0197 (0.0369)  time: 0.2749  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [13]  [ 610/1229]  eta: 0:02:48  lr: 0.000050  loss: 0.3984 (0.4413)  loss_classifier: 0.1462 (0.1552)  loss_box_reg: 0.1295 (0.1475)  loss_objectness: 0.0767 (0.1017)  loss_rpn_box_reg: 0.0234 (0.0369)  time: 0.2689  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [13]  [ 620/1229]  eta: 0:02:45  lr: 0.000050  loss: 0.3984 (0.4412)  loss_classifier: 0.1437 (0.1554)  loss_box_reg: 0.1504 (0.1474)  loss_objectness: 0.0758 (0.1017)  loss_rpn_box_reg: 0.0299 (0.0368)  time: 0.2664  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [13]  [ 630/1229]  eta: 0:02:42  lr: 0.000050  loss: 0.3283 (0.4407)  loss_classifier: 0.1328 (0.1553)  loss_box_reg: 0.1024 (0.1473)  loss_objectness: 0.0783 (0.1015)  loss_rpn_box_reg: 0.0212 (0.0365)  time: 0.2675  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [13]  [ 640/1229]  eta: 0:02:39  lr: 0.000050  loss: 0.3974 (0.4421)  loss_classifier: 0.1431 (0.1559)  loss_box_reg: 0.1024 (0.1477)  loss_objectness: 0.0916 (0.1021)  loss_rpn_box_reg: 0.0211 (0.0365)  time: 0.2696  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [13]  [ 650/1229]  eta: 0:02:37  lr: 0.000050  loss: 0.4526 (0.4420)  loss_classifier: 0.1763 (0.1559)  loss_box_reg: 0.1439 (0.1476)  loss_objectness: 0.1013 (0.1019)  loss_rpn_box_reg: 0.0374 (0.0366)  time: 0.2683  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [13]  [ 660/1229]  eta: 0:02:34  lr: 0.000050  loss: 0.4061 (0.4408)  loss_classifier: 0.1493 (0.1555)  loss_box_reg: 0.0930 (0.1469)  loss_objectness: 0.0833 (0.1017)  loss_rpn_box_reg: 0.0374 (0.0366)  time: 0.2770  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [13]  [ 670/1229]  eta: 0:02:31  lr: 0.000050  loss: 0.3650 (0.4398)  loss_classifier: 0.1220 (0.1553)  loss_box_reg: 0.0926 (0.1465)  loss_objectness: 0.0833 (0.1017)  loss_rpn_box_reg: 0.0160 (0.0363)  time: 0.2788  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [13]  [ 680/1229]  eta: 0:02:29  lr: 0.000050  loss: 0.3512 (0.4384)  loss_classifier: 0.1103 (0.1547)  loss_box_reg: 0.1135 (0.1458)  loss_objectness: 0.0902 (0.1015)  loss_rpn_box_reg: 0.0171 (0.0364)  time: 0.2740  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [13]  [ 690/1229]  eta: 0:02:26  lr: 0.000050  loss: 0.4369 (0.4391)  loss_classifier: 0.1334 (0.1550)  loss_box_reg: 0.1359 (0.1461)  loss_objectness: 0.0861 (0.1015)  loss_rpn_box_reg: 0.0277 (0.0365)  time: 0.2774  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [13]  [ 700/1229]  eta: 0:02:23  lr: 0.000050  loss: 0.3338 (0.4382)  loss_classifier: 0.1334 (0.1549)  loss_box_reg: 0.1204 (0.1458)  loss_objectness: 0.0832 (0.1013)  loss_rpn_box_reg: 0.0227 (0.0362)  time: 0.2769  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [13]  [ 710/1229]  eta: 0:02:21  lr: 0.000050  loss: 0.3509 (0.4382)  loss_classifier: 0.1176 (0.1548)  loss_box_reg: 0.1005 (0.1454)  loss_objectness: 0.0872 (0.1017)  loss_rpn_box_reg: 0.0206 (0.0362)  time: 0.2690  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [13]  [ 720/1229]  eta: 0:02:18  lr: 0.000050  loss: 0.3998 (0.4387)  loss_classifier: 0.1382 (0.1549)  loss_box_reg: 0.1226 (0.1457)  loss_objectness: 0.1019 (0.1018)  loss_rpn_box_reg: 0.0283 (0.0363)  time: 0.2681  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [13]  [ 730/1229]  eta: 0:02:15  lr: 0.000050  loss: 0.2802 (0.4368)  loss_classifier: 0.0924 (0.1543)  loss_box_reg: 0.0787 (0.1451)  loss_objectness: 0.0690 (0.1013)  loss_rpn_box_reg: 0.0237 (0.0361)  time: 0.2730  data: 0.1303  max mem: 1751\n",
      "Training Epoch: [13]  [ 740/1229]  eta: 0:02:12  lr: 0.000050  loss: 0.3341 (0.4372)  loss_classifier: 0.1140 (0.1544)  loss_box_reg: 0.0763 (0.1453)  loss_objectness: 0.0782 (0.1016)  loss_rpn_box_reg: 0.0189 (0.0360)  time: 0.2727  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [13]  [ 750/1229]  eta: 0:02:10  lr: 0.000050  loss: 0.3462 (0.4367)  loss_classifier: 0.1379 (0.1542)  loss_box_reg: 0.1115 (0.1450)  loss_objectness: 0.0926 (0.1017)  loss_rpn_box_reg: 0.0130 (0.0358)  time: 0.2701  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [13]  [ 760/1229]  eta: 0:02:07  lr: 0.000050  loss: 0.4907 (0.4380)  loss_classifier: 0.1715 (0.1547)  loss_box_reg: 0.1494 (0.1459)  loss_objectness: 0.0918 (0.1017)  loss_rpn_box_reg: 0.0157 (0.0358)  time: 0.2718  data: 0.1297  max mem: 1751\n",
      "Training Epoch: [13]  [ 770/1229]  eta: 0:02:04  lr: 0.000050  loss: 0.5010 (0.4380)  loss_classifier: 0.1797 (0.1548)  loss_box_reg: 0.1837 (0.1461)  loss_objectness: 0.0889 (0.1015)  loss_rpn_box_reg: 0.0235 (0.0356)  time: 0.2717  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [13]  [ 780/1229]  eta: 0:02:01  lr: 0.000050  loss: 0.3941 (0.4382)  loss_classifier: 0.1284 (0.1549)  loss_box_reg: 0.0949 (0.1461)  loss_objectness: 0.0928 (0.1016)  loss_rpn_box_reg: 0.0204 (0.0356)  time: 0.2700  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [13]  [ 790/1229]  eta: 0:01:59  lr: 0.000050  loss: 0.4206 (0.4387)  loss_classifier: 0.1693 (0.1551)  loss_box_reg: 0.1087 (0.1460)  loss_objectness: 0.1026 (0.1018)  loss_rpn_box_reg: 0.0252 (0.0359)  time: 0.2660  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [13]  [ 800/1229]  eta: 0:01:56  lr: 0.000050  loss: 0.3514 (0.4380)  loss_classifier: 0.1473 (0.1548)  loss_box_reg: 0.0993 (0.1457)  loss_objectness: 0.0848 (0.1016)  loss_rpn_box_reg: 0.0284 (0.0358)  time: 0.2675  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [13]  [ 810/1229]  eta: 0:01:53  lr: 0.000050  loss: 0.3736 (0.4390)  loss_classifier: 0.1388 (0.1552)  loss_box_reg: 0.1205 (0.1461)  loss_objectness: 0.0855 (0.1018)  loss_rpn_box_reg: 0.0273 (0.0359)  time: 0.2715  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [13]  [ 820/1229]  eta: 0:01:51  lr: 0.000050  loss: 0.4139 (0.4390)  loss_classifier: 0.1566 (0.1552)  loss_box_reg: 0.1459 (0.1461)  loss_objectness: 0.0967 (0.1016)  loss_rpn_box_reg: 0.0273 (0.0362)  time: 0.2707  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [13]  [ 830/1229]  eta: 0:01:48  lr: 0.000050  loss: 0.4139 (0.4397)  loss_classifier: 0.1566 (0.1554)  loss_box_reg: 0.1459 (0.1465)  loss_objectness: 0.0831 (0.1014)  loss_rpn_box_reg: 0.0287 (0.0363)  time: 0.2705  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [13]  [ 840/1229]  eta: 0:01:45  lr: 0.000050  loss: 0.3815 (0.4389)  loss_classifier: 0.1195 (0.1551)  loss_box_reg: 0.1208 (0.1461)  loss_objectness: 0.0723 (0.1013)  loss_rpn_box_reg: 0.0200 (0.0364)  time: 0.2701  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [13]  [ 850/1229]  eta: 0:01:42  lr: 0.000050  loss: 0.4091 (0.4397)  loss_classifier: 0.1195 (0.1555)  loss_box_reg: 0.1208 (0.1467)  loss_objectness: 0.0818 (0.1012)  loss_rpn_box_reg: 0.0186 (0.0363)  time: 0.2781  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [13]  [ 860/1229]  eta: 0:01:40  lr: 0.000050  loss: 0.4529 (0.4399)  loss_classifier: 0.1654 (0.1557)  loss_box_reg: 0.1460 (0.1467)  loss_objectness: 0.0891 (0.1013)  loss_rpn_box_reg: 0.0194 (0.0362)  time: 0.2805  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [13]  [ 870/1229]  eta: 0:01:37  lr: 0.000050  loss: 0.4288 (0.4406)  loss_classifier: 0.1654 (0.1561)  loss_box_reg: 0.1587 (0.1474)  loss_objectness: 0.0891 (0.1011)  loss_rpn_box_reg: 0.0194 (0.0360)  time: 0.2696  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [13]  [ 880/1229]  eta: 0:01:34  lr: 0.000050  loss: 0.3950 (0.4392)  loss_classifier: 0.1405 (0.1556)  loss_box_reg: 0.1475 (0.1469)  loss_objectness: 0.0692 (0.1009)  loss_rpn_box_reg: 0.0118 (0.0358)  time: 0.2663  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [13]  [ 890/1229]  eta: 0:01:32  lr: 0.000050  loss: 0.4165 (0.4400)  loss_classifier: 0.1460 (0.1559)  loss_box_reg: 0.1248 (0.1471)  loss_objectness: 0.0777 (0.1012)  loss_rpn_box_reg: 0.0228 (0.0358)  time: 0.2726  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [13]  [ 900/1229]  eta: 0:01:29  lr: 0.000050  loss: 0.4133 (0.4393)  loss_classifier: 0.1460 (0.1557)  loss_box_reg: 0.1484 (0.1469)  loss_objectness: 0.1042 (0.1011)  loss_rpn_box_reg: 0.0199 (0.0357)  time: 0.2748  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [13]  [ 910/1229]  eta: 0:01:26  lr: 0.000050  loss: 0.3500 (0.4401)  loss_classifier: 0.1244 (0.1558)  loss_box_reg: 0.1172 (0.1473)  loss_objectness: 0.0719 (0.1012)  loss_rpn_box_reg: 0.0191 (0.0358)  time: 0.2720  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [13]  [ 920/1229]  eta: 0:01:23  lr: 0.000050  loss: 0.3500 (0.4396)  loss_classifier: 0.1244 (0.1557)  loss_box_reg: 0.1172 (0.1472)  loss_objectness: 0.0739 (0.1009)  loss_rpn_box_reg: 0.0213 (0.0358)  time: 0.2686  data: 0.1371  max mem: 1751\n",
      "Training Epoch: [13]  [ 930/1229]  eta: 0:01:21  lr: 0.000050  loss: 0.3977 (0.4403)  loss_classifier: 0.1460 (0.1559)  loss_box_reg: 0.1288 (0.1476)  loss_objectness: 0.0739 (0.1010)  loss_rpn_box_reg: 0.0213 (0.0358)  time: 0.2697  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [13]  [ 940/1229]  eta: 0:01:18  lr: 0.000050  loss: 0.4983 (0.4408)  loss_classifier: 0.1635 (0.1560)  loss_box_reg: 0.1440 (0.1479)  loss_objectness: 0.0768 (0.1008)  loss_rpn_box_reg: 0.0221 (0.0361)  time: 0.2735  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [13]  [ 950/1229]  eta: 0:01:15  lr: 0.000050  loss: 0.4943 (0.4416)  loss_classifier: 0.1754 (0.1564)  loss_box_reg: 0.1375 (0.1481)  loss_objectness: 0.0820 (0.1011)  loss_rpn_box_reg: 0.0253 (0.0360)  time: 0.2703  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [13]  [ 960/1229]  eta: 0:01:13  lr: 0.000050  loss: 0.4296 (0.4408)  loss_classifier: 0.1643 (0.1562)  loss_box_reg: 0.1323 (0.1481)  loss_objectness: 0.0814 (0.1008)  loss_rpn_box_reg: 0.0178 (0.0358)  time: 0.2696  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [13]  [ 970/1229]  eta: 0:01:10  lr: 0.000050  loss: 0.3833 (0.4406)  loss_classifier: 0.1379 (0.1562)  loss_box_reg: 0.1083 (0.1479)  loss_objectness: 0.0683 (0.1008)  loss_rpn_box_reg: 0.0178 (0.0357)  time: 0.2715  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [13]  [ 980/1229]  eta: 0:01:07  lr: 0.000050  loss: 0.3674 (0.4401)  loss_classifier: 0.1412 (0.1560)  loss_box_reg: 0.0976 (0.1478)  loss_objectness: 0.0773 (0.1007)  loss_rpn_box_reg: 0.0205 (0.0356)  time: 0.2672  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [13]  [ 990/1229]  eta: 0:01:04  lr: 0.000050  loss: 0.4015 (0.4409)  loss_classifier: 0.1514 (0.1564)  loss_box_reg: 0.1255 (0.1481)  loss_objectness: 0.0934 (0.1009)  loss_rpn_box_reg: 0.0229 (0.0356)  time: 0.2679  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [13]  [1000/1229]  eta: 0:01:02  lr: 0.000050  loss: 0.4362 (0.4404)  loss_classifier: 0.1680 (0.1562)  loss_box_reg: 0.1255 (0.1479)  loss_objectness: 0.0788 (0.1009)  loss_rpn_box_reg: 0.0229 (0.0355)  time: 0.2717  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [13]  [1010/1229]  eta: 0:00:59  lr: 0.000050  loss: 0.4034 (0.4400)  loss_classifier: 0.1544 (0.1562)  loss_box_reg: 0.1267 (0.1478)  loss_objectness: 0.0727 (0.1007)  loss_rpn_box_reg: 0.0129 (0.0353)  time: 0.2750  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [13]  [1020/1229]  eta: 0:00:56  lr: 0.000050  loss: 0.3968 (0.4402)  loss_classifier: 0.1542 (0.1562)  loss_box_reg: 0.1360 (0.1479)  loss_objectness: 0.0728 (0.1008)  loss_rpn_box_reg: 0.0119 (0.0353)  time: 0.2721  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [13]  [1030/1229]  eta: 0:00:54  lr: 0.000050  loss: 0.3066 (0.4399)  loss_classifier: 0.1124 (0.1562)  loss_box_reg: 0.1066 (0.1476)  loss_objectness: 0.0660 (0.1008)  loss_rpn_box_reg: 0.0240 (0.0353)  time: 0.2753  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [13]  [1040/1229]  eta: 0:00:51  lr: 0.000050  loss: 0.2897 (0.4397)  loss_classifier: 0.1082 (0.1561)  loss_box_reg: 0.0895 (0.1473)  loss_objectness: 0.0732 (0.1010)  loss_rpn_box_reg: 0.0216 (0.0353)  time: 0.2743  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [13]  [1050/1229]  eta: 0:00:48  lr: 0.000050  loss: 0.3369 (0.4392)  loss_classifier: 0.1228 (0.1559)  loss_box_reg: 0.1020 (0.1470)  loss_objectness: 0.0904 (0.1010)  loss_rpn_box_reg: 0.0165 (0.0353)  time: 0.2638  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [13]  [1060/1229]  eta: 0:00:45  lr: 0.000050  loss: 0.3859 (0.4397)  loss_classifier: 0.1461 (0.1561)  loss_box_reg: 0.1162 (0.1472)  loss_objectness: 0.0904 (0.1011)  loss_rpn_box_reg: 0.0165 (0.0353)  time: 0.2711  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [13]  [1070/1229]  eta: 0:00:43  lr: 0.000050  loss: 0.3859 (0.4390)  loss_classifier: 0.1478 (0.1559)  loss_box_reg: 0.1344 (0.1469)  loss_objectness: 0.0883 (0.1011)  loss_rpn_box_reg: 0.0200 (0.0351)  time: 0.2726  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [13]  [1080/1229]  eta: 0:00:40  lr: 0.000050  loss: 0.4133 (0.4391)  loss_classifier: 0.1522 (0.1560)  loss_box_reg: 0.1344 (0.1470)  loss_objectness: 0.0905 (0.1011)  loss_rpn_box_reg: 0.0177 (0.0350)  time: 0.2706  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [13]  [1090/1229]  eta: 0:00:37  lr: 0.000050  loss: 0.4640 (0.4396)  loss_classifier: 0.1658 (0.1560)  loss_box_reg: 0.1731 (0.1473)  loss_objectness: 0.0931 (0.1013)  loss_rpn_box_reg: 0.0186 (0.0350)  time: 0.2720  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [13]  [1100/1229]  eta: 0:00:35  lr: 0.000050  loss: 0.3530 (0.4391)  loss_classifier: 0.1377 (0.1559)  loss_box_reg: 0.1359 (0.1471)  loss_objectness: 0.0844 (0.1012)  loss_rpn_box_reg: 0.0189 (0.0349)  time: 0.2690  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [13]  [1110/1229]  eta: 0:00:32  lr: 0.000050  loss: 0.3530 (0.4392)  loss_classifier: 0.1431 (0.1560)  loss_box_reg: 0.1158 (0.1474)  loss_objectness: 0.0693 (0.1010)  loss_rpn_box_reg: 0.0180 (0.0348)  time: 0.2750  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [13]  [1120/1229]  eta: 0:00:29  lr: 0.000050  loss: 0.3545 (0.4388)  loss_classifier: 0.1342 (0.1559)  loss_box_reg: 0.1124 (0.1472)  loss_objectness: 0.0838 (0.1010)  loss_rpn_box_reg: 0.0167 (0.0347)  time: 0.2790  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [13]  [1130/1229]  eta: 0:00:26  lr: 0.000050  loss: 0.3777 (0.4385)  loss_classifier: 0.1300 (0.1557)  loss_box_reg: 0.1089 (0.1471)  loss_objectness: 0.0989 (0.1010)  loss_rpn_box_reg: 0.0179 (0.0348)  time: 0.2662  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [13]  [1140/1229]  eta: 0:00:24  lr: 0.000050  loss: 0.3624 (0.4379)  loss_classifier: 0.1138 (0.1556)  loss_box_reg: 0.1011 (0.1469)  loss_objectness: 0.0667 (0.1008)  loss_rpn_box_reg: 0.0179 (0.0346)  time: 0.2652  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [13]  [1150/1229]  eta: 0:00:21  lr: 0.000050  loss: 0.3041 (0.4377)  loss_classifier: 0.1138 (0.1557)  loss_box_reg: 0.1011 (0.1467)  loss_objectness: 0.0700 (0.1008)  loss_rpn_box_reg: 0.0144 (0.0345)  time: 0.2763  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [13]  [1160/1229]  eta: 0:00:18  lr: 0.000050  loss: 0.3041 (0.4364)  loss_classifier: 0.1184 (0.1553)  loss_box_reg: 0.1079 (0.1462)  loss_objectness: 0.0718 (0.1006)  loss_rpn_box_reg: 0.0117 (0.0343)  time: 0.2788  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [13]  [1170/1229]  eta: 0:00:16  lr: 0.000050  loss: 0.2817 (0.4351)  loss_classifier: 0.1005 (0.1549)  loss_box_reg: 0.0639 (0.1457)  loss_objectness: 0.0627 (0.1004)  loss_rpn_box_reg: 0.0143 (0.0341)  time: 0.2785  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [13]  [1180/1229]  eta: 0:00:13  lr: 0.000050  loss: 0.2970 (0.4351)  loss_classifier: 0.1172 (0.1549)  loss_box_reg: 0.0938 (0.1457)  loss_objectness: 0.0642 (0.1004)  loss_rpn_box_reg: 0.0182 (0.0341)  time: 0.2750  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [13]  [1190/1229]  eta: 0:00:10  lr: 0.000050  loss: 0.3988 (0.4352)  loss_classifier: 0.1442 (0.1549)  loss_box_reg: 0.1205 (0.1457)  loss_objectness: 0.0902 (0.1005)  loss_rpn_box_reg: 0.0193 (0.0341)  time: 0.2691  data: 0.1297  max mem: 1751\n",
      "Training Epoch: [13]  [1200/1229]  eta: 0:00:07  lr: 0.000050  loss: 0.3988 (0.4344)  loss_classifier: 0.1442 (0.1546)  loss_box_reg: 0.1114 (0.1453)  loss_objectness: 0.0877 (0.1003)  loss_rpn_box_reg: 0.0126 (0.0342)  time: 0.2659  data: 0.1297  max mem: 1751\n",
      "Training Epoch: [13]  [1210/1229]  eta: 0:00:05  lr: 0.000050  loss: 0.3701 (0.4345)  loss_classifier: 0.1300 (0.1547)  loss_box_reg: 0.1035 (0.1452)  loss_objectness: 0.0959 (0.1005)  loss_rpn_box_reg: 0.0121 (0.0341)  time: 0.2705  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [13]  [1220/1229]  eta: 0:00:02  lr: 0.000050  loss: 0.4154 (0.4352)  loss_classifier: 0.1367 (0.1548)  loss_box_reg: 0.1285 (0.1455)  loss_objectness: 0.1145 (0.1007)  loss_rpn_box_reg: 0.0179 (0.0343)  time: 0.2742  data: 0.1368  max mem: 1751\n",
      "Training Epoch: [13]  [1228/1229]  eta: 0:00:00  lr: 0.000050  loss: 0.3910 (0.4347)  loss_classifier: 0.1287 (0.1546)  loss_box_reg: 0.1292 (0.1453)  loss_objectness: 0.0881 (0.1006)  loss_rpn_box_reg: 0.0179 (0.0342)  time: 0.2782  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [13] Total time: 0:05:34 (0.2718 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:46  model_time: 0.3120 (0.3120)  evaluator_time: 0.0020 (0.0020)  time: 0.3460  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0800 (0.0824)  evaluator_time: 0.0040 (0.0086)  time: 0.1269  data: 0.0359  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0820 (0.0809)  evaluator_time: 0.0030 (0.0078)  time: 0.1193  data: 0.0306  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0750 (0.0800)  evaluator_time: 0.0040 (0.0076)  time: 0.1194  data: 0.0347  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0750 (0.0800)  evaluator_time: 0.0030 (0.0076)  time: 0.1174  data: 0.0335  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1235 s / it)\n",
      "Averaged stats: model_time: 0.0750 (0.0800)  evaluator_time: 0.0030 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.118\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.345\n",
      "Testing Epoch: [13]  [  0/308]  eta: 0:00:37  lr: 0.000050  loss: 0.1681 (0.1681)  loss_classifier: 0.0615 (0.0615)  loss_box_reg: 0.0694 (0.0694)  loss_objectness: 0.0256 (0.0256)  loss_rpn_box_reg: 0.0116 (0.0116)  time: 0.1230  data: 0.0280  max mem: 1751\n",
      "Testing Epoch: [13]  [100/308]  eta: 0:00:28  lr: 0.000050  loss: 0.3128 (0.4821)  loss_classifier: 0.1343 (0.1555)  loss_box_reg: 0.1175 (0.1721)  loss_objectness: 0.0586 (0.1025)  loss_rpn_box_reg: 0.0190 (0.0520)  time: 0.1387  data: 0.0382  max mem: 1751\n",
      "Testing Epoch: [13]  [200/308]  eta: 0:00:14  lr: 0.000050  loss: 0.3508 (0.4579)  loss_classifier: 0.1399 (0.1497)  loss_box_reg: 0.1353 (0.1631)  loss_objectness: 0.0693 (0.0959)  loss_rpn_box_reg: 0.0198 (0.0493)  time: 0.1377  data: 0.0326  max mem: 1751\n",
      "Testing Epoch: [13]  [300/308]  eta: 0:00:01  lr: 0.000050  loss: 0.4553 (0.4546)  loss_classifier: 0.1548 (0.1500)  loss_box_reg: 0.1722 (0.1639)  loss_objectness: 0.0771 (0.0929)  loss_rpn_box_reg: 0.0262 (0.0477)  time: 0.1331  data: 0.0372  max mem: 1751\n",
      "Testing Epoch: [13]  [307/308]  eta: 0:00:00  lr: 0.000050  loss: 0.4435 (0.4547)  loss_classifier: 0.1837 (0.1503)  loss_box_reg: 0.1722 (0.1643)  loss_objectness: 0.0679 (0.0929)  loss_rpn_box_reg: 0.0271 (0.0473)  time: 0.1304  data: 0.0353  max mem: 1751\n",
      "Testing Epoch: [13] Total time: 0:00:42 (0.1368 s / it)\n",
      "Training Epoch: [14]  [   0/1229]  eta: 0:06:02  lr: 0.000050  loss: 0.7857 (0.7857)  loss_classifier: 0.2793 (0.2793)  loss_box_reg: 0.2742 (0.2742)  loss_objectness: 0.1733 (0.1733)  loss_rpn_box_reg: 0.0586 (0.0586)  time: 0.2950  data: 0.1280  max mem: 1751\n",
      "Training Epoch: [14]  [  10/1229]  eta: 0:05:41  lr: 0.000050  loss: 0.4314 (0.4183)  loss_classifier: 0.1552 (0.1518)  loss_box_reg: 0.1406 (0.1287)  loss_objectness: 0.0887 (0.1037)  loss_rpn_box_reg: 0.0255 (0.0340)  time: 0.2801  data: 0.1300  max mem: 1751\n",
      "Training Epoch: [14]  [  20/1229]  eta: 0:05:37  lr: 0.000050  loss: 0.4314 (0.4618)  loss_classifier: 0.1552 (0.1674)  loss_box_reg: 0.1406 (0.1503)  loss_objectness: 0.0838 (0.1129)  loss_rpn_box_reg: 0.0255 (0.0311)  time: 0.2786  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [14]  [  30/1229]  eta: 0:05:32  lr: 0.000050  loss: 0.3954 (0.4387)  loss_classifier: 0.1315 (0.1544)  loss_box_reg: 0.1298 (0.1366)  loss_objectness: 0.0832 (0.1108)  loss_rpn_box_reg: 0.0213 (0.0369)  time: 0.2755  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [14]  [  40/1229]  eta: 0:05:31  lr: 0.000050  loss: 0.3413 (0.4348)  loss_classifier: 0.1220 (0.1562)  loss_box_reg: 0.1112 (0.1411)  loss_objectness: 0.0814 (0.1035)  loss_rpn_box_reg: 0.0145 (0.0340)  time: 0.2777  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [14]  [  50/1229]  eta: 0:05:29  lr: 0.000050  loss: 0.4066 (0.4467)  loss_classifier: 0.1420 (0.1605)  loss_box_reg: 0.1458 (0.1532)  loss_objectness: 0.0799 (0.0998)  loss_rpn_box_reg: 0.0142 (0.0331)  time: 0.2821  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [14]  [  60/1229]  eta: 0:05:24  lr: 0.000050  loss: 0.3932 (0.4353)  loss_classifier: 0.1337 (0.1572)  loss_box_reg: 0.1282 (0.1484)  loss_objectness: 0.0845 (0.0976)  loss_rpn_box_reg: 0.0169 (0.0321)  time: 0.2748  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [14]  [  70/1229]  eta: 0:05:21  lr: 0.000050  loss: 0.3968 (0.4464)  loss_classifier: 0.1492 (0.1609)  loss_box_reg: 0.1256 (0.1515)  loss_objectness: 0.0850 (0.1006)  loss_rpn_box_reg: 0.0209 (0.0335)  time: 0.2719  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [14]  [  80/1229]  eta: 0:05:19  lr: 0.000050  loss: 0.4777 (0.4416)  loss_classifier: 0.1497 (0.1590)  loss_box_reg: 0.1256 (0.1485)  loss_objectness: 0.0982 (0.1006)  loss_rpn_box_reg: 0.0253 (0.0335)  time: 0.2804  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [14]  [  90/1229]  eta: 0:05:17  lr: 0.000050  loss: 0.3563 (0.4373)  loss_classifier: 0.1282 (0.1573)  loss_box_reg: 0.1172 (0.1482)  loss_objectness: 0.0616 (0.0989)  loss_rpn_box_reg: 0.0234 (0.0328)  time: 0.2853  data: 0.1381  max mem: 1751\n",
      "Training Epoch: [14]  [ 100/1229]  eta: 0:05:15  lr: 0.000050  loss: 0.3260 (0.4284)  loss_classifier: 0.1281 (0.1535)  loss_box_reg: 0.1122 (0.1447)  loss_objectness: 0.0633 (0.0975)  loss_rpn_box_reg: 0.0176 (0.0328)  time: 0.2849  data: 0.1414  max mem: 1751\n",
      "Training Epoch: [14]  [ 110/1229]  eta: 0:05:13  lr: 0.000050  loss: 0.4177 (0.4342)  loss_classifier: 0.1433 (0.1555)  loss_box_reg: 0.1110 (0.1470)  loss_objectness: 0.0903 (0.0981)  loss_rpn_box_reg: 0.0358 (0.0336)  time: 0.2851  data: 0.1416  max mem: 1751\n",
      "Training Epoch: [14]  [ 120/1229]  eta: 0:05:10  lr: 0.000050  loss: 0.4433 (0.4364)  loss_classifier: 0.1622 (0.1568)  loss_box_reg: 0.1575 (0.1490)  loss_objectness: 0.1006 (0.0980)  loss_rpn_box_reg: 0.0197 (0.0326)  time: 0.2821  data: 0.1412  max mem: 1751\n",
      "Training Epoch: [14]  [ 130/1229]  eta: 0:05:08  lr: 0.000050  loss: 0.3835 (0.4344)  loss_classifier: 0.1423 (0.1567)  loss_box_reg: 0.1332 (0.1468)  loss_objectness: 0.0860 (0.0983)  loss_rpn_box_reg: 0.0194 (0.0326)  time: 0.2826  data: 0.1413  max mem: 1751\n",
      "Training Epoch: [14]  [ 140/1229]  eta: 0:05:05  lr: 0.000050  loss: 0.3798 (0.4407)  loss_classifier: 0.1423 (0.1590)  loss_box_reg: 0.1282 (0.1494)  loss_objectness: 0.0846 (0.0993)  loss_rpn_box_reg: 0.0262 (0.0330)  time: 0.2843  data: 0.1423  max mem: 1751\n",
      "Training Epoch: [14]  [ 150/1229]  eta: 0:05:03  lr: 0.000050  loss: 0.3634 (0.4343)  loss_classifier: 0.1322 (0.1570)  loss_box_reg: 0.1206 (0.1467)  loss_objectness: 0.0712 (0.0987)  loss_rpn_box_reg: 0.0147 (0.0319)  time: 0.2848  data: 0.1427  max mem: 1751\n",
      "Training Epoch: [14]  [ 160/1229]  eta: 0:05:00  lr: 0.000050  loss: 0.3675 (0.4415)  loss_classifier: 0.1322 (0.1590)  loss_box_reg: 0.1135 (0.1496)  loss_objectness: 0.0889 (0.0993)  loss_rpn_box_reg: 0.0155 (0.0336)  time: 0.2847  data: 0.1402  max mem: 1751\n",
      "Training Epoch: [14]  [ 170/1229]  eta: 0:04:57  lr: 0.000050  loss: 0.6075 (0.4476)  loss_classifier: 0.1924 (0.1603)  loss_box_reg: 0.1927 (0.1527)  loss_objectness: 0.0936 (0.0999)  loss_rpn_box_reg: 0.0296 (0.0348)  time: 0.2789  data: 0.1391  max mem: 1751\n",
      "Training Epoch: [14]  [ 180/1229]  eta: 0:04:55  lr: 0.000050  loss: 0.3752 (0.4455)  loss_classifier: 0.1259 (0.1596)  loss_box_reg: 0.1152 (0.1527)  loss_objectness: 0.0783 (0.0988)  loss_rpn_box_reg: 0.0209 (0.0343)  time: 0.2860  data: 0.1404  max mem: 1751\n",
      "Training Epoch: [14]  [ 190/1229]  eta: 0:04:52  lr: 0.000050  loss: 0.3752 (0.4467)  loss_classifier: 0.1259 (0.1598)  loss_box_reg: 0.1152 (0.1531)  loss_objectness: 0.0747 (0.0996)  loss_rpn_box_reg: 0.0162 (0.0343)  time: 0.2857  data: 0.1421  max mem: 1751\n",
      "Training Epoch: [14]  [ 200/1229]  eta: 0:04:49  lr: 0.000050  loss: 0.3764 (0.4448)  loss_classifier: 0.1288 (0.1584)  loss_box_reg: 0.1327 (0.1524)  loss_objectness: 0.0749 (0.0986)  loss_rpn_box_reg: 0.0218 (0.0355)  time: 0.2812  data: 0.1434  max mem: 1751\n",
      "Training Epoch: [14]  [ 210/1229]  eta: 0:04:47  lr: 0.000050  loss: 0.4331 (0.4464)  loss_classifier: 0.1421 (0.1587)  loss_box_reg: 0.1415 (0.1535)  loss_objectness: 0.0749 (0.0982)  loss_rpn_box_reg: 0.0286 (0.0359)  time: 0.2950  data: 0.1446  max mem: 1751\n",
      "Training Epoch: [14]  [ 220/1229]  eta: 0:04:45  lr: 0.000050  loss: 0.4331 (0.4472)  loss_classifier: 0.1622 (0.1591)  loss_box_reg: 0.1561 (0.1541)  loss_objectness: 0.0853 (0.0982)  loss_rpn_box_reg: 0.0286 (0.0358)  time: 0.2922  data: 0.1456  max mem: 1751\n",
      "Training Epoch: [14]  [ 230/1229]  eta: 0:04:42  lr: 0.000050  loss: 0.4518 (0.4497)  loss_classifier: 0.1514 (0.1596)  loss_box_reg: 0.1459 (0.1549)  loss_objectness: 0.0885 (0.0988)  loss_rpn_box_reg: 0.0325 (0.0363)  time: 0.2805  data: 0.1434  max mem: 1751\n",
      "Training Epoch: [14]  [ 240/1229]  eta: 0:04:39  lr: 0.000050  loss: 0.4518 (0.4527)  loss_classifier: 0.1514 (0.1604)  loss_box_reg: 0.1459 (0.1570)  loss_objectness: 0.0929 (0.0987)  loss_rpn_box_reg: 0.0305 (0.0366)  time: 0.2784  data: 0.1419  max mem: 1751\n",
      "Training Epoch: [14]  [ 250/1229]  eta: 0:04:36  lr: 0.000050  loss: 0.4591 (0.4556)  loss_classifier: 0.1758 (0.1613)  loss_box_reg: 0.1582 (0.1574)  loss_objectness: 0.1230 (0.1001)  loss_rpn_box_reg: 0.0276 (0.0369)  time: 0.2836  data: 0.1432  max mem: 1751\n",
      "Training Epoch: [14]  [ 260/1229]  eta: 0:04:33  lr: 0.000050  loss: 0.3997 (0.4538)  loss_classifier: 0.1514 (0.1607)  loss_box_reg: 0.1489 (0.1571)  loss_objectness: 0.0960 (0.0997)  loss_rpn_box_reg: 0.0276 (0.0363)  time: 0.2850  data: 0.1460  max mem: 1751\n",
      "Training Epoch: [14]  [ 270/1229]  eta: 0:04:30  lr: 0.000050  loss: 0.3817 (0.4538)  loss_classifier: 0.1461 (0.1609)  loss_box_reg: 0.1160 (0.1579)  loss_objectness: 0.0764 (0.0991)  loss_rpn_box_reg: 0.0168 (0.0359)  time: 0.2816  data: 0.1452  max mem: 1751\n",
      "Training Epoch: [14]  [ 280/1229]  eta: 0:04:27  lr: 0.000050  loss: 0.3999 (0.4564)  loss_classifier: 0.1514 (0.1616)  loss_box_reg: 0.1537 (0.1591)  loss_objectness: 0.0833 (0.0992)  loss_rpn_box_reg: 0.0168 (0.0365)  time: 0.2811  data: 0.1426  max mem: 1751\n",
      "Training Epoch: [14]  [ 290/1229]  eta: 0:04:25  lr: 0.000050  loss: 0.4183 (0.4575)  loss_classifier: 0.1603 (0.1621)  loss_box_reg: 0.1544 (0.1589)  loss_objectness: 0.0850 (0.1001)  loss_rpn_box_reg: 0.0323 (0.0365)  time: 0.2853  data: 0.1411  max mem: 1751\n",
      "Training Epoch: [14]  [ 300/1229]  eta: 0:04:22  lr: 0.000050  loss: 0.4067 (0.4560)  loss_classifier: 0.1451 (0.1615)  loss_box_reg: 0.1064 (0.1580)  loss_objectness: 0.0892 (0.1005)  loss_rpn_box_reg: 0.0214 (0.0361)  time: 0.2841  data: 0.1427  max mem: 1751\n",
      "Training Epoch: [14]  [ 310/1229]  eta: 0:04:19  lr: 0.000050  loss: 0.3861 (0.4545)  loss_classifier: 0.1090 (0.1610)  loss_box_reg: 0.0925 (0.1567)  loss_objectness: 0.0939 (0.1011)  loss_rpn_box_reg: 0.0127 (0.0356)  time: 0.2843  data: 0.1452  max mem: 1751\n",
      "Training Epoch: [14]  [ 320/1229]  eta: 0:04:17  lr: 0.000050  loss: 0.2606 (0.4492)  loss_classifier: 0.0786 (0.1589)  loss_box_reg: 0.0619 (0.1547)  loss_objectness: 0.0751 (0.1002)  loss_rpn_box_reg: 0.0124 (0.0354)  time: 0.2881  data: 0.1444  max mem: 1751\n",
      "Training Epoch: [14]  [ 330/1229]  eta: 0:04:14  lr: 0.000050  loss: 0.2606 (0.4452)  loss_classifier: 0.0889 (0.1575)  loss_box_reg: 0.0783 (0.1527)  loss_objectness: 0.0680 (0.1001)  loss_rpn_box_reg: 0.0137 (0.0349)  time: 0.2820  data: 0.1409  max mem: 1751\n",
      "Training Epoch: [14]  [ 340/1229]  eta: 0:04:11  lr: 0.000050  loss: 0.3271 (0.4432)  loss_classifier: 0.1125 (0.1570)  loss_box_reg: 0.0943 (0.1514)  loss_objectness: 0.1068 (0.1001)  loss_rpn_box_reg: 0.0209 (0.0348)  time: 0.2800  data: 0.1429  max mem: 1751\n",
      "Training Epoch: [14]  [ 350/1229]  eta: 0:04:08  lr: 0.000050  loss: 0.3724 (0.4436)  loss_classifier: 0.1385 (0.1573)  loss_box_reg: 0.0973 (0.1517)  loss_objectness: 0.0954 (0.1002)  loss_rpn_box_reg: 0.0193 (0.0344)  time: 0.2843  data: 0.1464  max mem: 1751\n",
      "Training Epoch: [14]  [ 360/1229]  eta: 0:04:05  lr: 0.000050  loss: 0.4228 (0.4431)  loss_classifier: 0.1438 (0.1572)  loss_box_reg: 0.1521 (0.1519)  loss_objectness: 0.0953 (0.1002)  loss_rpn_box_reg: 0.0159 (0.0339)  time: 0.2848  data: 0.1450  max mem: 1751\n",
      "Training Epoch: [14]  [ 370/1229]  eta: 0:04:03  lr: 0.000050  loss: 0.3698 (0.4388)  loss_classifier: 0.1272 (0.1560)  loss_box_reg: 0.1100 (0.1505)  loss_objectness: 0.0633 (0.0991)  loss_rpn_box_reg: 0.0117 (0.0332)  time: 0.2891  data: 0.1458  max mem: 1751\n",
      "Training Epoch: [14]  [ 380/1229]  eta: 0:04:00  lr: 0.000050  loss: 0.2865 (0.4352)  loss_classifier: 0.1040 (0.1549)  loss_box_reg: 0.0903 (0.1489)  loss_objectness: 0.0605 (0.0986)  loss_rpn_box_reg: 0.0117 (0.0329)  time: 0.2925  data: 0.1479  max mem: 1751\n",
      "Training Epoch: [14]  [ 390/1229]  eta: 0:03:57  lr: 0.000050  loss: 0.3159 (0.4331)  loss_classifier: 0.1040 (0.1541)  loss_box_reg: 0.0779 (0.1477)  loss_objectness: 0.0774 (0.0985)  loss_rpn_box_reg: 0.0149 (0.0328)  time: 0.2835  data: 0.1474  max mem: 1751\n",
      "Training Epoch: [14]  [ 400/1229]  eta: 0:03:54  lr: 0.000050  loss: 0.3422 (0.4344)  loss_classifier: 0.1304 (0.1548)  loss_box_reg: 0.1038 (0.1480)  loss_objectness: 0.1020 (0.0989)  loss_rpn_box_reg: 0.0181 (0.0327)  time: 0.2856  data: 0.1449  max mem: 1751\n",
      "Training Epoch: [14]  [ 410/1229]  eta: 0:03:52  lr: 0.000050  loss: 0.3352 (0.4346)  loss_classifier: 0.1309 (0.1550)  loss_box_reg: 0.1135 (0.1481)  loss_objectness: 0.0925 (0.0987)  loss_rpn_box_reg: 0.0202 (0.0328)  time: 0.2867  data: 0.1423  max mem: 1751\n",
      "Training Epoch: [14]  [ 420/1229]  eta: 0:03:49  lr: 0.000050  loss: 0.3587 (0.4345)  loss_classifier: 0.1292 (0.1548)  loss_box_reg: 0.1216 (0.1480)  loss_objectness: 0.0775 (0.0991)  loss_rpn_box_reg: 0.0178 (0.0325)  time: 0.2803  data: 0.1397  max mem: 1751\n",
      "Training Epoch: [14]  [ 430/1229]  eta: 0:03:46  lr: 0.000050  loss: 0.4071 (0.4345)  loss_classifier: 0.1361 (0.1549)  loss_box_reg: 0.1348 (0.1478)  loss_objectness: 0.0816 (0.0992)  loss_rpn_box_reg: 0.0185 (0.0327)  time: 0.2771  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [14]  [ 440/1229]  eta: 0:03:43  lr: 0.000050  loss: 0.4599 (0.4359)  loss_classifier: 0.1632 (0.1553)  loss_box_reg: 0.1362 (0.1479)  loss_objectness: 0.0938 (0.0996)  loss_rpn_box_reg: 0.0194 (0.0331)  time: 0.2746  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [14]  [ 450/1229]  eta: 0:03:40  lr: 0.000050  loss: 0.4989 (0.4361)  loss_classifier: 0.1672 (0.1555)  loss_box_reg: 0.1344 (0.1477)  loss_objectness: 0.1097 (0.1001)  loss_rpn_box_reg: 0.0204 (0.0328)  time: 0.2697  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [14]  [ 460/1229]  eta: 0:03:37  lr: 0.000050  loss: 0.4477 (0.4362)  loss_classifier: 0.1443 (0.1553)  loss_box_reg: 0.1344 (0.1481)  loss_objectness: 0.0937 (0.0997)  loss_rpn_box_reg: 0.0204 (0.0331)  time: 0.2684  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [14]  [ 470/1229]  eta: 0:03:33  lr: 0.000050  loss: 0.4477 (0.4381)  loss_classifier: 0.1415 (0.1557)  loss_box_reg: 0.1449 (0.1489)  loss_objectness: 0.0724 (0.1000)  loss_rpn_box_reg: 0.0335 (0.0334)  time: 0.2670  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [14]  [ 480/1229]  eta: 0:03:30  lr: 0.000050  loss: 0.3963 (0.4370)  loss_classifier: 0.1097 (0.1555)  loss_box_reg: 0.1260 (0.1485)  loss_objectness: 0.0745 (0.0997)  loss_rpn_box_reg: 0.0242 (0.0332)  time: 0.2645  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [14]  [ 490/1229]  eta: 0:03:27  lr: 0.000050  loss: 0.3963 (0.4373)  loss_classifier: 0.1203 (0.1557)  loss_box_reg: 0.0986 (0.1486)  loss_objectness: 0.0823 (0.0997)  loss_rpn_box_reg: 0.0242 (0.0333)  time: 0.2652  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [14]  [ 500/1229]  eta: 0:03:24  lr: 0.000050  loss: 0.4454 (0.4377)  loss_classifier: 0.1685 (0.1560)  loss_box_reg: 0.0986 (0.1487)  loss_objectness: 0.1006 (0.0997)  loss_rpn_box_reg: 0.0227 (0.0332)  time: 0.2740  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [14]  [ 510/1229]  eta: 0:03:22  lr: 0.000050  loss: 0.3538 (0.4367)  loss_classifier: 0.1301 (0.1557)  loss_box_reg: 0.1003 (0.1479)  loss_objectness: 0.1006 (0.0999)  loss_rpn_box_reg: 0.0167 (0.0332)  time: 0.2786  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [14]  [ 520/1229]  eta: 0:03:19  lr: 0.000050  loss: 0.3143 (0.4347)  loss_classifier: 0.1165 (0.1550)  loss_box_reg: 0.0728 (0.1470)  loss_objectness: 0.0867 (0.0996)  loss_rpn_box_reg: 0.0182 (0.0331)  time: 0.2767  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [14]  [ 530/1229]  eta: 0:03:16  lr: 0.000050  loss: 0.3523 (0.4348)  loss_classifier: 0.1267 (0.1549)  loss_box_reg: 0.1158 (0.1473)  loss_objectness: 0.0627 (0.0992)  loss_rpn_box_reg: 0.0182 (0.0335)  time: 0.2740  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [14]  [ 540/1229]  eta: 0:03:13  lr: 0.000050  loss: 0.4620 (0.4366)  loss_classifier: 0.1705 (0.1556)  loss_box_reg: 0.1504 (0.1479)  loss_objectness: 0.0899 (0.0996)  loss_rpn_box_reg: 0.0261 (0.0336)  time: 0.2658  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [14]  [ 550/1229]  eta: 0:03:10  lr: 0.000050  loss: 0.4345 (0.4354)  loss_classifier: 0.1558 (0.1552)  loss_box_reg: 0.1240 (0.1476)  loss_objectness: 0.0836 (0.0991)  loss_rpn_box_reg: 0.0304 (0.0335)  time: 0.2644  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [14]  [ 560/1229]  eta: 0:03:07  lr: 0.000050  loss: 0.3288 (0.4340)  loss_classifier: 0.1289 (0.1547)  loss_box_reg: 0.1088 (0.1468)  loss_objectness: 0.0665 (0.0990)  loss_rpn_box_reg: 0.0116 (0.0337)  time: 0.2671  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [14]  [ 570/1229]  eta: 0:03:04  lr: 0.000050  loss: 0.3525 (0.4339)  loss_classifier: 0.1289 (0.1546)  loss_box_reg: 0.1129 (0.1464)  loss_objectness: 0.0890 (0.0992)  loss_rpn_box_reg: 0.0124 (0.0337)  time: 0.2722  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [14]  [ 580/1229]  eta: 0:03:01  lr: 0.000050  loss: 0.4150 (0.4350)  loss_classifier: 0.1406 (0.1548)  loss_box_reg: 0.0965 (0.1467)  loss_objectness: 0.0981 (0.0995)  loss_rpn_box_reg: 0.0209 (0.0340)  time: 0.2771  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [14]  [ 590/1229]  eta: 0:02:58  lr: 0.000050  loss: 0.4216 (0.4353)  loss_classifier: 0.1406 (0.1547)  loss_box_reg: 0.1022 (0.1467)  loss_objectness: 0.0828 (0.0993)  loss_rpn_box_reg: 0.0237 (0.0346)  time: 0.2744  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [14]  [ 600/1229]  eta: 0:02:55  lr: 0.000050  loss: 0.4216 (0.4361)  loss_classifier: 0.1526 (0.1550)  loss_box_reg: 0.1377 (0.1466)  loss_objectness: 0.0723 (0.0997)  loss_rpn_box_reg: 0.0334 (0.0347)  time: 0.2709  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [14]  [ 610/1229]  eta: 0:02:53  lr: 0.000050  loss: 0.4295 (0.4364)  loss_classifier: 0.1334 (0.1551)  loss_box_reg: 0.1044 (0.1469)  loss_objectness: 0.0860 (0.0995)  loss_rpn_box_reg: 0.0279 (0.0349)  time: 0.2768  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [14]  [ 620/1229]  eta: 0:02:50  lr: 0.000050  loss: 0.4068 (0.4360)  loss_classifier: 0.1271 (0.1551)  loss_box_reg: 0.0927 (0.1468)  loss_objectness: 0.0827 (0.0994)  loss_rpn_box_reg: 0.0269 (0.0348)  time: 0.2769  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [14]  [ 630/1229]  eta: 0:02:47  lr: 0.000050  loss: 0.3497 (0.4347)  loss_classifier: 0.1298 (0.1546)  loss_box_reg: 0.0927 (0.1464)  loss_objectness: 0.0826 (0.0991)  loss_rpn_box_reg: 0.0147 (0.0346)  time: 0.2792  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [14]  [ 640/1229]  eta: 0:02:44  lr: 0.000050  loss: 0.3497 (0.4333)  loss_classifier: 0.1298 (0.1540)  loss_box_reg: 0.0941 (0.1460)  loss_objectness: 0.0600 (0.0987)  loss_rpn_box_reg: 0.0147 (0.0345)  time: 0.2813  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [14]  [ 650/1229]  eta: 0:02:41  lr: 0.000050  loss: 0.3435 (0.4330)  loss_classifier: 0.1125 (0.1541)  loss_box_reg: 0.0794 (0.1461)  loss_objectness: 0.0619 (0.0985)  loss_rpn_box_reg: 0.0151 (0.0343)  time: 0.2726  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [14]  [ 660/1229]  eta: 0:02:38  lr: 0.000050  loss: 0.3015 (0.4315)  loss_classifier: 0.1196 (0.1537)  loss_box_reg: 0.0870 (0.1455)  loss_objectness: 0.0732 (0.0981)  loss_rpn_box_reg: 0.0151 (0.0342)  time: 0.2706  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [14]  [ 670/1229]  eta: 0:02:36  lr: 0.000050  loss: 0.3604 (0.4319)  loss_classifier: 0.1204 (0.1538)  loss_box_reg: 0.0957 (0.1457)  loss_objectness: 0.0896 (0.0982)  loss_rpn_box_reg: 0.0211 (0.0343)  time: 0.2734  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [14]  [ 680/1229]  eta: 0:02:33  lr: 0.000050  loss: 0.3901 (0.4316)  loss_classifier: 0.1204 (0.1535)  loss_box_reg: 0.0968 (0.1454)  loss_objectness: 0.1041 (0.0983)  loss_rpn_box_reg: 0.0281 (0.0344)  time: 0.2735  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [14]  [ 690/1229]  eta: 0:02:30  lr: 0.000050  loss: 0.3322 (0.4314)  loss_classifier: 0.1171 (0.1533)  loss_box_reg: 0.0928 (0.1452)  loss_objectness: 0.0914 (0.0983)  loss_rpn_box_reg: 0.0221 (0.0345)  time: 0.2717  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [14]  [ 700/1229]  eta: 0:02:27  lr: 0.000050  loss: 0.3257 (0.4313)  loss_classifier: 0.1171 (0.1532)  loss_box_reg: 0.0966 (0.1453)  loss_objectness: 0.0784 (0.0981)  loss_rpn_box_reg: 0.0221 (0.0346)  time: 0.2676  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [14]  [ 710/1229]  eta: 0:02:24  lr: 0.000050  loss: 0.3000 (0.4308)  loss_classifier: 0.1221 (0.1532)  loss_box_reg: 0.1003 (0.1453)  loss_objectness: 0.0790 (0.0980)  loss_rpn_box_reg: 0.0159 (0.0344)  time: 0.2697  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [14]  [ 720/1229]  eta: 0:02:21  lr: 0.000050  loss: 0.3833 (0.4312)  loss_classifier: 0.1239 (0.1533)  loss_box_reg: 0.1279 (0.1455)  loss_objectness: 0.0790 (0.0981)  loss_rpn_box_reg: 0.0221 (0.0343)  time: 0.2713  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [14]  [ 730/1229]  eta: 0:02:18  lr: 0.000050  loss: 0.4524 (0.4310)  loss_classifier: 0.1556 (0.1533)  loss_box_reg: 0.1406 (0.1456)  loss_objectness: 0.0838 (0.0979)  loss_rpn_box_reg: 0.0239 (0.0342)  time: 0.2700  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [14]  [ 740/1229]  eta: 0:02:16  lr: 0.000050  loss: 0.3867 (0.4310)  loss_classifier: 0.1458 (0.1532)  loss_box_reg: 0.1241 (0.1454)  loss_objectness: 0.0963 (0.0981)  loss_rpn_box_reg: 0.0239 (0.0343)  time: 0.2702  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [14]  [ 750/1229]  eta: 0:02:13  lr: 0.000050  loss: 0.3867 (0.4317)  loss_classifier: 0.1282 (0.1534)  loss_box_reg: 0.1315 (0.1453)  loss_objectness: 0.1134 (0.0986)  loss_rpn_box_reg: 0.0230 (0.0345)  time: 0.2736  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [14]  [ 760/1229]  eta: 0:02:10  lr: 0.000050  loss: 0.4806 (0.4321)  loss_classifier: 0.1729 (0.1535)  loss_box_reg: 0.1329 (0.1454)  loss_objectness: 0.1102 (0.0988)  loss_rpn_box_reg: 0.0313 (0.0344)  time: 0.2729  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [14]  [ 770/1229]  eta: 0:02:07  lr: 0.000050  loss: 0.4872 (0.4331)  loss_classifier: 0.1729 (0.1539)  loss_box_reg: 0.1404 (0.1456)  loss_objectness: 0.1093 (0.0992)  loss_rpn_box_reg: 0.0289 (0.0343)  time: 0.2705  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [14]  [ 780/1229]  eta: 0:02:04  lr: 0.000050  loss: 0.4573 (0.4335)  loss_classifier: 0.1794 (0.1541)  loss_box_reg: 0.1404 (0.1459)  loss_objectness: 0.1093 (0.0992)  loss_rpn_box_reg: 0.0246 (0.0342)  time: 0.2770  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [14]  [ 790/1229]  eta: 0:02:02  lr: 0.000050  loss: 0.4893 (0.4340)  loss_classifier: 0.1794 (0.1542)  loss_box_reg: 0.1497 (0.1461)  loss_objectness: 0.0860 (0.0994)  loss_rpn_box_reg: 0.0246 (0.0343)  time: 0.2792  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [14]  [ 800/1229]  eta: 0:01:59  lr: 0.000050  loss: 0.3698 (0.4336)  loss_classifier: 0.1401 (0.1540)  loss_box_reg: 0.1287 (0.1458)  loss_objectness: 0.0820 (0.0993)  loss_rpn_box_reg: 0.0209 (0.0345)  time: 0.2742  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [14]  [ 810/1229]  eta: 0:01:56  lr: 0.000050  loss: 0.3375 (0.4336)  loss_classifier: 0.1096 (0.1540)  loss_box_reg: 0.1036 (0.1458)  loss_objectness: 0.0766 (0.0992)  loss_rpn_box_reg: 0.0209 (0.0346)  time: 0.2747  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [14]  [ 820/1229]  eta: 0:01:53  lr: 0.000050  loss: 0.4504 (0.4339)  loss_classifier: 0.1556 (0.1541)  loss_box_reg: 0.1354 (0.1461)  loss_objectness: 0.0898 (0.0992)  loss_rpn_box_reg: 0.0242 (0.0345)  time: 0.2720  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [14]  [ 830/1229]  eta: 0:01:50  lr: 0.000050  loss: 0.4504 (0.4340)  loss_classifier: 0.1592 (0.1542)  loss_box_reg: 0.1494 (0.1461)  loss_objectness: 0.0898 (0.0993)  loss_rpn_box_reg: 0.0239 (0.0344)  time: 0.2703  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [14]  [ 840/1229]  eta: 0:01:48  lr: 0.000050  loss: 0.4288 (0.4347)  loss_classifier: 0.1477 (0.1542)  loss_box_reg: 0.1283 (0.1463)  loss_objectness: 0.1006 (0.0996)  loss_rpn_box_reg: 0.0232 (0.0346)  time: 0.2706  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [14]  [ 850/1229]  eta: 0:01:45  lr: 0.000050  loss: 0.4228 (0.4356)  loss_classifier: 0.1487 (0.1545)  loss_box_reg: 0.1283 (0.1464)  loss_objectness: 0.1021 (0.0998)  loss_rpn_box_reg: 0.0209 (0.0349)  time: 0.2716  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [14]  [ 860/1229]  eta: 0:01:42  lr: 0.000050  loss: 0.4304 (0.4359)  loss_classifier: 0.1620 (0.1546)  loss_box_reg: 0.1164 (0.1466)  loss_objectness: 0.1021 (0.0999)  loss_rpn_box_reg: 0.0199 (0.0348)  time: 0.2738  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [14]  [ 870/1229]  eta: 0:01:39  lr: 0.000050  loss: 0.3196 (0.4349)  loss_classifier: 0.1434 (0.1543)  loss_box_reg: 0.1005 (0.1464)  loss_objectness: 0.0855 (0.0997)  loss_rpn_box_reg: 0.0136 (0.0346)  time: 0.2669  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [14]  [ 880/1229]  eta: 0:01:36  lr: 0.000050  loss: 0.3196 (0.4344)  loss_classifier: 0.1251 (0.1541)  loss_box_reg: 0.1331 (0.1464)  loss_objectness: 0.0654 (0.0993)  loss_rpn_box_reg: 0.0134 (0.0346)  time: 0.2743  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [14]  [ 890/1229]  eta: 0:01:34  lr: 0.000050  loss: 0.3467 (0.4337)  loss_classifier: 0.1251 (0.1539)  loss_box_reg: 0.0927 (0.1462)  loss_objectness: 0.0622 (0.0992)  loss_rpn_box_reg: 0.0139 (0.0345)  time: 0.2754  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [14]  [ 900/1229]  eta: 0:01:31  lr: 0.000050  loss: 0.2945 (0.4325)  loss_classifier: 0.1070 (0.1534)  loss_box_reg: 0.0790 (0.1457)  loss_objectness: 0.0611 (0.0989)  loss_rpn_box_reg: 0.0115 (0.0344)  time: 0.2688  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [14]  [ 910/1229]  eta: 0:01:28  lr: 0.000050  loss: 0.3608 (0.4337)  loss_classifier: 0.1346 (0.1538)  loss_box_reg: 0.1021 (0.1462)  loss_objectness: 0.1006 (0.0990)  loss_rpn_box_reg: 0.0323 (0.0347)  time: 0.2720  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [14]  [ 920/1229]  eta: 0:01:25  lr: 0.000050  loss: 0.4254 (0.4338)  loss_classifier: 0.1639 (0.1538)  loss_box_reg: 0.1298 (0.1463)  loss_objectness: 0.1024 (0.0990)  loss_rpn_box_reg: 0.0317 (0.0347)  time: 0.2719  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [14]  [ 930/1229]  eta: 0:01:22  lr: 0.000050  loss: 0.3784 (0.4328)  loss_classifier: 0.1399 (0.1536)  loss_box_reg: 0.1247 (0.1457)  loss_objectness: 0.0829 (0.0989)  loss_rpn_box_reg: 0.0228 (0.0346)  time: 0.2744  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [14]  [ 940/1229]  eta: 0:01:20  lr: 0.000050  loss: 0.3514 (0.4334)  loss_classifier: 0.1206 (0.1538)  loss_box_reg: 0.1158 (0.1461)  loss_objectness: 0.0930 (0.0991)  loss_rpn_box_reg: 0.0179 (0.0345)  time: 0.2747  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [14]  [ 950/1229]  eta: 0:01:17  lr: 0.000050  loss: 0.2942 (0.4331)  loss_classifier: 0.1058 (0.1538)  loss_box_reg: 0.1138 (0.1459)  loss_objectness: 0.0912 (0.0990)  loss_rpn_box_reg: 0.0139 (0.0344)  time: 0.2674  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [14]  [ 960/1229]  eta: 0:01:14  lr: 0.000050  loss: 0.3010 (0.4322)  loss_classifier: 0.1133 (0.1534)  loss_box_reg: 0.0775 (0.1455)  loss_objectness: 0.0726 (0.0990)  loss_rpn_box_reg: 0.0107 (0.0343)  time: 0.2655  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [14]  [ 970/1229]  eta: 0:01:11  lr: 0.000050  loss: 0.3386 (0.4317)  loss_classifier: 0.1245 (0.1533)  loss_box_reg: 0.1078 (0.1453)  loss_objectness: 0.0594 (0.0987)  loss_rpn_box_reg: 0.0127 (0.0345)  time: 0.2758  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [14]  [ 980/1229]  eta: 0:01:08  lr: 0.000050  loss: 0.3772 (0.4323)  loss_classifier: 0.1343 (0.1534)  loss_box_reg: 0.1173 (0.1457)  loss_objectness: 0.0672 (0.0988)  loss_rpn_box_reg: 0.0280 (0.0345)  time: 0.2832  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [14]  [ 990/1229]  eta: 0:01:06  lr: 0.000050  loss: 0.4906 (0.4338)  loss_classifier: 0.1801 (0.1541)  loss_box_reg: 0.1537 (0.1460)  loss_objectness: 0.0973 (0.0993)  loss_rpn_box_reg: 0.0339 (0.0345)  time: 0.2768  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [14]  [1000/1229]  eta: 0:01:03  lr: 0.000050  loss: 0.4857 (0.4336)  loss_classifier: 0.1829 (0.1540)  loss_box_reg: 0.1537 (0.1459)  loss_objectness: 0.0904 (0.0992)  loss_rpn_box_reg: 0.0195 (0.0345)  time: 0.2765  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [14]  [1010/1229]  eta: 0:01:00  lr: 0.000050  loss: 0.3660 (0.4328)  loss_classifier: 0.1284 (0.1539)  loss_box_reg: 0.1056 (0.1455)  loss_objectness: 0.0701 (0.0991)  loss_rpn_box_reg: 0.0169 (0.0343)  time: 0.2785  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [14]  [1020/1229]  eta: 0:00:57  lr: 0.000050  loss: 0.3660 (0.4331)  loss_classifier: 0.1501 (0.1541)  loss_box_reg: 0.1146 (0.1457)  loss_objectness: 0.0893 (0.0990)  loss_rpn_box_reg: 0.0169 (0.0342)  time: 0.2733  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [14]  [1030/1229]  eta: 0:00:55  lr: 0.000050  loss: 0.5058 (0.4341)  loss_classifier: 0.1772 (0.1544)  loss_box_reg: 0.1743 (0.1462)  loss_objectness: 0.0969 (0.0993)  loss_rpn_box_reg: 0.0228 (0.0343)  time: 0.2719  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [14]  [1040/1229]  eta: 0:00:52  lr: 0.000050  loss: 0.3845 (0.4331)  loss_classifier: 0.1199 (0.1540)  loss_box_reg: 0.1283 (0.1457)  loss_objectness: 0.0957 (0.0992)  loss_rpn_box_reg: 0.0228 (0.0342)  time: 0.2736  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [14]  [1050/1229]  eta: 0:00:49  lr: 0.000050  loss: 0.2928 (0.4332)  loss_classifier: 0.1172 (0.1541)  loss_box_reg: 0.0728 (0.1457)  loss_objectness: 0.0830 (0.0993)  loss_rpn_box_reg: 0.0157 (0.0341)  time: 0.2749  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [14]  [1060/1229]  eta: 0:00:46  lr: 0.000050  loss: 0.3959 (0.4340)  loss_classifier: 0.1310 (0.1544)  loss_box_reg: 0.1478 (0.1462)  loss_objectness: 0.0841 (0.0994)  loss_rpn_box_reg: 0.0224 (0.0340)  time: 0.2752  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [14]  [1070/1229]  eta: 0:00:44  lr: 0.000050  loss: 0.3296 (0.4324)  loss_classifier: 0.1189 (0.1539)  loss_box_reg: 0.1077 (0.1456)  loss_objectness: 0.0734 (0.0991)  loss_rpn_box_reg: 0.0200 (0.0339)  time: 0.2728  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [14]  [1080/1229]  eta: 0:00:41  lr: 0.000050  loss: 0.2792 (0.4322)  loss_classifier: 0.1072 (0.1538)  loss_box_reg: 0.0850 (0.1455)  loss_objectness: 0.0686 (0.0990)  loss_rpn_box_reg: 0.0159 (0.0338)  time: 0.2664  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [14]  [1090/1229]  eta: 0:00:38  lr: 0.000050  loss: 0.3907 (0.4324)  loss_classifier: 0.1423 (0.1539)  loss_box_reg: 0.1196 (0.1457)  loss_objectness: 0.0894 (0.0990)  loss_rpn_box_reg: 0.0200 (0.0338)  time: 0.2691  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [14]  [1100/1229]  eta: 0:00:35  lr: 0.000050  loss: 0.3768 (0.4320)  loss_classifier: 0.1229 (0.1537)  loss_box_reg: 0.1137 (0.1455)  loss_objectness: 0.0854 (0.0989)  loss_rpn_box_reg: 0.0273 (0.0338)  time: 0.2720  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [14]  [1110/1229]  eta: 0:00:32  lr: 0.000050  loss: 0.3806 (0.4322)  loss_classifier: 0.1376 (0.1538)  loss_box_reg: 0.1162 (0.1456)  loss_objectness: 0.0852 (0.0992)  loss_rpn_box_reg: 0.0216 (0.0337)  time: 0.2714  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [14]  [1120/1229]  eta: 0:00:30  lr: 0.000050  loss: 0.3806 (0.4315)  loss_classifier: 0.1376 (0.1535)  loss_box_reg: 0.1136 (0.1451)  loss_objectness: 0.0852 (0.0992)  loss_rpn_box_reg: 0.0190 (0.0337)  time: 0.2734  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [14]  [1130/1229]  eta: 0:00:27  lr: 0.000050  loss: 0.3629 (0.4312)  loss_classifier: 0.1187 (0.1534)  loss_box_reg: 0.1013 (0.1451)  loss_objectness: 0.0698 (0.0991)  loss_rpn_box_reg: 0.0174 (0.0336)  time: 0.2779  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [14]  [1140/1229]  eta: 0:00:24  lr: 0.000050  loss: 0.3340 (0.4307)  loss_classifier: 0.1179 (0.1531)  loss_box_reg: 0.0930 (0.1449)  loss_objectness: 0.0746 (0.0991)  loss_rpn_box_reg: 0.0255 (0.0336)  time: 0.2778  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [14]  [1150/1229]  eta: 0:00:21  lr: 0.000050  loss: 0.3342 (0.4303)  loss_classifier: 0.1179 (0.1530)  loss_box_reg: 0.1033 (0.1448)  loss_objectness: 0.0702 (0.0990)  loss_rpn_box_reg: 0.0234 (0.0335)  time: 0.2742  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [14]  [1160/1229]  eta: 0:00:19  lr: 0.000050  loss: 0.4299 (0.4321)  loss_classifier: 0.1472 (0.1536)  loss_box_reg: 0.1348 (0.1457)  loss_objectness: 0.0972 (0.0992)  loss_rpn_box_reg: 0.0189 (0.0336)  time: 0.2736  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [14]  [1170/1229]  eta: 0:00:16  lr: 0.000050  loss: 0.4845 (0.4322)  loss_classifier: 0.1709 (0.1537)  loss_box_reg: 0.1412 (0.1458)  loss_objectness: 0.1071 (0.0992)  loss_rpn_box_reg: 0.0184 (0.0335)  time: 0.2707  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [14]  [1180/1229]  eta: 0:00:13  lr: 0.000050  loss: 0.4000 (0.4324)  loss_classifier: 0.1290 (0.1536)  loss_box_reg: 0.0898 (0.1457)  loss_objectness: 0.1003 (0.0995)  loss_rpn_box_reg: 0.0211 (0.0336)  time: 0.2687  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [14]  [1190/1229]  eta: 0:00:10  lr: 0.000050  loss: 0.3104 (0.4316)  loss_classifier: 0.1112 (0.1532)  loss_box_reg: 0.0853 (0.1454)  loss_objectness: 0.0797 (0.0993)  loss_rpn_box_reg: 0.0210 (0.0336)  time: 0.2713  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [14]  [1200/1229]  eta: 0:00:08  lr: 0.000050  loss: 0.3107 (0.4316)  loss_classifier: 0.1112 (0.1532)  loss_box_reg: 0.1013 (0.1454)  loss_objectness: 0.0765 (0.0993)  loss_rpn_box_reg: 0.0213 (0.0336)  time: 0.2692  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [14]  [1210/1229]  eta: 0:00:05  lr: 0.000050  loss: 0.3595 (0.4314)  loss_classifier: 0.1365 (0.1532)  loss_box_reg: 0.1053 (0.1451)  loss_objectness: 0.0946 (0.0994)  loss_rpn_box_reg: 0.0213 (0.0337)  time: 0.2643  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [14]  [1220/1229]  eta: 0:00:02  lr: 0.000050  loss: 0.4416 (0.4329)  loss_classifier: 0.1426 (0.1537)  loss_box_reg: 0.1722 (0.1459)  loss_objectness: 0.1064 (0.0994)  loss_rpn_box_reg: 0.0182 (0.0339)  time: 0.2703  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [14]  [1228/1229]  eta: 0:00:00  lr: 0.000050  loss: 0.4126 (0.4330)  loss_classifier: 0.1426 (0.1537)  loss_box_reg: 0.1644 (0.1459)  loss_objectness: 0.0748 (0.0994)  loss_rpn_box_reg: 0.0328 (0.0340)  time: 0.2789  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [14] Total time: 0:05:39 (0.2764 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:48  model_time: 0.3190 (0.3190)  evaluator_time: 0.0020 (0.0020)  time: 0.3530  data: 0.0300  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0770 (0.0823)  evaluator_time: 0.0040 (0.0086)  time: 0.1285  data: 0.0373  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0830 (0.0808)  evaluator_time: 0.0030 (0.0078)  time: 0.1209  data: 0.0320  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0710 (0.0798)  evaluator_time: 0.0040 (0.0076)  time: 0.1204  data: 0.0365  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0710 (0.0797)  evaluator_time: 0.0020 (0.0076)  time: 0.1176  data: 0.0349  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1247 s / it)\n",
      "Averaged stats: model_time: 0.0710 (0.0797)  evaluator_time: 0.0020 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.116\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
      "Testing Epoch: [14]  [  0/308]  eta: 0:00:38  lr: 0.000050  loss: 0.1882 (0.1882)  loss_classifier: 0.0653 (0.0653)  loss_box_reg: 0.0759 (0.0759)  loss_objectness: 0.0356 (0.0356)  loss_rpn_box_reg: 0.0115 (0.0115)  time: 0.1250  data: 0.0300  max mem: 1751\n",
      "Testing Epoch: [14]  [100/308]  eta: 0:00:29  lr: 0.000050  loss: 0.3105 (0.4816)  loss_classifier: 0.1331 (0.1548)  loss_box_reg: 0.1152 (0.1728)  loss_objectness: 0.0571 (0.1023)  loss_rpn_box_reg: 0.0189 (0.0517)  time: 0.1400  data: 0.0392  max mem: 1751\n",
      "Testing Epoch: [14]  [200/308]  eta: 0:00:15  lr: 0.000050  loss: 0.3674 (0.4561)  loss_classifier: 0.1383 (0.1489)  loss_box_reg: 0.1290 (0.1630)  loss_objectness: 0.0623 (0.0951)  loss_rpn_box_reg: 0.0198 (0.0491)  time: 0.1383  data: 0.0333  max mem: 1751\n",
      "Testing Epoch: [14]  [300/308]  eta: 0:00:01  lr: 0.000050  loss: 0.4493 (0.4535)  loss_classifier: 0.1589 (0.1494)  loss_box_reg: 0.1686 (0.1641)  loss_objectness: 0.0802 (0.0924)  loss_rpn_box_reg: 0.0263 (0.0475)  time: 0.1333  data: 0.0384  max mem: 1751\n",
      "Testing Epoch: [14]  [307/308]  eta: 0:00:00  lr: 0.000050  loss: 0.4360 (0.4538)  loss_classifier: 0.1827 (0.1497)  loss_box_reg: 0.1686 (0.1645)  loss_objectness: 0.0716 (0.0926)  loss_rpn_box_reg: 0.0276 (0.0470)  time: 0.1303  data: 0.0361  max mem: 1751\n",
      "Testing Epoch: [14] Total time: 0:00:42 (0.1385 s / it)\n",
      "Training Epoch: [15]  [   0/1229]  eta: 0:05:31  lr: 0.000050  loss: 0.2379 (0.2379)  loss_classifier: 0.0736 (0.0736)  loss_box_reg: 0.0809 (0.0809)  loss_objectness: 0.0617 (0.0617)  loss_rpn_box_reg: 0.0217 (0.0217)  time: 0.2700  data: 0.1440  max mem: 1751\n",
      "Training Epoch: [15]  [  10/1229]  eta: 0:05:32  lr: 0.000050  loss: 0.3113 (0.3925)  loss_classifier: 0.1033 (0.1211)  loss_box_reg: 0.0809 (0.1093)  loss_objectness: 0.0787 (0.0957)  loss_rpn_box_reg: 0.0140 (0.0665)  time: 0.2725  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [15]  [  20/1229]  eta: 0:05:27  lr: 0.000050  loss: 0.3236 (0.3864)  loss_classifier: 0.1262 (0.1304)  loss_box_reg: 0.1307 (0.1172)  loss_objectness: 0.0780 (0.0931)  loss_rpn_box_reg: 0.0140 (0.0457)  time: 0.2712  data: 0.1296  max mem: 1751\n",
      "Training Epoch: [15]  [  30/1229]  eta: 0:05:26  lr: 0.000050  loss: 0.3720 (0.3854)  loss_classifier: 0.1232 (0.1318)  loss_box_reg: 0.1177 (0.1215)  loss_objectness: 0.0647 (0.0888)  loss_rpn_box_reg: 0.0155 (0.0433)  time: 0.2717  data: 0.1300  max mem: 1751\n",
      "Training Epoch: [15]  [  40/1229]  eta: 0:05:23  lr: 0.000050  loss: 0.3845 (0.4124)  loss_classifier: 0.1464 (0.1405)  loss_box_reg: 0.1346 (0.1384)  loss_objectness: 0.0682 (0.0906)  loss_rpn_box_reg: 0.0217 (0.0429)  time: 0.2725  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [15]  [  50/1229]  eta: 0:05:20  lr: 0.000050  loss: 0.4607 (0.4348)  loss_classifier: 0.1637 (0.1487)  loss_box_reg: 0.1891 (0.1487)  loss_objectness: 0.0847 (0.0937)  loss_rpn_box_reg: 0.0282 (0.0437)  time: 0.2718  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [15]  [  60/1229]  eta: 0:05:16  lr: 0.000050  loss: 0.4466 (0.4324)  loss_classifier: 0.1597 (0.1496)  loss_box_reg: 0.1342 (0.1460)  loss_objectness: 0.0935 (0.0960)  loss_rpn_box_reg: 0.0247 (0.0408)  time: 0.2688  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [15]  [  70/1229]  eta: 0:05:14  lr: 0.000050  loss: 0.4533 (0.4516)  loss_classifier: 0.1597 (0.1561)  loss_box_reg: 0.1342 (0.1491)  loss_objectness: 0.1014 (0.0992)  loss_rpn_box_reg: 0.0374 (0.0472)  time: 0.2700  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [15]  [  80/1229]  eta: 0:05:12  lr: 0.000050  loss: 0.4125 (0.4360)  loss_classifier: 0.1143 (0.1504)  loss_box_reg: 0.0995 (0.1433)  loss_objectness: 0.0994 (0.0984)  loss_rpn_box_reg: 0.0296 (0.0439)  time: 0.2743  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [15]  [  90/1229]  eta: 0:05:10  lr: 0.000050  loss: 0.3153 (0.4318)  loss_classifier: 0.1009 (0.1498)  loss_box_reg: 0.0914 (0.1410)  loss_objectness: 0.0796 (0.0987)  loss_rpn_box_reg: 0.0190 (0.0424)  time: 0.2763  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [15]  [ 100/1229]  eta: 0:05:06  lr: 0.000050  loss: 0.3484 (0.4291)  loss_classifier: 0.1290 (0.1491)  loss_box_reg: 0.0963 (0.1384)  loss_objectness: 0.0838 (0.0997)  loss_rpn_box_reg: 0.0231 (0.0419)  time: 0.2723  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [15]  [ 110/1229]  eta: 0:05:04  lr: 0.000050  loss: 0.3484 (0.4287)  loss_classifier: 0.1198 (0.1501)  loss_box_reg: 0.0963 (0.1380)  loss_objectness: 0.0671 (0.0999)  loss_rpn_box_reg: 0.0147 (0.0407)  time: 0.2684  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [15]  [ 120/1229]  eta: 0:05:01  lr: 0.000050  loss: 0.3482 (0.4291)  loss_classifier: 0.1262 (0.1506)  loss_box_reg: 0.0890 (0.1367)  loss_objectness: 0.1018 (0.1018)  loss_rpn_box_reg: 0.0174 (0.0400)  time: 0.2720  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [15]  [ 130/1229]  eta: 0:04:58  lr: 0.000050  loss: 0.4647 (0.4380)  loss_classifier: 0.1720 (0.1540)  loss_box_reg: 0.1015 (0.1402)  loss_objectness: 0.1048 (0.1028)  loss_rpn_box_reg: 0.0261 (0.0411)  time: 0.2680  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [15]  [ 140/1229]  eta: 0:04:55  lr: 0.000050  loss: 0.4760 (0.4367)  loss_classifier: 0.1720 (0.1530)  loss_box_reg: 0.1335 (0.1385)  loss_objectness: 0.1118 (0.1033)  loss_rpn_box_reg: 0.0228 (0.0420)  time: 0.2670  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [15]  [ 150/1229]  eta: 0:04:52  lr: 0.000050  loss: 0.3989 (0.4357)  loss_classifier: 0.1559 (0.1527)  loss_box_reg: 0.1228 (0.1386)  loss_objectness: 0.1118 (0.1037)  loss_rpn_box_reg: 0.0225 (0.0407)  time: 0.2675  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [15]  [ 160/1229]  eta: 0:04:50  lr: 0.000050  loss: 0.3480 (0.4303)  loss_classifier: 0.1074 (0.1517)  loss_box_reg: 0.1000 (0.1369)  loss_objectness: 0.0904 (0.1025)  loss_rpn_box_reg: 0.0193 (0.0392)  time: 0.2731  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [15]  [ 170/1229]  eta: 0:04:47  lr: 0.000050  loss: 0.2497 (0.4286)  loss_classifier: 0.1051 (0.1519)  loss_box_reg: 0.0898 (0.1369)  loss_objectness: 0.0542 (0.1008)  loss_rpn_box_reg: 0.0120 (0.0390)  time: 0.2784  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [15]  [ 180/1229]  eta: 0:04:44  lr: 0.000050  loss: 0.3204 (0.4290)  loss_classifier: 0.1290 (0.1527)  loss_box_reg: 0.1255 (0.1373)  loss_objectness: 0.0490 (0.1007)  loss_rpn_box_reg: 0.0183 (0.0384)  time: 0.2704  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [15]  [ 190/1229]  eta: 0:04:42  lr: 0.000050  loss: 0.4741 (0.4374)  loss_classifier: 0.1721 (0.1557)  loss_box_reg: 0.1285 (0.1406)  loss_objectness: 0.1219 (0.1026)  loss_rpn_box_reg: 0.0215 (0.0385)  time: 0.2732  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [15]  [ 200/1229]  eta: 0:04:40  lr: 0.000050  loss: 0.4168 (0.4352)  loss_classifier: 0.1554 (0.1550)  loss_box_reg: 0.1057 (0.1401)  loss_objectness: 0.1149 (0.1019)  loss_rpn_box_reg: 0.0324 (0.0382)  time: 0.2798  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [15]  [ 210/1229]  eta: 0:04:37  lr: 0.000050  loss: 0.3954 (0.4380)  loss_classifier: 0.1284 (0.1560)  loss_box_reg: 0.1183 (0.1424)  loss_objectness: 0.0701 (0.1014)  loss_rpn_box_reg: 0.0267 (0.0381)  time: 0.2748  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [15]  [ 220/1229]  eta: 0:04:34  lr: 0.000050  loss: 0.4563 (0.4384)  loss_classifier: 0.1620 (0.1561)  loss_box_reg: 0.1299 (0.1422)  loss_objectness: 0.1031 (0.1027)  loss_rpn_box_reg: 0.0253 (0.0374)  time: 0.2766  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [15]  [ 230/1229]  eta: 0:04:32  lr: 0.000050  loss: 0.3466 (0.4333)  loss_classifier: 0.1120 (0.1543)  loss_box_reg: 0.0936 (0.1400)  loss_objectness: 0.0906 (0.1022)  loss_rpn_box_reg: 0.0179 (0.0369)  time: 0.2778  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [15]  [ 240/1229]  eta: 0:04:29  lr: 0.000050  loss: 0.3474 (0.4303)  loss_classifier: 0.1227 (0.1535)  loss_box_reg: 0.1082 (0.1392)  loss_objectness: 0.0729 (0.1010)  loss_rpn_box_reg: 0.0206 (0.0366)  time: 0.2730  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [15]  [ 250/1229]  eta: 0:04:26  lr: 0.000050  loss: 0.3521 (0.4258)  loss_classifier: 0.1257 (0.1522)  loss_box_reg: 0.1082 (0.1376)  loss_objectness: 0.0749 (0.1003)  loss_rpn_box_reg: 0.0136 (0.0357)  time: 0.2690  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [15]  [ 260/1229]  eta: 0:04:24  lr: 0.000050  loss: 0.3263 (0.4246)  loss_classifier: 0.1249 (0.1522)  loss_box_reg: 0.0927 (0.1369)  loss_objectness: 0.0812 (0.1003)  loss_rpn_box_reg: 0.0128 (0.0352)  time: 0.2726  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [15]  [ 270/1229]  eta: 0:04:21  lr: 0.000050  loss: 0.3263 (0.4222)  loss_classifier: 0.1243 (0.1514)  loss_box_reg: 0.1246 (0.1367)  loss_objectness: 0.0872 (0.0996)  loss_rpn_box_reg: 0.0128 (0.0345)  time: 0.2793  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [15]  [ 280/1229]  eta: 0:04:19  lr: 0.000050  loss: 0.3682 (0.4236)  loss_classifier: 0.1384 (0.1521)  loss_box_reg: 0.1294 (0.1380)  loss_objectness: 0.0857 (0.0992)  loss_rpn_box_reg: 0.0180 (0.0343)  time: 0.2777  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [15]  [ 290/1229]  eta: 0:04:16  lr: 0.000050  loss: 0.4593 (0.4267)  loss_classifier: 0.1654 (0.1534)  loss_box_reg: 0.1409 (0.1391)  loss_objectness: 0.0857 (0.1002)  loss_rpn_box_reg: 0.0213 (0.0340)  time: 0.2712  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [15]  [ 300/1229]  eta: 0:04:13  lr: 0.000050  loss: 0.4593 (0.4281)  loss_classifier: 0.1654 (0.1539)  loss_box_reg: 0.1578 (0.1403)  loss_objectness: 0.0968 (0.1002)  loss_rpn_box_reg: 0.0212 (0.0338)  time: 0.2694  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [15]  [ 310/1229]  eta: 0:04:10  lr: 0.000050  loss: 0.3762 (0.4288)  loss_classifier: 0.1259 (0.1538)  loss_box_reg: 0.1058 (0.1405)  loss_objectness: 0.0968 (0.1004)  loss_rpn_box_reg: 0.0219 (0.0340)  time: 0.2748  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [15]  [ 320/1229]  eta: 0:04:07  lr: 0.000050  loss: 0.3710 (0.4284)  loss_classifier: 0.1246 (0.1538)  loss_box_reg: 0.0841 (0.1395)  loss_objectness: 0.1067 (0.1010)  loss_rpn_box_reg: 0.0291 (0.0341)  time: 0.2724  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [15]  [ 330/1229]  eta: 0:04:05  lr: 0.000050  loss: 0.3419 (0.4300)  loss_classifier: 0.1351 (0.1544)  loss_box_reg: 0.0884 (0.1395)  loss_objectness: 0.1123 (0.1017)  loss_rpn_box_reg: 0.0251 (0.0343)  time: 0.2729  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [15]  [ 340/1229]  eta: 0:04:02  lr: 0.000050  loss: 0.4293 (0.4307)  loss_classifier: 0.1351 (0.1545)  loss_box_reg: 0.1230 (0.1397)  loss_objectness: 0.1084 (0.1020)  loss_rpn_box_reg: 0.0251 (0.0345)  time: 0.2709  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [15]  [ 350/1229]  eta: 0:03:59  lr: 0.000050  loss: 0.3866 (0.4307)  loss_classifier: 0.1458 (0.1546)  loss_box_reg: 0.1201 (0.1402)  loss_objectness: 0.0873 (0.1018)  loss_rpn_box_reg: 0.0186 (0.0342)  time: 0.2667  data: 0.1298  max mem: 1751\n",
      "Training Epoch: [15]  [ 360/1229]  eta: 0:03:56  lr: 0.000050  loss: 0.3408 (0.4294)  loss_classifier: 0.1306 (0.1541)  loss_box_reg: 0.1201 (0.1404)  loss_objectness: 0.0809 (0.1010)  loss_rpn_box_reg: 0.0178 (0.0338)  time: 0.2706  data: 0.1297  max mem: 1751\n",
      "Training Epoch: [15]  [ 370/1229]  eta: 0:03:54  lr: 0.000050  loss: 0.3408 (0.4294)  loss_classifier: 0.1306 (0.1541)  loss_box_reg: 0.0958 (0.1401)  loss_objectness: 0.0696 (0.1009)  loss_rpn_box_reg: 0.0168 (0.0343)  time: 0.2748  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [15]  [ 380/1229]  eta: 0:03:51  lr: 0.000050  loss: 0.3829 (0.4274)  loss_classifier: 0.1466 (0.1534)  loss_box_reg: 0.0958 (0.1396)  loss_objectness: 0.0654 (0.1003)  loss_rpn_box_reg: 0.0160 (0.0340)  time: 0.2774  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [15]  [ 390/1229]  eta: 0:03:48  lr: 0.000050  loss: 0.2949 (0.4264)  loss_classifier: 0.1038 (0.1532)  loss_box_reg: 0.0886 (0.1392)  loss_objectness: 0.0698 (0.1002)  loss_rpn_box_reg: 0.0160 (0.0338)  time: 0.2746  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [15]  [ 400/1229]  eta: 0:03:45  lr: 0.000050  loss: 0.4332 (0.4282)  loss_classifier: 0.1460 (0.1538)  loss_box_reg: 0.1096 (0.1400)  loss_objectness: 0.1005 (0.1005)  loss_rpn_box_reg: 0.0246 (0.0339)  time: 0.2695  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [15]  [ 410/1229]  eta: 0:03:43  lr: 0.000050  loss: 0.4404 (0.4280)  loss_classifier: 0.1312 (0.1538)  loss_box_reg: 0.1379 (0.1404)  loss_objectness: 0.1000 (0.1001)  loss_rpn_box_reg: 0.0235 (0.0336)  time: 0.2669  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [15]  [ 420/1229]  eta: 0:03:40  lr: 0.000050  loss: 0.3544 (0.4296)  loss_classifier: 0.1312 (0.1541)  loss_box_reg: 0.1127 (0.1411)  loss_objectness: 0.0809 (0.1005)  loss_rpn_box_reg: 0.0172 (0.0339)  time: 0.2726  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [15]  [ 430/1229]  eta: 0:03:37  lr: 0.000050  loss: 0.3544 (0.4286)  loss_classifier: 0.1354 (0.1537)  loss_box_reg: 0.0916 (0.1409)  loss_objectness: 0.0835 (0.1004)  loss_rpn_box_reg: 0.0184 (0.0337)  time: 0.2703  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [15]  [ 440/1229]  eta: 0:03:34  lr: 0.000050  loss: 0.2965 (0.4270)  loss_classifier: 0.1069 (0.1530)  loss_box_reg: 0.0808 (0.1401)  loss_objectness: 0.0835 (0.1006)  loss_rpn_box_reg: 0.0151 (0.0333)  time: 0.2646  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [15]  [ 450/1229]  eta: 0:03:32  lr: 0.000050  loss: 0.3096 (0.4268)  loss_classifier: 0.1229 (0.1531)  loss_box_reg: 0.0872 (0.1400)  loss_objectness: 0.1018 (0.1006)  loss_rpn_box_reg: 0.0140 (0.0331)  time: 0.2744  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [15]  [ 460/1229]  eta: 0:03:29  lr: 0.000050  loss: 0.3296 (0.4263)  loss_classifier: 0.1273 (0.1528)  loss_box_reg: 0.1071 (0.1401)  loss_objectness: 0.0849 (0.1004)  loss_rpn_box_reg: 0.0121 (0.0329)  time: 0.2748  data: 0.1367  max mem: 1751\n",
      "Training Epoch: [15]  [ 470/1229]  eta: 0:03:26  lr: 0.000050  loss: 0.3883 (0.4276)  loss_classifier: 0.1411 (0.1535)  loss_box_reg: 0.1379 (0.1406)  loss_objectness: 0.0813 (0.1004)  loss_rpn_box_reg: 0.0164 (0.0332)  time: 0.2699  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [15]  [ 480/1229]  eta: 0:03:23  lr: 0.000050  loss: 0.4189 (0.4280)  loss_classifier: 0.1537 (0.1537)  loss_box_reg: 0.1622 (0.1409)  loss_objectness: 0.0902 (0.1004)  loss_rpn_box_reg: 0.0232 (0.0331)  time: 0.2704  data: 0.1376  max mem: 1751\n",
      "Training Epoch: [15]  [ 490/1229]  eta: 0:03:21  lr: 0.000050  loss: 0.4026 (0.4275)  loss_classifier: 0.1360 (0.1534)  loss_box_reg: 0.1473 (0.1408)  loss_objectness: 0.0848 (0.1002)  loss_rpn_box_reg: 0.0299 (0.0332)  time: 0.2706  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [15]  [ 500/1229]  eta: 0:03:18  lr: 0.000050  loss: 0.3887 (0.4277)  loss_classifier: 0.1360 (0.1537)  loss_box_reg: 0.1527 (0.1409)  loss_objectness: 0.0711 (0.1001)  loss_rpn_box_reg: 0.0292 (0.0330)  time: 0.2737  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [15]  [ 510/1229]  eta: 0:03:15  lr: 0.000050  loss: 0.4169 (0.4274)  loss_classifier: 0.1594 (0.1535)  loss_box_reg: 0.1115 (0.1404)  loss_objectness: 0.1127 (0.1004)  loss_rpn_box_reg: 0.0249 (0.0332)  time: 0.2712  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [15]  [ 520/1229]  eta: 0:03:12  lr: 0.000050  loss: 0.4381 (0.4288)  loss_classifier: 0.1594 (0.1541)  loss_box_reg: 0.1129 (0.1410)  loss_objectness: 0.1210 (0.1006)  loss_rpn_box_reg: 0.0253 (0.0330)  time: 0.2691  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [15]  [ 530/1229]  eta: 0:03:10  lr: 0.000050  loss: 0.4068 (0.4288)  loss_classifier: 0.1493 (0.1542)  loss_box_reg: 0.1356 (0.1406)  loss_objectness: 0.0830 (0.1011)  loss_rpn_box_reg: 0.0177 (0.0329)  time: 0.2702  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [15]  [ 540/1229]  eta: 0:03:07  lr: 0.000050  loss: 0.3842 (0.4303)  loss_classifier: 0.1478 (0.1548)  loss_box_reg: 0.1370 (0.1417)  loss_objectness: 0.0788 (0.1009)  loss_rpn_box_reg: 0.0245 (0.0328)  time: 0.2720  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [15]  [ 550/1229]  eta: 0:03:04  lr: 0.000050  loss: 0.3842 (0.4291)  loss_classifier: 0.1335 (0.1543)  loss_box_reg: 0.1274 (0.1414)  loss_objectness: 0.0841 (0.1007)  loss_rpn_box_reg: 0.0245 (0.0326)  time: 0.2733  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [15]  [ 560/1229]  eta: 0:03:02  lr: 0.000050  loss: 0.3586 (0.4287)  loss_classifier: 0.1235 (0.1540)  loss_box_reg: 0.1144 (0.1410)  loss_objectness: 0.0841 (0.1009)  loss_rpn_box_reg: 0.0231 (0.0328)  time: 0.2710  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [15]  [ 570/1229]  eta: 0:02:59  lr: 0.000050  loss: 0.4257 (0.4299)  loss_classifier: 0.1384 (0.1543)  loss_box_reg: 0.1144 (0.1417)  loss_objectness: 0.1172 (0.1010)  loss_rpn_box_reg: 0.0333 (0.0329)  time: 0.2689  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [15]  [ 580/1229]  eta: 0:02:56  lr: 0.000050  loss: 0.3175 (0.4285)  loss_classifier: 0.1053 (0.1538)  loss_box_reg: 0.1010 (0.1412)  loss_objectness: 0.0713 (0.1007)  loss_rpn_box_reg: 0.0166 (0.0328)  time: 0.2708  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [15]  [ 590/1229]  eta: 0:02:53  lr: 0.000050  loss: 0.3507 (0.4289)  loss_classifier: 0.1053 (0.1538)  loss_box_reg: 0.1021 (0.1412)  loss_objectness: 0.0657 (0.1007)  loss_rpn_box_reg: 0.0166 (0.0332)  time: 0.2734  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [15]  [ 600/1229]  eta: 0:02:51  lr: 0.000050  loss: 0.3915 (0.4283)  loss_classifier: 0.1349 (0.1537)  loss_box_reg: 0.1284 (0.1411)  loss_objectness: 0.0696 (0.1003)  loss_rpn_box_reg: 0.0194 (0.0333)  time: 0.2737  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [15]  [ 610/1229]  eta: 0:02:48  lr: 0.000050  loss: 0.3641 (0.4294)  loss_classifier: 0.1409 (0.1540)  loss_box_reg: 0.1284 (0.1415)  loss_objectness: 0.0706 (0.1005)  loss_rpn_box_reg: 0.0159 (0.0333)  time: 0.2785  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [15]  [ 620/1229]  eta: 0:02:45  lr: 0.000050  loss: 0.3281 (0.4282)  loss_classifier: 0.1267 (0.1537)  loss_box_reg: 0.1212 (0.1414)  loss_objectness: 0.0819 (0.1001)  loss_rpn_box_reg: 0.0152 (0.0330)  time: 0.2794  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [15]  [ 630/1229]  eta: 0:02:43  lr: 0.000050  loss: 0.3281 (0.4282)  loss_classifier: 0.1212 (0.1536)  loss_box_reg: 0.1276 (0.1414)  loss_objectness: 0.0800 (0.1004)  loss_rpn_box_reg: 0.0154 (0.0328)  time: 0.2722  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [15]  [ 640/1229]  eta: 0:02:40  lr: 0.000050  loss: 0.3969 (0.4283)  loss_classifier: 0.1437 (0.1537)  loss_box_reg: 0.1276 (0.1415)  loss_objectness: 0.0800 (0.1004)  loss_rpn_box_reg: 0.0211 (0.0328)  time: 0.2685  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [15]  [ 650/1229]  eta: 0:02:37  lr: 0.000050  loss: 0.4649 (0.4294)  loss_classifier: 0.1559 (0.1540)  loss_box_reg: 0.1432 (0.1421)  loss_objectness: 0.0652 (0.1003)  loss_rpn_box_reg: 0.0222 (0.0330)  time: 0.2737  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [15]  [ 660/1229]  eta: 0:02:34  lr: 0.000050  loss: 0.4649 (0.4304)  loss_classifier: 0.1620 (0.1542)  loss_box_reg: 0.1432 (0.1423)  loss_objectness: 0.0992 (0.1004)  loss_rpn_box_reg: 0.0333 (0.0336)  time: 0.2757  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [15]  [ 670/1229]  eta: 0:02:32  lr: 0.000050  loss: 0.4283 (0.4311)  loss_classifier: 0.1740 (0.1546)  loss_box_reg: 0.1398 (0.1427)  loss_objectness: 0.0941 (0.1003)  loss_rpn_box_reg: 0.0210 (0.0334)  time: 0.2723  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [15]  [ 680/1229]  eta: 0:02:29  lr: 0.000050  loss: 0.4700 (0.4320)  loss_classifier: 0.1802 (0.1549)  loss_box_reg: 0.1832 (0.1435)  loss_objectness: 0.0746 (0.1002)  loss_rpn_box_reg: 0.0199 (0.0334)  time: 0.2746  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [15]  [ 690/1229]  eta: 0:02:26  lr: 0.000050  loss: 0.4170 (0.4305)  loss_classifier: 0.1626 (0.1545)  loss_box_reg: 0.1048 (0.1431)  loss_objectness: 0.0729 (0.0998)  loss_rpn_box_reg: 0.0145 (0.0331)  time: 0.2749  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [15]  [ 700/1229]  eta: 0:02:24  lr: 0.000050  loss: 0.3402 (0.4308)  loss_classifier: 0.1221 (0.1546)  loss_box_reg: 0.0978 (0.1432)  loss_objectness: 0.0781 (0.0999)  loss_rpn_box_reg: 0.0134 (0.0332)  time: 0.2702  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [15]  [ 710/1229]  eta: 0:02:21  lr: 0.000050  loss: 0.3985 (0.4303)  loss_classifier: 0.1466 (0.1543)  loss_box_reg: 0.1313 (0.1431)  loss_objectness: 0.0934 (0.0998)  loss_rpn_box_reg: 0.0202 (0.0332)  time: 0.2694  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [15]  [ 720/1229]  eta: 0:02:18  lr: 0.000050  loss: 0.4078 (0.4308)  loss_classifier: 0.1433 (0.1543)  loss_box_reg: 0.1335 (0.1435)  loss_objectness: 0.0899 (0.0996)  loss_rpn_box_reg: 0.0164 (0.0333)  time: 0.2700  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [15]  [ 730/1229]  eta: 0:02:15  lr: 0.000050  loss: 0.4078 (0.4313)  loss_classifier: 0.1349 (0.1544)  loss_box_reg: 0.1248 (0.1437)  loss_objectness: 0.0840 (0.0996)  loss_rpn_box_reg: 0.0276 (0.0336)  time: 0.2712  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [15]  [ 740/1229]  eta: 0:02:13  lr: 0.000050  loss: 0.3858 (0.4307)  loss_classifier: 0.1260 (0.1542)  loss_box_reg: 0.1180 (0.1435)  loss_objectness: 0.0755 (0.0995)  loss_rpn_box_reg: 0.0194 (0.0335)  time: 0.2704  data: 0.1289  max mem: 1751\n",
      "Training Epoch: [15]  [ 750/1229]  eta: 0:02:10  lr: 0.000050  loss: 0.3992 (0.4312)  loss_classifier: 0.1354 (0.1542)  loss_box_reg: 0.1278 (0.1434)  loss_objectness: 0.0839 (0.0997)  loss_rpn_box_reg: 0.0202 (0.0338)  time: 0.2731  data: 0.1286  max mem: 1751\n",
      "Training Epoch: [15]  [ 760/1229]  eta: 0:02:07  lr: 0.000050  loss: 0.3992 (0.4315)  loss_classifier: 0.1356 (0.1544)  loss_box_reg: 0.1316 (0.1435)  loss_objectness: 0.1059 (0.0999)  loss_rpn_box_reg: 0.0227 (0.0338)  time: 0.2741  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [15]  [ 770/1229]  eta: 0:02:04  lr: 0.000050  loss: 0.3840 (0.4312)  loss_classifier: 0.1438 (0.1543)  loss_box_reg: 0.0992 (0.1432)  loss_objectness: 0.1059 (0.1000)  loss_rpn_box_reg: 0.0186 (0.0336)  time: 0.2709  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [15]  [ 780/1229]  eta: 0:02:02  lr: 0.000050  loss: 0.3669 (0.4317)  loss_classifier: 0.1476 (0.1545)  loss_box_reg: 0.1025 (0.1434)  loss_objectness: 0.0874 (0.0999)  loss_rpn_box_reg: 0.0259 (0.0339)  time: 0.2768  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [15]  [ 790/1229]  eta: 0:01:59  lr: 0.000050  loss: 0.3669 (0.4314)  loss_classifier: 0.1476 (0.1544)  loss_box_reg: 0.1038 (0.1433)  loss_objectness: 0.0659 (0.1000)  loss_rpn_box_reg: 0.0276 (0.0337)  time: 0.2782  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [15]  [ 800/1229]  eta: 0:01:56  lr: 0.000050  loss: 0.2838 (0.4305)  loss_classifier: 0.1071 (0.1540)  loss_box_reg: 0.0837 (0.1429)  loss_objectness: 0.0861 (0.0999)  loss_rpn_box_reg: 0.0176 (0.0338)  time: 0.2775  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [15]  [ 810/1229]  eta: 0:01:54  lr: 0.000050  loss: 0.3237 (0.4297)  loss_classifier: 0.0979 (0.1537)  loss_box_reg: 0.0707 (0.1427)  loss_objectness: 0.0797 (0.0997)  loss_rpn_box_reg: 0.0218 (0.0337)  time: 0.2801  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [15]  [ 820/1229]  eta: 0:01:51  lr: 0.000050  loss: 0.3396 (0.4299)  loss_classifier: 0.1329 (0.1537)  loss_box_reg: 0.1032 (0.1430)  loss_objectness: 0.0723 (0.0997)  loss_rpn_box_reg: 0.0218 (0.0335)  time: 0.2765  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [15]  [ 830/1229]  eta: 0:01:48  lr: 0.000050  loss: 0.3586 (0.4312)  loss_classifier: 0.1337 (0.1542)  loss_box_reg: 0.1215 (0.1435)  loss_objectness: 0.0839 (0.0997)  loss_rpn_box_reg: 0.0256 (0.0337)  time: 0.2797  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [15]  [ 840/1229]  eta: 0:01:46  lr: 0.000050  loss: 0.4756 (0.4329)  loss_classifier: 0.1946 (0.1548)  loss_box_reg: 0.1577 (0.1440)  loss_objectness: 0.0895 (0.1000)  loss_rpn_box_reg: 0.0404 (0.0341)  time: 0.2786  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [15]  [ 850/1229]  eta: 0:01:43  lr: 0.000050  loss: 0.5600 (0.4327)  loss_classifier: 0.1722 (0.1547)  loss_box_reg: 0.1577 (0.1439)  loss_objectness: 0.0932 (0.1001)  loss_rpn_box_reg: 0.0350 (0.0341)  time: 0.2743  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [15]  [ 860/1229]  eta: 0:01:40  lr: 0.000050  loss: 0.4283 (0.4333)  loss_classifier: 0.1495 (0.1550)  loss_box_reg: 0.0875 (0.1440)  loss_objectness: 0.0989 (0.1003)  loss_rpn_box_reg: 0.0204 (0.0340)  time: 0.2729  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [15]  [ 870/1229]  eta: 0:01:37  lr: 0.000050  loss: 0.3961 (0.4328)  loss_classifier: 0.1367 (0.1548)  loss_box_reg: 0.1009 (0.1440)  loss_objectness: 0.0801 (0.1001)  loss_rpn_box_reg: 0.0237 (0.0340)  time: 0.2666  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [15]  [ 880/1229]  eta: 0:01:35  lr: 0.000050  loss: 0.3248 (0.4320)  loss_classifier: 0.1367 (0.1545)  loss_box_reg: 0.1060 (0.1437)  loss_objectness: 0.0761 (0.0999)  loss_rpn_box_reg: 0.0233 (0.0339)  time: 0.2688  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [15]  [ 890/1229]  eta: 0:01:32  lr: 0.000050  loss: 0.2942 (0.4318)  loss_classifier: 0.1030 (0.1544)  loss_box_reg: 0.1060 (0.1437)  loss_objectness: 0.0664 (0.0996)  loss_rpn_box_reg: 0.0257 (0.0340)  time: 0.2709  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [15]  [ 900/1229]  eta: 0:01:29  lr: 0.000050  loss: 0.3356 (0.4324)  loss_classifier: 0.1030 (0.1544)  loss_box_reg: 0.1020 (0.1437)  loss_objectness: 0.0753 (0.0997)  loss_rpn_box_reg: 0.0362 (0.0345)  time: 0.2705  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [15]  [ 910/1229]  eta: 0:01:26  lr: 0.000050  loss: 0.4803 (0.4330)  loss_classifier: 0.1361 (0.1545)  loss_box_reg: 0.1115 (0.1437)  loss_objectness: 0.1057 (0.1000)  loss_rpn_box_reg: 0.0394 (0.0348)  time: 0.2710  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [15]  [ 920/1229]  eta: 0:01:24  lr: 0.000050  loss: 0.4452 (0.4326)  loss_classifier: 0.1355 (0.1543)  loss_box_reg: 0.0970 (0.1435)  loss_objectness: 0.0845 (0.1000)  loss_rpn_box_reg: 0.0252 (0.0347)  time: 0.2691  data: 0.1286  max mem: 1751\n",
      "Training Epoch: [15]  [ 930/1229]  eta: 0:01:21  lr: 0.000050  loss: 0.3333 (0.4325)  loss_classifier: 0.1355 (0.1543)  loss_box_reg: 0.0929 (0.1434)  loss_objectness: 0.0788 (0.1002)  loss_rpn_box_reg: 0.0193 (0.0346)  time: 0.2639  data: 0.1293  max mem: 1751\n",
      "Training Epoch: [15]  [ 940/1229]  eta: 0:01:18  lr: 0.000050  loss: 0.3079 (0.4312)  loss_classifier: 0.0908 (0.1540)  loss_box_reg: 0.0923 (0.1430)  loss_objectness: 0.0729 (0.0998)  loss_rpn_box_reg: 0.0125 (0.0344)  time: 0.2663  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [15]  [ 950/1229]  eta: 0:01:16  lr: 0.000050  loss: 0.3434 (0.4309)  loss_classifier: 0.0988 (0.1538)  loss_box_reg: 0.1019 (0.1428)  loss_objectness: 0.0535 (0.0999)  loss_rpn_box_reg: 0.0161 (0.0344)  time: 0.2731  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [15]  [ 960/1229]  eta: 0:01:13  lr: 0.000050  loss: 0.4120 (0.4327)  loss_classifier: 0.1412 (0.1544)  loss_box_reg: 0.1231 (0.1435)  loss_objectness: 0.0990 (0.1003)  loss_rpn_box_reg: 0.0189 (0.0345)  time: 0.2689  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [15]  [ 970/1229]  eta: 0:01:10  lr: 0.000050  loss: 0.4931 (0.4329)  loss_classifier: 0.1841 (0.1545)  loss_box_reg: 0.1434 (0.1435)  loss_objectness: 0.0974 (0.1003)  loss_rpn_box_reg: 0.0231 (0.0346)  time: 0.2684  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [15]  [ 980/1229]  eta: 0:01:07  lr: 0.000050  loss: 0.5218 (0.4346)  loss_classifier: 0.2025 (0.1550)  loss_box_reg: 0.1758 (0.1442)  loss_objectness: 0.1066 (0.1006)  loss_rpn_box_reg: 0.0237 (0.0349)  time: 0.2697  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [15]  [ 990/1229]  eta: 0:01:05  lr: 0.000050  loss: 0.5514 (0.4358)  loss_classifier: 0.1890 (0.1553)  loss_box_reg: 0.1758 (0.1446)  loss_objectness: 0.1276 (0.1010)  loss_rpn_box_reg: 0.0301 (0.0349)  time: 0.2690  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [15]  [1000/1229]  eta: 0:01:02  lr: 0.000050  loss: 0.4101 (0.4357)  loss_classifier: 0.1423 (0.1554)  loss_box_reg: 0.1190 (0.1446)  loss_objectness: 0.0854 (0.1010)  loss_rpn_box_reg: 0.0300 (0.0349)  time: 0.2714  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [15]  [1010/1229]  eta: 0:00:59  lr: 0.000050  loss: 0.3989 (0.4365)  loss_classifier: 0.1342 (0.1555)  loss_box_reg: 0.1304 (0.1448)  loss_objectness: 0.0743 (0.1012)  loss_rpn_box_reg: 0.0300 (0.0350)  time: 0.2703  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [15]  [1020/1229]  eta: 0:00:56  lr: 0.000050  loss: 0.3823 (0.4362)  loss_classifier: 0.1246 (0.1554)  loss_box_reg: 0.1008 (0.1446)  loss_objectness: 0.1021 (0.1013)  loss_rpn_box_reg: 0.0291 (0.0349)  time: 0.2700  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [15]  [1030/1229]  eta: 0:00:54  lr: 0.000050  loss: 0.3937 (0.4362)  loss_classifier: 0.1385 (0.1554)  loss_box_reg: 0.1052 (0.1446)  loss_objectness: 0.1009 (0.1013)  loss_rpn_box_reg: 0.0200 (0.0348)  time: 0.2733  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [15]  [1040/1229]  eta: 0:00:51  lr: 0.000050  loss: 0.4219 (0.4361)  loss_classifier: 0.1471 (0.1554)  loss_box_reg: 0.1185 (0.1445)  loss_objectness: 0.1032 (0.1015)  loss_rpn_box_reg: 0.0200 (0.0347)  time: 0.2692  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [15]  [1050/1229]  eta: 0:00:48  lr: 0.000050  loss: 0.3469 (0.4366)  loss_classifier: 0.1337 (0.1556)  loss_box_reg: 0.1024 (0.1449)  loss_objectness: 0.0935 (0.1013)  loss_rpn_box_reg: 0.0177 (0.0347)  time: 0.2717  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [15]  [1060/1229]  eta: 0:00:46  lr: 0.000050  loss: 0.3469 (0.4362)  loss_classifier: 0.1337 (0.1556)  loss_box_reg: 0.1155 (0.1448)  loss_objectness: 0.0670 (0.1013)  loss_rpn_box_reg: 0.0222 (0.0346)  time: 0.2819  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [15]  [1070/1229]  eta: 0:00:43  lr: 0.000050  loss: 0.3098 (0.4353)  loss_classifier: 0.1064 (0.1553)  loss_box_reg: 0.1072 (0.1445)  loss_objectness: 0.0703 (0.1010)  loss_rpn_box_reg: 0.0125 (0.0345)  time: 0.2756  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [15]  [1080/1229]  eta: 0:00:40  lr: 0.000050  loss: 0.3115 (0.4349)  loss_classifier: 0.1054 (0.1551)  loss_box_reg: 0.1193 (0.1445)  loss_objectness: 0.0703 (0.1009)  loss_rpn_box_reg: 0.0196 (0.0345)  time: 0.2659  data: 0.1300  max mem: 1751\n",
      "Training Epoch: [15]  [1090/1229]  eta: 0:00:37  lr: 0.000050  loss: 0.3285 (0.4349)  loss_classifier: 0.1251 (0.1551)  loss_box_reg: 0.1062 (0.1444)  loss_objectness: 0.0767 (0.1009)  loss_rpn_box_reg: 0.0207 (0.0345)  time: 0.2680  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [15]  [1100/1229]  eta: 0:00:35  lr: 0.000050  loss: 0.3263 (0.4341)  loss_classifier: 0.1317 (0.1549)  loss_box_reg: 0.1093 (0.1442)  loss_objectness: 0.0808 (0.1006)  loss_rpn_box_reg: 0.0181 (0.0344)  time: 0.2673  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [15]  [1110/1229]  eta: 0:00:32  lr: 0.000050  loss: 0.3313 (0.4340)  loss_classifier: 0.1231 (0.1549)  loss_box_reg: 0.1149 (0.1442)  loss_objectness: 0.0844 (0.1007)  loss_rpn_box_reg: 0.0162 (0.0343)  time: 0.2642  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [15]  [1120/1229]  eta: 0:00:29  lr: 0.000050  loss: 0.3370 (0.4342)  loss_classifier: 0.1197 (0.1550)  loss_box_reg: 0.1060 (0.1444)  loss_objectness: 0.0936 (0.1006)  loss_rpn_box_reg: 0.0215 (0.0343)  time: 0.2724  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [15]  [1130/1229]  eta: 0:00:26  lr: 0.000050  loss: 0.3978 (0.4341)  loss_classifier: 0.1197 (0.1548)  loss_box_reg: 0.1338 (0.1445)  loss_objectness: 0.0886 (0.1006)  loss_rpn_box_reg: 0.0239 (0.0342)  time: 0.2699  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [15]  [1140/1229]  eta: 0:00:24  lr: 0.000050  loss: 0.3752 (0.4338)  loss_classifier: 0.1378 (0.1548)  loss_box_reg: 0.1338 (0.1444)  loss_objectness: 0.0817 (0.1004)  loss_rpn_box_reg: 0.0169 (0.0342)  time: 0.2689  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [15]  [1150/1229]  eta: 0:00:21  lr: 0.000050  loss: 0.3212 (0.4331)  loss_classifier: 0.1337 (0.1546)  loss_box_reg: 0.0806 (0.1440)  loss_objectness: 0.0905 (0.1005)  loss_rpn_box_reg: 0.0169 (0.0340)  time: 0.2738  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [15]  [1160/1229]  eta: 0:00:18  lr: 0.000050  loss: 0.3859 (0.4339)  loss_classifier: 0.1464 (0.1548)  loss_box_reg: 0.1511 (0.1444)  loss_objectness: 0.0968 (0.1006)  loss_rpn_box_reg: 0.0196 (0.0342)  time: 0.2735  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [15]  [1170/1229]  eta: 0:00:16  lr: 0.000050  loss: 0.4794 (0.4346)  loss_classifier: 0.1877 (0.1550)  loss_box_reg: 0.1581 (0.1449)  loss_objectness: 0.1066 (0.1006)  loss_rpn_box_reg: 0.0232 (0.0341)  time: 0.2708  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [15]  [1180/1229]  eta: 0:00:13  lr: 0.000050  loss: 0.4680 (0.4350)  loss_classifier: 0.1470 (0.1550)  loss_box_reg: 0.1469 (0.1449)  loss_objectness: 0.1150 (0.1009)  loss_rpn_box_reg: 0.0232 (0.0342)  time: 0.2660  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [15]  [1190/1229]  eta: 0:00:10  lr: 0.000050  loss: 0.4680 (0.4357)  loss_classifier: 0.1470 (0.1553)  loss_box_reg: 0.1469 (0.1452)  loss_objectness: 0.1150 (0.1010)  loss_rpn_box_reg: 0.0282 (0.0342)  time: 0.2647  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [15]  [1200/1229]  eta: 0:00:07  lr: 0.000050  loss: 0.4385 (0.4355)  loss_classifier: 0.1669 (0.1552)  loss_box_reg: 0.1576 (0.1453)  loss_objectness: 0.0957 (0.1009)  loss_rpn_box_reg: 0.0202 (0.0342)  time: 0.2700  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [15]  [1210/1229]  eta: 0:00:05  lr: 0.000050  loss: 0.3877 (0.4354)  loss_classifier: 0.1520 (0.1552)  loss_box_reg: 0.1417 (0.1454)  loss_objectness: 0.0844 (0.1008)  loss_rpn_box_reg: 0.0177 (0.0340)  time: 0.2792  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [15]  [1220/1229]  eta: 0:00:02  lr: 0.000050  loss: 0.3877 (0.4351)  loss_classifier: 0.1405 (0.1550)  loss_box_reg: 0.1317 (0.1453)  loss_objectness: 0.0783 (0.1007)  loss_rpn_box_reg: 0.0143 (0.0340)  time: 0.2755  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [15]  [1228/1229]  eta: 0:00:00  lr: 0.000050  loss: 0.4007 (0.4359)  loss_classifier: 0.1494 (0.1553)  loss_box_reg: 0.1417 (0.1458)  loss_objectness: 0.0845 (0.1007)  loss_rpn_box_reg: 0.0151 (0.0340)  time: 0.2702  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [15] Total time: 0:05:34 (0.2721 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:16  model_time: 0.2150 (0.2150)  evaluator_time: 0.0020 (0.0020)  time: 0.2480  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0780 (0.0813)  evaluator_time: 0.0040 (0.0086)  time: 0.1264  data: 0.0358  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0820 (0.0805)  evaluator_time: 0.0030 (0.0078)  time: 0.1194  data: 0.0307  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0760 (0.0798)  evaluator_time: 0.0040 (0.0076)  time: 0.1246  data: 0.0403  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0760 (0.0796)  evaluator_time: 0.0030 (0.0076)  time: 0.1214  data: 0.0385  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1239 s / it)\n",
      "Averaged stats: model_time: 0.0760 (0.0796)  evaluator_time: 0.0030 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.294\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
      "Testing Epoch: [15]  [  0/308]  eta: 0:00:37  lr: 0.000050  loss: 0.1735 (0.1735)  loss_classifier: 0.0625 (0.0625)  loss_box_reg: 0.0746 (0.0746)  loss_objectness: 0.0249 (0.0249)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1210  data: 0.0280  max mem: 1751\n",
      "Testing Epoch: [15]  [100/308]  eta: 0:00:28  lr: 0.000050  loss: 0.3113 (0.4821)  loss_classifier: 0.1335 (0.1547)  loss_box_reg: 0.1191 (0.1723)  loss_objectness: 0.0560 (0.1031)  loss_rpn_box_reg: 0.0186 (0.0520)  time: 0.1433  data: 0.0418  max mem: 1751\n",
      "Testing Epoch: [15]  [200/308]  eta: 0:00:14  lr: 0.000050  loss: 0.3635 (0.4578)  loss_classifier: 0.1407 (0.1493)  loss_box_reg: 0.1294 (0.1634)  loss_objectness: 0.0714 (0.0960)  loss_rpn_box_reg: 0.0198 (0.0492)  time: 0.1378  data: 0.0322  max mem: 1751\n",
      "Testing Epoch: [15]  [300/308]  eta: 0:00:01  lr: 0.000050  loss: 0.4585 (0.4545)  loss_classifier: 0.1559 (0.1495)  loss_box_reg: 0.1725 (0.1642)  loss_objectness: 0.0802 (0.0933)  loss_rpn_box_reg: 0.0264 (0.0475)  time: 0.1328  data: 0.0374  max mem: 1751\n",
      "Testing Epoch: [15]  [307/308]  eta: 0:00:00  lr: 0.000050  loss: 0.4585 (0.4548)  loss_classifier: 0.1854 (0.1498)  loss_box_reg: 0.1755 (0.1646)  loss_objectness: 0.0777 (0.0935)  loss_rpn_box_reg: 0.0275 (0.0470)  time: 0.1305  data: 0.0358  max mem: 1751\n",
      "Testing Epoch: [15] Total time: 0:00:42 (0.1370 s / it)\n",
      "Training Epoch: [16]  [   0/1229]  eta: 0:05:20  lr: 0.000050  loss: 0.1473 (0.1473)  loss_classifier: 0.0399 (0.0399)  loss_box_reg: 0.0319 (0.0319)  loss_objectness: 0.0706 (0.0706)  loss_rpn_box_reg: 0.0050 (0.0050)  time: 0.2610  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [16]  [  10/1229]  eta: 0:05:38  lr: 0.000050  loss: 0.2948 (0.3226)  loss_classifier: 0.1017 (0.1139)  loss_box_reg: 0.0751 (0.0810)  loss_objectness: 0.0713 (0.0994)  loss_rpn_box_reg: 0.0188 (0.0283)  time: 0.2775  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [16]  [  20/1229]  eta: 0:05:29  lr: 0.000050  loss: 0.2948 (0.3683)  loss_classifier: 0.1011 (0.1211)  loss_box_reg: 0.0778 (0.1076)  loss_objectness: 0.0713 (0.0982)  loss_rpn_box_reg: 0.0188 (0.0414)  time: 0.2728  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [16]  [  30/1229]  eta: 0:05:28  lr: 0.000050  loss: 0.2909 (0.3691)  loss_classifier: 0.1011 (0.1273)  loss_box_reg: 0.0801 (0.1108)  loss_objectness: 0.0739 (0.0948)  loss_rpn_box_reg: 0.0188 (0.0363)  time: 0.2722  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [16]  [  40/1229]  eta: 0:05:24  lr: 0.000050  loss: 0.3753 (0.4019)  loss_classifier: 0.1533 (0.1395)  loss_box_reg: 0.1093 (0.1267)  loss_objectness: 0.0835 (0.1000)  loss_rpn_box_reg: 0.0269 (0.0357)  time: 0.2741  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [16]  [  50/1229]  eta: 0:05:19  lr: 0.000050  loss: 0.4331 (0.4069)  loss_classifier: 0.1576 (0.1425)  loss_box_reg: 0.1608 (0.1280)  loss_objectness: 0.0913 (0.1001)  loss_rpn_box_reg: 0.0293 (0.0363)  time: 0.2669  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [16]  [  60/1229]  eta: 0:05:16  lr: 0.000050  loss: 0.3555 (0.4057)  loss_classifier: 0.1257 (0.1427)  loss_box_reg: 0.1143 (0.1300)  loss_objectness: 0.0883 (0.0977)  loss_rpn_box_reg: 0.0268 (0.0353)  time: 0.2658  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [16]  [  70/1229]  eta: 0:05:13  lr: 0.000050  loss: 0.3335 (0.4064)  loss_classifier: 0.1257 (0.1443)  loss_box_reg: 0.1075 (0.1342)  loss_objectness: 0.0696 (0.0945)  loss_rpn_box_reg: 0.0192 (0.0335)  time: 0.2692  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [16]  [  80/1229]  eta: 0:05:11  lr: 0.000050  loss: 0.3335 (0.3946)  loss_classifier: 0.1365 (0.1410)  loss_box_reg: 0.1298 (0.1320)  loss_objectness: 0.0610 (0.0901)  loss_rpn_box_reg: 0.0153 (0.0315)  time: 0.2720  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [16]  [  90/1229]  eta: 0:05:08  lr: 0.000050  loss: 0.3866 (0.4001)  loss_classifier: 0.1365 (0.1425)  loss_box_reg: 0.1298 (0.1346)  loss_objectness: 0.0574 (0.0920)  loss_rpn_box_reg: 0.0175 (0.0310)  time: 0.2729  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [16]  [ 100/1229]  eta: 0:05:06  lr: 0.000050  loss: 0.4342 (0.4072)  loss_classifier: 0.1562 (0.1445)  loss_box_reg: 0.1166 (0.1364)  loss_objectness: 0.0764 (0.0955)  loss_rpn_box_reg: 0.0227 (0.0308)  time: 0.2713  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [16]  [ 110/1229]  eta: 0:05:03  lr: 0.000050  loss: 0.3377 (0.4011)  loss_classifier: 0.1117 (0.1432)  loss_box_reg: 0.1166 (0.1353)  loss_objectness: 0.0734 (0.0925)  loss_rpn_box_reg: 0.0152 (0.0301)  time: 0.2707  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [16]  [ 120/1229]  eta: 0:05:00  lr: 0.000050  loss: 0.3376 (0.4002)  loss_classifier: 0.1136 (0.1430)  loss_box_reg: 0.1147 (0.1343)  loss_objectness: 0.0749 (0.0924)  loss_rpn_box_reg: 0.0129 (0.0306)  time: 0.2713  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [16]  [ 130/1229]  eta: 0:04:58  lr: 0.000050  loss: 0.3646 (0.4031)  loss_classifier: 0.1326 (0.1435)  loss_box_reg: 0.1082 (0.1365)  loss_objectness: 0.0782 (0.0922)  loss_rpn_box_reg: 0.0179 (0.0308)  time: 0.2729  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [16]  [ 140/1229]  eta: 0:04:55  lr: 0.000050  loss: 0.3646 (0.4021)  loss_classifier: 0.1304 (0.1431)  loss_box_reg: 0.1001 (0.1356)  loss_objectness: 0.0782 (0.0923)  loss_rpn_box_reg: 0.0246 (0.0311)  time: 0.2721  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [16]  [ 150/1229]  eta: 0:04:52  lr: 0.000050  loss: 0.3378 (0.4045)  loss_classifier: 0.1183 (0.1439)  loss_box_reg: 0.1001 (0.1361)  loss_objectness: 0.0916 (0.0933)  loss_rpn_box_reg: 0.0151 (0.0312)  time: 0.2684  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [16]  [ 160/1229]  eta: 0:04:49  lr: 0.000050  loss: 0.3378 (0.4050)  loss_classifier: 0.1183 (0.1441)  loss_box_reg: 0.1169 (0.1355)  loss_objectness: 0.0916 (0.0943)  loss_rpn_box_reg: 0.0183 (0.0311)  time: 0.2691  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [16]  [ 170/1229]  eta: 0:04:46  lr: 0.000050  loss: 0.4524 (0.4131)  loss_classifier: 0.1733 (0.1470)  loss_box_reg: 0.1343 (0.1399)  loss_objectness: 0.1022 (0.0949)  loss_rpn_box_reg: 0.0281 (0.0313)  time: 0.2708  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [16]  [ 180/1229]  eta: 0:04:44  lr: 0.000050  loss: 0.3921 (0.4149)  loss_classifier: 0.1576 (0.1478)  loss_box_reg: 0.1332 (0.1403)  loss_objectness: 0.1039 (0.0958)  loss_rpn_box_reg: 0.0173 (0.0310)  time: 0.2753  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [16]  [ 190/1229]  eta: 0:04:42  lr: 0.000050  loss: 0.4046 (0.4222)  loss_classifier: 0.1610 (0.1502)  loss_box_reg: 0.1332 (0.1425)  loss_objectness: 0.1038 (0.0966)  loss_rpn_box_reg: 0.0197 (0.0329)  time: 0.2785  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [16]  [ 200/1229]  eta: 0:04:40  lr: 0.000050  loss: 0.5412 (0.4309)  loss_classifier: 0.2068 (0.1534)  loss_box_reg: 0.1956 (0.1468)  loss_objectness: 0.1038 (0.0975)  loss_rpn_box_reg: 0.0263 (0.0332)  time: 0.2785  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [16]  [ 210/1229]  eta: 0:04:37  lr: 0.000050  loss: 0.5243 (0.4321)  loss_classifier: 0.1787 (0.1537)  loss_box_reg: 0.1630 (0.1467)  loss_objectness: 0.1044 (0.0981)  loss_rpn_box_reg: 0.0208 (0.0337)  time: 0.2805  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [16]  [ 220/1229]  eta: 0:04:34  lr: 0.000050  loss: 0.3579 (0.4291)  loss_classifier: 0.1387 (0.1529)  loss_box_reg: 0.1387 (0.1458)  loss_objectness: 0.0912 (0.0974)  loss_rpn_box_reg: 0.0208 (0.0330)  time: 0.2736  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [16]  [ 230/1229]  eta: 0:04:32  lr: 0.000050  loss: 0.3923 (0.4345)  loss_classifier: 0.1401 (0.1548)  loss_box_reg: 0.1499 (0.1481)  loss_objectness: 0.0864 (0.0983)  loss_rpn_box_reg: 0.0211 (0.0333)  time: 0.2710  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [16]  [ 240/1229]  eta: 0:04:29  lr: 0.000050  loss: 0.4681 (0.4320)  loss_classifier: 0.1626 (0.1537)  loss_box_reg: 0.1445 (0.1466)  loss_objectness: 0.0949 (0.0985)  loss_rpn_box_reg: 0.0282 (0.0332)  time: 0.2711  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [16]  [ 250/1229]  eta: 0:04:26  lr: 0.000050  loss: 0.2970 (0.4304)  loss_classifier: 0.1080 (0.1534)  loss_box_reg: 0.1111 (0.1454)  loss_objectness: 0.0783 (0.0985)  loss_rpn_box_reg: 0.0271 (0.0331)  time: 0.2708  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [16]  [ 260/1229]  eta: 0:04:24  lr: 0.000050  loss: 0.2853 (0.4279)  loss_classifier: 0.0993 (0.1525)  loss_box_reg: 0.0969 (0.1453)  loss_objectness: 0.0685 (0.0972)  loss_rpn_box_reg: 0.0203 (0.0330)  time: 0.2769  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [16]  [ 270/1229]  eta: 0:04:21  lr: 0.000050  loss: 0.3002 (0.4272)  loss_classifier: 0.1136 (0.1522)  loss_box_reg: 0.0969 (0.1449)  loss_objectness: 0.0592 (0.0974)  loss_rpn_box_reg: 0.0160 (0.0328)  time: 0.2750  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [16]  [ 280/1229]  eta: 0:04:18  lr: 0.000050  loss: 0.3833 (0.4256)  loss_classifier: 0.1348 (0.1517)  loss_box_reg: 0.0927 (0.1441)  loss_objectness: 0.0829 (0.0972)  loss_rpn_box_reg: 0.0195 (0.0326)  time: 0.2699  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [16]  [ 290/1229]  eta: 0:04:15  lr: 0.000050  loss: 0.3833 (0.4261)  loss_classifier: 0.1322 (0.1520)  loss_box_reg: 0.0939 (0.1444)  loss_objectness: 0.0829 (0.0970)  loss_rpn_box_reg: 0.0233 (0.0327)  time: 0.2675  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [16]  [ 300/1229]  eta: 0:04:12  lr: 0.000050  loss: 0.3136 (0.4247)  loss_classifier: 0.1227 (0.1516)  loss_box_reg: 0.0887 (0.1438)  loss_objectness: 0.0825 (0.0969)  loss_rpn_box_reg: 0.0267 (0.0324)  time: 0.2675  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [16]  [ 310/1229]  eta: 0:04:10  lr: 0.000050  loss: 0.3572 (0.4250)  loss_classifier: 0.1582 (0.1520)  loss_box_reg: 0.1052 (0.1434)  loss_objectness: 0.0937 (0.0976)  loss_rpn_box_reg: 0.0194 (0.0320)  time: 0.2707  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [16]  [ 320/1229]  eta: 0:04:07  lr: 0.000050  loss: 0.3592 (0.4249)  loss_classifier: 0.1598 (0.1520)  loss_box_reg: 0.1052 (0.1431)  loss_objectness: 0.0978 (0.0976)  loss_rpn_box_reg: 0.0191 (0.0322)  time: 0.2695  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [16]  [ 330/1229]  eta: 0:04:04  lr: 0.000050  loss: 0.3592 (0.4233)  loss_classifier: 0.1384 (0.1517)  loss_box_reg: 0.0995 (0.1424)  loss_objectness: 0.0782 (0.0975)  loss_rpn_box_reg: 0.0191 (0.0317)  time: 0.2704  data: 0.1298  max mem: 1751\n",
      "Training Epoch: [16]  [ 340/1229]  eta: 0:04:01  lr: 0.000050  loss: 0.3590 (0.4229)  loss_classifier: 0.1334 (0.1513)  loss_box_reg: 0.0893 (0.1418)  loss_objectness: 0.0782 (0.0981)  loss_rpn_box_reg: 0.0204 (0.0318)  time: 0.2752  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [16]  [ 350/1229]  eta: 0:03:58  lr: 0.000050  loss: 0.3780 (0.4235)  loss_classifier: 0.1331 (0.1512)  loss_box_reg: 0.0985 (0.1419)  loss_objectness: 0.1181 (0.0985)  loss_rpn_box_reg: 0.0207 (0.0319)  time: 0.2701  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [16]  [ 360/1229]  eta: 0:03:56  lr: 0.000050  loss: 0.3941 (0.4234)  loss_classifier: 0.1289 (0.1510)  loss_box_reg: 0.1143 (0.1417)  loss_objectness: 0.0947 (0.0985)  loss_rpn_box_reg: 0.0180 (0.0322)  time: 0.2698  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [16]  [ 370/1229]  eta: 0:03:53  lr: 0.000050  loss: 0.3001 (0.4217)  loss_classifier: 0.0978 (0.1504)  loss_box_reg: 0.0853 (0.1408)  loss_objectness: 0.0753 (0.0984)  loss_rpn_box_reg: 0.0197 (0.0321)  time: 0.2783  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [16]  [ 380/1229]  eta: 0:03:51  lr: 0.000050  loss: 0.3001 (0.4208)  loss_classifier: 0.1236 (0.1501)  loss_box_reg: 0.0881 (0.1410)  loss_objectness: 0.0777 (0.0977)  loss_rpn_box_reg: 0.0197 (0.0320)  time: 0.2821  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [16]  [ 390/1229]  eta: 0:03:48  lr: 0.000050  loss: 0.3747 (0.4218)  loss_classifier: 0.1254 (0.1505)  loss_box_reg: 0.1433 (0.1413)  loss_objectness: 0.0777 (0.0978)  loss_rpn_box_reg: 0.0232 (0.0323)  time: 0.2782  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [16]  [ 400/1229]  eta: 0:03:45  lr: 0.000050  loss: 0.3745 (0.4208)  loss_classifier: 0.1167 (0.1502)  loss_box_reg: 0.1159 (0.1408)  loss_objectness: 0.0901 (0.0975)  loss_rpn_box_reg: 0.0245 (0.0323)  time: 0.2681  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [16]  [ 410/1229]  eta: 0:03:43  lr: 0.000050  loss: 0.3394 (0.4188)  loss_classifier: 0.1124 (0.1496)  loss_box_reg: 0.0791 (0.1397)  loss_objectness: 0.0917 (0.0973)  loss_rpn_box_reg: 0.0184 (0.0323)  time: 0.2694  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [16]  [ 420/1229]  eta: 0:03:40  lr: 0.000050  loss: 0.3394 (0.4182)  loss_classifier: 0.1124 (0.1495)  loss_box_reg: 0.0865 (0.1394)  loss_objectness: 0.0820 (0.0970)  loss_rpn_box_reg: 0.0185 (0.0323)  time: 0.2768  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [16]  [ 430/1229]  eta: 0:03:37  lr: 0.000050  loss: 0.4010 (0.4181)  loss_classifier: 0.1462 (0.1493)  loss_box_reg: 0.1318 (0.1396)  loss_objectness: 0.0744 (0.0965)  loss_rpn_box_reg: 0.0185 (0.0326)  time: 0.2775  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [16]  [ 440/1229]  eta: 0:03:35  lr: 0.000050  loss: 0.3609 (0.4174)  loss_classifier: 0.1467 (0.1495)  loss_box_reg: 0.1266 (0.1395)  loss_objectness: 0.0766 (0.0962)  loss_rpn_box_reg: 0.0141 (0.0322)  time: 0.2726  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [16]  [ 450/1229]  eta: 0:03:32  lr: 0.000050  loss: 0.2979 (0.4153)  loss_classifier: 0.1008 (0.1484)  loss_box_reg: 0.0894 (0.1385)  loss_objectness: 0.0790 (0.0962)  loss_rpn_box_reg: 0.0128 (0.0322)  time: 0.2676  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [16]  [ 460/1229]  eta: 0:03:29  lr: 0.000050  loss: 0.3463 (0.4162)  loss_classifier: 0.1008 (0.1485)  loss_box_reg: 0.0894 (0.1391)  loss_objectness: 0.0880 (0.0963)  loss_rpn_box_reg: 0.0214 (0.0323)  time: 0.2703  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [16]  [ 470/1229]  eta: 0:03:26  lr: 0.000050  loss: 0.4103 (0.4158)  loss_classifier: 0.1390 (0.1483)  loss_box_reg: 0.1317 (0.1392)  loss_objectness: 0.0862 (0.0960)  loss_rpn_box_reg: 0.0286 (0.0324)  time: 0.2762  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [16]  [ 480/1229]  eta: 0:03:24  lr: 0.000050  loss: 0.4097 (0.4155)  loss_classifier: 0.1639 (0.1483)  loss_box_reg: 0.1282 (0.1392)  loss_objectness: 0.0723 (0.0956)  loss_rpn_box_reg: 0.0184 (0.0324)  time: 0.2737  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [16]  [ 490/1229]  eta: 0:03:21  lr: 0.000050  loss: 0.3165 (0.4142)  loss_classifier: 0.1267 (0.1482)  loss_box_reg: 0.0912 (0.1387)  loss_objectness: 0.0602 (0.0952)  loss_rpn_box_reg: 0.0110 (0.0321)  time: 0.2683  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [16]  [ 500/1229]  eta: 0:03:18  lr: 0.000050  loss: 0.3126 (0.4140)  loss_classifier: 0.1231 (0.1480)  loss_box_reg: 0.0912 (0.1386)  loss_objectness: 0.0620 (0.0952)  loss_rpn_box_reg: 0.0186 (0.0322)  time: 0.2720  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [16]  [ 510/1229]  eta: 0:03:15  lr: 0.000050  loss: 0.3766 (0.4149)  loss_classifier: 0.1323 (0.1483)  loss_box_reg: 0.1209 (0.1393)  loss_objectness: 0.0644 (0.0950)  loss_rpn_box_reg: 0.0264 (0.0323)  time: 0.2747  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [16]  [ 520/1229]  eta: 0:03:13  lr: 0.000050  loss: 0.3766 (0.4148)  loss_classifier: 0.1415 (0.1480)  loss_box_reg: 0.1040 (0.1391)  loss_objectness: 0.0853 (0.0953)  loss_rpn_box_reg: 0.0199 (0.0324)  time: 0.2734  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [16]  [ 530/1229]  eta: 0:03:10  lr: 0.000050  loss: 0.3814 (0.4161)  loss_classifier: 0.1415 (0.1483)  loss_box_reg: 0.1132 (0.1392)  loss_objectness: 0.0945 (0.0959)  loss_rpn_box_reg: 0.0216 (0.0327)  time: 0.2727  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [16]  [ 540/1229]  eta: 0:03:07  lr: 0.000050  loss: 0.3814 (0.4170)  loss_classifier: 0.1460 (0.1485)  loss_box_reg: 0.1202 (0.1398)  loss_objectness: 0.0948 (0.0961)  loss_rpn_box_reg: 0.0216 (0.0326)  time: 0.2707  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [16]  [ 550/1229]  eta: 0:03:04  lr: 0.000050  loss: 0.3660 (0.4172)  loss_classifier: 0.1262 (0.1486)  loss_box_reg: 0.1060 (0.1394)  loss_objectness: 0.0955 (0.0963)  loss_rpn_box_reg: 0.0226 (0.0328)  time: 0.2703  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [16]  [ 560/1229]  eta: 0:03:02  lr: 0.000050  loss: 0.3797 (0.4167)  loss_classifier: 0.1388 (0.1485)  loss_box_reg: 0.1057 (0.1393)  loss_objectness: 0.0944 (0.0963)  loss_rpn_box_reg: 0.0218 (0.0326)  time: 0.2740  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [16]  [ 570/1229]  eta: 0:02:59  lr: 0.000050  loss: 0.3824 (0.4162)  loss_classifier: 0.1439 (0.1485)  loss_box_reg: 0.1057 (0.1392)  loss_objectness: 0.0832 (0.0962)  loss_rpn_box_reg: 0.0176 (0.0324)  time: 0.2710  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [16]  [ 580/1229]  eta: 0:02:56  lr: 0.000050  loss: 0.3967 (0.4179)  loss_classifier: 0.1412 (0.1492)  loss_box_reg: 0.1300 (0.1399)  loss_objectness: 0.0829 (0.0965)  loss_rpn_box_reg: 0.0194 (0.0323)  time: 0.2670  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [16]  [ 590/1229]  eta: 0:02:54  lr: 0.000050  loss: 0.4031 (0.4202)  loss_classifier: 0.1466 (0.1501)  loss_box_reg: 0.1332 (0.1409)  loss_objectness: 0.0800 (0.0966)  loss_rpn_box_reg: 0.0196 (0.0326)  time: 0.2749  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [16]  [ 600/1229]  eta: 0:02:51  lr: 0.000050  loss: 0.5459 (0.4221)  loss_classifier: 0.1864 (0.1506)  loss_box_reg: 0.1624 (0.1417)  loss_objectness: 0.0984 (0.0969)  loss_rpn_box_reg: 0.0341 (0.0329)  time: 0.2773  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [16]  [ 610/1229]  eta: 0:02:48  lr: 0.000050  loss: 0.3714 (0.4217)  loss_classifier: 0.1379 (0.1504)  loss_box_reg: 0.0875 (0.1415)  loss_objectness: 0.0781 (0.0968)  loss_rpn_box_reg: 0.0249 (0.0330)  time: 0.2719  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [16]  [ 620/1229]  eta: 0:02:45  lr: 0.000050  loss: 0.2939 (0.4218)  loss_classifier: 0.1272 (0.1505)  loss_box_reg: 0.0875 (0.1414)  loss_objectness: 0.0781 (0.0969)  loss_rpn_box_reg: 0.0200 (0.0329)  time: 0.2722  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [16]  [ 630/1229]  eta: 0:02:43  lr: 0.000050  loss: 0.3756 (0.4222)  loss_classifier: 0.1353 (0.1507)  loss_box_reg: 0.1268 (0.1418)  loss_objectness: 0.1061 (0.0970)  loss_rpn_box_reg: 0.0259 (0.0328)  time: 0.2719  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [16]  [ 640/1229]  eta: 0:02:40  lr: 0.000050  loss: 0.3771 (0.4220)  loss_classifier: 0.1416 (0.1507)  loss_box_reg: 0.1290 (0.1418)  loss_objectness: 0.0840 (0.0968)  loss_rpn_box_reg: 0.0161 (0.0327)  time: 0.2705  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [16]  [ 650/1229]  eta: 0:02:37  lr: 0.000050  loss: 0.4088 (0.4233)  loss_classifier: 0.1416 (0.1509)  loss_box_reg: 0.1276 (0.1423)  loss_objectness: 0.0840 (0.0970)  loss_rpn_box_reg: 0.0174 (0.0331)  time: 0.2646  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [16]  [ 660/1229]  eta: 0:02:34  lr: 0.000050  loss: 0.3929 (0.4245)  loss_classifier: 0.1377 (0.1512)  loss_box_reg: 0.1276 (0.1429)  loss_objectness: 0.0930 (0.0972)  loss_rpn_box_reg: 0.0228 (0.0333)  time: 0.2617  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [16]  [ 670/1229]  eta: 0:02:32  lr: 0.000050  loss: 0.3949 (0.4256)  loss_classifier: 0.1401 (0.1516)  loss_box_reg: 0.1295 (0.1435)  loss_objectness: 0.0930 (0.0972)  loss_rpn_box_reg: 0.0233 (0.0333)  time: 0.2679  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [16]  [ 680/1229]  eta: 0:02:29  lr: 0.000050  loss: 0.4160 (0.4258)  loss_classifier: 0.1505 (0.1517)  loss_box_reg: 0.1467 (0.1437)  loss_objectness: 0.0930 (0.0973)  loss_rpn_box_reg: 0.0246 (0.0332)  time: 0.2716  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [16]  [ 690/1229]  eta: 0:02:26  lr: 0.000050  loss: 0.3965 (0.4258)  loss_classifier: 0.1405 (0.1516)  loss_box_reg: 0.1217 (0.1438)  loss_objectness: 0.0787 (0.0972)  loss_rpn_box_reg: 0.0200 (0.0332)  time: 0.2704  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [16]  [ 700/1229]  eta: 0:02:23  lr: 0.000050  loss: 0.3965 (0.4256)  loss_classifier: 0.1360 (0.1514)  loss_box_reg: 0.1217 (0.1436)  loss_objectness: 0.0666 (0.0975)  loss_rpn_box_reg: 0.0160 (0.0331)  time: 0.2646  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [16]  [ 710/1229]  eta: 0:02:21  lr: 0.000050  loss: 0.4134 (0.4254)  loss_classifier: 0.1360 (0.1512)  loss_box_reg: 0.1420 (0.1437)  loss_objectness: 0.0757 (0.0973)  loss_rpn_box_reg: 0.0165 (0.0332)  time: 0.2655  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [16]  [ 720/1229]  eta: 0:02:18  lr: 0.000050  loss: 0.3674 (0.4245)  loss_classifier: 0.1412 (0.1511)  loss_box_reg: 0.1169 (0.1434)  loss_objectness: 0.0640 (0.0971)  loss_rpn_box_reg: 0.0165 (0.0330)  time: 0.2754  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [16]  [ 730/1229]  eta: 0:02:15  lr: 0.000050  loss: 0.3644 (0.4244)  loss_classifier: 0.1415 (0.1511)  loss_box_reg: 0.1129 (0.1431)  loss_objectness: 0.0849 (0.0973)  loss_rpn_box_reg: 0.0207 (0.0329)  time: 0.2795  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [16]  [ 740/1229]  eta: 0:02:12  lr: 0.000050  loss: 0.3431 (0.4253)  loss_classifier: 0.1343 (0.1514)  loss_box_reg: 0.1090 (0.1436)  loss_objectness: 0.0935 (0.0972)  loss_rpn_box_reg: 0.0244 (0.0331)  time: 0.2714  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [16]  [ 750/1229]  eta: 0:02:10  lr: 0.000050  loss: 0.3862 (0.4248)  loss_classifier: 0.1339 (0.1512)  loss_box_reg: 0.1135 (0.1435)  loss_objectness: 0.0935 (0.0972)  loss_rpn_box_reg: 0.0244 (0.0330)  time: 0.2667  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [16]  [ 760/1229]  eta: 0:02:07  lr: 0.000050  loss: 0.4068 (0.4255)  loss_classifier: 0.1495 (0.1515)  loss_box_reg: 0.1504 (0.1439)  loss_objectness: 0.0921 (0.0972)  loss_rpn_box_reg: 0.0226 (0.0329)  time: 0.2709  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [16]  [ 770/1229]  eta: 0:02:04  lr: 0.000050  loss: 0.4149 (0.4252)  loss_classifier: 0.1602 (0.1514)  loss_box_reg: 0.1499 (0.1438)  loss_objectness: 0.0681 (0.0972)  loss_rpn_box_reg: 0.0251 (0.0329)  time: 0.2749  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [16]  [ 780/1229]  eta: 0:02:02  lr: 0.000050  loss: 0.2935 (0.4243)  loss_classifier: 0.0999 (0.1509)  loss_box_reg: 0.0828 (0.1432)  loss_objectness: 0.0717 (0.0971)  loss_rpn_box_reg: 0.0205 (0.0330)  time: 0.2755  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [16]  [ 790/1229]  eta: 0:01:59  lr: 0.000050  loss: 0.2927 (0.4246)  loss_classifier: 0.0999 (0.1510)  loss_box_reg: 0.0983 (0.1435)  loss_objectness: 0.0929 (0.0973)  loss_rpn_box_reg: 0.0167 (0.0328)  time: 0.2731  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [16]  [ 800/1229]  eta: 0:01:56  lr: 0.000050  loss: 0.3057 (0.4239)  loss_classifier: 0.1066 (0.1506)  loss_box_reg: 0.1124 (0.1432)  loss_objectness: 0.0767 (0.0972)  loss_rpn_box_reg: 0.0208 (0.0330)  time: 0.2708  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [16]  [ 810/1229]  eta: 0:01:53  lr: 0.000050  loss: 0.2910 (0.4240)  loss_classifier: 0.1059 (0.1506)  loss_box_reg: 0.1024 (0.1433)  loss_objectness: 0.0702 (0.0971)  loss_rpn_box_reg: 0.0217 (0.0330)  time: 0.2708  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [16]  [ 820/1229]  eta: 0:01:51  lr: 0.000050  loss: 0.3205 (0.4247)  loss_classifier: 0.1338 (0.1509)  loss_box_reg: 0.1274 (0.1439)  loss_objectness: 0.0644 (0.0969)  loss_rpn_box_reg: 0.0209 (0.0330)  time: 0.2699  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [16]  [ 830/1229]  eta: 0:01:48  lr: 0.000050  loss: 0.3873 (0.4250)  loss_classifier: 0.1338 (0.1510)  loss_box_reg: 0.1433 (0.1442)  loss_objectness: 0.0636 (0.0969)  loss_rpn_box_reg: 0.0157 (0.0329)  time: 0.2727  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [16]  [ 840/1229]  eta: 0:01:45  lr: 0.000050  loss: 0.3873 (0.4256)  loss_classifier: 0.1260 (0.1512)  loss_box_reg: 0.1185 (0.1441)  loss_objectness: 0.0927 (0.0973)  loss_rpn_box_reg: 0.0175 (0.0330)  time: 0.2769  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [16]  [ 850/1229]  eta: 0:01:43  lr: 0.000050  loss: 0.4298 (0.4260)  loss_classifier: 0.1462 (0.1514)  loss_box_reg: 0.1245 (0.1443)  loss_objectness: 0.0927 (0.0973)  loss_rpn_box_reg: 0.0210 (0.0330)  time: 0.2746  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [16]  [ 860/1229]  eta: 0:01:40  lr: 0.000050  loss: 0.3650 (0.4257)  loss_classifier: 0.1235 (0.1513)  loss_box_reg: 0.1328 (0.1443)  loss_objectness: 0.0801 (0.0972)  loss_rpn_box_reg: 0.0184 (0.0329)  time: 0.2725  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [16]  [ 870/1229]  eta: 0:01:37  lr: 0.000050  loss: 0.2710 (0.4246)  loss_classifier: 0.1004 (0.1509)  loss_box_reg: 0.0946 (0.1439)  loss_objectness: 0.0662 (0.0970)  loss_rpn_box_reg: 0.0086 (0.0327)  time: 0.2707  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [16]  [ 880/1229]  eta: 0:01:34  lr: 0.000050  loss: 0.3385 (0.4255)  loss_classifier: 0.1178 (0.1511)  loss_box_reg: 0.1030 (0.1443)  loss_objectness: 0.0870 (0.0972)  loss_rpn_box_reg: 0.0147 (0.0328)  time: 0.2678  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [16]  [ 890/1229]  eta: 0:01:32  lr: 0.000050  loss: 0.4754 (0.4252)  loss_classifier: 0.1605 (0.1511)  loss_box_reg: 0.1580 (0.1441)  loss_objectness: 0.0953 (0.0972)  loss_rpn_box_reg: 0.0260 (0.0328)  time: 0.2631  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [16]  [ 900/1229]  eta: 0:01:29  lr: 0.000050  loss: 0.4614 (0.4260)  loss_classifier: 0.1605 (0.1514)  loss_box_reg: 0.1201 (0.1443)  loss_objectness: 0.0978 (0.0974)  loss_rpn_box_reg: 0.0243 (0.0329)  time: 0.2692  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [16]  [ 910/1229]  eta: 0:01:26  lr: 0.000050  loss: 0.3674 (0.4261)  loss_classifier: 0.1475 (0.1515)  loss_box_reg: 0.1099 (0.1441)  loss_objectness: 0.0985 (0.0977)  loss_rpn_box_reg: 0.0243 (0.0329)  time: 0.2745  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [16]  [ 920/1229]  eta: 0:01:24  lr: 0.000050  loss: 0.3902 (0.4279)  loss_classifier: 0.1422 (0.1518)  loss_box_reg: 0.1285 (0.1445)  loss_objectness: 0.0993 (0.0979)  loss_rpn_box_reg: 0.0284 (0.0337)  time: 0.2734  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [16]  [ 930/1229]  eta: 0:01:21  lr: 0.000050  loss: 0.5255 (0.4285)  loss_classifier: 0.1670 (0.1519)  loss_box_reg: 0.1736 (0.1448)  loss_objectness: 0.0997 (0.0981)  loss_rpn_box_reg: 0.0228 (0.0337)  time: 0.2717  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [16]  [ 940/1229]  eta: 0:01:18  lr: 0.000050  loss: 0.5069 (0.4294)  loss_classifier: 0.1670 (0.1522)  loss_box_reg: 0.2161 (0.1453)  loss_objectness: 0.0907 (0.0981)  loss_rpn_box_reg: 0.0283 (0.0339)  time: 0.2700  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [16]  [ 950/1229]  eta: 0:01:15  lr: 0.000050  loss: 0.3196 (0.4284)  loss_classifier: 0.1188 (0.1518)  loss_box_reg: 0.1030 (0.1449)  loss_objectness: 0.0699 (0.0980)  loss_rpn_box_reg: 0.0223 (0.0338)  time: 0.2730  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [16]  [ 960/1229]  eta: 0:01:13  lr: 0.000050  loss: 0.4023 (0.4299)  loss_classifier: 0.1188 (0.1524)  loss_box_reg: 0.1045 (0.1455)  loss_objectness: 0.0949 (0.0982)  loss_rpn_box_reg: 0.0205 (0.0337)  time: 0.2676  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [16]  [ 970/1229]  eta: 0:01:10  lr: 0.000050  loss: 0.4511 (0.4305)  loss_classifier: 0.1796 (0.1526)  loss_box_reg: 0.1536 (0.1458)  loss_objectness: 0.0958 (0.0984)  loss_rpn_box_reg: 0.0253 (0.0337)  time: 0.2644  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [16]  [ 980/1229]  eta: 0:01:07  lr: 0.000050  loss: 0.3337 (0.4301)  loss_classifier: 0.1215 (0.1525)  loss_box_reg: 0.0965 (0.1454)  loss_objectness: 0.0864 (0.0985)  loss_rpn_box_reg: 0.0217 (0.0337)  time: 0.2727  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [16]  [ 990/1229]  eta: 0:01:04  lr: 0.000050  loss: 0.3337 (0.4311)  loss_classifier: 0.1461 (0.1530)  loss_box_reg: 0.0922 (0.1456)  loss_objectness: 0.1031 (0.0988)  loss_rpn_box_reg: 0.0164 (0.0338)  time: 0.2777  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [16]  [1000/1229]  eta: 0:01:02  lr: 0.000050  loss: 0.6065 (0.4336)  loss_classifier: 0.2246 (0.1539)  loss_box_reg: 0.1847 (0.1465)  loss_objectness: 0.1175 (0.0991)  loss_rpn_box_reg: 0.0340 (0.0340)  time: 0.2728  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [16]  [1010/1229]  eta: 0:00:59  lr: 0.000050  loss: 0.5168 (0.4339)  loss_classifier: 0.1691 (0.1541)  loss_box_reg: 0.1766 (0.1465)  loss_objectness: 0.1252 (0.0994)  loss_rpn_box_reg: 0.0306 (0.0340)  time: 0.2729  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [16]  [1020/1229]  eta: 0:00:56  lr: 0.000050  loss: 0.5015 (0.4351)  loss_classifier: 0.1816 (0.1544)  loss_box_reg: 0.1318 (0.1468)  loss_objectness: 0.1105 (0.0997)  loss_rpn_box_reg: 0.0246 (0.0341)  time: 0.2811  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [16]  [1030/1229]  eta: 0:00:54  lr: 0.000050  loss: 0.5015 (0.4351)  loss_classifier: 0.1816 (0.1544)  loss_box_reg: 0.1769 (0.1468)  loss_objectness: 0.0889 (0.0997)  loss_rpn_box_reg: 0.0246 (0.0343)  time: 0.2827  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [16]  [1040/1229]  eta: 0:00:51  lr: 0.000050  loss: 0.3300 (0.4350)  loss_classifier: 0.1302 (0.1544)  loss_box_reg: 0.1028 (0.1470)  loss_objectness: 0.0683 (0.0995)  loss_rpn_box_reg: 0.0216 (0.0342)  time: 0.2743  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [16]  [1050/1229]  eta: 0:00:48  lr: 0.000050  loss: 0.3205 (0.4346)  loss_classifier: 0.1302 (0.1543)  loss_box_reg: 0.1028 (0.1468)  loss_objectness: 0.0674 (0.0993)  loss_rpn_box_reg: 0.0162 (0.0342)  time: 0.2743  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [16]  [1060/1229]  eta: 0:00:45  lr: 0.000050  loss: 0.3743 (0.4350)  loss_classifier: 0.1422 (0.1543)  loss_box_reg: 0.1321 (0.1471)  loss_objectness: 0.0691 (0.0993)  loss_rpn_box_reg: 0.0141 (0.0343)  time: 0.2792  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [16]  [1070/1229]  eta: 0:00:43  lr: 0.000050  loss: 0.4813 (0.4364)  loss_classifier: 0.1787 (0.1549)  loss_box_reg: 0.1597 (0.1475)  loss_objectness: 0.0943 (0.0998)  loss_rpn_box_reg: 0.0231 (0.0343)  time: 0.2739  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [16]  [1080/1229]  eta: 0:00:40  lr: 0.000050  loss: 0.5140 (0.4371)  loss_classifier: 0.1865 (0.1551)  loss_box_reg: 0.1936 (0.1479)  loss_objectness: 0.1092 (0.0998)  loss_rpn_box_reg: 0.0266 (0.0342)  time: 0.2698  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [16]  [1090/1229]  eta: 0:00:37  lr: 0.000050  loss: 0.4085 (0.4365)  loss_classifier: 0.1418 (0.1549)  loss_box_reg: 0.1282 (0.1477)  loss_objectness: 0.0937 (0.0997)  loss_rpn_box_reg: 0.0250 (0.0342)  time: 0.2685  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [16]  [1100/1229]  eta: 0:00:35  lr: 0.000050  loss: 0.3062 (0.4357)  loss_classifier: 0.1183 (0.1547)  loss_box_reg: 0.0905 (0.1472)  loss_objectness: 0.0861 (0.0998)  loss_rpn_box_reg: 0.0171 (0.0340)  time: 0.2711  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [16]  [1110/1229]  eta: 0:00:32  lr: 0.000050  loss: 0.2593 (0.4361)  loss_classifier: 0.1074 (0.1548)  loss_box_reg: 0.0920 (0.1472)  loss_objectness: 0.0861 (0.1000)  loss_rpn_box_reg: 0.0171 (0.0341)  time: 0.2740  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [16]  [1120/1229]  eta: 0:00:29  lr: 0.000050  loss: 0.4394 (0.4366)  loss_classifier: 0.1526 (0.1549)  loss_box_reg: 0.1104 (0.1476)  loss_objectness: 0.0957 (0.1001)  loss_rpn_box_reg: 0.0253 (0.0340)  time: 0.2727  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [16]  [1130/1229]  eta: 0:00:26  lr: 0.000050  loss: 0.4497 (0.4366)  loss_classifier: 0.1801 (0.1550)  loss_box_reg: 0.1096 (0.1474)  loss_objectness: 0.0971 (0.1002)  loss_rpn_box_reg: 0.0253 (0.0341)  time: 0.2706  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [16]  [1140/1229]  eta: 0:00:24  lr: 0.000050  loss: 0.3556 (0.4358)  loss_classifier: 0.1348 (0.1547)  loss_box_reg: 0.0984 (0.1471)  loss_objectness: 0.0883 (0.1000)  loss_rpn_box_reg: 0.0190 (0.0339)  time: 0.2690  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [16]  [1150/1229]  eta: 0:00:21  lr: 0.000050  loss: 0.3425 (0.4349)  loss_classifier: 0.1084 (0.1545)  loss_box_reg: 0.1220 (0.1469)  loss_objectness: 0.0721 (0.0997)  loss_rpn_box_reg: 0.0110 (0.0338)  time: 0.2677  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [16]  [1160/1229]  eta: 0:00:18  lr: 0.000050  loss: 0.3492 (0.4344)  loss_classifier: 0.1084 (0.1543)  loss_box_reg: 0.1220 (0.1466)  loss_objectness: 0.0685 (0.0996)  loss_rpn_box_reg: 0.0125 (0.0339)  time: 0.2709  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [16]  [1170/1229]  eta: 0:00:16  lr: 0.000050  loss: 0.3297 (0.4339)  loss_classifier: 0.1182 (0.1542)  loss_box_reg: 0.1184 (0.1464)  loss_objectness: 0.0685 (0.0995)  loss_rpn_box_reg: 0.0187 (0.0338)  time: 0.2768  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [16]  [1180/1229]  eta: 0:00:13  lr: 0.000050  loss: 0.3613 (0.4335)  loss_classifier: 0.1309 (0.1540)  loss_box_reg: 0.1104 (0.1462)  loss_objectness: 0.0771 (0.0994)  loss_rpn_box_reg: 0.0151 (0.0338)  time: 0.2711  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [16]  [1190/1229]  eta: 0:00:10  lr: 0.000050  loss: 0.3968 (0.4333)  loss_classifier: 0.1453 (0.1539)  loss_box_reg: 0.1078 (0.1463)  loss_objectness: 0.0771 (0.0993)  loss_rpn_box_reg: 0.0188 (0.0338)  time: 0.2680  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [16]  [1200/1229]  eta: 0:00:07  lr: 0.000050  loss: 0.2985 (0.4333)  loss_classifier: 0.1193 (0.1539)  loss_box_reg: 0.1017 (0.1464)  loss_objectness: 0.0737 (0.0993)  loss_rpn_box_reg: 0.0263 (0.0338)  time: 0.2734  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [16]  [1210/1229]  eta: 0:00:05  lr: 0.000050  loss: 0.4083 (0.4342)  loss_classifier: 0.1316 (0.1542)  loss_box_reg: 0.1516 (0.1468)  loss_objectness: 0.0998 (0.0994)  loss_rpn_box_reg: 0.0298 (0.0337)  time: 0.2729  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [16]  [1220/1229]  eta: 0:00:02  lr: 0.000050  loss: 0.4422 (0.4340)  loss_classifier: 0.1316 (0.1539)  loss_box_reg: 0.1298 (0.1465)  loss_objectness: 0.1083 (0.0995)  loss_rpn_box_reg: 0.0329 (0.0341)  time: 0.2753  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [16]  [1228/1229]  eta: 0:00:00  lr: 0.000050  loss: 0.4422 (0.4341)  loss_classifier: 0.1470 (0.1540)  loss_box_reg: 0.1094 (0.1466)  loss_objectness: 0.0782 (0.0994)  loss_rpn_box_reg: 0.0299 (0.0340)  time: 0.2761  data: 0.1288  max mem: 1751\n",
      "Training Epoch: [16] Total time: 0:05:34 (0.2722 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:37  model_time: 0.2830 (0.2830)  evaluator_time: 0.0020 (0.0020)  time: 0.3160  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0780 (0.0819)  evaluator_time: 0.0040 (0.0086)  time: 0.1261  data: 0.0357  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0830 (0.0809)  evaluator_time: 0.0030 (0.0078)  time: 0.1197  data: 0.0307  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0720 (0.0799)  evaluator_time: 0.0040 (0.0076)  time: 0.1190  data: 0.0350  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0720 (0.0798)  evaluator_time: 0.0030 (0.0076)  time: 0.1210  data: 0.0386  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1238 s / it)\n",
      "Averaged stats: model_time: 0.0720 (0.0798)  evaluator_time: 0.0030 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.094\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.347\n",
      "Testing Epoch: [16]  [  0/308]  eta: 0:00:37  lr: 0.000050  loss: 0.1642 (0.1642)  loss_classifier: 0.0592 (0.0592)  loss_box_reg: 0.0687 (0.0687)  loss_objectness: 0.0249 (0.0249)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1220  data: 0.0280  max mem: 1751\n",
      "Testing Epoch: [16]  [100/308]  eta: 0:00:28  lr: 0.000050  loss: 0.3131 (0.4793)  loss_classifier: 0.1343 (0.1544)  loss_box_reg: 0.1176 (0.1725)  loss_objectness: 0.0533 (0.1005)  loss_rpn_box_reg: 0.0186 (0.0520)  time: 0.1412  data: 0.0385  max mem: 1751\n",
      "Testing Epoch: [16]  [200/308]  eta: 0:00:14  lr: 0.000050  loss: 0.3600 (0.4560)  loss_classifier: 0.1388 (0.1491)  loss_box_reg: 0.1252 (0.1634)  loss_objectness: 0.0573 (0.0944)  loss_rpn_box_reg: 0.0197 (0.0492)  time: 0.1365  data: 0.0316  max mem: 1751\n",
      "Testing Epoch: [16]  [300/308]  eta: 0:00:01  lr: 0.000050  loss: 0.4706 (0.4530)  loss_classifier: 0.1595 (0.1492)  loss_box_reg: 0.1752 (0.1641)  loss_objectness: 0.0834 (0.0921)  loss_rpn_box_reg: 0.0265 (0.0476)  time: 0.1323  data: 0.0372  max mem: 1751\n",
      "Testing Epoch: [16]  [307/308]  eta: 0:00:00  lr: 0.000050  loss: 0.4480 (0.4532)  loss_classifier: 0.1844 (0.1495)  loss_box_reg: 0.1752 (0.1644)  loss_objectness: 0.0729 (0.0922)  loss_rpn_box_reg: 0.0269 (0.0471)  time: 0.1322  data: 0.0367  max mem: 1751\n",
      "Testing Epoch: [16] Total time: 0:00:42 (0.1371 s / it)\n",
      "Training Epoch: [17]  [   0/1229]  eta: 0:05:34  lr: 0.000005  loss: 0.1993 (0.1993)  loss_classifier: 0.0651 (0.0651)  loss_box_reg: 0.0622 (0.0622)  loss_objectness: 0.0474 (0.0474)  loss_rpn_box_reg: 0.0246 (0.0246)  time: 0.2720  data: 0.1370  max mem: 1751\n",
      "Training Epoch: [17]  [  10/1229]  eta: 0:05:44  lr: 0.000005  loss: 0.5284 (0.4779)  loss_classifier: 0.1691 (0.1712)  loss_box_reg: 0.1802 (0.1736)  loss_objectness: 0.0929 (0.1040)  loss_rpn_box_reg: 0.0240 (0.0291)  time: 0.2825  data: 0.1440  max mem: 1751\n",
      "Training Epoch: [17]  [  20/1229]  eta: 0:05:41  lr: 0.000005  loss: 0.4777 (0.5156)  loss_classifier: 0.1633 (0.1826)  loss_box_reg: 0.1346 (0.1816)  loss_objectness: 0.1157 (0.1169)  loss_rpn_box_reg: 0.0240 (0.0346)  time: 0.2829  data: 0.1417  max mem: 1751\n",
      "Training Epoch: [17]  [  30/1229]  eta: 0:05:33  lr: 0.000005  loss: 0.4287 (0.4764)  loss_classifier: 0.1520 (0.1681)  loss_box_reg: 0.1285 (0.1683)  loss_objectness: 0.0866 (0.1051)  loss_rpn_box_reg: 0.0177 (0.0349)  time: 0.2758  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [17]  [  40/1229]  eta: 0:05:31  lr: 0.000005  loss: 0.3929 (0.4579)  loss_classifier: 0.1519 (0.1624)  loss_box_reg: 0.1442 (0.1602)  loss_objectness: 0.0797 (0.1016)  loss_rpn_box_reg: 0.0160 (0.0337)  time: 0.2744  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [17]  [  50/1229]  eta: 0:05:26  lr: 0.000005  loss: 0.4085 (0.4625)  loss_classifier: 0.1519 (0.1623)  loss_box_reg: 0.1470 (0.1620)  loss_objectness: 0.0902 (0.1013)  loss_rpn_box_reg: 0.0233 (0.0369)  time: 0.2743  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [17]  [  60/1229]  eta: 0:05:23  lr: 0.000005  loss: 0.3776 (0.4517)  loss_classifier: 0.1362 (0.1595)  loss_box_reg: 0.1161 (0.1565)  loss_objectness: 0.0748 (0.1003)  loss_rpn_box_reg: 0.0237 (0.0354)  time: 0.2725  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [17]  [  70/1229]  eta: 0:05:19  lr: 0.000005  loss: 0.4022 (0.4574)  loss_classifier: 0.1251 (0.1617)  loss_box_reg: 0.1064 (0.1553)  loss_objectness: 0.0846 (0.1039)  loss_rpn_box_reg: 0.0243 (0.0366)  time: 0.2727  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [17]  [  80/1229]  eta: 0:05:16  lr: 0.000005  loss: 0.4921 (0.4642)  loss_classifier: 0.1566 (0.1642)  loss_box_reg: 0.1454 (0.1593)  loss_objectness: 0.1024 (0.1047)  loss_rpn_box_reg: 0.0243 (0.0361)  time: 0.2721  data: 0.1372  max mem: 1751\n",
      "Training Epoch: [17]  [  90/1229]  eta: 0:05:13  lr: 0.000005  loss: 0.3927 (0.4552)  loss_classifier: 0.1349 (0.1598)  loss_box_reg: 0.1214 (0.1548)  loss_objectness: 0.0973 (0.1048)  loss_rpn_box_reg: 0.0273 (0.0358)  time: 0.2742  data: 0.1384  max mem: 1751\n",
      "Training Epoch: [17]  [ 100/1229]  eta: 0:05:10  lr: 0.000005  loss: 0.4141 (0.4610)  loss_classifier: 0.1431 (0.1613)  loss_box_reg: 0.1371 (0.1578)  loss_objectness: 0.1087 (0.1046)  loss_rpn_box_reg: 0.0329 (0.0373)  time: 0.2730  data: 0.1390  max mem: 1751\n",
      "Training Epoch: [17]  [ 110/1229]  eta: 0:05:07  lr: 0.000005  loss: 0.4267 (0.4584)  loss_classifier: 0.1439 (0.1613)  loss_box_reg: 0.1482 (0.1567)  loss_objectness: 0.0886 (0.1040)  loss_rpn_box_reg: 0.0274 (0.0364)  time: 0.2705  data: 0.1383  max mem: 1751\n",
      "Training Epoch: [17]  [ 120/1229]  eta: 0:05:03  lr: 0.000005  loss: 0.3216 (0.4479)  loss_classifier: 0.1131 (0.1576)  loss_box_reg: 0.0991 (0.1517)  loss_objectness: 0.0745 (0.1034)  loss_rpn_box_reg: 0.0201 (0.0352)  time: 0.2694  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [17]  [ 130/1229]  eta: 0:05:00  lr: 0.000005  loss: 0.3425 (0.4424)  loss_classifier: 0.1333 (0.1554)  loss_box_reg: 0.0923 (0.1485)  loss_objectness: 0.0865 (0.1031)  loss_rpn_box_reg: 0.0253 (0.0353)  time: 0.2685  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [17]  [ 140/1229]  eta: 0:04:57  lr: 0.000005  loss: 0.2977 (0.4300)  loss_classifier: 0.1139 (0.1511)  loss_box_reg: 0.0742 (0.1439)  loss_objectness: 0.0821 (0.1007)  loss_rpn_box_reg: 0.0233 (0.0343)  time: 0.2669  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [17]  [ 150/1229]  eta: 0:04:54  lr: 0.000005  loss: 0.3225 (0.4277)  loss_classifier: 0.1277 (0.1502)  loss_box_reg: 0.0869 (0.1416)  loss_objectness: 0.0633 (0.1016)  loss_rpn_box_reg: 0.0210 (0.0344)  time: 0.2722  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [17]  [ 160/1229]  eta: 0:04:53  lr: 0.000005  loss: 0.3467 (0.4304)  loss_classifier: 0.1387 (0.1519)  loss_box_reg: 0.0942 (0.1430)  loss_objectness: 0.0649 (0.1012)  loss_rpn_box_reg: 0.0199 (0.0342)  time: 0.2819  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [17]  [ 170/1229]  eta: 0:04:50  lr: 0.000005  loss: 0.3871 (0.4314)  loss_classifier: 0.1387 (0.1519)  loss_box_reg: 0.1011 (0.1427)  loss_objectness: 0.0915 (0.1015)  loss_rpn_box_reg: 0.0199 (0.0354)  time: 0.2782  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [17]  [ 180/1229]  eta: 0:04:47  lr: 0.000005  loss: 0.4323 (0.4336)  loss_classifier: 0.1519 (0.1528)  loss_box_reg: 0.1313 (0.1445)  loss_objectness: 0.0880 (0.1012)  loss_rpn_box_reg: 0.0291 (0.0352)  time: 0.2734  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [17]  [ 190/1229]  eta: 0:04:44  lr: 0.000005  loss: 0.3674 (0.4289)  loss_classifier: 0.1414 (0.1513)  loss_box_reg: 0.1245 (0.1418)  loss_objectness: 0.0794 (0.1001)  loss_rpn_box_reg: 0.0228 (0.0357)  time: 0.2748  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [17]  [ 200/1229]  eta: 0:04:41  lr: 0.000005  loss: 0.2997 (0.4265)  loss_classifier: 0.1088 (0.1507)  loss_box_reg: 0.0984 (0.1406)  loss_objectness: 0.0788 (0.1003)  loss_rpn_box_reg: 0.0130 (0.0350)  time: 0.2720  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [17]  [ 210/1229]  eta: 0:04:38  lr: 0.000005  loss: 0.2783 (0.4200)  loss_classifier: 0.0984 (0.1489)  loss_box_reg: 0.0804 (0.1381)  loss_objectness: 0.0744 (0.0990)  loss_rpn_box_reg: 0.0123 (0.0341)  time: 0.2709  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [17]  [ 220/1229]  eta: 0:04:36  lr: 0.000005  loss: 0.4221 (0.4271)  loss_classifier: 0.1344 (0.1516)  loss_box_reg: 0.1187 (0.1404)  loss_objectness: 0.1156 (0.1007)  loss_rpn_box_reg: 0.0232 (0.0344)  time: 0.2734  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [17]  [ 230/1229]  eta: 0:04:33  lr: 0.000005  loss: 0.5083 (0.4324)  loss_classifier: 0.1853 (0.1540)  loss_box_reg: 0.1724 (0.1429)  loss_objectness: 0.1229 (0.1013)  loss_rpn_box_reg: 0.0279 (0.0342)  time: 0.2773  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [17]  [ 240/1229]  eta: 0:04:31  lr: 0.000005  loss: 0.3475 (0.4283)  loss_classifier: 0.1292 (0.1529)  loss_box_reg: 0.1156 (0.1413)  loss_objectness: 0.0879 (0.1005)  loss_rpn_box_reg: 0.0207 (0.0337)  time: 0.2793  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [17]  [ 250/1229]  eta: 0:04:28  lr: 0.000005  loss: 0.3716 (0.4322)  loss_classifier: 0.1237 (0.1532)  loss_box_reg: 0.1013 (0.1421)  loss_objectness: 0.0732 (0.1012)  loss_rpn_box_reg: 0.0208 (0.0357)  time: 0.2745  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [17]  [ 260/1229]  eta: 0:04:25  lr: 0.000005  loss: 0.4693 (0.4367)  loss_classifier: 0.1464 (0.1540)  loss_box_reg: 0.1298 (0.1433)  loss_objectness: 0.1147 (0.1026)  loss_rpn_box_reg: 0.0382 (0.0368)  time: 0.2740  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [17]  [ 270/1229]  eta: 0:04:23  lr: 0.000005  loss: 0.5302 (0.4387)  loss_classifier: 0.1637 (0.1550)  loss_box_reg: 0.1686 (0.1444)  loss_objectness: 0.0930 (0.1029)  loss_rpn_box_reg: 0.0182 (0.0364)  time: 0.2778  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [17]  [ 280/1229]  eta: 0:04:19  lr: 0.000005  loss: 0.4669 (0.4412)  loss_classifier: 0.1613 (0.1558)  loss_box_reg: 0.1654 (0.1449)  loss_objectness: 0.0937 (0.1038)  loss_rpn_box_reg: 0.0185 (0.0368)  time: 0.2697  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [17]  [ 290/1229]  eta: 0:04:17  lr: 0.000005  loss: 0.4252 (0.4384)  loss_classifier: 0.1456 (0.1549)  loss_box_reg: 0.1227 (0.1445)  loss_objectness: 0.0836 (0.1026)  loss_rpn_box_reg: 0.0214 (0.0365)  time: 0.2705  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [17]  [ 300/1229]  eta: 0:04:14  lr: 0.000005  loss: 0.3543 (0.4378)  loss_classifier: 0.1150 (0.1545)  loss_box_reg: 0.0871 (0.1439)  loss_objectness: 0.0719 (0.1031)  loss_rpn_box_reg: 0.0210 (0.0362)  time: 0.2788  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [17]  [ 310/1229]  eta: 0:04:11  lr: 0.000005  loss: 0.4320 (0.4391)  loss_classifier: 0.1279 (0.1547)  loss_box_reg: 0.1332 (0.1448)  loss_objectness: 0.0834 (0.1029)  loss_rpn_box_reg: 0.0266 (0.0368)  time: 0.2758  data: 0.1376  max mem: 1751\n",
      "Training Epoch: [17]  [ 320/1229]  eta: 0:04:09  lr: 0.000005  loss: 0.4320 (0.4372)  loss_classifier: 0.1460 (0.1544)  loss_box_reg: 0.1345 (0.1443)  loss_objectness: 0.0775 (0.1023)  loss_rpn_box_reg: 0.0254 (0.0363)  time: 0.2728  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [17]  [ 330/1229]  eta: 0:04:06  lr: 0.000005  loss: 0.4426 (0.4376)  loss_classifier: 0.1490 (0.1547)  loss_box_reg: 0.1235 (0.1441)  loss_objectness: 0.0811 (0.1028)  loss_rpn_box_reg: 0.0192 (0.0360)  time: 0.2793  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [17]  [ 340/1229]  eta: 0:04:04  lr: 0.000005  loss: 0.3999 (0.4373)  loss_classifier: 0.1404 (0.1545)  loss_box_reg: 0.0977 (0.1439)  loss_objectness: 0.0946 (0.1030)  loss_rpn_box_reg: 0.0188 (0.0359)  time: 0.2809  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [17]  [ 350/1229]  eta: 0:04:01  lr: 0.000005  loss: 0.2802 (0.4368)  loss_classifier: 0.1012 (0.1545)  loss_box_reg: 0.0894 (0.1431)  loss_objectness: 0.0885 (0.1032)  loss_rpn_box_reg: 0.0130 (0.0360)  time: 0.2743  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [17]  [ 360/1229]  eta: 0:03:58  lr: 0.000005  loss: 0.4483 (0.4408)  loss_classifier: 0.1582 (0.1559)  loss_box_reg: 0.1605 (0.1452)  loss_objectness: 0.0931 (0.1034)  loss_rpn_box_reg: 0.0280 (0.0363)  time: 0.2781  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [17]  [ 370/1229]  eta: 0:03:56  lr: 0.000005  loss: 0.3244 (0.4360)  loss_classifier: 0.1273 (0.1544)  loss_box_reg: 0.1232 (0.1436)  loss_objectness: 0.0654 (0.1023)  loss_rpn_box_reg: 0.0221 (0.0358)  time: 0.2804  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [17]  [ 380/1229]  eta: 0:03:53  lr: 0.000005  loss: 0.2841 (0.4341)  loss_classifier: 0.0864 (0.1538)  loss_box_reg: 0.0748 (0.1429)  loss_objectness: 0.0616 (0.1021)  loss_rpn_box_reg: 0.0109 (0.0354)  time: 0.2756  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [17]  [ 390/1229]  eta: 0:03:50  lr: 0.000005  loss: 0.3083 (0.4338)  loss_classifier: 0.1207 (0.1536)  loss_box_reg: 0.1015 (0.1429)  loss_objectness: 0.0784 (0.1021)  loss_rpn_box_reg: 0.0151 (0.0351)  time: 0.2808  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [17]  [ 400/1229]  eta: 0:03:47  lr: 0.000005  loss: 0.3607 (0.4364)  loss_classifier: 0.1266 (0.1543)  loss_box_reg: 0.1111 (0.1437)  loss_objectness: 0.1030 (0.1028)  loss_rpn_box_reg: 0.0191 (0.0356)  time: 0.2798  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [17]  [ 410/1229]  eta: 0:03:45  lr: 0.000005  loss: 0.3759 (0.4370)  loss_classifier: 0.1475 (0.1548)  loss_box_reg: 0.1126 (0.1440)  loss_objectness: 0.0873 (0.1029)  loss_rpn_box_reg: 0.0238 (0.0354)  time: 0.2749  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [17]  [ 420/1229]  eta: 0:03:42  lr: 0.000005  loss: 0.4231 (0.4359)  loss_classifier: 0.1464 (0.1544)  loss_box_reg: 0.1126 (0.1438)  loss_objectness: 0.0774 (0.1024)  loss_rpn_box_reg: 0.0159 (0.0353)  time: 0.2772  data: 0.1387  max mem: 1751\n",
      "Training Epoch: [17]  [ 430/1229]  eta: 0:03:39  lr: 0.000005  loss: 0.4155 (0.4354)  loss_classifier: 0.1389 (0.1542)  loss_box_reg: 0.0852 (0.1436)  loss_objectness: 0.0663 (0.1026)  loss_rpn_box_reg: 0.0166 (0.0349)  time: 0.2735  data: 0.1389  max mem: 1751\n",
      "Training Epoch: [17]  [ 440/1229]  eta: 0:03:37  lr: 0.000005  loss: 0.4155 (0.4372)  loss_classifier: 0.1400 (0.1551)  loss_box_reg: 0.1152 (0.1439)  loss_objectness: 0.1135 (0.1034)  loss_rpn_box_reg: 0.0173 (0.0349)  time: 0.2740  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [17]  [ 450/1229]  eta: 0:03:34  lr: 0.000005  loss: 0.4167 (0.4382)  loss_classifier: 0.1622 (0.1552)  loss_box_reg: 0.1223 (0.1445)  loss_objectness: 0.1211 (0.1034)  loss_rpn_box_reg: 0.0279 (0.0352)  time: 0.2761  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [17]  [ 460/1229]  eta: 0:03:31  lr: 0.000005  loss: 0.5020 (0.4397)  loss_classifier: 0.1730 (0.1558)  loss_box_reg: 0.1749 (0.1453)  loss_objectness: 0.1076 (0.1036)  loss_rpn_box_reg: 0.0250 (0.0350)  time: 0.2747  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [17]  [ 470/1229]  eta: 0:03:28  lr: 0.000005  loss: 0.4580 (0.4414)  loss_classifier: 0.1597 (0.1562)  loss_box_reg: 0.1677 (0.1457)  loss_objectness: 0.1060 (0.1041)  loss_rpn_box_reg: 0.0213 (0.0353)  time: 0.2726  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [17]  [ 480/1229]  eta: 0:03:25  lr: 0.000005  loss: 0.3963 (0.4407)  loss_classifier: 0.1464 (0.1561)  loss_box_reg: 0.1215 (0.1453)  loss_objectness: 0.0872 (0.1039)  loss_rpn_box_reg: 0.0208 (0.0354)  time: 0.2701  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [17]  [ 490/1229]  eta: 0:03:23  lr: 0.000005  loss: 0.3319 (0.4389)  loss_classifier: 0.1290 (0.1556)  loss_box_reg: 0.1115 (0.1447)  loss_objectness: 0.0704 (0.1032)  loss_rpn_box_reg: 0.0164 (0.0354)  time: 0.2696  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [17]  [ 500/1229]  eta: 0:03:20  lr: 0.000005  loss: 0.3663 (0.4399)  loss_classifier: 0.1454 (0.1563)  loss_box_reg: 0.1159 (0.1447)  loss_objectness: 0.0800 (0.1036)  loss_rpn_box_reg: 0.0193 (0.0353)  time: 0.2699  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [17]  [ 510/1229]  eta: 0:03:17  lr: 0.000005  loss: 0.4721 (0.4414)  loss_classifier: 0.1727 (0.1570)  loss_box_reg: 0.1453 (0.1457)  loss_objectness: 0.1030 (0.1037)  loss_rpn_box_reg: 0.0195 (0.0351)  time: 0.2730  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [17]  [ 520/1229]  eta: 0:03:14  lr: 0.000005  loss: 0.4077 (0.4409)  loss_classifier: 0.1567 (0.1569)  loss_box_reg: 0.1545 (0.1461)  loss_objectness: 0.0938 (0.1032)  loss_rpn_box_reg: 0.0200 (0.0348)  time: 0.2762  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [17]  [ 530/1229]  eta: 0:03:12  lr: 0.000005  loss: 0.3896 (0.4400)  loss_classifier: 0.1376 (0.1568)  loss_box_reg: 0.1334 (0.1457)  loss_objectness: 0.0710 (0.1029)  loss_rpn_box_reg: 0.0200 (0.0346)  time: 0.2777  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [17]  [ 540/1229]  eta: 0:03:09  lr: 0.000005  loss: 0.3515 (0.4397)  loss_classifier: 0.1282 (0.1567)  loss_box_reg: 0.1175 (0.1459)  loss_objectness: 0.0709 (0.1026)  loss_rpn_box_reg: 0.0189 (0.0344)  time: 0.2762  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [17]  [ 550/1229]  eta: 0:03:06  lr: 0.000005  loss: 0.3515 (0.4405)  loss_classifier: 0.1158 (0.1572)  loss_box_reg: 0.1176 (0.1464)  loss_objectness: 0.0718 (0.1024)  loss_rpn_box_reg: 0.0119 (0.0345)  time: 0.2785  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [17]  [ 560/1229]  eta: 0:03:03  lr: 0.000005  loss: 0.4682 (0.4412)  loss_classifier: 0.1589 (0.1572)  loss_box_reg: 0.1489 (0.1470)  loss_objectness: 0.0862 (0.1022)  loss_rpn_box_reg: 0.0209 (0.0347)  time: 0.2770  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [17]  [ 570/1229]  eta: 0:03:01  lr: 0.000005  loss: 0.4191 (0.4402)  loss_classifier: 0.1555 (0.1569)  loss_box_reg: 0.1217 (0.1464)  loss_objectness: 0.0862 (0.1024)  loss_rpn_box_reg: 0.0209 (0.0345)  time: 0.2693  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [17]  [ 580/1229]  eta: 0:02:58  lr: 0.000005  loss: 0.2891 (0.4392)  loss_classifier: 0.1119 (0.1565)  loss_box_reg: 0.1088 (0.1463)  loss_objectness: 0.0651 (0.1020)  loss_rpn_box_reg: 0.0184 (0.0344)  time: 0.2719  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [17]  [ 590/1229]  eta: 0:02:55  lr: 0.000005  loss: 0.3119 (0.4385)  loss_classifier: 0.1083 (0.1562)  loss_box_reg: 0.1088 (0.1460)  loss_objectness: 0.0573 (0.1017)  loss_rpn_box_reg: 0.0150 (0.0346)  time: 0.2725  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [17]  [ 600/1229]  eta: 0:02:52  lr: 0.000005  loss: 0.3200 (0.4379)  loss_classifier: 0.1230 (0.1560)  loss_box_reg: 0.1182 (0.1457)  loss_objectness: 0.0798 (0.1016)  loss_rpn_box_reg: 0.0250 (0.0345)  time: 0.2738  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [17]  [ 610/1229]  eta: 0:02:50  lr: 0.000005  loss: 0.3625 (0.4374)  loss_classifier: 0.1373 (0.1560)  loss_box_reg: 0.1278 (0.1456)  loss_objectness: 0.0922 (0.1017)  loss_rpn_box_reg: 0.0184 (0.0342)  time: 0.2767  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [17]  [ 620/1229]  eta: 0:02:47  lr: 0.000005  loss: 0.4573 (0.4383)  loss_classifier: 0.1560 (0.1562)  loss_box_reg: 0.1196 (0.1458)  loss_objectness: 0.1169 (0.1020)  loss_rpn_box_reg: 0.0213 (0.0343)  time: 0.2741  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [17]  [ 630/1229]  eta: 0:02:44  lr: 0.000005  loss: 0.4051 (0.4372)  loss_classifier: 0.1357 (0.1559)  loss_box_reg: 0.1129 (0.1452)  loss_objectness: 0.1108 (0.1019)  loss_rpn_box_reg: 0.0239 (0.0342)  time: 0.2758  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [17]  [ 640/1229]  eta: 0:02:41  lr: 0.000005  loss: 0.3491 (0.4378)  loss_classifier: 0.1246 (0.1560)  loss_box_reg: 0.1093 (0.1454)  loss_objectness: 0.0814 (0.1021)  loss_rpn_box_reg: 0.0233 (0.0343)  time: 0.2754  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [17]  [ 650/1229]  eta: 0:02:39  lr: 0.000005  loss: 0.4139 (0.4377)  loss_classifier: 0.1460 (0.1559)  loss_box_reg: 0.1004 (0.1455)  loss_objectness: 0.0845 (0.1021)  loss_rpn_box_reg: 0.0181 (0.0341)  time: 0.2787  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [17]  [ 660/1229]  eta: 0:02:36  lr: 0.000005  loss: 0.3578 (0.4359)  loss_classifier: 0.1337 (0.1554)  loss_box_reg: 0.1047 (0.1451)  loss_objectness: 0.0691 (0.1015)  loss_rpn_box_reg: 0.0167 (0.0340)  time: 0.2771  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [17]  [ 670/1229]  eta: 0:02:33  lr: 0.000005  loss: 0.2582 (0.4347)  loss_classifier: 0.0947 (0.1548)  loss_box_reg: 0.0997 (0.1444)  loss_objectness: 0.0636 (0.1014)  loss_rpn_box_reg: 0.0163 (0.0341)  time: 0.2756  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [17]  [ 680/1229]  eta: 0:02:30  lr: 0.000005  loss: 0.3042 (0.4340)  loss_classifier: 0.1051 (0.1545)  loss_box_reg: 0.0845 (0.1438)  loss_objectness: 0.1094 (0.1016)  loss_rpn_box_reg: 0.0155 (0.0342)  time: 0.2761  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [17]  [ 690/1229]  eta: 0:02:28  lr: 0.000005  loss: 0.3542 (0.4332)  loss_classifier: 0.1348 (0.1542)  loss_box_reg: 0.0852 (0.1436)  loss_objectness: 0.1074 (0.1015)  loss_rpn_box_reg: 0.0165 (0.0339)  time: 0.2726  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [17]  [ 700/1229]  eta: 0:02:25  lr: 0.000005  loss: 0.4815 (0.4356)  loss_classifier: 0.1688 (0.1550)  loss_box_reg: 0.1621 (0.1448)  loss_objectness: 0.0982 (0.1017)  loss_rpn_box_reg: 0.0215 (0.0341)  time: 0.2740  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [17]  [ 710/1229]  eta: 0:02:22  lr: 0.000005  loss: 0.4829 (0.4349)  loss_classifier: 0.1730 (0.1548)  loss_box_reg: 0.1472 (0.1446)  loss_objectness: 0.0812 (0.1015)  loss_rpn_box_reg: 0.0218 (0.0340)  time: 0.2699  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [17]  [ 720/1229]  eta: 0:02:19  lr: 0.000005  loss: 0.3477 (0.4340)  loss_classifier: 0.1422 (0.1546)  loss_box_reg: 0.1174 (0.1444)  loss_objectness: 0.0678 (0.1011)  loss_rpn_box_reg: 0.0196 (0.0339)  time: 0.2736  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [17]  [ 730/1229]  eta: 0:02:17  lr: 0.000005  loss: 0.3619 (0.4350)  loss_classifier: 0.1422 (0.1548)  loss_box_reg: 0.1174 (0.1451)  loss_objectness: 0.0791 (0.1011)  loss_rpn_box_reg: 0.0269 (0.0339)  time: 0.2760  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [17]  [ 740/1229]  eta: 0:02:14  lr: 0.000005  loss: 0.4072 (0.4343)  loss_classifier: 0.1356 (0.1544)  loss_box_reg: 0.1140 (0.1448)  loss_objectness: 0.0810 (0.1011)  loss_rpn_box_reg: 0.0241 (0.0339)  time: 0.2722  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [17]  [ 750/1229]  eta: 0:02:11  lr: 0.000005  loss: 0.3689 (0.4331)  loss_classifier: 0.0977 (0.1540)  loss_box_reg: 0.0855 (0.1444)  loss_objectness: 0.0731 (0.1010)  loss_rpn_box_reg: 0.0145 (0.0337)  time: 0.2725  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [17]  [ 760/1229]  eta: 0:02:08  lr: 0.000005  loss: 0.3404 (0.4333)  loss_classifier: 0.1242 (0.1541)  loss_box_reg: 0.0867 (0.1445)  loss_objectness: 0.0788 (0.1010)  loss_rpn_box_reg: 0.0143 (0.0337)  time: 0.2700  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [17]  [ 770/1229]  eta: 0:02:06  lr: 0.000005  loss: 0.4237 (0.4341)  loss_classifier: 0.1602 (0.1545)  loss_box_reg: 0.1431 (0.1446)  loss_objectness: 0.0875 (0.1012)  loss_rpn_box_reg: 0.0247 (0.0337)  time: 0.2719  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [17]  [ 780/1229]  eta: 0:02:03  lr: 0.000005  loss: 0.4283 (0.4343)  loss_classifier: 0.1591 (0.1547)  loss_box_reg: 0.1224 (0.1448)  loss_objectness: 0.0870 (0.1011)  loss_rpn_box_reg: 0.0249 (0.0337)  time: 0.2736  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [17]  [ 790/1229]  eta: 0:02:00  lr: 0.000005  loss: 0.2928 (0.4321)  loss_classifier: 0.1222 (0.1539)  loss_box_reg: 0.0771 (0.1438)  loss_objectness: 0.0525 (0.1008)  loss_rpn_box_reg: 0.0131 (0.0336)  time: 0.2698  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [17]  [ 800/1229]  eta: 0:01:57  lr: 0.000005  loss: 0.2827 (0.4310)  loss_classifier: 0.0980 (0.1536)  loss_box_reg: 0.0719 (0.1434)  loss_objectness: 0.0670 (0.1007)  loss_rpn_box_reg: 0.0091 (0.0334)  time: 0.2698  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [17]  [ 810/1229]  eta: 0:01:54  lr: 0.000005  loss: 0.2975 (0.4308)  loss_classifier: 0.1185 (0.1536)  loss_box_reg: 0.0791 (0.1430)  loss_objectness: 0.0705 (0.1009)  loss_rpn_box_reg: 0.0141 (0.0333)  time: 0.2728  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [17]  [ 820/1229]  eta: 0:01:52  lr: 0.000005  loss: 0.3890 (0.4312)  loss_classifier: 0.1427 (0.1538)  loss_box_reg: 0.1205 (0.1432)  loss_objectness: 0.0705 (0.1009)  loss_rpn_box_reg: 0.0296 (0.0333)  time: 0.2776  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [17]  [ 830/1229]  eta: 0:01:49  lr: 0.000005  loss: 0.4061 (0.4306)  loss_classifier: 0.1427 (0.1536)  loss_box_reg: 0.1409 (0.1431)  loss_objectness: 0.0717 (0.1006)  loss_rpn_box_reg: 0.0279 (0.0333)  time: 0.2796  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [17]  [ 840/1229]  eta: 0:01:46  lr: 0.000005  loss: 0.4649 (0.4319)  loss_classifier: 0.1543 (0.1540)  loss_box_reg: 0.1516 (0.1438)  loss_objectness: 0.0717 (0.1006)  loss_rpn_box_reg: 0.0233 (0.0334)  time: 0.2772  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [17]  [ 850/1229]  eta: 0:01:44  lr: 0.000005  loss: 0.4649 (0.4312)  loss_classifier: 0.1532 (0.1539)  loss_box_reg: 0.1164 (0.1434)  loss_objectness: 0.0887 (0.1006)  loss_rpn_box_reg: 0.0264 (0.0333)  time: 0.2736  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [17]  [ 860/1229]  eta: 0:01:41  lr: 0.000005  loss: 0.4280 (0.4320)  loss_classifier: 0.1475 (0.1542)  loss_box_reg: 0.1104 (0.1438)  loss_objectness: 0.0771 (0.1007)  loss_rpn_box_reg: 0.0264 (0.0333)  time: 0.2726  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [17]  [ 870/1229]  eta: 0:01:38  lr: 0.000005  loss: 0.4878 (0.4324)  loss_classifier: 0.1538 (0.1543)  loss_box_reg: 0.1437 (0.1440)  loss_objectness: 0.0885 (0.1008)  loss_rpn_box_reg: 0.0224 (0.0333)  time: 0.2756  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [17]  [ 880/1229]  eta: 0:01:35  lr: 0.000005  loss: 0.3217 (0.4319)  loss_classifier: 0.1279 (0.1541)  loss_box_reg: 0.1322 (0.1439)  loss_objectness: 0.0700 (0.1005)  loss_rpn_box_reg: 0.0211 (0.0334)  time: 0.2770  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [17]  [ 890/1229]  eta: 0:01:33  lr: 0.000005  loss: 0.3024 (0.4313)  loss_classifier: 0.1200 (0.1539)  loss_box_reg: 0.1149 (0.1438)  loss_objectness: 0.0700 (0.1004)  loss_rpn_box_reg: 0.0166 (0.0332)  time: 0.2778  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [17]  [ 900/1229]  eta: 0:01:30  lr: 0.000005  loss: 0.2717 (0.4316)  loss_classifier: 0.1155 (0.1537)  loss_box_reg: 0.0969 (0.1438)  loss_objectness: 0.1016 (0.1005)  loss_rpn_box_reg: 0.0166 (0.0336)  time: 0.2774  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [17]  [ 910/1229]  eta: 0:01:27  lr: 0.000005  loss: 0.2673 (0.4317)  loss_classifier: 0.1102 (0.1537)  loss_box_reg: 0.0912 (0.1441)  loss_objectness: 0.0831 (0.1003)  loss_rpn_box_reg: 0.0223 (0.0336)  time: 0.2759  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [17]  [ 920/1229]  eta: 0:01:24  lr: 0.000005  loss: 0.3242 (0.4310)  loss_classifier: 0.1157 (0.1534)  loss_box_reg: 0.1030 (0.1437)  loss_objectness: 0.0757 (0.1004)  loss_rpn_box_reg: 0.0222 (0.0336)  time: 0.2781  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [17]  [ 930/1229]  eta: 0:01:22  lr: 0.000005  loss: 0.3362 (0.4304)  loss_classifier: 0.1157 (0.1532)  loss_box_reg: 0.0932 (0.1435)  loss_objectness: 0.0757 (0.1002)  loss_rpn_box_reg: 0.0153 (0.0335)  time: 0.2763  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [17]  [ 940/1229]  eta: 0:01:19  lr: 0.000005  loss: 0.3317 (0.4294)  loss_classifier: 0.1056 (0.1528)  loss_box_reg: 0.0895 (0.1431)  loss_objectness: 0.0716 (0.1001)  loss_rpn_box_reg: 0.0141 (0.0333)  time: 0.2742  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [17]  [ 950/1229]  eta: 0:01:16  lr: 0.000005  loss: 0.3492 (0.4297)  loss_classifier: 0.1299 (0.1530)  loss_box_reg: 0.1159 (0.1433)  loss_objectness: 0.0716 (0.1001)  loss_rpn_box_reg: 0.0197 (0.0333)  time: 0.2776  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [17]  [ 960/1229]  eta: 0:01:13  lr: 0.000005  loss: 0.4546 (0.4306)  loss_classifier: 0.1693 (0.1533)  loss_box_reg: 0.1727 (0.1436)  loss_objectness: 0.0742 (0.1002)  loss_rpn_box_reg: 0.0239 (0.0335)  time: 0.2799  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [17]  [ 970/1229]  eta: 0:01:11  lr: 0.000005  loss: 0.3787 (0.4310)  loss_classifier: 0.1576 (0.1533)  loss_box_reg: 0.1306 (0.1439)  loss_objectness: 0.0892 (0.1002)  loss_rpn_box_reg: 0.0177 (0.0336)  time: 0.2753  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [17]  [ 980/1229]  eta: 0:01:08  lr: 0.000005  loss: 0.3787 (0.4320)  loss_classifier: 0.1361 (0.1537)  loss_box_reg: 0.1364 (0.1442)  loss_objectness: 0.0875 (0.1003)  loss_rpn_box_reg: 0.0188 (0.0338)  time: 0.2801  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [17]  [ 990/1229]  eta: 0:01:05  lr: 0.000005  loss: 0.4273 (0.4323)  loss_classifier: 0.1324 (0.1539)  loss_box_reg: 0.1415 (0.1445)  loss_objectness: 0.0912 (0.1003)  loss_rpn_box_reg: 0.0259 (0.0337)  time: 0.2813  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [17]  [1000/1229]  eta: 0:01:02  lr: 0.000005  loss: 0.4161 (0.4330)  loss_classifier: 0.1726 (0.1541)  loss_box_reg: 0.1171 (0.1447)  loss_objectness: 0.0944 (0.1004)  loss_rpn_box_reg: 0.0235 (0.0338)  time: 0.2699  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [17]  [1010/1229]  eta: 0:01:00  lr: 0.000005  loss: 0.4159 (0.4332)  loss_classifier: 0.1257 (0.1541)  loss_box_reg: 0.1318 (0.1447)  loss_objectness: 0.1002 (0.1005)  loss_rpn_box_reg: 0.0235 (0.0340)  time: 0.2688  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [17]  [1020/1229]  eta: 0:00:57  lr: 0.000005  loss: 0.4151 (0.4336)  loss_classifier: 0.1339 (0.1542)  loss_box_reg: 0.1373 (0.1449)  loss_objectness: 0.0990 (0.1006)  loss_rpn_box_reg: 0.0236 (0.0339)  time: 0.2712  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [17]  [1030/1229]  eta: 0:00:54  lr: 0.000005  loss: 0.4151 (0.4339)  loss_classifier: 0.1659 (0.1544)  loss_box_reg: 0.1632 (0.1453)  loss_objectness: 0.0786 (0.1004)  loss_rpn_box_reg: 0.0163 (0.0338)  time: 0.2693  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [17]  [1040/1229]  eta: 0:00:51  lr: 0.000005  loss: 0.4392 (0.4341)  loss_classifier: 0.1516 (0.1544)  loss_box_reg: 0.1276 (0.1453)  loss_objectness: 0.0749 (0.1005)  loss_rpn_box_reg: 0.0329 (0.0339)  time: 0.2628  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [17]  [1050/1229]  eta: 0:00:49  lr: 0.000005  loss: 0.3567 (0.4338)  loss_classifier: 0.1289 (0.1543)  loss_box_reg: 0.1163 (0.1450)  loss_objectness: 0.0714 (0.1004)  loss_rpn_box_reg: 0.0352 (0.0341)  time: 0.2737  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [17]  [1060/1229]  eta: 0:00:46  lr: 0.000005  loss: 0.3791 (0.4352)  loss_classifier: 0.1339 (0.1548)  loss_box_reg: 0.1238 (0.1455)  loss_objectness: 0.0731 (0.1006)  loss_rpn_box_reg: 0.0308 (0.0343)  time: 0.2824  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [17]  [1070/1229]  eta: 0:00:43  lr: 0.000005  loss: 0.3729 (0.4347)  loss_classifier: 0.1411 (0.1547)  loss_box_reg: 0.1381 (0.1451)  loss_objectness: 0.0943 (0.1006)  loss_rpn_box_reg: 0.0308 (0.0343)  time: 0.2775  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [17]  [1080/1229]  eta: 0:00:40  lr: 0.000005  loss: 0.3729 (0.4344)  loss_classifier: 0.1411 (0.1546)  loss_box_reg: 0.0999 (0.1450)  loss_objectness: 0.0943 (0.1006)  loss_rpn_box_reg: 0.0159 (0.0342)  time: 0.2711  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [17]  [1090/1229]  eta: 0:00:38  lr: 0.000005  loss: 0.4183 (0.4341)  loss_classifier: 0.1223 (0.1543)  loss_box_reg: 0.0949 (0.1447)  loss_objectness: 0.0943 (0.1007)  loss_rpn_box_reg: 0.0199 (0.0343)  time: 0.2672  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [17]  [1100/1229]  eta: 0:00:35  lr: 0.000005  loss: 0.3322 (0.4331)  loss_classifier: 0.1148 (0.1541)  loss_box_reg: 0.0880 (0.1443)  loss_objectness: 0.0827 (0.1006)  loss_rpn_box_reg: 0.0195 (0.0342)  time: 0.2754  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [17]  [1110/1229]  eta: 0:00:32  lr: 0.000005  loss: 0.3841 (0.4346)  loss_classifier: 0.1465 (0.1547)  loss_box_reg: 0.1100 (0.1452)  loss_objectness: 0.0814 (0.1006)  loss_rpn_box_reg: 0.0183 (0.0341)  time: 0.2779  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [17]  [1120/1229]  eta: 0:00:29  lr: 0.000005  loss: 0.3814 (0.4337)  loss_classifier: 0.1465 (0.1544)  loss_box_reg: 0.1100 (0.1448)  loss_objectness: 0.0805 (0.1005)  loss_rpn_box_reg: 0.0226 (0.0341)  time: 0.2786  data: 0.1372  max mem: 1751\n",
      "Training Epoch: [17]  [1130/1229]  eta: 0:00:27  lr: 0.000005  loss: 0.2948 (0.4328)  loss_classifier: 0.1069 (0.1540)  loss_box_reg: 0.0781 (0.1445)  loss_objectness: 0.0801 (0.1003)  loss_rpn_box_reg: 0.0151 (0.0340)  time: 0.2697  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [17]  [1140/1229]  eta: 0:00:24  lr: 0.000005  loss: 0.3007 (0.4322)  loss_classifier: 0.0922 (0.1537)  loss_box_reg: 0.1068 (0.1443)  loss_objectness: 0.0801 (0.1001)  loss_rpn_box_reg: 0.0128 (0.0340)  time: 0.2671  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [17]  [1150/1229]  eta: 0:00:21  lr: 0.000005  loss: 0.3007 (0.4317)  loss_classifier: 0.1094 (0.1536)  loss_box_reg: 0.0959 (0.1440)  loss_objectness: 0.0881 (0.1001)  loss_rpn_box_reg: 0.0128 (0.0340)  time: 0.2727  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [17]  [1160/1229]  eta: 0:00:18  lr: 0.000005  loss: 0.4255 (0.4320)  loss_classifier: 0.1505 (0.1537)  loss_box_reg: 0.0982 (0.1441)  loss_objectness: 0.0902 (0.1003)  loss_rpn_box_reg: 0.0271 (0.0340)  time: 0.2721  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [17]  [1170/1229]  eta: 0:00:16  lr: 0.000005  loss: 0.4279 (0.4319)  loss_classifier: 0.1505 (0.1536)  loss_box_reg: 0.1244 (0.1441)  loss_objectness: 0.0939 (0.1002)  loss_rpn_box_reg: 0.0271 (0.0340)  time: 0.2769  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [17]  [1180/1229]  eta: 0:00:13  lr: 0.000005  loss: 0.3648 (0.4318)  loss_classifier: 0.1375 (0.1535)  loss_box_reg: 0.1398 (0.1443)  loss_objectness: 0.0815 (0.1000)  loss_rpn_box_reg: 0.0301 (0.0339)  time: 0.2760  data: 0.1375  max mem: 1751\n",
      "Training Epoch: [17]  [1190/1229]  eta: 0:00:10  lr: 0.000005  loss: 0.3948 (0.4319)  loss_classifier: 0.1432 (0.1535)  loss_box_reg: 0.1398 (0.1442)  loss_objectness: 0.0883 (0.1002)  loss_rpn_box_reg: 0.0221 (0.0339)  time: 0.2769  data: 0.1393  max mem: 1751\n",
      "Training Epoch: [17]  [1200/1229]  eta: 0:00:07  lr: 0.000005  loss: 0.3914 (0.4314)  loss_classifier: 0.1456 (0.1534)  loss_box_reg: 0.1381 (0.1442)  loss_objectness: 0.0874 (0.1000)  loss_rpn_box_reg: 0.0183 (0.0338)  time: 0.2741  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [17]  [1210/1229]  eta: 0:00:05  lr: 0.000005  loss: 0.4289 (0.4320)  loss_classifier: 0.1456 (0.1536)  loss_box_reg: 0.1398 (0.1444)  loss_objectness: 0.0852 (0.1002)  loss_rpn_box_reg: 0.0162 (0.0338)  time: 0.2682  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [17]  [1220/1229]  eta: 0:00:02  lr: 0.000005  loss: 0.4766 (0.4327)  loss_classifier: 0.1576 (0.1537)  loss_box_reg: 0.1398 (0.1445)  loss_objectness: 0.1253 (0.1006)  loss_rpn_box_reg: 0.0261 (0.0339)  time: 0.2702  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [17]  [1228/1229]  eta: 0:00:00  lr: 0.000005  loss: 0.4289 (0.4324)  loss_classifier: 0.1371 (0.1536)  loss_box_reg: 0.1122 (0.1444)  loss_objectness: 0.1102 (0.1005)  loss_rpn_box_reg: 0.0313 (0.0339)  time: 0.2755  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [17] Total time: 0:05:37 (0.2746 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:18  model_time: 0.2200 (0.2200)  evaluator_time: 0.0020 (0.0020)  time: 0.2550  data: 0.0300  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0780 (0.0814)  evaluator_time: 0.0050 (0.0086)  time: 0.1333  data: 0.0425  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0830 (0.0804)  evaluator_time: 0.0030 (0.0078)  time: 0.1215  data: 0.0320  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0730 (0.0798)  evaluator_time: 0.0040 (0.0076)  time: 0.1206  data: 0.0365  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0730 (0.0797)  evaluator_time: 0.0030 (0.0076)  time: 0.1177  data: 0.0347  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1252 s / it)\n",
      "Averaged stats: model_time: 0.0730 (0.0797)  evaluator_time: 0.0030 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.347\n",
      "Testing Epoch: [17]  [  0/308]  eta: 0:00:37  lr: 0.000005  loss: 0.1687 (0.1687)  loss_classifier: 0.0588 (0.0588)  loss_box_reg: 0.0686 (0.0686)  loss_objectness: 0.0299 (0.0299)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1230  data: 0.0290  max mem: 1751\n",
      "Testing Epoch: [17]  [100/308]  eta: 0:00:29  lr: 0.000005  loss: 0.3112 (0.4824)  loss_classifier: 0.1335 (0.1550)  loss_box_reg: 0.1175 (0.1724)  loss_objectness: 0.0578 (0.1029)  loss_rpn_box_reg: 0.0186 (0.0522)  time: 0.1410  data: 0.0396  max mem: 1751\n",
      "Testing Epoch: [17]  [200/308]  eta: 0:00:15  lr: 0.000005  loss: 0.3508 (0.4574)  loss_classifier: 0.1385 (0.1492)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0584 (0.0957)  loss_rpn_box_reg: 0.0197 (0.0492)  time: 0.1392  data: 0.0340  max mem: 1751\n",
      "Testing Epoch: [17]  [300/308]  eta: 0:00:01  lr: 0.000005  loss: 0.4790 (0.4541)  loss_classifier: 0.1556 (0.1494)  loss_box_reg: 0.1753 (0.1640)  loss_objectness: 0.0733 (0.0931)  loss_rpn_box_reg: 0.0265 (0.0476)  time: 0.1363  data: 0.0406  max mem: 1751\n",
      "Testing Epoch: [17]  [307/308]  eta: 0:00:00  lr: 0.000005  loss: 0.4512 (0.4543)  loss_classifier: 0.1838 (0.1497)  loss_box_reg: 0.1753 (0.1643)  loss_objectness: 0.0733 (0.0932)  loss_rpn_box_reg: 0.0270 (0.0471)  time: 0.1329  data: 0.0379  max mem: 1751\n",
      "Testing Epoch: [17] Total time: 0:00:42 (0.1386 s / it)\n",
      "Training Epoch: [18]  [   0/1229]  eta: 0:05:23  lr: 0.000005  loss: 0.5441 (0.5441)  loss_classifier: 0.1919 (0.1919)  loss_box_reg: 0.1493 (0.1493)  loss_objectness: 0.1251 (0.1251)  loss_rpn_box_reg: 0.0777 (0.0777)  time: 0.2630  data: 0.1280  max mem: 1751\n",
      "Training Epoch: [18]  [  10/1229]  eta: 0:05:23  lr: 0.000005  loss: 0.4281 (0.4734)  loss_classifier: 0.1285 (0.1526)  loss_box_reg: 0.0925 (0.1350)  loss_objectness: 0.1251 (0.1337)  loss_rpn_box_reg: 0.0255 (0.0521)  time: 0.2654  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [18]  [  20/1229]  eta: 0:05:24  lr: 0.000005  loss: 0.4522 (0.5072)  loss_classifier: 0.1497 (0.1662)  loss_box_reg: 0.1450 (0.1607)  loss_objectness: 0.1213 (0.1275)  loss_rpn_box_reg: 0.0255 (0.0527)  time: 0.2683  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [18]  [  30/1229]  eta: 0:05:24  lr: 0.000005  loss: 0.5362 (0.5264)  loss_classifier: 0.1810 (0.1753)  loss_box_reg: 0.1572 (0.1752)  loss_objectness: 0.1213 (0.1238)  loss_rpn_box_reg: 0.0302 (0.0521)  time: 0.2732  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [18]  [  40/1229]  eta: 0:05:23  lr: 0.000005  loss: 0.3651 (0.4957)  loss_classifier: 0.1142 (0.1631)  loss_box_reg: 0.1020 (0.1636)  loss_objectness: 0.0790 (0.1158)  loss_rpn_box_reg: 0.0345 (0.0532)  time: 0.2767  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [18]  [  50/1229]  eta: 0:05:20  lr: 0.000005  loss: 0.3651 (0.4903)  loss_classifier: 0.1260 (0.1644)  loss_box_reg: 0.1223 (0.1641)  loss_objectness: 0.0738 (0.1133)  loss_rpn_box_reg: 0.0293 (0.0484)  time: 0.2736  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [18]  [  60/1229]  eta: 0:05:18  lr: 0.000005  loss: 0.4404 (0.4832)  loss_classifier: 0.1621 (0.1625)  loss_box_reg: 0.1427 (0.1595)  loss_objectness: 0.0978 (0.1137)  loss_rpn_box_reg: 0.0226 (0.0474)  time: 0.2725  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [18]  [  70/1229]  eta: 0:05:16  lr: 0.000005  loss: 0.3785 (0.4676)  loss_classifier: 0.1390 (0.1599)  loss_box_reg: 0.1067 (0.1534)  loss_objectness: 0.0930 (0.1108)  loss_rpn_box_reg: 0.0205 (0.0435)  time: 0.2763  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [18]  [  80/1229]  eta: 0:05:13  lr: 0.000005  loss: 0.3752 (0.4664)  loss_classifier: 0.1390 (0.1608)  loss_box_reg: 0.1112 (0.1536)  loss_objectness: 0.0930 (0.1089)  loss_rpn_box_reg: 0.0196 (0.0431)  time: 0.2738  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [18]  [  90/1229]  eta: 0:05:10  lr: 0.000005  loss: 0.4733 (0.4788)  loss_classifier: 0.1729 (0.1659)  loss_box_reg: 0.1481 (0.1589)  loss_objectness: 0.0950 (0.1113)  loss_rpn_box_reg: 0.0189 (0.0427)  time: 0.2723  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [18]  [ 100/1229]  eta: 0:05:09  lr: 0.000005  loss: 0.4657 (0.4655)  loss_classifier: 0.1667 (0.1614)  loss_box_reg: 0.1316 (0.1543)  loss_objectness: 0.0844 (0.1100)  loss_rpn_box_reg: 0.0165 (0.0398)  time: 0.2780  data: 0.1383  max mem: 1751\n",
      "Training Epoch: [18]  [ 110/1229]  eta: 0:05:05  lr: 0.000005  loss: 0.4152 (0.4679)  loss_classifier: 0.1404 (0.1625)  loss_box_reg: 0.1146 (0.1549)  loss_objectness: 0.0859 (0.1100)  loss_rpn_box_reg: 0.0165 (0.0405)  time: 0.2757  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [18]  [ 120/1229]  eta: 0:05:02  lr: 0.000005  loss: 0.4168 (0.4658)  loss_classifier: 0.1412 (0.1613)  loss_box_reg: 0.1523 (0.1529)  loss_objectness: 0.0957 (0.1098)  loss_rpn_box_reg: 0.0247 (0.0418)  time: 0.2678  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [18]  [ 130/1229]  eta: 0:05:00  lr: 0.000005  loss: 0.4168 (0.4693)  loss_classifier: 0.1412 (0.1634)  loss_box_reg: 0.1371 (0.1535)  loss_objectness: 0.0969 (0.1113)  loss_rpn_box_reg: 0.0247 (0.0411)  time: 0.2715  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [18]  [ 140/1229]  eta: 0:04:57  lr: 0.000005  loss: 0.3989 (0.4672)  loss_classifier: 0.1434 (0.1630)  loss_box_reg: 0.1373 (0.1536)  loss_objectness: 0.0853 (0.1104)  loss_rpn_box_reg: 0.0250 (0.0402)  time: 0.2763  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [18]  [ 150/1229]  eta: 0:04:54  lr: 0.000005  loss: 0.3687 (0.4717)  loss_classifier: 0.1405 (0.1646)  loss_box_reg: 0.1373 (0.1566)  loss_objectness: 0.0853 (0.1102)  loss_rpn_box_reg: 0.0211 (0.0403)  time: 0.2709  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [18]  [ 160/1229]  eta: 0:04:51  lr: 0.000005  loss: 0.3704 (0.4648)  loss_classifier: 0.1368 (0.1622)  loss_box_reg: 0.1051 (0.1540)  loss_objectness: 0.0848 (0.1086)  loss_rpn_box_reg: 0.0211 (0.0401)  time: 0.2659  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [18]  [ 170/1229]  eta: 0:04:48  lr: 0.000005  loss: 0.3697 (0.4645)  loss_classifier: 0.1368 (0.1624)  loss_box_reg: 0.1051 (0.1539)  loss_objectness: 0.0873 (0.1081)  loss_rpn_box_reg: 0.0236 (0.0401)  time: 0.2676  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [18]  [ 180/1229]  eta: 0:04:44  lr: 0.000005  loss: 0.3697 (0.4615)  loss_classifier: 0.1459 (0.1612)  loss_box_reg: 0.1191 (0.1535)  loss_objectness: 0.0922 (0.1075)  loss_rpn_box_reg: 0.0188 (0.0392)  time: 0.2650  data: 0.1285  max mem: 1751\n",
      "Training Epoch: [18]  [ 190/1229]  eta: 0:04:42  lr: 0.000005  loss: 0.3530 (0.4579)  loss_classifier: 0.1401 (0.1602)  loss_box_reg: 0.1019 (0.1528)  loss_objectness: 0.0753 (0.1067)  loss_rpn_box_reg: 0.0135 (0.0382)  time: 0.2697  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [18]  [ 200/1229]  eta: 0:04:39  lr: 0.000005  loss: 0.2910 (0.4511)  loss_classifier: 0.1163 (0.1581)  loss_box_reg: 0.0921 (0.1494)  loss_objectness: 0.0881 (0.1058)  loss_rpn_box_reg: 0.0104 (0.0380)  time: 0.2724  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [18]  [ 210/1229]  eta: 0:04:36  lr: 0.000005  loss: 0.3426 (0.4492)  loss_classifier: 0.1163 (0.1575)  loss_box_reg: 0.0710 (0.1487)  loss_objectness: 0.0881 (0.1053)  loss_rpn_box_reg: 0.0118 (0.0377)  time: 0.2641  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [18]  [ 220/1229]  eta: 0:04:33  lr: 0.000005  loss: 0.4276 (0.4487)  loss_classifier: 0.1471 (0.1573)  loss_box_reg: 0.1415 (0.1484)  loss_objectness: 0.0982 (0.1054)  loss_rpn_box_reg: 0.0275 (0.0375)  time: 0.2672  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [18]  [ 230/1229]  eta: 0:04:31  lr: 0.000005  loss: 0.4142 (0.4513)  loss_classifier: 0.1298 (0.1586)  loss_box_reg: 0.1443 (0.1492)  loss_objectness: 0.1067 (0.1058)  loss_rpn_box_reg: 0.0275 (0.0378)  time: 0.2736  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [18]  [ 240/1229]  eta: 0:04:28  lr: 0.000005  loss: 0.4016 (0.4514)  loss_classifier: 0.1415 (0.1589)  loss_box_reg: 0.1372 (0.1489)  loss_objectness: 0.0934 (0.1059)  loss_rpn_box_reg: 0.0175 (0.0377)  time: 0.2725  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [18]  [ 250/1229]  eta: 0:04:25  lr: 0.000005  loss: 0.4016 (0.4478)  loss_classifier: 0.1426 (0.1577)  loss_box_reg: 0.1367 (0.1479)  loss_objectness: 0.0880 (0.1052)  loss_rpn_box_reg: 0.0188 (0.0370)  time: 0.2647  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [18]  [ 260/1229]  eta: 0:04:22  lr: 0.000005  loss: 0.3512 (0.4454)  loss_classifier: 0.1244 (0.1569)  loss_box_reg: 0.0815 (0.1469)  loss_objectness: 0.0837 (0.1047)  loss_rpn_box_reg: 0.0240 (0.0368)  time: 0.2651  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [18]  [ 270/1229]  eta: 0:04:19  lr: 0.000005  loss: 0.4116 (0.4464)  loss_classifier: 0.1259 (0.1571)  loss_box_reg: 0.1024 (0.1474)  loss_objectness: 0.0857 (0.1049)  loss_rpn_box_reg: 0.0244 (0.0369)  time: 0.2707  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [18]  [ 280/1229]  eta: 0:04:17  lr: 0.000005  loss: 0.4649 (0.4480)  loss_classifier: 0.1545 (0.1579)  loss_box_reg: 0.1484 (0.1486)  loss_objectness: 0.0917 (0.1049)  loss_rpn_box_reg: 0.0249 (0.0366)  time: 0.2711  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [18]  [ 290/1229]  eta: 0:04:14  lr: 0.000005  loss: 0.3434 (0.4421)  loss_classifier: 0.1300 (0.1563)  loss_box_reg: 0.1055 (0.1463)  loss_objectness: 0.0828 (0.1038)  loss_rpn_box_reg: 0.0149 (0.0357)  time: 0.2696  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [18]  [ 300/1229]  eta: 0:04:11  lr: 0.000005  loss: 0.3102 (0.4393)  loss_classifier: 0.1127 (0.1550)  loss_box_reg: 0.0967 (0.1449)  loss_objectness: 0.0793 (0.1039)  loss_rpn_box_reg: 0.0130 (0.0355)  time: 0.2683  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [18]  [ 310/1229]  eta: 0:04:08  lr: 0.000005  loss: 0.3102 (0.4372)  loss_classifier: 0.1127 (0.1544)  loss_box_reg: 0.0967 (0.1435)  loss_objectness: 0.0793 (0.1034)  loss_rpn_box_reg: 0.0189 (0.0359)  time: 0.2671  data: 0.1287  max mem: 1751\n",
      "Training Epoch: [18]  [ 320/1229]  eta: 0:04:06  lr: 0.000005  loss: 0.3156 (0.4360)  loss_classifier: 0.1368 (0.1543)  loss_box_reg: 0.0794 (0.1422)  loss_objectness: 0.1067 (0.1040)  loss_rpn_box_reg: 0.0190 (0.0354)  time: 0.2712  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [18]  [ 330/1229]  eta: 0:04:03  lr: 0.000005  loss: 0.3395 (0.4356)  loss_classifier: 0.1368 (0.1542)  loss_box_reg: 0.0815 (0.1428)  loss_objectness: 0.0946 (0.1034)  loss_rpn_box_reg: 0.0206 (0.0351)  time: 0.2800  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [18]  [ 340/1229]  eta: 0:04:00  lr: 0.000005  loss: 0.4005 (0.4355)  loss_classifier: 0.1451 (0.1545)  loss_box_reg: 0.1238 (0.1428)  loss_objectness: 0.0900 (0.1033)  loss_rpn_box_reg: 0.0229 (0.0349)  time: 0.2741  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [18]  [ 350/1229]  eta: 0:03:57  lr: 0.000005  loss: 0.3952 (0.4348)  loss_classifier: 0.1389 (0.1543)  loss_box_reg: 0.1333 (0.1427)  loss_objectness: 0.0901 (0.1032)  loss_rpn_box_reg: 0.0218 (0.0346)  time: 0.2651  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [18]  [ 360/1229]  eta: 0:03:55  lr: 0.000005  loss: 0.3580 (0.4341)  loss_classifier: 0.1378 (0.1543)  loss_box_reg: 0.1248 (0.1427)  loss_objectness: 0.0805 (0.1029)  loss_rpn_box_reg: 0.0180 (0.0343)  time: 0.2667  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [18]  [ 370/1229]  eta: 0:03:52  lr: 0.000005  loss: 0.3648 (0.4344)  loss_classifier: 0.1382 (0.1541)  loss_box_reg: 0.1248 (0.1427)  loss_objectness: 0.0761 (0.1027)  loss_rpn_box_reg: 0.0186 (0.0349)  time: 0.2726  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [18]  [ 380/1229]  eta: 0:03:49  lr: 0.000005  loss: 0.3648 (0.4350)  loss_classifier: 0.1351 (0.1543)  loss_box_reg: 0.1232 (0.1433)  loss_objectness: 0.0801 (0.1026)  loss_rpn_box_reg: 0.0212 (0.0349)  time: 0.2722  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [18]  [ 390/1229]  eta: 0:03:47  lr: 0.000005  loss: 0.3619 (0.4348)  loss_classifier: 0.1309 (0.1544)  loss_box_reg: 0.1126 (0.1434)  loss_objectness: 0.0829 (0.1023)  loss_rpn_box_reg: 0.0217 (0.0347)  time: 0.2665  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [18]  [ 400/1229]  eta: 0:03:44  lr: 0.000005  loss: 0.4093 (0.4392)  loss_classifier: 0.1422 (0.1561)  loss_box_reg: 0.1691 (0.1447)  loss_objectness: 0.1018 (0.1029)  loss_rpn_box_reg: 0.0185 (0.0355)  time: 0.2715  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [18]  [ 410/1229]  eta: 0:03:41  lr: 0.000005  loss: 0.4023 (0.4380)  loss_classifier: 0.1382 (0.1558)  loss_box_reg: 0.1272 (0.1443)  loss_objectness: 0.0922 (0.1025)  loss_rpn_box_reg: 0.0185 (0.0353)  time: 0.2733  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [18]  [ 420/1229]  eta: 0:03:39  lr: 0.000005  loss: 0.4023 (0.4400)  loss_classifier: 0.1382 (0.1566)  loss_box_reg: 0.1271 (0.1457)  loss_objectness: 0.0860 (0.1026)  loss_rpn_box_reg: 0.0196 (0.0352)  time: 0.2731  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [18]  [ 430/1229]  eta: 0:03:36  lr: 0.000005  loss: 0.4185 (0.4400)  loss_classifier: 0.1638 (0.1566)  loss_box_reg: 0.1342 (0.1462)  loss_objectness: 0.0852 (0.1022)  loss_rpn_box_reg: 0.0237 (0.0351)  time: 0.2766  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [18]  [ 440/1229]  eta: 0:03:33  lr: 0.000005  loss: 0.3936 (0.4384)  loss_classifier: 0.1388 (0.1559)  loss_box_reg: 0.1328 (0.1460)  loss_objectness: 0.0743 (0.1016)  loss_rpn_box_reg: 0.0207 (0.0348)  time: 0.2701  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [18]  [ 450/1229]  eta: 0:03:31  lr: 0.000005  loss: 0.3202 (0.4365)  loss_classifier: 0.1299 (0.1555)  loss_box_reg: 0.0932 (0.1453)  loss_objectness: 0.0707 (0.1013)  loss_rpn_box_reg: 0.0191 (0.0344)  time: 0.2707  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [18]  [ 460/1229]  eta: 0:03:28  lr: 0.000005  loss: 0.3449 (0.4363)  loss_classifier: 0.1348 (0.1557)  loss_box_reg: 0.1045 (0.1453)  loss_objectness: 0.0707 (0.1009)  loss_rpn_box_reg: 0.0207 (0.0344)  time: 0.2743  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [18]  [ 470/1229]  eta: 0:03:25  lr: 0.000005  loss: 0.3810 (0.4382)  loss_classifier: 0.1548 (0.1562)  loss_box_reg: 0.1305 (0.1460)  loss_objectness: 0.0788 (0.1016)  loss_rpn_box_reg: 0.0332 (0.0344)  time: 0.2695  data: 0.1298  max mem: 1751\n",
      "Training Epoch: [18]  [ 480/1229]  eta: 0:03:23  lr: 0.000005  loss: 0.4184 (0.4390)  loss_classifier: 0.1587 (0.1564)  loss_box_reg: 0.1777 (0.1463)  loss_objectness: 0.1084 (0.1014)  loss_rpn_box_reg: 0.0357 (0.0349)  time: 0.2706  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [18]  [ 490/1229]  eta: 0:03:20  lr: 0.000005  loss: 0.4022 (0.4393)  loss_classifier: 0.1548 (0.1567)  loss_box_reg: 0.1221 (0.1460)  loss_objectness: 0.0980 (0.1018)  loss_rpn_box_reg: 0.0238 (0.0347)  time: 0.2753  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [18]  [ 500/1229]  eta: 0:03:17  lr: 0.000005  loss: 0.3644 (0.4395)  loss_classifier: 0.1522 (0.1567)  loss_box_reg: 0.1409 (0.1466)  loss_objectness: 0.0922 (0.1017)  loss_rpn_box_reg: 0.0194 (0.0345)  time: 0.2712  data: 0.1367  max mem: 1751\n",
      "Training Epoch: [18]  [ 510/1229]  eta: 0:03:14  lr: 0.000005  loss: 0.3555 (0.4381)  loss_classifier: 0.1244 (0.1562)  loss_box_reg: 0.1449 (0.1461)  loss_objectness: 0.0896 (0.1014)  loss_rpn_box_reg: 0.0193 (0.0345)  time: 0.2725  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [18]  [ 520/1229]  eta: 0:03:12  lr: 0.000005  loss: 0.3555 (0.4400)  loss_classifier: 0.1406 (0.1571)  loss_box_reg: 0.1368 (0.1470)  loss_objectness: 0.0819 (0.1015)  loss_rpn_box_reg: 0.0206 (0.0344)  time: 0.2767  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [18]  [ 530/1229]  eta: 0:03:10  lr: 0.000005  loss: 0.4360 (0.4404)  loss_classifier: 0.1726 (0.1572)  loss_box_reg: 0.1592 (0.1473)  loss_objectness: 0.0988 (0.1014)  loss_rpn_box_reg: 0.0241 (0.0345)  time: 0.2955  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [18]  [ 540/1229]  eta: 0:03:07  lr: 0.000005  loss: 0.4360 (0.4413)  loss_classifier: 0.1666 (0.1573)  loss_box_reg: 0.1586 (0.1475)  loss_objectness: 0.0858 (0.1014)  loss_rpn_box_reg: 0.0299 (0.0350)  time: 0.3061  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [18]  [ 550/1229]  eta: 0:03:05  lr: 0.000005  loss: 0.3672 (0.4404)  loss_classifier: 0.1343 (0.1570)  loss_box_reg: 0.1412 (0.1476)  loss_objectness: 0.0823 (0.1010)  loss_rpn_box_reg: 0.0234 (0.0349)  time: 0.2829  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [18]  [ 560/1229]  eta: 0:03:02  lr: 0.000005  loss: 0.3672 (0.4399)  loss_classifier: 0.1256 (0.1568)  loss_box_reg: 0.1240 (0.1475)  loss_objectness: 0.0885 (0.1010)  loss_rpn_box_reg: 0.0188 (0.0346)  time: 0.2706  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [18]  [ 570/1229]  eta: 0:02:59  lr: 0.000005  loss: 0.4005 (0.4410)  loss_classifier: 0.1442 (0.1571)  loss_box_reg: 0.1426 (0.1479)  loss_objectness: 0.0913 (0.1014)  loss_rpn_box_reg: 0.0217 (0.0346)  time: 0.2716  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [18]  [ 580/1229]  eta: 0:02:56  lr: 0.000005  loss: 0.4113 (0.4405)  loss_classifier: 0.1567 (0.1571)  loss_box_reg: 0.1687 (0.1480)  loss_objectness: 0.0864 (0.1011)  loss_rpn_box_reg: 0.0225 (0.0344)  time: 0.2742  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [18]  [ 590/1229]  eta: 0:02:54  lr: 0.000005  loss: 0.3959 (0.4405)  loss_classifier: 0.1567 (0.1570)  loss_box_reg: 0.1346 (0.1476)  loss_objectness: 0.0944 (0.1013)  loss_rpn_box_reg: 0.0225 (0.0346)  time: 0.2768  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [18]  [ 600/1229]  eta: 0:02:51  lr: 0.000005  loss: 0.5012 (0.4417)  loss_classifier: 0.1733 (0.1575)  loss_box_reg: 0.1613 (0.1482)  loss_objectness: 0.1027 (0.1015)  loss_rpn_box_reg: 0.0193 (0.0344)  time: 0.2745  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [18]  [ 610/1229]  eta: 0:02:48  lr: 0.000005  loss: 0.5012 (0.4431)  loss_classifier: 0.2034 (0.1581)  loss_box_reg: 0.1691 (0.1493)  loss_objectness: 0.0900 (0.1014)  loss_rpn_box_reg: 0.0202 (0.0342)  time: 0.2732  data: 0.1375  max mem: 1751\n",
      "Training Epoch: [18]  [ 620/1229]  eta: 0:02:46  lr: 0.000005  loss: 0.3495 (0.4422)  loss_classifier: 0.1274 (0.1578)  loss_box_reg: 0.1519 (0.1491)  loss_objectness: 0.0657 (0.1011)  loss_rpn_box_reg: 0.0209 (0.0342)  time: 0.2764  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [18]  [ 630/1229]  eta: 0:02:43  lr: 0.000005  loss: 0.3241 (0.4421)  loss_classifier: 0.1138 (0.1579)  loss_box_reg: 0.1054 (0.1493)  loss_objectness: 0.0657 (0.1007)  loss_rpn_box_reg: 0.0221 (0.0342)  time: 0.2808  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [18]  [ 640/1229]  eta: 0:02:40  lr: 0.000005  loss: 0.4744 (0.4430)  loss_classifier: 0.1852 (0.1582)  loss_box_reg: 0.1658 (0.1501)  loss_objectness: 0.0830 (0.1006)  loss_rpn_box_reg: 0.0221 (0.0341)  time: 0.2784  data: 0.1368  max mem: 1751\n",
      "Training Epoch: [18]  [ 650/1229]  eta: 0:02:38  lr: 0.000005  loss: 0.3771 (0.4413)  loss_classifier: 0.1405 (0.1577)  loss_box_reg: 0.1389 (0.1493)  loss_objectness: 0.0864 (0.1003)  loss_rpn_box_reg: 0.0164 (0.0339)  time: 0.2849  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [18]  [ 660/1229]  eta: 0:02:35  lr: 0.000005  loss: 0.2929 (0.4406)  loss_classifier: 0.1139 (0.1576)  loss_box_reg: 0.0938 (0.1490)  loss_objectness: 0.0864 (0.1004)  loss_rpn_box_reg: 0.0124 (0.0337)  time: 0.2873  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [18]  [ 670/1229]  eta: 0:02:32  lr: 0.000005  loss: 0.3296 (0.4397)  loss_classifier: 0.1139 (0.1571)  loss_box_reg: 0.1193 (0.1488)  loss_objectness: 0.0755 (0.1001)  loss_rpn_box_reg: 0.0146 (0.0338)  time: 0.2794  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [18]  [ 680/1229]  eta: 0:02:30  lr: 0.000005  loss: 0.3715 (0.4401)  loss_classifier: 0.1254 (0.1573)  loss_box_reg: 0.1383 (0.1491)  loss_objectness: 0.0831 (0.1001)  loss_rpn_box_reg: 0.0150 (0.0336)  time: 0.2806  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [18]  [ 690/1229]  eta: 0:02:27  lr: 0.000005  loss: 0.4154 (0.4402)  loss_classifier: 0.1497 (0.1574)  loss_box_reg: 0.1204 (0.1488)  loss_objectness: 0.0942 (0.1005)  loss_rpn_box_reg: 0.0193 (0.0335)  time: 0.2792  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [18]  [ 700/1229]  eta: 0:02:24  lr: 0.000005  loss: 0.3993 (0.4399)  loss_classifier: 0.1394 (0.1572)  loss_box_reg: 0.1050 (0.1485)  loss_objectness: 0.0965 (0.1007)  loss_rpn_box_reg: 0.0200 (0.0335)  time: 0.2814  data: 0.1372  max mem: 1751\n",
      "Training Epoch: [18]  [ 710/1229]  eta: 0:02:22  lr: 0.000005  loss: 0.4579 (0.4410)  loss_classifier: 0.1509 (0.1577)  loss_box_reg: 0.1050 (0.1493)  loss_objectness: 0.0789 (0.1006)  loss_rpn_box_reg: 0.0228 (0.0334)  time: 0.2759  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [18]  [ 720/1229]  eta: 0:02:19  lr: 0.000005  loss: 0.4996 (0.4412)  loss_classifier: 0.1722 (0.1578)  loss_box_reg: 0.1652 (0.1495)  loss_objectness: 0.0844 (0.1007)  loss_rpn_box_reg: 0.0219 (0.0333)  time: 0.2779  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [18]  [ 730/1229]  eta: 0:02:16  lr: 0.000005  loss: 0.3961 (0.4410)  loss_classifier: 0.1342 (0.1577)  loss_box_reg: 0.1211 (0.1492)  loss_objectness: 0.0854 (0.1006)  loss_rpn_box_reg: 0.0212 (0.0334)  time: 0.2825  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [18]  [ 740/1229]  eta: 0:02:14  lr: 0.000005  loss: 0.3817 (0.4400)  loss_classifier: 0.1147 (0.1574)  loss_box_reg: 0.1190 (0.1487)  loss_objectness: 0.0830 (0.1005)  loss_rpn_box_reg: 0.0124 (0.0333)  time: 0.2793  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [18]  [ 750/1229]  eta: 0:02:11  lr: 0.000005  loss: 0.3817 (0.4392)  loss_classifier: 0.1406 (0.1572)  loss_box_reg: 0.1183 (0.1485)  loss_objectness: 0.0811 (0.1005)  loss_rpn_box_reg: 0.0120 (0.0331)  time: 0.2801  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [18]  [ 760/1229]  eta: 0:02:08  lr: 0.000005  loss: 0.3672 (0.4400)  loss_classifier: 0.1274 (0.1572)  loss_box_reg: 0.1183 (0.1491)  loss_objectness: 0.0803 (0.1004)  loss_rpn_box_reg: 0.0123 (0.0332)  time: 0.2782  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [18]  [ 770/1229]  eta: 0:02:05  lr: 0.000005  loss: 0.3354 (0.4394)  loss_classifier: 0.1172 (0.1570)  loss_box_reg: 0.1181 (0.1486)  loss_objectness: 0.0932 (0.1004)  loss_rpn_box_reg: 0.0222 (0.0334)  time: 0.2772  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [18]  [ 780/1229]  eta: 0:02:03  lr: 0.000005  loss: 0.3014 (0.4387)  loss_classifier: 0.0992 (0.1567)  loss_box_reg: 0.0983 (0.1486)  loss_objectness: 0.0922 (0.1002)  loss_rpn_box_reg: 0.0160 (0.0332)  time: 0.2685  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [18]  [ 790/1229]  eta: 0:02:00  lr: 0.000005  loss: 0.3252 (0.4390)  loss_classifier: 0.1078 (0.1566)  loss_box_reg: 0.1021 (0.1488)  loss_objectness: 0.0912 (0.1002)  loss_rpn_box_reg: 0.0237 (0.0335)  time: 0.2619  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [18]  [ 800/1229]  eta: 0:01:57  lr: 0.000005  loss: 0.4377 (0.4397)  loss_classifier: 0.1263 (0.1565)  loss_box_reg: 0.1287 (0.1490)  loss_objectness: 0.0912 (0.1002)  loss_rpn_box_reg: 0.0371 (0.0340)  time: 0.2674  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [18]  [ 810/1229]  eta: 0:01:54  lr: 0.000005  loss: 0.3850 (0.4383)  loss_classifier: 0.1208 (0.1561)  loss_box_reg: 0.1122 (0.1485)  loss_objectness: 0.0784 (0.0999)  loss_rpn_box_reg: 0.0169 (0.0339)  time: 0.2738  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [18]  [ 820/1229]  eta: 0:01:51  lr: 0.000005  loss: 0.2659 (0.4375)  loss_classifier: 0.1113 (0.1557)  loss_box_reg: 0.0904 (0.1481)  loss_objectness: 0.0784 (0.0999)  loss_rpn_box_reg: 0.0132 (0.0338)  time: 0.2695  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [18]  [ 830/1229]  eta: 0:01:49  lr: 0.000005  loss: 0.3281 (0.4375)  loss_classifier: 0.1172 (0.1557)  loss_box_reg: 0.1193 (0.1482)  loss_objectness: 0.0770 (0.0999)  loss_rpn_box_reg: 0.0165 (0.0337)  time: 0.2722  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [18]  [ 840/1229]  eta: 0:01:46  lr: 0.000005  loss: 0.4379 (0.4382)  loss_classifier: 0.1567 (0.1559)  loss_box_reg: 0.1193 (0.1484)  loss_objectness: 0.0953 (0.1001)  loss_rpn_box_reg: 0.0266 (0.0338)  time: 0.2766  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [18]  [ 850/1229]  eta: 0:01:43  lr: 0.000005  loss: 0.4379 (0.4392)  loss_classifier: 0.1567 (0.1564)  loss_box_reg: 0.1511 (0.1488)  loss_objectness: 0.0953 (0.1003)  loss_rpn_box_reg: 0.0301 (0.0338)  time: 0.2708  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [18]  [ 860/1229]  eta: 0:01:41  lr: 0.000005  loss: 0.3343 (0.4382)  loss_classifier: 0.1252 (0.1559)  loss_box_reg: 0.0973 (0.1484)  loss_objectness: 0.0767 (0.1001)  loss_rpn_box_reg: 0.0255 (0.0338)  time: 0.2765  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [18]  [ 870/1229]  eta: 0:01:38  lr: 0.000005  loss: 0.3940 (0.4390)  loss_classifier: 0.1271 (0.1562)  loss_box_reg: 0.1317 (0.1488)  loss_objectness: 0.0758 (0.1001)  loss_rpn_box_reg: 0.0181 (0.0338)  time: 0.2797  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [18]  [ 880/1229]  eta: 0:01:35  lr: 0.000005  loss: 0.3940 (0.4378)  loss_classifier: 0.1315 (0.1559)  loss_box_reg: 0.1317 (0.1482)  loss_objectness: 0.0886 (0.1000)  loss_rpn_box_reg: 0.0193 (0.0337)  time: 0.2734  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [18]  [ 890/1229]  eta: 0:01:32  lr: 0.000005  loss: 0.2825 (0.4370)  loss_classifier: 0.0939 (0.1555)  loss_box_reg: 0.0807 (0.1477)  loss_objectness: 0.0671 (0.0999)  loss_rpn_box_reg: 0.0199 (0.0339)  time: 0.2740  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [18]  [ 900/1229]  eta: 0:01:30  lr: 0.000005  loss: 0.3368 (0.4366)  loss_classifier: 0.1182 (0.1553)  loss_box_reg: 0.1135 (0.1478)  loss_objectness: 0.0712 (0.0997)  loss_rpn_box_reg: 0.0210 (0.0339)  time: 0.2712  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [18]  [ 910/1229]  eta: 0:01:27  lr: 0.000005  loss: 0.4336 (0.4370)  loss_classifier: 0.1411 (0.1555)  loss_box_reg: 0.1522 (0.1481)  loss_objectness: 0.0757 (0.0996)  loss_rpn_box_reg: 0.0190 (0.0338)  time: 0.2686  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [18]  [ 920/1229]  eta: 0:01:24  lr: 0.000005  loss: 0.4570 (0.4376)  loss_classifier: 0.1510 (0.1557)  loss_box_reg: 0.1334 (0.1487)  loss_objectness: 0.0749 (0.0995)  loss_rpn_box_reg: 0.0184 (0.0337)  time: 0.2769  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [18]  [ 930/1229]  eta: 0:01:21  lr: 0.000005  loss: 0.3946 (0.4370)  loss_classifier: 0.1453 (0.1556)  loss_box_reg: 0.1321 (0.1486)  loss_objectness: 0.0565 (0.0992)  loss_rpn_box_reg: 0.0184 (0.0336)  time: 0.2839  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [18]  [ 940/1229]  eta: 0:01:19  lr: 0.000005  loss: 0.3286 (0.4364)  loss_classifier: 0.1191 (0.1554)  loss_box_reg: 0.1159 (0.1483)  loss_objectness: 0.0610 (0.0992)  loss_rpn_box_reg: 0.0205 (0.0335)  time: 0.2826  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [18]  [ 950/1229]  eta: 0:01:16  lr: 0.000005  loss: 0.2900 (0.4354)  loss_classifier: 0.1177 (0.1551)  loss_box_reg: 0.0919 (0.1479)  loss_objectness: 0.0663 (0.0991)  loss_rpn_box_reg: 0.0168 (0.0333)  time: 0.2721  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [18]  [ 960/1229]  eta: 0:01:13  lr: 0.000005  loss: 0.2994 (0.4348)  loss_classifier: 0.1129 (0.1547)  loss_box_reg: 0.0978 (0.1476)  loss_objectness: 0.0843 (0.0991)  loss_rpn_box_reg: 0.0210 (0.0334)  time: 0.2701  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [18]  [ 970/1229]  eta: 0:01:10  lr: 0.000005  loss: 0.3480 (0.4347)  loss_classifier: 0.1129 (0.1547)  loss_box_reg: 0.1009 (0.1475)  loss_objectness: 0.0905 (0.0990)  loss_rpn_box_reg: 0.0211 (0.0335)  time: 0.2791  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [18]  [ 980/1229]  eta: 0:01:08  lr: 0.000005  loss: 0.3128 (0.4338)  loss_classifier: 0.1185 (0.1544)  loss_box_reg: 0.0936 (0.1470)  loss_objectness: 0.0835 (0.0990)  loss_rpn_box_reg: 0.0177 (0.0334)  time: 0.2776  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [18]  [ 990/1229]  eta: 0:01:05  lr: 0.000005  loss: 0.2942 (0.4327)  loss_classifier: 0.1143 (0.1541)  loss_box_reg: 0.0914 (0.1466)  loss_objectness: 0.0712 (0.0988)  loss_rpn_box_reg: 0.0133 (0.0333)  time: 0.2744  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [18]  [1000/1229]  eta: 0:01:02  lr: 0.000005  loss: 0.3921 (0.4336)  loss_classifier: 0.1539 (0.1543)  loss_box_reg: 0.1246 (0.1469)  loss_objectness: 0.0836 (0.0991)  loss_rpn_box_reg: 0.0233 (0.0333)  time: 0.2708  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [18]  [1010/1229]  eta: 0:01:00  lr: 0.000005  loss: 0.4027 (0.4337)  loss_classifier: 0.1559 (0.1543)  loss_box_reg: 0.1383 (0.1469)  loss_objectness: 0.0904 (0.0990)  loss_rpn_box_reg: 0.0249 (0.0334)  time: 0.2707  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [18]  [1020/1229]  eta: 0:00:57  lr: 0.000005  loss: 0.3949 (0.4344)  loss_classifier: 0.1342 (0.1546)  loss_box_reg: 0.1301 (0.1473)  loss_objectness: 0.0854 (0.0991)  loss_rpn_box_reg: 0.0163 (0.0334)  time: 0.2743  data: 0.1296  max mem: 1751\n",
      "Training Epoch: [18]  [1030/1229]  eta: 0:00:54  lr: 0.000005  loss: 0.3958 (0.4340)  loss_classifier: 0.1293 (0.1544)  loss_box_reg: 0.1221 (0.1470)  loss_objectness: 0.0916 (0.0991)  loss_rpn_box_reg: 0.0195 (0.0334)  time: 0.2737  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [18]  [1040/1229]  eta: 0:00:51  lr: 0.000005  loss: 0.3596 (0.4346)  loss_classifier: 0.1241 (0.1546)  loss_box_reg: 0.1088 (0.1474)  loss_objectness: 0.0916 (0.0992)  loss_rpn_box_reg: 0.0214 (0.0334)  time: 0.2714  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [18]  [1050/1229]  eta: 0:00:49  lr: 0.000005  loss: 0.3803 (0.4352)  loss_classifier: 0.1385 (0.1549)  loss_box_reg: 0.1407 (0.1476)  loss_objectness: 0.0932 (0.0994)  loss_rpn_box_reg: 0.0222 (0.0334)  time: 0.2718  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [18]  [1060/1229]  eta: 0:00:46  lr: 0.000005  loss: 0.3803 (0.4347)  loss_classifier: 0.1310 (0.1546)  loss_box_reg: 0.1281 (0.1471)  loss_objectness: 0.1094 (0.0996)  loss_rpn_box_reg: 0.0188 (0.0334)  time: 0.2714  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [18]  [1070/1229]  eta: 0:00:43  lr: 0.000005  loss: 0.3689 (0.4342)  loss_classifier: 0.1328 (0.1545)  loss_box_reg: 0.1066 (0.1468)  loss_objectness: 0.0941 (0.0995)  loss_rpn_box_reg: 0.0147 (0.0333)  time: 0.2684  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [18]  [1080/1229]  eta: 0:00:40  lr: 0.000005  loss: 0.3570 (0.4343)  loss_classifier: 0.1472 (0.1546)  loss_box_reg: 0.1086 (0.1469)  loss_objectness: 0.0941 (0.0996)  loss_rpn_box_reg: 0.0130 (0.0333)  time: 0.2714  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [18]  [1090/1229]  eta: 0:00:38  lr: 0.000005  loss: 0.3239 (0.4334)  loss_classifier: 0.1124 (0.1542)  loss_box_reg: 0.0792 (0.1463)  loss_objectness: 0.0987 (0.0996)  loss_rpn_box_reg: 0.0197 (0.0332)  time: 0.2711  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [18]  [1100/1229]  eta: 0:00:35  lr: 0.000005  loss: 0.3160 (0.4332)  loss_classifier: 0.0978 (0.1541)  loss_box_reg: 0.0789 (0.1464)  loss_objectness: 0.0656 (0.0995)  loss_rpn_box_reg: 0.0202 (0.0331)  time: 0.2696  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [18]  [1110/1229]  eta: 0:00:32  lr: 0.000005  loss: 0.4558 (0.4345)  loss_classifier: 0.1427 (0.1545)  loss_box_reg: 0.1530 (0.1471)  loss_objectness: 0.0732 (0.0997)  loss_rpn_box_reg: 0.0265 (0.0331)  time: 0.2704  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [18]  [1120/1229]  eta: 0:00:29  lr: 0.000005  loss: 0.4699 (0.4355)  loss_classifier: 0.1427 (0.1549)  loss_box_reg: 0.1530 (0.1475)  loss_objectness: 0.0996 (0.0998)  loss_rpn_box_reg: 0.0265 (0.0333)  time: 0.2731  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [18]  [1130/1229]  eta: 0:00:27  lr: 0.000005  loss: 0.4360 (0.4357)  loss_classifier: 0.1410 (0.1548)  loss_box_reg: 0.1214 (0.1475)  loss_objectness: 0.0909 (0.1000)  loss_rpn_box_reg: 0.0211 (0.0333)  time: 0.2728  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [18]  [1140/1229]  eta: 0:00:24  lr: 0.000005  loss: 0.4213 (0.4358)  loss_classifier: 0.1381 (0.1548)  loss_box_reg: 0.1214 (0.1475)  loss_objectness: 0.0760 (0.1002)  loss_rpn_box_reg: 0.0198 (0.0333)  time: 0.2732  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [18]  [1150/1229]  eta: 0:00:21  lr: 0.000005  loss: 0.3801 (0.4362)  loss_classifier: 0.1381 (0.1549)  loss_box_reg: 0.1108 (0.1476)  loss_objectness: 0.0876 (0.1003)  loss_rpn_box_reg: 0.0224 (0.0334)  time: 0.2731  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [18]  [1160/1229]  eta: 0:00:18  lr: 0.000005  loss: 0.3420 (0.4357)  loss_classifier: 0.1394 (0.1547)  loss_box_reg: 0.1187 (0.1476)  loss_objectness: 0.0805 (0.1000)  loss_rpn_box_reg: 0.0178 (0.0334)  time: 0.2714  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [18]  [1170/1229]  eta: 0:00:16  lr: 0.000005  loss: 0.4366 (0.4363)  loss_classifier: 0.1394 (0.1548)  loss_box_reg: 0.1354 (0.1476)  loss_objectness: 0.0788 (0.1002)  loss_rpn_box_reg: 0.0323 (0.0336)  time: 0.2955  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [18]  [1180/1229]  eta: 0:00:13  lr: 0.000005  loss: 0.4439 (0.4369)  loss_classifier: 0.1755 (0.1550)  loss_box_reg: 0.1436 (0.1479)  loss_objectness: 0.1126 (0.1003)  loss_rpn_box_reg: 0.0412 (0.0338)  time: 0.2902  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [18]  [1190/1229]  eta: 0:00:10  lr: 0.000005  loss: 0.4389 (0.4368)  loss_classifier: 0.1494 (0.1549)  loss_box_reg: 0.1436 (0.1479)  loss_objectness: 0.0948 (0.1002)  loss_rpn_box_reg: 0.0345 (0.0339)  time: 0.2726  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [18]  [1200/1229]  eta: 0:00:07  lr: 0.000005  loss: 0.3643 (0.4360)  loss_classifier: 0.1205 (0.1546)  loss_box_reg: 0.0800 (0.1473)  loss_objectness: 0.0745 (0.1001)  loss_rpn_box_reg: 0.0236 (0.0339)  time: 0.2825  data: 0.1401  max mem: 1751\n",
      "Training Epoch: [18]  [1210/1229]  eta: 0:00:05  lr: 0.000005  loss: 0.3652 (0.4361)  loss_classifier: 0.1360 (0.1547)  loss_box_reg: 0.0800 (0.1474)  loss_objectness: 0.0849 (0.1001)  loss_rpn_box_reg: 0.0234 (0.0339)  time: 0.2856  data: 0.1401  max mem: 1751\n",
      "Training Epoch: [18]  [1220/1229]  eta: 0:00:02  lr: 0.000005  loss: 0.4201 (0.4364)  loss_classifier: 0.1646 (0.1548)  loss_box_reg: 0.1362 (0.1474)  loss_objectness: 0.0908 (0.1001)  loss_rpn_box_reg: 0.0265 (0.0341)  time: 0.2835  data: 0.1375  max mem: 1751\n",
      "Training Epoch: [18]  [1228/1229]  eta: 0:00:00  lr: 0.000005  loss: 0.4421 (0.4361)  loss_classifier: 0.1464 (0.1547)  loss_box_reg: 0.1052 (0.1471)  loss_objectness: 0.0931 (0.1002)  loss_rpn_box_reg: 0.0290 (0.0341)  time: 0.2800  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [18] Total time: 0:05:37 (0.2744 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:28  model_time: 0.2550 (0.2550)  evaluator_time: 0.0010 (0.0010)  time: 0.2870  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0790 (0.0825)  evaluator_time: 0.0040 (0.0085)  time: 0.1276  data: 0.0361  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0850 (0.0819)  evaluator_time: 0.0030 (0.0078)  time: 0.1220  data: 0.0309  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0740 (0.0812)  evaluator_time: 0.0040 (0.0076)  time: 0.1207  data: 0.0355  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0740 (0.0811)  evaluator_time: 0.0030 (0.0076)  time: 0.1177  data: 0.0339  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1251 s / it)\n",
      "Averaged stats: model_time: 0.0740 (0.0811)  evaluator_time: 0.0030 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [18]  [  0/308]  eta: 0:00:37  lr: 0.000005  loss: 0.1783 (0.1783)  loss_classifier: 0.0588 (0.0588)  loss_box_reg: 0.0686 (0.0686)  loss_objectness: 0.0394 (0.0394)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1230  data: 0.0270  max mem: 1751\n",
      "Testing Epoch: [18]  [100/308]  eta: 0:00:29  lr: 0.000005  loss: 0.3181 (0.4803)  loss_classifier: 0.1355 (0.1545)  loss_box_reg: 0.1175 (0.1722)  loss_objectness: 0.0600 (0.1018)  loss_rpn_box_reg: 0.0186 (0.0519)  time: 0.1391  data: 0.0374  max mem: 1751\n",
      "Testing Epoch: [18]  [200/308]  eta: 0:00:15  lr: 0.000005  loss: 0.3576 (0.4563)  loss_classifier: 0.1388 (0.1490)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0573 (0.0950)  loss_rpn_box_reg: 0.0197 (0.0491)  time: 0.1383  data: 0.0324  max mem: 1751\n",
      "Testing Epoch: [18]  [300/308]  eta: 0:00:01  lr: 0.000005  loss: 0.4622 (0.4535)  loss_classifier: 0.1604 (0.1493)  loss_box_reg: 0.1750 (0.1641)  loss_objectness: 0.0768 (0.0926)  loss_rpn_box_reg: 0.0265 (0.0475)  time: 0.1332  data: 0.0369  max mem: 1751\n",
      "Testing Epoch: [18]  [307/308]  eta: 0:00:00  lr: 0.000005  loss: 0.4572 (0.4536)  loss_classifier: 0.1843 (0.1495)  loss_box_reg: 0.1750 (0.1643)  loss_objectness: 0.0689 (0.0927)  loss_rpn_box_reg: 0.0270 (0.0470)  time: 0.1306  data: 0.0353  max mem: 1751\n",
      "Testing Epoch: [18] Total time: 0:00:42 (0.1379 s / it)\n",
      "Training Epoch: [19]  [   0/1229]  eta: 0:05:08  lr: 0.000005  loss: 0.3610 (0.3610)  loss_classifier: 0.1353 (0.1353)  loss_box_reg: 0.1124 (0.1124)  loss_objectness: 0.0955 (0.0955)  loss_rpn_box_reg: 0.0179 (0.0179)  time: 0.2510  data: 0.1220  max mem: 1751\n",
      "Training Epoch: [19]  [  10/1229]  eta: 0:05:27  lr: 0.000005  loss: 0.3610 (0.4741)  loss_classifier: 0.1353 (0.1674)  loss_box_reg: 0.1233 (0.1714)  loss_objectness: 0.0902 (0.1031)  loss_rpn_box_reg: 0.0240 (0.0323)  time: 0.2688  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [19]  [  20/1229]  eta: 0:05:27  lr: 0.000005  loss: 0.3563 (0.4576)  loss_classifier: 0.1307 (0.1580)  loss_box_reg: 0.1257 (0.1665)  loss_objectness: 0.0735 (0.0995)  loss_rpn_box_reg: 0.0211 (0.0336)  time: 0.2714  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [19]  [  30/1229]  eta: 0:05:26  lr: 0.000005  loss: 0.3563 (0.4455)  loss_classifier: 0.1329 (0.1542)  loss_box_reg: 0.1298 (0.1647)  loss_objectness: 0.0672 (0.0957)  loss_rpn_box_reg: 0.0180 (0.0310)  time: 0.2742  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [19]  [  40/1229]  eta: 0:05:21  lr: 0.000005  loss: 0.3172 (0.4230)  loss_classifier: 0.1277 (0.1485)  loss_box_reg: 0.1126 (0.1504)  loss_objectness: 0.0657 (0.0952)  loss_rpn_box_reg: 0.0215 (0.0289)  time: 0.2710  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [19]  [  50/1229]  eta: 0:05:20  lr: 0.000005  loss: 0.3077 (0.4254)  loss_classifier: 0.1277 (0.1505)  loss_box_reg: 0.1126 (0.1509)  loss_objectness: 0.0691 (0.0931)  loss_rpn_box_reg: 0.0223 (0.0309)  time: 0.2703  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [19]  [  60/1229]  eta: 0:05:18  lr: 0.000005  loss: 0.4087 (0.4322)  loss_classifier: 0.1591 (0.1538)  loss_box_reg: 0.1455 (0.1510)  loss_objectness: 0.0867 (0.0977)  loss_rpn_box_reg: 0.0217 (0.0298)  time: 0.2767  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [19]  [  70/1229]  eta: 0:05:13  lr: 0.000005  loss: 0.3885 (0.4284)  loss_classifier: 0.1599 (0.1527)  loss_box_reg: 0.1159 (0.1469)  loss_objectness: 0.0955 (0.0998)  loss_rpn_box_reg: 0.0217 (0.0290)  time: 0.2690  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [19]  [  80/1229]  eta: 0:05:12  lr: 0.000005  loss: 0.3561 (0.4337)  loss_classifier: 0.1277 (0.1540)  loss_box_reg: 0.1174 (0.1468)  loss_objectness: 0.0955 (0.1008)  loss_rpn_box_reg: 0.0222 (0.0321)  time: 0.2683  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [19]  [  90/1229]  eta: 0:05:09  lr: 0.000005  loss: 0.3871 (0.4404)  loss_classifier: 0.1549 (0.1568)  loss_box_reg: 0.1298 (0.1482)  loss_objectness: 0.1118 (0.1033)  loss_rpn_box_reg: 0.0250 (0.0320)  time: 0.2750  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [19]  [ 100/1229]  eta: 0:05:08  lr: 0.000005  loss: 0.3955 (0.4402)  loss_classifier: 0.1501 (0.1573)  loss_box_reg: 0.1357 (0.1483)  loss_objectness: 0.0920 (0.1023)  loss_rpn_box_reg: 0.0165 (0.0322)  time: 0.2788  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [19]  [ 110/1229]  eta: 0:05:05  lr: 0.000005  loss: 0.2961 (0.4297)  loss_classifier: 0.1379 (0.1528)  loss_box_reg: 0.0928 (0.1446)  loss_objectness: 0.0776 (0.1008)  loss_rpn_box_reg: 0.0190 (0.0316)  time: 0.2767  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [19]  [ 120/1229]  eta: 0:05:03  lr: 0.000005  loss: 0.3239 (0.4336)  loss_classifier: 0.1125 (0.1532)  loss_box_reg: 0.0943 (0.1461)  loss_objectness: 0.0874 (0.1020)  loss_rpn_box_reg: 0.0202 (0.0323)  time: 0.2753  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [19]  [ 130/1229]  eta: 0:04:59  lr: 0.000005  loss: 0.3840 (0.4284)  loss_classifier: 0.1346 (0.1514)  loss_box_reg: 0.1262 (0.1452)  loss_objectness: 0.0859 (0.1006)  loss_rpn_box_reg: 0.0189 (0.0313)  time: 0.2740  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [19]  [ 140/1229]  eta: 0:04:56  lr: 0.000005  loss: 0.3840 (0.4278)  loss_classifier: 0.1304 (0.1506)  loss_box_reg: 0.1102 (0.1447)  loss_objectness: 0.0859 (0.1002)  loss_rpn_box_reg: 0.0166 (0.0323)  time: 0.2683  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [19]  [ 150/1229]  eta: 0:04:54  lr: 0.000005  loss: 0.4029 (0.4268)  loss_classifier: 0.1555 (0.1506)  loss_box_reg: 0.1158 (0.1442)  loss_objectness: 0.1012 (0.1002)  loss_rpn_box_reg: 0.0149 (0.0317)  time: 0.2706  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [19]  [ 160/1229]  eta: 0:04:51  lr: 0.000005  loss: 0.4350 (0.4296)  loss_classifier: 0.1584 (0.1519)  loss_box_reg: 0.1158 (0.1439)  loss_objectness: 0.0975 (0.1013)  loss_rpn_box_reg: 0.0198 (0.0324)  time: 0.2763  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [19]  [ 170/1229]  eta: 0:04:48  lr: 0.000005  loss: 0.4350 (0.4306)  loss_classifier: 0.1517 (0.1520)  loss_box_reg: 0.1292 (0.1436)  loss_objectness: 0.0933 (0.1014)  loss_rpn_box_reg: 0.0282 (0.0334)  time: 0.2701  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [19]  [ 180/1229]  eta: 0:04:46  lr: 0.000005  loss: 0.5204 (0.4406)  loss_classifier: 0.1715 (0.1554)  loss_box_reg: 0.1449 (0.1478)  loss_objectness: 0.0996 (0.1032)  loss_rpn_box_reg: 0.0345 (0.0342)  time: 0.2699  data: 0.1303  max mem: 1751\n",
      "Training Epoch: [19]  [ 190/1229]  eta: 0:04:44  lr: 0.000005  loss: 0.5182 (0.4382)  loss_classifier: 0.1715 (0.1556)  loss_box_reg: 0.1254 (0.1458)  loss_objectness: 0.0951 (0.1027)  loss_rpn_box_reg: 0.0347 (0.0341)  time: 0.2830  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [19]  [ 200/1229]  eta: 0:04:41  lr: 0.000005  loss: 0.3441 (0.4343)  loss_classifier: 0.1241 (0.1548)  loss_box_reg: 0.0887 (0.1436)  loss_objectness: 0.0798 (0.1022)  loss_rpn_box_reg: 0.0208 (0.0336)  time: 0.2767  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [19]  [ 210/1229]  eta: 0:04:38  lr: 0.000005  loss: 0.3357 (0.4309)  loss_classifier: 0.1177 (0.1528)  loss_box_reg: 0.0997 (0.1423)  loss_objectness: 0.0768 (0.1016)  loss_rpn_box_reg: 0.0181 (0.0342)  time: 0.2700  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [19]  [ 220/1229]  eta: 0:04:35  lr: 0.000005  loss: 0.3419 (0.4296)  loss_classifier: 0.1204 (0.1524)  loss_box_reg: 0.1050 (0.1420)  loss_objectness: 0.0768 (0.1012)  loss_rpn_box_reg: 0.0174 (0.0340)  time: 0.2674  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [19]  [ 230/1229]  eta: 0:04:32  lr: 0.000005  loss: 0.3419 (0.4259)  loss_classifier: 0.1225 (0.1515)  loss_box_reg: 0.1050 (0.1409)  loss_objectness: 0.0765 (0.1002)  loss_rpn_box_reg: 0.0137 (0.0333)  time: 0.2686  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [19]  [ 240/1229]  eta: 0:04:29  lr: 0.000005  loss: 0.2883 (0.4230)  loss_classifier: 0.1270 (0.1507)  loss_box_reg: 0.1077 (0.1403)  loss_objectness: 0.0718 (0.0994)  loss_rpn_box_reg: 0.0140 (0.0326)  time: 0.2746  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [19]  [ 250/1229]  eta: 0:04:27  lr: 0.000005  loss: 0.3380 (0.4243)  loss_classifier: 0.1283 (0.1510)  loss_box_reg: 0.1320 (0.1417)  loss_objectness: 0.0757 (0.0992)  loss_rpn_box_reg: 0.0188 (0.0325)  time: 0.2768  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [19]  [ 260/1229]  eta: 0:04:26  lr: 0.000005  loss: 0.4963 (0.4275)  loss_classifier: 0.1702 (0.1521)  loss_box_reg: 0.1355 (0.1426)  loss_objectness: 0.0758 (0.0996)  loss_rpn_box_reg: 0.0271 (0.0332)  time: 0.2983  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [19]  [ 270/1229]  eta: 0:04:23  lr: 0.000005  loss: 0.4578 (0.4270)  loss_classifier: 0.1418 (0.1519)  loss_box_reg: 0.1251 (0.1424)  loss_objectness: 0.0846 (0.0997)  loss_rpn_box_reg: 0.0260 (0.0330)  time: 0.2992  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [19]  [ 280/1229]  eta: 0:04:20  lr: 0.000005  loss: 0.3790 (0.4316)  loss_classifier: 0.1285 (0.1533)  loss_box_reg: 0.0810 (0.1439)  loss_objectness: 0.0983 (0.1005)  loss_rpn_box_reg: 0.0260 (0.0339)  time: 0.2756  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [19]  [ 290/1229]  eta: 0:04:17  lr: 0.000005  loss: 0.4202 (0.4324)  loss_classifier: 0.1406 (0.1538)  loss_box_reg: 0.1608 (0.1451)  loss_objectness: 0.0692 (0.0995)  loss_rpn_box_reg: 0.0321 (0.0340)  time: 0.2716  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [19]  [ 300/1229]  eta: 0:04:15  lr: 0.000005  loss: 0.4010 (0.4314)  loss_classifier: 0.1378 (0.1537)  loss_box_reg: 0.1381 (0.1447)  loss_objectness: 0.0666 (0.0992)  loss_rpn_box_reg: 0.0261 (0.0337)  time: 0.2814  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [19]  [ 310/1229]  eta: 0:04:13  lr: 0.000005  loss: 0.3608 (0.4313)  loss_classifier: 0.1335 (0.1535)  loss_box_reg: 0.1130 (0.1453)  loss_objectness: 0.0724 (0.0989)  loss_rpn_box_reg: 0.0133 (0.0337)  time: 0.2904  data: 0.1405  max mem: 1751\n",
      "Training Epoch: [19]  [ 320/1229]  eta: 0:04:10  lr: 0.000005  loss: 0.4392 (0.4338)  loss_classifier: 0.1444 (0.1545)  loss_box_reg: 0.1602 (0.1462)  loss_objectness: 0.0758 (0.0992)  loss_rpn_box_reg: 0.0190 (0.0340)  time: 0.2793  data: 0.1386  max mem: 1751\n",
      "Training Epoch: [19]  [ 330/1229]  eta: 0:04:07  lr: 0.000005  loss: 0.5079 (0.4349)  loss_classifier: 0.1971 (0.1545)  loss_box_reg: 0.1603 (0.1460)  loss_objectness: 0.1032 (0.0999)  loss_rpn_box_reg: 0.0301 (0.0345)  time: 0.2717  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [19]  [ 340/1229]  eta: 0:04:04  lr: 0.000005  loss: 0.5305 (0.4388)  loss_classifier: 0.1868 (0.1560)  loss_box_reg: 0.1603 (0.1471)  loss_objectness: 0.1113 (0.1010)  loss_rpn_box_reg: 0.0271 (0.0346)  time: 0.2729  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [19]  [ 350/1229]  eta: 0:04:02  lr: 0.000005  loss: 0.4126 (0.4360)  loss_classifier: 0.1588 (0.1549)  loss_box_reg: 0.1497 (0.1463)  loss_objectness: 0.0832 (0.1002)  loss_rpn_box_reg: 0.0196 (0.0346)  time: 0.2788  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [19]  [ 360/1229]  eta: 0:03:59  lr: 0.000005  loss: 0.3557 (0.4339)  loss_classifier: 0.1249 (0.1540)  loss_box_reg: 0.0676 (0.1449)  loss_objectness: 0.0813 (0.1004)  loss_rpn_box_reg: 0.0187 (0.0347)  time: 0.2808  data: 0.1303  max mem: 1751\n",
      "Training Epoch: [19]  [ 370/1229]  eta: 0:03:56  lr: 0.000005  loss: 0.3805 (0.4339)  loss_classifier: 0.1437 (0.1541)  loss_box_reg: 0.0924 (0.1446)  loss_objectness: 0.1019 (0.1009)  loss_rpn_box_reg: 0.0183 (0.0343)  time: 0.2768  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [19]  [ 380/1229]  eta: 0:03:54  lr: 0.000005  loss: 0.3408 (0.4361)  loss_classifier: 0.1249 (0.1545)  loss_box_reg: 0.0939 (0.1460)  loss_objectness: 0.0844 (0.1009)  loss_rpn_box_reg: 0.0183 (0.0348)  time: 0.2833  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [19]  [ 390/1229]  eta: 0:03:51  lr: 0.000005  loss: 0.3408 (0.4342)  loss_classifier: 0.1095 (0.1538)  loss_box_reg: 0.0939 (0.1453)  loss_objectness: 0.0836 (0.1005)  loss_rpn_box_reg: 0.0291 (0.0347)  time: 0.2804  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [19]  [ 400/1229]  eta: 0:03:48  lr: 0.000005  loss: 0.3286 (0.4337)  loss_classifier: 0.1277 (0.1536)  loss_box_reg: 0.1004 (0.1453)  loss_objectness: 0.1003 (0.1003)  loss_rpn_box_reg: 0.0171 (0.0345)  time: 0.2729  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [19]  [ 410/1229]  eta: 0:03:46  lr: 0.000005  loss: 0.3078 (0.4332)  loss_classifier: 0.1143 (0.1533)  loss_box_reg: 0.1056 (0.1449)  loss_objectness: 0.0807 (0.1001)  loss_rpn_box_reg: 0.0158 (0.0349)  time: 0.2769  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [19]  [ 420/1229]  eta: 0:03:43  lr: 0.000005  loss: 0.3143 (0.4332)  loss_classifier: 0.1143 (0.1533)  loss_box_reg: 0.1148 (0.1447)  loss_objectness: 0.0841 (0.1002)  loss_rpn_box_reg: 0.0152 (0.0351)  time: 0.2803  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [19]  [ 430/1229]  eta: 0:03:40  lr: 0.000005  loss: 0.3962 (0.4350)  loss_classifier: 0.1581 (0.1541)  loss_box_reg: 0.1371 (0.1461)  loss_objectness: 0.0917 (0.1001)  loss_rpn_box_reg: 0.0222 (0.0348)  time: 0.2816  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [19]  [ 440/1229]  eta: 0:03:37  lr: 0.000005  loss: 0.4695 (0.4372)  loss_classifier: 0.1626 (0.1547)  loss_box_reg: 0.1544 (0.1472)  loss_objectness: 0.0930 (0.1005)  loss_rpn_box_reg: 0.0267 (0.0347)  time: 0.2759  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [19]  [ 450/1229]  eta: 0:03:35  lr: 0.000005  loss: 0.4353 (0.4381)  loss_classifier: 0.1534 (0.1552)  loss_box_reg: 0.1383 (0.1476)  loss_objectness: 0.1002 (0.1005)  loss_rpn_box_reg: 0.0302 (0.0347)  time: 0.2742  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [19]  [ 460/1229]  eta: 0:03:32  lr: 0.000005  loss: 0.3572 (0.4375)  loss_classifier: 0.1401 (0.1546)  loss_box_reg: 0.1199 (0.1470)  loss_objectness: 0.0999 (0.1006)  loss_rpn_box_reg: 0.0223 (0.0352)  time: 0.2805  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [19]  [ 470/1229]  eta: 0:03:29  lr: 0.000005  loss: 0.2409 (0.4342)  loss_classifier: 0.1031 (0.1536)  loss_box_reg: 0.0718 (0.1456)  loss_objectness: 0.0695 (0.1002)  loss_rpn_box_reg: 0.0144 (0.0348)  time: 0.2822  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [19]  [ 480/1229]  eta: 0:03:27  lr: 0.000005  loss: 0.2436 (0.4341)  loss_classifier: 0.0917 (0.1537)  loss_box_reg: 0.0593 (0.1458)  loss_objectness: 0.0751 (0.1001)  loss_rpn_box_reg: 0.0144 (0.0346)  time: 0.2834  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [19]  [ 490/1229]  eta: 0:03:24  lr: 0.000005  loss: 0.2578 (0.4321)  loss_classifier: 0.1025 (0.1534)  loss_box_reg: 0.0728 (0.1451)  loss_objectness: 0.0845 (0.0995)  loss_rpn_box_reg: 0.0159 (0.0342)  time: 0.2739  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [19]  [ 500/1229]  eta: 0:03:21  lr: 0.000005  loss: 0.2519 (0.4307)  loss_classifier: 0.0958 (0.1528)  loss_box_reg: 0.0765 (0.1445)  loss_objectness: 0.0730 (0.0994)  loss_rpn_box_reg: 0.0178 (0.0340)  time: 0.2659  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [19]  [ 510/1229]  eta: 0:03:18  lr: 0.000005  loss: 0.2620 (0.4295)  loss_classifier: 0.0903 (0.1523)  loss_box_reg: 0.0789 (0.1444)  loss_objectness: 0.0706 (0.0990)  loss_rpn_box_reg: 0.0192 (0.0339)  time: 0.2671  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [19]  [ 520/1229]  eta: 0:03:15  lr: 0.000005  loss: 0.3325 (0.4298)  loss_classifier: 0.1270 (0.1524)  loss_box_reg: 0.1250 (0.1449)  loss_objectness: 0.0706 (0.0988)  loss_rpn_box_reg: 0.0181 (0.0338)  time: 0.2793  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [19]  [ 530/1229]  eta: 0:03:13  lr: 0.000005  loss: 0.3765 (0.4304)  loss_classifier: 0.1460 (0.1527)  loss_box_reg: 0.1102 (0.1449)  loss_objectness: 0.1032 (0.0990)  loss_rpn_box_reg: 0.0180 (0.0338)  time: 0.2813  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [19]  [ 540/1229]  eta: 0:03:10  lr: 0.000005  loss: 0.3728 (0.4318)  loss_classifier: 0.1407 (0.1531)  loss_box_reg: 0.1102 (0.1454)  loss_objectness: 0.0876 (0.0993)  loss_rpn_box_reg: 0.0215 (0.0340)  time: 0.2712  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [19]  [ 550/1229]  eta: 0:03:07  lr: 0.000005  loss: 0.3728 (0.4320)  loss_classifier: 0.1407 (0.1534)  loss_box_reg: 0.1354 (0.1457)  loss_objectness: 0.0868 (0.0991)  loss_rpn_box_reg: 0.0208 (0.0338)  time: 0.2729  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [19]  [ 560/1229]  eta: 0:03:04  lr: 0.000005  loss: 0.3236 (0.4305)  loss_classifier: 0.1219 (0.1528)  loss_box_reg: 0.1245 (0.1451)  loss_objectness: 0.0782 (0.0990)  loss_rpn_box_reg: 0.0190 (0.0337)  time: 0.2724  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [19]  [ 570/1229]  eta: 0:03:01  lr: 0.000005  loss: 0.3398 (0.4310)  loss_classifier: 0.1219 (0.1529)  loss_box_reg: 0.1350 (0.1456)  loss_objectness: 0.0759 (0.0989)  loss_rpn_box_reg: 0.0230 (0.0337)  time: 0.2691  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [19]  [ 580/1229]  eta: 0:02:58  lr: 0.000005  loss: 0.4790 (0.4324)  loss_classifier: 0.1671 (0.1534)  loss_box_reg: 0.1566 (0.1457)  loss_objectness: 0.0815 (0.0991)  loss_rpn_box_reg: 0.0362 (0.0341)  time: 0.2700  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [19]  [ 590/1229]  eta: 0:02:56  lr: 0.000005  loss: 0.5179 (0.4325)  loss_classifier: 0.1576 (0.1532)  loss_box_reg: 0.1528 (0.1455)  loss_objectness: 0.1017 (0.0994)  loss_rpn_box_reg: 0.0398 (0.0344)  time: 0.2703  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [19]  [ 600/1229]  eta: 0:02:53  lr: 0.000005  loss: 0.5179 (0.4334)  loss_classifier: 0.1421 (0.1536)  loss_box_reg: 0.1605 (0.1462)  loss_objectness: 0.0951 (0.0993)  loss_rpn_box_reg: 0.0265 (0.0343)  time: 0.2682  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [19]  [ 610/1229]  eta: 0:02:50  lr: 0.000005  loss: 0.3484 (0.4327)  loss_classifier: 0.1176 (0.1533)  loss_box_reg: 0.1212 (0.1462)  loss_objectness: 0.0733 (0.0990)  loss_rpn_box_reg: 0.0239 (0.0342)  time: 0.2704  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [19]  [ 620/1229]  eta: 0:02:47  lr: 0.000005  loss: 0.2865 (0.4310)  loss_classifier: 0.1086 (0.1528)  loss_box_reg: 0.0952 (0.1454)  loss_objectness: 0.0634 (0.0987)  loss_rpn_box_reg: 0.0201 (0.0341)  time: 0.2734  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [19]  [ 630/1229]  eta: 0:02:44  lr: 0.000005  loss: 0.3331 (0.4304)  loss_classifier: 0.1168 (0.1525)  loss_box_reg: 0.0848 (0.1453)  loss_objectness: 0.0634 (0.0984)  loss_rpn_box_reg: 0.0167 (0.0341)  time: 0.2745  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [19]  [ 640/1229]  eta: 0:02:42  lr: 0.000005  loss: 0.4448 (0.4312)  loss_classifier: 0.1697 (0.1530)  loss_box_reg: 0.1205 (0.1456)  loss_objectness: 0.0799 (0.0987)  loss_rpn_box_reg: 0.0214 (0.0339)  time: 0.2729  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [19]  [ 650/1229]  eta: 0:02:39  lr: 0.000005  loss: 0.4778 (0.4312)  loss_classifier: 0.1697 (0.1529)  loss_box_reg: 0.1466 (0.1459)  loss_objectness: 0.0902 (0.0985)  loss_rpn_box_reg: 0.0271 (0.0338)  time: 0.2798  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [19]  [ 660/1229]  eta: 0:02:36  lr: 0.000005  loss: 0.3685 (0.4302)  loss_classifier: 0.1337 (0.1525)  loss_box_reg: 0.1292 (0.1453)  loss_objectness: 0.0662 (0.0986)  loss_rpn_box_reg: 0.0156 (0.0337)  time: 0.2792  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [19]  [ 670/1229]  eta: 0:02:34  lr: 0.000005  loss: 0.3914 (0.4336)  loss_classifier: 0.1547 (0.1537)  loss_box_reg: 0.1292 (0.1467)  loss_objectness: 0.1132 (0.0992)  loss_rpn_box_reg: 0.0172 (0.0340)  time: 0.2763  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [19]  [ 680/1229]  eta: 0:02:31  lr: 0.000005  loss: 0.4632 (0.4333)  loss_classifier: 0.1647 (0.1537)  loss_box_reg: 0.1283 (0.1465)  loss_objectness: 0.1238 (0.0993)  loss_rpn_box_reg: 0.0240 (0.0339)  time: 0.2774  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [19]  [ 690/1229]  eta: 0:02:28  lr: 0.000005  loss: 0.5096 (0.4363)  loss_classifier: 0.1895 (0.1548)  loss_box_reg: 0.1271 (0.1472)  loss_objectness: 0.1355 (0.1004)  loss_rpn_box_reg: 0.0257 (0.0339)  time: 0.2723  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [19]  [ 700/1229]  eta: 0:02:25  lr: 0.000005  loss: 0.4280 (0.4346)  loss_classifier: 0.1514 (0.1542)  loss_box_reg: 0.1232 (0.1464)  loss_objectness: 0.1208 (0.1000)  loss_rpn_box_reg: 0.0260 (0.0339)  time: 0.2684  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [19]  [ 710/1229]  eta: 0:02:22  lr: 0.000005  loss: 0.3717 (0.4345)  loss_classifier: 0.1133 (0.1541)  loss_box_reg: 0.0891 (0.1464)  loss_objectness: 0.0793 (0.1000)  loss_rpn_box_reg: 0.0255 (0.0340)  time: 0.2693  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [19]  [ 720/1229]  eta: 0:02:20  lr: 0.000005  loss: 0.3727 (0.4335)  loss_classifier: 0.1191 (0.1539)  loss_box_reg: 0.0990 (0.1458)  loss_objectness: 0.0912 (0.0999)  loss_rpn_box_reg: 0.0239 (0.0339)  time: 0.2746  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [19]  [ 730/1229]  eta: 0:02:17  lr: 0.000005  loss: 0.3828 (0.4338)  loss_classifier: 0.1477 (0.1540)  loss_box_reg: 0.1095 (0.1460)  loss_objectness: 0.0876 (0.0998)  loss_rpn_box_reg: 0.0239 (0.0340)  time: 0.2745  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [19]  [ 740/1229]  eta: 0:02:14  lr: 0.000005  loss: 0.3971 (0.4330)  loss_classifier: 0.1428 (0.1537)  loss_box_reg: 0.1152 (0.1457)  loss_objectness: 0.0729 (0.0996)  loss_rpn_box_reg: 0.0194 (0.0339)  time: 0.2713  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [19]  [ 750/1229]  eta: 0:02:11  lr: 0.000005  loss: 0.3982 (0.4319)  loss_classifier: 0.1428 (0.1535)  loss_box_reg: 0.0922 (0.1452)  loss_objectness: 0.0729 (0.0995)  loss_rpn_box_reg: 0.0166 (0.0337)  time: 0.2701  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [19]  [ 760/1229]  eta: 0:02:09  lr: 0.000005  loss: 0.4180 (0.4321)  loss_classifier: 0.1464 (0.1535)  loss_box_reg: 0.0989 (0.1452)  loss_objectness: 0.0871 (0.0997)  loss_rpn_box_reg: 0.0200 (0.0337)  time: 0.2710  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [19]  [ 770/1229]  eta: 0:02:06  lr: 0.000005  loss: 0.4349 (0.4325)  loss_classifier: 0.1460 (0.1537)  loss_box_reg: 0.1160 (0.1454)  loss_objectness: 0.0969 (0.0996)  loss_rpn_box_reg: 0.0219 (0.0339)  time: 0.2726  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [19]  [ 780/1229]  eta: 0:02:03  lr: 0.000005  loss: 0.3860 (0.4323)  loss_classifier: 0.1311 (0.1535)  loss_box_reg: 0.1108 (0.1448)  loss_objectness: 0.0794 (0.0999)  loss_rpn_box_reg: 0.0211 (0.0342)  time: 0.2732  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [19]  [ 790/1229]  eta: 0:02:00  lr: 0.000005  loss: 0.3860 (0.4332)  loss_classifier: 0.1266 (0.1537)  loss_box_reg: 0.0978 (0.1450)  loss_objectness: 0.1152 (0.1003)  loss_rpn_box_reg: 0.0184 (0.0342)  time: 0.2667  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [19]  [ 800/1229]  eta: 0:01:57  lr: 0.000005  loss: 0.4496 (0.4336)  loss_classifier: 0.1661 (0.1539)  loss_box_reg: 0.1458 (0.1451)  loss_objectness: 0.1033 (0.1004)  loss_rpn_box_reg: 0.0184 (0.0342)  time: 0.2680  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [19]  [ 810/1229]  eta: 0:01:55  lr: 0.000005  loss: 0.4902 (0.4339)  loss_classifier: 0.1675 (0.1539)  loss_box_reg: 0.1447 (0.1454)  loss_objectness: 0.1028 (0.1005)  loss_rpn_box_reg: 0.0245 (0.0341)  time: 0.2708  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [19]  [ 820/1229]  eta: 0:01:52  lr: 0.000005  loss: 0.3368 (0.4336)  loss_classifier: 0.1202 (0.1538)  loss_box_reg: 0.1021 (0.1454)  loss_objectness: 0.0889 (0.1005)  loss_rpn_box_reg: 0.0193 (0.0339)  time: 0.2737  data: 0.1381  max mem: 1751\n",
      "Training Epoch: [19]  [ 830/1229]  eta: 0:01:49  lr: 0.000005  loss: 0.4202 (0.4346)  loss_classifier: 0.1439 (0.1543)  loss_box_reg: 0.0995 (0.1455)  loss_objectness: 0.0975 (0.1011)  loss_rpn_box_reg: 0.0158 (0.0338)  time: 0.2822  data: 0.1450  max mem: 1751\n",
      "Training Epoch: [19]  [ 840/1229]  eta: 0:01:46  lr: 0.000005  loss: 0.4202 (0.4336)  loss_classifier: 0.1439 (0.1539)  loss_box_reg: 0.0995 (0.1452)  loss_objectness: 0.0888 (0.1008)  loss_rpn_box_reg: 0.0221 (0.0337)  time: 0.2767  data: 0.1408  max mem: 1751\n",
      "Training Epoch: [19]  [ 850/1229]  eta: 0:01:44  lr: 0.000005  loss: 0.3369 (0.4338)  loss_classifier: 0.1246 (0.1540)  loss_box_reg: 0.1086 (0.1453)  loss_objectness: 0.0731 (0.1008)  loss_rpn_box_reg: 0.0238 (0.0338)  time: 0.2739  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [19]  [ 860/1229]  eta: 0:01:41  lr: 0.000005  loss: 0.4096 (0.4338)  loss_classifier: 0.1493 (0.1541)  loss_box_reg: 0.1326 (0.1454)  loss_objectness: 0.0731 (0.1006)  loss_rpn_box_reg: 0.0238 (0.0338)  time: 0.2742  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [19]  [ 870/1229]  eta: 0:01:38  lr: 0.000005  loss: 0.4793 (0.4350)  loss_classifier: 0.1716 (0.1545)  loss_box_reg: 0.1536 (0.1457)  loss_objectness: 0.0826 (0.1009)  loss_rpn_box_reg: 0.0184 (0.0338)  time: 0.2746  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [19]  [ 880/1229]  eta: 0:01:35  lr: 0.000005  loss: 0.4536 (0.4350)  loss_classifier: 0.1685 (0.1546)  loss_box_reg: 0.1492 (0.1457)  loss_objectness: 0.1057 (0.1010)  loss_rpn_box_reg: 0.0225 (0.0338)  time: 0.2759  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [19]  [ 890/1229]  eta: 0:01:33  lr: 0.000005  loss: 0.4030 (0.4353)  loss_classifier: 0.1478 (0.1546)  loss_box_reg: 0.1225 (0.1458)  loss_objectness: 0.0976 (0.1010)  loss_rpn_box_reg: 0.0203 (0.0339)  time: 0.2765  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [19]  [ 900/1229]  eta: 0:01:30  lr: 0.000005  loss: 0.3088 (0.4346)  loss_classifier: 0.1016 (0.1544)  loss_box_reg: 0.0888 (0.1454)  loss_objectness: 0.0837 (0.1009)  loss_rpn_box_reg: 0.0185 (0.0340)  time: 0.2770  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [19]  [ 910/1229]  eta: 0:01:27  lr: 0.000005  loss: 0.3912 (0.4353)  loss_classifier: 0.1259 (0.1545)  loss_box_reg: 0.1157 (0.1457)  loss_objectness: 0.0868 (0.1010)  loss_rpn_box_reg: 0.0201 (0.0340)  time: 0.2784  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [19]  [ 920/1229]  eta: 0:01:24  lr: 0.000005  loss: 0.3918 (0.4346)  loss_classifier: 0.1259 (0.1543)  loss_box_reg: 0.1118 (0.1455)  loss_objectness: 0.0855 (0.1009)  loss_rpn_box_reg: 0.0191 (0.0340)  time: 0.2782  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [19]  [ 930/1229]  eta: 0:01:22  lr: 0.000005  loss: 0.4268 (0.4359)  loss_classifier: 0.1610 (0.1549)  loss_box_reg: 0.1432 (0.1462)  loss_objectness: 0.0946 (0.1009)  loss_rpn_box_reg: 0.0215 (0.0340)  time: 0.2740  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [19]  [ 940/1229]  eta: 0:01:19  lr: 0.000005  loss: 0.4622 (0.4355)  loss_classifier: 0.1906 (0.1548)  loss_box_reg: 0.1432 (0.1460)  loss_objectness: 0.0977 (0.1007)  loss_rpn_box_reg: 0.0284 (0.0339)  time: 0.2730  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [19]  [ 950/1229]  eta: 0:01:16  lr: 0.000005  loss: 0.3616 (0.4346)  loss_classifier: 0.1252 (0.1546)  loss_box_reg: 0.1042 (0.1457)  loss_objectness: 0.0868 (0.1005)  loss_rpn_box_reg: 0.0207 (0.0338)  time: 0.2709  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [19]  [ 960/1229]  eta: 0:01:13  lr: 0.000005  loss: 0.2742 (0.4341)  loss_classifier: 0.1047 (0.1545)  loss_box_reg: 0.0897 (0.1454)  loss_objectness: 0.0887 (0.1004)  loss_rpn_box_reg: 0.0207 (0.0338)  time: 0.2721  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [19]  [ 970/1229]  eta: 0:01:11  lr: 0.000005  loss: 0.3237 (0.4340)  loss_classifier: 0.1229 (0.1545)  loss_box_reg: 0.0851 (0.1454)  loss_objectness: 0.0887 (0.1004)  loss_rpn_box_reg: 0.0226 (0.0337)  time: 0.2767  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [19]  [ 980/1229]  eta: 0:01:08  lr: 0.000005  loss: 0.4108 (0.4340)  loss_classifier: 0.1320 (0.1544)  loss_box_reg: 0.1384 (0.1456)  loss_objectness: 0.0837 (0.1003)  loss_rpn_box_reg: 0.0206 (0.0338)  time: 0.2826  data: 0.1392  max mem: 1751\n",
      "Training Epoch: [19]  [ 990/1229]  eta: 0:01:05  lr: 0.000005  loss: 0.4494 (0.4343)  loss_classifier: 0.1643 (0.1545)  loss_box_reg: 0.1611 (0.1457)  loss_objectness: 0.0862 (0.1003)  loss_rpn_box_reg: 0.0224 (0.0338)  time: 0.2788  data: 0.1372  max mem: 1751\n",
      "Training Epoch: [19]  [1000/1229]  eta: 0:01:02  lr: 0.000005  loss: 0.4156 (0.4341)  loss_classifier: 0.1403 (0.1544)  loss_box_reg: 0.1127 (0.1456)  loss_objectness: 0.0933 (0.1003)  loss_rpn_box_reg: 0.0291 (0.0338)  time: 0.2686  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [19]  [1010/1229]  eta: 0:01:00  lr: 0.000005  loss: 0.3705 (0.4345)  loss_classifier: 0.1259 (0.1546)  loss_box_reg: 0.1127 (0.1459)  loss_objectness: 0.0827 (0.1002)  loss_rpn_box_reg: 0.0297 (0.0338)  time: 0.2650  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [19]  [1020/1229]  eta: 0:00:57  lr: 0.000005  loss: 0.3904 (0.4342)  loss_classifier: 0.1260 (0.1545)  loss_box_reg: 0.1344 (0.1458)  loss_objectness: 0.0801 (0.1002)  loss_rpn_box_reg: 0.0202 (0.0337)  time: 0.2713  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [19]  [1030/1229]  eta: 0:00:54  lr: 0.000005  loss: 0.3258 (0.4336)  loss_classifier: 0.1183 (0.1543)  loss_box_reg: 0.1039 (0.1455)  loss_objectness: 0.0714 (0.1001)  loss_rpn_box_reg: 0.0137 (0.0337)  time: 0.2790  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [19]  [1040/1229]  eta: 0:00:51  lr: 0.000005  loss: 0.3154 (0.4327)  loss_classifier: 0.1149 (0.1539)  loss_box_reg: 0.1016 (0.1453)  loss_objectness: 0.0714 (0.0999)  loss_rpn_box_reg: 0.0141 (0.0336)  time: 0.2826  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [19]  [1050/1229]  eta: 0:00:49  lr: 0.000005  loss: 0.3305 (0.4334)  loss_classifier: 0.1149 (0.1541)  loss_box_reg: 0.1085 (0.1458)  loss_objectness: 0.0855 (0.0999)  loss_rpn_box_reg: 0.0179 (0.0336)  time: 0.2789  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [19]  [1060/1229]  eta: 0:00:46  lr: 0.000005  loss: 0.4340 (0.4337)  loss_classifier: 0.1597 (0.1542)  loss_box_reg: 0.1790 (0.1460)  loss_objectness: 0.0882 (0.0998)  loss_rpn_box_reg: 0.0269 (0.0337)  time: 0.2763  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [19]  [1070/1229]  eta: 0:00:43  lr: 0.000005  loss: 0.3165 (0.4328)  loss_classifier: 0.1202 (0.1539)  loss_box_reg: 0.1002 (0.1456)  loss_objectness: 0.0838 (0.0997)  loss_rpn_box_reg: 0.0229 (0.0336)  time: 0.2761  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [19]  [1080/1229]  eta: 0:00:40  lr: 0.000005  loss: 0.3053 (0.4329)  loss_classifier: 0.1144 (0.1540)  loss_box_reg: 0.0876 (0.1458)  loss_objectness: 0.0691 (0.0995)  loss_rpn_box_reg: 0.0225 (0.0336)  time: 0.2806  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [19]  [1090/1229]  eta: 0:00:38  lr: 0.000005  loss: 0.3711 (0.4329)  loss_classifier: 0.1220 (0.1540)  loss_box_reg: 0.1162 (0.1455)  loss_objectness: 0.0792 (0.0998)  loss_rpn_box_reg: 0.0254 (0.0337)  time: 0.2800  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [19]  [1100/1229]  eta: 0:00:35  lr: 0.000005  loss: 0.3522 (0.4334)  loss_classifier: 0.1066 (0.1540)  loss_box_reg: 0.1162 (0.1457)  loss_objectness: 0.0856 (0.0998)  loss_rpn_box_reg: 0.0291 (0.0339)  time: 0.2699  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [19]  [1110/1229]  eta: 0:00:32  lr: 0.000005  loss: 0.4309 (0.4333)  loss_classifier: 0.1521 (0.1541)  loss_box_reg: 0.1290 (0.1456)  loss_objectness: 0.1054 (0.0999)  loss_rpn_box_reg: 0.0247 (0.0338)  time: 0.2727  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [19]  [1120/1229]  eta: 0:00:29  lr: 0.000005  loss: 0.4343 (0.4328)  loss_classifier: 0.1521 (0.1538)  loss_box_reg: 0.0941 (0.1452)  loss_objectness: 0.0951 (0.0998)  loss_rpn_box_reg: 0.0247 (0.0340)  time: 0.2720  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [19]  [1130/1229]  eta: 0:00:27  lr: 0.000005  loss: 0.4343 (0.4327)  loss_classifier: 0.1135 (0.1538)  loss_box_reg: 0.0948 (0.1452)  loss_objectness: 0.0843 (0.0998)  loss_rpn_box_reg: 0.0256 (0.0339)  time: 0.2723  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [19]  [1140/1229]  eta: 0:00:24  lr: 0.000005  loss: 0.3808 (0.4331)  loss_classifier: 0.1359 (0.1539)  loss_box_reg: 0.1276 (0.1455)  loss_objectness: 0.0838 (0.0998)  loss_rpn_box_reg: 0.0278 (0.0339)  time: 0.2743  data: 0.1393  max mem: 1751\n",
      "Training Epoch: [19]  [1150/1229]  eta: 0:00:21  lr: 0.000005  loss: 0.2745 (0.4314)  loss_classifier: 0.0918 (0.1533)  loss_box_reg: 0.0675 (0.1448)  loss_objectness: 0.0742 (0.0995)  loss_rpn_box_reg: 0.0162 (0.0338)  time: 0.2776  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [19]  [1160/1229]  eta: 0:00:18  lr: 0.000005  loss: 0.3549 (0.4322)  loss_classifier: 0.1202 (0.1536)  loss_box_reg: 0.0903 (0.1451)  loss_objectness: 0.0789 (0.0997)  loss_rpn_box_reg: 0.0152 (0.0339)  time: 0.2845  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [19]  [1170/1229]  eta: 0:00:16  lr: 0.000005  loss: 0.5074 (0.4331)  loss_classifier: 0.1729 (0.1538)  loss_box_reg: 0.1591 (0.1455)  loss_objectness: 0.1003 (0.0998)  loss_rpn_box_reg: 0.0264 (0.0339)  time: 0.2792  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [19]  [1180/1229]  eta: 0:00:13  lr: 0.000005  loss: 0.3433 (0.4322)  loss_classifier: 0.1338 (0.1535)  loss_box_reg: 0.1226 (0.1451)  loss_objectness: 0.0850 (0.0997)  loss_rpn_box_reg: 0.0192 (0.0338)  time: 0.2732  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [19]  [1190/1229]  eta: 0:00:10  lr: 0.000005  loss: 0.3420 (0.4321)  loss_classifier: 0.1267 (0.1535)  loss_box_reg: 0.1203 (0.1451)  loss_objectness: 0.0786 (0.0998)  loss_rpn_box_reg: 0.0151 (0.0338)  time: 0.2762  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [19]  [1200/1229]  eta: 0:00:07  lr: 0.000005  loss: 0.4426 (0.4324)  loss_classifier: 0.1519 (0.1536)  loss_box_reg: 0.1315 (0.1451)  loss_objectness: 0.0828 (0.0998)  loss_rpn_box_reg: 0.0208 (0.0338)  time: 0.2777  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [19]  [1210/1229]  eta: 0:00:05  lr: 0.000005  loss: 0.4059 (0.4316)  loss_classifier: 0.1477 (0.1534)  loss_box_reg: 0.1041 (0.1447)  loss_objectness: 0.0784 (0.0998)  loss_rpn_box_reg: 0.0184 (0.0337)  time: 0.2787  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [19]  [1220/1229]  eta: 0:00:02  lr: 0.000005  loss: 0.3199 (0.4313)  loss_classifier: 0.1289 (0.1534)  loss_box_reg: 0.0912 (0.1446)  loss_objectness: 0.0744 (0.0996)  loss_rpn_box_reg: 0.0153 (0.0337)  time: 0.2758  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [19]  [1228/1229]  eta: 0:00:00  lr: 0.000005  loss: 0.4027 (0.4325)  loss_classifier: 0.1597 (0.1538)  loss_box_reg: 0.1301 (0.1449)  loss_objectness: 0.0817 (0.0999)  loss_rpn_box_reg: 0.0274 (0.0339)  time: 0.2729  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [19] Total time: 0:05:38 (0.2752 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:51  model_time: 0.3260 (0.3260)  evaluator_time: 0.0030 (0.0030)  time: 0.3610  data: 0.0300  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0800 (0.0827)  evaluator_time: 0.0040 (0.0085)  time: 0.1290  data: 0.0373  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0830 (0.0812)  evaluator_time: 0.0030 (0.0077)  time: 0.1212  data: 0.0320  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0730 (0.0803)  evaluator_time: 0.0040 (0.0076)  time: 0.1268  data: 0.0423  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0730 (0.0802)  evaluator_time: 0.0020 (0.0076)  time: 0.1231  data: 0.0401  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1257 s / it)\n",
      "Averaged stats: model_time: 0.0730 (0.0802)  evaluator_time: 0.0020 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [19]  [  0/308]  eta: 0:00:38  lr: 0.000005  loss: 0.1626 (0.1626)  loss_classifier: 0.0589 (0.0589)  loss_box_reg: 0.0679 (0.0679)  loss_objectness: 0.0243 (0.0243)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1240  data: 0.0290  max mem: 1751\n",
      "Testing Epoch: [19]  [100/308]  eta: 0:00:29  lr: 0.000005  loss: 0.3192 (0.4817)  loss_classifier: 0.1333 (0.1548)  loss_box_reg: 0.1175 (0.1725)  loss_objectness: 0.0582 (0.1025)  loss_rpn_box_reg: 0.0186 (0.0519)  time: 0.1470  data: 0.0444  max mem: 1751\n",
      "Testing Epoch: [19]  [200/308]  eta: 0:00:15  lr: 0.000005  loss: 0.3506 (0.4574)  loss_classifier: 0.1376 (0.1492)  loss_box_reg: 0.1250 (0.1634)  loss_objectness: 0.0616 (0.0957)  loss_rpn_box_reg: 0.0197 (0.0491)  time: 0.1444  data: 0.0389  max mem: 1751\n",
      "Testing Epoch: [19]  [300/308]  eta: 0:00:01  lr: 0.000005  loss: 0.4466 (0.4542)  loss_classifier: 0.1555 (0.1494)  loss_box_reg: 0.1788 (0.1643)  loss_objectness: 0.0756 (0.0930)  loss_rpn_box_reg: 0.0265 (0.0475)  time: 0.1396  data: 0.0440  max mem: 1751\n",
      "Testing Epoch: [19]  [307/308]  eta: 0:00:00  lr: 0.000005  loss: 0.4466 (0.4545)  loss_classifier: 0.1852 (0.1496)  loss_box_reg: 0.1749 (0.1646)  loss_objectness: 0.0656 (0.0932)  loss_rpn_box_reg: 0.0271 (0.0471)  time: 0.1375  data: 0.0421  max mem: 1751\n",
      "Testing Epoch: [19] Total time: 0:00:42 (0.1389 s / it)\n",
      "Training Epoch: [20]  [   0/1229]  eta: 0:05:06  lr: 0.000005  loss: 0.3418 (0.3418)  loss_classifier: 0.1226 (0.1226)  loss_box_reg: 0.1415 (0.1415)  loss_objectness: 0.0700 (0.0700)  loss_rpn_box_reg: 0.0077 (0.0077)  time: 0.2490  data: 0.1260  max mem: 1751\n",
      "Training Epoch: [20]  [  10/1229]  eta: 0:05:26  lr: 0.000005  loss: 0.4490 (0.5129)  loss_classifier: 0.1764 (0.1783)  loss_box_reg: 0.1427 (0.1935)  loss_objectness: 0.1043 (0.1056)  loss_rpn_box_reg: 0.0254 (0.0354)  time: 0.2675  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [20]  [  20/1229]  eta: 0:05:25  lr: 0.000005  loss: 0.4166 (0.4759)  loss_classifier: 0.1625 (0.1764)  loss_box_reg: 0.1296 (0.1741)  loss_objectness: 0.1016 (0.0966)  loss_rpn_box_reg: 0.0235 (0.0287)  time: 0.2704  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [20]  [  30/1229]  eta: 0:05:24  lr: 0.000005  loss: 0.3846 (0.4644)  loss_classifier: 0.1538 (0.1694)  loss_box_reg: 0.1296 (0.1666)  loss_objectness: 0.0829 (0.1009)  loss_rpn_box_reg: 0.0193 (0.0276)  time: 0.2726  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [20]  [  40/1229]  eta: 0:05:22  lr: 0.000005  loss: 0.3846 (0.4562)  loss_classifier: 0.1357 (0.1632)  loss_box_reg: 0.1354 (0.1593)  loss_objectness: 0.0804 (0.0963)  loss_rpn_box_reg: 0.0254 (0.0374)  time: 0.2726  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [20]  [  50/1229]  eta: 0:05:20  lr: 0.000005  loss: 0.4042 (0.4709)  loss_classifier: 0.1403 (0.1669)  loss_box_reg: 0.1354 (0.1625)  loss_objectness: 0.0927 (0.1025)  loss_rpn_box_reg: 0.0334 (0.0390)  time: 0.2724  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [20]  [  60/1229]  eta: 0:05:18  lr: 0.000005  loss: 0.4500 (0.4737)  loss_classifier: 0.1469 (0.1680)  loss_box_reg: 0.1450 (0.1665)  loss_objectness: 0.1098 (0.1008)  loss_rpn_box_reg: 0.0375 (0.0384)  time: 0.2764  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [20]  [  70/1229]  eta: 0:05:16  lr: 0.000005  loss: 0.4215 (0.4720)  loss_classifier: 0.1375 (0.1658)  loss_box_reg: 0.1322 (0.1655)  loss_objectness: 0.0958 (0.1008)  loss_rpn_box_reg: 0.0133 (0.0400)  time: 0.2782  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [20]  [  80/1229]  eta: 0:05:13  lr: 0.000005  loss: 0.4215 (0.4663)  loss_classifier: 0.1375 (0.1636)  loss_box_reg: 0.1322 (0.1630)  loss_objectness: 0.0964 (0.0998)  loss_rpn_box_reg: 0.0191 (0.0399)  time: 0.2739  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [20]  [  90/1229]  eta: 0:05:11  lr: 0.000005  loss: 0.5022 (0.4712)  loss_classifier: 0.1450 (0.1650)  loss_box_reg: 0.1699 (0.1658)  loss_objectness: 0.0904 (0.0999)  loss_rpn_box_reg: 0.0259 (0.0405)  time: 0.2726  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [20]  [ 100/1229]  eta: 0:05:08  lr: 0.000005  loss: 0.4486 (0.4678)  loss_classifier: 0.1500 (0.1646)  loss_box_reg: 0.1432 (0.1643)  loss_objectness: 0.0904 (0.1002)  loss_rpn_box_reg: 0.0270 (0.0386)  time: 0.2731  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [20]  [ 110/1229]  eta: 0:05:05  lr: 0.000005  loss: 0.4460 (0.4770)  loss_classifier: 0.1658 (0.1678)  loss_box_reg: 0.1318 (0.1651)  loss_objectness: 0.1008 (0.1039)  loss_rpn_box_reg: 0.0207 (0.0402)  time: 0.2712  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [20]  [ 120/1229]  eta: 0:05:02  lr: 0.000005  loss: 0.4460 (0.4745)  loss_classifier: 0.1725 (0.1679)  loss_box_reg: 0.1017 (0.1619)  loss_objectness: 0.0990 (0.1038)  loss_rpn_box_reg: 0.0207 (0.0409)  time: 0.2699  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [20]  [ 130/1229]  eta: 0:04:59  lr: 0.000005  loss: 0.3879 (0.4665)  loss_classifier: 0.1439 (0.1649)  loss_box_reg: 0.1122 (0.1599)  loss_objectness: 0.0923 (0.1020)  loss_rpn_box_reg: 0.0180 (0.0398)  time: 0.2682  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [20]  [ 140/1229]  eta: 0:04:56  lr: 0.000005  loss: 0.3718 (0.4664)  loss_classifier: 0.1200 (0.1650)  loss_box_reg: 0.1385 (0.1600)  loss_objectness: 0.0849 (0.1026)  loss_rpn_box_reg: 0.0186 (0.0388)  time: 0.2705  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [20]  [ 150/1229]  eta: 0:04:54  lr: 0.000005  loss: 0.3942 (0.4669)  loss_classifier: 0.1440 (0.1660)  loss_box_reg: 0.1385 (0.1604)  loss_objectness: 0.0849 (0.1020)  loss_rpn_box_reg: 0.0165 (0.0385)  time: 0.2788  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [20]  [ 160/1229]  eta: 0:04:51  lr: 0.000005  loss: 0.4412 (0.4731)  loss_classifier: 0.1683 (0.1674)  loss_box_reg: 0.1626 (0.1632)  loss_objectness: 0.1031 (0.1029)  loss_rpn_box_reg: 0.0165 (0.0396)  time: 0.2746  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [20]  [ 170/1229]  eta: 0:04:48  lr: 0.000005  loss: 0.4412 (0.4718)  loss_classifier: 0.1387 (0.1665)  loss_box_reg: 0.1221 (0.1633)  loss_objectness: 0.1063 (0.1028)  loss_rpn_box_reg: 0.0211 (0.0391)  time: 0.2698  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [20]  [ 180/1229]  eta: 0:04:45  lr: 0.000005  loss: 0.3507 (0.4723)  loss_classifier: 0.1183 (0.1668)  loss_box_reg: 0.1063 (0.1643)  loss_objectness: 0.0789 (0.1026)  loss_rpn_box_reg: 0.0172 (0.0386)  time: 0.2734  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [20]  [ 190/1229]  eta: 0:04:43  lr: 0.000005  loss: 0.4298 (0.4737)  loss_classifier: 0.1488 (0.1672)  loss_box_reg: 0.1528 (0.1641)  loss_objectness: 0.0918 (0.1037)  loss_rpn_box_reg: 0.0184 (0.0387)  time: 0.2727  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [20]  [ 200/1229]  eta: 0:04:40  lr: 0.000005  loss: 0.4409 (0.4750)  loss_classifier: 0.1534 (0.1676)  loss_box_reg: 0.1383 (0.1652)  loss_objectness: 0.0950 (0.1034)  loss_rpn_box_reg: 0.0256 (0.0389)  time: 0.2727  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [20]  [ 210/1229]  eta: 0:04:37  lr: 0.000005  loss: 0.3889 (0.4661)  loss_classifier: 0.1398 (0.1649)  loss_box_reg: 0.1295 (0.1621)  loss_objectness: 0.0783 (0.1015)  loss_rpn_box_reg: 0.0130 (0.0376)  time: 0.2721  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [20]  [ 220/1229]  eta: 0:04:35  lr: 0.000005  loss: 0.2904 (0.4632)  loss_classifier: 0.1093 (0.1639)  loss_box_reg: 0.0853 (0.1606)  loss_objectness: 0.0668 (0.1015)  loss_rpn_box_reg: 0.0108 (0.0373)  time: 0.2745  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [20]  [ 230/1229]  eta: 0:04:32  lr: 0.000005  loss: 0.3015 (0.4601)  loss_classifier: 0.1057 (0.1630)  loss_box_reg: 0.0797 (0.1592)  loss_objectness: 0.0970 (0.1009)  loss_rpn_box_reg: 0.0128 (0.0369)  time: 0.2804  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [20]  [ 240/1229]  eta: 0:04:30  lr: 0.000005  loss: 0.2786 (0.4550)  loss_classifier: 0.1057 (0.1615)  loss_box_reg: 0.0797 (0.1570)  loss_objectness: 0.0573 (0.1001)  loss_rpn_box_reg: 0.0128 (0.0364)  time: 0.2767  data: 0.1377  max mem: 1751\n",
      "Training Epoch: [20]  [ 250/1229]  eta: 0:04:27  lr: 0.000005  loss: 0.3002 (0.4540)  loss_classifier: 0.1141 (0.1613)  loss_box_reg: 0.0971 (0.1564)  loss_objectness: 0.0854 (0.0999)  loss_rpn_box_reg: 0.0203 (0.0364)  time: 0.2731  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [20]  [ 260/1229]  eta: 0:04:25  lr: 0.000005  loss: 0.3056 (0.4513)  loss_classifier: 0.1085 (0.1602)  loss_box_reg: 0.1078 (0.1553)  loss_objectness: 0.0736 (0.0997)  loss_rpn_box_reg: 0.0166 (0.0360)  time: 0.2780  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [20]  [ 270/1229]  eta: 0:04:22  lr: 0.000005  loss: 0.3056 (0.4466)  loss_classifier: 0.0992 (0.1584)  loss_box_reg: 0.0886 (0.1530)  loss_objectness: 0.0736 (0.0995)  loss_rpn_box_reg: 0.0137 (0.0356)  time: 0.2789  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [20]  [ 280/1229]  eta: 0:04:19  lr: 0.000005  loss: 0.3775 (0.4468)  loss_classifier: 0.1213 (0.1581)  loss_box_reg: 0.1038 (0.1528)  loss_objectness: 0.1140 (0.0996)  loss_rpn_box_reg: 0.0283 (0.0363)  time: 0.2774  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [20]  [ 290/1229]  eta: 0:04:17  lr: 0.000005  loss: 0.3775 (0.4476)  loss_classifier: 0.1311 (0.1587)  loss_box_reg: 0.1087 (0.1532)  loss_objectness: 0.1144 (0.0997)  loss_rpn_box_reg: 0.0283 (0.0360)  time: 0.2748  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [20]  [ 300/1229]  eta: 0:04:14  lr: 0.000005  loss: 0.3288 (0.4460)  loss_classifier: 0.1261 (0.1579)  loss_box_reg: 0.1079 (0.1525)  loss_objectness: 0.0721 (0.0994)  loss_rpn_box_reg: 0.0252 (0.0361)  time: 0.2738  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [20]  [ 310/1229]  eta: 0:04:11  lr: 0.000005  loss: 0.3849 (0.4463)  loss_classifier: 0.1261 (0.1579)  loss_box_reg: 0.1090 (0.1521)  loss_objectness: 0.0923 (0.1002)  loss_rpn_box_reg: 0.0286 (0.0361)  time: 0.2771  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [20]  [ 320/1229]  eta: 0:04:09  lr: 0.000005  loss: 0.4455 (0.4456)  loss_classifier: 0.1542 (0.1577)  loss_box_reg: 0.1134 (0.1518)  loss_objectness: 0.0944 (0.0996)  loss_rpn_box_reg: 0.0289 (0.0365)  time: 0.2796  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [20]  [ 330/1229]  eta: 0:04:06  lr: 0.000005  loss: 0.3507 (0.4429)  loss_classifier: 0.1239 (0.1566)  loss_box_reg: 0.1234 (0.1509)  loss_objectness: 0.0735 (0.0989)  loss_rpn_box_reg: 0.0268 (0.0365)  time: 0.2792  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [20]  [ 340/1229]  eta: 0:04:03  lr: 0.000005  loss: 0.3398 (0.4426)  loss_classifier: 0.1035 (0.1565)  loss_box_reg: 0.1168 (0.1509)  loss_objectness: 0.0712 (0.0986)  loss_rpn_box_reg: 0.0195 (0.0367)  time: 0.2763  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [20]  [ 350/1229]  eta: 0:04:01  lr: 0.000005  loss: 0.3700 (0.4413)  loss_classifier: 0.1232 (0.1561)  loss_box_reg: 0.1370 (0.1505)  loss_objectness: 0.0797 (0.0984)  loss_rpn_box_reg: 0.0170 (0.0363)  time: 0.2778  data: 0.1414  max mem: 1751\n",
      "Training Epoch: [20]  [ 360/1229]  eta: 0:03:58  lr: 0.000005  loss: 0.3605 (0.4384)  loss_classifier: 0.1191 (0.1550)  loss_box_reg: 0.1108 (0.1491)  loss_objectness: 0.0813 (0.0982)  loss_rpn_box_reg: 0.0131 (0.0361)  time: 0.2776  data: 0.1388  max mem: 1751\n",
      "Training Epoch: [20]  [ 370/1229]  eta: 0:03:55  lr: 0.000005  loss: 0.2809 (0.4357)  loss_classifier: 0.1003 (0.1541)  loss_box_reg: 0.0856 (0.1476)  loss_objectness: 0.0704 (0.0981)  loss_rpn_box_reg: 0.0110 (0.0359)  time: 0.2732  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [20]  [ 380/1229]  eta: 0:03:53  lr: 0.000005  loss: 0.3090 (0.4361)  loss_classifier: 0.1155 (0.1541)  loss_box_reg: 0.1054 (0.1480)  loss_objectness: 0.0688 (0.0980)  loss_rpn_box_reg: 0.0212 (0.0360)  time: 0.2768  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [20]  [ 390/1229]  eta: 0:03:50  lr: 0.000005  loss: 0.3915 (0.4381)  loss_classifier: 0.1427 (0.1545)  loss_box_reg: 0.1356 (0.1487)  loss_objectness: 0.0806 (0.0983)  loss_rpn_box_reg: 0.0326 (0.0366)  time: 0.2796  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [20]  [ 400/1229]  eta: 0:03:47  lr: 0.000005  loss: 0.3566 (0.4379)  loss_classifier: 0.1427 (0.1546)  loss_box_reg: 0.1071 (0.1494)  loss_objectness: 0.0806 (0.0977)  loss_rpn_box_reg: 0.0264 (0.0363)  time: 0.2826  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [20]  [ 410/1229]  eta: 0:03:45  lr: 0.000005  loss: 0.3179 (0.4352)  loss_classifier: 0.1276 (0.1539)  loss_box_reg: 0.0880 (0.1485)  loss_objectness: 0.0642 (0.0972)  loss_rpn_box_reg: 0.0129 (0.0357)  time: 0.2781  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [20]  [ 420/1229]  eta: 0:03:42  lr: 0.000005  loss: 0.3523 (0.4365)  loss_classifier: 0.1313 (0.1542)  loss_box_reg: 0.1287 (0.1492)  loss_objectness: 0.0810 (0.0971)  loss_rpn_box_reg: 0.0167 (0.0360)  time: 0.2699  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [20]  [ 430/1229]  eta: 0:03:39  lr: 0.000005  loss: 0.3966 (0.4360)  loss_classifier: 0.1378 (0.1542)  loss_box_reg: 0.1287 (0.1490)  loss_objectness: 0.0864 (0.0970)  loss_rpn_box_reg: 0.0270 (0.0359)  time: 0.2714  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [20]  [ 440/1229]  eta: 0:03:36  lr: 0.000005  loss: 0.3966 (0.4362)  loss_classifier: 0.1475 (0.1542)  loss_box_reg: 0.1178 (0.1485)  loss_objectness: 0.0850 (0.0975)  loss_rpn_box_reg: 0.0270 (0.0361)  time: 0.2702  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [20]  [ 450/1229]  eta: 0:03:33  lr: 0.000005  loss: 0.4540 (0.4374)  loss_classifier: 0.1556 (0.1549)  loss_box_reg: 0.1323 (0.1487)  loss_objectness: 0.0931 (0.0979)  loss_rpn_box_reg: 0.0301 (0.0360)  time: 0.2737  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [20]  [ 460/1229]  eta: 0:03:31  lr: 0.000005  loss: 0.5467 (0.4391)  loss_classifier: 0.1877 (0.1555)  loss_box_reg: 0.1938 (0.1493)  loss_objectness: 0.1057 (0.0986)  loss_rpn_box_reg: 0.0191 (0.0358)  time: 0.2822  data: 0.1378  max mem: 1751\n",
      "Training Epoch: [20]  [ 470/1229]  eta: 0:03:28  lr: 0.000005  loss: 0.4601 (0.4392)  loss_classifier: 0.1621 (0.1553)  loss_box_reg: 0.1512 (0.1489)  loss_objectness: 0.1057 (0.0987)  loss_rpn_box_reg: 0.0164 (0.0363)  time: 0.2838  data: 0.1377  max mem: 1751\n",
      "Training Epoch: [20]  [ 480/1229]  eta: 0:03:25  lr: 0.000005  loss: 0.3588 (0.4373)  loss_classifier: 0.1346 (0.1549)  loss_box_reg: 0.0875 (0.1479)  loss_objectness: 0.0908 (0.0986)  loss_rpn_box_reg: 0.0183 (0.0360)  time: 0.2766  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [20]  [ 490/1229]  eta: 0:03:23  lr: 0.000005  loss: 0.3043 (0.4360)  loss_classifier: 0.1234 (0.1544)  loss_box_reg: 0.0847 (0.1471)  loss_objectness: 0.0732 (0.0985)  loss_rpn_box_reg: 0.0183 (0.0359)  time: 0.2688  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [20]  [ 500/1229]  eta: 0:03:20  lr: 0.000005  loss: 0.3861 (0.4362)  loss_classifier: 0.1401 (0.1545)  loss_box_reg: 0.1013 (0.1471)  loss_objectness: 0.0888 (0.0986)  loss_rpn_box_reg: 0.0294 (0.0360)  time: 0.2681  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [20]  [ 510/1229]  eta: 0:03:17  lr: 0.000005  loss: 0.3439 (0.4347)  loss_classifier: 0.1401 (0.1543)  loss_box_reg: 0.1202 (0.1466)  loss_objectness: 0.0658 (0.0983)  loss_rpn_box_reg: 0.0263 (0.0356)  time: 0.2768  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [20]  [ 520/1229]  eta: 0:03:14  lr: 0.000005  loss: 0.3012 (0.4350)  loss_classifier: 0.1179 (0.1544)  loss_box_reg: 0.1169 (0.1467)  loss_objectness: 0.0588 (0.0984)  loss_rpn_box_reg: 0.0136 (0.0355)  time: 0.2786  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [20]  [ 530/1229]  eta: 0:03:12  lr: 0.000005  loss: 0.4000 (0.4348)  loss_classifier: 0.1472 (0.1543)  loss_box_reg: 0.1357 (0.1469)  loss_objectness: 0.0824 (0.0985)  loss_rpn_box_reg: 0.0164 (0.0352)  time: 0.2730  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [20]  [ 540/1229]  eta: 0:03:09  lr: 0.000005  loss: 0.4000 (0.4341)  loss_classifier: 0.1427 (0.1542)  loss_box_reg: 0.1357 (0.1466)  loss_objectness: 0.0832 (0.0980)  loss_rpn_box_reg: 0.0219 (0.0352)  time: 0.2730  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [20]  [ 550/1229]  eta: 0:03:06  lr: 0.000005  loss: 0.3571 (0.4344)  loss_classifier: 0.1229 (0.1543)  loss_box_reg: 0.1387 (0.1471)  loss_objectness: 0.0697 (0.0978)  loss_rpn_box_reg: 0.0226 (0.0352)  time: 0.2771  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [20]  [ 560/1229]  eta: 0:03:03  lr: 0.000005  loss: 0.3571 (0.4340)  loss_classifier: 0.1305 (0.1541)  loss_box_reg: 0.1594 (0.1468)  loss_objectness: 0.0720 (0.0977)  loss_rpn_box_reg: 0.0199 (0.0354)  time: 0.2780  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [20]  [ 570/1229]  eta: 0:03:01  lr: 0.000005  loss: 0.3379 (0.4327)  loss_classifier: 0.1266 (0.1537)  loss_box_reg: 0.0941 (0.1461)  loss_objectness: 0.0773 (0.0974)  loss_rpn_box_reg: 0.0259 (0.0356)  time: 0.2720  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [20]  [ 580/1229]  eta: 0:02:58  lr: 0.000005  loss: 0.3447 (0.4343)  loss_classifier: 0.1250 (0.1539)  loss_box_reg: 0.1012 (0.1469)  loss_objectness: 0.0818 (0.0976)  loss_rpn_box_reg: 0.0392 (0.0360)  time: 0.2712  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [20]  [ 590/1229]  eta: 0:02:55  lr: 0.000005  loss: 0.4023 (0.4346)  loss_classifier: 0.1250 (0.1538)  loss_box_reg: 0.1232 (0.1465)  loss_objectness: 0.0937 (0.0981)  loss_rpn_box_reg: 0.0339 (0.0362)  time: 0.2740  data: 0.1372  max mem: 1751\n",
      "Training Epoch: [20]  [ 600/1229]  eta: 0:02:52  lr: 0.000005  loss: 0.4387 (0.4354)  loss_classifier: 0.1256 (0.1539)  loss_box_reg: 0.1068 (0.1470)  loss_objectness: 0.0937 (0.0981)  loss_rpn_box_reg: 0.0284 (0.0365)  time: 0.2782  data: 0.1371  max mem: 1751\n",
      "Training Epoch: [20]  [ 610/1229]  eta: 0:02:50  lr: 0.000005  loss: 0.4221 (0.4360)  loss_classifier: 0.1409 (0.1541)  loss_box_reg: 0.1298 (0.1473)  loss_objectness: 0.0952 (0.0982)  loss_rpn_box_reg: 0.0178 (0.0364)  time: 0.2747  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [20]  [ 620/1229]  eta: 0:02:47  lr: 0.000005  loss: 0.3669 (0.4339)  loss_classifier: 0.1328 (0.1533)  loss_box_reg: 0.1047 (0.1463)  loss_objectness: 0.0818 (0.0982)  loss_rpn_box_reg: 0.0154 (0.0361)  time: 0.2690  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [20]  [ 630/1229]  eta: 0:02:44  lr: 0.000005  loss: 0.3437 (0.4345)  loss_classifier: 0.1328 (0.1537)  loss_box_reg: 0.1047 (0.1470)  loss_objectness: 0.0830 (0.0979)  loss_rpn_box_reg: 0.0157 (0.0359)  time: 0.2674  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [20]  [ 640/1229]  eta: 0:02:41  lr: 0.000005  loss: 0.4261 (0.4343)  loss_classifier: 0.1527 (0.1535)  loss_box_reg: 0.1726 (0.1471)  loss_objectness: 0.0830 (0.0979)  loss_rpn_box_reg: 0.0211 (0.0358)  time: 0.2647  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [20]  [ 650/1229]  eta: 0:02:38  lr: 0.000005  loss: 0.4179 (0.4336)  loss_classifier: 0.1489 (0.1534)  loss_box_reg: 0.1726 (0.1471)  loss_objectness: 0.0818 (0.0977)  loss_rpn_box_reg: 0.0136 (0.0355)  time: 0.2719  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [20]  [ 660/1229]  eta: 0:02:36  lr: 0.000005  loss: 0.4407 (0.4350)  loss_classifier: 0.1689 (0.1540)  loss_box_reg: 0.1401 (0.1473)  loss_objectness: 0.0929 (0.0980)  loss_rpn_box_reg: 0.0169 (0.0358)  time: 0.2801  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [20]  [ 670/1229]  eta: 0:02:33  lr: 0.000005  loss: 0.4736 (0.4349)  loss_classifier: 0.1720 (0.1539)  loss_box_reg: 0.1401 (0.1474)  loss_objectness: 0.0865 (0.0979)  loss_rpn_box_reg: 0.0247 (0.0357)  time: 0.2736  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [20]  [ 680/1229]  eta: 0:02:30  lr: 0.000005  loss: 0.3477 (0.4357)  loss_classifier: 0.1290 (0.1542)  loss_box_reg: 0.1103 (0.1475)  loss_objectness: 0.0769 (0.0985)  loss_rpn_box_reg: 0.0187 (0.0356)  time: 0.2692  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [20]  [ 690/1229]  eta: 0:02:27  lr: 0.000005  loss: 0.4341 (0.4370)  loss_classifier: 0.1541 (0.1545)  loss_box_reg: 0.1479 (0.1480)  loss_objectness: 0.1012 (0.0987)  loss_rpn_box_reg: 0.0260 (0.0357)  time: 0.2687  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [20]  [ 700/1229]  eta: 0:02:25  lr: 0.000005  loss: 0.4538 (0.4377)  loss_classifier: 0.1740 (0.1548)  loss_box_reg: 0.1628 (0.1486)  loss_objectness: 0.0922 (0.0986)  loss_rpn_box_reg: 0.0303 (0.0358)  time: 0.2752  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [20]  [ 710/1229]  eta: 0:02:22  lr: 0.000005  loss: 0.4387 (0.4377)  loss_classifier: 0.1775 (0.1548)  loss_box_reg: 0.1494 (0.1485)  loss_objectness: 0.0867 (0.0988)  loss_rpn_box_reg: 0.0173 (0.0356)  time: 0.2809  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [20]  [ 720/1229]  eta: 0:02:19  lr: 0.000005  loss: 0.3245 (0.4380)  loss_classifier: 0.1320 (0.1548)  loss_box_reg: 0.1097 (0.1484)  loss_objectness: 0.0935 (0.0990)  loss_rpn_box_reg: 0.0171 (0.0358)  time: 0.2809  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [20]  [ 730/1229]  eta: 0:02:17  lr: 0.000005  loss: 0.3245 (0.4384)  loss_classifier: 0.1320 (0.1550)  loss_box_reg: 0.1097 (0.1487)  loss_objectness: 0.0794 (0.0989)  loss_rpn_box_reg: 0.0185 (0.0358)  time: 0.2820  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [20]  [ 740/1229]  eta: 0:02:14  lr: 0.000005  loss: 0.3356 (0.4379)  loss_classifier: 0.1289 (0.1548)  loss_box_reg: 0.1389 (0.1486)  loss_objectness: 0.0756 (0.0988)  loss_rpn_box_reg: 0.0185 (0.0356)  time: 0.2767  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [20]  [ 750/1229]  eta: 0:02:11  lr: 0.000005  loss: 0.3356 (0.4372)  loss_classifier: 0.1260 (0.1546)  loss_box_reg: 0.1307 (0.1486)  loss_objectness: 0.0531 (0.0985)  loss_rpn_box_reg: 0.0146 (0.0355)  time: 0.2732  data: 0.1382  max mem: 1751\n",
      "Training Epoch: [20]  [ 760/1229]  eta: 0:02:08  lr: 0.000005  loss: 0.4241 (0.4385)  loss_classifier: 0.1627 (0.1552)  loss_box_reg: 0.1433 (0.1491)  loss_objectness: 0.0966 (0.0987)  loss_rpn_box_reg: 0.0191 (0.0356)  time: 0.2734  data: 0.1398  max mem: 1751\n",
      "Training Epoch: [20]  [ 770/1229]  eta: 0:02:06  lr: 0.000005  loss: 0.4649 (0.4376)  loss_classifier: 0.1633 (0.1550)  loss_box_reg: 0.1213 (0.1486)  loss_objectness: 0.0978 (0.0985)  loss_rpn_box_reg: 0.0274 (0.0354)  time: 0.2746  data: 0.1375  max mem: 1751\n",
      "Training Epoch: [20]  [ 780/1229]  eta: 0:02:03  lr: 0.000005  loss: 0.2827 (0.4361)  loss_classifier: 0.1127 (0.1545)  loss_box_reg: 0.0770 (0.1479)  loss_objectness: 0.0719 (0.0983)  loss_rpn_box_reg: 0.0274 (0.0354)  time: 0.2735  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [20]  [ 790/1229]  eta: 0:02:00  lr: 0.000005  loss: 0.2939 (0.4369)  loss_classifier: 0.1147 (0.1550)  loss_box_reg: 0.0864 (0.1480)  loss_objectness: 0.0707 (0.0984)  loss_rpn_box_reg: 0.0296 (0.0354)  time: 0.2718  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [20]  [ 800/1229]  eta: 0:01:57  lr: 0.000005  loss: 0.4802 (0.4373)  loss_classifier: 0.1681 (0.1553)  loss_box_reg: 0.1299 (0.1482)  loss_objectness: 0.0891 (0.0984)  loss_rpn_box_reg: 0.0316 (0.0354)  time: 0.2757  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [20]  [ 810/1229]  eta: 0:01:55  lr: 0.000005  loss: 0.3790 (0.4374)  loss_classifier: 0.1375 (0.1552)  loss_box_reg: 0.1168 (0.1482)  loss_objectness: 0.0851 (0.0985)  loss_rpn_box_reg: 0.0248 (0.0355)  time: 0.2750  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [20]  [ 820/1229]  eta: 0:01:52  lr: 0.000005  loss: 0.3330 (0.4364)  loss_classifier: 0.1244 (0.1550)  loss_box_reg: 0.1014 (0.1477)  loss_objectness: 0.0804 (0.0983)  loss_rpn_box_reg: 0.0206 (0.0355)  time: 0.2686  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [20]  [ 830/1229]  eta: 0:01:49  lr: 0.000005  loss: 0.3633 (0.4369)  loss_classifier: 0.1348 (0.1552)  loss_box_reg: 0.1141 (0.1480)  loss_objectness: 0.0804 (0.0984)  loss_rpn_box_reg: 0.0152 (0.0354)  time: 0.2705  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [20]  [ 840/1229]  eta: 0:01:46  lr: 0.000005  loss: 0.3633 (0.4359)  loss_classifier: 0.1261 (0.1548)  loss_box_reg: 0.1131 (0.1475)  loss_objectness: 0.0920 (0.0983)  loss_rpn_box_reg: 0.0152 (0.0353)  time: 0.2740  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [20]  [ 850/1229]  eta: 0:01:44  lr: 0.000005  loss: 0.2755 (0.4350)  loss_classifier: 0.1085 (0.1545)  loss_box_reg: 0.0809 (0.1470)  loss_objectness: 0.0701 (0.0984)  loss_rpn_box_reg: 0.0132 (0.0352)  time: 0.2801  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [20]  [ 860/1229]  eta: 0:01:41  lr: 0.000005  loss: 0.3624 (0.4358)  loss_classifier: 0.1243 (0.1548)  loss_box_reg: 0.1042 (0.1475)  loss_objectness: 0.0837 (0.0984)  loss_rpn_box_reg: 0.0177 (0.0351)  time: 0.2736  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [20]  [ 870/1229]  eta: 0:01:38  lr: 0.000005  loss: 0.3210 (0.4351)  loss_classifier: 0.1097 (0.1546)  loss_box_reg: 0.0947 (0.1472)  loss_objectness: 0.0944 (0.0983)  loss_rpn_box_reg: 0.0186 (0.0349)  time: 0.2659  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [20]  [ 880/1229]  eta: 0:01:35  lr: 0.000005  loss: 0.2935 (0.4344)  loss_classifier: 0.1042 (0.1545)  loss_box_reg: 0.0903 (0.1470)  loss_objectness: 0.0689 (0.0982)  loss_rpn_box_reg: 0.0160 (0.0348)  time: 0.2685  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [20]  [ 890/1229]  eta: 0:01:32  lr: 0.000005  loss: 0.3452 (0.4342)  loss_classifier: 0.1197 (0.1544)  loss_box_reg: 0.1057 (0.1467)  loss_objectness: 0.0987 (0.0983)  loss_rpn_box_reg: 0.0240 (0.0348)  time: 0.2678  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [20]  [ 900/1229]  eta: 0:01:30  lr: 0.000005  loss: 0.3741 (0.4342)  loss_classifier: 0.1361 (0.1543)  loss_box_reg: 0.1138 (0.1469)  loss_objectness: 0.1026 (0.0982)  loss_rpn_box_reg: 0.0311 (0.0348)  time: 0.2698  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [20]  [ 910/1229]  eta: 0:01:27  lr: 0.000005  loss: 0.3312 (0.4336)  loss_classifier: 0.1187 (0.1539)  loss_box_reg: 0.1174 (0.1469)  loss_objectness: 0.0732 (0.0980)  loss_rpn_box_reg: 0.0226 (0.0348)  time: 0.2711  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [20]  [ 920/1229]  eta: 0:01:24  lr: 0.000005  loss: 0.3312 (0.4337)  loss_classifier: 0.1187 (0.1539)  loss_box_reg: 0.1069 (0.1470)  loss_objectness: 0.0732 (0.0980)  loss_rpn_box_reg: 0.0226 (0.0348)  time: 0.2726  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [20]  [ 930/1229]  eta: 0:01:21  lr: 0.000005  loss: 0.3397 (0.4331)  loss_classifier: 0.1357 (0.1538)  loss_box_reg: 0.0961 (0.1468)  loss_objectness: 0.0708 (0.0978)  loss_rpn_box_reg: 0.0243 (0.0347)  time: 0.2753  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [20]  [ 940/1229]  eta: 0:01:19  lr: 0.000005  loss: 0.3551 (0.4345)  loss_classifier: 0.1428 (0.1541)  loss_box_reg: 0.1104 (0.1469)  loss_objectness: 0.0733 (0.0984)  loss_rpn_box_reg: 0.0343 (0.0350)  time: 0.2796  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [20]  [ 950/1229]  eta: 0:01:16  lr: 0.000005  loss: 0.4047 (0.4338)  loss_classifier: 0.1361 (0.1539)  loss_box_reg: 0.1216 (0.1468)  loss_objectness: 0.0865 (0.0981)  loss_rpn_box_reg: 0.0354 (0.0349)  time: 0.2812  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [20]  [ 960/1229]  eta: 0:01:13  lr: 0.000005  loss: 0.4462 (0.4349)  loss_classifier: 0.1442 (0.1543)  loss_box_reg: 0.1593 (0.1472)  loss_objectness: 0.0797 (0.0985)  loss_rpn_box_reg: 0.0233 (0.0349)  time: 0.2772  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [20]  [ 970/1229]  eta: 0:01:11  lr: 0.000005  loss: 0.4528 (0.4346)  loss_classifier: 0.1549 (0.1542)  loss_box_reg: 0.1534 (0.1471)  loss_objectness: 0.0880 (0.0985)  loss_rpn_box_reg: 0.0194 (0.0349)  time: 0.2800  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [20]  [ 980/1229]  eta: 0:01:08  lr: 0.000005  loss: 0.3946 (0.4344)  loss_classifier: 0.1396 (0.1541)  loss_box_reg: 0.1167 (0.1470)  loss_objectness: 0.0880 (0.0986)  loss_rpn_box_reg: 0.0194 (0.0347)  time: 0.2798  data: 0.1372  max mem: 1751\n",
      "Training Epoch: [20]  [ 990/1229]  eta: 0:01:05  lr: 0.000005  loss: 0.3946 (0.4340)  loss_classifier: 0.1396 (0.1539)  loss_box_reg: 0.1174 (0.1468)  loss_objectness: 0.0986 (0.0984)  loss_rpn_box_reg: 0.0208 (0.0348)  time: 0.2738  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [20]  [1000/1229]  eta: 0:01:02  lr: 0.000005  loss: 0.3502 (0.4334)  loss_classifier: 0.1279 (0.1537)  loss_box_reg: 0.0854 (0.1465)  loss_objectness: 0.0886 (0.0984)  loss_rpn_box_reg: 0.0229 (0.0348)  time: 0.2728  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [20]  [1010/1229]  eta: 0:01:00  lr: 0.000005  loss: 0.3053 (0.4328)  loss_classifier: 0.1077 (0.1536)  loss_box_reg: 0.0773 (0.1463)  loss_objectness: 0.0832 (0.0982)  loss_rpn_box_reg: 0.0132 (0.0346)  time: 0.2734  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [20]  [1020/1229]  eta: 0:00:57  lr: 0.000005  loss: 0.2930 (0.4319)  loss_classifier: 0.1057 (0.1534)  loss_box_reg: 0.0935 (0.1459)  loss_objectness: 0.0798 (0.0981)  loss_rpn_box_reg: 0.0115 (0.0345)  time: 0.2746  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [20]  [1030/1229]  eta: 0:00:54  lr: 0.000005  loss: 0.2624 (0.4310)  loss_classifier: 0.1057 (0.1532)  loss_box_reg: 0.0890 (0.1457)  loss_objectness: 0.0798 (0.0978)  loss_rpn_box_reg: 0.0115 (0.0343)  time: 0.2760  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [20]  [1040/1229]  eta: 0:00:51  lr: 0.000005  loss: 0.3040 (0.4304)  loss_classifier: 0.1073 (0.1530)  loss_box_reg: 0.0989 (0.1455)  loss_objectness: 0.0872 (0.0978)  loss_rpn_box_reg: 0.0122 (0.0342)  time: 0.2738  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [20]  [1050/1229]  eta: 0:00:49  lr: 0.000005  loss: 0.4393 (0.4314)  loss_classifier: 0.1603 (0.1534)  loss_box_reg: 0.1372 (0.1459)  loss_objectness: 0.1054 (0.0980)  loss_rpn_box_reg: 0.0172 (0.0341)  time: 0.2738  data: 0.1367  max mem: 1751\n",
      "Training Epoch: [20]  [1060/1229]  eta: 0:00:46  lr: 0.000005  loss: 0.4393 (0.4313)  loss_classifier: 0.1667 (0.1534)  loss_box_reg: 0.1467 (0.1460)  loss_objectness: 0.0913 (0.0979)  loss_rpn_box_reg: 0.0240 (0.0341)  time: 0.2723  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [20]  [1070/1229]  eta: 0:00:43  lr: 0.000005  loss: 0.4086 (0.4315)  loss_classifier: 0.1310 (0.1534)  loss_box_reg: 0.1536 (0.1462)  loss_objectness: 0.0688 (0.0977)  loss_rpn_box_reg: 0.0279 (0.0342)  time: 0.2715  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [20]  [1080/1229]  eta: 0:00:40  lr: 0.000005  loss: 0.4230 (0.4313)  loss_classifier: 0.1440 (0.1534)  loss_box_reg: 0.1194 (0.1460)  loss_objectness: 0.0934 (0.0978)  loss_rpn_box_reg: 0.0242 (0.0341)  time: 0.2783  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [20]  [1090/1229]  eta: 0:00:38  lr: 0.000005  loss: 0.3201 (0.4306)  loss_classifier: 0.1198 (0.1532)  loss_box_reg: 0.1047 (0.1457)  loss_objectness: 0.0786 (0.0976)  loss_rpn_box_reg: 0.0153 (0.0341)  time: 0.2718  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [20]  [1100/1229]  eta: 0:00:35  lr: 0.000005  loss: 0.2850 (0.4301)  loss_classifier: 0.0939 (0.1529)  loss_box_reg: 0.1014 (0.1455)  loss_objectness: 0.0671 (0.0975)  loss_rpn_box_reg: 0.0133 (0.0342)  time: 0.2659  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [20]  [1110/1229]  eta: 0:00:32  lr: 0.000005  loss: 0.3345 (0.4296)  loss_classifier: 0.0989 (0.1527)  loss_box_reg: 0.0972 (0.1452)  loss_objectness: 0.0756 (0.0975)  loss_rpn_box_reg: 0.0154 (0.0342)  time: 0.2742  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [20]  [1120/1229]  eta: 0:00:29  lr: 0.000005  loss: 0.3687 (0.4296)  loss_classifier: 0.1371 (0.1527)  loss_box_reg: 0.1024 (0.1451)  loss_objectness: 0.1127 (0.0977)  loss_rpn_box_reg: 0.0175 (0.0341)  time: 0.2766  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [20]  [1130/1229]  eta: 0:00:27  lr: 0.000005  loss: 0.3723 (0.4298)  loss_classifier: 0.1382 (0.1528)  loss_box_reg: 0.1104 (0.1453)  loss_objectness: 0.0930 (0.0977)  loss_rpn_box_reg: 0.0195 (0.0340)  time: 0.2770  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [20]  [1140/1229]  eta: 0:00:24  lr: 0.000005  loss: 0.4302 (0.4301)  loss_classifier: 0.1653 (0.1529)  loss_box_reg: 0.1205 (0.1454)  loss_objectness: 0.0759 (0.0977)  loss_rpn_box_reg: 0.0195 (0.0340)  time: 0.2777  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [20]  [1150/1229]  eta: 0:00:21  lr: 0.000005  loss: 0.4445 (0.4300)  loss_classifier: 0.1604 (0.1529)  loss_box_reg: 0.1401 (0.1455)  loss_objectness: 0.0858 (0.0977)  loss_rpn_box_reg: 0.0221 (0.0340)  time: 0.2774  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [20]  [1160/1229]  eta: 0:00:18  lr: 0.000005  loss: 0.3848 (0.4313)  loss_classifier: 0.1436 (0.1532)  loss_box_reg: 0.1456 (0.1460)  loss_objectness: 0.1053 (0.0979)  loss_rpn_box_reg: 0.0254 (0.0341)  time: 0.2790  data: 0.1373  max mem: 1751\n",
      "Training Epoch: [20]  [1170/1229]  eta: 0:00:16  lr: 0.000005  loss: 0.3766 (0.4313)  loss_classifier: 0.1436 (0.1534)  loss_box_reg: 0.1456 (0.1460)  loss_objectness: 0.1122 (0.0980)  loss_rpn_box_reg: 0.0201 (0.0340)  time: 0.2796  data: 0.1378  max mem: 1751\n",
      "Training Epoch: [20]  [1180/1229]  eta: 0:00:13  lr: 0.000005  loss: 0.3296 (0.4304)  loss_classifier: 0.1248 (0.1531)  loss_box_reg: 0.0793 (0.1457)  loss_objectness: 0.0955 (0.0978)  loss_rpn_box_reg: 0.0182 (0.0339)  time: 0.2731  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [20]  [1190/1229]  eta: 0:00:10  lr: 0.000005  loss: 0.2625 (0.4293)  loss_classifier: 0.0921 (0.1527)  loss_box_reg: 0.0789 (0.1453)  loss_objectness: 0.0652 (0.0975)  loss_rpn_box_reg: 0.0107 (0.0338)  time: 0.2704  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [20]  [1200/1229]  eta: 0:00:07  lr: 0.000005  loss: 0.2905 (0.4296)  loss_classifier: 0.0969 (0.1528)  loss_box_reg: 0.0907 (0.1455)  loss_objectness: 0.0676 (0.0975)  loss_rpn_box_reg: 0.0224 (0.0338)  time: 0.2765  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [20]  [1210/1229]  eta: 0:00:05  lr: 0.000005  loss: 0.4706 (0.4301)  loss_classifier: 0.1638 (0.1530)  loss_box_reg: 0.1490 (0.1456)  loss_objectness: 0.0941 (0.0976)  loss_rpn_box_reg: 0.0254 (0.0339)  time: 0.2773  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [20]  [1220/1229]  eta: 0:00:02  lr: 0.000005  loss: 0.4179 (0.4300)  loss_classifier: 0.1547 (0.1530)  loss_box_reg: 0.1404 (0.1456)  loss_objectness: 0.0877 (0.0976)  loss_rpn_box_reg: 0.0219 (0.0339)  time: 0.2782  data: 0.1379  max mem: 1751\n",
      "Training Epoch: [20]  [1228/1229]  eta: 0:00:00  lr: 0.000005  loss: 0.4161 (0.4305)  loss_classifier: 0.1547 (0.1532)  loss_box_reg: 0.1146 (0.1459)  loss_objectness: 0.0907 (0.0976)  loss_rpn_box_reg: 0.0219 (0.0338)  time: 0.2809  data: 0.1397  max mem: 1751\n",
      "Training Epoch: [20] Total time: 0:05:37 (0.2747 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:35  model_time: 0.2760 (0.2760)  evaluator_time: 0.0020 (0.0020)  time: 0.3100  data: 0.0300  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0780 (0.0822)  evaluator_time: 0.0040 (0.0086)  time: 0.1283  data: 0.0373  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0830 (0.0812)  evaluator_time: 0.0030 (0.0078)  time: 0.1210  data: 0.0318  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0720 (0.0803)  evaluator_time: 0.0040 (0.0076)  time: 0.1204  data: 0.0363  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0720 (0.0801)  evaluator_time: 0.0030 (0.0076)  time: 0.1174  data: 0.0347  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1251 s / it)\n",
      "Averaged stats: model_time: 0.0720 (0.0801)  evaluator_time: 0.0030 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [20]  [  0/308]  eta: 0:00:37  lr: 0.000005  loss: 0.1585 (0.1585)  loss_classifier: 0.0587 (0.0587)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0199 (0.0199)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1220  data: 0.0280  max mem: 1751\n",
      "Testing Epoch: [20]  [100/308]  eta: 0:00:29  lr: 0.000005  loss: 0.3202 (0.4802)  loss_classifier: 0.1353 (0.1545)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0575 (0.1015)  loss_rpn_box_reg: 0.0186 (0.0519)  time: 0.1402  data: 0.0400  max mem: 1751\n",
      "Testing Epoch: [20]  [200/308]  eta: 0:00:15  lr: 0.000005  loss: 0.3465 (0.4570)  loss_classifier: 0.1396 (0.1490)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0758 (0.0956)  loss_rpn_box_reg: 0.0197 (0.0491)  time: 0.1392  data: 0.0337  max mem: 1751\n",
      "Testing Epoch: [20]  [300/308]  eta: 0:00:01  lr: 0.000005  loss: 0.4673 (0.4539)  loss_classifier: 0.1581 (0.1493)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0774 (0.0931)  loss_rpn_box_reg: 0.0265 (0.0474)  time: 0.1336  data: 0.0382  max mem: 1751\n",
      "Testing Epoch: [20]  [307/308]  eta: 0:00:00  lr: 0.000005  loss: 0.4569 (0.4541)  loss_classifier: 0.1860 (0.1495)  loss_box_reg: 0.1749 (0.1644)  loss_objectness: 0.0774 (0.0932)  loss_rpn_box_reg: 0.0271 (0.0470)  time: 0.1311  data: 0.0363  max mem: 1751\n",
      "Testing Epoch: [20] Total time: 0:00:42 (0.1382 s / it)\n",
      "Training Epoch: [21]  [   0/1229]  eta: 0:05:06  lr: 0.000001  loss: 0.4404 (0.4404)  loss_classifier: 0.1506 (0.1506)  loss_box_reg: 0.1274 (0.1274)  loss_objectness: 0.0901 (0.0901)  loss_rpn_box_reg: 0.0722 (0.0722)  time: 0.2490  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [21]  [  10/1229]  eta: 0:05:25  lr: 0.000001  loss: 0.3342 (0.3712)  loss_classifier: 0.0981 (0.1335)  loss_box_reg: 0.0873 (0.1263)  loss_objectness: 0.0695 (0.0808)  loss_rpn_box_reg: 0.0156 (0.0306)  time: 0.2673  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [21]  [  20/1229]  eta: 0:05:24  lr: 0.000001  loss: 0.4275 (0.4520)  loss_classifier: 0.1289 (0.1560)  loss_box_reg: 0.0873 (0.1496)  loss_objectness: 0.0729 (0.1098)  loss_rpn_box_reg: 0.0190 (0.0366)  time: 0.2696  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [21]  [  30/1229]  eta: 0:05:19  lr: 0.000001  loss: 0.4583 (0.4641)  loss_classifier: 0.1498 (0.1638)  loss_box_reg: 0.1146 (0.1630)  loss_objectness: 0.0921 (0.1044)  loss_rpn_box_reg: 0.0260 (0.0329)  time: 0.2667  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [21]  [  40/1229]  eta: 0:05:19  lr: 0.000001  loss: 0.3158 (0.4493)  loss_classifier: 0.1243 (0.1600)  loss_box_reg: 0.1046 (0.1550)  loss_objectness: 0.0822 (0.1010)  loss_rpn_box_reg: 0.0162 (0.0332)  time: 0.2684  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [21]  [  50/1229]  eta: 0:05:16  lr: 0.000001  loss: 0.3077 (0.4429)  loss_classifier: 0.1243 (0.1569)  loss_box_reg: 0.0952 (0.1515)  loss_objectness: 0.0948 (0.1044)  loss_rpn_box_reg: 0.0154 (0.0301)  time: 0.2706  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [21]  [  60/1229]  eta: 0:05:16  lr: 0.000001  loss: 0.4166 (0.4499)  loss_classifier: 0.1569 (0.1606)  loss_box_reg: 0.1444 (0.1548)  loss_objectness: 0.1193 (0.1045)  loss_rpn_box_reg: 0.0145 (0.0299)  time: 0.2754  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [21]  [  70/1229]  eta: 0:05:14  lr: 0.000001  loss: 0.4466 (0.4535)  loss_classifier: 0.1569 (0.1627)  loss_box_reg: 0.1495 (0.1552)  loss_objectness: 0.1003 (0.1045)  loss_rpn_box_reg: 0.0274 (0.0311)  time: 0.2800  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [21]  [  80/1229]  eta: 0:05:14  lr: 0.000001  loss: 0.4466 (0.4466)  loss_classifier: 0.1506 (0.1602)  loss_box_reg: 0.1230 (0.1537)  loss_objectness: 0.0746 (0.1022)  loss_rpn_box_reg: 0.0330 (0.0305)  time: 0.2824  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [21]  [  90/1229]  eta: 0:05:11  lr: 0.000001  loss: 0.4120 (0.4463)  loss_classifier: 0.1508 (0.1606)  loss_box_reg: 0.1067 (0.1516)  loss_objectness: 0.0902 (0.1037)  loss_rpn_box_reg: 0.0179 (0.0304)  time: 0.2797  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [21]  [ 100/1229]  eta: 0:05:09  lr: 0.000001  loss: 0.4154 (0.4550)  loss_classifier: 0.1556 (0.1630)  loss_box_reg: 0.1091 (0.1563)  loss_objectness: 0.0940 (0.1039)  loss_rpn_box_reg: 0.0164 (0.0317)  time: 0.2758  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [21]  [ 110/1229]  eta: 0:05:05  lr: 0.000001  loss: 0.4154 (0.4469)  loss_classifier: 0.1556 (0.1605)  loss_box_reg: 0.1306 (0.1534)  loss_objectness: 0.0829 (0.1022)  loss_rpn_box_reg: 0.0164 (0.0308)  time: 0.2707  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [21]  [ 120/1229]  eta: 0:05:02  lr: 0.000001  loss: 0.3558 (0.4399)  loss_classifier: 0.1248 (0.1569)  loss_box_reg: 0.1037 (0.1487)  loss_objectness: 0.0829 (0.1025)  loss_rpn_box_reg: 0.0153 (0.0319)  time: 0.2646  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [21]  [ 130/1229]  eta: 0:04:59  lr: 0.000001  loss: 0.2936 (0.4289)  loss_classifier: 0.0943 (0.1531)  loss_box_reg: 0.0756 (0.1453)  loss_objectness: 0.0681 (0.1003)  loss_rpn_box_reg: 0.0117 (0.0302)  time: 0.2710  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [21]  [ 140/1229]  eta: 0:04:57  lr: 0.000001  loss: 0.2742 (0.4331)  loss_classifier: 0.1060 (0.1530)  loss_box_reg: 0.0957 (0.1457)  loss_objectness: 0.0636 (0.1009)  loss_rpn_box_reg: 0.0117 (0.0335)  time: 0.2759  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [21]  [ 150/1229]  eta: 0:04:54  lr: 0.000001  loss: 0.2992 (0.4340)  loss_classifier: 0.1226 (0.1537)  loss_box_reg: 0.1122 (0.1471)  loss_objectness: 0.0650 (0.1005)  loss_rpn_box_reg: 0.0150 (0.0326)  time: 0.2777  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [21]  [ 160/1229]  eta: 0:04:52  lr: 0.000001  loss: 0.2992 (0.4296)  loss_classifier: 0.1160 (0.1526)  loss_box_reg: 0.1069 (0.1442)  loss_objectness: 0.0812 (0.1002)  loss_rpn_box_reg: 0.0144 (0.0325)  time: 0.2749  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [21]  [ 170/1229]  eta: 0:04:49  lr: 0.000001  loss: 0.2559 (0.4230)  loss_classifier: 0.1085 (0.1506)  loss_box_reg: 0.0724 (0.1412)  loss_objectness: 0.0705 (0.0992)  loss_rpn_box_reg: 0.0195 (0.0320)  time: 0.2757  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [21]  [ 180/1229]  eta: 0:04:47  lr: 0.000001  loss: 0.2876 (0.4265)  loss_classifier: 0.1161 (0.1521)  loss_box_reg: 0.1019 (0.1433)  loss_objectness: 0.0735 (0.0991)  loss_rpn_box_reg: 0.0197 (0.0320)  time: 0.2771  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [21]  [ 190/1229]  eta: 0:04:44  lr: 0.000001  loss: 0.3754 (0.4290)  loss_classifier: 0.1383 (0.1532)  loss_box_reg: 0.1240 (0.1449)  loss_objectness: 0.0968 (0.0990)  loss_rpn_box_reg: 0.0198 (0.0320)  time: 0.2764  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [21]  [ 200/1229]  eta: 0:04:42  lr: 0.000001  loss: 0.3014 (0.4231)  loss_classifier: 0.1149 (0.1519)  loss_box_reg: 0.1082 (0.1419)  loss_objectness: 0.0949 (0.0981)  loss_rpn_box_reg: 0.0198 (0.0312)  time: 0.2786  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [21]  [ 210/1229]  eta: 0:04:39  lr: 0.000001  loss: 0.3014 (0.4187)  loss_classifier: 0.1113 (0.1504)  loss_box_reg: 0.0767 (0.1397)  loss_objectness: 0.0711 (0.0972)  loss_rpn_box_reg: 0.0201 (0.0314)  time: 0.2789  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [21]  [ 220/1229]  eta: 0:04:36  lr: 0.000001  loss: 0.3567 (0.4209)  loss_classifier: 0.1318 (0.1508)  loss_box_reg: 0.1144 (0.1410)  loss_objectness: 0.0752 (0.0971)  loss_rpn_box_reg: 0.0277 (0.0320)  time: 0.2735  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [21]  [ 230/1229]  eta: 0:04:33  lr: 0.000001  loss: 0.3687 (0.4210)  loss_classifier: 0.1440 (0.1510)  loss_box_reg: 0.1354 (0.1410)  loss_objectness: 0.0752 (0.0972)  loss_rpn_box_reg: 0.0228 (0.0317)  time: 0.2690  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [21]  [ 240/1229]  eta: 0:04:30  lr: 0.000001  loss: 0.3687 (0.4211)  loss_classifier: 0.1371 (0.1508)  loss_box_reg: 0.1115 (0.1410)  loss_objectness: 0.0609 (0.0968)  loss_rpn_box_reg: 0.0228 (0.0324)  time: 0.2689  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [21]  [ 250/1229]  eta: 0:04:28  lr: 0.000001  loss: 0.3843 (0.4211)  loss_classifier: 0.1244 (0.1503)  loss_box_reg: 0.1115 (0.1404)  loss_objectness: 0.0851 (0.0973)  loss_rpn_box_reg: 0.0232 (0.0331)  time: 0.2736  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [21]  [ 260/1229]  eta: 0:04:25  lr: 0.000001  loss: 0.4086 (0.4225)  loss_classifier: 0.1244 (0.1499)  loss_box_reg: 0.1086 (0.1405)  loss_objectness: 0.1021 (0.0980)  loss_rpn_box_reg: 0.0238 (0.0341)  time: 0.2742  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [21]  [ 270/1229]  eta: 0:04:22  lr: 0.000001  loss: 0.4010 (0.4222)  loss_classifier: 0.1349 (0.1498)  loss_box_reg: 0.0959 (0.1398)  loss_objectness: 0.1149 (0.0988)  loss_rpn_box_reg: 0.0238 (0.0339)  time: 0.2685  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [21]  [ 280/1229]  eta: 0:04:19  lr: 0.000001  loss: 0.3906 (0.4217)  loss_classifier: 0.1349 (0.1495)  loss_box_reg: 0.0959 (0.1392)  loss_objectness: 0.1100 (0.0994)  loss_rpn_box_reg: 0.0216 (0.0336)  time: 0.2667  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [21]  [ 290/1229]  eta: 0:04:16  lr: 0.000001  loss: 0.3458 (0.4205)  loss_classifier: 0.1279 (0.1492)  loss_box_reg: 0.1052 (0.1393)  loss_objectness: 0.0874 (0.0989)  loss_rpn_box_reg: 0.0165 (0.0330)  time: 0.2694  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [21]  [ 300/1229]  eta: 0:04:13  lr: 0.000001  loss: 0.2904 (0.4187)  loss_classifier: 0.1112 (0.1488)  loss_box_reg: 0.0949 (0.1393)  loss_objectness: 0.0667 (0.0977)  loss_rpn_box_reg: 0.0113 (0.0329)  time: 0.2744  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [21]  [ 310/1229]  eta: 0:04:11  lr: 0.000001  loss: 0.3298 (0.4189)  loss_classifier: 0.1117 (0.1487)  loss_box_reg: 0.1203 (0.1394)  loss_objectness: 0.0603 (0.0976)  loss_rpn_box_reg: 0.0237 (0.0332)  time: 0.2784  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [21]  [ 320/1229]  eta: 0:04:08  lr: 0.000001  loss: 0.3437 (0.4172)  loss_classifier: 0.1432 (0.1482)  loss_box_reg: 0.1203 (0.1386)  loss_objectness: 0.0820 (0.0977)  loss_rpn_box_reg: 0.0200 (0.0327)  time: 0.2730  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [21]  [ 330/1229]  eta: 0:04:05  lr: 0.000001  loss: 0.3437 (0.4176)  loss_classifier: 0.1432 (0.1485)  loss_box_reg: 0.1082 (0.1391)  loss_objectness: 0.0846 (0.0974)  loss_rpn_box_reg: 0.0190 (0.0325)  time: 0.2705  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [21]  [ 340/1229]  eta: 0:04:02  lr: 0.000001  loss: 0.4487 (0.4204)  loss_classifier: 0.1655 (0.1497)  loss_box_reg: 0.1500 (0.1401)  loss_objectness: 0.0938 (0.0980)  loss_rpn_box_reg: 0.0210 (0.0326)  time: 0.2726  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [21]  [ 350/1229]  eta: 0:04:00  lr: 0.000001  loss: 0.4660 (0.4218)  loss_classifier: 0.1763 (0.1503)  loss_box_reg: 0.1694 (0.1414)  loss_objectness: 0.0937 (0.0978)  loss_rpn_box_reg: 0.0227 (0.0323)  time: 0.2729  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [21]  [ 360/1229]  eta: 0:03:57  lr: 0.000001  loss: 0.4737 (0.4245)  loss_classifier: 0.1763 (0.1514)  loss_box_reg: 0.1976 (0.1426)  loss_objectness: 0.0876 (0.0982)  loss_rpn_box_reg: 0.0234 (0.0322)  time: 0.2720  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [21]  [ 370/1229]  eta: 0:03:54  lr: 0.000001  loss: 0.4039 (0.4224)  loss_classifier: 0.1428 (0.1507)  loss_box_reg: 0.1418 (0.1417)  loss_objectness: 0.0768 (0.0977)  loss_rpn_box_reg: 0.0217 (0.0322)  time: 0.2761  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [21]  [ 380/1229]  eta: 0:03:52  lr: 0.000001  loss: 0.4039 (0.4241)  loss_classifier: 0.1499 (0.1513)  loss_box_reg: 0.1353 (0.1422)  loss_objectness: 0.0873 (0.0982)  loss_rpn_box_reg: 0.0217 (0.0323)  time: 0.2798  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [21]  [ 390/1229]  eta: 0:03:49  lr: 0.000001  loss: 0.5008 (0.4267)  loss_classifier: 0.1632 (0.1521)  loss_box_reg: 0.1516 (0.1426)  loss_objectness: 0.1099 (0.0994)  loss_rpn_box_reg: 0.0251 (0.0326)  time: 0.2746  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [21]  [ 400/1229]  eta: 0:03:46  lr: 0.000001  loss: 0.4784 (0.4283)  loss_classifier: 0.1666 (0.1528)  loss_box_reg: 0.1565 (0.1436)  loss_objectness: 0.0989 (0.0993)  loss_rpn_box_reg: 0.0274 (0.0326)  time: 0.2772  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [21]  [ 410/1229]  eta: 0:03:44  lr: 0.000001  loss: 0.4122 (0.4280)  loss_classifier: 0.1388 (0.1524)  loss_box_reg: 0.1448 (0.1427)  loss_objectness: 0.0947 (0.1001)  loss_rpn_box_reg: 0.0212 (0.0328)  time: 0.2806  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [21]  [ 420/1229]  eta: 0:03:41  lr: 0.000001  loss: 0.3560 (0.4271)  loss_classifier: 0.1239 (0.1522)  loss_box_reg: 0.0805 (0.1424)  loss_objectness: 0.0901 (0.0999)  loss_rpn_box_reg: 0.0176 (0.0325)  time: 0.2757  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [21]  [ 430/1229]  eta: 0:03:38  lr: 0.000001  loss: 0.3626 (0.4255)  loss_classifier: 0.1415 (0.1518)  loss_box_reg: 0.0838 (0.1415)  loss_objectness: 0.0892 (0.1000)  loss_rpn_box_reg: 0.0172 (0.0322)  time: 0.2707  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [21]  [ 440/1229]  eta: 0:03:35  lr: 0.000001  loss: 0.3372 (0.4250)  loss_classifier: 0.1326 (0.1515)  loss_box_reg: 0.0970 (0.1417)  loss_objectness: 0.0785 (0.0997)  loss_rpn_box_reg: 0.0200 (0.0321)  time: 0.2716  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [21]  [ 450/1229]  eta: 0:03:33  lr: 0.000001  loss: 0.3372 (0.4258)  loss_classifier: 0.1068 (0.1514)  loss_box_reg: 0.1057 (0.1417)  loss_objectness: 0.0731 (0.0998)  loss_rpn_box_reg: 0.0190 (0.0329)  time: 0.2721  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [21]  [ 460/1229]  eta: 0:03:30  lr: 0.000001  loss: 0.3687 (0.4241)  loss_classifier: 0.1155 (0.1507)  loss_box_reg: 0.0930 (0.1408)  loss_objectness: 0.0757 (0.0998)  loss_rpn_box_reg: 0.0257 (0.0329)  time: 0.2726  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [21]  [ 470/1229]  eta: 0:03:27  lr: 0.000001  loss: 0.3396 (0.4227)  loss_classifier: 0.1125 (0.1501)  loss_box_reg: 0.0930 (0.1403)  loss_objectness: 0.0696 (0.0994)  loss_rpn_box_reg: 0.0236 (0.0330)  time: 0.2752  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [21]  [ 480/1229]  eta: 0:03:25  lr: 0.000001  loss: 0.3487 (0.4234)  loss_classifier: 0.1198 (0.1503)  loss_box_reg: 0.1115 (0.1406)  loss_objectness: 0.0683 (0.0992)  loss_rpn_box_reg: 0.0220 (0.0332)  time: 0.2756  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [21]  [ 490/1229]  eta: 0:03:22  lr: 0.000001  loss: 0.3603 (0.4217)  loss_classifier: 0.1476 (0.1501)  loss_box_reg: 0.1141 (0.1401)  loss_objectness: 0.0699 (0.0988)  loss_rpn_box_reg: 0.0134 (0.0328)  time: 0.2738  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [21]  [ 500/1229]  eta: 0:03:19  lr: 0.000001  loss: 0.3603 (0.4224)  loss_classifier: 0.1530 (0.1502)  loss_box_reg: 0.1351 (0.1402)  loss_objectness: 0.0683 (0.0990)  loss_rpn_box_reg: 0.0175 (0.0331)  time: 0.2727  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [21]  [ 510/1229]  eta: 0:03:16  lr: 0.000001  loss: 0.4589 (0.4230)  loss_classifier: 0.1692 (0.1505)  loss_box_reg: 0.1448 (0.1404)  loss_objectness: 0.0668 (0.0990)  loss_rpn_box_reg: 0.0294 (0.0331)  time: 0.2717  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [21]  [ 520/1229]  eta: 0:03:13  lr: 0.000001  loss: 0.4589 (0.4248)  loss_classifier: 0.1543 (0.1510)  loss_box_reg: 0.1853 (0.1412)  loss_objectness: 0.0936 (0.0997)  loss_rpn_box_reg: 0.0294 (0.0330)  time: 0.2700  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [21]  [ 530/1229]  eta: 0:03:11  lr: 0.000001  loss: 0.3634 (0.4223)  loss_classifier: 0.1241 (0.1502)  loss_box_reg: 0.1083 (0.1404)  loss_objectness: 0.0797 (0.0989)  loss_rpn_box_reg: 0.0118 (0.0327)  time: 0.2647  data: 0.1298  max mem: 1751\n",
      "Training Epoch: [21]  [ 540/1229]  eta: 0:03:08  lr: 0.000001  loss: 0.3289 (0.4224)  loss_classifier: 0.1185 (0.1501)  loss_box_reg: 0.1004 (0.1405)  loss_objectness: 0.0759 (0.0991)  loss_rpn_box_reg: 0.0226 (0.0328)  time: 0.2687  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [21]  [ 550/1229]  eta: 0:03:05  lr: 0.000001  loss: 0.4391 (0.4240)  loss_classifier: 0.1456 (0.1506)  loss_box_reg: 0.1447 (0.1414)  loss_objectness: 0.0880 (0.0990)  loss_rpn_box_reg: 0.0272 (0.0331)  time: 0.2774  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [21]  [ 560/1229]  eta: 0:03:02  lr: 0.000001  loss: 0.5199 (0.4257)  loss_classifier: 0.1903 (0.1513)  loss_box_reg: 0.1980 (0.1427)  loss_objectness: 0.0810 (0.0987)  loss_rpn_box_reg: 0.0250 (0.0330)  time: 0.2727  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [21]  [ 570/1229]  eta: 0:03:00  lr: 0.000001  loss: 0.3646 (0.4242)  loss_classifier: 0.1771 (0.1509)  loss_box_reg: 0.1404 (0.1422)  loss_objectness: 0.0830 (0.0983)  loss_rpn_box_reg: 0.0130 (0.0327)  time: 0.2664  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [21]  [ 580/1229]  eta: 0:02:57  lr: 0.000001  loss: 0.3646 (0.4245)  loss_classifier: 0.1360 (0.1510)  loss_box_reg: 0.1366 (0.1426)  loss_objectness: 0.0706 (0.0980)  loss_rpn_box_reg: 0.0178 (0.0328)  time: 0.2649  data: 0.1296  max mem: 1751\n",
      "Training Epoch: [21]  [ 590/1229]  eta: 0:02:54  lr: 0.000001  loss: 0.4254 (0.4242)  loss_classifier: 0.1462 (0.1508)  loss_box_reg: 0.1631 (0.1426)  loss_objectness: 0.0831 (0.0981)  loss_rpn_box_reg: 0.0198 (0.0328)  time: 0.2720  data: 0.1297  max mem: 1751\n",
      "Training Epoch: [21]  [ 600/1229]  eta: 0:02:51  lr: 0.000001  loss: 0.4189 (0.4273)  loss_classifier: 0.1462 (0.1517)  loss_box_reg: 0.1631 (0.1441)  loss_objectness: 0.1034 (0.0985)  loss_rpn_box_reg: 0.0206 (0.0330)  time: 0.2718  data: 0.1300  max mem: 1751\n",
      "Training Epoch: [21]  [ 610/1229]  eta: 0:02:48  lr: 0.000001  loss: 0.3365 (0.4259)  loss_classifier: 0.1184 (0.1512)  loss_box_reg: 0.1131 (0.1439)  loss_objectness: 0.0757 (0.0979)  loss_rpn_box_reg: 0.0238 (0.0329)  time: 0.2641  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [21]  [ 620/1229]  eta: 0:02:46  lr: 0.000001  loss: 0.3365 (0.4259)  loss_classifier: 0.1195 (0.1511)  loss_box_reg: 0.0911 (0.1437)  loss_objectness: 0.0691 (0.0980)  loss_rpn_box_reg: 0.0232 (0.0331)  time: 0.2669  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [21]  [ 630/1229]  eta: 0:02:43  lr: 0.000001  loss: 0.3929 (0.4275)  loss_classifier: 0.1564 (0.1518)  loss_box_reg: 0.1691 (0.1450)  loss_objectness: 0.0828 (0.0979)  loss_rpn_box_reg: 0.0215 (0.0329)  time: 0.2735  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [21]  [ 640/1229]  eta: 0:02:40  lr: 0.000001  loss: 0.5184 (0.4296)  loss_classifier: 0.1707 (0.1523)  loss_box_reg: 0.1895 (0.1456)  loss_objectness: 0.0909 (0.0986)  loss_rpn_box_reg: 0.0196 (0.0332)  time: 0.2713  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [21]  [ 650/1229]  eta: 0:02:38  lr: 0.000001  loss: 0.3508 (0.4274)  loss_classifier: 0.1230 (0.1516)  loss_box_reg: 0.1293 (0.1448)  loss_objectness: 0.0895 (0.0981)  loss_rpn_box_reg: 0.0161 (0.0329)  time: 0.2741  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [21]  [ 660/1229]  eta: 0:02:35  lr: 0.000001  loss: 0.2158 (0.4251)  loss_classifier: 0.0813 (0.1509)  loss_box_reg: 0.0752 (0.1440)  loss_objectness: 0.0524 (0.0976)  loss_rpn_box_reg: 0.0146 (0.0327)  time: 0.2773  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [21]  [ 670/1229]  eta: 0:02:32  lr: 0.000001  loss: 0.3611 (0.4273)  loss_classifier: 0.1309 (0.1516)  loss_box_reg: 0.0990 (0.1446)  loss_objectness: 0.0765 (0.0983)  loss_rpn_box_reg: 0.0176 (0.0329)  time: 0.2685  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [21]  [ 680/1229]  eta: 0:02:29  lr: 0.000001  loss: 0.4246 (0.4270)  loss_classifier: 0.1567 (0.1514)  loss_box_reg: 0.1493 (0.1444)  loss_objectness: 0.1002 (0.0982)  loss_rpn_box_reg: 0.0267 (0.0330)  time: 0.2680  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [21]  [ 690/1229]  eta: 0:02:27  lr: 0.000001  loss: 0.3800 (0.4273)  loss_classifier: 0.1394 (0.1515)  loss_box_reg: 0.1205 (0.1446)  loss_objectness: 0.0928 (0.0984)  loss_rpn_box_reg: 0.0226 (0.0328)  time: 0.2769  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [21]  [ 700/1229]  eta: 0:02:24  lr: 0.000001  loss: 0.3771 (0.4283)  loss_classifier: 0.1516 (0.1520)  loss_box_reg: 0.1317 (0.1451)  loss_objectness: 0.0940 (0.0984)  loss_rpn_box_reg: 0.0231 (0.0328)  time: 0.2767  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [21]  [ 710/1229]  eta: 0:02:21  lr: 0.000001  loss: 0.3670 (0.4277)  loss_classifier: 0.1439 (0.1519)  loss_box_reg: 0.1125 (0.1448)  loss_objectness: 0.0816 (0.0983)  loss_rpn_box_reg: 0.0213 (0.0328)  time: 0.2657  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [21]  [ 720/1229]  eta: 0:02:18  lr: 0.000001  loss: 0.3695 (0.4282)  loss_classifier: 0.1154 (0.1519)  loss_box_reg: 0.1029 (0.1449)  loss_objectness: 0.1094 (0.0985)  loss_rpn_box_reg: 0.0175 (0.0328)  time: 0.2713  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [21]  [ 730/1229]  eta: 0:02:16  lr: 0.000001  loss: 0.4025 (0.4304)  loss_classifier: 0.1469 (0.1525)  loss_box_reg: 0.1210 (0.1458)  loss_objectness: 0.1252 (0.0989)  loss_rpn_box_reg: 0.0280 (0.0332)  time: 0.2799  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [21]  [ 740/1229]  eta: 0:02:13  lr: 0.000001  loss: 0.5158 (0.4315)  loss_classifier: 0.1476 (0.1528)  loss_box_reg: 0.1708 (0.1463)  loss_objectness: 0.1024 (0.0990)  loss_rpn_box_reg: 0.0353 (0.0333)  time: 0.2749  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [21]  [ 750/1229]  eta: 0:02:10  lr: 0.000001  loss: 0.4676 (0.4319)  loss_classifier: 0.1399 (0.1529)  loss_box_reg: 0.1503 (0.1464)  loss_objectness: 0.1018 (0.0990)  loss_rpn_box_reg: 0.0348 (0.0336)  time: 0.2720  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [21]  [ 760/1229]  eta: 0:02:08  lr: 0.000001  loss: 0.3795 (0.4316)  loss_classifier: 0.1326 (0.1528)  loss_box_reg: 0.1127 (0.1463)  loss_objectness: 0.0927 (0.0990)  loss_rpn_box_reg: 0.0255 (0.0335)  time: 0.2756  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [21]  [ 770/1229]  eta: 0:02:05  lr: 0.000001  loss: 0.3563 (0.4316)  loss_classifier: 0.1263 (0.1529)  loss_box_reg: 0.1152 (0.1464)  loss_objectness: 0.0834 (0.0989)  loss_rpn_box_reg: 0.0210 (0.0334)  time: 0.2772  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [21]  [ 780/1229]  eta: 0:02:02  lr: 0.000001  loss: 0.3563 (0.4312)  loss_classifier: 0.1263 (0.1528)  loss_box_reg: 0.1152 (0.1465)  loss_objectness: 0.0834 (0.0987)  loss_rpn_box_reg: 0.0210 (0.0333)  time: 0.2747  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [21]  [ 790/1229]  eta: 0:01:59  lr: 0.000001  loss: 0.3705 (0.4318)  loss_classifier: 0.1271 (0.1530)  loss_box_reg: 0.1294 (0.1470)  loss_objectness: 0.0758 (0.0986)  loss_rpn_box_reg: 0.0180 (0.0332)  time: 0.2717  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [21]  [ 800/1229]  eta: 0:01:57  lr: 0.000001  loss: 0.4167 (0.4314)  loss_classifier: 0.1403 (0.1527)  loss_box_reg: 0.1294 (0.1470)  loss_objectness: 0.0739 (0.0985)  loss_rpn_box_reg: 0.0174 (0.0331)  time: 0.2725  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [21]  [ 810/1229]  eta: 0:01:54  lr: 0.000001  loss: 0.3245 (0.4312)  loss_classifier: 0.1296 (0.1527)  loss_box_reg: 0.0831 (0.1466)  loss_objectness: 0.0789 (0.0987)  loss_rpn_box_reg: 0.0208 (0.0332)  time: 0.2760  data: 0.1290  max mem: 1751\n",
      "Training Epoch: [21]  [ 820/1229]  eta: 0:01:51  lr: 0.000001  loss: 0.3234 (0.4309)  loss_classifier: 0.1206 (0.1527)  loss_box_reg: 0.0831 (0.1463)  loss_objectness: 0.0832 (0.0989)  loss_rpn_box_reg: 0.0213 (0.0331)  time: 0.2758  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [21]  [ 830/1229]  eta: 0:01:49  lr: 0.000001  loss: 0.3291 (0.4311)  loss_classifier: 0.1350 (0.1529)  loss_box_reg: 0.1077 (0.1462)  loss_objectness: 0.0828 (0.0990)  loss_rpn_box_reg: 0.0218 (0.0330)  time: 0.2796  data: 0.1373  max mem: 1751\n",
      "Training Epoch: [21]  [ 840/1229]  eta: 0:01:46  lr: 0.000001  loss: 0.3967 (0.4311)  loss_classifier: 0.1359 (0.1529)  loss_box_reg: 0.1100 (0.1461)  loss_objectness: 0.0803 (0.0990)  loss_rpn_box_reg: 0.0276 (0.0331)  time: 0.2776  data: 0.1384  max mem: 1751\n",
      "Training Epoch: [21]  [ 850/1229]  eta: 0:01:43  lr: 0.000001  loss: 0.4265 (0.4313)  loss_classifier: 0.1436 (0.1528)  loss_box_reg: 0.1322 (0.1462)  loss_objectness: 0.0901 (0.0992)  loss_rpn_box_reg: 0.0282 (0.0331)  time: 0.2694  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [21]  [ 860/1229]  eta: 0:01:40  lr: 0.000001  loss: 0.4282 (0.4310)  loss_classifier: 0.1459 (0.1527)  loss_box_reg: 0.1322 (0.1461)  loss_objectness: 0.0885 (0.0991)  loss_rpn_box_reg: 0.0282 (0.0331)  time: 0.2718  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [21]  [ 870/1229]  eta: 0:01:38  lr: 0.000001  loss: 0.4282 (0.4317)  loss_classifier: 0.1421 (0.1531)  loss_box_reg: 0.1448 (0.1464)  loss_objectness: 0.0894 (0.0992)  loss_rpn_box_reg: 0.0260 (0.0330)  time: 0.2801  data: 0.1368  max mem: 1751\n",
      "Training Epoch: [21]  [ 880/1229]  eta: 0:01:35  lr: 0.000001  loss: 0.4293 (0.4317)  loss_classifier: 0.1492 (0.1531)  loss_box_reg: 0.1405 (0.1462)  loss_objectness: 0.0953 (0.0992)  loss_rpn_box_reg: 0.0304 (0.0331)  time: 0.2785  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [21]  [ 890/1229]  eta: 0:01:32  lr: 0.000001  loss: 0.3955 (0.4315)  loss_classifier: 0.1492 (0.1531)  loss_box_reg: 0.1143 (0.1462)  loss_objectness: 0.0887 (0.0992)  loss_rpn_box_reg: 0.0253 (0.0330)  time: 0.2721  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [21]  [ 900/1229]  eta: 0:01:29  lr: 0.000001  loss: 0.3496 (0.4313)  loss_classifier: 0.1212 (0.1531)  loss_box_reg: 0.1154 (0.1461)  loss_objectness: 0.0774 (0.0992)  loss_rpn_box_reg: 0.0213 (0.0330)  time: 0.2749  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [21]  [ 910/1229]  eta: 0:01:27  lr: 0.000001  loss: 0.4025 (0.4312)  loss_classifier: 0.1406 (0.1530)  loss_box_reg: 0.1177 (0.1459)  loss_objectness: 0.0722 (0.0992)  loss_rpn_box_reg: 0.0262 (0.0331)  time: 0.2744  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [21]  [ 920/1229]  eta: 0:01:24  lr: 0.000001  loss: 0.4029 (0.4311)  loss_classifier: 0.1406 (0.1529)  loss_box_reg: 0.1201 (0.1457)  loss_objectness: 0.0926 (0.0993)  loss_rpn_box_reg: 0.0235 (0.0332)  time: 0.2699  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [21]  [ 930/1229]  eta: 0:01:21  lr: 0.000001  loss: 0.3970 (0.4310)  loss_classifier: 0.1327 (0.1530)  loss_box_reg: 0.1089 (0.1457)  loss_objectness: 0.0898 (0.0992)  loss_rpn_box_reg: 0.0217 (0.0331)  time: 0.2702  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [21]  [ 940/1229]  eta: 0:01:18  lr: 0.000001  loss: 0.3352 (0.4306)  loss_classifier: 0.1273 (0.1529)  loss_box_reg: 0.0987 (0.1459)  loss_objectness: 0.0762 (0.0989)  loss_rpn_box_reg: 0.0190 (0.0329)  time: 0.2714  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [21]  [ 950/1229]  eta: 0:01:16  lr: 0.000001  loss: 0.3210 (0.4301)  loss_classifier: 0.0840 (0.1527)  loss_box_reg: 0.0817 (0.1453)  loss_objectness: 0.0884 (0.0991)  loss_rpn_box_reg: 0.0122 (0.0330)  time: 0.2665  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [21]  [ 960/1229]  eta: 0:01:13  lr: 0.000001  loss: 0.3851 (0.4308)  loss_classifier: 0.1061 (0.1528)  loss_box_reg: 0.0891 (0.1455)  loss_objectness: 0.1095 (0.0992)  loss_rpn_box_reg: 0.0341 (0.0333)  time: 0.2678  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [21]  [ 970/1229]  eta: 0:01:10  lr: 0.000001  loss: 0.4328 (0.4304)  loss_classifier: 0.1370 (0.1528)  loss_box_reg: 0.0891 (0.1452)  loss_objectness: 0.0893 (0.0992)  loss_rpn_box_reg: 0.0230 (0.0332)  time: 0.2743  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [21]  [ 980/1229]  eta: 0:01:08  lr: 0.000001  loss: 0.2754 (0.4299)  loss_classifier: 0.1021 (0.1526)  loss_box_reg: 0.0798 (0.1450)  loss_objectness: 0.0812 (0.0992)  loss_rpn_box_reg: 0.0107 (0.0331)  time: 0.2797  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [21]  [ 990/1229]  eta: 0:01:05  lr: 0.000001  loss: 0.4244 (0.4306)  loss_classifier: 0.1566 (0.1528)  loss_box_reg: 0.0912 (0.1451)  loss_objectness: 0.0968 (0.0993)  loss_rpn_box_reg: 0.0198 (0.0334)  time: 0.2738  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [21]  [1000/1229]  eta: 0:01:02  lr: 0.000001  loss: 0.4308 (0.4301)  loss_classifier: 0.1510 (0.1527)  loss_box_reg: 0.1183 (0.1448)  loss_objectness: 0.0884 (0.0993)  loss_rpn_box_reg: 0.0254 (0.0333)  time: 0.2691  data: 0.1295  max mem: 1751\n",
      "Training Epoch: [21]  [1010/1229]  eta: 0:00:59  lr: 0.000001  loss: 0.4069 (0.4296)  loss_classifier: 0.1504 (0.1526)  loss_box_reg: 0.1086 (0.1446)  loss_objectness: 0.0791 (0.0992)  loss_rpn_box_reg: 0.0166 (0.0332)  time: 0.2706  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [21]  [1020/1229]  eta: 0:00:57  lr: 0.000001  loss: 0.4483 (0.4306)  loss_classifier: 0.1704 (0.1528)  loss_box_reg: 0.1235 (0.1452)  loss_objectness: 0.0869 (0.0991)  loss_rpn_box_reg: 0.0211 (0.0334)  time: 0.2710  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [21]  [1030/1229]  eta: 0:00:54  lr: 0.000001  loss: 0.4106 (0.4307)  loss_classifier: 0.1479 (0.1529)  loss_box_reg: 0.1415 (0.1452)  loss_objectness: 0.0869 (0.0992)  loss_rpn_box_reg: 0.0225 (0.0334)  time: 0.2771  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [21]  [1040/1229]  eta: 0:00:51  lr: 0.000001  loss: 0.4106 (0.4307)  loss_classifier: 0.1471 (0.1529)  loss_box_reg: 0.1415 (0.1451)  loss_objectness: 0.0629 (0.0993)  loss_rpn_box_reg: 0.0198 (0.0334)  time: 0.2796  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [21]  [1050/1229]  eta: 0:00:48  lr: 0.000001  loss: 0.3601 (0.4303)  loss_classifier: 0.1471 (0.1528)  loss_box_reg: 0.1161 (0.1449)  loss_objectness: 0.0922 (0.0993)  loss_rpn_box_reg: 0.0193 (0.0333)  time: 0.2749  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [21]  [1060/1229]  eta: 0:00:46  lr: 0.000001  loss: 0.3288 (0.4300)  loss_classifier: 0.1176 (0.1526)  loss_box_reg: 0.0952 (0.1446)  loss_objectness: 0.0943 (0.0993)  loss_rpn_box_reg: 0.0182 (0.0334)  time: 0.2782  data: 0.1296  max mem: 1751\n",
      "Training Epoch: [21]  [1070/1229]  eta: 0:00:43  lr: 0.000001  loss: 0.3655 (0.4301)  loss_classifier: 0.1257 (0.1527)  loss_box_reg: 0.1107 (0.1446)  loss_objectness: 0.1003 (0.0994)  loss_rpn_box_reg: 0.0290 (0.0334)  time: 0.2854  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [21]  [1080/1229]  eta: 0:00:40  lr: 0.000001  loss: 0.3861 (0.4300)  loss_classifier: 0.1306 (0.1527)  loss_box_reg: 0.1196 (0.1445)  loss_objectness: 0.0957 (0.0994)  loss_rpn_box_reg: 0.0212 (0.0334)  time: 0.2752  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [21]  [1090/1229]  eta: 0:00:37  lr: 0.000001  loss: 0.3798 (0.4299)  loss_classifier: 0.1390 (0.1527)  loss_box_reg: 0.1392 (0.1446)  loss_objectness: 0.0734 (0.0992)  loss_rpn_box_reg: 0.0176 (0.0333)  time: 0.2699  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [21]  [1100/1229]  eta: 0:00:35  lr: 0.000001  loss: 0.4118 (0.4298)  loss_classifier: 0.1447 (0.1527)  loss_box_reg: 0.1482 (0.1446)  loss_objectness: 0.0695 (0.0993)  loss_rpn_box_reg: 0.0204 (0.0332)  time: 0.2765  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [21]  [1110/1229]  eta: 0:00:32  lr: 0.000001  loss: 0.4626 (0.4309)  loss_classifier: 0.1904 (0.1532)  loss_box_reg: 0.1534 (0.1450)  loss_objectness: 0.0901 (0.0995)  loss_rpn_box_reg: 0.0181 (0.0332)  time: 0.2759  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [21]  [1120/1229]  eta: 0:00:29  lr: 0.000001  loss: 0.4192 (0.4303)  loss_classifier: 0.1549 (0.1531)  loss_box_reg: 0.1385 (0.1448)  loss_objectness: 0.0987 (0.0994)  loss_rpn_box_reg: 0.0118 (0.0330)  time: 0.2710  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [21]  [1130/1229]  eta: 0:00:27  lr: 0.000001  loss: 0.3772 (0.4307)  loss_classifier: 0.1227 (0.1531)  loss_box_reg: 0.1011 (0.1449)  loss_objectness: 0.1001 (0.0996)  loss_rpn_box_reg: 0.0179 (0.0331)  time: 0.2759  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [21]  [1140/1229]  eta: 0:00:24  lr: 0.000001  loss: 0.4573 (0.4317)  loss_classifier: 0.1500 (0.1534)  loss_box_reg: 0.1434 (0.1454)  loss_objectness: 0.0972 (0.0996)  loss_rpn_box_reg: 0.0420 (0.0333)  time: 0.2786  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [21]  [1150/1229]  eta: 0:00:21  lr: 0.000001  loss: 0.5525 (0.4328)  loss_classifier: 0.1567 (0.1537)  loss_box_reg: 0.1450 (0.1458)  loss_objectness: 0.1010 (0.0999)  loss_rpn_box_reg: 0.0420 (0.0334)  time: 0.2734  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [21]  [1160/1229]  eta: 0:00:18  lr: 0.000001  loss: 0.4787 (0.4331)  loss_classifier: 0.1626 (0.1538)  loss_box_reg: 0.1271 (0.1461)  loss_objectness: 0.0927 (0.0999)  loss_rpn_box_reg: 0.0286 (0.0333)  time: 0.2741  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [21]  [1170/1229]  eta: 0:00:16  lr: 0.000001  loss: 0.5508 (0.4349)  loss_classifier: 0.2015 (0.1544)  loss_box_reg: 0.1901 (0.1467)  loss_objectness: 0.0927 (0.1003)  loss_rpn_box_reg: 0.0253 (0.0335)  time: 0.2735  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [21]  [1180/1229]  eta: 0:00:13  lr: 0.000001  loss: 0.5764 (0.4361)  loss_classifier: 0.2015 (0.1547)  loss_box_reg: 0.1875 (0.1473)  loss_objectness: 0.1051 (0.1004)  loss_rpn_box_reg: 0.0289 (0.0337)  time: 0.2684  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [21]  [1190/1229]  eta: 0:00:10  lr: 0.000001  loss: 0.4771 (0.4372)  loss_classifier: 0.1896 (0.1551)  loss_box_reg: 0.1455 (0.1477)  loss_objectness: 0.1007 (0.1007)  loss_rpn_box_reg: 0.0270 (0.0337)  time: 0.2710  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [21]  [1200/1229]  eta: 0:00:07  lr: 0.000001  loss: 0.4273 (0.4374)  loss_classifier: 0.1530 (0.1553)  loss_box_reg: 0.1200 (0.1477)  loss_objectness: 0.1007 (0.1008)  loss_rpn_box_reg: 0.0215 (0.0337)  time: 0.2781  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [21]  [1210/1229]  eta: 0:00:05  lr: 0.000001  loss: 0.3799 (0.4374)  loss_classifier: 0.1404 (0.1553)  loss_box_reg: 0.1230 (0.1477)  loss_objectness: 0.0930 (0.1007)  loss_rpn_box_reg: 0.0257 (0.0338)  time: 0.2777  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [21]  [1220/1229]  eta: 0:00:02  lr: 0.000001  loss: 0.3812 (0.4376)  loss_classifier: 0.1326 (0.1553)  loss_box_reg: 0.1116 (0.1477)  loss_objectness: 0.0981 (0.1007)  loss_rpn_box_reg: 0.0297 (0.0339)  time: 0.2690  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [21]  [1228/1229]  eta: 0:00:00  lr: 0.000001  loss: 0.3558 (0.4371)  loss_classifier: 0.1124 (0.1551)  loss_box_reg: 0.0964 (0.1476)  loss_objectness: 0.0837 (0.1006)  loss_rpn_box_reg: 0.0280 (0.0338)  time: 0.2683  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [21] Total time: 0:05:36 (0.2735 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:24  model_time: 0.2410 (0.2410)  evaluator_time: 0.0020 (0.0020)  time: 0.2750  data: 0.0300  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0780 (0.0816)  evaluator_time: 0.0040 (0.0086)  time: 0.1268  data: 0.0356  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0830 (0.0807)  evaluator_time: 0.0030 (0.0078)  time: 0.1198  data: 0.0305  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0730 (0.0800)  evaluator_time: 0.0040 (0.0076)  time: 0.1197  data: 0.0350  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0730 (0.0799)  evaluator_time: 0.0030 (0.0076)  time: 0.1163  data: 0.0335  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1234 s / it)\n",
      "Averaged stats: model_time: 0.0730 (0.0799)  evaluator_time: 0.0030 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [21]  [  0/308]  eta: 0:00:36  lr: 0.000001  loss: 0.1683 (0.1683)  loss_classifier: 0.0591 (0.0591)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0292 (0.0292)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1200  data: 0.0271  max mem: 1751\n",
      "Testing Epoch: [21]  [100/308]  eta: 0:00:28  lr: 0.000001  loss: 0.3131 (0.4802)  loss_classifier: 0.1343 (0.1545)  loss_box_reg: 0.1175 (0.1724)  loss_objectness: 0.0540 (0.1014)  loss_rpn_box_reg: 0.0186 (0.0519)  time: 0.1383  data: 0.0373  max mem: 1751\n",
      "Testing Epoch: [21]  [200/308]  eta: 0:00:14  lr: 0.000001  loss: 0.3519 (0.4565)  loss_classifier: 0.1387 (0.1490)  loss_box_reg: 0.1251 (0.1633)  loss_objectness: 0.0641 (0.0952)  loss_rpn_box_reg: 0.0197 (0.0491)  time: 0.1366  data: 0.0315  max mem: 1751\n",
      "Testing Epoch: [21]  [300/308]  eta: 0:00:01  lr: 0.000001  loss: 0.4693 (0.4535)  loss_classifier: 0.1521 (0.1492)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0771 (0.0927)  loss_rpn_box_reg: 0.0265 (0.0475)  time: 0.1312  data: 0.0362  max mem: 1751\n",
      "Testing Epoch: [21]  [307/308]  eta: 0:00:00  lr: 0.000001  loss: 0.4693 (0.4537)  loss_classifier: 0.1860 (0.1495)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0671 (0.0928)  loss_rpn_box_reg: 0.0271 (0.0470)  time: 0.1300  data: 0.0354  max mem: 1751\n",
      "Testing Epoch: [21] Total time: 0:00:42 (0.1370 s / it)\n",
      "Training Epoch: [22]  [   0/1229]  eta: 0:05:19  lr: 0.000001  loss: 0.1261 (0.1261)  loss_classifier: 0.0493 (0.0493)  loss_box_reg: 0.0334 (0.0334)  loss_objectness: 0.0367 (0.0367)  loss_rpn_box_reg: 0.0067 (0.0067)  time: 0.2600  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [22]  [  10/1229]  eta: 0:05:25  lr: 0.000001  loss: 0.3996 (0.4229)  loss_classifier: 0.1326 (0.1585)  loss_box_reg: 0.1714 (0.1480)  loss_objectness: 0.0848 (0.0905)  loss_rpn_box_reg: 0.0259 (0.0258)  time: 0.2668  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [22]  [  20/1229]  eta: 0:05:25  lr: 0.000001  loss: 0.4161 (0.5111)  loss_classifier: 0.1553 (0.1759)  loss_box_reg: 0.1377 (0.1871)  loss_objectness: 0.0878 (0.1056)  loss_rpn_box_reg: 0.0316 (0.0425)  time: 0.2695  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [22]  [  30/1229]  eta: 0:05:24  lr: 0.000001  loss: 0.4501 (0.5114)  loss_classifier: 0.1694 (0.1774)  loss_box_reg: 0.1525 (0.1786)  loss_objectness: 0.1084 (0.1132)  loss_rpn_box_reg: 0.0403 (0.0422)  time: 0.2730  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [22]  [  40/1229]  eta: 0:05:20  lr: 0.000001  loss: 0.3749 (0.4699)  loss_classifier: 0.1415 (0.1634)  loss_box_reg: 0.1085 (0.1614)  loss_objectness: 0.0863 (0.1064)  loss_rpn_box_reg: 0.0280 (0.0386)  time: 0.2703  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [22]  [  50/1229]  eta: 0:05:17  lr: 0.000001  loss: 0.3112 (0.4767)  loss_classifier: 0.1207 (0.1660)  loss_box_reg: 0.1039 (0.1683)  loss_objectness: 0.0779 (0.1057)  loss_rpn_box_reg: 0.0158 (0.0367)  time: 0.2670  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [22]  [  60/1229]  eta: 0:05:15  lr: 0.000001  loss: 0.4391 (0.4671)  loss_classifier: 0.1414 (0.1637)  loss_box_reg: 0.1307 (0.1632)  loss_objectness: 0.0943 (0.1055)  loss_rpn_box_reg: 0.0178 (0.0347)  time: 0.2698  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [22]  [  70/1229]  eta: 0:05:12  lr: 0.000001  loss: 0.4197 (0.4524)  loss_classifier: 0.1414 (0.1604)  loss_box_reg: 0.1362 (0.1561)  loss_objectness: 0.0928 (0.1038)  loss_rpn_box_reg: 0.0164 (0.0320)  time: 0.2696  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [22]  [  80/1229]  eta: 0:05:10  lr: 0.000001  loss: 0.3561 (0.4430)  loss_classifier: 0.1279 (0.1577)  loss_box_reg: 0.0894 (0.1518)  loss_objectness: 0.0770 (0.1026)  loss_rpn_box_reg: 0.0166 (0.0309)  time: 0.2702  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [22]  [  90/1229]  eta: 0:05:07  lr: 0.000001  loss: 0.3544 (0.4442)  loss_classifier: 0.1279 (0.1575)  loss_box_reg: 0.1035 (0.1522)  loss_objectness: 0.0711 (0.1006)  loss_rpn_box_reg: 0.0180 (0.0339)  time: 0.2703  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [22]  [ 100/1229]  eta: 0:05:05  lr: 0.000001  loss: 0.3727 (0.4383)  loss_classifier: 0.1196 (0.1555)  loss_box_reg: 0.1066 (0.1510)  loss_objectness: 0.0691 (0.0991)  loss_rpn_box_reg: 0.0174 (0.0328)  time: 0.2736  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [22]  [ 110/1229]  eta: 0:05:03  lr: 0.000001  loss: 0.4054 (0.4456)  loss_classifier: 0.1196 (0.1573)  loss_box_reg: 0.1479 (0.1546)  loss_objectness: 0.0676 (0.0987)  loss_rpn_box_reg: 0.0245 (0.0349)  time: 0.2775  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [22]  [ 120/1229]  eta: 0:05:01  lr: 0.000001  loss: 0.4120 (0.4455)  loss_classifier: 0.1580 (0.1583)  loss_box_reg: 0.1534 (0.1545)  loss_objectness: 0.0711 (0.0984)  loss_rpn_box_reg: 0.0245 (0.0342)  time: 0.2760  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [22]  [ 130/1229]  eta: 0:04:57  lr: 0.000001  loss: 0.4051 (0.4384)  loss_classifier: 0.1379 (0.1566)  loss_box_reg: 0.1505 (0.1519)  loss_objectness: 0.0760 (0.0967)  loss_rpn_box_reg: 0.0188 (0.0332)  time: 0.2708  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [22]  [ 140/1229]  eta: 0:04:55  lr: 0.000001  loss: 0.3335 (0.4308)  loss_classifier: 0.1215 (0.1546)  loss_box_reg: 0.0908 (0.1478)  loss_objectness: 0.0749 (0.0962)  loss_rpn_box_reg: 0.0158 (0.0321)  time: 0.2693  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [22]  [ 150/1229]  eta: 0:04:52  lr: 0.000001  loss: 0.4008 (0.4324)  loss_classifier: 0.1490 (0.1560)  loss_box_reg: 0.1055 (0.1480)  loss_objectness: 0.0815 (0.0966)  loss_rpn_box_reg: 0.0168 (0.0318)  time: 0.2713  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [22]  [ 160/1229]  eta: 0:04:49  lr: 0.000001  loss: 0.3393 (0.4270)  loss_classifier: 0.1276 (0.1537)  loss_box_reg: 0.1130 (0.1447)  loss_objectness: 0.0815 (0.0974)  loss_rpn_box_reg: 0.0175 (0.0311)  time: 0.2676  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [22]  [ 170/1229]  eta: 0:04:46  lr: 0.000001  loss: 0.3503 (0.4304)  loss_classifier: 0.1357 (0.1556)  loss_box_reg: 0.1304 (0.1467)  loss_objectness: 0.0935 (0.0973)  loss_rpn_box_reg: 0.0186 (0.0308)  time: 0.2683  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [22]  [ 180/1229]  eta: 0:04:43  lr: 0.000001  loss: 0.4116 (0.4296)  loss_classifier: 0.1541 (0.1553)  loss_box_reg: 0.1504 (0.1457)  loss_objectness: 0.0880 (0.0981)  loss_rpn_box_reg: 0.0189 (0.0304)  time: 0.2699  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [22]  [ 190/1229]  eta: 0:04:41  lr: 0.000001  loss: 0.3820 (0.4323)  loss_classifier: 0.1359 (0.1563)  loss_box_reg: 0.1057 (0.1457)  loss_objectness: 0.0855 (0.0993)  loss_rpn_box_reg: 0.0262 (0.0310)  time: 0.2715  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [22]  [ 200/1229]  eta: 0:04:38  lr: 0.000001  loss: 0.3758 (0.4292)  loss_classifier: 0.1331 (0.1550)  loss_box_reg: 0.0930 (0.1443)  loss_objectness: 0.0983 (0.0992)  loss_rpn_box_reg: 0.0261 (0.0308)  time: 0.2721  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [22]  [ 210/1229]  eta: 0:04:35  lr: 0.000001  loss: 0.4547 (0.4322)  loss_classifier: 0.1532 (0.1554)  loss_box_reg: 0.1213 (0.1451)  loss_objectness: 0.1018 (0.0995)  loss_rpn_box_reg: 0.0261 (0.0322)  time: 0.2699  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [22]  [ 220/1229]  eta: 0:04:33  lr: 0.000001  loss: 0.4547 (0.4301)  loss_classifier: 0.1597 (0.1550)  loss_box_reg: 0.1373 (0.1442)  loss_objectness: 0.0865 (0.0984)  loss_rpn_box_reg: 0.0292 (0.0324)  time: 0.2728  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [22]  [ 230/1229]  eta: 0:04:30  lr: 0.000001  loss: 0.3329 (0.4250)  loss_classifier: 0.1017 (0.1527)  loss_box_reg: 0.0977 (0.1425)  loss_objectness: 0.0617 (0.0975)  loss_rpn_box_reg: 0.0185 (0.0323)  time: 0.2713  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [22]  [ 240/1229]  eta: 0:04:28  lr: 0.000001  loss: 0.2727 (0.4216)  loss_classifier: 0.0973 (0.1514)  loss_box_reg: 0.0684 (0.1409)  loss_objectness: 0.0645 (0.0975)  loss_rpn_box_reg: 0.0155 (0.0318)  time: 0.2713  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [22]  [ 250/1229]  eta: 0:04:25  lr: 0.000001  loss: 0.3124 (0.4203)  loss_classifier: 0.1210 (0.1513)  loss_box_reg: 0.0870 (0.1407)  loss_objectness: 0.0762 (0.0970)  loss_rpn_box_reg: 0.0155 (0.0314)  time: 0.2764  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [22]  [ 260/1229]  eta: 0:04:22  lr: 0.000001  loss: 0.4053 (0.4223)  loss_classifier: 0.1416 (0.1519)  loss_box_reg: 0.1281 (0.1412)  loss_objectness: 0.0957 (0.0976)  loss_rpn_box_reg: 0.0211 (0.0317)  time: 0.2698  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [22]  [ 270/1229]  eta: 0:04:19  lr: 0.000001  loss: 0.4053 (0.4213)  loss_classifier: 0.1416 (0.1514)  loss_box_reg: 0.1011 (0.1405)  loss_objectness: 0.0987 (0.0980)  loss_rpn_box_reg: 0.0252 (0.0314)  time: 0.2656  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [22]  [ 280/1229]  eta: 0:04:17  lr: 0.000001  loss: 0.3622 (0.4208)  loss_classifier: 0.1299 (0.1512)  loss_box_reg: 0.1046 (0.1406)  loss_objectness: 0.1052 (0.0979)  loss_rpn_box_reg: 0.0186 (0.0311)  time: 0.2730  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [22]  [ 290/1229]  eta: 0:04:14  lr: 0.000001  loss: 0.3824 (0.4226)  loss_classifier: 0.1343 (0.1518)  loss_box_reg: 0.1326 (0.1415)  loss_objectness: 0.0908 (0.0976)  loss_rpn_box_reg: 0.0154 (0.0316)  time: 0.2745  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [22]  [ 300/1229]  eta: 0:04:11  lr: 0.000001  loss: 0.4728 (0.4241)  loss_classifier: 0.1562 (0.1521)  loss_box_reg: 0.1388 (0.1419)  loss_objectness: 0.0925 (0.0985)  loss_rpn_box_reg: 0.0275 (0.0316)  time: 0.2735  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [22]  [ 310/1229]  eta: 0:04:09  lr: 0.000001  loss: 0.4264 (0.4218)  loss_classifier: 0.1447 (0.1516)  loss_box_reg: 0.1322 (0.1412)  loss_objectness: 0.0925 (0.0980)  loss_rpn_box_reg: 0.0226 (0.0311)  time: 0.2765  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [22]  [ 320/1229]  eta: 0:04:06  lr: 0.000001  loss: 0.3387 (0.4219)  loss_classifier: 0.1241 (0.1518)  loss_box_reg: 0.1036 (0.1409)  loss_objectness: 0.0854 (0.0982)  loss_rpn_box_reg: 0.0190 (0.0310)  time: 0.2757  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [22]  [ 330/1229]  eta: 0:04:04  lr: 0.000001  loss: 0.3360 (0.4210)  loss_classifier: 0.1313 (0.1513)  loss_box_reg: 0.0981 (0.1403)  loss_objectness: 0.0797 (0.0982)  loss_rpn_box_reg: 0.0214 (0.0312)  time: 0.2758  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [22]  [ 340/1229]  eta: 0:04:01  lr: 0.000001  loss: 0.3360 (0.4213)  loss_classifier: 0.1232 (0.1509)  loss_box_reg: 0.0981 (0.1407)  loss_objectness: 0.0785 (0.0982)  loss_rpn_box_reg: 0.0214 (0.0316)  time: 0.2747  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [22]  [ 350/1229]  eta: 0:03:58  lr: 0.000001  loss: 0.3983 (0.4221)  loss_classifier: 0.1390 (0.1509)  loss_box_reg: 0.1085 (0.1406)  loss_objectness: 0.0884 (0.0989)  loss_rpn_box_reg: 0.0246 (0.0317)  time: 0.2702  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [22]  [ 360/1229]  eta: 0:03:56  lr: 0.000001  loss: 0.3983 (0.4227)  loss_classifier: 0.1597 (0.1514)  loss_box_reg: 0.1028 (0.1407)  loss_objectness: 0.0967 (0.0991)  loss_rpn_box_reg: 0.0195 (0.0316)  time: 0.2715  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [22]  [ 370/1229]  eta: 0:03:53  lr: 0.000001  loss: 0.3598 (0.4239)  loss_classifier: 0.1278 (0.1517)  loss_box_reg: 0.1445 (0.1412)  loss_objectness: 0.0895 (0.0995)  loss_rpn_box_reg: 0.0195 (0.0316)  time: 0.2752  data: 0.1368  max mem: 1751\n",
      "Training Epoch: [22]  [ 380/1229]  eta: 0:03:50  lr: 0.000001  loss: 0.3648 (0.4248)  loss_classifier: 0.1334 (0.1521)  loss_box_reg: 0.1445 (0.1417)  loss_objectness: 0.0940 (0.0998)  loss_rpn_box_reg: 0.0194 (0.0313)  time: 0.2730  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [22]  [ 390/1229]  eta: 0:03:47  lr: 0.000001  loss: 0.3648 (0.4252)  loss_classifier: 0.1270 (0.1518)  loss_box_reg: 0.1034 (0.1415)  loss_objectness: 0.0940 (0.1000)  loss_rpn_box_reg: 0.0194 (0.0319)  time: 0.2702  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [22]  [ 400/1229]  eta: 0:03:45  lr: 0.000001  loss: 0.4224 (0.4252)  loss_classifier: 0.1270 (0.1517)  loss_box_reg: 0.1159 (0.1418)  loss_objectness: 0.0829 (0.0996)  loss_rpn_box_reg: 0.0237 (0.0321)  time: 0.2718  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [22]  [ 410/1229]  eta: 0:03:42  lr: 0.000001  loss: 0.3977 (0.4244)  loss_classifier: 0.1506 (0.1517)  loss_box_reg: 0.1379 (0.1416)  loss_objectness: 0.0744 (0.0994)  loss_rpn_box_reg: 0.0202 (0.0318)  time: 0.2729  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [22]  [ 420/1229]  eta: 0:03:39  lr: 0.000001  loss: 0.3663 (0.4231)  loss_classifier: 0.1331 (0.1512)  loss_box_reg: 0.1281 (0.1413)  loss_objectness: 0.0744 (0.0989)  loss_rpn_box_reg: 0.0207 (0.0316)  time: 0.2730  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [22]  [ 430/1229]  eta: 0:03:37  lr: 0.000001  loss: 0.3921 (0.4255)  loss_classifier: 0.1331 (0.1518)  loss_box_reg: 0.1350 (0.1427)  loss_objectness: 0.0765 (0.0991)  loss_rpn_box_reg: 0.0280 (0.0319)  time: 0.2736  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [22]  [ 440/1229]  eta: 0:03:34  lr: 0.000001  loss: 0.3972 (0.4252)  loss_classifier: 0.1503 (0.1517)  loss_box_reg: 0.1549 (0.1428)  loss_objectness: 0.0882 (0.0989)  loss_rpn_box_reg: 0.0214 (0.0318)  time: 0.2783  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [22]  [ 450/1229]  eta: 0:03:32  lr: 0.000001  loss: 0.3204 (0.4260)  loss_classifier: 0.1337 (0.1516)  loss_box_reg: 0.1181 (0.1430)  loss_objectness: 0.0798 (0.0988)  loss_rpn_box_reg: 0.0162 (0.0326)  time: 0.2808  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [22]  [ 460/1229]  eta: 0:03:29  lr: 0.000001  loss: 0.2682 (0.4242)  loss_classifier: 0.1030 (0.1511)  loss_box_reg: 0.0804 (0.1425)  loss_objectness: 0.0654 (0.0982)  loss_rpn_box_reg: 0.0139 (0.0324)  time: 0.2798  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [22]  [ 470/1229]  eta: 0:03:26  lr: 0.000001  loss: 0.3054 (0.4232)  loss_classifier: 0.1072 (0.1508)  loss_box_reg: 0.0948 (0.1423)  loss_objectness: 0.0637 (0.0978)  loss_rpn_box_reg: 0.0145 (0.0322)  time: 0.2785  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [22]  [ 480/1229]  eta: 0:03:24  lr: 0.000001  loss: 0.4463 (0.4254)  loss_classifier: 0.1727 (0.1516)  loss_box_reg: 0.1443 (0.1435)  loss_objectness: 0.0600 (0.0979)  loss_rpn_box_reg: 0.0236 (0.0325)  time: 0.2832  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [22]  [ 490/1229]  eta: 0:03:21  lr: 0.000001  loss: 0.4641 (0.4268)  loss_classifier: 0.1836 (0.1520)  loss_box_reg: 0.1642 (0.1442)  loss_objectness: 0.1111 (0.0981)  loss_rpn_box_reg: 0.0265 (0.0324)  time: 0.2812  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [22]  [ 500/1229]  eta: 0:03:19  lr: 0.000001  loss: 0.4073 (0.4262)  loss_classifier: 0.1454 (0.1518)  loss_box_reg: 0.1237 (0.1441)  loss_objectness: 0.1033 (0.0982)  loss_rpn_box_reg: 0.0161 (0.0321)  time: 0.2755  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [22]  [ 510/1229]  eta: 0:03:16  lr: 0.000001  loss: 0.3512 (0.4265)  loss_classifier: 0.1317 (0.1518)  loss_box_reg: 0.1176 (0.1441)  loss_objectness: 0.0889 (0.0984)  loss_rpn_box_reg: 0.0215 (0.0322)  time: 0.2784  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [22]  [ 520/1229]  eta: 0:03:13  lr: 0.000001  loss: 0.3954 (0.4273)  loss_classifier: 0.1449 (0.1520)  loss_box_reg: 0.1182 (0.1445)  loss_objectness: 0.1009 (0.0987)  loss_rpn_box_reg: 0.0266 (0.0321)  time: 0.2733  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [22]  [ 530/1229]  eta: 0:03:10  lr: 0.000001  loss: 0.4095 (0.4270)  loss_classifier: 0.1459 (0.1521)  loss_box_reg: 0.1219 (0.1444)  loss_objectness: 0.0998 (0.0986)  loss_rpn_box_reg: 0.0231 (0.0320)  time: 0.2719  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [22]  [ 540/1229]  eta: 0:03:08  lr: 0.000001  loss: 0.5413 (0.4321)  loss_classifier: 0.1841 (0.1537)  loss_box_reg: 0.1534 (0.1463)  loss_objectness: 0.0998 (0.0994)  loss_rpn_box_reg: 0.0292 (0.0327)  time: 0.2733  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [22]  [ 550/1229]  eta: 0:03:05  lr: 0.000001  loss: 0.5472 (0.4311)  loss_classifier: 0.1836 (0.1533)  loss_box_reg: 0.1500 (0.1462)  loss_objectness: 0.0996 (0.0991)  loss_rpn_box_reg: 0.0292 (0.0325)  time: 0.2731  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [22]  [ 560/1229]  eta: 0:03:02  lr: 0.000001  loss: 0.3851 (0.4317)  loss_classifier: 0.1237 (0.1533)  loss_box_reg: 0.1240 (0.1465)  loss_objectness: 0.0872 (0.0991)  loss_rpn_box_reg: 0.0186 (0.0329)  time: 0.2712  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [22]  [ 570/1229]  eta: 0:02:59  lr: 0.000001  loss: 0.3851 (0.4306)  loss_classifier: 0.1237 (0.1529)  loss_box_reg: 0.1127 (0.1458)  loss_objectness: 0.0877 (0.0989)  loss_rpn_box_reg: 0.0229 (0.0331)  time: 0.2686  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [22]  [ 580/1229]  eta: 0:02:57  lr: 0.000001  loss: 0.3335 (0.4293)  loss_classifier: 0.1005 (0.1524)  loss_box_reg: 0.0750 (0.1454)  loss_objectness: 0.0835 (0.0986)  loss_rpn_box_reg: 0.0134 (0.0329)  time: 0.2739  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [22]  [ 590/1229]  eta: 0:02:54  lr: 0.000001  loss: 0.3335 (0.4296)  loss_classifier: 0.1069 (0.1525)  loss_box_reg: 0.1011 (0.1452)  loss_objectness: 0.0958 (0.0991)  loss_rpn_box_reg: 0.0191 (0.0328)  time: 0.2742  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [22]  [ 600/1229]  eta: 0:02:51  lr: 0.000001  loss: 0.4825 (0.4317)  loss_classifier: 0.1793 (0.1531)  loss_box_reg: 0.1589 (0.1462)  loss_objectness: 0.1169 (0.0995)  loss_rpn_box_reg: 0.0263 (0.0328)  time: 0.2750  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [22]  [ 610/1229]  eta: 0:02:49  lr: 0.000001  loss: 0.4622 (0.4310)  loss_classifier: 0.1638 (0.1531)  loss_box_reg: 0.1414 (0.1459)  loss_objectness: 0.1067 (0.0995)  loss_rpn_box_reg: 0.0180 (0.0326)  time: 0.2756  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [22]  [ 620/1229]  eta: 0:02:46  lr: 0.000001  loss: 0.4992 (0.4337)  loss_classifier: 0.1810 (0.1539)  loss_box_reg: 0.1453 (0.1470)  loss_objectness: 0.0866 (0.1000)  loss_rpn_box_reg: 0.0242 (0.0329)  time: 0.2746  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [22]  [ 630/1229]  eta: 0:02:43  lr: 0.000001  loss: 0.5191 (0.4341)  loss_classifier: 0.1862 (0.1541)  loss_box_reg: 0.1881 (0.1470)  loss_objectness: 0.0866 (0.1001)  loss_rpn_box_reg: 0.0298 (0.0329)  time: 0.2765  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [22]  [ 640/1229]  eta: 0:02:40  lr: 0.000001  loss: 0.3806 (0.4346)  loss_classifier: 0.1256 (0.1543)  loss_box_reg: 0.1057 (0.1470)  loss_objectness: 0.0881 (0.1004)  loss_rpn_box_reg: 0.0154 (0.0329)  time: 0.2724  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [22]  [ 650/1229]  eta: 0:02:38  lr: 0.000001  loss: 0.3806 (0.4339)  loss_classifier: 0.1471 (0.1542)  loss_box_reg: 0.1057 (0.1466)  loss_objectness: 0.0963 (0.1003)  loss_rpn_box_reg: 0.0200 (0.0328)  time: 0.2697  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [22]  [ 660/1229]  eta: 0:02:35  lr: 0.000001  loss: 0.3443 (0.4349)  loss_classifier: 0.1268 (0.1546)  loss_box_reg: 0.0972 (0.1472)  loss_objectness: 0.0817 (0.1002)  loss_rpn_box_reg: 0.0206 (0.0328)  time: 0.2727  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [22]  [ 670/1229]  eta: 0:02:32  lr: 0.000001  loss: 0.3855 (0.4358)  loss_classifier: 0.1417 (0.1549)  loss_box_reg: 0.1273 (0.1474)  loss_objectness: 0.0818 (0.1005)  loss_rpn_box_reg: 0.0196 (0.0330)  time: 0.2745  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [22]  [ 680/1229]  eta: 0:02:29  lr: 0.000001  loss: 0.3743 (0.4347)  loss_classifier: 0.1385 (0.1547)  loss_box_reg: 0.1395 (0.1474)  loss_objectness: 0.0662 (0.1000)  loss_rpn_box_reg: 0.0175 (0.0327)  time: 0.2748  data: 0.1372  max mem: 1751\n",
      "Training Epoch: [22]  [ 690/1229]  eta: 0:02:27  lr: 0.000001  loss: 0.3627 (0.4350)  loss_classifier: 0.1351 (0.1548)  loss_box_reg: 0.1048 (0.1472)  loss_objectness: 0.0643 (0.1000)  loss_rpn_box_reg: 0.0217 (0.0330)  time: 0.2771  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [22]  [ 700/1229]  eta: 0:02:24  lr: 0.000001  loss: 0.3627 (0.4345)  loss_classifier: 0.1215 (0.1546)  loss_box_reg: 0.1038 (0.1470)  loss_objectness: 0.0808 (0.0999)  loss_rpn_box_reg: 0.0323 (0.0329)  time: 0.2722  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [22]  [ 710/1229]  eta: 0:02:21  lr: 0.000001  loss: 0.3528 (0.4335)  loss_classifier: 0.1215 (0.1542)  loss_box_reg: 0.1056 (0.1464)  loss_objectness: 0.0935 (0.1000)  loss_rpn_box_reg: 0.0218 (0.0330)  time: 0.2665  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [22]  [ 720/1229]  eta: 0:02:18  lr: 0.000001  loss: 0.3688 (0.4349)  loss_classifier: 0.1293 (0.1545)  loss_box_reg: 0.1092 (0.1466)  loss_objectness: 0.0937 (0.1007)  loss_rpn_box_reg: 0.0294 (0.0331)  time: 0.2714  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [22]  [ 730/1229]  eta: 0:02:16  lr: 0.000001  loss: 0.4475 (0.4360)  loss_classifier: 0.1473 (0.1547)  loss_box_reg: 0.1631 (0.1471)  loss_objectness: 0.0806 (0.1005)  loss_rpn_box_reg: 0.0355 (0.0336)  time: 0.2726  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [22]  [ 740/1229]  eta: 0:02:13  lr: 0.000001  loss: 0.3902 (0.4351)  loss_classifier: 0.1395 (0.1544)  loss_box_reg: 0.1364 (0.1468)  loss_objectness: 0.0764 (0.1004)  loss_rpn_box_reg: 0.0288 (0.0335)  time: 0.2799  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [22]  [ 750/1229]  eta: 0:02:10  lr: 0.000001  loss: 0.4404 (0.4361)  loss_classifier: 0.1384 (0.1546)  loss_box_reg: 0.1364 (0.1470)  loss_objectness: 0.0870 (0.1004)  loss_rpn_box_reg: 0.0283 (0.0340)  time: 0.2852  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [22]  [ 760/1229]  eta: 0:02:08  lr: 0.000001  loss: 0.4498 (0.4361)  loss_classifier: 0.1664 (0.1546)  loss_box_reg: 0.1219 (0.1466)  loss_objectness: 0.0870 (0.1007)  loss_rpn_box_reg: 0.0276 (0.0341)  time: 0.2743  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [22]  [ 770/1229]  eta: 0:02:05  lr: 0.000001  loss: 0.4063 (0.4361)  loss_classifier: 0.1627 (0.1546)  loss_box_reg: 0.1035 (0.1467)  loss_objectness: 0.0810 (0.1008)  loss_rpn_box_reg: 0.0229 (0.0340)  time: 0.2750  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [22]  [ 780/1229]  eta: 0:02:02  lr: 0.000001  loss: 0.3370 (0.4349)  loss_classifier: 0.1181 (0.1542)  loss_box_reg: 0.1006 (0.1463)  loss_objectness: 0.0794 (0.1006)  loss_rpn_box_reg: 0.0218 (0.0338)  time: 0.2760  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [22]  [ 790/1229]  eta: 0:02:00  lr: 0.000001  loss: 0.3054 (0.4337)  loss_classifier: 0.1171 (0.1537)  loss_box_reg: 0.1006 (0.1459)  loss_objectness: 0.0687 (0.1004)  loss_rpn_box_reg: 0.0133 (0.0338)  time: 0.2732  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [22]  [ 800/1229]  eta: 0:01:57  lr: 0.000001  loss: 0.3684 (0.4337)  loss_classifier: 0.1236 (0.1537)  loss_box_reg: 0.1194 (0.1457)  loss_objectness: 0.0739 (0.1003)  loss_rpn_box_reg: 0.0158 (0.0340)  time: 0.2720  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [22]  [ 810/1229]  eta: 0:01:54  lr: 0.000001  loss: 0.4059 (0.4341)  loss_classifier: 0.1357 (0.1538)  loss_box_reg: 0.1211 (0.1456)  loss_objectness: 0.0868 (0.1005)  loss_rpn_box_reg: 0.0168 (0.0343)  time: 0.2723  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [22]  [ 820/1229]  eta: 0:01:51  lr: 0.000001  loss: 0.3635 (0.4332)  loss_classifier: 0.1205 (0.1535)  loss_box_reg: 0.0995 (0.1451)  loss_objectness: 0.0981 (0.1005)  loss_rpn_box_reg: 0.0219 (0.0342)  time: 0.2701  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [22]  [ 830/1229]  eta: 0:01:49  lr: 0.000001  loss: 0.3563 (0.4321)  loss_classifier: 0.1108 (0.1530)  loss_box_reg: 0.0959 (0.1446)  loss_objectness: 0.0991 (0.1003)  loss_rpn_box_reg: 0.0211 (0.0341)  time: 0.2677  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [22]  [ 840/1229]  eta: 0:01:46  lr: 0.000001  loss: 0.2944 (0.4317)  loss_classifier: 0.0981 (0.1529)  loss_box_reg: 0.0898 (0.1448)  loss_objectness: 0.0656 (0.1000)  loss_rpn_box_reg: 0.0194 (0.0340)  time: 0.2760  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [22]  [ 850/1229]  eta: 0:01:43  lr: 0.000001  loss: 0.3596 (0.4316)  loss_classifier: 0.1448 (0.1529)  loss_box_reg: 0.1371 (0.1447)  loss_objectness: 0.0656 (0.1000)  loss_rpn_box_reg: 0.0170 (0.0339)  time: 0.2818  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [22]  [ 860/1229]  eta: 0:01:40  lr: 0.000001  loss: 0.4015 (0.4318)  loss_classifier: 0.1626 (0.1531)  loss_box_reg: 0.1371 (0.1447)  loss_objectness: 0.0830 (0.1000)  loss_rpn_box_reg: 0.0170 (0.0341)  time: 0.2819  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [22]  [ 870/1229]  eta: 0:01:38  lr: 0.000001  loss: 0.3963 (0.4318)  loss_classifier: 0.1434 (0.1531)  loss_box_reg: 0.1364 (0.1447)  loss_objectness: 0.0806 (0.1001)  loss_rpn_box_reg: 0.0169 (0.0340)  time: 0.2799  data: 0.1377  max mem: 1751\n",
      "Training Epoch: [22]  [ 880/1229]  eta: 0:01:35  lr: 0.000001  loss: 0.3859 (0.4312)  loss_classifier: 0.1384 (0.1529)  loss_box_reg: 0.1247 (0.1444)  loss_objectness: 0.0747 (0.0999)  loss_rpn_box_reg: 0.0186 (0.0339)  time: 0.2734  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [22]  [ 890/1229]  eta: 0:01:32  lr: 0.000001  loss: 0.3898 (0.4322)  loss_classifier: 0.1384 (0.1532)  loss_box_reg: 0.1199 (0.1447)  loss_objectness: 0.0867 (0.1000)  loss_rpn_box_reg: 0.0332 (0.0343)  time: 0.2707  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [22]  [ 900/1229]  eta: 0:01:29  lr: 0.000001  loss: 0.3546 (0.4317)  loss_classifier: 0.1390 (0.1531)  loss_box_reg: 0.1345 (0.1446)  loss_objectness: 0.0867 (0.0998)  loss_rpn_box_reg: 0.0179 (0.0342)  time: 0.2746  data: 0.1293  max mem: 1751\n",
      "Training Epoch: [22]  [ 910/1229]  eta: 0:01:27  lr: 0.000001  loss: 0.3782 (0.4315)  loss_classifier: 0.1361 (0.1531)  loss_box_reg: 0.1050 (0.1445)  loss_objectness: 0.0841 (0.0998)  loss_rpn_box_reg: 0.0117 (0.0342)  time: 0.2830  data: 0.1303  max mem: 1751\n",
      "Training Epoch: [22]  [ 920/1229]  eta: 0:01:24  lr: 0.000001  loss: 0.4011 (0.4313)  loss_classifier: 0.1459 (0.1530)  loss_box_reg: 0.1150 (0.1444)  loss_objectness: 0.0925 (0.0997)  loss_rpn_box_reg: 0.0253 (0.0342)  time: 0.2795  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [22]  [ 930/1229]  eta: 0:01:21  lr: 0.000001  loss: 0.3873 (0.4309)  loss_classifier: 0.1451 (0.1529)  loss_box_reg: 0.1165 (0.1443)  loss_objectness: 0.0827 (0.0995)  loss_rpn_box_reg: 0.0171 (0.0342)  time: 0.2714  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [22]  [ 940/1229]  eta: 0:01:19  lr: 0.000001  loss: 0.4284 (0.4312)  loss_classifier: 0.1375 (0.1530)  loss_box_reg: 0.1312 (0.1445)  loss_objectness: 0.0890 (0.0996)  loss_rpn_box_reg: 0.0164 (0.0342)  time: 0.2689  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [22]  [ 950/1229]  eta: 0:01:16  lr: 0.000001  loss: 0.4284 (0.4311)  loss_classifier: 0.1405 (0.1529)  loss_box_reg: 0.1355 (0.1446)  loss_objectness: 0.0767 (0.0994)  loss_rpn_box_reg: 0.0164 (0.0342)  time: 0.2684  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [22]  [ 960/1229]  eta: 0:01:13  lr: 0.000001  loss: 0.3681 (0.4307)  loss_classifier: 0.1342 (0.1527)  loss_box_reg: 0.1162 (0.1444)  loss_objectness: 0.0656 (0.0994)  loss_rpn_box_reg: 0.0353 (0.0342)  time: 0.2679  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [22]  [ 970/1229]  eta: 0:01:10  lr: 0.000001  loss: 0.3311 (0.4309)  loss_classifier: 0.1234 (0.1528)  loss_box_reg: 0.0882 (0.1443)  loss_objectness: 0.0953 (0.0996)  loss_rpn_box_reg: 0.0184 (0.0341)  time: 0.2708  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [22]  [ 980/1229]  eta: 0:01:08  lr: 0.000001  loss: 0.3650 (0.4312)  loss_classifier: 0.1234 (0.1528)  loss_box_reg: 0.0934 (0.1444)  loss_objectness: 0.1025 (0.0998)  loss_rpn_box_reg: 0.0185 (0.0341)  time: 0.2735  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [22]  [ 990/1229]  eta: 0:01:05  lr: 0.000001  loss: 0.3719 (0.4332)  loss_classifier: 0.1218 (0.1534)  loss_box_reg: 0.1331 (0.1452)  loss_objectness: 0.0998 (0.1000)  loss_rpn_box_reg: 0.0307 (0.0346)  time: 0.2773  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [22]  [1000/1229]  eta: 0:01:02  lr: 0.000001  loss: 0.4443 (0.4336)  loss_classifier: 0.1671 (0.1535)  loss_box_reg: 0.1538 (0.1454)  loss_objectness: 0.0962 (0.1001)  loss_rpn_box_reg: 0.0338 (0.0346)  time: 0.2801  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [22]  [1010/1229]  eta: 0:00:59  lr: 0.000001  loss: 0.4149 (0.4339)  loss_classifier: 0.1537 (0.1536)  loss_box_reg: 0.1348 (0.1455)  loss_objectness: 0.1094 (0.1003)  loss_rpn_box_reg: 0.0194 (0.0345)  time: 0.2740  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [22]  [1020/1229]  eta: 0:00:57  lr: 0.000001  loss: 0.3882 (0.4339)  loss_classifier: 0.1304 (0.1537)  loss_box_reg: 0.1132 (0.1455)  loss_objectness: 0.0879 (0.1002)  loss_rpn_box_reg: 0.0209 (0.0345)  time: 0.2721  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [22]  [1030/1229]  eta: 0:00:54  lr: 0.000001  loss: 0.4262 (0.4346)  loss_classifier: 0.1432 (0.1540)  loss_box_reg: 0.1199 (0.1459)  loss_objectness: 0.0876 (0.1002)  loss_rpn_box_reg: 0.0263 (0.0345)  time: 0.2723  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [22]  [1040/1229]  eta: 0:00:51  lr: 0.000001  loss: 0.4256 (0.4346)  loss_classifier: 0.1432 (0.1540)  loss_box_reg: 0.1199 (0.1460)  loss_objectness: 0.0862 (0.1002)  loss_rpn_box_reg: 0.0227 (0.0344)  time: 0.2741  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [22]  [1050/1229]  eta: 0:00:48  lr: 0.000001  loss: 0.3733 (0.4344)  loss_classifier: 0.1229 (0.1540)  loss_box_reg: 0.1464 (0.1460)  loss_objectness: 0.0859 (0.1002)  loss_rpn_box_reg: 0.0218 (0.0342)  time: 0.2721  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [22]  [1060/1229]  eta: 0:00:46  lr: 0.000001  loss: 0.4209 (0.4354)  loss_classifier: 0.1482 (0.1542)  loss_box_reg: 0.1464 (0.1463)  loss_objectness: 0.0942 (0.1006)  loss_rpn_box_reg: 0.0235 (0.0343)  time: 0.2706  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [22]  [1070/1229]  eta: 0:00:43  lr: 0.000001  loss: 0.4304 (0.4361)  loss_classifier: 0.1631 (0.1545)  loss_box_reg: 0.1227 (0.1468)  loss_objectness: 0.0929 (0.1006)  loss_rpn_box_reg: 0.0241 (0.0343)  time: 0.2781  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [22]  [1080/1229]  eta: 0:00:40  lr: 0.000001  loss: 0.2993 (0.4355)  loss_classifier: 0.1119 (0.1544)  loss_box_reg: 0.0886 (0.1465)  loss_objectness: 0.0771 (0.1004)  loss_rpn_box_reg: 0.0241 (0.0342)  time: 0.2818  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [22]  [1090/1229]  eta: 0:00:38  lr: 0.000001  loss: 0.3963 (0.4353)  loss_classifier: 0.1259 (0.1544)  loss_box_reg: 0.1186 (0.1463)  loss_objectness: 0.0734 (0.1004)  loss_rpn_box_reg: 0.0191 (0.0341)  time: 0.2743  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [22]  [1100/1229]  eta: 0:00:35  lr: 0.000001  loss: 0.4844 (0.4361)  loss_classifier: 0.1732 (0.1547)  loss_box_reg: 0.1510 (0.1466)  loss_objectness: 0.1076 (0.1007)  loss_rpn_box_reg: 0.0268 (0.0342)  time: 0.2704  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [22]  [1110/1229]  eta: 0:00:32  lr: 0.000001  loss: 0.5373 (0.4364)  loss_classifier: 0.1599 (0.1548)  loss_box_reg: 0.1460 (0.1465)  loss_objectness: 0.1569 (0.1009)  loss_rpn_box_reg: 0.0274 (0.0342)  time: 0.2670  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [22]  [1120/1229]  eta: 0:00:29  lr: 0.000001  loss: 0.3751 (0.4365)  loss_classifier: 0.1372 (0.1548)  loss_box_reg: 0.0992 (0.1465)  loss_objectness: 0.0869 (0.1008)  loss_rpn_box_reg: 0.0194 (0.0343)  time: 0.2657  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [22]  [1130/1229]  eta: 0:00:27  lr: 0.000001  loss: 0.3690 (0.4358)  loss_classifier: 0.1245 (0.1547)  loss_box_reg: 0.1014 (0.1463)  loss_objectness: 0.0710 (0.1006)  loss_rpn_box_reg: 0.0147 (0.0342)  time: 0.2733  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [22]  [1140/1229]  eta: 0:00:24  lr: 0.000001  loss: 0.3873 (0.4363)  loss_classifier: 0.1558 (0.1550)  loss_box_reg: 0.1243 (0.1466)  loss_objectness: 0.0710 (0.1006)  loss_rpn_box_reg: 0.0172 (0.0341)  time: 0.2744  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [22]  [1150/1229]  eta: 0:00:21  lr: 0.000001  loss: 0.3874 (0.4360)  loss_classifier: 0.1565 (0.1547)  loss_box_reg: 0.1285 (0.1465)  loss_objectness: 0.0852 (0.1006)  loss_rpn_box_reg: 0.0235 (0.0342)  time: 0.2772  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [22]  [1160/1229]  eta: 0:00:18  lr: 0.000001  loss: 0.3874 (0.4367)  loss_classifier: 0.1266 (0.1549)  loss_box_reg: 0.1232 (0.1467)  loss_objectness: 0.0892 (0.1009)  loss_rpn_box_reg: 0.0242 (0.0343)  time: 0.2788  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [22]  [1170/1229]  eta: 0:00:16  lr: 0.000001  loss: 0.4468 (0.4374)  loss_classifier: 0.1593 (0.1551)  loss_box_reg: 0.1394 (0.1469)  loss_objectness: 0.0912 (0.1010)  loss_rpn_box_reg: 0.0299 (0.0344)  time: 0.2754  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [22]  [1180/1229]  eta: 0:00:13  lr: 0.000001  loss: 0.3909 (0.4369)  loss_classifier: 0.1459 (0.1550)  loss_box_reg: 0.1423 (0.1469)  loss_objectness: 0.0859 (0.1008)  loss_rpn_box_reg: 0.0220 (0.0342)  time: 0.2752  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [22]  [1190/1229]  eta: 0:00:10  lr: 0.000001  loss: 0.3281 (0.4367)  loss_classifier: 0.1342 (0.1549)  loss_box_reg: 0.0950 (0.1468)  loss_objectness: 0.0855 (0.1008)  loss_rpn_box_reg: 0.0198 (0.0342)  time: 0.2710  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [22]  [1200/1229]  eta: 0:00:07  lr: 0.000001  loss: 0.3006 (0.4365)  loss_classifier: 0.1201 (0.1548)  loss_box_reg: 0.0843 (0.1467)  loss_objectness: 0.0868 (0.1007)  loss_rpn_box_reg: 0.0198 (0.0342)  time: 0.2750  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [22]  [1210/1229]  eta: 0:00:05  lr: 0.000001  loss: 0.3753 (0.4363)  loss_classifier: 0.1387 (0.1549)  loss_box_reg: 0.1071 (0.1467)  loss_objectness: 0.0856 (0.1005)  loss_rpn_box_reg: 0.0191 (0.0341)  time: 0.2770  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [22]  [1220/1229]  eta: 0:00:02  lr: 0.000001  loss: 0.3753 (0.4358)  loss_classifier: 0.1438 (0.1547)  loss_box_reg: 0.1223 (0.1466)  loss_objectness: 0.0822 (0.1004)  loss_rpn_box_reg: 0.0177 (0.0340)  time: 0.2735  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [22]  [1228/1229]  eta: 0:00:00  lr: 0.000001  loss: 0.3681 (0.4358)  loss_classifier: 0.1304 (0.1548)  loss_box_reg: 0.1165 (0.1467)  loss_objectness: 0.0951 (0.1004)  loss_rpn_box_reg: 0.0177 (0.0340)  time: 0.2711  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [22] Total time: 0:05:36 (0.2737 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:21  model_time: 0.2280 (0.2280)  evaluator_time: 0.0020 (0.0020)  time: 0.2630  data: 0.0310  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0780 (0.0818)  evaluator_time: 0.0040 (0.0086)  time: 0.1269  data: 0.0356  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0830 (0.0809)  evaluator_time: 0.0030 (0.0078)  time: 0.1197  data: 0.0306  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0750 (0.0801)  evaluator_time: 0.0040 (0.0076)  time: 0.1247  data: 0.0402  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0750 (0.0800)  evaluator_time: 0.0020 (0.0076)  time: 0.1217  data: 0.0386  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1240 s / it)\n",
      "Averaged stats: model_time: 0.0750 (0.0800)  evaluator_time: 0.0020 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [22]  [  0/308]  eta: 0:00:41  lr: 0.000001  loss: 0.1644 (0.1644)  loss_classifier: 0.0585 (0.0585)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0259 (0.0259)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1360  data: 0.0290  max mem: 1751\n",
      "Testing Epoch: [22]  [100/308]  eta: 0:00:28  lr: 0.000001  loss: 0.3138 (0.4810)  loss_classifier: 0.1326 (0.1546)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0564 (0.1021)  loss_rpn_box_reg: 0.0186 (0.0520)  time: 0.1455  data: 0.0432  max mem: 1751\n",
      "Testing Epoch: [22]  [200/308]  eta: 0:00:14  lr: 0.000001  loss: 0.3533 (0.4569)  loss_classifier: 0.1384 (0.1489)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0671 (0.0955)  loss_rpn_box_reg: 0.0197 (0.0492)  time: 0.1382  data: 0.0324  max mem: 1751\n",
      "Testing Epoch: [22]  [300/308]  eta: 0:00:01  lr: 0.000001  loss: 0.4684 (0.4538)  loss_classifier: 0.1541 (0.1492)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0753 (0.0930)  loss_rpn_box_reg: 0.0265 (0.0475)  time: 0.1321  data: 0.0370  max mem: 1751\n",
      "Testing Epoch: [22]  [307/308]  eta: 0:00:00  lr: 0.000001  loss: 0.4684 (0.4540)  loss_classifier: 0.1860 (0.1494)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0743 (0.0931)  loss_rpn_box_reg: 0.0271 (0.0471)  time: 0.1358  data: 0.0408  max mem: 1751\n",
      "Testing Epoch: [22] Total time: 0:00:42 (0.1375 s / it)\n",
      "Training Epoch: [23]  [   0/1229]  eta: 0:05:24  lr: 0.000001  loss: 0.4184 (0.4184)  loss_classifier: 0.1532 (0.1532)  loss_box_reg: 0.1630 (0.1630)  loss_objectness: 0.0887 (0.0887)  loss_rpn_box_reg: 0.0136 (0.0136)  time: 0.2640  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [23]  [  10/1229]  eta: 0:05:35  lr: 0.000001  loss: 0.3444 (0.4090)  loss_classifier: 0.1251 (0.1433)  loss_box_reg: 0.1063 (0.1375)  loss_objectness: 0.0827 (0.0884)  loss_rpn_box_reg: 0.0147 (0.0398)  time: 0.2749  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [23]  [  20/1229]  eta: 0:05:31  lr: 0.000001  loss: 0.3563 (0.4155)  loss_classifier: 0.1251 (0.1464)  loss_box_reg: 0.1175 (0.1451)  loss_objectness: 0.0661 (0.0874)  loss_rpn_box_reg: 0.0212 (0.0367)  time: 0.2744  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [23]  [  30/1229]  eta: 0:05:33  lr: 0.000001  loss: 0.4021 (0.3953)  loss_classifier: 0.1394 (0.1413)  loss_box_reg: 0.1404 (0.1351)  loss_objectness: 0.0750 (0.0895)  loss_rpn_box_reg: 0.0146 (0.0293)  time: 0.2804  data: 0.1383  max mem: 1751\n",
      "Training Epoch: [23]  [  40/1229]  eta: 0:05:31  lr: 0.000001  loss: 0.3449 (0.4071)  loss_classifier: 0.1254 (0.1462)  loss_box_reg: 0.1108 (0.1384)  loss_objectness: 0.0970 (0.0946)  loss_rpn_box_reg: 0.0135 (0.0278)  time: 0.2840  data: 0.1397  max mem: 1751\n",
      "Training Epoch: [23]  [  50/1229]  eta: 0:05:31  lr: 0.000001  loss: 0.3283 (0.3996)  loss_classifier: 0.1212 (0.1432)  loss_box_reg: 0.1110 (0.1350)  loss_objectness: 0.0970 (0.0932)  loss_rpn_box_reg: 0.0184 (0.0283)  time: 0.2858  data: 0.1406  max mem: 1751\n",
      "Training Epoch: [23]  [  60/1229]  eta: 0:05:27  lr: 0.000001  loss: 0.2808 (0.3908)  loss_classifier: 0.0944 (0.1396)  loss_box_reg: 0.0971 (0.1290)  loss_objectness: 0.0623 (0.0920)  loss_rpn_box_reg: 0.0223 (0.0301)  time: 0.2829  data: 0.1422  max mem: 1751\n",
      "Training Epoch: [23]  [  70/1229]  eta: 0:05:24  lr: 0.000001  loss: 0.3166 (0.3903)  loss_classifier: 0.1239 (0.1401)  loss_box_reg: 0.0850 (0.1275)  loss_objectness: 0.0763 (0.0926)  loss_rpn_box_reg: 0.0191 (0.0301)  time: 0.2776  data: 0.1429  max mem: 1751\n",
      "Training Epoch: [23]  [  80/1229]  eta: 0:05:22  lr: 0.000001  loss: 0.3166 (0.3875)  loss_classifier: 0.1239 (0.1395)  loss_box_reg: 0.0963 (0.1269)  loss_objectness: 0.0760 (0.0927)  loss_rpn_box_reg: 0.0141 (0.0284)  time: 0.2833  data: 0.1424  max mem: 1751\n",
      "Training Epoch: [23]  [  90/1229]  eta: 0:05:19  lr: 0.000001  loss: 0.4251 (0.4057)  loss_classifier: 0.1541 (0.1437)  loss_box_reg: 0.0963 (0.1301)  loss_objectness: 0.1157 (0.0995)  loss_rpn_box_reg: 0.0204 (0.0324)  time: 0.2811  data: 0.1394  max mem: 1751\n",
      "Training Epoch: [23]  [ 100/1229]  eta: 0:05:16  lr: 0.000001  loss: 0.4167 (0.4014)  loss_classifier: 0.1542 (0.1422)  loss_box_reg: 0.1170 (0.1301)  loss_objectness: 0.0891 (0.0971)  loss_rpn_box_reg: 0.0210 (0.0319)  time: 0.2775  data: 0.1379  max mem: 1751\n",
      "Training Epoch: [23]  [ 110/1229]  eta: 0:05:13  lr: 0.000001  loss: 0.3391 (0.3948)  loss_classifier: 0.1124 (0.1406)  loss_box_reg: 0.1057 (0.1274)  loss_objectness: 0.0710 (0.0961)  loss_rpn_box_reg: 0.0139 (0.0307)  time: 0.2807  data: 0.1375  max mem: 1751\n",
      "Training Epoch: [23]  [ 120/1229]  eta: 0:05:10  lr: 0.000001  loss: 0.2816 (0.3915)  loss_classifier: 0.1068 (0.1390)  loss_box_reg: 0.0862 (0.1252)  loss_objectness: 0.0938 (0.0968)  loss_rpn_box_reg: 0.0098 (0.0305)  time: 0.2796  data: 0.1378  max mem: 1751\n",
      "Training Epoch: [23]  [ 130/1229]  eta: 0:05:08  lr: 0.000001  loss: 0.2736 (0.3885)  loss_classifier: 0.1083 (0.1381)  loss_box_reg: 0.0862 (0.1261)  loss_objectness: 0.0816 (0.0946)  loss_rpn_box_reg: 0.0098 (0.0297)  time: 0.2806  data: 0.1383  max mem: 1751\n",
      "Training Epoch: [23]  [ 140/1229]  eta: 0:05:06  lr: 0.000001  loss: 0.3077 (0.3889)  loss_classifier: 0.1189 (0.1387)  loss_box_reg: 0.0887 (0.1251)  loss_objectness: 0.0757 (0.0952)  loss_rpn_box_reg: 0.0132 (0.0299)  time: 0.2884  data: 0.1380  max mem: 1751\n",
      "Training Epoch: [23]  [ 150/1229]  eta: 0:05:03  lr: 0.000001  loss: 0.3382 (0.3953)  loss_classifier: 0.1422 (0.1408)  loss_box_reg: 0.0942 (0.1281)  loss_objectness: 0.0960 (0.0966)  loss_rpn_box_reg: 0.0206 (0.0298)  time: 0.2848  data: 0.1375  max mem: 1751\n",
      "Training Epoch: [23]  [ 160/1229]  eta: 0:05:00  lr: 0.000001  loss: 0.4435 (0.3961)  loss_classifier: 0.1440 (0.1407)  loss_box_reg: 0.1227 (0.1281)  loss_objectness: 0.0856 (0.0961)  loss_rpn_box_reg: 0.0200 (0.0313)  time: 0.2830  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [23]  [ 170/1229]  eta: 0:04:58  lr: 0.000001  loss: 0.4435 (0.4005)  loss_classifier: 0.1469 (0.1421)  loss_box_reg: 0.1142 (0.1279)  loss_objectness: 0.0915 (0.0987)  loss_rpn_box_reg: 0.0138 (0.0318)  time: 0.2863  data: 0.1382  max mem: 1751\n",
      "Training Epoch: [23]  [ 180/1229]  eta: 0:04:55  lr: 0.000001  loss: 0.4328 (0.4049)  loss_classifier: 0.1469 (0.1432)  loss_box_reg: 0.1137 (0.1301)  loss_objectness: 0.0915 (0.0989)  loss_rpn_box_reg: 0.0293 (0.0327)  time: 0.2811  data: 0.1399  max mem: 1751\n",
      "Training Epoch: [23]  [ 190/1229]  eta: 0:04:52  lr: 0.000001  loss: 0.4328 (0.4057)  loss_classifier: 0.1298 (0.1435)  loss_box_reg: 0.1775 (0.1313)  loss_objectness: 0.0750 (0.0982)  loss_rpn_box_reg: 0.0227 (0.0327)  time: 0.2807  data: 0.1407  max mem: 1751\n",
      "Training Epoch: [23]  [ 200/1229]  eta: 0:04:50  lr: 0.000001  loss: 0.4321 (0.4069)  loss_classifier: 0.1455 (0.1438)  loss_box_reg: 0.1775 (0.1326)  loss_objectness: 0.0717 (0.0980)  loss_rpn_box_reg: 0.0199 (0.0325)  time: 0.2877  data: 0.1437  max mem: 1751\n",
      "Training Epoch: [23]  [ 210/1229]  eta: 0:04:47  lr: 0.000001  loss: 0.3611 (0.4077)  loss_classifier: 0.1351 (0.1442)  loss_box_reg: 0.1121 (0.1330)  loss_objectness: 0.0850 (0.0977)  loss_rpn_box_reg: 0.0225 (0.0328)  time: 0.2873  data: 0.1437  max mem: 1751\n",
      "Training Epoch: [23]  [ 220/1229]  eta: 0:04:44  lr: 0.000001  loss: 0.3831 (0.4105)  loss_classifier: 0.1495 (0.1456)  loss_box_reg: 0.1179 (0.1344)  loss_objectness: 0.0850 (0.0980)  loss_rpn_box_reg: 0.0282 (0.0326)  time: 0.2838  data: 0.1439  max mem: 1751\n",
      "Training Epoch: [23]  [ 230/1229]  eta: 0:04:42  lr: 0.000001  loss: 0.3967 (0.4131)  loss_classifier: 0.1550 (0.1469)  loss_box_reg: 0.1414 (0.1352)  loss_objectness: 0.0755 (0.0984)  loss_rpn_box_reg: 0.0257 (0.0327)  time: 0.2847  data: 0.1416  max mem: 1751\n",
      "Training Epoch: [23]  [ 240/1229]  eta: 0:04:39  lr: 0.000001  loss: 0.4081 (0.4146)  loss_classifier: 0.1641 (0.1478)  loss_box_reg: 0.1284 (0.1356)  loss_objectness: 0.0881 (0.0990)  loss_rpn_box_reg: 0.0175 (0.0322)  time: 0.2833  data: 0.1409  max mem: 1751\n",
      "Training Epoch: [23]  [ 250/1229]  eta: 0:04:36  lr: 0.000001  loss: 0.4081 (0.4148)  loss_classifier: 0.1589 (0.1480)  loss_box_reg: 0.1292 (0.1357)  loss_objectness: 0.0881 (0.0991)  loss_rpn_box_reg: 0.0175 (0.0320)  time: 0.2822  data: 0.1423  max mem: 1751\n",
      "Training Epoch: [23]  [ 260/1229]  eta: 0:04:33  lr: 0.000001  loss: 0.3761 (0.4136)  loss_classifier: 0.1221 (0.1476)  loss_box_reg: 0.1218 (0.1354)  loss_objectness: 0.0890 (0.0987)  loss_rpn_box_reg: 0.0153 (0.0319)  time: 0.2821  data: 0.1412  max mem: 1751\n",
      "Training Epoch: [23]  [ 270/1229]  eta: 0:04:30  lr: 0.000001  loss: 0.3411 (0.4104)  loss_classifier: 0.1215 (0.1467)  loss_box_reg: 0.0991 (0.1345)  loss_objectness: 0.0739 (0.0978)  loss_rpn_box_reg: 0.0115 (0.0314)  time: 0.2799  data: 0.1380  max mem: 1751\n",
      "Training Epoch: [23]  [ 280/1229]  eta: 0:04:27  lr: 0.000001  loss: 0.3545 (0.4172)  loss_classifier: 0.1251 (0.1489)  loss_box_reg: 0.1192 (0.1373)  loss_objectness: 0.0871 (0.0986)  loss_rpn_box_reg: 0.0229 (0.0325)  time: 0.2787  data: 0.1378  max mem: 1751\n",
      "Training Epoch: [23]  [ 290/1229]  eta: 0:04:25  lr: 0.000001  loss: 0.3200 (0.4140)  loss_classifier: 0.1227 (0.1478)  loss_box_reg: 0.0968 (0.1362)  loss_objectness: 0.0941 (0.0978)  loss_rpn_box_reg: 0.0253 (0.0321)  time: 0.2866  data: 0.1404  max mem: 1751\n",
      "Training Epoch: [23]  [ 300/1229]  eta: 0:04:22  lr: 0.000001  loss: 0.3200 (0.4172)  loss_classifier: 0.1055 (0.1490)  loss_box_reg: 0.0931 (0.1370)  loss_objectness: 0.0970 (0.0993)  loss_rpn_box_reg: 0.0191 (0.0320)  time: 0.2923  data: 0.1414  max mem: 1751\n",
      "Training Epoch: [23]  [ 310/1229]  eta: 0:04:19  lr: 0.000001  loss: 0.3300 (0.4147)  loss_classifier: 0.1219 (0.1485)  loss_box_reg: 0.1025 (0.1360)  loss_objectness: 0.0956 (0.0987)  loss_rpn_box_reg: 0.0164 (0.0314)  time: 0.2865  data: 0.1407  max mem: 1751\n",
      "Training Epoch: [23]  [ 320/1229]  eta: 0:04:16  lr: 0.000001  loss: 0.2918 (0.4146)  loss_classifier: 0.1168 (0.1485)  loss_box_reg: 0.0870 (0.1359)  loss_objectness: 0.0749 (0.0990)  loss_rpn_box_reg: 0.0161 (0.0311)  time: 0.2821  data: 0.1401  max mem: 1751\n",
      "Training Epoch: [23]  [ 330/1229]  eta: 0:04:14  lr: 0.000001  loss: 0.3513 (0.4148)  loss_classifier: 0.1151 (0.1485)  loss_box_reg: 0.1122 (0.1364)  loss_objectness: 0.0954 (0.0985)  loss_rpn_box_reg: 0.0196 (0.0313)  time: 0.2867  data: 0.1444  max mem: 1751\n",
      "Training Epoch: [23]  [ 340/1229]  eta: 0:04:11  lr: 0.000001  loss: 0.4103 (0.4168)  loss_classifier: 0.1289 (0.1495)  loss_box_reg: 0.1232 (0.1368)  loss_objectness: 0.0954 (0.0989)  loss_rpn_box_reg: 0.0237 (0.0316)  time: 0.2898  data: 0.1457  max mem: 1751\n",
      "Training Epoch: [23]  [ 350/1229]  eta: 0:04:08  lr: 0.000001  loss: 0.3287 (0.4149)  loss_classifier: 0.1154 (0.1489)  loss_box_reg: 0.0896 (0.1358)  loss_objectness: 0.0932 (0.0989)  loss_rpn_box_reg: 0.0254 (0.0314)  time: 0.2831  data: 0.1422  max mem: 1751\n",
      "Training Epoch: [23]  [ 360/1229]  eta: 0:04:05  lr: 0.000001  loss: 0.3849 (0.4164)  loss_classifier: 0.1272 (0.1491)  loss_box_reg: 0.0950 (0.1365)  loss_objectness: 0.0944 (0.0992)  loss_rpn_box_reg: 0.0197 (0.0315)  time: 0.2802  data: 0.1395  max mem: 1751\n",
      "Training Epoch: [23]  [ 370/1229]  eta: 0:04:02  lr: 0.000001  loss: 0.3793 (0.4149)  loss_classifier: 0.1301 (0.1487)  loss_box_reg: 0.1122 (0.1358)  loss_objectness: 0.0771 (0.0992)  loss_rpn_box_reg: 0.0210 (0.0313)  time: 0.2737  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [23]  [ 380/1229]  eta: 0:03:59  lr: 0.000001  loss: 0.3979 (0.4182)  loss_classifier: 0.1418 (0.1494)  loss_box_reg: 0.1323 (0.1373)  loss_objectness: 0.0744 (0.0994)  loss_rpn_box_reg: 0.0242 (0.0320)  time: 0.2688  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [23]  [ 390/1229]  eta: 0:03:56  lr: 0.000001  loss: 0.5060 (0.4211)  loss_classifier: 0.1710 (0.1503)  loss_box_reg: 0.1382 (0.1377)  loss_objectness: 0.0929 (0.0999)  loss_rpn_box_reg: 0.0395 (0.0333)  time: 0.2776  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [23]  [ 400/1229]  eta: 0:03:53  lr: 0.000001  loss: 0.4763 (0.4223)  loss_classifier: 0.1710 (0.1504)  loss_box_reg: 0.1359 (0.1386)  loss_objectness: 0.0898 (0.0996)  loss_rpn_box_reg: 0.0221 (0.0336)  time: 0.2768  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [23]  [ 410/1229]  eta: 0:03:50  lr: 0.000001  loss: 0.4478 (0.4223)  loss_classifier: 0.1526 (0.1505)  loss_box_reg: 0.1210 (0.1380)  loss_objectness: 0.0817 (0.1002)  loss_rpn_box_reg: 0.0211 (0.0336)  time: 0.2723  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [23]  [ 420/1229]  eta: 0:03:47  lr: 0.000001  loss: 0.3904 (0.4228)  loss_classifier: 0.1418 (0.1509)  loss_box_reg: 0.1266 (0.1384)  loss_objectness: 0.0891 (0.1002)  loss_rpn_box_reg: 0.0208 (0.0333)  time: 0.2753  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [23]  [ 430/1229]  eta: 0:03:44  lr: 0.000001  loss: 0.4204 (0.4248)  loss_classifier: 0.1495 (0.1513)  loss_box_reg: 0.1315 (0.1390)  loss_objectness: 0.0924 (0.1009)  loss_rpn_box_reg: 0.0147 (0.0336)  time: 0.2749  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [23]  [ 440/1229]  eta: 0:03:41  lr: 0.000001  loss: 0.3621 (0.4227)  loss_classifier: 0.1254 (0.1506)  loss_box_reg: 0.0939 (0.1383)  loss_objectness: 0.0922 (0.1005)  loss_rpn_box_reg: 0.0240 (0.0333)  time: 0.2737  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [23]  [ 450/1229]  eta: 0:03:38  lr: 0.000001  loss: 0.3092 (0.4226)  loss_classifier: 0.1188 (0.1504)  loss_box_reg: 0.0770 (0.1382)  loss_objectness: 0.0732 (0.1003)  loss_rpn_box_reg: 0.0180 (0.0337)  time: 0.2742  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [23]  [ 460/1229]  eta: 0:03:36  lr: 0.000001  loss: 0.4222 (0.4246)  loss_classifier: 0.1299 (0.1511)  loss_box_reg: 0.1140 (0.1385)  loss_objectness: 0.0941 (0.1009)  loss_rpn_box_reg: 0.0221 (0.0341)  time: 0.2768  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [23]  [ 470/1229]  eta: 0:03:33  lr: 0.000001  loss: 0.4085 (0.4242)  loss_classifier: 0.1299 (0.1511)  loss_box_reg: 0.1141 (0.1384)  loss_objectness: 0.0908 (0.1008)  loss_rpn_box_reg: 0.0235 (0.0340)  time: 0.2724  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [23]  [ 480/1229]  eta: 0:03:30  lr: 0.000001  loss: 0.3578 (0.4245)  loss_classifier: 0.1323 (0.1512)  loss_box_reg: 0.1114 (0.1386)  loss_objectness: 0.0996 (0.1007)  loss_rpn_box_reg: 0.0235 (0.0341)  time: 0.2674  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [23]  [ 490/1229]  eta: 0:03:27  lr: 0.000001  loss: 0.4009 (0.4256)  loss_classifier: 0.1412 (0.1515)  loss_box_reg: 0.1215 (0.1393)  loss_objectness: 0.0955 (0.1008)  loss_rpn_box_reg: 0.0320 (0.0340)  time: 0.2669  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [23]  [ 500/1229]  eta: 0:03:24  lr: 0.000001  loss: 0.3464 (0.4251)  loss_classifier: 0.1333 (0.1514)  loss_box_reg: 0.1165 (0.1390)  loss_objectness: 0.0789 (0.1007)  loss_rpn_box_reg: 0.0227 (0.0340)  time: 0.2691  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [23]  [ 510/1229]  eta: 0:03:21  lr: 0.000001  loss: 0.3587 (0.4245)  loss_classifier: 0.1140 (0.1512)  loss_box_reg: 0.0959 (0.1386)  loss_objectness: 0.0796 (0.1007)  loss_rpn_box_reg: 0.0221 (0.0340)  time: 0.2758  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [23]  [ 520/1229]  eta: 0:03:18  lr: 0.000001  loss: 0.4121 (0.4249)  loss_classifier: 0.1512 (0.1512)  loss_box_reg: 0.1334 (0.1391)  loss_objectness: 0.0854 (0.1008)  loss_rpn_box_reg: 0.0211 (0.0338)  time: 0.2709  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [23]  [ 530/1229]  eta: 0:03:15  lr: 0.000001  loss: 0.4305 (0.4241)  loss_classifier: 0.1512 (0.1508)  loss_box_reg: 0.1159 (0.1387)  loss_objectness: 0.0967 (0.1010)  loss_rpn_box_reg: 0.0148 (0.0336)  time: 0.2685  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [23]  [ 540/1229]  eta: 0:03:12  lr: 0.000001  loss: 0.3702 (0.4245)  loss_classifier: 0.1295 (0.1510)  loss_box_reg: 0.1159 (0.1390)  loss_objectness: 0.0965 (0.1009)  loss_rpn_box_reg: 0.0235 (0.0336)  time: 0.2727  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [23]  [ 550/1229]  eta: 0:03:09  lr: 0.000001  loss: 0.3403 (0.4227)  loss_classifier: 0.1255 (0.1504)  loss_box_reg: 0.0947 (0.1381)  loss_objectness: 0.0881 (0.1007)  loss_rpn_box_reg: 0.0235 (0.0336)  time: 0.2725  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [23]  [ 560/1229]  eta: 0:03:06  lr: 0.000001  loss: 0.3012 (0.4213)  loss_classifier: 0.1115 (0.1498)  loss_box_reg: 0.0828 (0.1375)  loss_objectness: 0.0842 (0.1004)  loss_rpn_box_reg: 0.0137 (0.0335)  time: 0.2649  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [23]  [ 570/1229]  eta: 0:03:03  lr: 0.000001  loss: 0.3300 (0.4231)  loss_classifier: 0.1205 (0.1503)  loss_box_reg: 0.1282 (0.1381)  loss_objectness: 0.0953 (0.1009)  loss_rpn_box_reg: 0.0197 (0.0339)  time: 0.2626  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [23]  [ 580/1229]  eta: 0:03:00  lr: 0.000001  loss: 0.4689 (0.4234)  loss_classifier: 0.1797 (0.1502)  loss_box_reg: 0.1340 (0.1377)  loss_objectness: 0.1087 (0.1016)  loss_rpn_box_reg: 0.0247 (0.0339)  time: 0.2654  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [23]  [ 590/1229]  eta: 0:02:57  lr: 0.000001  loss: 0.3795 (0.4235)  loss_classifier: 0.1366 (0.1502)  loss_box_reg: 0.1170 (0.1379)  loss_objectness: 0.0978 (0.1016)  loss_rpn_box_reg: 0.0228 (0.0337)  time: 0.2680  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [23]  [ 600/1229]  eta: 0:02:55  lr: 0.000001  loss: 0.4344 (0.4253)  loss_classifier: 0.1427 (0.1508)  loss_box_reg: 0.1516 (0.1390)  loss_objectness: 0.0892 (0.1016)  loss_rpn_box_reg: 0.0223 (0.0339)  time: 0.2767  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [23]  [ 610/1229]  eta: 0:02:52  lr: 0.000001  loss: 0.5107 (0.4262)  loss_classifier: 0.1584 (0.1511)  loss_box_reg: 0.1322 (0.1393)  loss_objectness: 0.0913 (0.1018)  loss_rpn_box_reg: 0.0325 (0.0340)  time: 0.2713  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [23]  [ 620/1229]  eta: 0:02:49  lr: 0.000001  loss: 0.3265 (0.4251)  loss_classifier: 0.1102 (0.1508)  loss_box_reg: 0.1130 (0.1389)  loss_objectness: 0.0913 (0.1015)  loss_rpn_box_reg: 0.0261 (0.0339)  time: 0.2610  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [23]  [ 630/1229]  eta: 0:02:46  lr: 0.000001  loss: 0.3408 (0.4251)  loss_classifier: 0.1179 (0.1508)  loss_box_reg: 0.1082 (0.1389)  loss_objectness: 0.0926 (0.1017)  loss_rpn_box_reg: 0.0193 (0.0338)  time: 0.2644  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [23]  [ 640/1229]  eta: 0:02:43  lr: 0.000001  loss: 0.4349 (0.4262)  loss_classifier: 0.1482 (0.1511)  loss_box_reg: 0.1321 (0.1392)  loss_objectness: 0.1022 (0.1021)  loss_rpn_box_reg: 0.0195 (0.0337)  time: 0.2653  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [23]  [ 650/1229]  eta: 0:02:40  lr: 0.000001  loss: 0.4926 (0.4277)  loss_classifier: 0.1844 (0.1516)  loss_box_reg: 0.1537 (0.1398)  loss_objectness: 0.1098 (0.1023)  loss_rpn_box_reg: 0.0218 (0.0339)  time: 0.2699  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [23]  [ 660/1229]  eta: 0:02:37  lr: 0.000001  loss: 0.4558 (0.4273)  loss_classifier: 0.1621 (0.1516)  loss_box_reg: 0.1537 (0.1396)  loss_objectness: 0.0777 (0.1024)  loss_rpn_box_reg: 0.0207 (0.0338)  time: 0.2795  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [23]  [ 670/1229]  eta: 0:02:35  lr: 0.000001  loss: 0.4162 (0.4269)  loss_classifier: 0.1539 (0.1515)  loss_box_reg: 0.0913 (0.1392)  loss_objectness: 0.0897 (0.1025)  loss_rpn_box_reg: 0.0181 (0.0337)  time: 0.2771  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [23]  [ 680/1229]  eta: 0:02:32  lr: 0.000001  loss: 0.4162 (0.4280)  loss_classifier: 0.1539 (0.1520)  loss_box_reg: 0.1224 (0.1396)  loss_objectness: 0.1040 (0.1027)  loss_rpn_box_reg: 0.0181 (0.0337)  time: 0.2723  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [23]  [ 690/1229]  eta: 0:02:29  lr: 0.000001  loss: 0.4515 (0.4287)  loss_classifier: 0.1626 (0.1523)  loss_box_reg: 0.1375 (0.1398)  loss_objectness: 0.1011 (0.1028)  loss_rpn_box_reg: 0.0213 (0.0338)  time: 0.2690  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [23]  [ 700/1229]  eta: 0:02:26  lr: 0.000001  loss: 0.3415 (0.4268)  loss_classifier: 0.1256 (0.1518)  loss_box_reg: 0.0914 (0.1390)  loss_objectness: 0.0820 (0.1024)  loss_rpn_box_reg: 0.0181 (0.0337)  time: 0.2707  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [23]  [ 710/1229]  eta: 0:02:23  lr: 0.000001  loss: 0.3140 (0.4262)  loss_classifier: 0.1119 (0.1516)  loss_box_reg: 0.0874 (0.1389)  loss_objectness: 0.0710 (0.1022)  loss_rpn_box_reg: 0.0179 (0.0336)  time: 0.2723  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [23]  [ 720/1229]  eta: 0:02:20  lr: 0.000001  loss: 0.3173 (0.4259)  loss_classifier: 0.1169 (0.1516)  loss_box_reg: 0.0914 (0.1387)  loss_objectness: 0.0881 (0.1023)  loss_rpn_box_reg: 0.0179 (0.0334)  time: 0.2700  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [23]  [ 730/1229]  eta: 0:02:18  lr: 0.000001  loss: 0.2874 (0.4260)  loss_classifier: 0.1169 (0.1517)  loss_box_reg: 0.0748 (0.1385)  loss_objectness: 0.0881 (0.1025)  loss_rpn_box_reg: 0.0106 (0.0333)  time: 0.2701  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [23]  [ 740/1229]  eta: 0:02:15  lr: 0.000001  loss: 0.2906 (0.4253)  loss_classifier: 0.1042 (0.1513)  loss_box_reg: 0.1002 (0.1382)  loss_objectness: 0.0842 (0.1024)  loss_rpn_box_reg: 0.0231 (0.0335)  time: 0.2728  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [23]  [ 750/1229]  eta: 0:02:12  lr: 0.000001  loss: 0.4549 (0.4274)  loss_classifier: 0.1530 (0.1520)  loss_box_reg: 0.1531 (0.1390)  loss_objectness: 0.0896 (0.1026)  loss_rpn_box_reg: 0.0306 (0.0338)  time: 0.2747  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [23]  [ 760/1229]  eta: 0:02:09  lr: 0.000001  loss: 0.4878 (0.4280)  loss_classifier: 0.1569 (0.1521)  loss_box_reg: 0.1531 (0.1395)  loss_objectness: 0.0935 (0.1026)  loss_rpn_box_reg: 0.0358 (0.0338)  time: 0.2746  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [23]  [ 770/1229]  eta: 0:02:07  lr: 0.000001  loss: 0.4344 (0.4299)  loss_classifier: 0.1754 (0.1529)  loss_box_reg: 0.1260 (0.1400)  loss_objectness: 0.1271 (0.1032)  loss_rpn_box_reg: 0.0290 (0.0338)  time: 0.2727  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [23]  [ 780/1229]  eta: 0:02:04  lr: 0.000001  loss: 0.5043 (0.4303)  loss_classifier: 0.1777 (0.1529)  loss_box_reg: 0.1434 (0.1400)  loss_objectness: 0.1289 (0.1032)  loss_rpn_box_reg: 0.0250 (0.0341)  time: 0.2709  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [23]  [ 790/1229]  eta: 0:02:01  lr: 0.000001  loss: 0.3251 (0.4285)  loss_classifier: 0.1000 (0.1523)  loss_box_reg: 0.0756 (0.1394)  loss_objectness: 0.0661 (0.1028)  loss_rpn_box_reg: 0.0199 (0.0340)  time: 0.2712  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [23]  [ 800/1229]  eta: 0:01:58  lr: 0.000001  loss: 0.3331 (0.4276)  loss_classifier: 0.0869 (0.1518)  loss_box_reg: 0.0693 (0.1389)  loss_objectness: 0.0724 (0.1026)  loss_rpn_box_reg: 0.0193 (0.0342)  time: 0.2669  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [23]  [ 810/1229]  eta: 0:01:55  lr: 0.000001  loss: 0.3807 (0.4275)  loss_classifier: 0.0972 (0.1518)  loss_box_reg: 0.0992 (0.1391)  loss_objectness: 0.0824 (0.1026)  loss_rpn_box_reg: 0.0189 (0.0340)  time: 0.2722  data: 0.1367  max mem: 1751\n",
      "Training Epoch: [23]  [ 820/1229]  eta: 0:01:53  lr: 0.000001  loss: 0.3401 (0.4275)  loss_classifier: 0.1113 (0.1520)  loss_box_reg: 0.1335 (0.1392)  loss_objectness: 0.0824 (0.1023)  loss_rpn_box_reg: 0.0189 (0.0339)  time: 0.2745  data: 0.1372  max mem: 1751\n",
      "Training Epoch: [23]  [ 830/1229]  eta: 0:01:50  lr: 0.000001  loss: 0.2922 (0.4265)  loss_classifier: 0.1113 (0.1516)  loss_box_reg: 0.0989 (0.1387)  loss_objectness: 0.0911 (0.1023)  loss_rpn_box_reg: 0.0196 (0.0338)  time: 0.2658  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [23]  [ 840/1229]  eta: 0:01:47  lr: 0.000001  loss: 0.3257 (0.4264)  loss_classifier: 0.1235 (0.1516)  loss_box_reg: 0.0989 (0.1389)  loss_objectness: 0.0910 (0.1021)  loss_rpn_box_reg: 0.0179 (0.0338)  time: 0.2709  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [23]  [ 850/1229]  eta: 0:01:44  lr: 0.000001  loss: 0.4078 (0.4261)  loss_classifier: 0.1388 (0.1515)  loss_box_reg: 0.1093 (0.1387)  loss_objectness: 0.0874 (0.1020)  loss_rpn_box_reg: 0.0209 (0.0339)  time: 0.2772  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [23]  [ 860/1229]  eta: 0:01:41  lr: 0.000001  loss: 0.3487 (0.4257)  loss_classifier: 0.1160 (0.1513)  loss_box_reg: 0.0989 (0.1384)  loss_objectness: 0.0929 (0.1022)  loss_rpn_box_reg: 0.0221 (0.0338)  time: 0.2807  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [23]  [ 870/1229]  eta: 0:01:39  lr: 0.000001  loss: 0.3116 (0.4245)  loss_classifier: 0.1204 (0.1510)  loss_box_reg: 0.0833 (0.1378)  loss_objectness: 0.0929 (0.1021)  loss_rpn_box_reg: 0.0188 (0.0336)  time: 0.2776  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [23]  [ 880/1229]  eta: 0:01:36  lr: 0.000001  loss: 0.3116 (0.4241)  loss_classifier: 0.1254 (0.1510)  loss_box_reg: 0.0898 (0.1377)  loss_objectness: 0.0865 (0.1020)  loss_rpn_box_reg: 0.0188 (0.0335)  time: 0.2742  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [23]  [ 890/1229]  eta: 0:01:33  lr: 0.000001  loss: 0.4500 (0.4259)  loss_classifier: 0.1682 (0.1517)  loss_box_reg: 0.1355 (0.1384)  loss_objectness: 0.1080 (0.1022)  loss_rpn_box_reg: 0.0206 (0.0336)  time: 0.2721  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [23]  [ 900/1229]  eta: 0:01:30  lr: 0.000001  loss: 0.4884 (0.4254)  loss_classifier: 0.1687 (0.1516)  loss_box_reg: 0.1355 (0.1382)  loss_objectness: 0.1142 (0.1022)  loss_rpn_box_reg: 0.0199 (0.0334)  time: 0.2715  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [23]  [ 910/1229]  eta: 0:01:28  lr: 0.000001  loss: 0.3904 (0.4266)  loss_classifier: 0.1335 (0.1520)  loss_box_reg: 0.1161 (0.1387)  loss_objectness: 0.1067 (0.1025)  loss_rpn_box_reg: 0.0199 (0.0334)  time: 0.2787  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [23]  [ 920/1229]  eta: 0:01:25  lr: 0.000001  loss: 0.4642 (0.4278)  loss_classifier: 0.1575 (0.1523)  loss_box_reg: 0.1282 (0.1394)  loss_objectness: 0.1222 (0.1026)  loss_rpn_box_reg: 0.0257 (0.0335)  time: 0.2764  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [23]  [ 930/1229]  eta: 0:01:22  lr: 0.000001  loss: 0.4419 (0.4277)  loss_classifier: 0.1575 (0.1523)  loss_box_reg: 0.1562 (0.1395)  loss_objectness: 0.0809 (0.1023)  loss_rpn_box_reg: 0.0174 (0.0335)  time: 0.2726  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [23]  [ 940/1229]  eta: 0:01:19  lr: 0.000001  loss: 0.3144 (0.4269)  loss_classifier: 0.1168 (0.1520)  loss_box_reg: 0.1121 (0.1394)  loss_objectness: 0.0601 (0.1020)  loss_rpn_box_reg: 0.0174 (0.0335)  time: 0.2716  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [23]  [ 950/1229]  eta: 0:01:17  lr: 0.000001  loss: 0.3022 (0.4262)  loss_classifier: 0.1168 (0.1518)  loss_box_reg: 0.0984 (0.1391)  loss_objectness: 0.0623 (0.1019)  loss_rpn_box_reg: 0.0122 (0.0334)  time: 0.2690  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [23]  [ 960/1229]  eta: 0:01:14  lr: 0.000001  loss: 0.3022 (0.4262)  loss_classifier: 0.1163 (0.1518)  loss_box_reg: 0.0833 (0.1390)  loss_objectness: 0.0890 (0.1020)  loss_rpn_box_reg: 0.0174 (0.0334)  time: 0.2725  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [23]  [ 970/1229]  eta: 0:01:11  lr: 0.000001  loss: 0.3180 (0.4267)  loss_classifier: 0.1223 (0.1519)  loss_box_reg: 0.1006 (0.1392)  loss_objectness: 0.0851 (0.1021)  loss_rpn_box_reg: 0.0225 (0.0336)  time: 0.2742  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [23]  [ 980/1229]  eta: 0:01:08  lr: 0.000001  loss: 0.4245 (0.4283)  loss_classifier: 0.1387 (0.1524)  loss_box_reg: 0.1300 (0.1398)  loss_objectness: 0.0829 (0.1023)  loss_rpn_box_reg: 0.0331 (0.0338)  time: 0.2670  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [23]  [ 990/1229]  eta: 0:01:05  lr: 0.000001  loss: 0.4768 (0.4291)  loss_classifier: 0.1387 (0.1526)  loss_box_reg: 0.1353 (0.1402)  loss_objectness: 0.1152 (0.1025)  loss_rpn_box_reg: 0.0393 (0.0339)  time: 0.2628  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [23]  [1000/1229]  eta: 0:01:03  lr: 0.000001  loss: 0.4333 (0.4300)  loss_classifier: 0.1266 (0.1528)  loss_box_reg: 0.1533 (0.1406)  loss_objectness: 0.0979 (0.1026)  loss_rpn_box_reg: 0.0264 (0.0340)  time: 0.2688  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [23]  [1010/1229]  eta: 0:01:00  lr: 0.000001  loss: 0.5089 (0.4319)  loss_classifier: 0.1736 (0.1533)  loss_box_reg: 0.1552 (0.1415)  loss_objectness: 0.1082 (0.1029)  loss_rpn_box_reg: 0.0264 (0.0342)  time: 0.2764  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [23]  [1020/1229]  eta: 0:00:57  lr: 0.000001  loss: 0.5290 (0.4333)  loss_classifier: 0.1736 (0.1537)  loss_box_reg: 0.1980 (0.1424)  loss_objectness: 0.1115 (0.1029)  loss_rpn_box_reg: 0.0306 (0.0343)  time: 0.2761  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [23]  [1030/1229]  eta: 0:00:54  lr: 0.000001  loss: 0.4460 (0.4328)  loss_classifier: 0.1495 (0.1536)  loss_box_reg: 0.1486 (0.1422)  loss_objectness: 0.0864 (0.1026)  loss_rpn_box_reg: 0.0337 (0.0344)  time: 0.2720  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [23]  [1040/1229]  eta: 0:00:52  lr: 0.000001  loss: 0.3910 (0.4324)  loss_classifier: 0.1450 (0.1535)  loss_box_reg: 0.1252 (0.1422)  loss_objectness: 0.0691 (0.1023)  loss_rpn_box_reg: 0.0182 (0.0343)  time: 0.2757  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [23]  [1050/1229]  eta: 0:00:49  lr: 0.000001  loss: 0.4455 (0.4334)  loss_classifier: 0.1598 (0.1540)  loss_box_reg: 0.1786 (0.1428)  loss_objectness: 0.0755 (0.1024)  loss_rpn_box_reg: 0.0172 (0.0343)  time: 0.2812  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [23]  [1060/1229]  eta: 0:00:46  lr: 0.000001  loss: 0.4779 (0.4338)  loss_classifier: 0.1632 (0.1541)  loss_box_reg: 0.1898 (0.1433)  loss_objectness: 0.0876 (0.1023)  loss_rpn_box_reg: 0.0209 (0.0342)  time: 0.2743  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [23]  [1070/1229]  eta: 0:00:43  lr: 0.000001  loss: 0.4478 (0.4338)  loss_classifier: 0.1604 (0.1541)  loss_box_reg: 0.1637 (0.1433)  loss_objectness: 0.0861 (0.1022)  loss_rpn_box_reg: 0.0220 (0.0342)  time: 0.2719  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [23]  [1080/1229]  eta: 0:00:41  lr: 0.000001  loss: 0.3720 (0.4339)  loss_classifier: 0.1437 (0.1541)  loss_box_reg: 0.1525 (0.1436)  loss_objectness: 0.0734 (0.1020)  loss_rpn_box_reg: 0.0220 (0.0341)  time: 0.2723  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [23]  [1090/1229]  eta: 0:00:38  lr: 0.000001  loss: 0.4227 (0.4336)  loss_classifier: 0.1597 (0.1540)  loss_box_reg: 0.1525 (0.1437)  loss_objectness: 0.0688 (0.1019)  loss_rpn_box_reg: 0.0196 (0.0340)  time: 0.2683  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [23]  [1100/1229]  eta: 0:00:35  lr: 0.000001  loss: 0.3230 (0.4323)  loss_classifier: 0.1204 (0.1536)  loss_box_reg: 0.1051 (0.1431)  loss_objectness: 0.0757 (0.1018)  loss_rpn_box_reg: 0.0160 (0.0338)  time: 0.2698  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [23]  [1110/1229]  eta: 0:00:32  lr: 0.000001  loss: 0.3451 (0.4328)  loss_classifier: 0.1204 (0.1539)  loss_box_reg: 0.1006 (0.1434)  loss_objectness: 0.0757 (0.1017)  loss_rpn_box_reg: 0.0207 (0.0338)  time: 0.2809  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [23]  [1120/1229]  eta: 0:00:30  lr: 0.000001  loss: 0.4440 (0.4327)  loss_classifier: 0.1737 (0.1539)  loss_box_reg: 0.1415 (0.1435)  loss_objectness: 0.0693 (0.1015)  loss_rpn_box_reg: 0.0239 (0.0338)  time: 0.2824  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [23]  [1130/1229]  eta: 0:00:27  lr: 0.000001  loss: 0.3737 (0.4318)  loss_classifier: 0.1282 (0.1536)  loss_box_reg: 0.1213 (0.1432)  loss_objectness: 0.0743 (0.1013)  loss_rpn_box_reg: 0.0125 (0.0337)  time: 0.2699  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [23]  [1140/1229]  eta: 0:00:24  lr: 0.000001  loss: 0.3629 (0.4325)  loss_classifier: 0.1322 (0.1538)  loss_box_reg: 0.1042 (0.1433)  loss_objectness: 0.0905 (0.1015)  loss_rpn_box_reg: 0.0283 (0.0338)  time: 0.2725  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [23]  [1150/1229]  eta: 0:00:21  lr: 0.000001  loss: 0.4299 (0.4328)  loss_classifier: 0.1385 (0.1539)  loss_box_reg: 0.1448 (0.1436)  loss_objectness: 0.0921 (0.1015)  loss_rpn_box_reg: 0.0283 (0.0338)  time: 0.2766  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [23]  [1160/1229]  eta: 0:00:19  lr: 0.000001  loss: 0.4299 (0.4325)  loss_classifier: 0.1305 (0.1537)  loss_box_reg: 0.1628 (0.1437)  loss_objectness: 0.0744 (0.1013)  loss_rpn_box_reg: 0.0153 (0.0338)  time: 0.2729  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [23]  [1170/1229]  eta: 0:00:16  lr: 0.000001  loss: 0.3462 (0.4324)  loss_classifier: 0.1047 (0.1537)  loss_box_reg: 0.1019 (0.1437)  loss_objectness: 0.0720 (0.1011)  loss_rpn_box_reg: 0.0153 (0.0339)  time: 0.2741  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [23]  [1180/1229]  eta: 0:00:13  lr: 0.000001  loss: 0.4522 (0.4332)  loss_classifier: 0.1671 (0.1539)  loss_box_reg: 0.1392 (0.1440)  loss_objectness: 0.0868 (0.1014)  loss_rpn_box_reg: 0.0319 (0.0339)  time: 0.2741  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [23]  [1190/1229]  eta: 0:00:10  lr: 0.000001  loss: 0.4926 (0.4339)  loss_classifier: 0.1724 (0.1542)  loss_box_reg: 0.1591 (0.1441)  loss_objectness: 0.1076 (0.1016)  loss_rpn_box_reg: 0.0376 (0.0339)  time: 0.2748  data: 0.1372  max mem: 1751\n",
      "Training Epoch: [23]  [1200/1229]  eta: 0:00:07  lr: 0.000001  loss: 0.4369 (0.4342)  loss_classifier: 0.1664 (0.1543)  loss_box_reg: 0.1423 (0.1444)  loss_objectness: 0.1020 (0.1015)  loss_rpn_box_reg: 0.0263 (0.0340)  time: 0.2722  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [23]  [1210/1229]  eta: 0:00:05  lr: 0.000001  loss: 0.2983 (0.4337)  loss_classifier: 0.0941 (0.1541)  loss_box_reg: 0.0769 (0.1441)  loss_objectness: 0.0915 (0.1015)  loss_rpn_box_reg: 0.0145 (0.0341)  time: 0.2670  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [23]  [1220/1229]  eta: 0:00:02  lr: 0.000001  loss: 0.2983 (0.4332)  loss_classifier: 0.1048 (0.1539)  loss_box_reg: 0.0789 (0.1439)  loss_objectness: 0.0728 (0.1014)  loss_rpn_box_reg: 0.0102 (0.0340)  time: 0.2686  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [23]  [1228/1229]  eta: 0:00:00  lr: 0.000001  loss: 0.3254 (0.4335)  loss_classifier: 0.1256 (0.1540)  loss_box_reg: 0.0869 (0.1441)  loss_objectness: 0.0838 (0.1015)  loss_rpn_box_reg: 0.0144 (0.0340)  time: 0.2722  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [23] Total time: 0:05:38 (0.2754 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:53  model_time: 0.3370 (0.3370)  evaluator_time: 0.0020 (0.0020)  time: 0.3700  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:27  model_time: 0.0790 (0.0832)  evaluator_time: 0.0050 (0.0086)  time: 0.1320  data: 0.0407  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0840 (0.0816)  evaluator_time: 0.0030 (0.0079)  time: 0.1201  data: 0.0306  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0740 (0.0807)  evaluator_time: 0.0040 (0.0076)  time: 0.1196  data: 0.0350  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0740 (0.0806)  evaluator_time: 0.0020 (0.0076)  time: 0.1169  data: 0.0335  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1247 s / it)\n",
      "Averaged stats: model_time: 0.0740 (0.0806)  evaluator_time: 0.0020 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [23]  [  0/308]  eta: 0:00:37  lr: 0.000001  loss: 0.1638 (0.1638)  loss_classifier: 0.0583 (0.0583)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0255 (0.0255)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1210  data: 0.0280  max mem: 1751\n",
      "Testing Epoch: [23]  [100/308]  eta: 0:00:28  lr: 0.000001  loss: 0.3164 (0.4804)  loss_classifier: 0.1339 (0.1547)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0589 (0.1014)  loss_rpn_box_reg: 0.0186 (0.0519)  time: 0.1394  data: 0.0379  max mem: 1751\n",
      "Testing Epoch: [23]  [200/308]  eta: 0:00:14  lr: 0.000001  loss: 0.3526 (0.4558)  loss_classifier: 0.1389 (0.1492)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0625 (0.0943)  loss_rpn_box_reg: 0.0197 (0.0491)  time: 0.1380  data: 0.0321  max mem: 1751\n",
      "Testing Epoch: [23]  [300/308]  eta: 0:00:01  lr: 0.000001  loss: 0.4659 (0.4531)  loss_classifier: 0.1555 (0.1494)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0742 (0.0922)  loss_rpn_box_reg: 0.0265 (0.0475)  time: 0.1380  data: 0.0425  max mem: 1751\n",
      "Testing Epoch: [23]  [307/308]  eta: 0:00:00  lr: 0.000001  loss: 0.4659 (0.4533)  loss_classifier: 0.1860 (0.1496)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0714 (0.0923)  loss_rpn_box_reg: 0.0271 (0.0470)  time: 0.1300  data: 0.0346  max mem: 1751\n",
      "Testing Epoch: [23] Total time: 0:00:42 (0.1371 s / it)\n",
      "Training Epoch: [24]  [   0/1229]  eta: 0:05:26  lr: 0.000001  loss: 0.2667 (0.2667)  loss_classifier: 0.0946 (0.0946)  loss_box_reg: 0.1129 (0.1129)  loss_objectness: 0.0441 (0.0441)  loss_rpn_box_reg: 0.0151 (0.0151)  time: 0.2660  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [24]  [  10/1229]  eta: 0:05:27  lr: 0.000001  loss: 0.4017 (0.4069)  loss_classifier: 0.1523 (0.1462)  loss_box_reg: 0.1367 (0.1565)  loss_objectness: 0.0729 (0.0751)  loss_rpn_box_reg: 0.0219 (0.0291)  time: 0.2685  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [24]  [  20/1229]  eta: 0:05:30  lr: 0.000001  loss: 0.4160 (0.4619)  loss_classifier: 0.1523 (0.1629)  loss_box_reg: 0.1523 (0.1650)  loss_objectness: 0.0847 (0.0886)  loss_rpn_box_reg: 0.0299 (0.0455)  time: 0.2736  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [24]  [  30/1229]  eta: 0:05:28  lr: 0.000001  loss: 0.3895 (0.4476)  loss_classifier: 0.1495 (0.1594)  loss_box_reg: 0.1558 (0.1587)  loss_objectness: 0.1016 (0.0885)  loss_rpn_box_reg: 0.0339 (0.0411)  time: 0.2775  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [24]  [  40/1229]  eta: 0:05:27  lr: 0.000001  loss: 0.3817 (0.4322)  loss_classifier: 0.1454 (0.1531)  loss_box_reg: 0.1477 (0.1576)  loss_objectness: 0.0723 (0.0836)  loss_rpn_box_reg: 0.0184 (0.0379)  time: 0.2775  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [24]  [  50/1229]  eta: 0:05:25  lr: 0.000001  loss: 0.3518 (0.4222)  loss_classifier: 0.1186 (0.1495)  loss_box_reg: 0.1240 (0.1545)  loss_objectness: 0.0564 (0.0843)  loss_rpn_box_reg: 0.0129 (0.0339)  time: 0.2782  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [24]  [  60/1229]  eta: 0:05:21  lr: 0.000001  loss: 0.3518 (0.4382)  loss_classifier: 0.1315 (0.1556)  loss_box_reg: 0.1121 (0.1610)  loss_objectness: 0.0894 (0.0889)  loss_rpn_box_reg: 0.0141 (0.0328)  time: 0.2741  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [24]  [  70/1229]  eta: 0:05:19  lr: 0.000001  loss: 0.4408 (0.4536)  loss_classifier: 0.1659 (0.1592)  loss_box_reg: 0.1378 (0.1664)  loss_objectness: 0.0940 (0.0926)  loss_rpn_box_reg: 0.0191 (0.0353)  time: 0.2746  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [24]  [  80/1229]  eta: 0:05:15  lr: 0.000001  loss: 0.5405 (0.4779)  loss_classifier: 0.1798 (0.1671)  loss_box_reg: 0.1378 (0.1679)  loss_objectness: 0.1126 (0.1026)  loss_rpn_box_reg: 0.0316 (0.0403)  time: 0.2732  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [24]  [  90/1229]  eta: 0:05:12  lr: 0.000001  loss: 0.5359 (0.4667)  loss_classifier: 0.1798 (0.1637)  loss_box_reg: 0.1342 (0.1633)  loss_objectness: 0.1108 (0.1012)  loss_rpn_box_reg: 0.0256 (0.0385)  time: 0.2691  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [24]  [ 100/1229]  eta: 0:05:08  lr: 0.000001  loss: 0.3198 (0.4592)  loss_classifier: 0.1132 (0.1611)  loss_box_reg: 0.0959 (0.1614)  loss_objectness: 0.0798 (0.0991)  loss_rpn_box_reg: 0.0161 (0.0377)  time: 0.2676  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [24]  [ 110/1229]  eta: 0:05:05  lr: 0.000001  loss: 0.4249 (0.4649)  loss_classifier: 0.1600 (0.1639)  loss_box_reg: 0.1240 (0.1641)  loss_objectness: 0.0798 (0.1002)  loss_rpn_box_reg: 0.0205 (0.0368)  time: 0.2701  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [24]  [ 120/1229]  eta: 0:05:03  lr: 0.000001  loss: 0.4938 (0.4615)  loss_classifier: 0.1635 (0.1624)  loss_box_reg: 0.1731 (0.1639)  loss_objectness: 0.0797 (0.0996)  loss_rpn_box_reg: 0.0216 (0.0356)  time: 0.2740  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [24]  [ 130/1229]  eta: 0:04:59  lr: 0.000001  loss: 0.3812 (0.4566)  loss_classifier: 0.1075 (0.1603)  loss_box_reg: 0.1019 (0.1600)  loss_objectness: 0.0797 (0.0988)  loss_rpn_box_reg: 0.0216 (0.0375)  time: 0.2704  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [24]  [ 140/1229]  eta: 0:04:58  lr: 0.000001  loss: 0.3721 (0.4544)  loss_classifier: 0.1227 (0.1596)  loss_box_reg: 0.1117 (0.1600)  loss_objectness: 0.0798 (0.0973)  loss_rpn_box_reg: 0.0242 (0.0375)  time: 0.2781  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [24]  [ 150/1229]  eta: 0:04:55  lr: 0.000001  loss: 0.2904 (0.4482)  loss_classifier: 0.1039 (0.1579)  loss_box_reg: 0.1041 (0.1580)  loss_objectness: 0.0721 (0.0962)  loss_rpn_box_reg: 0.0140 (0.0361)  time: 0.2830  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [24]  [ 160/1229]  eta: 0:04:52  lr: 0.000001  loss: 0.3131 (0.4513)  loss_classifier: 0.1070 (0.1589)  loss_box_reg: 0.1227 (0.1585)  loss_objectness: 0.0722 (0.0969)  loss_rpn_box_reg: 0.0177 (0.0370)  time: 0.2731  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [24]  [ 170/1229]  eta: 0:04:50  lr: 0.000001  loss: 0.4791 (0.4583)  loss_classifier: 0.1715 (0.1619)  loss_box_reg: 0.1622 (0.1606)  loss_objectness: 0.1071 (0.0990)  loss_rpn_box_reg: 0.0276 (0.0369)  time: 0.2722  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [24]  [ 180/1229]  eta: 0:04:47  lr: 0.000001  loss: 0.4174 (0.4516)  loss_classifier: 0.1583 (0.1595)  loss_box_reg: 0.1440 (0.1577)  loss_objectness: 0.0944 (0.0985)  loss_rpn_box_reg: 0.0254 (0.0359)  time: 0.2748  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [24]  [ 190/1229]  eta: 0:04:44  lr: 0.000001  loss: 0.3940 (0.4505)  loss_classifier: 0.1392 (0.1595)  loss_box_reg: 0.0938 (0.1581)  loss_objectness: 0.0787 (0.0976)  loss_rpn_box_reg: 0.0174 (0.0352)  time: 0.2739  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [24]  [ 200/1229]  eta: 0:04:41  lr: 0.000001  loss: 0.3184 (0.4443)  loss_classifier: 0.1083 (0.1573)  loss_box_reg: 0.0914 (0.1553)  loss_objectness: 0.0787 (0.0967)  loss_rpn_box_reg: 0.0206 (0.0349)  time: 0.2706  data: 0.1293  max mem: 1751\n",
      "Training Epoch: [24]  [ 210/1229]  eta: 0:04:38  lr: 0.000001  loss: 0.2933 (0.4432)  loss_classifier: 0.1082 (0.1571)  loss_box_reg: 0.0914 (0.1545)  loss_objectness: 0.0826 (0.0971)  loss_rpn_box_reg: 0.0166 (0.0346)  time: 0.2673  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [24]  [ 220/1229]  eta: 0:04:35  lr: 0.000001  loss: 0.4083 (0.4428)  loss_classifier: 0.1132 (0.1567)  loss_box_reg: 0.0927 (0.1546)  loss_objectness: 0.0769 (0.0972)  loss_rpn_box_reg: 0.0232 (0.0344)  time: 0.2724  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [24]  [ 230/1229]  eta: 0:04:33  lr: 0.000001  loss: 0.3341 (0.4405)  loss_classifier: 0.1006 (0.1553)  loss_box_reg: 0.0927 (0.1535)  loss_objectness: 0.0788 (0.0970)  loss_rpn_box_reg: 0.0201 (0.0347)  time: 0.2774  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [24]  [ 240/1229]  eta: 0:04:30  lr: 0.000001  loss: 0.3341 (0.4392)  loss_classifier: 0.1075 (0.1553)  loss_box_reg: 0.1036 (0.1529)  loss_objectness: 0.0861 (0.0968)  loss_rpn_box_reg: 0.0164 (0.0342)  time: 0.2736  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [24]  [ 250/1229]  eta: 0:04:27  lr: 0.000001  loss: 0.3778 (0.4379)  loss_classifier: 0.1395 (0.1549)  loss_box_reg: 0.1074 (0.1522)  loss_objectness: 0.0851 (0.0964)  loss_rpn_box_reg: 0.0159 (0.0344)  time: 0.2672  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [24]  [ 260/1229]  eta: 0:04:24  lr: 0.000001  loss: 0.4564 (0.4362)  loss_classifier: 0.1449 (0.1543)  loss_box_reg: 0.1610 (0.1519)  loss_objectness: 0.0851 (0.0959)  loss_rpn_box_reg: 0.0207 (0.0341)  time: 0.2689  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [24]  [ 270/1229]  eta: 0:04:21  lr: 0.000001  loss: 0.3878 (0.4349)  loss_classifier: 0.1447 (0.1540)  loss_box_reg: 0.1272 (0.1512)  loss_objectness: 0.0920 (0.0959)  loss_rpn_box_reg: 0.0243 (0.0338)  time: 0.2706  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [24]  [ 280/1229]  eta: 0:04:18  lr: 0.000001  loss: 0.3878 (0.4342)  loss_classifier: 0.1340 (0.1538)  loss_box_reg: 0.1199 (0.1508)  loss_objectness: 0.0975 (0.0961)  loss_rpn_box_reg: 0.0221 (0.0335)  time: 0.2681  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [24]  [ 290/1229]  eta: 0:04:16  lr: 0.000001  loss: 0.3754 (0.4357)  loss_classifier: 0.1353 (0.1545)  loss_box_reg: 0.1220 (0.1519)  loss_objectness: 0.0788 (0.0961)  loss_rpn_box_reg: 0.0210 (0.0332)  time: 0.2684  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [24]  [ 300/1229]  eta: 0:04:13  lr: 0.000001  loss: 0.3703 (0.4337)  loss_classifier: 0.1456 (0.1544)  loss_box_reg: 0.1169 (0.1509)  loss_objectness: 0.0755 (0.0956)  loss_rpn_box_reg: 0.0181 (0.0328)  time: 0.2767  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [24]  [ 310/1229]  eta: 0:04:10  lr: 0.000001  loss: 0.3559 (0.4334)  loss_classifier: 0.1299 (0.1545)  loss_box_reg: 0.1294 (0.1512)  loss_objectness: 0.0624 (0.0951)  loss_rpn_box_reg: 0.0149 (0.0326)  time: 0.2779  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [24]  [ 320/1229]  eta: 0:04:08  lr: 0.000001  loss: 0.3964 (0.4332)  loss_classifier: 0.1299 (0.1542)  loss_box_reg: 0.1412 (0.1510)  loss_objectness: 0.0768 (0.0955)  loss_rpn_box_reg: 0.0186 (0.0325)  time: 0.2742  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [24]  [ 330/1229]  eta: 0:04:05  lr: 0.000001  loss: 0.3964 (0.4327)  loss_classifier: 0.1213 (0.1539)  loss_box_reg: 0.1154 (0.1510)  loss_objectness: 0.0837 (0.0954)  loss_rpn_box_reg: 0.0213 (0.0324)  time: 0.2740  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [24]  [ 340/1229]  eta: 0:04:02  lr: 0.000001  loss: 0.3396 (0.4315)  loss_classifier: 0.1205 (0.1533)  loss_box_reg: 0.1154 (0.1506)  loss_objectness: 0.0759 (0.0953)  loss_rpn_box_reg: 0.0153 (0.0324)  time: 0.2708  data: 0.1298  max mem: 1751\n",
      "Training Epoch: [24]  [ 350/1229]  eta: 0:04:00  lr: 0.000001  loss: 0.4058 (0.4323)  loss_classifier: 0.1407 (0.1536)  loss_box_reg: 0.1193 (0.1505)  loss_objectness: 0.0979 (0.0960)  loss_rpn_box_reg: 0.0222 (0.0322)  time: 0.2729  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [24]  [ 360/1229]  eta: 0:03:57  lr: 0.000001  loss: 0.4404 (0.4317)  loss_classifier: 0.1538 (0.1533)  loss_box_reg: 0.1143 (0.1504)  loss_objectness: 0.0887 (0.0956)  loss_rpn_box_reg: 0.0222 (0.0324)  time: 0.2789  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [24]  [ 370/1229]  eta: 0:03:54  lr: 0.000001  loss: 0.4149 (0.4316)  loss_classifier: 0.1490 (0.1536)  loss_box_reg: 0.1166 (0.1500)  loss_objectness: 0.0747 (0.0954)  loss_rpn_box_reg: 0.0283 (0.0327)  time: 0.2769  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [24]  [ 380/1229]  eta: 0:03:52  lr: 0.000001  loss: 0.4645 (0.4334)  loss_classifier: 0.1587 (0.1539)  loss_box_reg: 0.1476 (0.1503)  loss_objectness: 0.0792 (0.0962)  loss_rpn_box_reg: 0.0265 (0.0329)  time: 0.2785  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [24]  [ 390/1229]  eta: 0:03:49  lr: 0.000001  loss: 0.5174 (0.4365)  loss_classifier: 0.1851 (0.1550)  loss_box_reg: 0.1729 (0.1517)  loss_objectness: 0.1008 (0.0965)  loss_rpn_box_reg: 0.0290 (0.0333)  time: 0.2818  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [24]  [ 400/1229]  eta: 0:03:46  lr: 0.000001  loss: 0.5661 (0.4414)  loss_classifier: 0.1949 (0.1563)  loss_box_reg: 0.1768 (0.1538)  loss_objectness: 0.1011 (0.0972)  loss_rpn_box_reg: 0.0318 (0.0341)  time: 0.2732  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [24]  [ 410/1229]  eta: 0:03:44  lr: 0.000001  loss: 0.4215 (0.4397)  loss_classifier: 0.1521 (0.1559)  loss_box_reg: 0.1517 (0.1533)  loss_objectness: 0.0905 (0.0967)  loss_rpn_box_reg: 0.0249 (0.0338)  time: 0.2779  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [24]  [ 420/1229]  eta: 0:03:41  lr: 0.000001  loss: 0.3646 (0.4398)  loss_classifier: 0.1434 (0.1563)  loss_box_reg: 0.1091 (0.1527)  loss_objectness: 0.0847 (0.0973)  loss_rpn_box_reg: 0.0145 (0.0336)  time: 0.2790  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [24]  [ 430/1229]  eta: 0:03:38  lr: 0.000001  loss: 0.3025 (0.4386)  loss_classifier: 0.1346 (0.1559)  loss_box_reg: 0.1071 (0.1527)  loss_objectness: 0.0751 (0.0964)  loss_rpn_box_reg: 0.0157 (0.0336)  time: 0.2740  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [24]  [ 440/1229]  eta: 0:03:36  lr: 0.000001  loss: 0.2892 (0.4379)  loss_classifier: 0.1203 (0.1555)  loss_box_reg: 0.1071 (0.1520)  loss_objectness: 0.0561 (0.0967)  loss_rpn_box_reg: 0.0157 (0.0337)  time: 0.2792  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [24]  [ 450/1229]  eta: 0:03:33  lr: 0.000001  loss: 0.4009 (0.4376)  loss_classifier: 0.1464 (0.1554)  loss_box_reg: 0.1443 (0.1521)  loss_objectness: 0.0818 (0.0961)  loss_rpn_box_reg: 0.0247 (0.0339)  time: 0.2748  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [24]  [ 460/1229]  eta: 0:03:30  lr: 0.000001  loss: 0.4619 (0.4389)  loss_classifier: 0.1721 (0.1559)  loss_box_reg: 0.1443 (0.1524)  loss_objectness: 0.0901 (0.0967)  loss_rpn_box_reg: 0.0269 (0.0339)  time: 0.2711  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [24]  [ 470/1229]  eta: 0:03:27  lr: 0.000001  loss: 0.4619 (0.4381)  loss_classifier: 0.1726 (0.1558)  loss_box_reg: 0.1265 (0.1525)  loss_objectness: 0.0896 (0.0963)  loss_rpn_box_reg: 0.0211 (0.0336)  time: 0.2733  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [24]  [ 480/1229]  eta: 0:03:25  lr: 0.000001  loss: 0.3629 (0.4376)  loss_classifier: 0.1426 (0.1557)  loss_box_reg: 0.0897 (0.1524)  loss_objectness: 0.0827 (0.0961)  loss_rpn_box_reg: 0.0191 (0.0334)  time: 0.2753  data: 0.1373  max mem: 1751\n",
      "Training Epoch: [24]  [ 490/1229]  eta: 0:03:22  lr: 0.000001  loss: 0.3572 (0.4355)  loss_classifier: 0.1181 (0.1550)  loss_box_reg: 0.0820 (0.1516)  loss_objectness: 0.0854 (0.0959)  loss_rpn_box_reg: 0.0191 (0.0331)  time: 0.2756  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [24]  [ 500/1229]  eta: 0:03:19  lr: 0.000001  loss: 0.3572 (0.4344)  loss_classifier: 0.1168 (0.1546)  loss_box_reg: 0.0820 (0.1509)  loss_objectness: 0.0817 (0.0960)  loss_rpn_box_reg: 0.0134 (0.0329)  time: 0.2747  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [24]  [ 510/1229]  eta: 0:03:16  lr: 0.000001  loss: 0.3820 (0.4356)  loss_classifier: 0.1345 (0.1549)  loss_box_reg: 0.1153 (0.1510)  loss_objectness: 0.0958 (0.0968)  loss_rpn_box_reg: 0.0160 (0.0330)  time: 0.2720  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [24]  [ 520/1229]  eta: 0:03:14  lr: 0.000001  loss: 0.3586 (0.4350)  loss_classifier: 0.1185 (0.1542)  loss_box_reg: 0.0937 (0.1506)  loss_objectness: 0.0961 (0.0966)  loss_rpn_box_reg: 0.0254 (0.0335)  time: 0.2688  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [24]  [ 530/1229]  eta: 0:03:11  lr: 0.000001  loss: 0.3878 (0.4360)  loss_classifier: 0.1224 (0.1546)  loss_box_reg: 0.1204 (0.1508)  loss_objectness: 0.0953 (0.0968)  loss_rpn_box_reg: 0.0348 (0.0338)  time: 0.2734  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [24]  [ 540/1229]  eta: 0:03:08  lr: 0.000001  loss: 0.4914 (0.4370)  loss_classifier: 0.1906 (0.1552)  loss_box_reg: 0.1687 (0.1514)  loss_objectness: 0.0953 (0.0968)  loss_rpn_box_reg: 0.0220 (0.0336)  time: 0.2756  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [24]  [ 550/1229]  eta: 0:03:05  lr: 0.000001  loss: 0.3668 (0.4354)  loss_classifier: 0.1304 (0.1546)  loss_box_reg: 0.1009 (0.1503)  loss_objectness: 0.0692 (0.0968)  loss_rpn_box_reg: 0.0187 (0.0336)  time: 0.2746  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [24]  [ 560/1229]  eta: 0:03:03  lr: 0.000001  loss: 0.3441 (0.4346)  loss_classifier: 0.1113 (0.1544)  loss_box_reg: 0.0866 (0.1500)  loss_objectness: 0.0709 (0.0965)  loss_rpn_box_reg: 0.0186 (0.0336)  time: 0.2744  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [24]  [ 570/1229]  eta: 0:03:00  lr: 0.000001  loss: 0.3676 (0.4341)  loss_classifier: 0.1324 (0.1540)  loss_box_reg: 0.1049 (0.1493)  loss_objectness: 0.0709 (0.0969)  loss_rpn_box_reg: 0.0198 (0.0339)  time: 0.2675  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [24]  [ 580/1229]  eta: 0:02:57  lr: 0.000001  loss: 0.3754 (0.4330)  loss_classifier: 0.1324 (0.1535)  loss_box_reg: 0.1049 (0.1489)  loss_objectness: 0.0812 (0.0969)  loss_rpn_box_reg: 0.0203 (0.0338)  time: 0.2688  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [24]  [ 590/1229]  eta: 0:02:54  lr: 0.000001  loss: 0.3754 (0.4332)  loss_classifier: 0.1334 (0.1536)  loss_box_reg: 0.1146 (0.1492)  loss_objectness: 0.0890 (0.0968)  loss_rpn_box_reg: 0.0225 (0.0337)  time: 0.2747  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [24]  [ 600/1229]  eta: 0:02:52  lr: 0.000001  loss: 0.3919 (0.4339)  loss_classifier: 0.1385 (0.1537)  loss_box_reg: 0.1428 (0.1492)  loss_objectness: 0.0928 (0.0970)  loss_rpn_box_reg: 0.0235 (0.0341)  time: 0.2740  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [24]  [ 610/1229]  eta: 0:02:49  lr: 0.000001  loss: 0.3895 (0.4333)  loss_classifier: 0.1537 (0.1535)  loss_box_reg: 0.1396 (0.1488)  loss_objectness: 0.0928 (0.0970)  loss_rpn_box_reg: 0.0224 (0.0339)  time: 0.2728  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [24]  [ 620/1229]  eta: 0:02:46  lr: 0.000001  loss: 0.3880 (0.4315)  loss_classifier: 0.1476 (0.1528)  loss_box_reg: 0.0968 (0.1478)  loss_objectness: 0.0914 (0.0971)  loss_rpn_box_reg: 0.0169 (0.0338)  time: 0.2634  data: 0.1290  max mem: 1751\n",
      "Training Epoch: [24]  [ 630/1229]  eta: 0:02:43  lr: 0.000001  loss: 0.2768 (0.4311)  loss_classifier: 0.0891 (0.1526)  loss_box_reg: 0.0645 (0.1477)  loss_objectness: 0.0856 (0.0971)  loss_rpn_box_reg: 0.0129 (0.0338)  time: 0.2629  data: 0.1291  max mem: 1751\n",
      "Training Epoch: [24]  [ 640/1229]  eta: 0:02:40  lr: 0.000001  loss: 0.3091 (0.4335)  loss_classifier: 0.1004 (0.1534)  loss_box_reg: 0.0650 (0.1484)  loss_objectness: 0.1109 (0.0975)  loss_rpn_box_reg: 0.0273 (0.0342)  time: 0.2683  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [24]  [ 650/1229]  eta: 0:02:38  lr: 0.000001  loss: 0.4158 (0.4335)  loss_classifier: 0.1511 (0.1534)  loss_box_reg: 0.1177 (0.1484)  loss_objectness: 0.1109 (0.0977)  loss_rpn_box_reg: 0.0266 (0.0341)  time: 0.2704  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [24]  [ 660/1229]  eta: 0:02:35  lr: 0.000001  loss: 0.3832 (0.4345)  loss_classifier: 0.1455 (0.1538)  loss_box_reg: 0.1152 (0.1488)  loss_objectness: 0.1057 (0.0979)  loss_rpn_box_reg: 0.0209 (0.0339)  time: 0.2731  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [24]  [ 670/1229]  eta: 0:02:32  lr: 0.000001  loss: 0.3722 (0.4334)  loss_classifier: 0.1426 (0.1535)  loss_box_reg: 0.1152 (0.1484)  loss_objectness: 0.0891 (0.0977)  loss_rpn_box_reg: 0.0219 (0.0339)  time: 0.2755  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [24]  [ 680/1229]  eta: 0:02:30  lr: 0.000001  loss: 0.2566 (0.4317)  loss_classifier: 0.0957 (0.1529)  loss_box_reg: 0.0787 (0.1478)  loss_objectness: 0.0681 (0.0974)  loss_rpn_box_reg: 0.0199 (0.0337)  time: 0.2777  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [24]  [ 690/1229]  eta: 0:02:27  lr: 0.000001  loss: 0.2112 (0.4297)  loss_classifier: 0.0814 (0.1523)  loss_box_reg: 0.0580 (0.1470)  loss_objectness: 0.0534 (0.0969)  loss_rpn_box_reg: 0.0130 (0.0335)  time: 0.2734  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [24]  [ 700/1229]  eta: 0:02:24  lr: 0.000001  loss: 0.3135 (0.4299)  loss_classifier: 0.1034 (0.1524)  loss_box_reg: 0.1052 (0.1468)  loss_objectness: 0.0717 (0.0971)  loss_rpn_box_reg: 0.0152 (0.0336)  time: 0.2741  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [24]  [ 710/1229]  eta: 0:02:21  lr: 0.000001  loss: 0.5017 (0.4311)  loss_classifier: 0.1367 (0.1529)  loss_box_reg: 0.1252 (0.1469)  loss_objectness: 0.1026 (0.0976)  loss_rpn_box_reg: 0.0278 (0.0336)  time: 0.2751  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [24]  [ 720/1229]  eta: 0:02:19  lr: 0.000001  loss: 0.3484 (0.4303)  loss_classifier: 0.1254 (0.1526)  loss_box_reg: 0.1192 (0.1465)  loss_objectness: 0.1166 (0.0975)  loss_rpn_box_reg: 0.0278 (0.0337)  time: 0.2694  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [24]  [ 730/1229]  eta: 0:02:16  lr: 0.000001  loss: 0.3257 (0.4295)  loss_classifier: 0.1011 (0.1524)  loss_box_reg: 0.0756 (0.1464)  loss_objectness: 0.0599 (0.0971)  loss_rpn_box_reg: 0.0117 (0.0336)  time: 0.2682  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [24]  [ 740/1229]  eta: 0:02:13  lr: 0.000001  loss: 0.2909 (0.4279)  loss_classifier: 0.0923 (0.1518)  loss_box_reg: 0.0756 (0.1459)  loss_objectness: 0.0578 (0.0968)  loss_rpn_box_reg: 0.0117 (0.0334)  time: 0.2718  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [24]  [ 750/1229]  eta: 0:02:10  lr: 0.000001  loss: 0.3579 (0.4290)  loss_classifier: 0.1318 (0.1523)  loss_box_reg: 0.0856 (0.1463)  loss_objectness: 0.0888 (0.0970)  loss_rpn_box_reg: 0.0178 (0.0334)  time: 0.2697  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [24]  [ 760/1229]  eta: 0:02:08  lr: 0.000001  loss: 0.4583 (0.4297)  loss_classifier: 0.1727 (0.1526)  loss_box_reg: 0.1669 (0.1465)  loss_objectness: 0.0927 (0.0973)  loss_rpn_box_reg: 0.0202 (0.0333)  time: 0.2705  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [24]  [ 770/1229]  eta: 0:02:05  lr: 0.000001  loss: 0.3347 (0.4284)  loss_classifier: 0.1343 (0.1522)  loss_box_reg: 0.1017 (0.1461)  loss_objectness: 0.0783 (0.0970)  loss_rpn_box_reg: 0.0173 (0.0331)  time: 0.2771  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [24]  [ 780/1229]  eta: 0:02:02  lr: 0.000001  loss: 0.2883 (0.4275)  loss_classifier: 0.1016 (0.1518)  loss_box_reg: 0.0959 (0.1457)  loss_objectness: 0.0696 (0.0969)  loss_rpn_box_reg: 0.0128 (0.0330)  time: 0.2774  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [24]  [ 790/1229]  eta: 0:01:59  lr: 0.000001  loss: 0.3388 (0.4277)  loss_classifier: 0.1245 (0.1520)  loss_box_reg: 0.0732 (0.1458)  loss_objectness: 0.0913 (0.0971)  loss_rpn_box_reg: 0.0197 (0.0328)  time: 0.2705  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [24]  [ 800/1229]  eta: 0:01:57  lr: 0.000001  loss: 0.4258 (0.4290)  loss_classifier: 0.1704 (0.1526)  loss_box_reg: 0.1279 (0.1464)  loss_objectness: 0.1004 (0.0970)  loss_rpn_box_reg: 0.0197 (0.0331)  time: 0.2691  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [24]  [ 810/1229]  eta: 0:01:54  lr: 0.000001  loss: 0.5405 (0.4289)  loss_classifier: 0.1823 (0.1524)  loss_box_reg: 0.1331 (0.1464)  loss_objectness: 0.0748 (0.0969)  loss_rpn_box_reg: 0.0196 (0.0331)  time: 0.2712  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [24]  [ 820/1229]  eta: 0:01:51  lr: 0.000001  loss: 0.3531 (0.4289)  loss_classifier: 0.1367 (0.1525)  loss_box_reg: 0.1080 (0.1460)  loss_objectness: 0.0820 (0.0970)  loss_rpn_box_reg: 0.0213 (0.0333)  time: 0.2653  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [24]  [ 830/1229]  eta: 0:01:48  lr: 0.000001  loss: 0.4137 (0.4291)  loss_classifier: 0.1558 (0.1525)  loss_box_reg: 0.1101 (0.1460)  loss_objectness: 0.0885 (0.0971)  loss_rpn_box_reg: 0.0213 (0.0334)  time: 0.2742  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [24]  [ 840/1229]  eta: 0:01:46  lr: 0.000001  loss: 0.4361 (0.4299)  loss_classifier: 0.1595 (0.1528)  loss_box_reg: 0.1337 (0.1462)  loss_objectness: 0.0981 (0.0974)  loss_rpn_box_reg: 0.0178 (0.0335)  time: 0.2807  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [24]  [ 850/1229]  eta: 0:01:43  lr: 0.000001  loss: 0.3624 (0.4294)  loss_classifier: 0.1348 (0.1527)  loss_box_reg: 0.0998 (0.1459)  loss_objectness: 0.0923 (0.0974)  loss_rpn_box_reg: 0.0130 (0.0335)  time: 0.2704  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [24]  [ 860/1229]  eta: 0:01:40  lr: 0.000001  loss: 0.3535 (0.4294)  loss_classifier: 0.1197 (0.1527)  loss_box_reg: 0.0998 (0.1460)  loss_objectness: 0.0854 (0.0974)  loss_rpn_box_reg: 0.0188 (0.0333)  time: 0.2652  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [24]  [ 870/1229]  eta: 0:01:37  lr: 0.000001  loss: 0.3642 (0.4290)  loss_classifier: 0.1246 (0.1525)  loss_box_reg: 0.1127 (0.1459)  loss_objectness: 0.0900 (0.0974)  loss_rpn_box_reg: 0.0233 (0.0333)  time: 0.2657  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [24]  [ 880/1229]  eta: 0:01:35  lr: 0.000001  loss: 0.3519 (0.4287)  loss_classifier: 0.1242 (0.1525)  loss_box_reg: 0.1127 (0.1458)  loss_objectness: 0.0827 (0.0972)  loss_rpn_box_reg: 0.0155 (0.0333)  time: 0.2727  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [24]  [ 890/1229]  eta: 0:01:32  lr: 0.000001  loss: 0.3164 (0.4290)  loss_classifier: 0.1233 (0.1526)  loss_box_reg: 0.1098 (0.1457)  loss_objectness: 0.0824 (0.0973)  loss_rpn_box_reg: 0.0181 (0.0333)  time: 0.2760  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [24]  [ 900/1229]  eta: 0:01:29  lr: 0.000001  loss: 0.3164 (0.4286)  loss_classifier: 0.1190 (0.1525)  loss_box_reg: 0.0938 (0.1456)  loss_objectness: 0.0791 (0.0971)  loss_rpn_box_reg: 0.0181 (0.0334)  time: 0.2732  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [24]  [ 910/1229]  eta: 0:01:27  lr: 0.000001  loss: 0.4101 (0.4291)  loss_classifier: 0.1323 (0.1526)  loss_box_reg: 0.1081 (0.1454)  loss_objectness: 0.0824 (0.0975)  loss_rpn_box_reg: 0.0227 (0.0336)  time: 0.2700  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [24]  [ 920/1229]  eta: 0:01:24  lr: 0.000001  loss: 0.4324 (0.4290)  loss_classifier: 0.1771 (0.1527)  loss_box_reg: 0.1107 (0.1453)  loss_objectness: 0.0982 (0.0975)  loss_rpn_box_reg: 0.0284 (0.0335)  time: 0.2718  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [24]  [ 930/1229]  eta: 0:01:21  lr: 0.000001  loss: 0.3875 (0.4286)  loss_classifier: 0.1404 (0.1525)  loss_box_reg: 0.1153 (0.1452)  loss_objectness: 0.0806 (0.0974)  loss_rpn_box_reg: 0.0154 (0.0335)  time: 0.2751  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [24]  [ 940/1229]  eta: 0:01:18  lr: 0.000001  loss: 0.3879 (0.4293)  loss_classifier: 0.1429 (0.1527)  loss_box_reg: 0.1214 (0.1452)  loss_objectness: 0.1030 (0.0979)  loss_rpn_box_reg: 0.0191 (0.0335)  time: 0.2716  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [24]  [ 950/1229]  eta: 0:01:16  lr: 0.000001  loss: 0.4528 (0.4293)  loss_classifier: 0.1555 (0.1528)  loss_box_reg: 0.1214 (0.1454)  loss_objectness: 0.1030 (0.0977)  loss_rpn_box_reg: 0.0226 (0.0334)  time: 0.2713  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [24]  [ 960/1229]  eta: 0:01:13  lr: 0.000001  loss: 0.3333 (0.4293)  loss_classifier: 0.1212 (0.1527)  loss_box_reg: 0.0934 (0.1454)  loss_objectness: 0.0771 (0.0976)  loss_rpn_box_reg: 0.0241 (0.0336)  time: 0.2754  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [24]  [ 970/1229]  eta: 0:01:10  lr: 0.000001  loss: 0.4816 (0.4299)  loss_classifier: 0.1428 (0.1528)  loss_box_reg: 0.1343 (0.1455)  loss_objectness: 0.1019 (0.0978)  loss_rpn_box_reg: 0.0254 (0.0338)  time: 0.2725  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [24]  [ 980/1229]  eta: 0:01:07  lr: 0.000001  loss: 0.4730 (0.4302)  loss_classifier: 0.1428 (0.1527)  loss_box_reg: 0.1343 (0.1456)  loss_objectness: 0.1073 (0.0979)  loss_rpn_box_reg: 0.0254 (0.0340)  time: 0.2696  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [24]  [ 990/1229]  eta: 0:01:05  lr: 0.000001  loss: 0.4329 (0.4296)  loss_classifier: 0.1220 (0.1526)  loss_box_reg: 0.1160 (0.1454)  loss_objectness: 0.0975 (0.0978)  loss_rpn_box_reg: 0.0187 (0.0338)  time: 0.2734  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [24]  [1000/1229]  eta: 0:01:02  lr: 0.000001  loss: 0.3129 (0.4295)  loss_classifier: 0.1263 (0.1526)  loss_box_reg: 0.0994 (0.1453)  loss_objectness: 0.0971 (0.0979)  loss_rpn_box_reg: 0.0139 (0.0338)  time: 0.2719  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [24]  [1010/1229]  eta: 0:00:59  lr: 0.000001  loss: 0.3129 (0.4295)  loss_classifier: 0.1108 (0.1525)  loss_box_reg: 0.0859 (0.1451)  loss_objectness: 0.1063 (0.0980)  loss_rpn_box_reg: 0.0266 (0.0340)  time: 0.2738  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [24]  [1020/1229]  eta: 0:00:57  lr: 0.000001  loss: 0.4040 (0.4304)  loss_classifier: 0.1235 (0.1526)  loss_box_reg: 0.0899 (0.1455)  loss_objectness: 0.1035 (0.0982)  loss_rpn_box_reg: 0.0321 (0.0341)  time: 0.2735  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [24]  [1030/1229]  eta: 0:00:54  lr: 0.000001  loss: 0.4085 (0.4302)  loss_classifier: 0.1549 (0.1526)  loss_box_reg: 0.1310 (0.1453)  loss_objectness: 0.0920 (0.0982)  loss_rpn_box_reg: 0.0301 (0.0341)  time: 0.2698  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [24]  [1040/1229]  eta: 0:00:51  lr: 0.000001  loss: 0.3889 (0.4304)  loss_classifier: 0.1615 (0.1528)  loss_box_reg: 0.1310 (0.1454)  loss_objectness: 0.0912 (0.0982)  loss_rpn_box_reg: 0.0187 (0.0340)  time: 0.2727  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [24]  [1050/1229]  eta: 0:00:48  lr: 0.000001  loss: 0.3685 (0.4298)  loss_classifier: 0.1504 (0.1526)  loss_box_reg: 0.1202 (0.1452)  loss_objectness: 0.0765 (0.0981)  loss_rpn_box_reg: 0.0137 (0.0339)  time: 0.2719  data: 0.1297  max mem: 1751\n",
      "Training Epoch: [24]  [1060/1229]  eta: 0:00:46  lr: 0.000001  loss: 0.3476 (0.4305)  loss_classifier: 0.1362 (0.1529)  loss_box_reg: 0.1183 (0.1452)  loss_objectness: 0.0901 (0.0984)  loss_rpn_box_reg: 0.0230 (0.0340)  time: 0.2726  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [24]  [1070/1229]  eta: 0:00:43  lr: 0.000001  loss: 0.3600 (0.4304)  loss_classifier: 0.1396 (0.1528)  loss_box_reg: 0.1254 (0.1451)  loss_objectness: 0.0962 (0.0984)  loss_rpn_box_reg: 0.0278 (0.0341)  time: 0.2708  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [24]  [1080/1229]  eta: 0:00:40  lr: 0.000001  loss: 0.4353 (0.4308)  loss_classifier: 0.1449 (0.1530)  loss_box_reg: 0.1583 (0.1455)  loss_objectness: 0.0810 (0.0982)  loss_rpn_box_reg: 0.0232 (0.0340)  time: 0.2706  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [24]  [1090/1229]  eta: 0:00:37  lr: 0.000001  loss: 0.3660 (0.4300)  loss_classifier: 0.1406 (0.1528)  loss_box_reg: 0.1406 (0.1452)  loss_objectness: 0.0525 (0.0980)  loss_rpn_box_reg: 0.0210 (0.0339)  time: 0.2742  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [24]  [1100/1229]  eta: 0:00:35  lr: 0.000001  loss: 0.3517 (0.4308)  loss_classifier: 0.1406 (0.1530)  loss_box_reg: 0.1057 (0.1456)  loss_objectness: 0.0836 (0.0983)  loss_rpn_box_reg: 0.0179 (0.0340)  time: 0.2718  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [24]  [1110/1229]  eta: 0:00:32  lr: 0.000001  loss: 0.3727 (0.4303)  loss_classifier: 0.1282 (0.1528)  loss_box_reg: 0.1002 (0.1452)  loss_objectness: 0.0986 (0.0984)  loss_rpn_box_reg: 0.0179 (0.0339)  time: 0.2693  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [24]  [1120/1229]  eta: 0:00:29  lr: 0.000001  loss: 0.3596 (0.4303)  loss_classifier: 0.1263 (0.1528)  loss_box_reg: 0.0906 (0.1451)  loss_objectness: 0.1180 (0.0986)  loss_rpn_box_reg: 0.0208 (0.0339)  time: 0.2693  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [24]  [1130/1229]  eta: 0:00:27  lr: 0.000001  loss: 0.3729 (0.4303)  loss_classifier: 0.1444 (0.1527)  loss_box_reg: 0.1022 (0.1451)  loss_objectness: 0.1079 (0.0986)  loss_rpn_box_reg: 0.0211 (0.0339)  time: 0.3003  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [24]  [1140/1229]  eta: 0:00:24  lr: 0.000001  loss: 0.4473 (0.4311)  loss_classifier: 0.1621 (0.1530)  loss_box_reg: 0.1475 (0.1456)  loss_objectness: 0.0980 (0.0986)  loss_rpn_box_reg: 0.0232 (0.0338)  time: 0.3056  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [24]  [1150/1229]  eta: 0:00:21  lr: 0.000001  loss: 0.3835 (0.4305)  loss_classifier: 0.1486 (0.1529)  loss_box_reg: 0.1210 (0.1454)  loss_objectness: 0.0820 (0.0985)  loss_rpn_box_reg: 0.0217 (0.0337)  time: 0.2791  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [24]  [1160/1229]  eta: 0:00:18  lr: 0.000001  loss: 0.3341 (0.4306)  loss_classifier: 0.1333 (0.1530)  loss_box_reg: 0.1152 (0.1454)  loss_objectness: 0.0726 (0.0985)  loss_rpn_box_reg: 0.0199 (0.0337)  time: 0.2762  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [24]  [1170/1229]  eta: 0:00:16  lr: 0.000001  loss: 0.3270 (0.4304)  loss_classifier: 0.1333 (0.1530)  loss_box_reg: 0.1198 (0.1454)  loss_objectness: 0.0726 (0.0984)  loss_rpn_box_reg: 0.0231 (0.0337)  time: 0.2788  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [24]  [1180/1229]  eta: 0:00:13  lr: 0.000001  loss: 0.4298 (0.4312)  loss_classifier: 0.1582 (0.1533)  loss_box_reg: 0.1516 (0.1457)  loss_objectness: 0.0843 (0.0984)  loss_rpn_box_reg: 0.0253 (0.0338)  time: 0.2809  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [24]  [1190/1229]  eta: 0:00:10  lr: 0.000001  loss: 0.4276 (0.4311)  loss_classifier: 0.1464 (0.1533)  loss_box_reg: 0.1306 (0.1455)  loss_objectness: 0.0918 (0.0985)  loss_rpn_box_reg: 0.0241 (0.0338)  time: 0.2732  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [24]  [1200/1229]  eta: 0:00:07  lr: 0.000001  loss: 0.3573 (0.4314)  loss_classifier: 0.1414 (0.1533)  loss_box_reg: 0.1145 (0.1458)  loss_objectness: 0.0811 (0.0984)  loss_rpn_box_reg: 0.0170 (0.0339)  time: 0.2754  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [24]  [1210/1229]  eta: 0:00:05  lr: 0.000001  loss: 0.4867 (0.4325)  loss_classifier: 0.1478 (0.1537)  loss_box_reg: 0.1531 (0.1461)  loss_objectness: 0.0912 (0.0987)  loss_rpn_box_reg: 0.0271 (0.0340)  time: 0.2848  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [24]  [1220/1229]  eta: 0:00:02  lr: 0.000001  loss: 0.3626 (0.4316)  loss_classifier: 0.1295 (0.1535)  loss_box_reg: 0.0945 (0.1457)  loss_objectness: 0.1028 (0.0985)  loss_rpn_box_reg: 0.0190 (0.0339)  time: 0.2839  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [24]  [1228/1229]  eta: 0:00:00  lr: 0.000001  loss: 0.3127 (0.4313)  loss_classifier: 0.1131 (0.1534)  loss_box_reg: 0.0647 (0.1455)  loss_objectness: 0.0895 (0.0986)  loss_rpn_box_reg: 0.0185 (0.0339)  time: 0.2840  data: 0.1368  max mem: 1751\n",
      "Training Epoch: [24] Total time: 0:05:36 (0.2739 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:52  model_time: 0.3300 (0.3300)  evaluator_time: 0.0020 (0.0020)  time: 0.3640  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0800 (0.0836)  evaluator_time: 0.0040 (0.0087)  time: 0.1288  data: 0.0360  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0840 (0.0823)  evaluator_time: 0.0030 (0.0079)  time: 0.1210  data: 0.0307  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0770 (0.0816)  evaluator_time: 0.0030 (0.0077)  time: 0.1220  data: 0.0356  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0760 (0.0815)  evaluator_time: 0.0030 (0.0077)  time: 0.1186  data: 0.0339  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1256 s / it)\n",
      "Averaged stats: model_time: 0.0760 (0.0815)  evaluator_time: 0.0030 (0.0077)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [24]  [  0/308]  eta: 0:00:39  lr: 0.000001  loss: 0.1648 (0.1648)  loss_classifier: 0.0598 (0.0598)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0250 (0.0250)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1290  data: 0.0300  max mem: 1751\n",
      "Testing Epoch: [24]  [100/308]  eta: 0:00:29  lr: 0.000001  loss: 0.3136 (0.4812)  loss_classifier: 0.1333 (0.1547)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0595 (0.1024)  loss_rpn_box_reg: 0.0186 (0.0518)  time: 0.1406  data: 0.0381  max mem: 1751\n",
      "Testing Epoch: [24]  [200/308]  eta: 0:00:15  lr: 0.000001  loss: 0.3463 (0.4567)  loss_classifier: 0.1389 (0.1491)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0623 (0.0953)  loss_rpn_box_reg: 0.0197 (0.0490)  time: 0.1383  data: 0.0324  max mem: 1751\n",
      "Testing Epoch: [24]  [300/308]  eta: 0:00:01  lr: 0.000001  loss: 0.4518 (0.4536)  loss_classifier: 0.1547 (0.1493)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0779 (0.0928)  loss_rpn_box_reg: 0.0265 (0.0474)  time: 0.1326  data: 0.0380  max mem: 1751\n",
      "Testing Epoch: [24]  [307/308]  eta: 0:00:00  lr: 0.000001  loss: 0.4518 (0.4536)  loss_classifier: 0.1860 (0.1495)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0705 (0.0928)  loss_rpn_box_reg: 0.0271 (0.0470)  time: 0.1310  data: 0.0360  max mem: 1751\n",
      "Testing Epoch: [24] Total time: 0:00:42 (0.1383 s / it)\n",
      "Training Epoch: [25]  [   0/1229]  eta: 0:05:35  lr: 0.000000  loss: 0.3530 (0.3530)  loss_classifier: 0.0933 (0.0933)  loss_box_reg: 0.1017 (0.1017)  loss_objectness: 0.0426 (0.0426)  loss_rpn_box_reg: 0.1154 (0.1154)  time: 0.2730  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [25]  [  10/1229]  eta: 0:05:25  lr: 0.000000  loss: 0.3981 (0.4393)  loss_classifier: 0.1515 (0.1627)  loss_box_reg: 0.1256 (0.1417)  loss_objectness: 0.0724 (0.0983)  loss_rpn_box_reg: 0.0217 (0.0366)  time: 0.2672  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [25]  [  20/1229]  eta: 0:05:27  lr: 0.000000  loss: 0.3981 (0.4284)  loss_classifier: 0.1515 (0.1600)  loss_box_reg: 0.1256 (0.1399)  loss_objectness: 0.0843 (0.0999)  loss_rpn_box_reg: 0.0166 (0.0286)  time: 0.2706  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [25]  [  30/1229]  eta: 0:05:26  lr: 0.000000  loss: 0.3015 (0.4051)  loss_classifier: 0.1109 (0.1502)  loss_box_reg: 0.0999 (0.1341)  loss_objectness: 0.0843 (0.0944)  loss_rpn_box_reg: 0.0159 (0.0264)  time: 0.2746  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [25]  [  40/1229]  eta: 0:05:24  lr: 0.000000  loss: 0.4034 (0.4319)  loss_classifier: 0.1398 (0.1574)  loss_box_reg: 0.1174 (0.1400)  loss_objectness: 0.1011 (0.1020)  loss_rpn_box_reg: 0.0216 (0.0326)  time: 0.2745  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [25]  [  50/1229]  eta: 0:05:20  lr: 0.000000  loss: 0.4620 (0.4214)  loss_classifier: 0.1423 (0.1531)  loss_box_reg: 0.1279 (0.1344)  loss_objectness: 0.1038 (0.1010)  loss_rpn_box_reg: 0.0224 (0.0329)  time: 0.2718  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [25]  [  60/1229]  eta: 0:05:18  lr: 0.000000  loss: 0.3807 (0.4171)  loss_classifier: 0.1304 (0.1523)  loss_box_reg: 0.1301 (0.1339)  loss_objectness: 0.0938 (0.0994)  loss_rpn_box_reg: 0.0162 (0.0316)  time: 0.2733  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [25]  [  70/1229]  eta: 0:05:14  lr: 0.000000  loss: 0.3737 (0.4065)  loss_classifier: 0.1250 (0.1466)  loss_box_reg: 0.1449 (0.1321)  loss_objectness: 0.0740 (0.0959)  loss_rpn_box_reg: 0.0196 (0.0319)  time: 0.2711  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [25]  [  80/1229]  eta: 0:05:13  lr: 0.000000  loss: 0.3728 (0.4156)  loss_classifier: 0.1250 (0.1506)  loss_box_reg: 0.1462 (0.1361)  loss_objectness: 0.0716 (0.0974)  loss_rpn_box_reg: 0.0196 (0.0315)  time: 0.2714  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [25]  [  90/1229]  eta: 0:05:11  lr: 0.000000  loss: 0.4243 (0.4223)  loss_classifier: 0.1368 (0.1534)  loss_box_reg: 0.1285 (0.1391)  loss_objectness: 0.1034 (0.0974)  loss_rpn_box_reg: 0.0187 (0.0324)  time: 0.2786  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [25]  [ 100/1229]  eta: 0:05:08  lr: 0.000000  loss: 0.4243 (0.4329)  loss_classifier: 0.1401 (0.1550)  loss_box_reg: 0.1073 (0.1432)  loss_objectness: 0.1050 (0.1017)  loss_rpn_box_reg: 0.0186 (0.0330)  time: 0.2768  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [25]  [ 110/1229]  eta: 0:05:06  lr: 0.000000  loss: 0.4317 (0.4357)  loss_classifier: 0.1475 (0.1565)  loss_box_reg: 0.1073 (0.1447)  loss_objectness: 0.1050 (0.1016)  loss_rpn_box_reg: 0.0263 (0.0330)  time: 0.2770  data: 0.1379  max mem: 1751\n",
      "Training Epoch: [25]  [ 120/1229]  eta: 0:05:04  lr: 0.000000  loss: 0.4040 (0.4358)  loss_classifier: 0.1233 (0.1550)  loss_box_reg: 0.1251 (0.1446)  loss_objectness: 0.0894 (0.1015)  loss_rpn_box_reg: 0.0353 (0.0348)  time: 0.2783  data: 0.1391  max mem: 1751\n",
      "Training Epoch: [25]  [ 130/1229]  eta: 0:05:01  lr: 0.000000  loss: 0.3525 (0.4326)  loss_classifier: 0.1214 (0.1539)  loss_box_reg: 0.1021 (0.1442)  loss_objectness: 0.0783 (0.1000)  loss_rpn_box_reg: 0.0296 (0.0345)  time: 0.2783  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [25]  [ 140/1229]  eta: 0:04:59  lr: 0.000000  loss: 0.3732 (0.4289)  loss_classifier: 0.1328 (0.1534)  loss_box_reg: 0.1021 (0.1439)  loss_objectness: 0.0744 (0.0982)  loss_rpn_box_reg: 0.0194 (0.0333)  time: 0.2773  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [25]  [ 150/1229]  eta: 0:04:55  lr: 0.000000  loss: 0.4343 (0.4308)  loss_classifier: 0.1486 (0.1540)  loss_box_reg: 0.1300 (0.1458)  loss_objectness: 0.0787 (0.0977)  loss_rpn_box_reg: 0.0191 (0.0332)  time: 0.2726  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [25]  [ 160/1229]  eta: 0:04:53  lr: 0.000000  loss: 0.3890 (0.4259)  loss_classifier: 0.1107 (0.1521)  loss_box_reg: 0.1160 (0.1434)  loss_objectness: 0.0797 (0.0974)  loss_rpn_box_reg: 0.0233 (0.0330)  time: 0.2736  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [25]  [ 170/1229]  eta: 0:04:50  lr: 0.000000  loss: 0.3513 (0.4279)  loss_classifier: 0.1209 (0.1535)  loss_box_reg: 0.1160 (0.1446)  loss_objectness: 0.0839 (0.0970)  loss_rpn_box_reg: 0.0244 (0.0327)  time: 0.2718  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [25]  [ 180/1229]  eta: 0:04:47  lr: 0.000000  loss: 0.3790 (0.4278)  loss_classifier: 0.1348 (0.1536)  loss_box_reg: 0.1148 (0.1446)  loss_objectness: 0.0949 (0.0970)  loss_rpn_box_reg: 0.0234 (0.0326)  time: 0.2685  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [25]  [ 190/1229]  eta: 0:04:44  lr: 0.000000  loss: 0.3790 (0.4287)  loss_classifier: 0.1381 (0.1540)  loss_box_reg: 0.1126 (0.1447)  loss_objectness: 0.0985 (0.0972)  loss_rpn_box_reg: 0.0247 (0.0328)  time: 0.2766  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [25]  [ 200/1229]  eta: 0:04:41  lr: 0.000000  loss: 0.3803 (0.4298)  loss_classifier: 0.1536 (0.1547)  loss_box_reg: 0.1417 (0.1451)  loss_objectness: 0.0907 (0.0977)  loss_rpn_box_reg: 0.0247 (0.0323)  time: 0.2746  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [25]  [ 210/1229]  eta: 0:04:38  lr: 0.000000  loss: 0.4027 (0.4319)  loss_classifier: 0.1536 (0.1552)  loss_box_reg: 0.1510 (0.1461)  loss_objectness: 0.0925 (0.0982)  loss_rpn_box_reg: 0.0169 (0.0324)  time: 0.2682  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [25]  [ 220/1229]  eta: 0:04:36  lr: 0.000000  loss: 0.4137 (0.4334)  loss_classifier: 0.1454 (0.1560)  loss_box_reg: 0.1104 (0.1459)  loss_objectness: 0.0998 (0.0991)  loss_rpn_box_reg: 0.0218 (0.0324)  time: 0.2717  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [25]  [ 230/1229]  eta: 0:04:33  lr: 0.000000  loss: 0.4137 (0.4403)  loss_classifier: 0.1578 (0.1577)  loss_box_reg: 0.1104 (0.1478)  loss_objectness: 0.1198 (0.1002)  loss_rpn_box_reg: 0.0283 (0.0346)  time: 0.2699  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [25]  [ 240/1229]  eta: 0:04:30  lr: 0.000000  loss: 0.5235 (0.4432)  loss_classifier: 0.1578 (0.1586)  loss_box_reg: 0.1080 (0.1486)  loss_objectness: 0.1198 (0.1011)  loss_rpn_box_reg: 0.0312 (0.0348)  time: 0.2739  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [25]  [ 250/1229]  eta: 0:04:27  lr: 0.000000  loss: 0.4158 (0.4426)  loss_classifier: 0.1443 (0.1581)  loss_box_reg: 0.1128 (0.1490)  loss_objectness: 0.0844 (0.1007)  loss_rpn_box_reg: 0.0264 (0.0349)  time: 0.2741  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [25]  [ 260/1229]  eta: 0:04:25  lr: 0.000000  loss: 0.3836 (0.4399)  loss_classifier: 0.1277 (0.1573)  loss_box_reg: 0.1128 (0.1482)  loss_objectness: 0.0687 (0.0998)  loss_rpn_box_reg: 0.0174 (0.0347)  time: 0.2728  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [25]  [ 270/1229]  eta: 0:04:22  lr: 0.000000  loss: 0.3151 (0.4379)  loss_classifier: 0.1172 (0.1565)  loss_box_reg: 0.1093 (0.1484)  loss_objectness: 0.0604 (0.0983)  loss_rpn_box_reg: 0.0139 (0.0348)  time: 0.2798  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [25]  [ 280/1229]  eta: 0:04:19  lr: 0.000000  loss: 0.3670 (0.4397)  loss_classifier: 0.1328 (0.1573)  loss_box_reg: 0.1423 (0.1486)  loss_objectness: 0.0638 (0.0988)  loss_rpn_box_reg: 0.0218 (0.0350)  time: 0.2721  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [25]  [ 290/1229]  eta: 0:04:16  lr: 0.000000  loss: 0.5105 (0.4459)  loss_classifier: 0.1814 (0.1593)  loss_box_reg: 0.1573 (0.1516)  loss_objectness: 0.0860 (0.0992)  loss_rpn_box_reg: 0.0329 (0.0358)  time: 0.2661  data: 0.1368  max mem: 1751\n",
      "Training Epoch: [25]  [ 300/1229]  eta: 0:04:14  lr: 0.000000  loss: 0.4917 (0.4449)  loss_classifier: 0.1372 (0.1585)  loss_box_reg: 0.1530 (0.1516)  loss_objectness: 0.0848 (0.0987)  loss_rpn_box_reg: 0.0284 (0.0361)  time: 0.2727  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [25]  [ 310/1229]  eta: 0:04:11  lr: 0.000000  loss: 0.3502 (0.4478)  loss_classifier: 0.1208 (0.1594)  loss_box_reg: 0.1071 (0.1532)  loss_objectness: 0.0824 (0.0985)  loss_rpn_box_reg: 0.0284 (0.0367)  time: 0.2780  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [25]  [ 320/1229]  eta: 0:04:08  lr: 0.000000  loss: 0.4662 (0.4485)  loss_classifier: 0.1610 (0.1596)  loss_box_reg: 0.1274 (0.1533)  loss_objectness: 0.0857 (0.0990)  loss_rpn_box_reg: 0.0294 (0.0367)  time: 0.2764  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [25]  [ 330/1229]  eta: 0:04:06  lr: 0.000000  loss: 0.4662 (0.4475)  loss_classifier: 0.1610 (0.1593)  loss_box_reg: 0.1223 (0.1523)  loss_objectness: 0.0984 (0.0993)  loss_rpn_box_reg: 0.0305 (0.0366)  time: 0.2749  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [25]  [ 340/1229]  eta: 0:04:03  lr: 0.000000  loss: 0.4814 (0.4499)  loss_classifier: 0.1691 (0.1604)  loss_box_reg: 0.1490 (0.1524)  loss_objectness: 0.1129 (0.1002)  loss_rpn_box_reg: 0.0327 (0.0369)  time: 0.2766  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [25]  [ 350/1229]  eta: 0:04:00  lr: 0.000000  loss: 0.4814 (0.4505)  loss_classifier: 0.1986 (0.1604)  loss_box_reg: 0.1591 (0.1525)  loss_objectness: 0.1049 (0.1006)  loss_rpn_box_reg: 0.0327 (0.0370)  time: 0.2752  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [25]  [ 360/1229]  eta: 0:03:58  lr: 0.000000  loss: 0.3693 (0.4480)  loss_classifier: 0.1241 (0.1592)  loss_box_reg: 0.0858 (0.1512)  loss_objectness: 0.0833 (0.1003)  loss_rpn_box_reg: 0.0239 (0.0374)  time: 0.2768  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [25]  [ 370/1229]  eta: 0:03:55  lr: 0.000000  loss: 0.3149 (0.4458)  loss_classifier: 0.0829 (0.1583)  loss_box_reg: 0.0812 (0.1501)  loss_objectness: 0.0833 (0.1004)  loss_rpn_box_reg: 0.0168 (0.0370)  time: 0.2776  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [25]  [ 380/1229]  eta: 0:03:52  lr: 0.000000  loss: 0.3149 (0.4415)  loss_classifier: 0.0828 (0.1571)  loss_box_reg: 0.0812 (0.1484)  loss_objectness: 0.0790 (0.0996)  loss_rpn_box_reg: 0.0159 (0.0365)  time: 0.2779  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [25]  [ 390/1229]  eta: 0:03:50  lr: 0.000000  loss: 0.3431 (0.4427)  loss_classifier: 0.1316 (0.1573)  loss_box_reg: 0.1111 (0.1496)  loss_objectness: 0.0707 (0.0994)  loss_rpn_box_reg: 0.0197 (0.0364)  time: 0.2785  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [25]  [ 400/1229]  eta: 0:03:47  lr: 0.000000  loss: 0.3778 (0.4408)  loss_classifier: 0.1405 (0.1564)  loss_box_reg: 0.1018 (0.1484)  loss_objectness: 0.0781 (0.0996)  loss_rpn_box_reg: 0.0278 (0.0365)  time: 0.2750  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [25]  [ 410/1229]  eta: 0:03:44  lr: 0.000000  loss: 0.2864 (0.4375)  loss_classifier: 0.0952 (0.1553)  loss_box_reg: 0.0628 (0.1470)  loss_objectness: 0.0757 (0.0991)  loss_rpn_box_reg: 0.0123 (0.0360)  time: 0.2720  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [25]  [ 420/1229]  eta: 0:03:41  lr: 0.000000  loss: 0.2729 (0.4351)  loss_classifier: 0.0952 (0.1545)  loss_box_reg: 0.0875 (0.1461)  loss_objectness: 0.0694 (0.0984)  loss_rpn_box_reg: 0.0147 (0.0361)  time: 0.2768  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [25]  [ 430/1229]  eta: 0:03:39  lr: 0.000000  loss: 0.3963 (0.4377)  loss_classifier: 0.1329 (0.1552)  loss_box_reg: 0.1545 (0.1475)  loss_objectness: 0.0708 (0.0987)  loss_rpn_box_reg: 0.0275 (0.0363)  time: 0.2797  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [25]  [ 440/1229]  eta: 0:03:36  lr: 0.000000  loss: 0.4995 (0.4373)  loss_classifier: 0.1660 (0.1550)  loss_box_reg: 0.1559 (0.1472)  loss_objectness: 0.0918 (0.0991)  loss_rpn_box_reg: 0.0261 (0.0360)  time: 0.2713  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [25]  [ 450/1229]  eta: 0:03:33  lr: 0.000000  loss: 0.4042 (0.4377)  loss_classifier: 0.1377 (0.1551)  loss_box_reg: 0.1093 (0.1479)  loss_objectness: 0.0986 (0.0990)  loss_rpn_box_reg: 0.0203 (0.0358)  time: 0.2679  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [25]  [ 460/1229]  eta: 0:03:30  lr: 0.000000  loss: 0.4123 (0.4373)  loss_classifier: 0.1447 (0.1547)  loss_box_reg: 0.1180 (0.1477)  loss_objectness: 0.0986 (0.0990)  loss_rpn_box_reg: 0.0309 (0.0359)  time: 0.2734  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [25]  [ 470/1229]  eta: 0:03:28  lr: 0.000000  loss: 0.3971 (0.4368)  loss_classifier: 0.1399 (0.1548)  loss_box_reg: 0.1208 (0.1477)  loss_objectness: 0.0678 (0.0987)  loss_rpn_box_reg: 0.0209 (0.0357)  time: 0.2756  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [25]  [ 480/1229]  eta: 0:03:25  lr: 0.000000  loss: 0.3435 (0.4349)  loss_classifier: 0.1089 (0.1542)  loss_box_reg: 0.1019 (0.1471)  loss_objectness: 0.0673 (0.0981)  loss_rpn_box_reg: 0.0157 (0.0356)  time: 0.2762  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [25]  [ 490/1229]  eta: 0:03:22  lr: 0.000000  loss: 0.3954 (0.4348)  loss_classifier: 0.1274 (0.1541)  loss_box_reg: 0.1019 (0.1467)  loss_objectness: 0.0814 (0.0985)  loss_rpn_box_reg: 0.0252 (0.0355)  time: 0.2782  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [25]  [ 500/1229]  eta: 0:03:19  lr: 0.000000  loss: 0.3858 (0.4339)  loss_classifier: 0.1307 (0.1538)  loss_box_reg: 0.1077 (0.1464)  loss_objectness: 0.0912 (0.0984)  loss_rpn_box_reg: 0.0271 (0.0354)  time: 0.2745  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [25]  [ 510/1229]  eta: 0:03:17  lr: 0.000000  loss: 0.3584 (0.4347)  loss_classifier: 0.1237 (0.1540)  loss_box_reg: 0.1206 (0.1472)  loss_objectness: 0.0892 (0.0983)  loss_rpn_box_reg: 0.0139 (0.0352)  time: 0.2690  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [25]  [ 520/1229]  eta: 0:03:14  lr: 0.000000  loss: 0.3538 (0.4346)  loss_classifier: 0.1204 (0.1538)  loss_box_reg: 0.1190 (0.1474)  loss_objectness: 0.0960 (0.0982)  loss_rpn_box_reg: 0.0156 (0.0352)  time: 0.2676  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [25]  [ 530/1229]  eta: 0:03:11  lr: 0.000000  loss: 0.3540 (0.4339)  loss_classifier: 0.1109 (0.1534)  loss_box_reg: 0.1144 (0.1468)  loss_objectness: 0.0976 (0.0984)  loss_rpn_box_reg: 0.0194 (0.0353)  time: 0.2659  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [25]  [ 540/1229]  eta: 0:03:08  lr: 0.000000  loss: 0.3659 (0.4354)  loss_classifier: 0.1292 (0.1539)  loss_box_reg: 0.1201 (0.1473)  loss_objectness: 0.1044 (0.0989)  loss_rpn_box_reg: 0.0274 (0.0352)  time: 0.2664  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [25]  [ 550/1229]  eta: 0:03:05  lr: 0.000000  loss: 0.5022 (0.4379)  loss_classifier: 0.2070 (0.1549)  loss_box_reg: 0.1709 (0.1486)  loss_objectness: 0.1052 (0.0993)  loss_rpn_box_reg: 0.0274 (0.0351)  time: 0.2695  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [25]  [ 560/1229]  eta: 0:03:03  lr: 0.000000  loss: 0.4310 (0.4372)  loss_classifier: 0.1797 (0.1547)  loss_box_reg: 0.1465 (0.1488)  loss_objectness: 0.0913 (0.0990)  loss_rpn_box_reg: 0.0243 (0.0348)  time: 0.2742  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [25]  [ 570/1229]  eta: 0:03:00  lr: 0.000000  loss: 0.3622 (0.4361)  loss_classifier: 0.1167 (0.1542)  loss_box_reg: 0.1400 (0.1486)  loss_objectness: 0.0814 (0.0986)  loss_rpn_box_reg: 0.0143 (0.0348)  time: 0.2756  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [25]  [ 580/1229]  eta: 0:02:57  lr: 0.000000  loss: 0.3622 (0.4360)  loss_classifier: 0.1252 (0.1540)  loss_box_reg: 0.1324 (0.1487)  loss_objectness: 0.0828 (0.0985)  loss_rpn_box_reg: 0.0161 (0.0348)  time: 0.2718  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [25]  [ 590/1229]  eta: 0:02:54  lr: 0.000000  loss: 0.4319 (0.4365)  loss_classifier: 0.1281 (0.1542)  loss_box_reg: 0.1345 (0.1487)  loss_objectness: 0.1032 (0.0989)  loss_rpn_box_reg: 0.0255 (0.0348)  time: 0.2763  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [25]  [ 600/1229]  eta: 0:02:52  lr: 0.000000  loss: 0.4485 (0.4378)  loss_classifier: 0.1494 (0.1546)  loss_box_reg: 0.1450 (0.1491)  loss_objectness: 0.0916 (0.0993)  loss_rpn_box_reg: 0.0258 (0.0350)  time: 0.2861  data: 0.1387  max mem: 1751\n",
      "Training Epoch: [25]  [ 610/1229]  eta: 0:02:49  lr: 0.000000  loss: 0.3983 (0.4369)  loss_classifier: 0.1277 (0.1544)  loss_box_reg: 0.1351 (0.1484)  loss_objectness: 0.0916 (0.0994)  loss_rpn_box_reg: 0.0246 (0.0347)  time: 0.2792  data: 0.1398  max mem: 1751\n",
      "Training Epoch: [25]  [ 620/1229]  eta: 0:02:46  lr: 0.000000  loss: 0.3983 (0.4384)  loss_classifier: 0.1378 (0.1548)  loss_box_reg: 0.1390 (0.1490)  loss_objectness: 0.0910 (0.0997)  loss_rpn_box_reg: 0.0242 (0.0349)  time: 0.2749  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [25]  [ 630/1229]  eta: 0:02:44  lr: 0.000000  loss: 0.4158 (0.4392)  loss_classifier: 0.1483 (0.1550)  loss_box_reg: 0.1449 (0.1490)  loss_objectness: 0.1129 (0.1000)  loss_rpn_box_reg: 0.0163 (0.0351)  time: 0.2754  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [25]  [ 640/1229]  eta: 0:02:41  lr: 0.000000  loss: 0.3635 (0.4383)  loss_classifier: 0.1304 (0.1546)  loss_box_reg: 0.1307 (0.1488)  loss_objectness: 0.0787 (0.0996)  loss_rpn_box_reg: 0.0180 (0.0352)  time: 0.2650  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [25]  [ 650/1229]  eta: 0:02:38  lr: 0.000000  loss: 0.3348 (0.4370)  loss_classifier: 0.1266 (0.1542)  loss_box_reg: 0.0985 (0.1481)  loss_objectness: 0.0702 (0.0994)  loss_rpn_box_reg: 0.0168 (0.0353)  time: 0.2702  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [25]  [ 660/1229]  eta: 0:02:35  lr: 0.000000  loss: 0.3538 (0.4371)  loss_classifier: 0.1232 (0.1544)  loss_box_reg: 0.1088 (0.1484)  loss_objectness: 0.0650 (0.0993)  loss_rpn_box_reg: 0.0168 (0.0350)  time: 0.2772  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [25]  [ 670/1229]  eta: 0:02:33  lr: 0.000000  loss: 0.3753 (0.4377)  loss_classifier: 0.1326 (0.1546)  loss_box_reg: 0.1327 (0.1488)  loss_objectness: 0.0868 (0.0991)  loss_rpn_box_reg: 0.0189 (0.0352)  time: 0.2740  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [25]  [ 680/1229]  eta: 0:02:30  lr: 0.000000  loss: 0.4639 (0.4383)  loss_classifier: 0.1545 (0.1549)  loss_box_reg: 0.1243 (0.1492)  loss_objectness: 0.0983 (0.0991)  loss_rpn_box_reg: 0.0235 (0.0352)  time: 0.2686  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [25]  [ 690/1229]  eta: 0:02:27  lr: 0.000000  loss: 0.4639 (0.4387)  loss_classifier: 0.1847 (0.1552)  loss_box_reg: 0.1484 (0.1494)  loss_objectness: 0.0897 (0.0990)  loss_rpn_box_reg: 0.0226 (0.0351)  time: 0.2715  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [25]  [ 700/1229]  eta: 0:02:24  lr: 0.000000  loss: 0.4082 (0.4384)  loss_classifier: 0.1395 (0.1551)  loss_box_reg: 0.1484 (0.1495)  loss_objectness: 0.0760 (0.0989)  loss_rpn_box_reg: 0.0274 (0.0350)  time: 0.2764  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [25]  [ 710/1229]  eta: 0:02:22  lr: 0.000000  loss: 0.3794 (0.4388)  loss_classifier: 0.1395 (0.1553)  loss_box_reg: 0.1295 (0.1497)  loss_objectness: 0.0943 (0.0989)  loss_rpn_box_reg: 0.0242 (0.0349)  time: 0.2759  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [25]  [ 720/1229]  eta: 0:02:19  lr: 0.000000  loss: 0.3663 (0.4387)  loss_classifier: 0.1431 (0.1553)  loss_box_reg: 0.1138 (0.1498)  loss_objectness: 0.0934 (0.0988)  loss_rpn_box_reg: 0.0197 (0.0348)  time: 0.2800  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [25]  [ 730/1229]  eta: 0:02:16  lr: 0.000000  loss: 0.4202 (0.4380)  loss_classifier: 0.1477 (0.1552)  loss_box_reg: 0.0972 (0.1497)  loss_objectness: 0.0837 (0.0985)  loss_rpn_box_reg: 0.0161 (0.0346)  time: 0.2786  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [25]  [ 740/1229]  eta: 0:02:14  lr: 0.000000  loss: 0.4121 (0.4388)  loss_classifier: 0.1647 (0.1557)  loss_box_reg: 0.1570 (0.1500)  loss_objectness: 0.0717 (0.0985)  loss_rpn_box_reg: 0.0188 (0.0346)  time: 0.2766  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [25]  [ 750/1229]  eta: 0:02:11  lr: 0.000000  loss: 0.4063 (0.4377)  loss_classifier: 0.1559 (0.1554)  loss_box_reg: 0.1439 (0.1497)  loss_objectness: 0.0686 (0.0983)  loss_rpn_box_reg: 0.0188 (0.0344)  time: 0.2729  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [25]  [ 760/1229]  eta: 0:02:08  lr: 0.000000  loss: 0.3492 (0.4373)  loss_classifier: 0.1236 (0.1552)  loss_box_reg: 0.1140 (0.1496)  loss_objectness: 0.0709 (0.0980)  loss_rpn_box_reg: 0.0129 (0.0345)  time: 0.2679  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [25]  [ 770/1229]  eta: 0:02:05  lr: 0.000000  loss: 0.3526 (0.4375)  loss_classifier: 0.1306 (0.1550)  loss_box_reg: 0.1398 (0.1498)  loss_objectness: 0.0633 (0.0978)  loss_rpn_box_reg: 0.0190 (0.0349)  time: 0.2761  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [25]  [ 780/1229]  eta: 0:02:03  lr: 0.000000  loss: 0.3744 (0.4371)  loss_classifier: 0.1400 (0.1549)  loss_box_reg: 0.1411 (0.1495)  loss_objectness: 0.0665 (0.0977)  loss_rpn_box_reg: 0.0229 (0.0349)  time: 0.2823  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [25]  [ 790/1229]  eta: 0:02:00  lr: 0.000000  loss: 0.4948 (0.4386)  loss_classifier: 0.1697 (0.1554)  loss_box_reg: 0.1541 (0.1500)  loss_objectness: 0.1137 (0.0981)  loss_rpn_box_reg: 0.0254 (0.0351)  time: 0.2773  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [25]  [ 800/1229]  eta: 0:01:57  lr: 0.000000  loss: 0.4910 (0.4387)  loss_classifier: 0.1719 (0.1554)  loss_box_reg: 0.1530 (0.1498)  loss_objectness: 0.1026 (0.0981)  loss_rpn_box_reg: 0.0331 (0.0354)  time: 0.2769  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [25]  [ 810/1229]  eta: 0:01:54  lr: 0.000000  loss: 0.4224 (0.4385)  loss_classifier: 0.1547 (0.1554)  loss_box_reg: 0.1124 (0.1495)  loss_objectness: 0.0969 (0.0982)  loss_rpn_box_reg: 0.0264 (0.0353)  time: 0.2817  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [25]  [ 820/1229]  eta: 0:01:52  lr: 0.000000  loss: 0.2959 (0.4372)  loss_classifier: 0.1096 (0.1551)  loss_box_reg: 0.0988 (0.1490)  loss_objectness: 0.0896 (0.0980)  loss_rpn_box_reg: 0.0218 (0.0351)  time: 0.2814  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [25]  [ 830/1229]  eta: 0:01:49  lr: 0.000000  loss: 0.3735 (0.4380)  loss_classifier: 0.1223 (0.1552)  loss_box_reg: 0.1038 (0.1492)  loss_objectness: 0.0817 (0.0982)  loss_rpn_box_reg: 0.0335 (0.0354)  time: 0.2763  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [25]  [ 840/1229]  eta: 0:01:46  lr: 0.000000  loss: 0.4548 (0.4383)  loss_classifier: 0.1348 (0.1554)  loss_box_reg: 0.1219 (0.1495)  loss_objectness: 0.0817 (0.0980)  loss_rpn_box_reg: 0.0344 (0.0355)  time: 0.2748  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [25]  [ 850/1229]  eta: 0:01:43  lr: 0.000000  loss: 0.4548 (0.4396)  loss_classifier: 0.1628 (0.1558)  loss_box_reg: 0.1501 (0.1500)  loss_objectness: 0.0929 (0.0983)  loss_rpn_box_reg: 0.0375 (0.0355)  time: 0.2752  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [25]  [ 860/1229]  eta: 0:01:41  lr: 0.000000  loss: 0.4681 (0.4401)  loss_classifier: 0.1880 (0.1561)  loss_box_reg: 0.1669 (0.1504)  loss_objectness: 0.0971 (0.0983)  loss_rpn_box_reg: 0.0196 (0.0353)  time: 0.2741  data: 0.1370  max mem: 1751\n",
      "Training Epoch: [25]  [ 870/1229]  eta: 0:01:38  lr: 0.000000  loss: 0.4631 (0.4406)  loss_classifier: 0.1880 (0.1563)  loss_box_reg: 0.1300 (0.1504)  loss_objectness: 0.1022 (0.0986)  loss_rpn_box_reg: 0.0166 (0.0353)  time: 0.2789  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [25]  [ 880/1229]  eta: 0:01:35  lr: 0.000000  loss: 0.3629 (0.4400)  loss_classifier: 0.1431 (0.1561)  loss_box_reg: 0.1156 (0.1501)  loss_objectness: 0.1082 (0.0986)  loss_rpn_box_reg: 0.0180 (0.0352)  time: 0.2820  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [25]  [ 890/1229]  eta: 0:01:33  lr: 0.000000  loss: 0.3528 (0.4400)  loss_classifier: 0.1201 (0.1561)  loss_box_reg: 0.1069 (0.1500)  loss_objectness: 0.0828 (0.0985)  loss_rpn_box_reg: 0.0181 (0.0354)  time: 0.2850  data: 0.1371  max mem: 1751\n",
      "Training Epoch: [25]  [ 900/1229]  eta: 0:01:30  lr: 0.000000  loss: 0.3965 (0.4413)  loss_classifier: 0.1531 (0.1566)  loss_box_reg: 0.1620 (0.1505)  loss_objectness: 0.0820 (0.0986)  loss_rpn_box_reg: 0.0243 (0.0356)  time: 0.2862  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [25]  [ 910/1229]  eta: 0:01:27  lr: 0.000000  loss: 0.3403 (0.4405)  loss_classifier: 0.1151 (0.1562)  loss_box_reg: 0.1160 (0.1503)  loss_objectness: 0.0734 (0.0984)  loss_rpn_box_reg: 0.0200 (0.0356)  time: 0.2813  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [25]  [ 920/1229]  eta: 0:01:24  lr: 0.000000  loss: 0.3357 (0.4393)  loss_classifier: 0.0971 (0.1557)  loss_box_reg: 0.0867 (0.1500)  loss_objectness: 0.0594 (0.0981)  loss_rpn_box_reg: 0.0189 (0.0355)  time: 0.2804  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [25]  [ 930/1229]  eta: 0:01:22  lr: 0.000000  loss: 0.3706 (0.4392)  loss_classifier: 0.1121 (0.1557)  loss_box_reg: 0.0863 (0.1496)  loss_objectness: 0.0888 (0.0985)  loss_rpn_box_reg: 0.0231 (0.0354)  time: 0.2789  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [25]  [ 940/1229]  eta: 0:01:19  lr: 0.000000  loss: 0.4144 (0.4395)  loss_classifier: 0.1562 (0.1559)  loss_box_reg: 0.1277 (0.1499)  loss_objectness: 0.0822 (0.0985)  loss_rpn_box_reg: 0.0158 (0.0353)  time: 0.2736  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [25]  [ 950/1229]  eta: 0:01:16  lr: 0.000000  loss: 0.2861 (0.4384)  loss_classifier: 0.1030 (0.1555)  loss_box_reg: 0.0884 (0.1495)  loss_objectness: 0.0776 (0.0982)  loss_rpn_box_reg: 0.0164 (0.0351)  time: 0.2727  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [25]  [ 960/1229]  eta: 0:01:13  lr: 0.000000  loss: 0.3462 (0.4390)  loss_classifier: 0.1091 (0.1557)  loss_box_reg: 0.0909 (0.1494)  loss_objectness: 0.0847 (0.0986)  loss_rpn_box_reg: 0.0275 (0.0354)  time: 0.2712  data: 0.1371  max mem: 1751\n",
      "Training Epoch: [25]  [ 970/1229]  eta: 0:01:11  lr: 0.000000  loss: 0.4451 (0.4386)  loss_classifier: 0.1547 (0.1557)  loss_box_reg: 0.1340 (0.1493)  loss_objectness: 0.0847 (0.0984)  loss_rpn_box_reg: 0.0240 (0.0352)  time: 0.2717  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [25]  [ 980/1229]  eta: 0:01:08  lr: 0.000000  loss: 0.3594 (0.4382)  loss_classifier: 0.1058 (0.1555)  loss_box_reg: 0.0760 (0.1488)  loss_objectness: 0.0791 (0.0985)  loss_rpn_box_reg: 0.0183 (0.0353)  time: 0.2687  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [25]  [ 990/1229]  eta: 0:01:05  lr: 0.000000  loss: 0.3731 (0.4378)  loss_classifier: 0.1357 (0.1554)  loss_box_reg: 0.1084 (0.1486)  loss_objectness: 0.0873 (0.0984)  loss_rpn_box_reg: 0.0210 (0.0354)  time: 0.2692  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [25]  [1000/1229]  eta: 0:01:02  lr: 0.000000  loss: 0.3846 (0.4368)  loss_classifier: 0.1390 (0.1550)  loss_box_reg: 0.1202 (0.1481)  loss_objectness: 0.0898 (0.0984)  loss_rpn_box_reg: 0.0204 (0.0353)  time: 0.2745  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [25]  [1010/1229]  eta: 0:01:00  lr: 0.000000  loss: 0.2969 (0.4373)  loss_classifier: 0.1218 (0.1553)  loss_box_reg: 0.0845 (0.1480)  loss_objectness: 0.1018 (0.0987)  loss_rpn_box_reg: 0.0232 (0.0353)  time: 0.2784  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [25]  [1020/1229]  eta: 0:00:57  lr: 0.000000  loss: 0.3892 (0.4378)  loss_classifier: 0.1429 (0.1556)  loss_box_reg: 0.1008 (0.1480)  loss_objectness: 0.1209 (0.0991)  loss_rpn_box_reg: 0.0259 (0.0353)  time: 0.2750  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [25]  [1030/1229]  eta: 0:00:54  lr: 0.000000  loss: 0.4047 (0.4383)  loss_classifier: 0.1580 (0.1557)  loss_box_reg: 0.1434 (0.1483)  loss_objectness: 0.0964 (0.0990)  loss_rpn_box_reg: 0.0259 (0.0353)  time: 0.2687  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [25]  [1040/1229]  eta: 0:00:51  lr: 0.000000  loss: 0.4097 (0.4375)  loss_classifier: 0.1498 (0.1555)  loss_box_reg: 0.1545 (0.1480)  loss_objectness: 0.0830 (0.0988)  loss_rpn_box_reg: 0.0240 (0.0352)  time: 0.2757  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [25]  [1050/1229]  eta: 0:00:49  lr: 0.000000  loss: 0.3524 (0.4374)  loss_classifier: 0.1366 (0.1556)  loss_box_reg: 0.1203 (0.1481)  loss_objectness: 0.0795 (0.0987)  loss_rpn_box_reg: 0.0208 (0.0350)  time: 0.2760  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [25]  [1060/1229]  eta: 0:00:46  lr: 0.000000  loss: 0.3167 (0.4369)  loss_classifier: 0.1244 (0.1554)  loss_box_reg: 0.1057 (0.1479)  loss_objectness: 0.0738 (0.0986)  loss_rpn_box_reg: 0.0165 (0.0350)  time: 0.2673  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [25]  [1070/1229]  eta: 0:00:43  lr: 0.000000  loss: 0.3048 (0.4368)  loss_classifier: 0.1006 (0.1554)  loss_box_reg: 0.0934 (0.1479)  loss_objectness: 0.0738 (0.0985)  loss_rpn_box_reg: 0.0193 (0.0350)  time: 0.2641  data: 0.1295  max mem: 1751\n",
      "Training Epoch: [25]  [1080/1229]  eta: 0:00:40  lr: 0.000000  loss: 0.2864 (0.4352)  loss_classifier: 0.1019 (0.1549)  loss_box_reg: 0.0848 (0.1473)  loss_objectness: 0.0695 (0.0982)  loss_rpn_box_reg: 0.0128 (0.0348)  time: 0.2703  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [25]  [1090/1229]  eta: 0:00:38  lr: 0.000000  loss: 0.2594 (0.4349)  loss_classifier: 0.1063 (0.1549)  loss_box_reg: 0.0906 (0.1473)  loss_objectness: 0.0582 (0.0981)  loss_rpn_box_reg: 0.0136 (0.0347)  time: 0.2705  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [25]  [1100/1229]  eta: 0:00:35  lr: 0.000000  loss: 0.3765 (0.4349)  loss_classifier: 0.1423 (0.1549)  loss_box_reg: 0.1379 (0.1473)  loss_objectness: 0.0822 (0.0981)  loss_rpn_box_reg: 0.0185 (0.0347)  time: 0.2698  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [25]  [1110/1229]  eta: 0:00:32  lr: 0.000000  loss: 0.3252 (0.4340)  loss_classifier: 0.1161 (0.1545)  loss_box_reg: 0.0927 (0.1468)  loss_objectness: 0.0919 (0.0982)  loss_rpn_box_reg: 0.0149 (0.0346)  time: 0.2750  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [25]  [1120/1229]  eta: 0:00:29  lr: 0.000000  loss: 0.3169 (0.4332)  loss_classifier: 0.1108 (0.1542)  loss_box_reg: 0.0898 (0.1463)  loss_objectness: 0.0910 (0.0982)  loss_rpn_box_reg: 0.0155 (0.0345)  time: 0.2725  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [25]  [1130/1229]  eta: 0:00:27  lr: 0.000000  loss: 0.3343 (0.4330)  loss_classifier: 0.1165 (0.1542)  loss_box_reg: 0.0844 (0.1463)  loss_objectness: 0.0758 (0.0981)  loss_rpn_box_reg: 0.0179 (0.0344)  time: 0.2721  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [25]  [1140/1229]  eta: 0:00:24  lr: 0.000000  loss: 0.3343 (0.4328)  loss_classifier: 0.1057 (0.1540)  loss_box_reg: 0.0915 (0.1464)  loss_objectness: 0.0712 (0.0980)  loss_rpn_box_reg: 0.0179 (0.0344)  time: 0.2761  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [25]  [1150/1229]  eta: 0:00:21  lr: 0.000000  loss: 0.3581 (0.4334)  loss_classifier: 0.1115 (0.1542)  loss_box_reg: 0.1094 (0.1467)  loss_objectness: 0.0763 (0.0980)  loss_rpn_box_reg: 0.0178 (0.0344)  time: 0.2774  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [25]  [1160/1229]  eta: 0:00:18  lr: 0.000000  loss: 0.3960 (0.4327)  loss_classifier: 0.1381 (0.1540)  loss_box_reg: 0.1331 (0.1465)  loss_objectness: 0.0877 (0.0980)  loss_rpn_box_reg: 0.0177 (0.0342)  time: 0.2797  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [25]  [1170/1229]  eta: 0:00:16  lr: 0.000000  loss: 0.3960 (0.4329)  loss_classifier: 0.1440 (0.1541)  loss_box_reg: 0.1331 (0.1467)  loss_objectness: 0.0784 (0.0979)  loss_rpn_box_reg: 0.0265 (0.0342)  time: 0.2779  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [25]  [1180/1229]  eta: 0:00:13  lr: 0.000000  loss: 0.3960 (0.4329)  loss_classifier: 0.1438 (0.1541)  loss_box_reg: 0.1043 (0.1466)  loss_objectness: 0.0871 (0.0981)  loss_rpn_box_reg: 0.0287 (0.0342)  time: 0.2767  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [25]  [1190/1229]  eta: 0:00:10  lr: 0.000000  loss: 0.3286 (0.4321)  loss_classifier: 0.1057 (0.1538)  loss_box_reg: 0.0872 (0.1461)  loss_objectness: 0.0871 (0.0981)  loss_rpn_box_reg: 0.0169 (0.0341)  time: 0.2745  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [25]  [1200/1229]  eta: 0:00:07  lr: 0.000000  loss: 0.3709 (0.4322)  loss_classifier: 0.1085 (0.1538)  loss_box_reg: 0.0989 (0.1464)  loss_objectness: 0.0799 (0.0980)  loss_rpn_box_reg: 0.0156 (0.0341)  time: 0.2761  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [25]  [1210/1229]  eta: 0:00:05  lr: 0.000000  loss: 0.3852 (0.4324)  loss_classifier: 0.1512 (0.1539)  loss_box_reg: 0.1255 (0.1463)  loss_objectness: 0.0843 (0.0982)  loss_rpn_box_reg: 0.0203 (0.0340)  time: 0.2747  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [25]  [1220/1229]  eta: 0:00:02  lr: 0.000000  loss: 0.3604 (0.4317)  loss_classifier: 0.1401 (0.1537)  loss_box_reg: 0.0991 (0.1461)  loss_objectness: 0.0843 (0.0981)  loss_rpn_box_reg: 0.0138 (0.0339)  time: 0.2700  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [25]  [1228/1229]  eta: 0:00:00  lr: 0.000000  loss: 0.3765 (0.4319)  loss_classifier: 0.1451 (0.1538)  loss_box_reg: 0.1160 (0.1462)  loss_objectness: 0.0992 (0.0982)  loss_rpn_box_reg: 0.0138 (0.0338)  time: 0.2698  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [25] Total time: 0:05:37 (0.2746 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:50  model_time: 0.3240 (0.3240)  evaluator_time: 0.0020 (0.0020)  time: 0.3580  data: 0.0300  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0790 (0.0829)  evaluator_time: 0.0040 (0.0085)  time: 0.1273  data: 0.0359  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0830 (0.0815)  evaluator_time: 0.0030 (0.0078)  time: 0.1197  data: 0.0302  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0730 (0.0806)  evaluator_time: 0.0040 (0.0076)  time: 0.1191  data: 0.0353  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0730 (0.0805)  evaluator_time: 0.0020 (0.0076)  time: 0.1164  data: 0.0339  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1243 s / it)\n",
      "Averaged stats: model_time: 0.0730 (0.0805)  evaluator_time: 0.0020 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [25]  [  0/308]  eta: 0:00:38  lr: 0.000000  loss: 0.1701 (0.1701)  loss_classifier: 0.0588 (0.0588)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0314 (0.0314)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1250  data: 0.0320  max mem: 1751\n",
      "Testing Epoch: [25]  [100/308]  eta: 0:00:28  lr: 0.000000  loss: 0.3094 (0.4821)  loss_classifier: 0.1342 (0.1549)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0510 (0.1030)  loss_rpn_box_reg: 0.0186 (0.0519)  time: 0.1383  data: 0.0373  max mem: 1751\n",
      "Testing Epoch: [25]  [200/308]  eta: 0:00:14  lr: 0.000000  loss: 0.3485 (0.4574)  loss_classifier: 0.1390 (0.1492)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0695 (0.0959)  loss_rpn_box_reg: 0.0197 (0.0491)  time: 0.1376  data: 0.0316  max mem: 1751\n",
      "Testing Epoch: [25]  [300/308]  eta: 0:00:01  lr: 0.000000  loss: 0.4839 (0.4544)  loss_classifier: 0.1583 (0.1494)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0857 (0.0933)  loss_rpn_box_reg: 0.0265 (0.0475)  time: 0.1324  data: 0.0374  max mem: 1751\n",
      "Testing Epoch: [25]  [307/308]  eta: 0:00:00  lr: 0.000000  loss: 0.4575 (0.4546)  loss_classifier: 0.1860 (0.1496)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0684 (0.0935)  loss_rpn_box_reg: 0.0271 (0.0471)  time: 0.1306  data: 0.0359  max mem: 1751\n",
      "Testing Epoch: [25] Total time: 0:00:42 (0.1369 s / it)\n",
      "Training Epoch: [26]  [   0/1229]  eta: 0:05:44  lr: 0.000000  loss: 0.5318 (0.5318)  loss_classifier: 0.1786 (0.1786)  loss_box_reg: 0.2133 (0.2133)  loss_objectness: 0.1048 (0.1048)  loss_rpn_box_reg: 0.0352 (0.0352)  time: 0.2800  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [26]  [  10/1229]  eta: 0:05:36  lr: 0.000000  loss: 0.5318 (0.5460)  loss_classifier: 0.1786 (0.1924)  loss_box_reg: 0.1455 (0.2013)  loss_objectness: 0.1128 (0.1092)  loss_rpn_box_reg: 0.0467 (0.0430)  time: 0.2757  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [26]  [  20/1229]  eta: 0:05:27  lr: 0.000000  loss: 0.4119 (0.4967)  loss_classifier: 0.1394 (0.1743)  loss_box_reg: 0.1323 (0.1783)  loss_objectness: 0.1066 (0.1067)  loss_rpn_box_reg: 0.0242 (0.0373)  time: 0.2704  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [26]  [  30/1229]  eta: 0:05:25  lr: 0.000000  loss: 0.4119 (0.4897)  loss_classifier: 0.1394 (0.1690)  loss_box_reg: 0.1224 (0.1631)  loss_objectness: 0.0938 (0.1130)  loss_rpn_box_reg: 0.0289 (0.0446)  time: 0.2688  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [26]  [  40/1229]  eta: 0:05:25  lr: 0.000000  loss: 0.4792 (0.4903)  loss_classifier: 0.1857 (0.1718)  loss_box_reg: 0.1357 (0.1655)  loss_objectness: 0.0949 (0.1104)  loss_rpn_box_reg: 0.0334 (0.0426)  time: 0.2768  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [26]  [  50/1229]  eta: 0:05:24  lr: 0.000000  loss: 0.3797 (0.4683)  loss_classifier: 0.1598 (0.1647)  loss_box_reg: 0.1065 (0.1544)  loss_objectness: 0.0949 (0.1099)  loss_rpn_box_reg: 0.0273 (0.0393)  time: 0.2821  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [26]  [  60/1229]  eta: 0:05:22  lr: 0.000000  loss: 0.3285 (0.4523)  loss_classifier: 0.1249 (0.1593)  loss_box_reg: 0.0728 (0.1476)  loss_objectness: 0.0788 (0.1068)  loss_rpn_box_reg: 0.0194 (0.0386)  time: 0.2791  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [26]  [  70/1229]  eta: 0:05:18  lr: 0.000000  loss: 0.3253 (0.4408)  loss_classifier: 0.1041 (0.1531)  loss_box_reg: 0.0795 (0.1425)  loss_objectness: 0.0779 (0.1055)  loss_rpn_box_reg: 0.0188 (0.0398)  time: 0.2733  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [26]  [  80/1229]  eta: 0:05:16  lr: 0.000000  loss: 0.3131 (0.4308)  loss_classifier: 0.0994 (0.1503)  loss_box_reg: 0.0873 (0.1375)  loss_objectness: 0.0868 (0.1055)  loss_rpn_box_reg: 0.0183 (0.0375)  time: 0.2741  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [26]  [  90/1229]  eta: 0:05:13  lr: 0.000000  loss: 0.3237 (0.4278)  loss_classifier: 0.1254 (0.1496)  loss_box_reg: 0.0873 (0.1372)  loss_objectness: 0.0985 (0.1045)  loss_rpn_box_reg: 0.0156 (0.0366)  time: 0.2754  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [26]  [ 100/1229]  eta: 0:05:10  lr: 0.000000  loss: 0.4176 (0.4331)  loss_classifier: 0.1548 (0.1521)  loss_box_reg: 0.0962 (0.1396)  loss_objectness: 0.0992 (0.1051)  loss_rpn_box_reg: 0.0210 (0.0363)  time: 0.2750  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [26]  [ 110/1229]  eta: 0:05:07  lr: 0.000000  loss: 0.4963 (0.4411)  loss_classifier: 0.1730 (0.1557)  loss_box_reg: 0.1138 (0.1427)  loss_objectness: 0.1025 (0.1065)  loss_rpn_box_reg: 0.0288 (0.0362)  time: 0.2747  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [26]  [ 120/1229]  eta: 0:05:04  lr: 0.000000  loss: 0.4446 (0.4376)  loss_classifier: 0.1704 (0.1541)  loss_box_reg: 0.1138 (0.1419)  loss_objectness: 0.0994 (0.1059)  loss_rpn_box_reg: 0.0196 (0.0355)  time: 0.2713  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [26]  [ 130/1229]  eta: 0:05:00  lr: 0.000000  loss: 0.4471 (0.4454)  loss_classifier: 0.1428 (0.1555)  loss_box_reg: 0.1317 (0.1442)  loss_objectness: 0.1175 (0.1086)  loss_rpn_box_reg: 0.0264 (0.0372)  time: 0.2669  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [26]  [ 140/1229]  eta: 0:04:57  lr: 0.000000  loss: 0.4471 (0.4440)  loss_classifier: 0.1428 (0.1554)  loss_box_reg: 0.1346 (0.1442)  loss_objectness: 0.1135 (0.1075)  loss_rpn_box_reg: 0.0288 (0.0370)  time: 0.2675  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [26]  [ 150/1229]  eta: 0:04:55  lr: 0.000000  loss: 0.4293 (0.4472)  loss_classifier: 0.1638 (0.1567)  loss_box_reg: 0.1685 (0.1472)  loss_objectness: 0.0985 (0.1069)  loss_rpn_box_reg: 0.0219 (0.0364)  time: 0.2740  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [26]  [ 160/1229]  eta: 0:04:52  lr: 0.000000  loss: 0.4518 (0.4473)  loss_classifier: 0.1638 (0.1574)  loss_box_reg: 0.1345 (0.1460)  loss_objectness: 0.0894 (0.1075)  loss_rpn_box_reg: 0.0217 (0.0365)  time: 0.2729  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [26]  [ 170/1229]  eta: 0:04:49  lr: 0.000000  loss: 0.2694 (0.4414)  loss_classifier: 0.1083 (0.1551)  loss_box_reg: 0.0896 (0.1457)  loss_objectness: 0.0718 (0.1052)  loss_rpn_box_reg: 0.0145 (0.0354)  time: 0.2709  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [26]  [ 180/1229]  eta: 0:04:47  lr: 0.000000  loss: 0.2518 (0.4403)  loss_classifier: 0.1002 (0.1546)  loss_box_reg: 0.0861 (0.1450)  loss_objectness: 0.0718 (0.1059)  loss_rpn_box_reg: 0.0118 (0.0348)  time: 0.2749  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [26]  [ 190/1229]  eta: 0:04:44  lr: 0.000000  loss: 0.4335 (0.4407)  loss_classifier: 0.1202 (0.1553)  loss_box_reg: 0.0954 (0.1448)  loss_objectness: 0.0821 (0.1059)  loss_rpn_box_reg: 0.0131 (0.0347)  time: 0.2730  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [26]  [ 200/1229]  eta: 0:04:41  lr: 0.000000  loss: 0.3940 (0.4355)  loss_classifier: 0.1144 (0.1531)  loss_box_reg: 0.0950 (0.1421)  loss_objectness: 0.0862 (0.1056)  loss_rpn_box_reg: 0.0213 (0.0347)  time: 0.2769  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [26]  [ 210/1229]  eta: 0:04:39  lr: 0.000000  loss: 0.3834 (0.4351)  loss_classifier: 0.1350 (0.1532)  loss_box_reg: 0.1164 (0.1423)  loss_objectness: 0.0765 (0.1053)  loss_rpn_box_reg: 0.0213 (0.0343)  time: 0.2822  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [26]  [ 220/1229]  eta: 0:04:36  lr: 0.000000  loss: 0.3805 (0.4333)  loss_classifier: 0.1400 (0.1521)  loss_box_reg: 0.1210 (0.1411)  loss_objectness: 0.1127 (0.1059)  loss_rpn_box_reg: 0.0198 (0.0342)  time: 0.2788  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [26]  [ 230/1229]  eta: 0:04:34  lr: 0.000000  loss: 0.3508 (0.4336)  loss_classifier: 0.1142 (0.1521)  loss_box_reg: 0.1025 (0.1415)  loss_objectness: 0.0849 (0.1054)  loss_rpn_box_reg: 0.0198 (0.0346)  time: 0.2766  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [26]  [ 240/1229]  eta: 0:04:31  lr: 0.000000  loss: 0.4016 (0.4331)  loss_classifier: 0.1410 (0.1524)  loss_box_reg: 0.1208 (0.1409)  loss_objectness: 0.0661 (0.1053)  loss_rpn_box_reg: 0.0203 (0.0344)  time: 0.2804  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [26]  [ 250/1229]  eta: 0:04:29  lr: 0.000000  loss: 0.3961 (0.4336)  loss_classifier: 0.1390 (0.1522)  loss_box_reg: 0.1281 (0.1412)  loss_objectness: 0.0753 (0.1050)  loss_rpn_box_reg: 0.0224 (0.0352)  time: 0.2789  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [26]  [ 260/1229]  eta: 0:04:26  lr: 0.000000  loss: 0.3961 (0.4329)  loss_classifier: 0.1434 (0.1523)  loss_box_reg: 0.1287 (0.1415)  loss_objectness: 0.0721 (0.1044)  loss_rpn_box_reg: 0.0183 (0.0347)  time: 0.2728  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [26]  [ 270/1229]  eta: 0:04:23  lr: 0.000000  loss: 0.3435 (0.4282)  loss_classifier: 0.1340 (0.1509)  loss_box_reg: 0.1287 (0.1401)  loss_objectness: 0.0699 (0.1030)  loss_rpn_box_reg: 0.0156 (0.0342)  time: 0.2738  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [26]  [ 280/1229]  eta: 0:04:20  lr: 0.000000  loss: 0.3005 (0.4286)  loss_classifier: 0.1191 (0.1510)  loss_box_reg: 0.0968 (0.1406)  loss_objectness: 0.0759 (0.1030)  loss_rpn_box_reg: 0.0141 (0.0340)  time: 0.2747  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [26]  [ 290/1229]  eta: 0:04:18  lr: 0.000000  loss: 0.3691 (0.4260)  loss_classifier: 0.1200 (0.1502)  loss_box_reg: 0.1056 (0.1396)  loss_objectness: 0.0905 (0.1029)  loss_rpn_box_reg: 0.0173 (0.0333)  time: 0.2757  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [26]  [ 300/1229]  eta: 0:04:15  lr: 0.000000  loss: 0.3691 (0.4276)  loss_classifier: 0.1200 (0.1505)  loss_box_reg: 0.0983 (0.1397)  loss_objectness: 0.0939 (0.1037)  loss_rpn_box_reg: 0.0202 (0.0337)  time: 0.2773  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [26]  [ 310/1229]  eta: 0:04:12  lr: 0.000000  loss: 0.3652 (0.4270)  loss_classifier: 0.1377 (0.1504)  loss_box_reg: 0.0966 (0.1384)  loss_objectness: 0.0939 (0.1042)  loss_rpn_box_reg: 0.0284 (0.0340)  time: 0.2750  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [26]  [ 320/1229]  eta: 0:04:09  lr: 0.000000  loss: 0.3807 (0.4297)  loss_classifier: 0.1389 (0.1512)  loss_box_reg: 0.1092 (0.1394)  loss_objectness: 0.0909 (0.1046)  loss_rpn_box_reg: 0.0243 (0.0345)  time: 0.2729  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [26]  [ 330/1229]  eta: 0:04:06  lr: 0.000000  loss: 0.4117 (0.4287)  loss_classifier: 0.1541 (0.1510)  loss_box_reg: 0.1433 (0.1391)  loss_objectness: 0.0847 (0.1041)  loss_rpn_box_reg: 0.0251 (0.0346)  time: 0.2716  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [26]  [ 340/1229]  eta: 0:04:04  lr: 0.000000  loss: 0.4117 (0.4278)  loss_classifier: 0.1526 (0.1510)  loss_box_reg: 0.1177 (0.1397)  loss_objectness: 0.0732 (0.1031)  loss_rpn_box_reg: 0.0187 (0.0340)  time: 0.2773  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [26]  [ 350/1229]  eta: 0:04:01  lr: 0.000000  loss: 0.3672 (0.4255)  loss_classifier: 0.1439 (0.1503)  loss_box_reg: 0.1224 (0.1394)  loss_objectness: 0.0583 (0.1021)  loss_rpn_box_reg: 0.0115 (0.0336)  time: 0.2825  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [26]  [ 360/1229]  eta: 0:03:58  lr: 0.000000  loss: 0.3617 (0.4245)  loss_classifier: 0.1222 (0.1499)  loss_box_reg: 0.1205 (0.1394)  loss_objectness: 0.0721 (0.1019)  loss_rpn_box_reg: 0.0127 (0.0333)  time: 0.2764  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [26]  [ 370/1229]  eta: 0:03:56  lr: 0.000000  loss: 0.3886 (0.4265)  loss_classifier: 0.1417 (0.1508)  loss_box_reg: 0.1096 (0.1397)  loss_objectness: 0.1050 (0.1024)  loss_rpn_box_reg: 0.0258 (0.0335)  time: 0.2780  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [26]  [ 380/1229]  eta: 0:03:53  lr: 0.000000  loss: 0.3776 (0.4252)  loss_classifier: 0.1456 (0.1510)  loss_box_reg: 0.1096 (0.1391)  loss_objectness: 0.0894 (0.1018)  loss_rpn_box_reg: 0.0221 (0.0332)  time: 0.2807  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [26]  [ 390/1229]  eta: 0:03:50  lr: 0.000000  loss: 0.3569 (0.4247)  loss_classifier: 0.1270 (0.1507)  loss_box_reg: 0.1090 (0.1391)  loss_objectness: 0.0804 (0.1019)  loss_rpn_box_reg: 0.0189 (0.0330)  time: 0.2711  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [26]  [ 400/1229]  eta: 0:03:47  lr: 0.000000  loss: 0.3587 (0.4275)  loss_classifier: 0.1296 (0.1516)  loss_box_reg: 0.1273 (0.1401)  loss_objectness: 0.0926 (0.1025)  loss_rpn_box_reg: 0.0177 (0.0333)  time: 0.2691  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [26]  [ 410/1229]  eta: 0:03:45  lr: 0.000000  loss: 0.3616 (0.4255)  loss_classifier: 0.1346 (0.1510)  loss_box_reg: 0.1277 (0.1392)  loss_objectness: 0.0926 (0.1022)  loss_rpn_box_reg: 0.0155 (0.0332)  time: 0.2745  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [26]  [ 420/1229]  eta: 0:03:42  lr: 0.000000  loss: 0.3605 (0.4256)  loss_classifier: 0.1272 (0.1511)  loss_box_reg: 0.1240 (0.1392)  loss_objectness: 0.0877 (0.1024)  loss_rpn_box_reg: 0.0190 (0.0329)  time: 0.2746  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [26]  [ 430/1229]  eta: 0:03:39  lr: 0.000000  loss: 0.3432 (0.4259)  loss_classifier: 0.1194 (0.1513)  loss_box_reg: 0.1006 (0.1393)  loss_objectness: 0.1052 (0.1024)  loss_rpn_box_reg: 0.0175 (0.0329)  time: 0.2739  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [26]  [ 440/1229]  eta: 0:03:36  lr: 0.000000  loss: 0.4131 (0.4260)  loss_classifier: 0.1315 (0.1512)  loss_box_reg: 0.1005 (0.1390)  loss_objectness: 0.0900 (0.1026)  loss_rpn_box_reg: 0.0180 (0.0332)  time: 0.2750  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [26]  [ 450/1229]  eta: 0:03:34  lr: 0.000000  loss: 0.4276 (0.4261)  loss_classifier: 0.1422 (0.1511)  loss_box_reg: 0.1085 (0.1391)  loss_objectness: 0.0900 (0.1024)  loss_rpn_box_reg: 0.0174 (0.0335)  time: 0.2770  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [26]  [ 460/1229]  eta: 0:03:31  lr: 0.000000  loss: 0.4309 (0.4267)  loss_classifier: 0.1456 (0.1514)  loss_box_reg: 0.1225 (0.1397)  loss_objectness: 0.0748 (0.1022)  loss_rpn_box_reg: 0.0174 (0.0334)  time: 0.2813  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [26]  [ 470/1229]  eta: 0:03:28  lr: 0.000000  loss: 0.3688 (0.4263)  loss_classifier: 0.1423 (0.1511)  loss_box_reg: 0.1225 (0.1398)  loss_objectness: 0.0862 (0.1022)  loss_rpn_box_reg: 0.0174 (0.0332)  time: 0.2769  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [26]  [ 480/1229]  eta: 0:03:25  lr: 0.000000  loss: 0.3439 (0.4280)  loss_classifier: 0.1294 (0.1516)  loss_box_reg: 0.1342 (0.1409)  loss_objectness: 0.0907 (0.1022)  loss_rpn_box_reg: 0.0187 (0.0332)  time: 0.2674  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [26]  [ 490/1229]  eta: 0:03:23  lr: 0.000000  loss: 0.4007 (0.4303)  loss_classifier: 0.1552 (0.1525)  loss_box_reg: 0.1526 (0.1423)  loss_objectness: 0.0946 (0.1023)  loss_rpn_box_reg: 0.0269 (0.0332)  time: 0.2690  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [26]  [ 500/1229]  eta: 0:03:20  lr: 0.000000  loss: 0.3878 (0.4305)  loss_classifier: 0.1494 (0.1526)  loss_box_reg: 0.1558 (0.1426)  loss_objectness: 0.0820 (0.1024)  loss_rpn_box_reg: 0.0253 (0.0330)  time: 0.2716  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [26]  [ 510/1229]  eta: 0:03:17  lr: 0.000000  loss: 0.4000 (0.4323)  loss_classifier: 0.1494 (0.1532)  loss_box_reg: 0.1600 (0.1437)  loss_objectness: 0.0801 (0.1024)  loss_rpn_box_reg: 0.0253 (0.0330)  time: 0.2693  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [26]  [ 520/1229]  eta: 0:03:14  lr: 0.000000  loss: 0.4279 (0.4330)  loss_classifier: 0.1584 (0.1536)  loss_box_reg: 0.1833 (0.1440)  loss_objectness: 0.0888 (0.1024)  loss_rpn_box_reg: 0.0266 (0.0330)  time: 0.2743  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [26]  [ 530/1229]  eta: 0:03:12  lr: 0.000000  loss: 0.3892 (0.4311)  loss_classifier: 0.1351 (0.1526)  loss_box_reg: 0.0944 (0.1429)  loss_objectness: 0.0748 (0.1024)  loss_rpn_box_reg: 0.0274 (0.0333)  time: 0.2767  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [26]  [ 540/1229]  eta: 0:03:09  lr: 0.000000  loss: 0.2897 (0.4287)  loss_classifier: 0.1028 (0.1519)  loss_box_reg: 0.0622 (0.1417)  loss_objectness: 0.0706 (0.1022)  loss_rpn_box_reg: 0.0174 (0.0329)  time: 0.2729  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [26]  [ 550/1229]  eta: 0:03:06  lr: 0.000000  loss: 0.3035 (0.4295)  loss_classifier: 0.1135 (0.1521)  loss_box_reg: 0.0957 (0.1424)  loss_objectness: 0.0772 (0.1019)  loss_rpn_box_reg: 0.0174 (0.0331)  time: 0.2684  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [26]  [ 560/1229]  eta: 0:03:03  lr: 0.000000  loss: 0.3973 (0.4303)  loss_classifier: 0.1484 (0.1525)  loss_box_reg: 0.1372 (0.1430)  loss_objectness: 0.0774 (0.1018)  loss_rpn_box_reg: 0.0210 (0.0330)  time: 0.2684  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [26]  [ 570/1229]  eta: 0:03:00  lr: 0.000000  loss: 0.3938 (0.4294)  loss_classifier: 0.1455 (0.1520)  loss_box_reg: 0.1372 (0.1429)  loss_objectness: 0.0716 (0.1014)  loss_rpn_box_reg: 0.0164 (0.0331)  time: 0.2714  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [26]  [ 580/1229]  eta: 0:02:57  lr: 0.000000  loss: 0.2707 (0.4269)  loss_classifier: 0.0886 (0.1509)  loss_box_reg: 0.0754 (0.1414)  loss_objectness: 0.0588 (0.1010)  loss_rpn_box_reg: 0.0108 (0.0335)  time: 0.2677  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [26]  [ 590/1229]  eta: 0:02:55  lr: 0.000000  loss: 0.3090 (0.4282)  loss_classifier: 0.0998 (0.1515)  loss_box_reg: 0.1018 (0.1422)  loss_objectness: 0.0672 (0.1008)  loss_rpn_box_reg: 0.0174 (0.0337)  time: 0.2741  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [26]  [ 600/1229]  eta: 0:02:52  lr: 0.000000  loss: 0.4719 (0.4283)  loss_classifier: 0.1663 (0.1515)  loss_box_reg: 0.1445 (0.1423)  loss_objectness: 0.0832 (0.1009)  loss_rpn_box_reg: 0.0212 (0.0337)  time: 0.2741  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [26]  [ 610/1229]  eta: 0:02:49  lr: 0.000000  loss: 0.4553 (0.4294)  loss_classifier: 0.1444 (0.1519)  loss_box_reg: 0.1414 (0.1429)  loss_objectness: 0.0837 (0.1009)  loss_rpn_box_reg: 0.0197 (0.0337)  time: 0.2739  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [26]  [ 620/1229]  eta: 0:02:46  lr: 0.000000  loss: 0.4553 (0.4294)  loss_classifier: 0.1638 (0.1521)  loss_box_reg: 0.1454 (0.1427)  loss_objectness: 0.0835 (0.1011)  loss_rpn_box_reg: 0.0172 (0.0335)  time: 0.2721  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [26]  [ 630/1229]  eta: 0:02:44  lr: 0.000000  loss: 0.4803 (0.4303)  loss_classifier: 0.1862 (0.1525)  loss_box_reg: 0.1111 (0.1433)  loss_objectness: 0.0964 (0.1011)  loss_rpn_box_reg: 0.0172 (0.0333)  time: 0.2671  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [26]  [ 640/1229]  eta: 0:02:41  lr: 0.000000  loss: 0.4874 (0.4307)  loss_classifier: 0.1318 (0.1526)  loss_box_reg: 0.1111 (0.1431)  loss_objectness: 0.1084 (0.1013)  loss_rpn_box_reg: 0.0250 (0.0337)  time: 0.2781  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [26]  [ 650/1229]  eta: 0:02:38  lr: 0.000000  loss: 0.3786 (0.4304)  loss_classifier: 0.1318 (0.1526)  loss_box_reg: 0.1230 (0.1432)  loss_objectness: 0.0876 (0.1010)  loss_rpn_box_reg: 0.0241 (0.0336)  time: 0.2809  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [26]  [ 660/1229]  eta: 0:02:36  lr: 0.000000  loss: 0.3777 (0.4298)  loss_classifier: 0.1414 (0.1522)  loss_box_reg: 0.1071 (0.1429)  loss_objectness: 0.0677 (0.1010)  loss_rpn_box_reg: 0.0241 (0.0337)  time: 0.2736  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [26]  [ 670/1229]  eta: 0:02:33  lr: 0.000000  loss: 0.3432 (0.4297)  loss_classifier: 0.1113 (0.1522)  loss_box_reg: 0.0957 (0.1429)  loss_objectness: 0.0902 (0.1009)  loss_rpn_box_reg: 0.0191 (0.0336)  time: 0.2727  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [26]  [ 680/1229]  eta: 0:02:30  lr: 0.000000  loss: 0.3360 (0.4299)  loss_classifier: 0.1113 (0.1524)  loss_box_reg: 0.0959 (0.1427)  loss_objectness: 0.0880 (0.1011)  loss_rpn_box_reg: 0.0191 (0.0337)  time: 0.2727  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [26]  [ 690/1229]  eta: 0:02:27  lr: 0.000000  loss: 0.3152 (0.4288)  loss_classifier: 0.1104 (0.1520)  loss_box_reg: 0.0917 (0.1424)  loss_objectness: 0.0786 (0.1011)  loss_rpn_box_reg: 0.0167 (0.0334)  time: 0.2730  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [26]  [ 700/1229]  eta: 0:02:25  lr: 0.000000  loss: 0.3154 (0.4294)  loss_classifier: 0.1191 (0.1522)  loss_box_reg: 0.1108 (0.1422)  loss_objectness: 0.0990 (0.1015)  loss_rpn_box_reg: 0.0178 (0.0336)  time: 0.2700  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [26]  [ 710/1229]  eta: 0:02:22  lr: 0.000000  loss: 0.3511 (0.4289)  loss_classifier: 0.1251 (0.1520)  loss_box_reg: 0.1103 (0.1420)  loss_objectness: 0.0973 (0.1014)  loss_rpn_box_reg: 0.0251 (0.0335)  time: 0.2662  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [26]  [ 720/1229]  eta: 0:02:19  lr: 0.000000  loss: 0.4033 (0.4302)  loss_classifier: 0.1327 (0.1526)  loss_box_reg: 0.1364 (0.1427)  loss_objectness: 0.0861 (0.1014)  loss_rpn_box_reg: 0.0270 (0.0334)  time: 0.2712  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [26]  [ 730/1229]  eta: 0:02:16  lr: 0.000000  loss: 0.4836 (0.4305)  loss_classifier: 0.1603 (0.1526)  loss_box_reg: 0.1434 (0.1429)  loss_objectness: 0.0861 (0.1012)  loss_rpn_box_reg: 0.0359 (0.0338)  time: 0.2772  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [26]  [ 740/1229]  eta: 0:02:14  lr: 0.000000  loss: 0.4018 (0.4310)  loss_classifier: 0.1381 (0.1529)  loss_box_reg: 0.1213 (0.1435)  loss_objectness: 0.0853 (0.1011)  loss_rpn_box_reg: 0.0283 (0.0336)  time: 0.2743  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [26]  [ 750/1229]  eta: 0:02:11  lr: 0.000000  loss: 0.3125 (0.4305)  loss_classifier: 0.1273 (0.1526)  loss_box_reg: 0.1205 (0.1431)  loss_objectness: 0.0878 (0.1011)  loss_rpn_box_reg: 0.0212 (0.0338)  time: 0.2660  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [26]  [ 760/1229]  eta: 0:02:08  lr: 0.000000  loss: 0.3843 (0.4312)  loss_classifier: 0.1251 (0.1528)  loss_box_reg: 0.1205 (0.1433)  loss_objectness: 0.0954 (0.1013)  loss_rpn_box_reg: 0.0291 (0.0339)  time: 0.2683  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [26]  [ 770/1229]  eta: 0:02:05  lr: 0.000000  loss: 0.4024 (0.4310)  loss_classifier: 0.1271 (0.1527)  loss_box_reg: 0.1295 (0.1434)  loss_objectness: 0.0937 (0.1009)  loss_rpn_box_reg: 0.0386 (0.0340)  time: 0.2702  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [26]  [ 780/1229]  eta: 0:02:02  lr: 0.000000  loss: 0.4555 (0.4322)  loss_classifier: 0.1656 (0.1531)  loss_box_reg: 0.1176 (0.1436)  loss_objectness: 0.0807 (0.1014)  loss_rpn_box_reg: 0.0266 (0.0341)  time: 0.2656  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [26]  [ 790/1229]  eta: 0:02:00  lr: 0.000000  loss: 0.4801 (0.4330)  loss_classifier: 0.1672 (0.1533)  loss_box_reg: 0.1487 (0.1442)  loss_objectness: 0.0950 (0.1014)  loss_rpn_box_reg: 0.0195 (0.0341)  time: 0.2633  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [26]  [ 800/1229]  eta: 0:01:57  lr: 0.000000  loss: 0.4558 (0.4337)  loss_classifier: 0.1672 (0.1536)  loss_box_reg: 0.1561 (0.1444)  loss_objectness: 0.0858 (0.1016)  loss_rpn_box_reg: 0.0195 (0.0342)  time: 0.2713  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [26]  [ 810/1229]  eta: 0:01:54  lr: 0.000000  loss: 0.5032 (0.4360)  loss_classifier: 0.1689 (0.1545)  loss_box_reg: 0.1511 (0.1455)  loss_objectness: 0.1013 (0.1018)  loss_rpn_box_reg: 0.0296 (0.0342)  time: 0.2768  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [26]  [ 820/1229]  eta: 0:01:51  lr: 0.000000  loss: 0.4584 (0.4363)  loss_classifier: 0.1660 (0.1545)  loss_box_reg: 0.1464 (0.1460)  loss_objectness: 0.1051 (0.1016)  loss_rpn_box_reg: 0.0294 (0.0341)  time: 0.2702  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [26]  [ 830/1229]  eta: 0:01:49  lr: 0.000000  loss: 0.4049 (0.4360)  loss_classifier: 0.1547 (0.1545)  loss_box_reg: 0.1464 (0.1460)  loss_objectness: 0.0988 (0.1015)  loss_rpn_box_reg: 0.0248 (0.0340)  time: 0.2727  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [26]  [ 840/1229]  eta: 0:01:46  lr: 0.000000  loss: 0.4003 (0.4358)  loss_classifier: 0.1472 (0.1545)  loss_box_reg: 0.1337 (0.1459)  loss_objectness: 0.0877 (0.1015)  loss_rpn_box_reg: 0.0205 (0.0340)  time: 0.2787  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [26]  [ 850/1229]  eta: 0:01:43  lr: 0.000000  loss: 0.3749 (0.4362)  loss_classifier: 0.1346 (0.1545)  loss_box_reg: 0.1278 (0.1461)  loss_objectness: 0.0830 (0.1013)  loss_rpn_box_reg: 0.0196 (0.0343)  time: 0.2736  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [26]  [ 860/1229]  eta: 0:01:40  lr: 0.000000  loss: 0.4409 (0.4367)  loss_classifier: 0.1650 (0.1547)  loss_box_reg: 0.1509 (0.1464)  loss_objectness: 0.0824 (0.1013)  loss_rpn_box_reg: 0.0196 (0.0343)  time: 0.2723  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [26]  [ 870/1229]  eta: 0:01:38  lr: 0.000000  loss: 0.4578 (0.4368)  loss_classifier: 0.1353 (0.1548)  loss_box_reg: 0.1270 (0.1463)  loss_objectness: 0.0824 (0.1013)  loss_rpn_box_reg: 0.0198 (0.0344)  time: 0.2771  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [26]  [ 880/1229]  eta: 0:01:35  lr: 0.000000  loss: 0.3611 (0.4365)  loss_classifier: 0.1199 (0.1547)  loss_box_reg: 0.1140 (0.1463)  loss_objectness: 0.0889 (0.1014)  loss_rpn_box_reg: 0.0191 (0.0342)  time: 0.2723  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [26]  [ 890/1229]  eta: 0:01:32  lr: 0.000000  loss: 0.3681 (0.4368)  loss_classifier: 0.1483 (0.1548)  loss_box_reg: 0.1146 (0.1464)  loss_objectness: 0.0944 (0.1014)  loss_rpn_box_reg: 0.0194 (0.0342)  time: 0.2716  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [26]  [ 900/1229]  eta: 0:01:30  lr: 0.000000  loss: 0.3047 (0.4359)  loss_classifier: 0.1425 (0.1546)  loss_box_reg: 0.1146 (0.1460)  loss_objectness: 0.0831 (0.1012)  loss_rpn_box_reg: 0.0164 (0.0341)  time: 0.2777  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [26]  [ 910/1229]  eta: 0:01:27  lr: 0.000000  loss: 0.4117 (0.4370)  loss_classifier: 0.1443 (0.1550)  loss_box_reg: 0.1145 (0.1464)  loss_objectness: 0.0849 (0.1013)  loss_rpn_box_reg: 0.0257 (0.0343)  time: 0.2742  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [26]  [ 920/1229]  eta: 0:01:24  lr: 0.000000  loss: 0.4209 (0.4376)  loss_classifier: 0.1510 (0.1552)  loss_box_reg: 0.1256 (0.1464)  loss_objectness: 0.1089 (0.1015)  loss_rpn_box_reg: 0.0344 (0.0344)  time: 0.2692  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [26]  [ 930/1229]  eta: 0:01:21  lr: 0.000000  loss: 0.3845 (0.4372)  loss_classifier: 0.1309 (0.1550)  loss_box_reg: 0.1117 (0.1462)  loss_objectness: 0.1233 (0.1016)  loss_rpn_box_reg: 0.0228 (0.0344)  time: 0.2708  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [26]  [ 940/1229]  eta: 0:01:19  lr: 0.000000  loss: 0.4243 (0.4381)  loss_classifier: 0.1377 (0.1553)  loss_box_reg: 0.1225 (0.1465)  loss_objectness: 0.0790 (0.1019)  loss_rpn_box_reg: 0.0190 (0.0345)  time: 0.2709  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [26]  [ 950/1229]  eta: 0:01:16  lr: 0.000000  loss: 0.4243 (0.4390)  loss_classifier: 0.1769 (0.1557)  loss_box_reg: 0.1689 (0.1468)  loss_objectness: 0.1392 (0.1021)  loss_rpn_box_reg: 0.0208 (0.0345)  time: 0.2717  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [26]  [ 960/1229]  eta: 0:01:13  lr: 0.000000  loss: 0.3792 (0.4380)  loss_classifier: 0.1346 (0.1554)  loss_box_reg: 0.1371 (0.1465)  loss_objectness: 0.0794 (0.1018)  loss_rpn_box_reg: 0.0208 (0.0344)  time: 0.2720  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [26]  [ 970/1229]  eta: 0:01:10  lr: 0.000000  loss: 0.3678 (0.4382)  loss_classifier: 0.1301 (0.1555)  loss_box_reg: 0.1267 (0.1464)  loss_objectness: 0.0794 (0.1019)  loss_rpn_box_reg: 0.0176 (0.0343)  time: 0.2729  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [26]  [ 980/1229]  eta: 0:01:08  lr: 0.000000  loss: 0.4257 (0.4392)  loss_classifier: 0.1641 (0.1559)  loss_box_reg: 0.1156 (0.1467)  loss_objectness: 0.0838 (0.1023)  loss_rpn_box_reg: 0.0212 (0.0343)  time: 0.2785  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [26]  [ 990/1229]  eta: 0:01:05  lr: 0.000000  loss: 0.4179 (0.4392)  loss_classifier: 0.1487 (0.1559)  loss_box_reg: 0.0990 (0.1467)  loss_objectness: 0.1043 (0.1024)  loss_rpn_box_reg: 0.0224 (0.0343)  time: 0.2774  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [26]  [1000/1229]  eta: 0:01:02  lr: 0.000000  loss: 0.3303 (0.4390)  loss_classifier: 0.1178 (0.1559)  loss_box_reg: 0.1138 (0.1467)  loss_objectness: 0.0795 (0.1022)  loss_rpn_box_reg: 0.0222 (0.0342)  time: 0.2734  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [26]  [1010/1229]  eta: 0:00:59  lr: 0.000000  loss: 0.3472 (0.4386)  loss_classifier: 0.1248 (0.1558)  loss_box_reg: 0.1158 (0.1467)  loss_objectness: 0.0777 (0.1020)  loss_rpn_box_reg: 0.0214 (0.0342)  time: 0.2743  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [26]  [1020/1229]  eta: 0:00:57  lr: 0.000000  loss: 0.3929 (0.4386)  loss_classifier: 0.1569 (0.1559)  loss_box_reg: 0.1385 (0.1467)  loss_objectness: 0.0937 (0.1019)  loss_rpn_box_reg: 0.0214 (0.0341)  time: 0.2996  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [26]  [1030/1229]  eta: 0:00:54  lr: 0.000000  loss: 0.4558 (0.4390)  loss_classifier: 0.1652 (0.1561)  loss_box_reg: 0.1411 (0.1468)  loss_objectness: 0.1011 (0.1021)  loss_rpn_box_reg: 0.0236 (0.0340)  time: 0.2984  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [26]  [1040/1229]  eta: 0:00:51  lr: 0.000000  loss: 0.4338 (0.4386)  loss_classifier: 0.1508 (0.1559)  loss_box_reg: 0.1345 (0.1466)  loss_objectness: 0.0940 (0.1020)  loss_rpn_box_reg: 0.0260 (0.0340)  time: 0.2720  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [26]  [1050/1229]  eta: 0:00:49  lr: 0.000000  loss: 0.3657 (0.4384)  loss_classifier: 0.1409 (0.1559)  loss_box_reg: 0.1248 (0.1466)  loss_objectness: 0.0940 (0.1020)  loss_rpn_box_reg: 0.0267 (0.0339)  time: 0.2746  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [26]  [1060/1229]  eta: 0:00:46  lr: 0.000000  loss: 0.3210 (0.4376)  loss_classifier: 0.1229 (0.1557)  loss_box_reg: 0.1022 (0.1462)  loss_objectness: 0.0669 (0.1019)  loss_rpn_box_reg: 0.0215 (0.0338)  time: 0.2839  data: 0.1381  max mem: 1751\n",
      "Training Epoch: [26]  [1070/1229]  eta: 0:00:43  lr: 0.000000  loss: 0.3480 (0.4375)  loss_classifier: 0.1229 (0.1556)  loss_box_reg: 0.1039 (0.1462)  loss_objectness: 0.0861 (0.1019)  loss_rpn_box_reg: 0.0226 (0.0338)  time: 0.2909  data: 0.1405  max mem: 1751\n",
      "Training Epoch: [26]  [1080/1229]  eta: 0:00:40  lr: 0.000000  loss: 0.3057 (0.4363)  loss_classifier: 0.1031 (0.1552)  loss_box_reg: 0.0859 (0.1458)  loss_objectness: 0.0861 (0.1017)  loss_rpn_box_reg: 0.0210 (0.0337)  time: 0.2879  data: 0.1397  max mem: 1751\n",
      "Training Epoch: [26]  [1090/1229]  eta: 0:00:38  lr: 0.000000  loss: 0.3341 (0.4362)  loss_classifier: 0.1270 (0.1551)  loss_box_reg: 0.1105 (0.1458)  loss_objectness: 0.0752 (0.1017)  loss_rpn_box_reg: 0.0138 (0.0336)  time: 0.2793  data: 0.1376  max mem: 1751\n",
      "Training Epoch: [26]  [1100/1229]  eta: 0:00:35  lr: 0.000000  loss: 0.4527 (0.4370)  loss_classifier: 0.1598 (0.1555)  loss_box_reg: 0.1378 (0.1462)  loss_objectness: 0.0765 (0.1016)  loss_rpn_box_reg: 0.0225 (0.0338)  time: 0.2722  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [26]  [1110/1229]  eta: 0:00:32  lr: 0.000000  loss: 0.4527 (0.4369)  loss_classifier: 0.1842 (0.1554)  loss_box_reg: 0.1171 (0.1460)  loss_objectness: 0.0772 (0.1017)  loss_rpn_box_reg: 0.0192 (0.0338)  time: 0.2684  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [26]  [1120/1229]  eta: 0:00:29  lr: 0.000000  loss: 0.3835 (0.4372)  loss_classifier: 0.1360 (0.1555)  loss_box_reg: 0.1105 (0.1462)  loss_objectness: 0.0894 (0.1017)  loss_rpn_box_reg: 0.0186 (0.0338)  time: 0.2713  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [26]  [1130/1229]  eta: 0:00:27  lr: 0.000000  loss: 0.3523 (0.4359)  loss_classifier: 0.1256 (0.1551)  loss_box_reg: 0.0966 (0.1456)  loss_objectness: 0.0776 (0.1014)  loss_rpn_box_reg: 0.0158 (0.0338)  time: 0.2808  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [26]  [1140/1229]  eta: 0:00:24  lr: 0.000000  loss: 0.2691 (0.4356)  loss_classifier: 0.0988 (0.1549)  loss_box_reg: 0.0750 (0.1457)  loss_objectness: 0.0761 (0.1012)  loss_rpn_box_reg: 0.0118 (0.0338)  time: 0.2858  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [26]  [1150/1229]  eta: 0:00:21  lr: 0.000000  loss: 0.3772 (0.4363)  loss_classifier: 0.1393 (0.1551)  loss_box_reg: 0.1181 (0.1459)  loss_objectness: 0.0763 (0.1013)  loss_rpn_box_reg: 0.0207 (0.0341)  time: 0.2772  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [26]  [1160/1229]  eta: 0:00:18  lr: 0.000000  loss: 0.3772 (0.4363)  loss_classifier: 0.1393 (0.1550)  loss_box_reg: 0.1181 (0.1456)  loss_objectness: 0.0836 (0.1013)  loss_rpn_box_reg: 0.0365 (0.0343)  time: 0.2677  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [26]  [1170/1229]  eta: 0:00:16  lr: 0.000000  loss: 0.3202 (0.4353)  loss_classifier: 0.0886 (0.1547)  loss_box_reg: 0.0902 (0.1453)  loss_objectness: 0.0663 (0.1011)  loss_rpn_box_reg: 0.0261 (0.0342)  time: 0.2691  data: 0.1298  max mem: 1751\n",
      "Training Epoch: [26]  [1180/1229]  eta: 0:00:13  lr: 0.000000  loss: 0.3202 (0.4353)  loss_classifier: 0.0992 (0.1548)  loss_box_reg: 0.0933 (0.1451)  loss_objectness: 0.0809 (0.1013)  loss_rpn_box_reg: 0.0128 (0.0342)  time: 0.2768  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [26]  [1190/1229]  eta: 0:00:10  lr: 0.000000  loss: 0.3948 (0.4355)  loss_classifier: 0.1377 (0.1548)  loss_box_reg: 0.1171 (0.1450)  loss_objectness: 0.1212 (0.1015)  loss_rpn_box_reg: 0.0197 (0.0342)  time: 0.2738  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [26]  [1200/1229]  eta: 0:00:07  lr: 0.000000  loss: 0.3930 (0.4352)  loss_classifier: 0.1236 (0.1548)  loss_box_reg: 0.1065 (0.1448)  loss_objectness: 0.0984 (0.1015)  loss_rpn_box_reg: 0.0199 (0.0342)  time: 0.2714  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [26]  [1210/1229]  eta: 0:00:05  lr: 0.000000  loss: 0.3930 (0.4351)  loss_classifier: 0.1236 (0.1547)  loss_box_reg: 0.1106 (0.1447)  loss_objectness: 0.0801 (0.1013)  loss_rpn_box_reg: 0.0194 (0.0343)  time: 0.2817  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [26]  [1220/1229]  eta: 0:00:02  lr: 0.000000  loss: 0.4219 (0.4352)  loss_classifier: 0.1465 (0.1548)  loss_box_reg: 0.1414 (0.1450)  loss_objectness: 0.0677 (0.1012)  loss_rpn_box_reg: 0.0178 (0.0342)  time: 0.2851  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [26]  [1228/1229]  eta: 0:00:00  lr: 0.000000  loss: 0.3974 (0.4356)  loss_classifier: 0.1429 (0.1549)  loss_box_reg: 0.1411 (0.1451)  loss_objectness: 0.0798 (0.1013)  loss_rpn_box_reg: 0.0168 (0.0343)  time: 0.2821  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [26] Total time: 0:05:37 (0.2748 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:38  model_time: 0.2880 (0.2880)  evaluator_time: 0.0010 (0.0010)  time: 0.3210  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:27  model_time: 0.0820 (0.0846)  evaluator_time: 0.0040 (0.0086)  time: 0.1279  data: 0.0363  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0840 (0.0824)  evaluator_time: 0.0030 (0.0079)  time: 0.1207  data: 0.0305  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0730 (0.0812)  evaluator_time: 0.0040 (0.0077)  time: 0.1210  data: 0.0357  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0730 (0.0811)  evaluator_time: 0.0030 (0.0077)  time: 0.1175  data: 0.0344  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1250 s / it)\n",
      "Averaged stats: model_time: 0.0730 (0.0811)  evaluator_time: 0.0030 (0.0077)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [26]  [  0/308]  eta: 0:00:38  lr: 0.000000  loss: 0.1644 (0.1644)  loss_classifier: 0.0581 (0.0581)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0264 (0.0264)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1260  data: 0.0271  max mem: 1751\n",
      "Testing Epoch: [26]  [100/308]  eta: 0:00:28  lr: 0.000000  loss: 0.3108 (0.4813)  loss_classifier: 0.1334 (0.1543)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0546 (0.1026)  loss_rpn_box_reg: 0.0186 (0.0521)  time: 0.1393  data: 0.0376  max mem: 1751\n",
      "Testing Epoch: [26]  [200/308]  eta: 0:00:14  lr: 0.000000  loss: 0.3501 (0.4565)  loss_classifier: 0.1392 (0.1490)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0720 (0.0951)  loss_rpn_box_reg: 0.0197 (0.0492)  time: 0.1385  data: 0.0325  max mem: 1751\n",
      "Testing Epoch: [26]  [300/308]  eta: 0:00:01  lr: 0.000000  loss: 0.4572 (0.4534)  loss_classifier: 0.1569 (0.1493)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0759 (0.0924)  loss_rpn_box_reg: 0.0265 (0.0476)  time: 0.1318  data: 0.0369  max mem: 1751\n",
      "Testing Epoch: [26]  [307/308]  eta: 0:00:00  lr: 0.000000  loss: 0.4572 (0.4536)  loss_classifier: 0.1860 (0.1495)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0711 (0.0926)  loss_rpn_box_reg: 0.0271 (0.0471)  time: 0.1296  data: 0.0349  max mem: 1751\n",
      "Testing Epoch: [26] Total time: 0:00:42 (0.1373 s / it)\n",
      "Training Epoch: [27]  [   0/1229]  eta: 0:05:56  lr: 0.000000  loss: 0.4998 (0.4998)  loss_classifier: 0.1825 (0.1825)  loss_box_reg: 0.2189 (0.2189)  loss_objectness: 0.0647 (0.0647)  loss_rpn_box_reg: 0.0337 (0.0337)  time: 0.2900  data: 0.1280  max mem: 1751\n",
      "Training Epoch: [27]  [  10/1229]  eta: 0:05:31  lr: 0.000000  loss: 0.2899 (0.3534)  loss_classifier: 0.1076 (0.1284)  loss_box_reg: 0.1028 (0.1302)  loss_objectness: 0.0647 (0.0728)  loss_rpn_box_reg: 0.0195 (0.0220)  time: 0.2716  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [27]  [  20/1229]  eta: 0:05:33  lr: 0.000000  loss: 0.3057 (0.3742)  loss_classifier: 0.1076 (0.1342)  loss_box_reg: 0.0879 (0.1257)  loss_objectness: 0.0658 (0.0838)  loss_rpn_box_reg: 0.0185 (0.0305)  time: 0.2749  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [27]  [  30/1229]  eta: 0:05:30  lr: 0.000000  loss: 0.3057 (0.3649)  loss_classifier: 0.0906 (0.1294)  loss_box_reg: 0.0780 (0.1181)  loss_objectness: 0.0717 (0.0835)  loss_rpn_box_reg: 0.0185 (0.0338)  time: 0.2784  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [27]  [  40/1229]  eta: 0:05:25  lr: 0.000000  loss: 0.3169 (0.3733)  loss_classifier: 0.1157 (0.1344)  loss_box_reg: 0.1021 (0.1215)  loss_objectness: 0.0740 (0.0854)  loss_rpn_box_reg: 0.0184 (0.0321)  time: 0.2725  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [27]  [  50/1229]  eta: 0:05:23  lr: 0.000000  loss: 0.3746 (0.3928)  loss_classifier: 0.1426 (0.1417)  loss_box_reg: 0.1274 (0.1308)  loss_objectness: 0.0740 (0.0901)  loss_rpn_box_reg: 0.0184 (0.0303)  time: 0.2728  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [27]  [  60/1229]  eta: 0:05:22  lr: 0.000000  loss: 0.3590 (0.3880)  loss_classifier: 0.1267 (0.1388)  loss_box_reg: 0.1274 (0.1271)  loss_objectness: 0.0729 (0.0909)  loss_rpn_box_reg: 0.0172 (0.0312)  time: 0.2790  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [27]  [  70/1229]  eta: 0:05:18  lr: 0.000000  loss: 0.3257 (0.3904)  loss_classifier: 0.1100 (0.1410)  loss_box_reg: 0.0945 (0.1267)  loss_objectness: 0.0713 (0.0917)  loss_rpn_box_reg: 0.0190 (0.0309)  time: 0.2734  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [27]  [  80/1229]  eta: 0:05:14  lr: 0.000000  loss: 0.3257 (0.3885)  loss_classifier: 0.1133 (0.1403)  loss_box_reg: 0.0994 (0.1278)  loss_objectness: 0.0685 (0.0900)  loss_rpn_box_reg: 0.0176 (0.0304)  time: 0.2683  data: 0.1292  max mem: 1751\n",
      "Training Epoch: [27]  [  90/1229]  eta: 0:05:12  lr: 0.000000  loss: 0.3572 (0.3979)  loss_classifier: 0.1543 (0.1439)  loss_box_reg: 0.1364 (0.1310)  loss_objectness: 0.0812 (0.0921)  loss_rpn_box_reg: 0.0176 (0.0309)  time: 0.2754  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [27]  [ 100/1229]  eta: 0:05:09  lr: 0.000000  loss: 0.4498 (0.4038)  loss_classifier: 0.1615 (0.1454)  loss_box_reg: 0.1243 (0.1317)  loss_objectness: 0.0904 (0.0954)  loss_rpn_box_reg: 0.0198 (0.0312)  time: 0.2751  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [27]  [ 110/1229]  eta: 0:05:05  lr: 0.000000  loss: 0.3258 (0.4025)  loss_classifier: 0.1267 (0.1454)  loss_box_reg: 0.1225 (0.1318)  loss_objectness: 0.0810 (0.0952)  loss_rpn_box_reg: 0.0162 (0.0301)  time: 0.2681  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [27]  [ 120/1229]  eta: 0:05:02  lr: 0.000000  loss: 0.3106 (0.4049)  loss_classifier: 0.1131 (0.1462)  loss_box_reg: 0.1232 (0.1336)  loss_objectness: 0.0787 (0.0952)  loss_rpn_box_reg: 0.0164 (0.0298)  time: 0.2683  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [27]  [ 130/1229]  eta: 0:05:00  lr: 0.000000  loss: 0.3106 (0.4036)  loss_classifier: 0.1135 (0.1460)  loss_box_reg: 0.1086 (0.1335)  loss_objectness: 0.0797 (0.0945)  loss_rpn_box_reg: 0.0164 (0.0297)  time: 0.2746  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [27]  [ 140/1229]  eta: 0:04:57  lr: 0.000000  loss: 0.4286 (0.4116)  loss_classifier: 0.1593 (0.1491)  loss_box_reg: 0.1425 (0.1379)  loss_objectness: 0.0861 (0.0946)  loss_rpn_box_reg: 0.0180 (0.0300)  time: 0.2748  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [27]  [ 150/1229]  eta: 0:04:54  lr: 0.000000  loss: 0.4156 (0.4135)  loss_classifier: 0.1584 (0.1496)  loss_box_reg: 0.1562 (0.1391)  loss_objectness: 0.0792 (0.0945)  loss_rpn_box_reg: 0.0177 (0.0304)  time: 0.2710  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [27]  [ 160/1229]  eta: 0:04:51  lr: 0.000000  loss: 0.4029 (0.4140)  loss_classifier: 0.1338 (0.1497)  loss_box_reg: 0.1342 (0.1388)  loss_objectness: 0.0792 (0.0939)  loss_rpn_box_reg: 0.0131 (0.0316)  time: 0.2698  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [27]  [ 170/1229]  eta: 0:04:48  lr: 0.000000  loss: 0.4033 (0.4181)  loss_classifier: 0.1338 (0.1507)  loss_box_reg: 0.1342 (0.1411)  loss_objectness: 0.0795 (0.0947)  loss_rpn_box_reg: 0.0254 (0.0316)  time: 0.2698  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [27]  [ 180/1229]  eta: 0:04:45  lr: 0.000000  loss: 0.4163 (0.4183)  loss_classifier: 0.1630 (0.1506)  loss_box_reg: 0.1372 (0.1411)  loss_objectness: 0.0806 (0.0944)  loss_rpn_box_reg: 0.0220 (0.0321)  time: 0.2680  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [27]  [ 190/1229]  eta: 0:04:42  lr: 0.000000  loss: 0.4912 (0.4280)  loss_classifier: 0.1814 (0.1541)  loss_box_reg: 0.1443 (0.1454)  loss_objectness: 0.1009 (0.0964)  loss_rpn_box_reg: 0.0231 (0.0320)  time: 0.2651  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [27]  [ 200/1229]  eta: 0:04:39  lr: 0.000000  loss: 0.4720 (0.4284)  loss_classifier: 0.1814 (0.1541)  loss_box_reg: 0.1248 (0.1443)  loss_objectness: 0.1279 (0.0976)  loss_rpn_box_reg: 0.0237 (0.0324)  time: 0.2666  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [27]  [ 210/1229]  eta: 0:04:37  lr: 0.000000  loss: 0.3653 (0.4248)  loss_classifier: 0.1377 (0.1531)  loss_box_reg: 0.1075 (0.1430)  loss_objectness: 0.0905 (0.0971)  loss_rpn_box_reg: 0.0179 (0.0316)  time: 0.2706  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [27]  [ 220/1229]  eta: 0:04:34  lr: 0.000000  loss: 0.3653 (0.4224)  loss_classifier: 0.1256 (0.1520)  loss_box_reg: 0.1075 (0.1415)  loss_objectness: 0.0888 (0.0972)  loss_rpn_box_reg: 0.0157 (0.0318)  time: 0.2729  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [27]  [ 230/1229]  eta: 0:04:31  lr: 0.000000  loss: 0.4029 (0.4222)  loss_classifier: 0.1241 (0.1524)  loss_box_reg: 0.1023 (0.1411)  loss_objectness: 0.1000 (0.0968)  loss_rpn_box_reg: 0.0184 (0.0319)  time: 0.2695  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [27]  [ 240/1229]  eta: 0:04:29  lr: 0.000000  loss: 0.4969 (0.4295)  loss_classifier: 0.1847 (0.1553)  loss_box_reg: 0.1289 (0.1445)  loss_objectness: 0.1047 (0.0976)  loss_rpn_box_reg: 0.0216 (0.0320)  time: 0.2737  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [27]  [ 250/1229]  eta: 0:04:26  lr: 0.000000  loss: 0.4969 (0.4317)  loss_classifier: 0.1847 (0.1558)  loss_box_reg: 0.1704 (0.1452)  loss_objectness: 0.1047 (0.0976)  loss_rpn_box_reg: 0.0339 (0.0331)  time: 0.2729  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [27]  [ 260/1229]  eta: 0:04:23  lr: 0.000000  loss: 0.4262 (0.4330)  loss_classifier: 0.1600 (0.1562)  loss_box_reg: 0.1704 (0.1466)  loss_objectness: 0.0871 (0.0973)  loss_rpn_box_reg: 0.0274 (0.0329)  time: 0.2696  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [27]  [ 270/1229]  eta: 0:04:21  lr: 0.000000  loss: 0.4419 (0.4350)  loss_classifier: 0.1643 (0.1567)  loss_box_reg: 0.1479 (0.1461)  loss_objectness: 0.0893 (0.0985)  loss_rpn_box_reg: 0.0236 (0.0337)  time: 0.2788  data: 0.1372  max mem: 1751\n",
      "Training Epoch: [27]  [ 280/1229]  eta: 0:04:18  lr: 0.000000  loss: 0.4148 (0.4333)  loss_classifier: 0.1515 (0.1559)  loss_box_reg: 0.0834 (0.1445)  loss_objectness: 0.0941 (0.0985)  loss_rpn_box_reg: 0.0305 (0.0345)  time: 0.2773  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [27]  [ 290/1229]  eta: 0:04:16  lr: 0.000000  loss: 0.3234 (0.4363)  loss_classifier: 0.1077 (0.1564)  loss_box_reg: 0.0809 (0.1465)  loss_objectness: 0.0754 (0.0983)  loss_rpn_box_reg: 0.0296 (0.0351)  time: 0.2770  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [27]  [ 300/1229]  eta: 0:04:13  lr: 0.000000  loss: 0.3339 (0.4356)  loss_classifier: 0.1245 (0.1562)  loss_box_reg: 0.0872 (0.1459)  loss_objectness: 0.0946 (0.0984)  loss_rpn_box_reg: 0.0248 (0.0350)  time: 0.2819  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [27]  [ 310/1229]  eta: 0:04:10  lr: 0.000000  loss: 0.2885 (0.4322)  loss_classifier: 0.1181 (0.1549)  loss_box_reg: 0.0872 (0.1439)  loss_objectness: 0.0672 (0.0979)  loss_rpn_box_reg: 0.0111 (0.0355)  time: 0.2753  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [27]  [ 320/1229]  eta: 0:04:08  lr: 0.000000  loss: 0.3635 (0.4316)  loss_classifier: 0.1274 (0.1546)  loss_box_reg: 0.0965 (0.1438)  loss_objectness: 0.0690 (0.0980)  loss_rpn_box_reg: 0.0149 (0.0352)  time: 0.2721  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [27]  [ 330/1229]  eta: 0:04:05  lr: 0.000000  loss: 0.4155 (0.4298)  loss_classifier: 0.1392 (0.1539)  loss_box_reg: 0.1317 (0.1433)  loss_objectness: 0.0865 (0.0976)  loss_rpn_box_reg: 0.0245 (0.0350)  time: 0.2726  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [27]  [ 340/1229]  eta: 0:04:02  lr: 0.000000  loss: 0.4441 (0.4328)  loss_classifier: 0.1515 (0.1547)  loss_box_reg: 0.1569 (0.1442)  loss_objectness: 0.0955 (0.0986)  loss_rpn_box_reg: 0.0255 (0.0353)  time: 0.2700  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [27]  [ 350/1229]  eta: 0:03:59  lr: 0.000000  loss: 0.5363 (0.4339)  loss_classifier: 0.1884 (0.1552)  loss_box_reg: 0.1719 (0.1454)  loss_objectness: 0.1166 (0.0984)  loss_rpn_box_reg: 0.0243 (0.0349)  time: 0.2728  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [27]  [ 360/1229]  eta: 0:03:56  lr: 0.000000  loss: 0.4228 (0.4336)  loss_classifier: 0.1503 (0.1550)  loss_box_reg: 0.1058 (0.1449)  loss_objectness: 0.0865 (0.0983)  loss_rpn_box_reg: 0.0251 (0.0354)  time: 0.2706  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [27]  [ 370/1229]  eta: 0:03:54  lr: 0.000000  loss: 0.4228 (0.4352)  loss_classifier: 0.1296 (0.1553)  loss_box_reg: 0.1222 (0.1461)  loss_objectness: 0.0832 (0.0983)  loss_rpn_box_reg: 0.0234 (0.0355)  time: 0.2717  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [27]  [ 380/1229]  eta: 0:03:51  lr: 0.000000  loss: 0.4830 (0.4373)  loss_classifier: 0.1791 (0.1562)  loss_box_reg: 0.1881 (0.1474)  loss_objectness: 0.0857 (0.0983)  loss_rpn_box_reg: 0.0206 (0.0354)  time: 0.2754  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [27]  [ 390/1229]  eta: 0:03:48  lr: 0.000000  loss: 0.3765 (0.4351)  loss_classifier: 0.1317 (0.1555)  loss_box_reg: 0.1113 (0.1461)  loss_objectness: 0.0887 (0.0981)  loss_rpn_box_reg: 0.0264 (0.0354)  time: 0.2746  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [27]  [ 400/1229]  eta: 0:03:46  lr: 0.000000  loss: 0.3123 (0.4335)  loss_classifier: 0.1186 (0.1550)  loss_box_reg: 0.0858 (0.1454)  loss_objectness: 0.0887 (0.0978)  loss_rpn_box_reg: 0.0256 (0.0352)  time: 0.2770  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [27]  [ 410/1229]  eta: 0:03:43  lr: 0.000000  loss: 0.4687 (0.4336)  loss_classifier: 0.1633 (0.1550)  loss_box_reg: 0.1351 (0.1454)  loss_objectness: 0.0925 (0.0981)  loss_rpn_box_reg: 0.0256 (0.0351)  time: 0.2774  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [27]  [ 420/1229]  eta: 0:03:40  lr: 0.000000  loss: 0.3914 (0.4342)  loss_classifier: 0.1592 (0.1551)  loss_box_reg: 0.1013 (0.1448)  loss_objectness: 0.0979 (0.0989)  loss_rpn_box_reg: 0.0153 (0.0354)  time: 0.2754  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [27]  [ 430/1229]  eta: 0:03:38  lr: 0.000000  loss: 0.3359 (0.4338)  loss_classifier: 0.1398 (0.1551)  loss_box_reg: 0.1013 (0.1445)  loss_objectness: 0.0995 (0.0990)  loss_rpn_box_reg: 0.0153 (0.0352)  time: 0.2713  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [27]  [ 440/1229]  eta: 0:03:35  lr: 0.000000  loss: 0.3313 (0.4336)  loss_classifier: 0.1104 (0.1549)  loss_box_reg: 0.1223 (0.1448)  loss_objectness: 0.0793 (0.0986)  loss_rpn_box_reg: 0.0130 (0.0352)  time: 0.2709  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [27]  [ 450/1229]  eta: 0:03:32  lr: 0.000000  loss: 0.3324 (0.4350)  loss_classifier: 0.1126 (0.1556)  loss_box_reg: 0.1223 (0.1454)  loss_objectness: 0.0793 (0.0989)  loss_rpn_box_reg: 0.0220 (0.0351)  time: 0.2769  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [27]  [ 460/1229]  eta: 0:03:30  lr: 0.000000  loss: 0.3324 (0.4340)  loss_classifier: 0.1353 (0.1553)  loss_box_reg: 0.1267 (0.1454)  loss_objectness: 0.0788 (0.0984)  loss_rpn_box_reg: 0.0220 (0.0349)  time: 0.2793  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [27]  [ 470/1229]  eta: 0:03:27  lr: 0.000000  loss: 0.3141 (0.4353)  loss_classifier: 0.1405 (0.1561)  loss_box_reg: 0.0995 (0.1456)  loss_objectness: 0.0838 (0.0986)  loss_rpn_box_reg: 0.0213 (0.0350)  time: 0.2799  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [27]  [ 480/1229]  eta: 0:03:24  lr: 0.000000  loss: 0.4075 (0.4369)  loss_classifier: 0.1487 (0.1568)  loss_box_reg: 0.1187 (0.1466)  loss_objectness: 0.0908 (0.0987)  loss_rpn_box_reg: 0.0211 (0.0348)  time: 0.2764  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [27]  [ 490/1229]  eta: 0:03:22  lr: 0.000000  loss: 0.3592 (0.4377)  loss_classifier: 0.1476 (0.1572)  loss_box_reg: 0.1271 (0.1469)  loss_objectness: 0.0969 (0.0989)  loss_rpn_box_reg: 0.0278 (0.0348)  time: 0.2738  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [27]  [ 500/1229]  eta: 0:03:19  lr: 0.000000  loss: 0.3579 (0.4380)  loss_classifier: 0.1379 (0.1573)  loss_box_reg: 0.0919 (0.1464)  loss_objectness: 0.1030 (0.0996)  loss_rpn_box_reg: 0.0302 (0.0347)  time: 0.2778  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [27]  [ 510/1229]  eta: 0:03:16  lr: 0.000000  loss: 0.3579 (0.4378)  loss_classifier: 0.1094 (0.1572)  loss_box_reg: 0.0903 (0.1463)  loss_objectness: 0.1030 (0.0995)  loss_rpn_box_reg: 0.0149 (0.0347)  time: 0.2775  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [27]  [ 520/1229]  eta: 0:03:14  lr: 0.000000  loss: 0.4169 (0.4375)  loss_classifier: 0.1428 (0.1571)  loss_box_reg: 0.1102 (0.1459)  loss_objectness: 0.0947 (0.0999)  loss_rpn_box_reg: 0.0250 (0.0347)  time: 0.2755  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [27]  [ 530/1229]  eta: 0:03:11  lr: 0.000000  loss: 0.3753 (0.4376)  loss_classifier: 0.1428 (0.1571)  loss_box_reg: 0.1135 (0.1461)  loss_objectness: 0.0908 (0.0999)  loss_rpn_box_reg: 0.0232 (0.0345)  time: 0.2742  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [27]  [ 540/1229]  eta: 0:03:08  lr: 0.000000  loss: 0.3753 (0.4375)  loss_classifier: 0.1320 (0.1570)  loss_box_reg: 0.1201 (0.1459)  loss_objectness: 0.0908 (0.1000)  loss_rpn_box_reg: 0.0185 (0.0346)  time: 0.2730  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [27]  [ 550/1229]  eta: 0:03:05  lr: 0.000000  loss: 0.4016 (0.4382)  loss_classifier: 0.1429 (0.1572)  loss_box_reg: 0.1283 (0.1464)  loss_objectness: 0.0847 (0.1000)  loss_rpn_box_reg: 0.0232 (0.0345)  time: 0.2760  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [27]  [ 560/1229]  eta: 0:03:03  lr: 0.000000  loss: 0.4232 (0.4382)  loss_classifier: 0.1429 (0.1572)  loss_box_reg: 0.1317 (0.1462)  loss_objectness: 0.0762 (0.1002)  loss_rpn_box_reg: 0.0247 (0.0346)  time: 0.2774  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [27]  [ 570/1229]  eta: 0:03:00  lr: 0.000000  loss: 0.4188 (0.4384)  loss_classifier: 0.1454 (0.1573)  loss_box_reg: 0.1204 (0.1461)  loss_objectness: 0.1069 (0.1004)  loss_rpn_box_reg: 0.0243 (0.0346)  time: 0.2812  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [27]  [ 580/1229]  eta: 0:02:57  lr: 0.000000  loss: 0.3687 (0.4377)  loss_classifier: 0.1290 (0.1570)  loss_box_reg: 0.1076 (0.1453)  loss_objectness: 0.1079 (0.1009)  loss_rpn_box_reg: 0.0223 (0.0345)  time: 0.2803  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [27]  [ 590/1229]  eta: 0:02:55  lr: 0.000000  loss: 0.3499 (0.4364)  loss_classifier: 0.1234 (0.1564)  loss_box_reg: 0.0989 (0.1452)  loss_objectness: 0.0886 (0.1004)  loss_rpn_box_reg: 0.0148 (0.0344)  time: 0.2799  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [27]  [ 600/1229]  eta: 0:02:52  lr: 0.000000  loss: 0.3736 (0.4384)  loss_classifier: 0.1243 (0.1571)  loss_box_reg: 0.1324 (0.1459)  loss_objectness: 0.0758 (0.1008)  loss_rpn_box_reg: 0.0247 (0.0345)  time: 0.2776  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [27]  [ 610/1229]  eta: 0:02:49  lr: 0.000000  loss: 0.3384 (0.4363)  loss_classifier: 0.1184 (0.1564)  loss_box_reg: 0.1094 (0.1454)  loss_objectness: 0.0927 (0.1004)  loss_rpn_box_reg: 0.0174 (0.0342)  time: 0.2690  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [27]  [ 620/1229]  eta: 0:02:46  lr: 0.000000  loss: 0.3384 (0.4372)  loss_classifier: 0.1155 (0.1565)  loss_box_reg: 0.0959 (0.1456)  loss_objectness: 0.0951 (0.1008)  loss_rpn_box_reg: 0.0174 (0.0342)  time: 0.2673  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [27]  [ 630/1229]  eta: 0:02:43  lr: 0.000000  loss: 0.4479 (0.4371)  loss_classifier: 0.1483 (0.1566)  loss_box_reg: 0.1254 (0.1458)  loss_objectness: 0.1072 (0.1007)  loss_rpn_box_reg: 0.0246 (0.0340)  time: 0.2663  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [27]  [ 640/1229]  eta: 0:02:41  lr: 0.000000  loss: 0.3976 (0.4367)  loss_classifier: 0.1412 (0.1563)  loss_box_reg: 0.1415 (0.1457)  loss_objectness: 0.0829 (0.1006)  loss_rpn_box_reg: 0.0220 (0.0341)  time: 0.2680  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [27]  [ 650/1229]  eta: 0:02:38  lr: 0.000000  loss: 0.4153 (0.4377)  loss_classifier: 0.1378 (0.1568)  loss_box_reg: 0.1578 (0.1463)  loss_objectness: 0.0825 (0.1006)  loss_rpn_box_reg: 0.0297 (0.0342)  time: 0.2721  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [27]  [ 660/1229]  eta: 0:02:35  lr: 0.000000  loss: 0.3462 (0.4364)  loss_classifier: 0.1301 (0.1563)  loss_box_reg: 0.1003 (0.1456)  loss_objectness: 0.0825 (0.1005)  loss_rpn_box_reg: 0.0273 (0.0339)  time: 0.2772  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [27]  [ 670/1229]  eta: 0:02:33  lr: 0.000000  loss: 0.3420 (0.4367)  loss_classifier: 0.1083 (0.1563)  loss_box_reg: 0.0851 (0.1456)  loss_objectness: 0.0893 (0.1008)  loss_rpn_box_reg: 0.0216 (0.0340)  time: 0.2754  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [27]  [ 680/1229]  eta: 0:02:30  lr: 0.000000  loss: 0.3995 (0.4360)  loss_classifier: 0.1364 (0.1560)  loss_box_reg: 0.1327 (0.1454)  loss_objectness: 0.0965 (0.1006)  loss_rpn_box_reg: 0.0216 (0.0340)  time: 0.2703  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [27]  [ 690/1229]  eta: 0:02:27  lr: 0.000000  loss: 0.3921 (0.4351)  loss_classifier: 0.1296 (0.1557)  loss_box_reg: 0.1150 (0.1451)  loss_objectness: 0.0739 (0.1004)  loss_rpn_box_reg: 0.0177 (0.0338)  time: 0.2690  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [27]  [ 700/1229]  eta: 0:02:24  lr: 0.000000  loss: 0.3921 (0.4355)  loss_classifier: 0.1278 (0.1557)  loss_box_reg: 0.1228 (0.1454)  loss_objectness: 0.0848 (0.1004)  loss_rpn_box_reg: 0.0129 (0.0340)  time: 0.2696  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [27]  [ 710/1229]  eta: 0:02:21  lr: 0.000000  loss: 0.4358 (0.4363)  loss_classifier: 0.1604 (0.1561)  loss_box_reg: 0.1448 (0.1457)  loss_objectness: 0.0960 (0.1006)  loss_rpn_box_reg: 0.0207 (0.0340)  time: 0.2704  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [27]  [ 720/1229]  eta: 0:02:19  lr: 0.000000  loss: 0.3973 (0.4357)  loss_classifier: 0.1583 (0.1558)  loss_box_reg: 0.1394 (0.1454)  loss_objectness: 0.0858 (0.1004)  loss_rpn_box_reg: 0.0224 (0.0340)  time: 0.2682  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [27]  [ 730/1229]  eta: 0:02:16  lr: 0.000000  loss: 0.4162 (0.4370)  loss_classifier: 0.1583 (0.1564)  loss_box_reg: 0.1366 (0.1458)  loss_objectness: 0.1010 (0.1008)  loss_rpn_box_reg: 0.0239 (0.0340)  time: 0.2730  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [27]  [ 740/1229]  eta: 0:02:13  lr: 0.000000  loss: 0.5677 (0.4387)  loss_classifier: 0.2244 (0.1570)  loss_box_reg: 0.1770 (0.1465)  loss_objectness: 0.1190 (0.1011)  loss_rpn_box_reg: 0.0254 (0.0341)  time: 0.2789  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [27]  [ 750/1229]  eta: 0:02:11  lr: 0.000000  loss: 0.4532 (0.4390)  loss_classifier: 0.1703 (0.1571)  loss_box_reg: 0.1584 (0.1466)  loss_objectness: 0.1089 (0.1013)  loss_rpn_box_reg: 0.0173 (0.0340)  time: 0.2743  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [27]  [ 760/1229]  eta: 0:02:08  lr: 0.000000  loss: 0.3873 (0.4383)  loss_classifier: 0.1382 (0.1568)  loss_box_reg: 0.0941 (0.1463)  loss_objectness: 0.0953 (0.1012)  loss_rpn_box_reg: 0.0184 (0.0341)  time: 0.2729  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [27]  [ 770/1229]  eta: 0:02:05  lr: 0.000000  loss: 0.3450 (0.4379)  loss_classifier: 0.1309 (0.1566)  loss_box_reg: 0.1113 (0.1461)  loss_objectness: 0.0710 (0.1010)  loss_rpn_box_reg: 0.0305 (0.0342)  time: 0.2693  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [27]  [ 780/1229]  eta: 0:02:02  lr: 0.000000  loss: 0.3192 (0.4370)  loss_classifier: 0.1096 (0.1563)  loss_box_reg: 0.1041 (0.1459)  loss_objectness: 0.0710 (0.1008)  loss_rpn_box_reg: 0.0203 (0.0341)  time: 0.2705  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [27]  [ 790/1229]  eta: 0:02:00  lr: 0.000000  loss: 0.3818 (0.4377)  loss_classifier: 0.1416 (0.1567)  loss_box_reg: 0.1109 (0.1462)  loss_objectness: 0.0931 (0.1007)  loss_rpn_box_reg: 0.0203 (0.0342)  time: 0.2781  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [27]  [ 800/1229]  eta: 0:01:57  lr: 0.000000  loss: 0.4142 (0.4368)  loss_classifier: 0.1600 (0.1563)  loss_box_reg: 0.1188 (0.1458)  loss_objectness: 0.0958 (0.1005)  loss_rpn_box_reg: 0.0196 (0.0342)  time: 0.2786  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [27]  [ 810/1229]  eta: 0:01:54  lr: 0.000000  loss: 0.3875 (0.4369)  loss_classifier: 0.1378 (0.1564)  loss_box_reg: 0.0953 (0.1458)  loss_objectness: 0.0965 (0.1007)  loss_rpn_box_reg: 0.0163 (0.0340)  time: 0.2764  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [27]  [ 820/1229]  eta: 0:01:51  lr: 0.000000  loss: 0.3592 (0.4362)  loss_classifier: 0.1226 (0.1560)  loss_box_reg: 0.0929 (0.1456)  loss_objectness: 0.0877 (0.1005)  loss_rpn_box_reg: 0.0255 (0.0342)  time: 0.2706  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [27]  [ 830/1229]  eta: 0:01:49  lr: 0.000000  loss: 0.3374 (0.4358)  loss_classifier: 0.1029 (0.1558)  loss_box_reg: 0.1161 (0.1457)  loss_objectness: 0.0636 (0.1003)  loss_rpn_box_reg: 0.0255 (0.0340)  time: 0.2700  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [27]  [ 840/1229]  eta: 0:01:46  lr: 0.000000  loss: 0.3841 (0.4371)  loss_classifier: 0.1559 (0.1563)  loss_box_reg: 0.1471 (0.1464)  loss_objectness: 0.0777 (0.1003)  loss_rpn_box_reg: 0.0232 (0.0340)  time: 0.2780  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [27]  [ 850/1229]  eta: 0:01:43  lr: 0.000000  loss: 0.3600 (0.4355)  loss_classifier: 0.1263 (0.1557)  loss_box_reg: 0.1195 (0.1459)  loss_objectness: 0.0753 (0.1000)  loss_rpn_box_reg: 0.0249 (0.0339)  time: 0.2822  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [27]  [ 860/1229]  eta: 0:01:41  lr: 0.000000  loss: 0.2579 (0.4345)  loss_classifier: 0.0999 (0.1555)  loss_box_reg: 0.0908 (0.1455)  loss_objectness: 0.0698 (0.0998)  loss_rpn_box_reg: 0.0173 (0.0338)  time: 0.2812  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [27]  [ 870/1229]  eta: 0:01:38  lr: 0.000000  loss: 0.2875 (0.4338)  loss_classifier: 0.1128 (0.1552)  loss_box_reg: 0.1016 (0.1453)  loss_objectness: 0.0699 (0.0996)  loss_rpn_box_reg: 0.0148 (0.0337)  time: 0.2752  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [27]  [ 880/1229]  eta: 0:01:35  lr: 0.000000  loss: 0.3716 (0.4337)  loss_classifier: 0.1317 (0.1550)  loss_box_reg: 0.1148 (0.1451)  loss_objectness: 0.0699 (0.0995)  loss_rpn_box_reg: 0.0235 (0.0341)  time: 0.2734  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [27]  [ 890/1229]  eta: 0:01:32  lr: 0.000000  loss: 0.4110 (0.4345)  loss_classifier: 0.1333 (0.1552)  loss_box_reg: 0.1301 (0.1454)  loss_objectness: 0.0838 (0.0997)  loss_rpn_box_reg: 0.0348 (0.0343)  time: 0.2790  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [27]  [ 900/1229]  eta: 0:01:30  lr: 0.000000  loss: 0.3324 (0.4335)  loss_classifier: 0.1210 (0.1548)  loss_box_reg: 0.1078 (0.1449)  loss_objectness: 0.0799 (0.0998)  loss_rpn_box_reg: 0.0210 (0.0341)  time: 0.2824  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [27]  [ 910/1229]  eta: 0:01:27  lr: 0.000000  loss: 0.2916 (0.4339)  loss_classifier: 0.1154 (0.1549)  loss_box_reg: 0.0948 (0.1449)  loss_objectness: 0.0716 (0.1000)  loss_rpn_box_reg: 0.0168 (0.0342)  time: 0.2778  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [27]  [ 920/1229]  eta: 0:01:24  lr: 0.000000  loss: 0.3543 (0.4333)  loss_classifier: 0.1306 (0.1548)  loss_box_reg: 0.0984 (0.1446)  loss_objectness: 0.0779 (0.0999)  loss_rpn_box_reg: 0.0185 (0.0341)  time: 0.2766  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [27]  [ 930/1229]  eta: 0:01:21  lr: 0.000000  loss: 0.3488 (0.4337)  loss_classifier: 0.1273 (0.1548)  loss_box_reg: 0.0984 (0.1448)  loss_objectness: 0.0711 (0.0998)  loss_rpn_box_reg: 0.0185 (0.0343)  time: 0.2763  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [27]  [ 940/1229]  eta: 0:01:19  lr: 0.000000  loss: 0.3260 (0.4337)  loss_classifier: 0.1144 (0.1547)  loss_box_reg: 0.1226 (0.1449)  loss_objectness: 0.0935 (0.0999)  loss_rpn_box_reg: 0.0165 (0.0342)  time: 0.2762  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [27]  [ 950/1229]  eta: 0:01:16  lr: 0.000000  loss: 0.3604 (0.4341)  loss_classifier: 0.1281 (0.1549)  loss_box_reg: 0.1182 (0.1451)  loss_objectness: 0.0989 (0.1000)  loss_rpn_box_reg: 0.0165 (0.0343)  time: 0.2735  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [27]  [ 960/1229]  eta: 0:01:13  lr: 0.000000  loss: 0.4576 (0.4348)  loss_classifier: 0.1594 (0.1551)  loss_box_reg: 0.1442 (0.1453)  loss_objectness: 0.1037 (0.1003)  loss_rpn_box_reg: 0.0255 (0.0342)  time: 0.2689  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [27]  [ 970/1229]  eta: 0:01:10  lr: 0.000000  loss: 0.4386 (0.4349)  loss_classifier: 0.1611 (0.1552)  loss_box_reg: 0.1334 (0.1453)  loss_objectness: 0.0998 (0.1002)  loss_rpn_box_reg: 0.0352 (0.0343)  time: 0.2680  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [27]  [ 980/1229]  eta: 0:01:08  lr: 0.000000  loss: 0.4105 (0.4348)  loss_classifier: 0.1373 (0.1551)  loss_box_reg: 0.1243 (0.1453)  loss_objectness: 0.0756 (0.1001)  loss_rpn_box_reg: 0.0258 (0.0343)  time: 0.2632  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [27]  [ 990/1229]  eta: 0:01:05  lr: 0.000000  loss: 0.3901 (0.4338)  loss_classifier: 0.1250 (0.1547)  loss_box_reg: 0.1227 (0.1449)  loss_objectness: 0.0843 (0.1000)  loss_rpn_box_reg: 0.0245 (0.0342)  time: 0.2657  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [27]  [1000/1229]  eta: 0:01:02  lr: 0.000000  loss: 0.3748 (0.4335)  loss_classifier: 0.1192 (0.1545)  loss_box_reg: 0.1113 (0.1448)  loss_objectness: 0.0851 (0.1000)  loss_rpn_box_reg: 0.0193 (0.0343)  time: 0.2731  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [27]  [1010/1229]  eta: 0:00:59  lr: 0.000000  loss: 0.4906 (0.4345)  loss_classifier: 0.1571 (0.1547)  loss_box_reg: 0.1334 (0.1450)  loss_objectness: 0.1141 (0.1004)  loss_rpn_box_reg: 0.0240 (0.0344)  time: 0.2741  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [27]  [1020/1229]  eta: 0:00:57  lr: 0.000000  loss: 0.4906 (0.4348)  loss_classifier: 0.1417 (0.1547)  loss_box_reg: 0.1481 (0.1453)  loss_objectness: 0.1029 (0.1002)  loss_rpn_box_reg: 0.0416 (0.0346)  time: 0.2714  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [27]  [1030/1229]  eta: 0:00:54  lr: 0.000000  loss: 0.3885 (0.4341)  loss_classifier: 0.1350 (0.1545)  loss_box_reg: 0.1520 (0.1452)  loss_objectness: 0.0661 (0.1000)  loss_rpn_box_reg: 0.0215 (0.0344)  time: 0.2719  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [27]  [1040/1229]  eta: 0:00:51  lr: 0.000000  loss: 0.2961 (0.4332)  loss_classifier: 0.1174 (0.1543)  loss_box_reg: 0.1017 (0.1451)  loss_objectness: 0.0592 (0.0996)  loss_rpn_box_reg: 0.0130 (0.0343)  time: 0.2729  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [27]  [1050/1229]  eta: 0:00:48  lr: 0.000000  loss: 0.2961 (0.4332)  loss_classifier: 0.1191 (0.1542)  loss_box_reg: 0.1000 (0.1452)  loss_objectness: 0.0767 (0.0997)  loss_rpn_box_reg: 0.0130 (0.0341)  time: 0.2704  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [27]  [1060/1229]  eta: 0:00:46  lr: 0.000000  loss: 0.3955 (0.4339)  loss_classifier: 0.1461 (0.1544)  loss_box_reg: 0.1400 (0.1456)  loss_objectness: 0.0909 (0.0996)  loss_rpn_box_reg: 0.0173 (0.0342)  time: 0.2686  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [27]  [1070/1229]  eta: 0:00:43  lr: 0.000000  loss: 0.4188 (0.4336)  loss_classifier: 0.1342 (0.1543)  loss_box_reg: 0.1405 (0.1455)  loss_objectness: 0.0849 (0.0996)  loss_rpn_box_reg: 0.0239 (0.0342)  time: 0.2695  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [27]  [1080/1229]  eta: 0:00:40  lr: 0.000000  loss: 0.3686 (0.4329)  loss_classifier: 0.1324 (0.1540)  loss_box_reg: 0.1088 (0.1452)  loss_objectness: 0.0824 (0.0995)  loss_rpn_box_reg: 0.0196 (0.0341)  time: 0.2718  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [27]  [1090/1229]  eta: 0:00:38  lr: 0.000000  loss: 0.3899 (0.4339)  loss_classifier: 0.1482 (0.1544)  loss_box_reg: 0.0926 (0.1456)  loss_objectness: 0.0835 (0.0999)  loss_rpn_box_reg: 0.0239 (0.0340)  time: 0.2761  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [27]  [1100/1229]  eta: 0:00:35  lr: 0.000000  loss: 0.3968 (0.4331)  loss_classifier: 0.1324 (0.1541)  loss_box_reg: 0.1031 (0.1452)  loss_objectness: 0.0839 (0.0998)  loss_rpn_box_reg: 0.0239 (0.0340)  time: 0.2765  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [27]  [1110/1229]  eta: 0:00:32  lr: 0.000000  loss: 0.3727 (0.4337)  loss_classifier: 0.1221 (0.1543)  loss_box_reg: 0.1080 (0.1455)  loss_objectness: 0.0861 (0.0998)  loss_rpn_box_reg: 0.0238 (0.0341)  time: 0.2723  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [27]  [1120/1229]  eta: 0:00:29  lr: 0.000000  loss: 0.4310 (0.4335)  loss_classifier: 0.1503 (0.1543)  loss_box_reg: 0.1493 (0.1456)  loss_objectness: 0.0939 (0.0998)  loss_rpn_box_reg: 0.0231 (0.0339)  time: 0.2734  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [27]  [1130/1229]  eta: 0:00:27  lr: 0.000000  loss: 0.4223 (0.4339)  loss_classifier: 0.1503 (0.1544)  loss_box_reg: 0.1683 (0.1459)  loss_objectness: 0.0849 (0.0997)  loss_rpn_box_reg: 0.0229 (0.0339)  time: 0.2777  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [27]  [1140/1229]  eta: 0:00:24  lr: 0.000000  loss: 0.3829 (0.4335)  loss_classifier: 0.1534 (0.1544)  loss_box_reg: 0.1305 (0.1457)  loss_objectness: 0.0793 (0.0996)  loss_rpn_box_reg: 0.0256 (0.0339)  time: 0.2799  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [27]  [1150/1229]  eta: 0:00:21  lr: 0.000000  loss: 0.3792 (0.4333)  loss_classifier: 0.1472 (0.1543)  loss_box_reg: 0.1074 (0.1455)  loss_objectness: 0.0655 (0.0996)  loss_rpn_box_reg: 0.0236 (0.0340)  time: 0.2835  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [27]  [1160/1229]  eta: 0:00:18  lr: 0.000000  loss: 0.3433 (0.4330)  loss_classifier: 0.1385 (0.1542)  loss_box_reg: 0.1254 (0.1454)  loss_objectness: 0.0645 (0.0995)  loss_rpn_box_reg: 0.0148 (0.0340)  time: 0.2827  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [27]  [1170/1229]  eta: 0:00:16  lr: 0.000000  loss: 0.3349 (0.4328)  loss_classifier: 0.1126 (0.1541)  loss_box_reg: 0.1027 (0.1452)  loss_objectness: 0.0734 (0.0995)  loss_rpn_box_reg: 0.0161 (0.0340)  time: 0.2741  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [27]  [1180/1229]  eta: 0:00:13  lr: 0.000000  loss: 0.3560 (0.4323)  loss_classifier: 0.1143 (0.1539)  loss_box_reg: 0.1019 (0.1448)  loss_objectness: 0.0822 (0.0996)  loss_rpn_box_reg: 0.0156 (0.0339)  time: 0.2723  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [27]  [1190/1229]  eta: 0:00:10  lr: 0.000000  loss: 0.3560 (0.4323)  loss_classifier: 0.1216 (0.1539)  loss_box_reg: 0.1019 (0.1449)  loss_objectness: 0.0802 (0.0996)  loss_rpn_box_reg: 0.0147 (0.0338)  time: 0.2745  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [27]  [1200/1229]  eta: 0:00:07  lr: 0.000000  loss: 0.5219 (0.4340)  loss_classifier: 0.1881 (0.1545)  loss_box_reg: 0.2102 (0.1457)  loss_objectness: 0.0965 (0.1000)  loss_rpn_box_reg: 0.0275 (0.0338)  time: 0.2729  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [27]  [1210/1229]  eta: 0:00:05  lr: 0.000000  loss: 0.4608 (0.4334)  loss_classifier: 0.1394 (0.1542)  loss_box_reg: 0.1350 (0.1453)  loss_objectness: 0.1215 (0.1001)  loss_rpn_box_reg: 0.0159 (0.0338)  time: 0.2726  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [27]  [1220/1229]  eta: 0:00:02  lr: 0.000000  loss: 0.3821 (0.4335)  loss_classifier: 0.1224 (0.1541)  loss_box_reg: 0.1175 (0.1453)  loss_objectness: 0.0906 (0.1001)  loss_rpn_box_reg: 0.0223 (0.0340)  time: 0.2742  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [27]  [1228/1229]  eta: 0:00:00  lr: 0.000000  loss: 0.3486 (0.4328)  loss_classifier: 0.1272 (0.1539)  loss_box_reg: 0.1085 (0.1450)  loss_objectness: 0.0818 (0.0999)  loss_rpn_box_reg: 0.0224 (0.0339)  time: 0.2793  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [27] Total time: 0:05:36 (0.2740 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:28  model_time: 0.2540 (0.2540)  evaluator_time: 0.0020 (0.0020)  time: 0.2870  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0780 (0.0820)  evaluator_time: 0.0040 (0.0086)  time: 0.1267  data: 0.0354  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0840 (0.0809)  evaluator_time: 0.0030 (0.0078)  time: 0.1196  data: 0.0307  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0730 (0.0802)  evaluator_time: 0.0040 (0.0076)  time: 0.1192  data: 0.0348  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0730 (0.0801)  evaluator_time: 0.0030 (0.0076)  time: 0.1166  data: 0.0335  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1237 s / it)\n",
      "Averaged stats: model_time: 0.0730 (0.0801)  evaluator_time: 0.0030 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [27]  [  0/308]  eta: 0:00:37  lr: 0.000000  loss: 0.1650 (0.1650)  loss_classifier: 0.0587 (0.0587)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0263 (0.0263)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1210  data: 0.0280  max mem: 1751\n",
      "Testing Epoch: [27]  [100/308]  eta: 0:00:28  lr: 0.000000  loss: 0.3228 (0.4820)  loss_classifier: 0.1335 (0.1543)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0597 (0.1034)  loss_rpn_box_reg: 0.0186 (0.0519)  time: 0.1388  data: 0.0371  max mem: 1751\n",
      "Testing Epoch: [27]  [200/308]  eta: 0:00:14  lr: 0.000000  loss: 0.3493 (0.4578)  loss_classifier: 0.1387 (0.1490)  loss_box_reg: 0.1251 (0.1633)  loss_objectness: 0.0626 (0.0965)  loss_rpn_box_reg: 0.0197 (0.0491)  time: 0.1375  data: 0.0320  max mem: 1751\n",
      "Testing Epoch: [27]  [300/308]  eta: 0:00:01  lr: 0.000000  loss: 0.4697 (0.4541)  loss_classifier: 0.1573 (0.1493)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0770 (0.0932)  loss_rpn_box_reg: 0.0265 (0.0475)  time: 0.1325  data: 0.0369  max mem: 1751\n",
      "Testing Epoch: [27]  [307/308]  eta: 0:00:00  lr: 0.000000  loss: 0.4490 (0.4544)  loss_classifier: 0.1860 (0.1495)  loss_box_reg: 0.1748 (0.1645)  loss_objectness: 0.0666 (0.0934)  loss_rpn_box_reg: 0.0271 (0.0470)  time: 0.1371  data: 0.0406  max mem: 1751\n",
      "Testing Epoch: [27] Total time: 0:00:42 (0.1376 s / it)\n",
      "Training Epoch: [28]  [   0/1229]  eta: 0:06:29  lr: 0.000000  loss: 0.5467 (0.5467)  loss_classifier: 0.2174 (0.2174)  loss_box_reg: 0.2189 (0.2189)  loss_objectness: 0.0908 (0.0908)  loss_rpn_box_reg: 0.0196 (0.0196)  time: 0.3170  data: 0.1200  max mem: 1751\n",
      "Training Epoch: [28]  [  10/1229]  eta: 0:05:36  lr: 0.000000  loss: 0.3992 (0.5206)  loss_classifier: 0.1450 (0.1751)  loss_box_reg: 0.1260 (0.1768)  loss_objectness: 0.0992 (0.1175)  loss_rpn_box_reg: 0.0160 (0.0512)  time: 0.2758  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [28]  [  20/1229]  eta: 0:05:30  lr: 0.000000  loss: 0.3659 (0.4402)  loss_classifier: 0.1313 (0.1549)  loss_box_reg: 0.1209 (0.1514)  loss_objectness: 0.0748 (0.1005)  loss_rpn_box_reg: 0.0145 (0.0335)  time: 0.2715  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [28]  [  30/1229]  eta: 0:05:28  lr: 0.000000  loss: 0.3711 (0.4415)  loss_classifier: 0.1338 (0.1572)  loss_box_reg: 0.1287 (0.1546)  loss_objectness: 0.0793 (0.0985)  loss_rpn_box_reg: 0.0162 (0.0312)  time: 0.2726  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [28]  [  40/1229]  eta: 0:05:24  lr: 0.000000  loss: 0.4112 (0.4475)  loss_classifier: 0.1526 (0.1556)  loss_box_reg: 0.1362 (0.1534)  loss_objectness: 0.0999 (0.1005)  loss_rpn_box_reg: 0.0190 (0.0380)  time: 0.2720  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [28]  [  50/1229]  eta: 0:05:20  lr: 0.000000  loss: 0.2892 (0.4297)  loss_classifier: 0.1179 (0.1511)  loss_box_reg: 0.0912 (0.1466)  loss_objectness: 0.0797 (0.0975)  loss_rpn_box_reg: 0.0125 (0.0346)  time: 0.2692  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [28]  [  60/1229]  eta: 0:05:19  lr: 0.000000  loss: 0.2650 (0.4216)  loss_classifier: 0.1066 (0.1485)  loss_box_reg: 0.0862 (0.1434)  loss_objectness: 0.0639 (0.0945)  loss_rpn_box_reg: 0.0129 (0.0352)  time: 0.2738  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [28]  [  70/1229]  eta: 0:05:16  lr: 0.000000  loss: 0.3235 (0.4239)  loss_classifier: 0.1191 (0.1495)  loss_box_reg: 0.1082 (0.1476)  loss_objectness: 0.0695 (0.0930)  loss_rpn_box_reg: 0.0167 (0.0338)  time: 0.2761  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [28]  [  80/1229]  eta: 0:05:14  lr: 0.000000  loss: 0.4312 (0.4267)  loss_classifier: 0.1697 (0.1518)  loss_box_reg: 0.1252 (0.1472)  loss_objectness: 0.0784 (0.0939)  loss_rpn_box_reg: 0.0285 (0.0338)  time: 0.2757  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [28]  [  90/1229]  eta: 0:05:12  lr: 0.000000  loss: 0.2972 (0.4080)  loss_classifier: 0.1300 (0.1455)  loss_box_reg: 0.1043 (0.1387)  loss_objectness: 0.0764 (0.0915)  loss_rpn_box_reg: 0.0161 (0.0323)  time: 0.2775  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [28]  [ 100/1229]  eta: 0:05:10  lr: 0.000000  loss: 0.2672 (0.4106)  loss_classifier: 0.1049 (0.1473)  loss_box_reg: 0.0737 (0.1385)  loss_objectness: 0.0774 (0.0928)  loss_rpn_box_reg: 0.0162 (0.0319)  time: 0.2802  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [28]  [ 110/1229]  eta: 0:05:07  lr: 0.000000  loss: 0.3487 (0.4191)  loss_classifier: 0.1278 (0.1503)  loss_box_reg: 0.1349 (0.1420)  loss_objectness: 0.0988 (0.0947)  loss_rpn_box_reg: 0.0185 (0.0320)  time: 0.2768  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [28]  [ 120/1229]  eta: 0:05:04  lr: 0.000000  loss: 0.4629 (0.4224)  loss_classifier: 0.1727 (0.1509)  loss_box_reg: 0.1455 (0.1438)  loss_objectness: 0.0813 (0.0948)  loss_rpn_box_reg: 0.0122 (0.0329)  time: 0.2721  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [28]  [ 130/1229]  eta: 0:05:01  lr: 0.000000  loss: 0.4110 (0.4233)  loss_classifier: 0.1613 (0.1514)  loss_box_reg: 0.1021 (0.1428)  loss_objectness: 0.0808 (0.0962)  loss_rpn_box_reg: 0.0243 (0.0328)  time: 0.2730  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [28]  [ 140/1229]  eta: 0:04:59  lr: 0.000000  loss: 0.3488 (0.4190)  loss_classifier: 0.1168 (0.1499)  loss_box_reg: 0.0975 (0.1420)  loss_objectness: 0.0740 (0.0951)  loss_rpn_box_reg: 0.0239 (0.0319)  time: 0.2754  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [28]  [ 150/1229]  eta: 0:04:56  lr: 0.000000  loss: 0.3577 (0.4265)  loss_classifier: 0.1168 (0.1519)  loss_box_reg: 0.1069 (0.1438)  loss_objectness: 0.1075 (0.0984)  loss_rpn_box_reg: 0.0239 (0.0325)  time: 0.2771  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [28]  [ 160/1229]  eta: 0:04:53  lr: 0.000000  loss: 0.4684 (0.4300)  loss_classifier: 0.1821 (0.1531)  loss_box_reg: 0.1569 (0.1466)  loss_objectness: 0.1075 (0.0985)  loss_rpn_box_reg: 0.0243 (0.0318)  time: 0.2727  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [28]  [ 170/1229]  eta: 0:04:50  lr: 0.000000  loss: 0.4984 (0.4396)  loss_classifier: 0.1930 (0.1570)  loss_box_reg: 0.1746 (0.1496)  loss_objectness: 0.0961 (0.1001)  loss_rpn_box_reg: 0.0260 (0.0329)  time: 0.2740  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [28]  [ 180/1229]  eta: 0:04:48  lr: 0.000000  loss: 0.4403 (0.4352)  loss_classifier: 0.1592 (0.1564)  loss_box_reg: 0.1604 (0.1494)  loss_objectness: 0.0702 (0.0976)  loss_rpn_box_reg: 0.0233 (0.0318)  time: 0.2802  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [28]  [ 190/1229]  eta: 0:04:46  lr: 0.000000  loss: 0.3646 (0.4366)  loss_classifier: 0.1312 (0.1569)  loss_box_reg: 0.1220 (0.1495)  loss_objectness: 0.0664 (0.0979)  loss_rpn_box_reg: 0.0153 (0.0322)  time: 0.2808  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [28]  [ 200/1229]  eta: 0:04:43  lr: 0.000000  loss: 0.3450 (0.4330)  loss_classifier: 0.1389 (0.1558)  loss_box_reg: 0.0925 (0.1468)  loss_objectness: 0.0944 (0.0982)  loss_rpn_box_reg: 0.0177 (0.0323)  time: 0.2801  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [28]  [ 210/1229]  eta: 0:04:40  lr: 0.000000  loss: 0.3450 (0.4311)  loss_classifier: 0.1193 (0.1549)  loss_box_reg: 0.0970 (0.1462)  loss_objectness: 0.0806 (0.0971)  loss_rpn_box_reg: 0.0177 (0.0328)  time: 0.2775  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [28]  [ 220/1229]  eta: 0:04:38  lr: 0.000000  loss: 0.3614 (0.4340)  loss_classifier: 0.1188 (0.1552)  loss_box_reg: 0.1087 (0.1457)  loss_objectness: 0.0806 (0.0993)  loss_rpn_box_reg: 0.0274 (0.0339)  time: 0.2783  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [28]  [ 230/1229]  eta: 0:04:35  lr: 0.000000  loss: 0.3583 (0.4301)  loss_classifier: 0.1085 (0.1537)  loss_box_reg: 0.1006 (0.1448)  loss_objectness: 0.0774 (0.0982)  loss_rpn_box_reg: 0.0239 (0.0334)  time: 0.2744  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [28]  [ 240/1229]  eta: 0:04:32  lr: 0.000000  loss: 0.2832 (0.4277)  loss_classifier: 0.1017 (0.1525)  loss_box_reg: 0.0895 (0.1429)  loss_objectness: 0.0725 (0.0982)  loss_rpn_box_reg: 0.0170 (0.0341)  time: 0.2715  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [28]  [ 250/1229]  eta: 0:04:29  lr: 0.000000  loss: 0.3726 (0.4290)  loss_classifier: 0.1189 (0.1527)  loss_box_reg: 0.0895 (0.1429)  loss_objectness: 0.0795 (0.0983)  loss_rpn_box_reg: 0.0263 (0.0351)  time: 0.2715  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [28]  [ 260/1229]  eta: 0:04:26  lr: 0.000000  loss: 0.4681 (0.4331)  loss_classifier: 0.1478 (0.1541)  loss_box_reg: 0.1298 (0.1443)  loss_objectness: 0.1021 (0.0991)  loss_rpn_box_reg: 0.0282 (0.0357)  time: 0.2742  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [28]  [ 270/1229]  eta: 0:04:24  lr: 0.000000  loss: 0.4266 (0.4312)  loss_classifier: 0.1478 (0.1534)  loss_box_reg: 0.1287 (0.1440)  loss_objectness: 0.0954 (0.0984)  loss_rpn_box_reg: 0.0147 (0.0354)  time: 0.2788  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [28]  [ 280/1229]  eta: 0:04:21  lr: 0.000000  loss: 0.3859 (0.4347)  loss_classifier: 0.1394 (0.1545)  loss_box_reg: 0.1396 (0.1459)  loss_objectness: 0.0816 (0.0985)  loss_rpn_box_reg: 0.0237 (0.0358)  time: 0.2772  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [28]  [ 290/1229]  eta: 0:04:18  lr: 0.000000  loss: 0.3770 (0.4315)  loss_classifier: 0.1394 (0.1535)  loss_box_reg: 0.1396 (0.1450)  loss_objectness: 0.0816 (0.0978)  loss_rpn_box_reg: 0.0237 (0.0352)  time: 0.2777  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [28]  [ 300/1229]  eta: 0:04:15  lr: 0.000000  loss: 0.3139 (0.4296)  loss_classifier: 0.0982 (0.1523)  loss_box_reg: 0.1007 (0.1433)  loss_objectness: 0.0790 (0.0979)  loss_rpn_box_reg: 0.0159 (0.0362)  time: 0.2741  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [28]  [ 310/1229]  eta: 0:04:13  lr: 0.000000  loss: 0.2924 (0.4300)  loss_classifier: 0.0982 (0.1527)  loss_box_reg: 0.0969 (0.1439)  loss_objectness: 0.0806 (0.0973)  loss_rpn_box_reg: 0.0252 (0.0361)  time: 0.2779  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [28]  [ 320/1229]  eta: 0:04:10  lr: 0.000000  loss: 0.4726 (0.4350)  loss_classifier: 0.1758 (0.1543)  loss_box_reg: 0.1522 (0.1460)  loss_objectness: 0.0956 (0.0986)  loss_rpn_box_reg: 0.0201 (0.0361)  time: 0.2746  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [28]  [ 330/1229]  eta: 0:04:07  lr: 0.000000  loss: 0.3785 (0.4319)  loss_classifier: 0.1343 (0.1529)  loss_box_reg: 0.1431 (0.1447)  loss_objectness: 0.0966 (0.0984)  loss_rpn_box_reg: 0.0185 (0.0358)  time: 0.2642  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [28]  [ 340/1229]  eta: 0:04:04  lr: 0.000000  loss: 0.3367 (0.4306)  loss_classifier: 0.1050 (0.1526)  loss_box_reg: 0.0859 (0.1444)  loss_objectness: 0.0798 (0.0981)  loss_rpn_box_reg: 0.0172 (0.0355)  time: 0.2738  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [28]  [ 350/1229]  eta: 0:04:01  lr: 0.000000  loss: 0.3328 (0.4289)  loss_classifier: 0.1345 (0.1519)  loss_box_reg: 0.1061 (0.1436)  loss_objectness: 0.0698 (0.0979)  loss_rpn_box_reg: 0.0166 (0.0354)  time: 0.2788  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [28]  [ 360/1229]  eta: 0:03:59  lr: 0.000000  loss: 0.3622 (0.4324)  loss_classifier: 0.1345 (0.1529)  loss_box_reg: 0.1128 (0.1451)  loss_objectness: 0.1164 (0.0987)  loss_rpn_box_reg: 0.0228 (0.0356)  time: 0.2738  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [28]  [ 370/1229]  eta: 0:03:56  lr: 0.000000  loss: 0.3622 (0.4310)  loss_classifier: 0.1248 (0.1524)  loss_box_reg: 0.1333 (0.1446)  loss_objectness: 0.0842 (0.0981)  loss_rpn_box_reg: 0.0210 (0.0358)  time: 0.2685  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [28]  [ 380/1229]  eta: 0:03:53  lr: 0.000000  loss: 0.3969 (0.4307)  loss_classifier: 0.1553 (0.1526)  loss_box_reg: 0.1153 (0.1445)  loss_objectness: 0.0761 (0.0979)  loss_rpn_box_reg: 0.0163 (0.0356)  time: 0.2661  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [28]  [ 390/1229]  eta: 0:03:50  lr: 0.000000  loss: 0.4729 (0.4321)  loss_classifier: 0.1622 (0.1533)  loss_box_reg: 0.1616 (0.1454)  loss_objectness: 0.0887 (0.0979)  loss_rpn_box_reg: 0.0215 (0.0354)  time: 0.2758  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [28]  [ 400/1229]  eta: 0:03:48  lr: 0.000000  loss: 0.4729 (0.4334)  loss_classifier: 0.1758 (0.1539)  loss_box_reg: 0.1616 (0.1460)  loss_objectness: 0.0915 (0.0981)  loss_rpn_box_reg: 0.0244 (0.0353)  time: 0.2826  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [28]  [ 410/1229]  eta: 0:03:45  lr: 0.000000  loss: 0.4728 (0.4341)  loss_classifier: 0.1760 (0.1540)  loss_box_reg: 0.1713 (0.1468)  loss_objectness: 0.0915 (0.0980)  loss_rpn_box_reg: 0.0277 (0.0353)  time: 0.2768  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [28]  [ 420/1229]  eta: 0:03:42  lr: 0.000000  loss: 0.4331 (0.4318)  loss_classifier: 0.1357 (0.1532)  loss_box_reg: 0.1500 (0.1460)  loss_objectness: 0.0666 (0.0977)  loss_rpn_box_reg: 0.0151 (0.0349)  time: 0.2714  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [28]  [ 430/1229]  eta: 0:03:39  lr: 0.000000  loss: 0.4331 (0.4325)  loss_classifier: 0.1477 (0.1537)  loss_box_reg: 0.1248 (0.1458)  loss_objectness: 0.0992 (0.0983)  loss_rpn_box_reg: 0.0151 (0.0347)  time: 0.2683  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [28]  [ 440/1229]  eta: 0:03:36  lr: 0.000000  loss: 0.4552 (0.4323)  loss_classifier: 0.1752 (0.1539)  loss_box_reg: 0.1121 (0.1457)  loss_objectness: 0.1154 (0.0981)  loss_rpn_box_reg: 0.0182 (0.0346)  time: 0.2702  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [28]  [ 450/1229]  eta: 0:03:33  lr: 0.000000  loss: 0.4648 (0.4336)  loss_classifier: 0.1556 (0.1544)  loss_box_reg: 0.1216 (0.1457)  loss_objectness: 0.0979 (0.0986)  loss_rpn_box_reg: 0.0188 (0.0349)  time: 0.2747  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [28]  [ 460/1229]  eta: 0:03:30  lr: 0.000000  loss: 0.4338 (0.4323)  loss_classifier: 0.1448 (0.1538)  loss_box_reg: 0.1241 (0.1448)  loss_objectness: 0.0983 (0.0988)  loss_rpn_box_reg: 0.0314 (0.0348)  time: 0.2666  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [28]  [ 470/1229]  eta: 0:03:28  lr: 0.000000  loss: 0.3576 (0.4317)  loss_classifier: 0.1283 (0.1537)  loss_box_reg: 0.1198 (0.1447)  loss_objectness: 0.0983 (0.0988)  loss_rpn_box_reg: 0.0177 (0.0346)  time: 0.2669  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [28]  [ 480/1229]  eta: 0:03:25  lr: 0.000000  loss: 0.3576 (0.4318)  loss_classifier: 0.1399 (0.1534)  loss_box_reg: 0.1130 (0.1442)  loss_objectness: 0.0735 (0.0988)  loss_rpn_box_reg: 0.0179 (0.0354)  time: 0.2734  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [28]  [ 490/1229]  eta: 0:03:22  lr: 0.000000  loss: 0.3586 (0.4330)  loss_classifier: 0.1322 (0.1539)  loss_box_reg: 0.1174 (0.1449)  loss_objectness: 0.0722 (0.0987)  loss_rpn_box_reg: 0.0268 (0.0355)  time: 0.2733  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [28]  [ 500/1229]  eta: 0:03:19  lr: 0.000000  loss: 0.4227 (0.4336)  loss_classifier: 0.1400 (0.1542)  loss_box_reg: 0.1222 (0.1452)  loss_objectness: 0.0997 (0.0989)  loss_rpn_box_reg: 0.0300 (0.0354)  time: 0.2709  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [28]  [ 510/1229]  eta: 0:03:17  lr: 0.000000  loss: 0.4027 (0.4317)  loss_classifier: 0.1250 (0.1536)  loss_box_reg: 0.1222 (0.1445)  loss_objectness: 0.0840 (0.0985)  loss_rpn_box_reg: 0.0229 (0.0352)  time: 0.2680  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [28]  [ 520/1229]  eta: 0:03:14  lr: 0.000000  loss: 0.3911 (0.4322)  loss_classifier: 0.1250 (0.1538)  loss_box_reg: 0.1292 (0.1449)  loss_objectness: 0.0661 (0.0983)  loss_rpn_box_reg: 0.0211 (0.0352)  time: 0.2693  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [28]  [ 530/1229]  eta: 0:03:11  lr: 0.000000  loss: 0.3911 (0.4331)  loss_classifier: 0.1288 (0.1543)  loss_box_reg: 0.1509 (0.1455)  loss_objectness: 0.0661 (0.0984)  loss_rpn_box_reg: 0.0229 (0.0350)  time: 0.2708  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [28]  [ 540/1229]  eta: 0:03:08  lr: 0.000000  loss: 0.3077 (0.4313)  loss_classifier: 0.1239 (0.1535)  loss_box_reg: 0.1119 (0.1450)  loss_objectness: 0.0912 (0.0982)  loss_rpn_box_reg: 0.0128 (0.0346)  time: 0.2745  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [28]  [ 550/1229]  eta: 0:03:06  lr: 0.000000  loss: 0.3259 (0.4312)  loss_classifier: 0.1208 (0.1534)  loss_box_reg: 0.1054 (0.1447)  loss_objectness: 0.0913 (0.0983)  loss_rpn_box_reg: 0.0188 (0.0347)  time: 0.2774  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [28]  [ 560/1229]  eta: 0:03:03  lr: 0.000000  loss: 0.3603 (0.4305)  loss_classifier: 0.1233 (0.1536)  loss_box_reg: 0.1082 (0.1441)  loss_objectness: 0.1022 (0.0984)  loss_rpn_box_reg: 0.0188 (0.0344)  time: 0.2805  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [28]  [ 570/1229]  eta: 0:03:00  lr: 0.000000  loss: 0.3603 (0.4316)  loss_classifier: 0.1455 (0.1541)  loss_box_reg: 0.1151 (0.1447)  loss_objectness: 0.1041 (0.0986)  loss_rpn_box_reg: 0.0168 (0.0342)  time: 0.2760  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [28]  [ 580/1229]  eta: 0:02:57  lr: 0.000000  loss: 0.4015 (0.4321)  loss_classifier: 0.1455 (0.1543)  loss_box_reg: 0.1379 (0.1449)  loss_objectness: 0.0852 (0.0987)  loss_rpn_box_reg: 0.0227 (0.0341)  time: 0.2711  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [28]  [ 590/1229]  eta: 0:02:55  lr: 0.000000  loss: 0.3233 (0.4306)  loss_classifier: 0.1251 (0.1539)  loss_box_reg: 0.1318 (0.1446)  loss_objectness: 0.0630 (0.0981)  loss_rpn_box_reg: 0.0215 (0.0340)  time: 0.2783  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [28]  [ 600/1229]  eta: 0:02:52  lr: 0.000000  loss: 0.3014 (0.4293)  loss_classifier: 0.1063 (0.1533)  loss_box_reg: 0.1069 (0.1443)  loss_objectness: 0.0430 (0.0976)  loss_rpn_box_reg: 0.0144 (0.0340)  time: 0.2806  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [28]  [ 610/1229]  eta: 0:02:49  lr: 0.000000  loss: 0.3014 (0.4289)  loss_classifier: 0.1121 (0.1532)  loss_box_reg: 0.1069 (0.1441)  loss_objectness: 0.0570 (0.0974)  loss_rpn_box_reg: 0.0171 (0.0342)  time: 0.2819  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [28]  [ 620/1229]  eta: 0:02:47  lr: 0.000000  loss: 0.4445 (0.4315)  loss_classifier: 0.1486 (0.1539)  loss_box_reg: 0.1205 (0.1446)  loss_objectness: 0.0893 (0.0980)  loss_rpn_box_reg: 0.0411 (0.0349)  time: 0.2803  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [28]  [ 630/1229]  eta: 0:02:44  lr: 0.000000  loss: 0.4840 (0.4320)  loss_classifier: 0.1505 (0.1540)  loss_box_reg: 0.1205 (0.1447)  loss_objectness: 0.1132 (0.0983)  loss_rpn_box_reg: 0.0390 (0.0349)  time: 0.2791  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [28]  [ 640/1229]  eta: 0:02:41  lr: 0.000000  loss: 0.5383 (0.4343)  loss_classifier: 0.1761 (0.1547)  loss_box_reg: 0.1791 (0.1455)  loss_objectness: 0.0969 (0.0987)  loss_rpn_box_reg: 0.0295 (0.0355)  time: 0.2783  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [28]  [ 650/1229]  eta: 0:02:38  lr: 0.000000  loss: 0.5383 (0.4343)  loss_classifier: 0.1761 (0.1547)  loss_box_reg: 0.1646 (0.1452)  loss_objectness: 0.1231 (0.0991)  loss_rpn_box_reg: 0.0294 (0.0353)  time: 0.2691  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [28]  [ 660/1229]  eta: 0:02:36  lr: 0.000000  loss: 0.3649 (0.4341)  loss_classifier: 0.1008 (0.1544)  loss_box_reg: 0.0915 (0.1448)  loss_objectness: 0.1113 (0.0993)  loss_rpn_box_reg: 0.0277 (0.0355)  time: 0.2635  data: 0.1295  max mem: 1751\n",
      "Training Epoch: [28]  [ 670/1229]  eta: 0:02:33  lr: 0.000000  loss: 0.3681 (0.4343)  loss_classifier: 0.1125 (0.1543)  loss_box_reg: 0.0999 (0.1450)  loss_objectness: 0.0826 (0.0996)  loss_rpn_box_reg: 0.0291 (0.0355)  time: 0.2642  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [28]  [ 680/1229]  eta: 0:02:30  lr: 0.000000  loss: 0.3523 (0.4322)  loss_classifier: 0.1037 (0.1535)  loss_box_reg: 0.0970 (0.1442)  loss_objectness: 0.0709 (0.0991)  loss_rpn_box_reg: 0.0250 (0.0354)  time: 0.2676  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [28]  [ 690/1229]  eta: 0:02:27  lr: 0.000000  loss: 0.2937 (0.4328)  loss_classifier: 0.1048 (0.1537)  loss_box_reg: 0.0970 (0.1443)  loss_objectness: 0.0796 (0.0993)  loss_rpn_box_reg: 0.0214 (0.0354)  time: 0.2723  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [28]  [ 700/1229]  eta: 0:02:25  lr: 0.000000  loss: 0.4243 (0.4330)  loss_classifier: 0.1400 (0.1537)  loss_box_reg: 0.1558 (0.1444)  loss_objectness: 0.1091 (0.0995)  loss_rpn_box_reg: 0.0250 (0.0354)  time: 0.2731  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [28]  [ 710/1229]  eta: 0:02:22  lr: 0.000000  loss: 0.4243 (0.4341)  loss_classifier: 0.1443 (0.1541)  loss_box_reg: 0.1615 (0.1449)  loss_objectness: 0.1133 (0.0998)  loss_rpn_box_reg: 0.0274 (0.0353)  time: 0.2726  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [28]  [ 720/1229]  eta: 0:02:19  lr: 0.000000  loss: 0.4290 (0.4340)  loss_classifier: 0.1331 (0.1541)  loss_box_reg: 0.1582 (0.1452)  loss_objectness: 0.0951 (0.0995)  loss_rpn_box_reg: 0.0221 (0.0352)  time: 0.2710  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [28]  [ 730/1229]  eta: 0:02:16  lr: 0.000000  loss: 0.4129 (0.4343)  loss_classifier: 0.1168 (0.1540)  loss_box_reg: 0.1438 (0.1452)  loss_objectness: 0.0849 (0.0997)  loss_rpn_box_reg: 0.0172 (0.0353)  time: 0.2707  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [28]  [ 740/1229]  eta: 0:02:14  lr: 0.000000  loss: 0.4179 (0.4354)  loss_classifier: 0.1666 (0.1546)  loss_box_reg: 0.1394 (0.1459)  loss_objectness: 0.0879 (0.0997)  loss_rpn_box_reg: 0.0171 (0.0352)  time: 0.2774  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [28]  [ 750/1229]  eta: 0:02:11  lr: 0.000000  loss: 0.3758 (0.4337)  loss_classifier: 0.1212 (0.1540)  loss_box_reg: 0.1213 (0.1453)  loss_objectness: 0.0736 (0.0994)  loss_rpn_box_reg: 0.0170 (0.0349)  time: 0.2782  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [28]  [ 760/1229]  eta: 0:02:08  lr: 0.000000  loss: 0.3217 (0.4351)  loss_classifier: 0.1225 (0.1546)  loss_box_reg: 0.1188 (0.1464)  loss_objectness: 0.0667 (0.0992)  loss_rpn_box_reg: 0.0173 (0.0349)  time: 0.2809  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [28]  [ 770/1229]  eta: 0:02:05  lr: 0.000000  loss: 0.3405 (0.4334)  loss_classifier: 0.1225 (0.1540)  loss_box_reg: 0.1241 (0.1458)  loss_objectness: 0.0740 (0.0990)  loss_rpn_box_reg: 0.0175 (0.0346)  time: 0.2772  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [28]  [ 780/1229]  eta: 0:02:03  lr: 0.000000  loss: 0.3277 (0.4336)  loss_classifier: 0.1162 (0.1540)  loss_box_reg: 0.0923 (0.1459)  loss_objectness: 0.0793 (0.0991)  loss_rpn_box_reg: 0.0138 (0.0346)  time: 0.2727  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [28]  [ 790/1229]  eta: 0:02:00  lr: 0.000000  loss: 0.4588 (0.4342)  loss_classifier: 0.1417 (0.1542)  loss_box_reg: 0.1210 (0.1459)  loss_objectness: 0.1112 (0.0997)  loss_rpn_box_reg: 0.0254 (0.0345)  time: 0.2758  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [28]  [ 800/1229]  eta: 0:01:57  lr: 0.000000  loss: 0.3989 (0.4334)  loss_classifier: 0.1359 (0.1539)  loss_box_reg: 0.1140 (0.1457)  loss_objectness: 0.1011 (0.0994)  loss_rpn_box_reg: 0.0172 (0.0344)  time: 0.2755  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [28]  [ 810/1229]  eta: 0:01:54  lr: 0.000000  loss: 0.3895 (0.4336)  loss_classifier: 0.1359 (0.1540)  loss_box_reg: 0.1254 (0.1459)  loss_objectness: 0.0762 (0.0994)  loss_rpn_box_reg: 0.0164 (0.0343)  time: 0.2750  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [28]  [ 820/1229]  eta: 0:01:52  lr: 0.000000  loss: 0.4417 (0.4340)  loss_classifier: 0.1628 (0.1541)  loss_box_reg: 0.1479 (0.1460)  loss_objectness: 0.0983 (0.0996)  loss_rpn_box_reg: 0.0162 (0.0343)  time: 0.2700  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [28]  [ 830/1229]  eta: 0:01:49  lr: 0.000000  loss: 0.4406 (0.4349)  loss_classifier: 0.1738 (0.1545)  loss_box_reg: 0.1764 (0.1464)  loss_objectness: 0.0859 (0.0998)  loss_rpn_box_reg: 0.0183 (0.0342)  time: 0.2671  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [28]  [ 840/1229]  eta: 0:01:46  lr: 0.000000  loss: 0.3195 (0.4336)  loss_classifier: 0.1097 (0.1540)  loss_box_reg: 0.1094 (0.1460)  loss_objectness: 0.0673 (0.0994)  loss_rpn_box_reg: 0.0175 (0.0342)  time: 0.2709  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [28]  [ 850/1229]  eta: 0:01:43  lr: 0.000000  loss: 0.3399 (0.4340)  loss_classifier: 0.1097 (0.1542)  loss_box_reg: 0.1062 (0.1461)  loss_objectness: 0.0673 (0.0994)  loss_rpn_box_reg: 0.0174 (0.0343)  time: 0.2715  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [28]  [ 860/1229]  eta: 0:01:41  lr: 0.000000  loss: 0.4212 (0.4348)  loss_classifier: 0.1639 (0.1544)  loss_box_reg: 0.1372 (0.1466)  loss_objectness: 0.1144 (0.0995)  loss_rpn_box_reg: 0.0279 (0.0344)  time: 0.2736  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [28]  [ 870/1229]  eta: 0:01:38  lr: 0.000000  loss: 0.3705 (0.4342)  loss_classifier: 0.1223 (0.1542)  loss_box_reg: 0.1320 (0.1464)  loss_objectness: 0.0875 (0.0994)  loss_rpn_box_reg: 0.0165 (0.0343)  time: 0.2786  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [28]  [ 880/1229]  eta: 0:01:35  lr: 0.000000  loss: 0.3126 (0.4343)  loss_classifier: 0.1204 (0.1543)  loss_box_reg: 0.1020 (0.1465)  loss_objectness: 0.0757 (0.0994)  loss_rpn_box_reg: 0.0165 (0.0342)  time: 0.2750  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [28]  [ 890/1229]  eta: 0:01:32  lr: 0.000000  loss: 0.4187 (0.4344)  loss_classifier: 0.1293 (0.1542)  loss_box_reg: 0.1221 (0.1467)  loss_objectness: 0.0829 (0.0994)  loss_rpn_box_reg: 0.0198 (0.0341)  time: 0.2728  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [28]  [ 900/1229]  eta: 0:01:30  lr: 0.000000  loss: 0.3680 (0.4336)  loss_classifier: 0.1213 (0.1540)  loss_box_reg: 0.1102 (0.1463)  loss_objectness: 0.0945 (0.0993)  loss_rpn_box_reg: 0.0162 (0.0341)  time: 0.2692  data: 0.1303  max mem: 1751\n",
      "Training Epoch: [28]  [ 910/1229]  eta: 0:01:27  lr: 0.000000  loss: 0.3680 (0.4332)  loss_classifier: 0.1213 (0.1538)  loss_box_reg: 0.1125 (0.1463)  loss_objectness: 0.0834 (0.0990)  loss_rpn_box_reg: 0.0180 (0.0342)  time: 0.2696  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [28]  [ 920/1229]  eta: 0:01:24  lr: 0.000000  loss: 0.3800 (0.4332)  loss_classifier: 0.1366 (0.1537)  loss_box_reg: 0.1163 (0.1463)  loss_objectness: 0.0800 (0.0990)  loss_rpn_box_reg: 0.0214 (0.0342)  time: 0.2790  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [28]  [ 930/1229]  eta: 0:01:21  lr: 0.000000  loss: 0.4032 (0.4336)  loss_classifier: 0.1432 (0.1539)  loss_box_reg: 0.1523 (0.1465)  loss_objectness: 0.0916 (0.0991)  loss_rpn_box_reg: 0.0224 (0.0341)  time: 0.2769  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [28]  [ 940/1229]  eta: 0:01:19  lr: 0.000000  loss: 0.3690 (0.4333)  loss_classifier: 0.1416 (0.1539)  loss_box_reg: 0.1287 (0.1463)  loss_objectness: 0.0916 (0.0991)  loss_rpn_box_reg: 0.0242 (0.0340)  time: 0.2681  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [28]  [ 950/1229]  eta: 0:01:16  lr: 0.000000  loss: 0.3345 (0.4339)  loss_classifier: 0.1236 (0.1541)  loss_box_reg: 0.0868 (0.1464)  loss_objectness: 0.0776 (0.0992)  loss_rpn_box_reg: 0.0214 (0.0341)  time: 0.2707  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [28]  [ 960/1229]  eta: 0:01:13  lr: 0.000000  loss: 0.4124 (0.4347)  loss_classifier: 0.1482 (0.1546)  loss_box_reg: 0.1429 (0.1468)  loss_objectness: 0.0880 (0.0993)  loss_rpn_box_reg: 0.0277 (0.0341)  time: 0.2702  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [28]  [ 970/1229]  eta: 0:01:10  lr: 0.000000  loss: 0.4197 (0.4346)  loss_classifier: 0.1482 (0.1545)  loss_box_reg: 0.1451 (0.1466)  loss_objectness: 0.0998 (0.0994)  loss_rpn_box_reg: 0.0277 (0.0341)  time: 0.2670  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [28]  [ 980/1229]  eta: 0:01:08  lr: 0.000000  loss: 0.4447 (0.4360)  loss_classifier: 0.1740 (0.1549)  loss_box_reg: 0.1573 (0.1473)  loss_objectness: 0.0996 (0.0994)  loss_rpn_box_reg: 0.0247 (0.0343)  time: 0.2718  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [28]  [ 990/1229]  eta: 0:01:05  lr: 0.000000  loss: 0.4447 (0.4361)  loss_classifier: 0.1731 (0.1549)  loss_box_reg: 0.1549 (0.1473)  loss_objectness: 0.0971 (0.0996)  loss_rpn_box_reg: 0.0309 (0.0344)  time: 0.2715  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [28]  [1000/1229]  eta: 0:01:02  lr: 0.000000  loss: 0.3799 (0.4367)  loss_classifier: 0.1379 (0.1551)  loss_box_reg: 0.1305 (0.1476)  loss_objectness: 0.0937 (0.0996)  loss_rpn_box_reg: 0.0326 (0.0345)  time: 0.2685  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [28]  [1010/1229]  eta: 0:00:59  lr: 0.000000  loss: 0.4002 (0.4369)  loss_classifier: 0.1512 (0.1552)  loss_box_reg: 0.1422 (0.1477)  loss_objectness: 0.0925 (0.0996)  loss_rpn_box_reg: 0.0278 (0.0345)  time: 0.2712  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [28]  [1020/1229]  eta: 0:00:57  lr: 0.000000  loss: 0.4312 (0.4373)  loss_classifier: 0.1517 (0.1552)  loss_box_reg: 0.1447 (0.1477)  loss_objectness: 0.0946 (0.0998)  loss_rpn_box_reg: 0.0225 (0.0345)  time: 0.2765  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [28]  [1030/1229]  eta: 0:00:54  lr: 0.000000  loss: 0.4312 (0.4376)  loss_classifier: 0.1517 (0.1554)  loss_box_reg: 0.1511 (0.1479)  loss_objectness: 0.1036 (0.0998)  loss_rpn_box_reg: 0.0259 (0.0346)  time: 0.2692  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [28]  [1040/1229]  eta: 0:00:51  lr: 0.000000  loss: 0.3678 (0.4378)  loss_classifier: 0.1506 (0.1555)  loss_box_reg: 0.1458 (0.1480)  loss_objectness: 0.0806 (0.0997)  loss_rpn_box_reg: 0.0217 (0.0345)  time: 0.2691  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [28]  [1050/1229]  eta: 0:00:48  lr: 0.000000  loss: 0.2115 (0.4366)  loss_classifier: 0.0908 (0.1551)  loss_box_reg: 0.0974 (0.1476)  loss_objectness: 0.0462 (0.0995)  loss_rpn_box_reg: 0.0078 (0.0343)  time: 0.2756  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [28]  [1060/1229]  eta: 0:00:46  lr: 0.000000  loss: 0.2178 (0.4351)  loss_classifier: 0.0917 (0.1546)  loss_box_reg: 0.0718 (0.1469)  loss_objectness: 0.0484 (0.0993)  loss_rpn_box_reg: 0.0106 (0.0343)  time: 0.2728  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [28]  [1070/1229]  eta: 0:00:43  lr: 0.000000  loss: 0.3026 (0.4354)  loss_classifier: 0.1097 (0.1546)  loss_box_reg: 0.0806 (0.1470)  loss_objectness: 0.0876 (0.0994)  loss_rpn_box_reg: 0.0174 (0.0343)  time: 0.2712  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [28]  [1080/1229]  eta: 0:00:40  lr: 0.000000  loss: 0.4192 (0.4349)  loss_classifier: 0.1396 (0.1545)  loss_box_reg: 0.0985 (0.1467)  loss_objectness: 0.0977 (0.0996)  loss_rpn_box_reg: 0.0202 (0.0342)  time: 0.2682  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [28]  [1090/1229]  eta: 0:00:38  lr: 0.000000  loss: 0.3688 (0.4348)  loss_classifier: 0.1396 (0.1545)  loss_box_reg: 0.0781 (0.1467)  loss_objectness: 0.0877 (0.0994)  loss_rpn_box_reg: 0.0180 (0.0342)  time: 0.2702  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [28]  [1100/1229]  eta: 0:00:35  lr: 0.000000  loss: 0.3688 (0.4344)  loss_classifier: 0.1422 (0.1543)  loss_box_reg: 0.0973 (0.1464)  loss_objectness: 0.0780 (0.0996)  loss_rpn_box_reg: 0.0201 (0.0342)  time: 0.2724  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [28]  [1110/1229]  eta: 0:00:32  lr: 0.000000  loss: 0.3350 (0.4341)  loss_classifier: 0.1541 (0.1542)  loss_box_reg: 0.0974 (0.1463)  loss_objectness: 0.0805 (0.0995)  loss_rpn_box_reg: 0.0225 (0.0341)  time: 0.2724  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [28]  [1120/1229]  eta: 0:00:29  lr: 0.000000  loss: 0.3826 (0.4343)  loss_classifier: 0.1477 (0.1543)  loss_box_reg: 0.1121 (0.1466)  loss_objectness: 0.0788 (0.0994)  loss_rpn_box_reg: 0.0280 (0.0340)  time: 0.2728  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [28]  [1130/1229]  eta: 0:00:27  lr: 0.000000  loss: 0.4516 (0.4342)  loss_classifier: 0.1477 (0.1542)  loss_box_reg: 0.1421 (0.1466)  loss_objectness: 0.0748 (0.0994)  loss_rpn_box_reg: 0.0280 (0.0339)  time: 0.2717  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [28]  [1140/1229]  eta: 0:00:24  lr: 0.000000  loss: 0.3917 (0.4343)  loss_classifier: 0.1364 (0.1542)  loss_box_reg: 0.1351 (0.1467)  loss_objectness: 0.0805 (0.0994)  loss_rpn_box_reg: 0.0236 (0.0339)  time: 0.2735  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [28]  [1150/1229]  eta: 0:00:21  lr: 0.000000  loss: 0.3917 (0.4345)  loss_classifier: 0.1364 (0.1544)  loss_box_reg: 0.1246 (0.1469)  loss_objectness: 0.0805 (0.0993)  loss_rpn_box_reg: 0.0225 (0.0339)  time: 0.2839  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [28]  [1160/1229]  eta: 0:00:18  lr: 0.000000  loss: 0.3002 (0.4342)  loss_classifier: 0.1213 (0.1543)  loss_box_reg: 0.1100 (0.1468)  loss_objectness: 0.0958 (0.0992)  loss_rpn_box_reg: 0.0220 (0.0340)  time: 0.2783  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [28]  [1170/1229]  eta: 0:00:16  lr: 0.000000  loss: 0.4117 (0.4348)  loss_classifier: 0.1226 (0.1543)  loss_box_reg: 0.1209 (0.1470)  loss_objectness: 0.1086 (0.0993)  loss_rpn_box_reg: 0.0232 (0.0342)  time: 0.2713  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [28]  [1180/1229]  eta: 0:00:13  lr: 0.000000  loss: 0.4621 (0.4351)  loss_classifier: 0.1571 (0.1545)  loss_box_reg: 0.1379 (0.1468)  loss_objectness: 0.1237 (0.0996)  loss_rpn_box_reg: 0.0246 (0.0342)  time: 0.2757  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [28]  [1190/1229]  eta: 0:00:10  lr: 0.000000  loss: 0.4621 (0.4347)  loss_classifier: 0.1571 (0.1544)  loss_box_reg: 0.1219 (0.1466)  loss_objectness: 0.0792 (0.0996)  loss_rpn_box_reg: 0.0191 (0.0341)  time: 0.2730  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [28]  [1200/1229]  eta: 0:00:07  lr: 0.000000  loss: 0.4043 (0.4350)  loss_classifier: 0.1508 (0.1545)  loss_box_reg: 0.1259 (0.1469)  loss_objectness: 0.0724 (0.0995)  loss_rpn_box_reg: 0.0234 (0.0341)  time: 0.2747  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [28]  [1210/1229]  eta: 0:00:05  lr: 0.000000  loss: 0.4043 (0.4355)  loss_classifier: 0.1508 (0.1547)  loss_box_reg: 0.1272 (0.1471)  loss_objectness: 0.0809 (0.0996)  loss_rpn_box_reg: 0.0250 (0.0341)  time: 0.2754  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [28]  [1220/1229]  eta: 0:00:02  lr: 0.000000  loss: 0.4036 (0.4360)  loss_classifier: 0.1653 (0.1549)  loss_box_reg: 0.1203 (0.1472)  loss_objectness: 0.0995 (0.0997)  loss_rpn_box_reg: 0.0220 (0.0341)  time: 0.2756  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [28]  [1228/1229]  eta: 0:00:00  lr: 0.000000  loss: 0.3847 (0.4357)  loss_classifier: 0.1416 (0.1548)  loss_box_reg: 0.1203 (0.1473)  loss_objectness: 0.0995 (0.0996)  loss_rpn_box_reg: 0.0204 (0.0340)  time: 0.2775  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [28] Total time: 0:05:36 (0.2738 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:39  model_time: 0.2890 (0.2890)  evaluator_time: 0.0020 (0.0020)  time: 0.3220  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0800 (0.0824)  evaluator_time: 0.0040 (0.0085)  time: 0.1322  data: 0.0407  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0840 (0.0813)  evaluator_time: 0.0030 (0.0078)  time: 0.1195  data: 0.0305  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0730 (0.0804)  evaluator_time: 0.0040 (0.0076)  time: 0.1194  data: 0.0352  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0730 (0.0803)  evaluator_time: 0.0020 (0.0076)  time: 0.1164  data: 0.0336  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1239 s / it)\n",
      "Averaged stats: model_time: 0.0730 (0.0803)  evaluator_time: 0.0020 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [28]  [  0/308]  eta: 0:00:36  lr: 0.000000  loss: 0.1636 (0.1636)  loss_classifier: 0.0595 (0.0595)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0241 (0.0241)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1200  data: 0.0280  max mem: 1751\n",
      "Testing Epoch: [28]  [100/308]  eta: 0:00:28  lr: 0.000000  loss: 0.3059 (0.4806)  loss_classifier: 0.1334 (0.1546)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0495 (0.1018)  loss_rpn_box_reg: 0.0186 (0.0520)  time: 0.1399  data: 0.0385  max mem: 1751\n",
      "Testing Epoch: [28]  [200/308]  eta: 0:00:14  lr: 0.000000  loss: 0.3526 (0.4576)  loss_classifier: 0.1383 (0.1491)  loss_box_reg: 0.1251 (0.1633)  loss_objectness: 0.0725 (0.0961)  loss_rpn_box_reg: 0.0197 (0.0491)  time: 0.1377  data: 0.0318  max mem: 1751\n",
      "Testing Epoch: [28]  [300/308]  eta: 0:00:01  lr: 0.000000  loss: 0.4588 (0.4541)  loss_classifier: 0.1552 (0.1494)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0773 (0.0931)  loss_rpn_box_reg: 0.0265 (0.0475)  time: 0.1336  data: 0.0377  max mem: 1751\n",
      "Testing Epoch: [28]  [307/308]  eta: 0:00:00  lr: 0.000000  loss: 0.4588 (0.4542)  loss_classifier: 0.1860 (0.1496)  loss_box_reg: 0.1748 (0.1645)  loss_objectness: 0.0727 (0.0931)  loss_rpn_box_reg: 0.0271 (0.0470)  time: 0.1313  data: 0.0358  max mem: 1751\n",
      "Testing Epoch: [28] Total time: 0:00:42 (0.1375 s / it)\n",
      "Training Epoch: [29]  [   0/1229]  eta: 0:05:42  lr: 0.000000  loss: 0.4720 (0.4720)  loss_classifier: 0.1648 (0.1648)  loss_box_reg: 0.2089 (0.2089)  loss_objectness: 0.0705 (0.0705)  loss_rpn_box_reg: 0.0279 (0.0279)  time: 0.2790  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [29]  [  10/1229]  eta: 0:05:38  lr: 0.000000  loss: 0.3868 (0.3820)  loss_classifier: 0.1464 (0.1380)  loss_box_reg: 0.1561 (0.1430)  loss_objectness: 0.0637 (0.0808)  loss_rpn_box_reg: 0.0194 (0.0203)  time: 0.2780  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [29]  [  20/1229]  eta: 0:05:36  lr: 0.000000  loss: 0.3620 (0.3656)  loss_classifier: 0.1281 (0.1307)  loss_box_reg: 0.1204 (0.1260)  loss_objectness: 0.0637 (0.0873)  loss_rpn_box_reg: 0.0190 (0.0216)  time: 0.2781  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [29]  [  30/1229]  eta: 0:05:30  lr: 0.000000  loss: 0.3348 (0.3888)  loss_classifier: 0.1256 (0.1342)  loss_box_reg: 0.1111 (0.1269)  loss_objectness: 0.0874 (0.0993)  loss_rpn_box_reg: 0.0205 (0.0284)  time: 0.2742  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [29]  [  40/1229]  eta: 0:05:28  lr: 0.000000  loss: 0.4048 (0.4137)  loss_classifier: 0.1472 (0.1440)  loss_box_reg: 0.1130 (0.1408)  loss_objectness: 0.0948 (0.0977)  loss_rpn_box_reg: 0.0209 (0.0311)  time: 0.2749  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [29]  [  50/1229]  eta: 0:05:25  lr: 0.000000  loss: 0.3965 (0.4205)  loss_classifier: 0.1472 (0.1490)  loss_box_reg: 0.1525 (0.1446)  loss_objectness: 0.0786 (0.0954)  loss_rpn_box_reg: 0.0256 (0.0314)  time: 0.2779  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [29]  [  60/1229]  eta: 0:05:22  lr: 0.000000  loss: 0.3800 (0.4193)  loss_classifier: 0.1261 (0.1486)  loss_box_reg: 0.1210 (0.1456)  loss_objectness: 0.0836 (0.0945)  loss_rpn_box_reg: 0.0228 (0.0306)  time: 0.2737  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [29]  [  70/1229]  eta: 0:05:20  lr: 0.000000  loss: 0.3180 (0.4194)  loss_classifier: 0.1261 (0.1486)  loss_box_reg: 0.1177 (0.1452)  loss_objectness: 0.0867 (0.0947)  loss_rpn_box_reg: 0.0155 (0.0309)  time: 0.2757  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [29]  [  80/1229]  eta: 0:05:17  lr: 0.000000  loss: 0.3316 (0.4243)  loss_classifier: 0.1277 (0.1516)  loss_box_reg: 0.1177 (0.1462)  loss_objectness: 0.0962 (0.0958)  loss_rpn_box_reg: 0.0172 (0.0307)  time: 0.2798  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [29]  [  90/1229]  eta: 0:05:15  lr: 0.000000  loss: 0.3380 (0.4187)  loss_classifier: 0.1385 (0.1501)  loss_box_reg: 0.1045 (0.1455)  loss_objectness: 0.0776 (0.0937)  loss_rpn_box_reg: 0.0172 (0.0295)  time: 0.2788  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [29]  [ 100/1229]  eta: 0:05:12  lr: 0.000000  loss: 0.3800 (0.4294)  loss_classifier: 0.1394 (0.1541)  loss_box_reg: 0.1573 (0.1476)  loss_objectness: 0.0808 (0.0952)  loss_rpn_box_reg: 0.0196 (0.0325)  time: 0.2796  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [29]  [ 110/1229]  eta: 0:05:09  lr: 0.000000  loss: 0.4575 (0.4379)  loss_classifier: 0.1439 (0.1559)  loss_box_reg: 0.1702 (0.1502)  loss_objectness: 0.0985 (0.0981)  loss_rpn_box_reg: 0.0349 (0.0338)  time: 0.2741  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [29]  [ 120/1229]  eta: 0:05:06  lr: 0.000000  loss: 0.4306 (0.4312)  loss_classifier: 0.1271 (0.1527)  loss_box_reg: 0.1321 (0.1476)  loss_objectness: 0.0825 (0.0968)  loss_rpn_box_reg: 0.0225 (0.0341)  time: 0.2708  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [29]  [ 130/1229]  eta: 0:05:02  lr: 0.000000  loss: 0.3929 (0.4270)  loss_classifier: 0.1129 (0.1512)  loss_box_reg: 0.1216 (0.1462)  loss_objectness: 0.0817 (0.0966)  loss_rpn_box_reg: 0.0173 (0.0331)  time: 0.2713  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [29]  [ 140/1229]  eta: 0:04:59  lr: 0.000000  loss: 0.3082 (0.4167)  loss_classifier: 0.1082 (0.1481)  loss_box_reg: 0.0829 (0.1418)  loss_objectness: 0.0801 (0.0951)  loss_rpn_box_reg: 0.0163 (0.0317)  time: 0.2651  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [29]  [ 150/1229]  eta: 0:04:55  lr: 0.000000  loss: 0.3034 (0.4126)  loss_classifier: 0.1068 (0.1458)  loss_box_reg: 0.0844 (0.1407)  loss_objectness: 0.0716 (0.0936)  loss_rpn_box_reg: 0.0120 (0.0325)  time: 0.2634  data: 0.1290  max mem: 1751\n",
      "Training Epoch: [29]  [ 160/1229]  eta: 0:04:52  lr: 0.000000  loss: 0.3415 (0.4116)  loss_classifier: 0.1221 (0.1453)  loss_box_reg: 0.1130 (0.1401)  loss_objectness: 0.0724 (0.0944)  loss_rpn_box_reg: 0.0135 (0.0319)  time: 0.2701  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [29]  [ 170/1229]  eta: 0:04:49  lr: 0.000000  loss: 0.3894 (0.4149)  loss_classifier: 0.1324 (0.1461)  loss_box_reg: 0.1478 (0.1393)  loss_objectness: 0.0892 (0.0968)  loss_rpn_box_reg: 0.0193 (0.0326)  time: 0.2708  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [29]  [ 180/1229]  eta: 0:04:46  lr: 0.000000  loss: 0.4290 (0.4189)  loss_classifier: 0.1533 (0.1480)  loss_box_reg: 0.1353 (0.1410)  loss_objectness: 0.1009 (0.0977)  loss_rpn_box_reg: 0.0193 (0.0322)  time: 0.2676  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [29]  [ 190/1229]  eta: 0:04:43  lr: 0.000000  loss: 0.3672 (0.4190)  loss_classifier: 0.1462 (0.1481)  loss_box_reg: 0.1326 (0.1403)  loss_objectness: 0.0854 (0.0978)  loss_rpn_box_reg: 0.0189 (0.0328)  time: 0.2690  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [29]  [ 200/1229]  eta: 0:04:41  lr: 0.000000  loss: 0.3561 (0.4225)  loss_classifier: 0.1462 (0.1494)  loss_box_reg: 0.1225 (0.1416)  loss_objectness: 0.0829 (0.0982)  loss_rpn_box_reg: 0.0208 (0.0333)  time: 0.2748  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [29]  [ 210/1229]  eta: 0:04:38  lr: 0.000000  loss: 0.3665 (0.4206)  loss_classifier: 0.1504 (0.1490)  loss_box_reg: 0.1239 (0.1411)  loss_objectness: 0.0829 (0.0976)  loss_rpn_box_reg: 0.0194 (0.0330)  time: 0.2772  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [29]  [ 220/1229]  eta: 0:04:35  lr: 0.000000  loss: 0.3665 (0.4199)  loss_classifier: 0.1212 (0.1488)  loss_box_reg: 0.1002 (0.1410)  loss_objectness: 0.0891 (0.0972)  loss_rpn_box_reg: 0.0200 (0.0329)  time: 0.2694  data: 0.1300  max mem: 1751\n",
      "Training Epoch: [29]  [ 230/1229]  eta: 0:04:32  lr: 0.000000  loss: 0.4309 (0.4232)  loss_classifier: 0.1542 (0.1505)  loss_box_reg: 0.1072 (0.1422)  loss_objectness: 0.0927 (0.0974)  loss_rpn_box_reg: 0.0270 (0.0331)  time: 0.2686  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [29]  [ 240/1229]  eta: 0:04:30  lr: 0.000000  loss: 0.4309 (0.4249)  loss_classifier: 0.1542 (0.1507)  loss_box_reg: 0.1207 (0.1424)  loss_objectness: 0.1007 (0.0981)  loss_rpn_box_reg: 0.0300 (0.0337)  time: 0.2735  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [29]  [ 250/1229]  eta: 0:04:27  lr: 0.000000  loss: 0.4078 (0.4228)  loss_classifier: 0.1139 (0.1504)  loss_box_reg: 0.0989 (0.1418)  loss_objectness: 0.0793 (0.0973)  loss_rpn_box_reg: 0.0261 (0.0333)  time: 0.2760  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [29]  [ 260/1229]  eta: 0:04:25  lr: 0.000000  loss: 0.3047 (0.4219)  loss_classifier: 0.1284 (0.1504)  loss_box_reg: 0.1028 (0.1420)  loss_objectness: 0.0783 (0.0968)  loss_rpn_box_reg: 0.0156 (0.0327)  time: 0.2795  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [29]  [ 270/1229]  eta: 0:04:22  lr: 0.000000  loss: 0.3873 (0.4242)  loss_classifier: 0.1185 (0.1506)  loss_box_reg: 0.1187 (0.1429)  loss_objectness: 0.0580 (0.0965)  loss_rpn_box_reg: 0.0223 (0.0342)  time: 0.2797  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [29]  [ 280/1229]  eta: 0:04:20  lr: 0.000000  loss: 0.4514 (0.4269)  loss_classifier: 0.1420 (0.1514)  loss_box_reg: 0.1192 (0.1444)  loss_objectness: 0.0747 (0.0966)  loss_rpn_box_reg: 0.0273 (0.0344)  time: 0.2832  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [29]  [ 290/1229]  eta: 0:04:17  lr: 0.000000  loss: 0.3694 (0.4249)  loss_classifier: 0.1318 (0.1508)  loss_box_reg: 0.1161 (0.1438)  loss_objectness: 0.0893 (0.0964)  loss_rpn_box_reg: 0.0199 (0.0338)  time: 0.2824  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [29]  [ 300/1229]  eta: 0:04:14  lr: 0.000000  loss: 0.3232 (0.4232)  loss_classifier: 0.1186 (0.1504)  loss_box_reg: 0.1120 (0.1432)  loss_objectness: 0.0872 (0.0958)  loss_rpn_box_reg: 0.0169 (0.0338)  time: 0.2769  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [29]  [ 310/1229]  eta: 0:04:11  lr: 0.000000  loss: 0.3447 (0.4244)  loss_classifier: 0.1235 (0.1508)  loss_box_reg: 0.1263 (0.1438)  loss_objectness: 0.0872 (0.0960)  loss_rpn_box_reg: 0.0242 (0.0338)  time: 0.2712  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [29]  [ 320/1229]  eta: 0:04:09  lr: 0.000000  loss: 0.3254 (0.4222)  loss_classifier: 0.1073 (0.1499)  loss_box_reg: 0.1002 (0.1428)  loss_objectness: 0.0922 (0.0960)  loss_rpn_box_reg: 0.0237 (0.0335)  time: 0.2706  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [29]  [ 330/1229]  eta: 0:04:06  lr: 0.000000  loss: 0.2674 (0.4240)  loss_classifier: 0.1073 (0.1506)  loss_box_reg: 0.0847 (0.1438)  loss_objectness: 0.0771 (0.0961)  loss_rpn_box_reg: 0.0163 (0.0336)  time: 0.2836  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [29]  [ 340/1229]  eta: 0:04:04  lr: 0.000000  loss: 0.3403 (0.4234)  loss_classifier: 0.1337 (0.1501)  loss_box_reg: 0.0897 (0.1430)  loss_objectness: 0.0842 (0.0959)  loss_rpn_box_reg: 0.0179 (0.0344)  time: 0.2793  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [29]  [ 350/1229]  eta: 0:04:01  lr: 0.000000  loss: 0.4054 (0.4245)  loss_classifier: 0.1436 (0.1502)  loss_box_reg: 0.1194 (0.1432)  loss_objectness: 0.0952 (0.0962)  loss_rpn_box_reg: 0.0189 (0.0349)  time: 0.2706  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [29]  [ 360/1229]  eta: 0:03:58  lr: 0.000000  loss: 0.4222 (0.4241)  loss_classifier: 0.1494 (0.1503)  loss_box_reg: 0.1263 (0.1433)  loss_objectness: 0.0674 (0.0957)  loss_rpn_box_reg: 0.0267 (0.0348)  time: 0.2750  data: 0.1303  max mem: 1751\n",
      "Training Epoch: [29]  [ 370/1229]  eta: 0:03:55  lr: 0.000000  loss: 0.3786 (0.4234)  loss_classifier: 0.1345 (0.1498)  loss_box_reg: 0.1131 (0.1422)  loss_objectness: 0.0872 (0.0967)  loss_rpn_box_reg: 0.0243 (0.0346)  time: 0.2776  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [29]  [ 380/1229]  eta: 0:03:53  lr: 0.000000  loss: 0.4267 (0.4242)  loss_classifier: 0.1458 (0.1504)  loss_box_reg: 0.1036 (0.1422)  loss_objectness: 0.1070 (0.0973)  loss_rpn_box_reg: 0.0237 (0.0343)  time: 0.2776  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [29]  [ 390/1229]  eta: 0:03:50  lr: 0.000000  loss: 0.4700 (0.4261)  loss_classifier: 0.1757 (0.1511)  loss_box_reg: 0.1404 (0.1423)  loss_objectness: 0.1050 (0.0978)  loss_rpn_box_reg: 0.0279 (0.0349)  time: 0.2761  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [29]  [ 400/1229]  eta: 0:03:47  lr: 0.000000  loss: 0.4700 (0.4277)  loss_classifier: 0.1598 (0.1518)  loss_box_reg: 0.1265 (0.1431)  loss_objectness: 0.0985 (0.0980)  loss_rpn_box_reg: 0.0293 (0.0348)  time: 0.2758  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [29]  [ 410/1229]  eta: 0:03:45  lr: 0.000000  loss: 0.3834 (0.4269)  loss_classifier: 0.1274 (0.1515)  loss_box_reg: 0.1132 (0.1428)  loss_objectness: 0.0792 (0.0976)  loss_rpn_box_reg: 0.0200 (0.0350)  time: 0.2746  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [29]  [ 420/1229]  eta: 0:03:42  lr: 0.000000  loss: 0.3352 (0.4271)  loss_classifier: 0.1274 (0.1518)  loss_box_reg: 0.0988 (0.1424)  loss_objectness: 0.1002 (0.0979)  loss_rpn_box_reg: 0.0194 (0.0350)  time: 0.2709  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [29]  [ 430/1229]  eta: 0:03:39  lr: 0.000000  loss: 0.3853 (0.4282)  loss_classifier: 0.1368 (0.1521)  loss_box_reg: 0.1223 (0.1428)  loss_objectness: 0.0959 (0.0985)  loss_rpn_box_reg: 0.0254 (0.0349)  time: 0.2697  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [29]  [ 440/1229]  eta: 0:03:36  lr: 0.000000  loss: 0.3483 (0.4269)  loss_classifier: 0.1295 (0.1516)  loss_box_reg: 0.1265 (0.1425)  loss_objectness: 0.0878 (0.0982)  loss_rpn_box_reg: 0.0219 (0.0346)  time: 0.2747  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [29]  [ 450/1229]  eta: 0:03:33  lr: 0.000000  loss: 0.3261 (0.4254)  loss_classifier: 0.1285 (0.1510)  loss_box_reg: 0.1065 (0.1418)  loss_objectness: 0.0750 (0.0978)  loss_rpn_box_reg: 0.0221 (0.0348)  time: 0.2668  data: 0.1295  max mem: 1751\n",
      "Training Epoch: [29]  [ 460/1229]  eta: 0:03:30  lr: 0.000000  loss: 0.3373 (0.4245)  loss_classifier: 0.1071 (0.1507)  loss_box_reg: 0.0859 (0.1417)  loss_objectness: 0.0750 (0.0975)  loss_rpn_box_reg: 0.0287 (0.0346)  time: 0.2645  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [29]  [ 470/1229]  eta: 0:03:28  lr: 0.000000  loss: 0.3339 (0.4240)  loss_classifier: 0.1190 (0.1506)  loss_box_reg: 0.0645 (0.1411)  loss_objectness: 0.0768 (0.0976)  loss_rpn_box_reg: 0.0136 (0.0346)  time: 0.2762  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [29]  [ 480/1229]  eta: 0:03:25  lr: 0.000000  loss: 0.4290 (0.4260)  loss_classifier: 0.1534 (0.1516)  loss_box_reg: 0.0991 (0.1420)  loss_objectness: 0.0914 (0.0978)  loss_rpn_box_reg: 0.0316 (0.0346)  time: 0.2811  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [29]  [ 490/1229]  eta: 0:03:22  lr: 0.000000  loss: 0.4290 (0.4271)  loss_classifier: 0.1649 (0.1519)  loss_box_reg: 0.1130 (0.1423)  loss_objectness: 0.0919 (0.0982)  loss_rpn_box_reg: 0.0328 (0.0347)  time: 0.2809  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [29]  [ 500/1229]  eta: 0:03:20  lr: 0.000000  loss: 0.4079 (0.4280)  loss_classifier: 0.1506 (0.1523)  loss_box_reg: 0.1108 (0.1425)  loss_objectness: 0.0902 (0.0983)  loss_rpn_box_reg: 0.0328 (0.0349)  time: 0.2744  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [29]  [ 510/1229]  eta: 0:03:17  lr: 0.000000  loss: 0.3775 (0.4260)  loss_classifier: 0.1210 (0.1516)  loss_box_reg: 0.1099 (0.1419)  loss_objectness: 0.0708 (0.0975)  loss_rpn_box_reg: 0.0311 (0.0349)  time: 0.2781  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [29]  [ 520/1229]  eta: 0:03:14  lr: 0.000000  loss: 0.3664 (0.4256)  loss_classifier: 0.1201 (0.1513)  loss_box_reg: 0.1076 (0.1418)  loss_objectness: 0.0671 (0.0972)  loss_rpn_box_reg: 0.0330 (0.0354)  time: 0.2793  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [29]  [ 530/1229]  eta: 0:03:11  lr: 0.000000  loss: 0.3819 (0.4268)  loss_classifier: 0.1235 (0.1515)  loss_box_reg: 0.0982 (0.1418)  loss_objectness: 0.0856 (0.0980)  loss_rpn_box_reg: 0.0246 (0.0356)  time: 0.2699  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [29]  [ 540/1229]  eta: 0:03:09  lr: 0.000000  loss: 0.3995 (0.4255)  loss_classifier: 0.1382 (0.1511)  loss_box_reg: 0.0915 (0.1415)  loss_objectness: 0.0781 (0.0976)  loss_rpn_box_reg: 0.0144 (0.0353)  time: 0.2680  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [29]  [ 550/1229]  eta: 0:03:06  lr: 0.000000  loss: 0.3864 (0.4260)  loss_classifier: 0.1508 (0.1515)  loss_box_reg: 0.1409 (0.1419)  loss_objectness: 0.0749 (0.0975)  loss_rpn_box_reg: 0.0153 (0.0351)  time: 0.2715  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [29]  [ 560/1229]  eta: 0:03:03  lr: 0.000000  loss: 0.3500 (0.4250)  loss_classifier: 0.1398 (0.1512)  loss_box_reg: 0.1087 (0.1412)  loss_objectness: 0.0855 (0.0976)  loss_rpn_box_reg: 0.0197 (0.0350)  time: 0.2742  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [29]  [ 570/1229]  eta: 0:03:00  lr: 0.000000  loss: 0.3345 (0.4255)  loss_classifier: 0.1323 (0.1513)  loss_box_reg: 0.1087 (0.1413)  loss_objectness: 0.0919 (0.0978)  loss_rpn_box_reg: 0.0247 (0.0351)  time: 0.2722  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [29]  [ 580/1229]  eta: 0:02:57  lr: 0.000000  loss: 0.3025 (0.4238)  loss_classifier: 0.1122 (0.1508)  loss_box_reg: 0.1059 (0.1408)  loss_objectness: 0.0587 (0.0974)  loss_rpn_box_reg: 0.0184 (0.0349)  time: 0.2680  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [29]  [ 590/1229]  eta: 0:02:55  lr: 0.000000  loss: 0.3044 (0.4241)  loss_classifier: 0.1221 (0.1508)  loss_box_reg: 0.1059 (0.1413)  loss_objectness: 0.0622 (0.0971)  loss_rpn_box_reg: 0.0195 (0.0349)  time: 0.2706  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [29]  [ 600/1229]  eta: 0:02:52  lr: 0.000000  loss: 0.4953 (0.4264)  loss_classifier: 0.1688 (0.1518)  loss_box_reg: 0.1730 (0.1420)  loss_objectness: 0.0961 (0.0975)  loss_rpn_box_reg: 0.0258 (0.0351)  time: 0.2769  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [29]  [ 610/1229]  eta: 0:02:49  lr: 0.000000  loss: 0.5046 (0.4281)  loss_classifier: 0.1816 (0.1525)  loss_box_reg: 0.1586 (0.1429)  loss_objectness: 0.1071 (0.0977)  loss_rpn_box_reg: 0.0242 (0.0350)  time: 0.2739  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [29]  [ 620/1229]  eta: 0:02:46  lr: 0.000000  loss: 0.4754 (0.4286)  loss_classifier: 0.1737 (0.1528)  loss_box_reg: 0.1586 (0.1434)  loss_objectness: 0.0863 (0.0976)  loss_rpn_box_reg: 0.0168 (0.0348)  time: 0.2669  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [29]  [ 630/1229]  eta: 0:02:44  lr: 0.000000  loss: 0.4132 (0.4282)  loss_classifier: 0.1433 (0.1525)  loss_box_reg: 0.1111 (0.1433)  loss_objectness: 0.0804 (0.0976)  loss_rpn_box_reg: 0.0168 (0.0348)  time: 0.2757  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [29]  [ 640/1229]  eta: 0:02:41  lr: 0.000000  loss: 0.3208 (0.4274)  loss_classifier: 0.1296 (0.1525)  loss_box_reg: 0.0950 (0.1430)  loss_objectness: 0.0804 (0.0975)  loss_rpn_box_reg: 0.0154 (0.0345)  time: 0.2823  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [29]  [ 650/1229]  eta: 0:02:38  lr: 0.000000  loss: 0.4210 (0.4280)  loss_classifier: 0.1323 (0.1525)  loss_box_reg: 0.1028 (0.1429)  loss_objectness: 0.0864 (0.0979)  loss_rpn_box_reg: 0.0197 (0.0347)  time: 0.2729  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [29]  [ 660/1229]  eta: 0:02:35  lr: 0.000000  loss: 0.3646 (0.4265)  loss_classifier: 0.1213 (0.1520)  loss_box_reg: 0.1028 (0.1425)  loss_objectness: 0.0864 (0.0976)  loss_rpn_box_reg: 0.0191 (0.0345)  time: 0.2684  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [29]  [ 670/1229]  eta: 0:02:33  lr: 0.000000  loss: 0.3573 (0.4273)  loss_classifier: 0.1320 (0.1523)  loss_box_reg: 0.1112 (0.1428)  loss_objectness: 0.0894 (0.0978)  loss_rpn_box_reg: 0.0129 (0.0344)  time: 0.2722  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [29]  [ 680/1229]  eta: 0:02:30  lr: 0.000000  loss: 0.4009 (0.4270)  loss_classifier: 0.1447 (0.1521)  loss_box_reg: 0.1293 (0.1428)  loss_objectness: 0.0974 (0.0977)  loss_rpn_box_reg: 0.0211 (0.0344)  time: 0.2762  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [29]  [ 690/1229]  eta: 0:02:27  lr: 0.000000  loss: 0.4009 (0.4278)  loss_classifier: 0.1398 (0.1523)  loss_box_reg: 0.1312 (0.1432)  loss_objectness: 0.0974 (0.0976)  loss_rpn_box_reg: 0.0260 (0.0346)  time: 0.2829  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [29]  [ 700/1229]  eta: 0:02:25  lr: 0.000000  loss: 0.3579 (0.4271)  loss_classifier: 0.1309 (0.1521)  loss_box_reg: 0.1099 (0.1429)  loss_objectness: 0.1006 (0.0977)  loss_rpn_box_reg: 0.0185 (0.0345)  time: 0.2822  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [29]  [ 710/1229]  eta: 0:02:22  lr: 0.000000  loss: 0.3014 (0.4265)  loss_classifier: 0.1074 (0.1518)  loss_box_reg: 0.0968 (0.1428)  loss_objectness: 0.0821 (0.0975)  loss_rpn_box_reg: 0.0185 (0.0343)  time: 0.2773  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [29]  [ 720/1229]  eta: 0:02:19  lr: 0.000000  loss: 0.3460 (0.4265)  loss_classifier: 0.1077 (0.1517)  loss_box_reg: 0.1055 (0.1426)  loss_objectness: 0.0850 (0.0980)  loss_rpn_box_reg: 0.0197 (0.0343)  time: 0.2704  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [29]  [ 730/1229]  eta: 0:02:16  lr: 0.000000  loss: 0.3460 (0.4251)  loss_classifier: 0.1241 (0.1512)  loss_box_reg: 0.0869 (0.1423)  loss_objectness: 0.0854 (0.0977)  loss_rpn_box_reg: 0.0159 (0.0340)  time: 0.2666  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [29]  [ 740/1229]  eta: 0:02:14  lr: 0.000000  loss: 0.3665 (0.4272)  loss_classifier: 0.1265 (0.1520)  loss_box_reg: 0.1431 (0.1432)  loss_objectness: 0.0854 (0.0980)  loss_rpn_box_reg: 0.0162 (0.0340)  time: 0.2768  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [29]  [ 750/1229]  eta: 0:02:11  lr: 0.000000  loss: 0.5432 (0.4282)  loss_classifier: 0.1881 (0.1523)  loss_box_reg: 0.2241 (0.1438)  loss_objectness: 0.1049 (0.0981)  loss_rpn_box_reg: 0.0252 (0.0339)  time: 0.2776  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [29]  [ 760/1229]  eta: 0:02:08  lr: 0.000000  loss: 0.4167 (0.4278)  loss_classifier: 0.1516 (0.1523)  loss_box_reg: 0.1150 (0.1438)  loss_objectness: 0.0998 (0.0982)  loss_rpn_box_reg: 0.0205 (0.0336)  time: 0.2736  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [29]  [ 770/1229]  eta: 0:02:05  lr: 0.000000  loss: 0.4126 (0.4289)  loss_classifier: 0.1532 (0.1525)  loss_box_reg: 0.1115 (0.1444)  loss_objectness: 0.0866 (0.0982)  loss_rpn_box_reg: 0.0152 (0.0338)  time: 0.2705  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [29]  [ 780/1229]  eta: 0:02:03  lr: 0.000000  loss: 0.4126 (0.4282)  loss_classifier: 0.1532 (0.1522)  loss_box_reg: 0.1249 (0.1440)  loss_objectness: 0.0866 (0.0981)  loss_rpn_box_reg: 0.0322 (0.0338)  time: 0.2713  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [29]  [ 790/1229]  eta: 0:02:00  lr: 0.000000  loss: 0.4082 (0.4285)  loss_classifier: 0.1354 (0.1525)  loss_box_reg: 0.1060 (0.1444)  loss_objectness: 0.0794 (0.0979)  loss_rpn_box_reg: 0.0289 (0.0338)  time: 0.2808  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [29]  [ 800/1229]  eta: 0:01:57  lr: 0.000000  loss: 0.3335 (0.4279)  loss_classifier: 0.1305 (0.1523)  loss_box_reg: 0.1025 (0.1444)  loss_objectness: 0.0633 (0.0977)  loss_rpn_box_reg: 0.0240 (0.0336)  time: 0.2730  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [29]  [ 810/1229]  eta: 0:01:54  lr: 0.000000  loss: 0.3175 (0.4271)  loss_classifier: 0.1142 (0.1519)  loss_box_reg: 0.1025 (0.1440)  loss_objectness: 0.0527 (0.0976)  loss_rpn_box_reg: 0.0092 (0.0336)  time: 0.2708  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [29]  [ 820/1229]  eta: 0:01:52  lr: 0.000000  loss: 0.3169 (0.4269)  loss_classifier: 0.1071 (0.1518)  loss_box_reg: 0.0927 (0.1438)  loss_objectness: 0.0644 (0.0977)  loss_rpn_box_reg: 0.0207 (0.0336)  time: 0.2755  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [29]  [ 830/1229]  eta: 0:01:49  lr: 0.000000  loss: 0.4207 (0.4279)  loss_classifier: 0.1670 (0.1522)  loss_box_reg: 0.1348 (0.1442)  loss_objectness: 0.1126 (0.0980)  loss_rpn_box_reg: 0.0182 (0.0336)  time: 0.2710  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [29]  [ 840/1229]  eta: 0:01:46  lr: 0.000000  loss: 0.4721 (0.4286)  loss_classifier: 0.1714 (0.1525)  loss_box_reg: 0.1450 (0.1444)  loss_objectness: 0.1126 (0.0981)  loss_rpn_box_reg: 0.0219 (0.0336)  time: 0.2712  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [29]  [ 850/1229]  eta: 0:01:43  lr: 0.000000  loss: 0.4213 (0.4284)  loss_classifier: 0.1650 (0.1525)  loss_box_reg: 0.1412 (0.1445)  loss_objectness: 0.0987 (0.0980)  loss_rpn_box_reg: 0.0233 (0.0334)  time: 0.2725  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [29]  [ 860/1229]  eta: 0:01:41  lr: 0.000000  loss: 0.4213 (0.4294)  loss_classifier: 0.1520 (0.1528)  loss_box_reg: 0.1310 (0.1448)  loss_objectness: 0.0762 (0.0982)  loss_rpn_box_reg: 0.0258 (0.0336)  time: 0.2684  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [29]  [ 870/1229]  eta: 0:01:38  lr: 0.000000  loss: 0.4753 (0.4310)  loss_classifier: 0.1746 (0.1532)  loss_box_reg: 0.1709 (0.1454)  loss_objectness: 0.0698 (0.0983)  loss_rpn_box_reg: 0.0222 (0.0341)  time: 0.2682  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [29]  [ 880/1229]  eta: 0:01:35  lr: 0.000000  loss: 0.4113 (0.4304)  loss_classifier: 0.1484 (0.1531)  loss_box_reg: 0.1418 (0.1453)  loss_objectness: 0.0664 (0.0981)  loss_rpn_box_reg: 0.0199 (0.0340)  time: 0.2768  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [29]  [ 890/1229]  eta: 0:01:32  lr: 0.000000  loss: 0.4265 (0.4316)  loss_classifier: 0.1592 (0.1534)  loss_box_reg: 0.1418 (0.1459)  loss_objectness: 0.0885 (0.0983)  loss_rpn_box_reg: 0.0245 (0.0341)  time: 0.2780  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [29]  [ 900/1229]  eta: 0:01:30  lr: 0.000000  loss: 0.5217 (0.4334)  loss_classifier: 0.1937 (0.1542)  loss_box_reg: 0.2068 (0.1466)  loss_objectness: 0.0968 (0.0985)  loss_rpn_box_reg: 0.0302 (0.0341)  time: 0.2738  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [29]  [ 910/1229]  eta: 0:01:27  lr: 0.000000  loss: 0.5021 (0.4332)  loss_classifier: 0.1876 (0.1541)  loss_box_reg: 0.1702 (0.1466)  loss_objectness: 0.0968 (0.0985)  loss_rpn_box_reg: 0.0286 (0.0340)  time: 0.2709  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [29]  [ 920/1229]  eta: 0:01:24  lr: 0.000000  loss: 0.3519 (0.4326)  loss_classifier: 0.1072 (0.1539)  loss_box_reg: 0.0801 (0.1463)  loss_objectness: 0.0700 (0.0984)  loss_rpn_box_reg: 0.0223 (0.0339)  time: 0.2739  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [29]  [ 930/1229]  eta: 0:01:21  lr: 0.000000  loss: 0.3778 (0.4327)  loss_classifier: 0.1164 (0.1538)  loss_box_reg: 0.0916 (0.1460)  loss_objectness: 0.1030 (0.0990)  loss_rpn_box_reg: 0.0285 (0.0339)  time: 0.2742  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [29]  [ 940/1229]  eta: 0:01:19  lr: 0.000000  loss: 0.3825 (0.4322)  loss_classifier: 0.1276 (0.1536)  loss_box_reg: 0.0989 (0.1457)  loss_objectness: 0.0893 (0.0988)  loss_rpn_box_reg: 0.0337 (0.0340)  time: 0.2729  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [29]  [ 950/1229]  eta: 0:01:16  lr: 0.000000  loss: 0.3307 (0.4313)  loss_classifier: 0.1195 (0.1534)  loss_box_reg: 0.1028 (0.1455)  loss_objectness: 0.0747 (0.0985)  loss_rpn_box_reg: 0.0257 (0.0339)  time: 0.2746  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [29]  [ 960/1229]  eta: 0:01:13  lr: 0.000000  loss: 0.3930 (0.4314)  loss_classifier: 0.1385 (0.1535)  loss_box_reg: 0.1187 (0.1454)  loss_objectness: 0.0736 (0.0985)  loss_rpn_box_reg: 0.0271 (0.0339)  time: 0.2830  data: 0.1381  max mem: 1751\n",
      "Training Epoch: [29]  [ 970/1229]  eta: 0:01:11  lr: 0.000000  loss: 0.3362 (0.4305)  loss_classifier: 0.1301 (0.1531)  loss_box_reg: 0.1066 (0.1451)  loss_objectness: 0.0703 (0.0984)  loss_rpn_box_reg: 0.0226 (0.0339)  time: 0.2796  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [29]  [ 980/1229]  eta: 0:01:08  lr: 0.000000  loss: 0.2918 (0.4301)  loss_classifier: 0.1189 (0.1531)  loss_box_reg: 0.0864 (0.1450)  loss_objectness: 0.0589 (0.0984)  loss_rpn_box_reg: 0.0121 (0.0337)  time: 0.2710  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [29]  [ 990/1229]  eta: 0:01:05  lr: 0.000000  loss: 0.3608 (0.4305)  loss_classifier: 0.1505 (0.1532)  loss_box_reg: 0.1130 (0.1452)  loss_objectness: 0.0612 (0.0985)  loss_rpn_box_reg: 0.0132 (0.0337)  time: 0.2758  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [29]  [1000/1229]  eta: 0:01:02  lr: 0.000000  loss: 0.3772 (0.4307)  loss_classifier: 0.1505 (0.1532)  loss_box_reg: 0.1442 (0.1454)  loss_objectness: 0.1001 (0.0985)  loss_rpn_box_reg: 0.0179 (0.0336)  time: 0.2787  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [29]  [1010/1229]  eta: 0:01:00  lr: 0.000000  loss: 0.3535 (0.4297)  loss_classifier: 0.1285 (0.1529)  loss_box_reg: 0.1260 (0.1450)  loss_objectness: 0.0817 (0.0983)  loss_rpn_box_reg: 0.0179 (0.0335)  time: 0.2706  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [29]  [1020/1229]  eta: 0:00:57  lr: 0.000000  loss: 0.3293 (0.4292)  loss_classifier: 0.1161 (0.1527)  loss_box_reg: 0.1099 (0.1447)  loss_objectness: 0.0686 (0.0983)  loss_rpn_box_reg: 0.0168 (0.0335)  time: 0.2698  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [29]  [1030/1229]  eta: 0:00:54  lr: 0.000000  loss: 0.3976 (0.4305)  loss_classifier: 0.1443 (0.1532)  loss_box_reg: 0.1323 (0.1451)  loss_objectness: 0.0875 (0.0986)  loss_rpn_box_reg: 0.0209 (0.0337)  time: 0.2787  data: 0.1368  max mem: 1751\n",
      "Training Epoch: [29]  [1040/1229]  eta: 0:00:51  lr: 0.000000  loss: 0.5143 (0.4320)  loss_classifier: 0.1996 (0.1537)  loss_box_reg: 0.2103 (0.1459)  loss_objectness: 0.1038 (0.0986)  loss_rpn_box_reg: 0.0304 (0.0337)  time: 0.2764  data: 0.1377  max mem: 1751\n",
      "Training Epoch: [29]  [1050/1229]  eta: 0:00:49  lr: 0.000000  loss: 0.5061 (0.4328)  loss_classifier: 0.1873 (0.1539)  loss_box_reg: 0.2103 (0.1464)  loss_objectness: 0.0999 (0.0988)  loss_rpn_box_reg: 0.0295 (0.0338)  time: 0.2736  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [29]  [1060/1229]  eta: 0:00:46  lr: 0.000000  loss: 0.4596 (0.4335)  loss_classifier: 0.1295 (0.1540)  loss_box_reg: 0.1199 (0.1464)  loss_objectness: 0.1118 (0.0992)  loss_rpn_box_reg: 0.0295 (0.0339)  time: 0.2759  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [29]  [1070/1229]  eta: 0:00:43  lr: 0.000000  loss: 0.4515 (0.4339)  loss_classifier: 0.1438 (0.1542)  loss_box_reg: 0.1096 (0.1465)  loss_objectness: 0.1142 (0.0994)  loss_rpn_box_reg: 0.0225 (0.0338)  time: 0.2767  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [29]  [1080/1229]  eta: 0:00:40  lr: 0.000000  loss: 0.4983 (0.4352)  loss_classifier: 0.1560 (0.1546)  loss_box_reg: 0.1619 (0.1469)  loss_objectness: 0.1142 (0.0996)  loss_rpn_box_reg: 0.0207 (0.0341)  time: 0.2702  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [29]  [1090/1229]  eta: 0:00:38  lr: 0.000000  loss: 0.4703 (0.4348)  loss_classifier: 0.1490 (0.1545)  loss_box_reg: 0.1566 (0.1466)  loss_objectness: 0.1116 (0.0996)  loss_rpn_box_reg: 0.0191 (0.0341)  time: 0.2678  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [29]  [1100/1229]  eta: 0:00:35  lr: 0.000000  loss: 0.4219 (0.4354)  loss_classifier: 0.1392 (0.1547)  loss_box_reg: 0.1506 (0.1468)  loss_objectness: 0.0975 (0.0997)  loss_rpn_box_reg: 0.0153 (0.0341)  time: 0.2719  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [29]  [1110/1229]  eta: 0:00:32  lr: 0.000000  loss: 0.3731 (0.4349)  loss_classifier: 0.1206 (0.1547)  loss_box_reg: 0.1335 (0.1466)  loss_objectness: 0.0915 (0.0996)  loss_rpn_box_reg: 0.0172 (0.0340)  time: 0.2771  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [29]  [1120/1229]  eta: 0:00:29  lr: 0.000000  loss: 0.3292 (0.4342)  loss_classifier: 0.1169 (0.1544)  loss_box_reg: 0.1014 (0.1464)  loss_objectness: 0.0847 (0.0994)  loss_rpn_box_reg: 0.0139 (0.0339)  time: 0.2830  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [29]  [1130/1229]  eta: 0:00:27  lr: 0.000000  loss: 0.3453 (0.4343)  loss_classifier: 0.1261 (0.1545)  loss_box_reg: 0.1197 (0.1467)  loss_objectness: 0.0819 (0.0993)  loss_rpn_box_reg: 0.0219 (0.0339)  time: 0.2790  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [29]  [1140/1229]  eta: 0:00:24  lr: 0.000000  loss: 0.4032 (0.4345)  loss_classifier: 0.1278 (0.1545)  loss_box_reg: 0.1197 (0.1467)  loss_objectness: 0.0732 (0.0994)  loss_rpn_box_reg: 0.0283 (0.0339)  time: 0.2711  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [29]  [1150/1229]  eta: 0:00:21  lr: 0.000000  loss: 0.4083 (0.4341)  loss_classifier: 0.1458 (0.1545)  loss_box_reg: 0.1060 (0.1466)  loss_objectness: 0.0727 (0.0992)  loss_rpn_box_reg: 0.0250 (0.0339)  time: 0.2754  data: 0.1377  max mem: 1751\n",
      "Training Epoch: [29]  [1160/1229]  eta: 0:00:18  lr: 0.000000  loss: 0.4161 (0.4338)  loss_classifier: 0.1307 (0.1543)  loss_box_reg: 0.1343 (0.1465)  loss_objectness: 0.0731 (0.0990)  loss_rpn_box_reg: 0.0153 (0.0340)  time: 0.2782  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [29]  [1170/1229]  eta: 0:00:16  lr: 0.000000  loss: 0.3531 (0.4342)  loss_classifier: 0.1229 (0.1544)  loss_box_reg: 0.1190 (0.1466)  loss_objectness: 0.0785 (0.0992)  loss_rpn_box_reg: 0.0140 (0.0340)  time: 0.2763  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [29]  [1180/1229]  eta: 0:00:13  lr: 0.000000  loss: 0.3531 (0.4342)  loss_classifier: 0.1207 (0.1545)  loss_box_reg: 0.1189 (0.1464)  loss_objectness: 0.0978 (0.0993)  loss_rpn_box_reg: 0.0178 (0.0340)  time: 0.2770  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [29]  [1190/1229]  eta: 0:00:10  lr: 0.000000  loss: 0.3973 (0.4343)  loss_classifier: 0.1207 (0.1545)  loss_box_reg: 0.1206 (0.1464)  loss_objectness: 0.0978 (0.0993)  loss_rpn_box_reg: 0.0239 (0.0340)  time: 0.2761  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [29]  [1200/1229]  eta: 0:00:07  lr: 0.000000  loss: 0.4270 (0.4346)  loss_classifier: 0.1494 (0.1547)  loss_box_reg: 0.1412 (0.1467)  loss_objectness: 0.0890 (0.0993)  loss_rpn_box_reg: 0.0239 (0.0339)  time: 0.2699  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [29]  [1210/1229]  eta: 0:00:05  lr: 0.000000  loss: 0.4474 (0.4342)  loss_classifier: 0.1494 (0.1545)  loss_box_reg: 0.1398 (0.1466)  loss_objectness: 0.0849 (0.0992)  loss_rpn_box_reg: 0.0181 (0.0339)  time: 0.2719  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [29]  [1220/1229]  eta: 0:00:02  lr: 0.000000  loss: 0.3796 (0.4336)  loss_classifier: 0.1249 (0.1543)  loss_box_reg: 0.1027 (0.1462)  loss_objectness: 0.0849 (0.0991)  loss_rpn_box_reg: 0.0178 (0.0339)  time: 0.2772  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [29]  [1228/1229]  eta: 0:00:00  lr: 0.000000  loss: 0.3538 (0.4340)  loss_classifier: 0.1372 (0.1544)  loss_box_reg: 0.1285 (0.1466)  loss_objectness: 0.0782 (0.0990)  loss_rpn_box_reg: 0.0158 (0.0340)  time: 0.2777  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [29] Total time: 0:05:37 (0.2745 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:48  model_time: 0.3200 (0.3200)  evaluator_time: 0.0010 (0.0010)  time: 0.3510  data: 0.0280  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0790 (0.0824)  evaluator_time: 0.0050 (0.0085)  time: 0.1271  data: 0.0357  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0830 (0.0812)  evaluator_time: 0.0030 (0.0078)  time: 0.1200  data: 0.0307  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0750 (0.0804)  evaluator_time: 0.0040 (0.0076)  time: 0.1202  data: 0.0356  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0740 (0.0802)  evaluator_time: 0.0030 (0.0076)  time: 0.1173  data: 0.0340  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1240 s / it)\n",
      "Averaged stats: model_time: 0.0740 (0.0802)  evaluator_time: 0.0030 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [29]  [  0/308]  eta: 0:00:37  lr: 0.000000  loss: 0.1618 (0.1618)  loss_classifier: 0.0597 (0.0597)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0222 (0.0222)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1220  data: 0.0280  max mem: 1751\n",
      "Testing Epoch: [29]  [100/308]  eta: 0:00:28  lr: 0.000000  loss: 0.3183 (0.4800)  loss_classifier: 0.1344 (0.1548)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0513 (0.1011)  loss_rpn_box_reg: 0.0186 (0.0519)  time: 0.1397  data: 0.0380  max mem: 1751\n",
      "Testing Epoch: [29]  [200/308]  eta: 0:00:14  lr: 0.000000  loss: 0.3516 (0.4565)  loss_classifier: 0.1396 (0.1491)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0624 (0.0951)  loss_rpn_box_reg: 0.0197 (0.0491)  time: 0.1379  data: 0.0324  max mem: 1751\n",
      "Testing Epoch: [29]  [300/308]  eta: 0:00:01  lr: 0.000000  loss: 0.4616 (0.4536)  loss_classifier: 0.1545 (0.1493)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0773 (0.0928)  loss_rpn_box_reg: 0.0265 (0.0475)  time: 0.1331  data: 0.0373  max mem: 1751\n",
      "Testing Epoch: [29]  [307/308]  eta: 0:00:00  lr: 0.000000  loss: 0.4616 (0.4539)  loss_classifier: 0.1860 (0.1496)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0737 (0.0930)  loss_rpn_box_reg: 0.0271 (0.0470)  time: 0.1305  data: 0.0350  max mem: 1751\n",
      "Testing Epoch: [29] Total time: 0:00:42 (0.1375 s / it)\n",
      "Training Epoch: [30]  [   0/1229]  eta: 0:05:52  lr: 0.000000  loss: 1.1786 (1.1786)  loss_classifier: 0.3733 (0.3733)  loss_box_reg: 0.4854 (0.4854)  loss_objectness: 0.1238 (0.1238)  loss_rpn_box_reg: 0.1964 (0.1964)  time: 0.2870  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [30]  [  10/1229]  eta: 0:05:31  lr: 0.000000  loss: 0.4336 (0.4768)  loss_classifier: 0.1389 (0.1666)  loss_box_reg: 0.1542 (0.1629)  loss_objectness: 0.0769 (0.0916)  loss_rpn_box_reg: 0.0408 (0.0557)  time: 0.2721  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [30]  [  20/1229]  eta: 0:05:27  lr: 0.000000  loss: 0.3963 (0.4327)  loss_classifier: 0.1292 (0.1539)  loss_box_reg: 0.1488 (0.1435)  loss_objectness: 0.0696 (0.0915)  loss_rpn_box_reg: 0.0244 (0.0438)  time: 0.2704  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [30]  [  30/1229]  eta: 0:05:27  lr: 0.000000  loss: 0.4302 (0.4564)  loss_classifier: 0.1433 (0.1619)  loss_box_reg: 0.1724 (0.1595)  loss_objectness: 0.0744 (0.0929)  loss_rpn_box_reg: 0.0191 (0.0421)  time: 0.2742  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [30]  [  40/1229]  eta: 0:05:25  lr: 0.000000  loss: 0.4302 (0.4542)  loss_classifier: 0.1415 (0.1616)  loss_box_reg: 0.1724 (0.1585)  loss_objectness: 0.0778 (0.0945)  loss_rpn_box_reg: 0.0259 (0.0395)  time: 0.2759  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [30]  [  50/1229]  eta: 0:05:22  lr: 0.000000  loss: 0.3755 (0.4694)  loss_classifier: 0.1405 (0.1692)  loss_box_reg: 0.1172 (0.1650)  loss_objectness: 0.0770 (0.0979)  loss_rpn_box_reg: 0.0259 (0.0373)  time: 0.2742  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [30]  [  60/1229]  eta: 0:05:20  lr: 0.000000  loss: 0.3755 (0.4514)  loss_classifier: 0.1339 (0.1621)  loss_box_reg: 0.1155 (0.1580)  loss_objectness: 0.0816 (0.0948)  loss_rpn_box_reg: 0.0176 (0.0365)  time: 0.2747  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [30]  [  70/1229]  eta: 0:05:15  lr: 0.000000  loss: 0.3661 (0.4547)  loss_classifier: 0.1298 (0.1621)  loss_box_reg: 0.1155 (0.1568)  loss_objectness: 0.0882 (0.0987)  loss_rpn_box_reg: 0.0176 (0.0371)  time: 0.2697  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [30]  [  80/1229]  eta: 0:05:13  lr: 0.000000  loss: 0.2961 (0.4416)  loss_classifier: 0.1298 (0.1567)  loss_box_reg: 0.0969 (0.1518)  loss_objectness: 0.0882 (0.0981)  loss_rpn_box_reg: 0.0197 (0.0349)  time: 0.2710  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [30]  [  90/1229]  eta: 0:05:10  lr: 0.000000  loss: 0.2961 (0.4447)  loss_classifier: 0.1036 (0.1566)  loss_box_reg: 0.0966 (0.1519)  loss_objectness: 0.0786 (0.0990)  loss_rpn_box_reg: 0.0197 (0.0373)  time: 0.2740  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [30]  [ 100/1229]  eta: 0:05:08  lr: 0.000000  loss: 0.2942 (0.4299)  loss_classifier: 0.1266 (0.1522)  loss_box_reg: 0.0892 (0.1450)  loss_objectness: 0.0810 (0.0975)  loss_rpn_box_reg: 0.0146 (0.0352)  time: 0.2713  data: 0.1299  max mem: 1751\n",
      "Training Epoch: [30]  [ 110/1229]  eta: 0:05:05  lr: 0.000000  loss: 0.2942 (0.4303)  loss_classifier: 0.1266 (0.1523)  loss_box_reg: 0.0892 (0.1452)  loss_objectness: 0.0810 (0.0979)  loss_rpn_box_reg: 0.0154 (0.0349)  time: 0.2736  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [30]  [ 120/1229]  eta: 0:05:02  lr: 0.000000  loss: 0.4000 (0.4446)  loss_classifier: 0.1746 (0.1577)  loss_box_reg: 0.1361 (0.1520)  loss_objectness: 0.0878 (0.0999)  loss_rpn_box_reg: 0.0187 (0.0350)  time: 0.2748  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [30]  [ 130/1229]  eta: 0:04:59  lr: 0.000000  loss: 0.4954 (0.4428)  loss_classifier: 0.1649 (0.1561)  loss_box_reg: 0.1233 (0.1490)  loss_objectness: 0.1113 (0.1025)  loss_rpn_box_reg: 0.0187 (0.0352)  time: 0.2714  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [30]  [ 140/1229]  eta: 0:04:57  lr: 0.000000  loss: 0.3958 (0.4403)  loss_classifier: 0.1377 (0.1559)  loss_box_reg: 0.1090 (0.1477)  loss_objectness: 0.1113 (0.1025)  loss_rpn_box_reg: 0.0203 (0.0342)  time: 0.2752  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [30]  [ 150/1229]  eta: 0:04:54  lr: 0.000000  loss: 0.3958 (0.4431)  loss_classifier: 0.1511 (0.1564)  loss_box_reg: 0.1221 (0.1485)  loss_objectness: 0.1089 (0.1031)  loss_rpn_box_reg: 0.0206 (0.0351)  time: 0.2772  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [30]  [ 160/1229]  eta: 0:04:51  lr: 0.000000  loss: 0.4284 (0.4413)  loss_classifier: 0.1409 (0.1559)  loss_box_reg: 0.1155 (0.1467)  loss_objectness: 0.1123 (0.1031)  loss_rpn_box_reg: 0.0347 (0.0355)  time: 0.2705  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [30]  [ 170/1229]  eta: 0:04:49  lr: 0.000000  loss: 0.3628 (0.4348)  loss_classifier: 0.1231 (0.1537)  loss_box_reg: 0.1061 (0.1450)  loss_objectness: 0.0635 (0.1016)  loss_rpn_box_reg: 0.0253 (0.0345)  time: 0.2709  data: 0.1300  max mem: 1751\n",
      "Training Epoch: [30]  [ 180/1229]  eta: 0:04:46  lr: 0.000000  loss: 0.2582 (0.4301)  loss_classifier: 0.1049 (0.1528)  loss_box_reg: 0.0771 (0.1420)  loss_objectness: 0.0684 (0.1017)  loss_rpn_box_reg: 0.0143 (0.0336)  time: 0.2726  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [30]  [ 190/1229]  eta: 0:04:43  lr: 0.000000  loss: 0.3621 (0.4335)  loss_classifier: 0.1653 (0.1544)  loss_box_reg: 0.1016 (0.1443)  loss_objectness: 0.0846 (0.1014)  loss_rpn_box_reg: 0.0183 (0.0334)  time: 0.2690  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [30]  [ 200/1229]  eta: 0:04:40  lr: 0.000000  loss: 0.4686 (0.4335)  loss_classifier: 0.1709 (0.1542)  loss_box_reg: 0.1525 (0.1441)  loss_objectness: 0.0872 (0.1013)  loss_rpn_box_reg: 0.0207 (0.0340)  time: 0.2672  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [30]  [ 210/1229]  eta: 0:04:37  lr: 0.000000  loss: 0.3194 (0.4279)  loss_classifier: 0.1042 (0.1522)  loss_box_reg: 0.0862 (0.1422)  loss_objectness: 0.0739 (0.0998)  loss_rpn_box_reg: 0.0178 (0.0337)  time: 0.2687  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [30]  [ 220/1229]  eta: 0:04:34  lr: 0.000000  loss: 0.3504 (0.4347)  loss_classifier: 0.1197 (0.1548)  loss_box_reg: 0.0931 (0.1443)  loss_objectness: 0.0876 (0.1012)  loss_rpn_box_reg: 0.0216 (0.0344)  time: 0.2688  data: 0.1297  max mem: 1751\n",
      "Training Epoch: [30]  [ 230/1229]  eta: 0:04:32  lr: 0.000000  loss: 0.5361 (0.4388)  loss_classifier: 0.1846 (0.1560)  loss_box_reg: 0.1292 (0.1454)  loss_objectness: 0.0999 (0.1025)  loss_rpn_box_reg: 0.0225 (0.0350)  time: 0.2758  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [30]  [ 240/1229]  eta: 0:04:29  lr: 0.000000  loss: 0.4261 (0.4375)  loss_classifier: 0.1621 (0.1553)  loss_box_reg: 0.1292 (0.1457)  loss_objectness: 0.0837 (0.1017)  loss_rpn_box_reg: 0.0219 (0.0348)  time: 0.2764  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [30]  [ 250/1229]  eta: 0:04:27  lr: 0.000000  loss: 0.3796 (0.4352)  loss_classifier: 0.1322 (0.1547)  loss_box_reg: 0.1403 (0.1457)  loss_objectness: 0.0599 (0.1004)  loss_rpn_box_reg: 0.0239 (0.0345)  time: 0.2744  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [30]  [ 260/1229]  eta: 0:04:24  lr: 0.000000  loss: 0.3993 (0.4336)  loss_classifier: 0.1368 (0.1541)  loss_box_reg: 0.1451 (0.1452)  loss_objectness: 0.0608 (0.0998)  loss_rpn_box_reg: 0.0216 (0.0344)  time: 0.2740  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [30]  [ 270/1229]  eta: 0:04:21  lr: 0.000000  loss: 0.3185 (0.4351)  loss_classifier: 0.1368 (0.1548)  loss_box_reg: 0.1256 (0.1461)  loss_objectness: 0.0741 (0.0997)  loss_rpn_box_reg: 0.0258 (0.0345)  time: 0.2778  data: 0.1367  max mem: 1751\n",
      "Training Epoch: [30]  [ 280/1229]  eta: 0:04:19  lr: 0.000000  loss: 0.3773 (0.4343)  loss_classifier: 0.1447 (0.1546)  loss_box_reg: 0.1256 (0.1454)  loss_objectness: 0.0863 (0.1000)  loss_rpn_box_reg: 0.0285 (0.0343)  time: 0.2847  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [30]  [ 290/1229]  eta: 0:04:16  lr: 0.000000  loss: 0.4117 (0.4329)  loss_classifier: 0.1372 (0.1540)  loss_box_reg: 0.1268 (0.1448)  loss_objectness: 0.0938 (0.1002)  loss_rpn_box_reg: 0.0207 (0.0339)  time: 0.2777  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [30]  [ 300/1229]  eta: 0:04:13  lr: 0.000000  loss: 0.4117 (0.4372)  loss_classifier: 0.1395 (0.1553)  loss_box_reg: 0.1292 (0.1465)  loss_objectness: 0.0999 (0.1007)  loss_rpn_box_reg: 0.0236 (0.0346)  time: 0.2722  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [30]  [ 310/1229]  eta: 0:04:11  lr: 0.000000  loss: 0.4538 (0.4377)  loss_classifier: 0.1633 (0.1558)  loss_box_reg: 0.1199 (0.1472)  loss_objectness: 0.1001 (0.1003)  loss_rpn_box_reg: 0.0288 (0.0344)  time: 0.2749  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [30]  [ 320/1229]  eta: 0:04:08  lr: 0.000000  loss: 0.3741 (0.4391)  loss_classifier: 0.1398 (0.1562)  loss_box_reg: 0.1090 (0.1480)  loss_objectness: 0.1001 (0.1002)  loss_rpn_box_reg: 0.0174 (0.0346)  time: 0.2748  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [30]  [ 330/1229]  eta: 0:04:05  lr: 0.000000  loss: 0.3467 (0.4375)  loss_classifier: 0.1082 (0.1555)  loss_box_reg: 0.1033 (0.1473)  loss_objectness: 0.0848 (0.0998)  loss_rpn_box_reg: 0.0252 (0.0349)  time: 0.2711  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [30]  [ 340/1229]  eta: 0:04:03  lr: 0.000000  loss: 0.2691 (0.4345)  loss_classifier: 0.0943 (0.1546)  loss_box_reg: 0.0807 (0.1455)  loss_objectness: 0.0848 (0.0999)  loss_rpn_box_reg: 0.0252 (0.0346)  time: 0.2719  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [30]  [ 350/1229]  eta: 0:04:00  lr: 0.000000  loss: 0.3292 (0.4345)  loss_classifier: 0.1095 (0.1543)  loss_box_reg: 0.0813 (0.1454)  loss_objectness: 0.0950 (0.0998)  loss_rpn_box_reg: 0.0248 (0.0349)  time: 0.2698  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [30]  [ 360/1229]  eta: 0:03:57  lr: 0.000000  loss: 0.4045 (0.4346)  loss_classifier: 0.1338 (0.1540)  loss_box_reg: 0.1188 (0.1449)  loss_objectness: 0.0866 (0.1008)  loss_rpn_box_reg: 0.0273 (0.0349)  time: 0.2717  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [30]  [ 370/1229]  eta: 0:03:54  lr: 0.000000  loss: 0.4045 (0.4328)  loss_classifier: 0.1338 (0.1536)  loss_box_reg: 0.1157 (0.1443)  loss_objectness: 0.0858 (0.1004)  loss_rpn_box_reg: 0.0228 (0.0345)  time: 0.2725  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [30]  [ 380/1229]  eta: 0:03:51  lr: 0.000000  loss: 0.4181 (0.4344)  loss_classifier: 0.1511 (0.1544)  loss_box_reg: 0.1154 (0.1453)  loss_objectness: 0.0858 (0.1004)  loss_rpn_box_reg: 0.0184 (0.0342)  time: 0.2683  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [30]  [ 390/1229]  eta: 0:03:49  lr: 0.000000  loss: 0.2215 (0.4306)  loss_classifier: 0.0989 (0.1532)  loss_box_reg: 0.0612 (0.1434)  loss_objectness: 0.0797 (0.0998)  loss_rpn_box_reg: 0.0194 (0.0342)  time: 0.2709  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [30]  [ 400/1229]  eta: 0:03:46  lr: 0.000000  loss: 0.2604 (0.4309)  loss_classifier: 0.1045 (0.1535)  loss_box_reg: 0.0833 (0.1434)  loss_objectness: 0.0835 (0.0999)  loss_rpn_box_reg: 0.0193 (0.0340)  time: 0.2750  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [30]  [ 410/1229]  eta: 0:03:43  lr: 0.000000  loss: 0.5112 (0.4362)  loss_classifier: 0.1705 (0.1553)  loss_box_reg: 0.1669 (0.1461)  loss_objectness: 0.1072 (0.1005)  loss_rpn_box_reg: 0.0196 (0.0344)  time: 0.2794  data: 0.1380  max mem: 1751\n",
      "Training Epoch: [30]  [ 420/1229]  eta: 0:03:41  lr: 0.000000  loss: 0.5112 (0.4370)  loss_classifier: 0.1774 (0.1557)  loss_box_reg: 0.1710 (0.1461)  loss_objectness: 0.0992 (0.1007)  loss_rpn_box_reg: 0.0223 (0.0344)  time: 0.2758  data: 0.1377  max mem: 1751\n",
      "Training Epoch: [30]  [ 430/1229]  eta: 0:03:38  lr: 0.000000  loss: 0.4285 (0.4356)  loss_classifier: 0.1339 (0.1553)  loss_box_reg: 0.1164 (0.1454)  loss_objectness: 0.0857 (0.1007)  loss_rpn_box_reg: 0.0224 (0.0343)  time: 0.2706  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [30]  [ 440/1229]  eta: 0:03:35  lr: 0.000000  loss: 0.3180 (0.4365)  loss_classifier: 0.1257 (0.1554)  loss_box_reg: 0.1257 (0.1461)  loss_objectness: 0.0707 (0.1006)  loss_rpn_box_reg: 0.0227 (0.0344)  time: 0.2708  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [30]  [ 450/1229]  eta: 0:03:32  lr: 0.000000  loss: 0.3973 (0.4369)  loss_classifier: 0.1296 (0.1551)  loss_box_reg: 0.1475 (0.1463)  loss_objectness: 0.0720 (0.1005)  loss_rpn_box_reg: 0.0230 (0.0350)  time: 0.2711  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [30]  [ 460/1229]  eta: 0:03:29  lr: 0.000000  loss: 0.3973 (0.4352)  loss_classifier: 0.1296 (0.1544)  loss_box_reg: 0.1287 (0.1458)  loss_objectness: 0.0720 (0.1000)  loss_rpn_box_reg: 0.0230 (0.0349)  time: 0.2671  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [30]  [ 470/1229]  eta: 0:03:27  lr: 0.000000  loss: 0.3685 (0.4359)  loss_classifier: 0.1326 (0.1550)  loss_box_reg: 0.1189 (0.1459)  loss_objectness: 0.0726 (0.1002)  loss_rpn_box_reg: 0.0273 (0.0348)  time: 0.2723  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [30]  [ 480/1229]  eta: 0:03:24  lr: 0.000000  loss: 0.3211 (0.4345)  loss_classifier: 0.1238 (0.1546)  loss_box_reg: 0.0913 (0.1454)  loss_objectness: 0.0906 (0.0999)  loss_rpn_box_reg: 0.0209 (0.0345)  time: 0.2747  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [30]  [ 490/1229]  eta: 0:03:21  lr: 0.000000  loss: 0.3863 (0.4346)  loss_classifier: 0.1235 (0.1545)  loss_box_reg: 0.0935 (0.1454)  loss_objectness: 0.0702 (0.0996)  loss_rpn_box_reg: 0.0197 (0.0351)  time: 0.2673  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [30]  [ 500/1229]  eta: 0:03:19  lr: 0.000000  loss: 0.4096 (0.4346)  loss_classifier: 0.1289 (0.1545)  loss_box_reg: 0.1306 (0.1459)  loss_objectness: 0.0702 (0.0994)  loss_rpn_box_reg: 0.0308 (0.0349)  time: 0.2738  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [30]  [ 510/1229]  eta: 0:03:16  lr: 0.000000  loss: 0.4411 (0.4366)  loss_classifier: 0.1488 (0.1549)  loss_box_reg: 0.1432 (0.1471)  loss_objectness: 0.0861 (0.0995)  loss_rpn_box_reg: 0.0305 (0.0350)  time: 0.2801  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [30]  [ 520/1229]  eta: 0:03:13  lr: 0.000000  loss: 0.3806 (0.4364)  loss_classifier: 0.1488 (0.1547)  loss_box_reg: 0.1351 (0.1468)  loss_objectness: 0.0768 (0.0993)  loss_rpn_box_reg: 0.0352 (0.0356)  time: 0.2805  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [30]  [ 530/1229]  eta: 0:03:10  lr: 0.000000  loss: 0.3804 (0.4365)  loss_classifier: 0.1420 (0.1548)  loss_box_reg: 0.1129 (0.1467)  loss_objectness: 0.0718 (0.0992)  loss_rpn_box_reg: 0.0276 (0.0358)  time: 0.2747  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [30]  [ 540/1229]  eta: 0:03:08  lr: 0.000000  loss: 0.3154 (0.4335)  loss_classifier: 0.1157 (0.1537)  loss_box_reg: 0.1023 (0.1457)  loss_objectness: 0.0714 (0.0986)  loss_rpn_box_reg: 0.0153 (0.0354)  time: 0.2748  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [30]  [ 550/1229]  eta: 0:03:05  lr: 0.000000  loss: 0.3306 (0.4337)  loss_classifier: 0.1157 (0.1536)  loss_box_reg: 0.1204 (0.1463)  loss_objectness: 0.0761 (0.0985)  loss_rpn_box_reg: 0.0185 (0.0353)  time: 0.2795  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [30]  [ 560/1229]  eta: 0:03:02  lr: 0.000000  loss: 0.3677 (0.4343)  loss_classifier: 0.1300 (0.1535)  loss_box_reg: 0.1315 (0.1465)  loss_objectness: 0.0964 (0.0987)  loss_rpn_box_reg: 0.0238 (0.0356)  time: 0.2785  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [30]  [ 570/1229]  eta: 0:03:00  lr: 0.000000  loss: 0.3743 (0.4359)  loss_classifier: 0.1339 (0.1539)  loss_box_reg: 0.1019 (0.1473)  loss_objectness: 0.1156 (0.0989)  loss_rpn_box_reg: 0.0197 (0.0358)  time: 0.2809  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [30]  [ 580/1229]  eta: 0:02:57  lr: 0.000000  loss: 0.3103 (0.4355)  loss_classifier: 0.1017 (0.1536)  loss_box_reg: 0.1038 (0.1471)  loss_objectness: 0.0995 (0.0990)  loss_rpn_box_reg: 0.0170 (0.0357)  time: 0.2757  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [30]  [ 590/1229]  eta: 0:02:54  lr: 0.000000  loss: 0.3103 (0.4357)  loss_classifier: 0.1185 (0.1537)  loss_box_reg: 0.1339 (0.1476)  loss_objectness: 0.0772 (0.0988)  loss_rpn_box_reg: 0.0209 (0.0357)  time: 0.2705  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [30]  [ 600/1229]  eta: 0:02:52  lr: 0.000000  loss: 0.4113 (0.4349)  loss_classifier: 0.1530 (0.1536)  loss_box_reg: 0.1240 (0.1471)  loss_objectness: 0.0846 (0.0988)  loss_rpn_box_reg: 0.0180 (0.0355)  time: 0.2739  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [30]  [ 610/1229]  eta: 0:02:49  lr: 0.000000  loss: 0.3238 (0.4338)  loss_classifier: 0.1519 (0.1534)  loss_box_reg: 0.0969 (0.1467)  loss_objectness: 0.0846 (0.0986)  loss_rpn_box_reg: 0.0144 (0.0351)  time: 0.2789  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [30]  [ 620/1229]  eta: 0:02:46  lr: 0.000000  loss: 0.3041 (0.4336)  loss_classifier: 0.1294 (0.1533)  loss_box_reg: 0.1066 (0.1469)  loss_objectness: 0.0713 (0.0984)  loss_rpn_box_reg: 0.0205 (0.0350)  time: 0.2791  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [30]  [ 630/1229]  eta: 0:02:44  lr: 0.000000  loss: 0.4392 (0.4350)  loss_classifier: 0.1699 (0.1540)  loss_box_reg: 0.1588 (0.1471)  loss_objectness: 0.0821 (0.0986)  loss_rpn_box_reg: 0.0272 (0.0353)  time: 0.2778  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [30]  [ 640/1229]  eta: 0:02:41  lr: 0.000000  loss: 0.4886 (0.4362)  loss_classifier: 0.1849 (0.1543)  loss_box_reg: 0.1626 (0.1479)  loss_objectness: 0.1005 (0.0985)  loss_rpn_box_reg: 0.0277 (0.0354)  time: 0.2766  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [30]  [ 650/1229]  eta: 0:02:38  lr: 0.000000  loss: 0.3442 (0.4342)  loss_classifier: 0.1203 (0.1536)  loss_box_reg: 0.1024 (0.1471)  loss_objectness: 0.0710 (0.0982)  loss_rpn_box_reg: 0.0127 (0.0353)  time: 0.2743  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [30]  [ 660/1229]  eta: 0:02:35  lr: 0.000000  loss: 0.3442 (0.4340)  loss_classifier: 0.1203 (0.1536)  loss_box_reg: 0.0979 (0.1474)  loss_objectness: 0.0710 (0.0980)  loss_rpn_box_reg: 0.0112 (0.0350)  time: 0.2761  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [30]  [ 670/1229]  eta: 0:02:33  lr: 0.000000  loss: 0.3202 (0.4325)  loss_classifier: 0.1201 (0.1530)  loss_box_reg: 0.0906 (0.1466)  loss_objectness: 0.0875 (0.0980)  loss_rpn_box_reg: 0.0168 (0.0348)  time: 0.2731  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [30]  [ 680/1229]  eta: 0:02:30  lr: 0.000000  loss: 0.3261 (0.4335)  loss_classifier: 0.1292 (0.1534)  loss_box_reg: 0.0923 (0.1472)  loss_objectness: 0.1007 (0.0982)  loss_rpn_box_reg: 0.0243 (0.0348)  time: 0.2727  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [30]  [ 690/1229]  eta: 0:02:27  lr: 0.000000  loss: 0.4088 (0.4333)  loss_classifier: 0.1434 (0.1533)  loss_box_reg: 0.1462 (0.1473)  loss_objectness: 0.0744 (0.0979)  loss_rpn_box_reg: 0.0194 (0.0348)  time: 0.2746  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [30]  [ 700/1229]  eta: 0:02:24  lr: 0.000000  loss: 0.4183 (0.4344)  loss_classifier: 0.1471 (0.1537)  loss_box_reg: 0.1368 (0.1474)  loss_objectness: 0.0904 (0.0983)  loss_rpn_box_reg: 0.0240 (0.0349)  time: 0.2740  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [30]  [ 710/1229]  eta: 0:02:22  lr: 0.000000  loss: 0.5402 (0.4365)  loss_classifier: 0.1731 (0.1544)  loss_box_reg: 0.1467 (0.1481)  loss_objectness: 0.1398 (0.0987)  loss_rpn_box_reg: 0.0371 (0.0353)  time: 0.2797  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [30]  [ 720/1229]  eta: 0:02:19  lr: 0.000000  loss: 0.4293 (0.4357)  loss_classifier: 0.1527 (0.1542)  loss_box_reg: 0.1251 (0.1478)  loss_objectness: 0.0790 (0.0985)  loss_rpn_box_reg: 0.0371 (0.0352)  time: 0.2822  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [30]  [ 730/1229]  eta: 0:02:16  lr: 0.000000  loss: 0.3582 (0.4358)  loss_classifier: 0.1326 (0.1544)  loss_box_reg: 0.0963 (0.1476)  loss_objectness: 0.0651 (0.0987)  loss_rpn_box_reg: 0.0268 (0.0352)  time: 0.2751  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [30]  [ 740/1229]  eta: 0:02:14  lr: 0.000000  loss: 0.3603 (0.4356)  loss_classifier: 0.1365 (0.1544)  loss_box_reg: 0.1146 (0.1476)  loss_objectness: 0.1090 (0.0986)  loss_rpn_box_reg: 0.0206 (0.0350)  time: 0.2777  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [30]  [ 750/1229]  eta: 0:02:11  lr: 0.000000  loss: 0.3349 (0.4343)  loss_classifier: 0.1158 (0.1539)  loss_box_reg: 0.0897 (0.1471)  loss_objectness: 0.1083 (0.0986)  loss_rpn_box_reg: 0.0113 (0.0348)  time: 0.2813  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [30]  [ 760/1229]  eta: 0:02:08  lr: 0.000000  loss: 0.3349 (0.4349)  loss_classifier: 0.1158 (0.1541)  loss_box_reg: 0.1129 (0.1473)  loss_objectness: 0.0937 (0.0989)  loss_rpn_box_reg: 0.0113 (0.0347)  time: 0.2813  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [30]  [ 770/1229]  eta: 0:02:06  lr: 0.000000  loss: 0.4944 (0.4353)  loss_classifier: 0.1709 (0.1541)  loss_box_reg: 0.1263 (0.1472)  loss_objectness: 0.0963 (0.0991)  loss_rpn_box_reg: 0.0164 (0.0349)  time: 0.2850  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [30]  [ 780/1229]  eta: 0:02:03  lr: 0.000000  loss: 0.3597 (0.4338)  loss_classifier: 0.1318 (0.1536)  loss_box_reg: 0.1051 (0.1467)  loss_objectness: 0.0649 (0.0986)  loss_rpn_box_reg: 0.0295 (0.0348)  time: 0.2811  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [30]  [ 790/1229]  eta: 0:02:00  lr: 0.000000  loss: 0.3777 (0.4343)  loss_classifier: 0.1382 (0.1539)  loss_box_reg: 0.1343 (0.1470)  loss_objectness: 0.0707 (0.0986)  loss_rpn_box_reg: 0.0283 (0.0347)  time: 0.2777  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [30]  [ 800/1229]  eta: 0:01:57  lr: 0.000000  loss: 0.4253 (0.4341)  loss_classifier: 0.1562 (0.1539)  loss_box_reg: 0.1564 (0.1470)  loss_objectness: 0.0788 (0.0984)  loss_rpn_box_reg: 0.0265 (0.0347)  time: 0.2794  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [30]  [ 810/1229]  eta: 0:01:55  lr: 0.000000  loss: 0.4068 (0.4343)  loss_classifier: 0.1447 (0.1540)  loss_box_reg: 0.1564 (0.1474)  loss_objectness: 0.0684 (0.0983)  loss_rpn_box_reg: 0.0218 (0.0346)  time: 0.2773  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [30]  [ 820/1229]  eta: 0:01:52  lr: 0.000000  loss: 0.4017 (0.4337)  loss_classifier: 0.1340 (0.1538)  loss_box_reg: 0.1428 (0.1472)  loss_objectness: 0.0948 (0.0982)  loss_rpn_box_reg: 0.0216 (0.0345)  time: 0.2740  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [30]  [ 830/1229]  eta: 0:01:49  lr: 0.000000  loss: 0.4017 (0.4335)  loss_classifier: 0.1454 (0.1537)  loss_box_reg: 0.1252 (0.1469)  loss_objectness: 0.0983 (0.0983)  loss_rpn_box_reg: 0.0162 (0.0346)  time: 0.2691  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [30]  [ 840/1229]  eta: 0:01:46  lr: 0.000000  loss: 0.4859 (0.4333)  loss_classifier: 0.1453 (0.1536)  loss_box_reg: 0.1075 (0.1466)  loss_objectness: 0.0983 (0.0983)  loss_rpn_box_reg: 0.0169 (0.0347)  time: 0.2670  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [30]  [ 850/1229]  eta: 0:01:44  lr: 0.000000  loss: 0.3048 (0.4320)  loss_classifier: 0.1196 (0.1532)  loss_box_reg: 0.0954 (0.1463)  loss_objectness: 0.0692 (0.0979)  loss_rpn_box_reg: 0.0161 (0.0346)  time: 0.2731  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [30]  [ 860/1229]  eta: 0:01:41  lr: 0.000000  loss: 0.2841 (0.4317)  loss_classifier: 0.1070 (0.1530)  loss_box_reg: 0.0923 (0.1461)  loss_objectness: 0.0747 (0.0978)  loss_rpn_box_reg: 0.0145 (0.0347)  time: 0.2748  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [30]  [ 870/1229]  eta: 0:01:38  lr: 0.000000  loss: 0.3662 (0.4319)  loss_classifier: 0.1339 (0.1531)  loss_box_reg: 0.1158 (0.1461)  loss_objectness: 0.0958 (0.0980)  loss_rpn_box_reg: 0.0193 (0.0346)  time: 0.2730  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [30]  [ 880/1229]  eta: 0:01:35  lr: 0.000000  loss: 0.4338 (0.4318)  loss_classifier: 0.1646 (0.1532)  loss_box_reg: 0.1234 (0.1460)  loss_objectness: 0.0997 (0.0982)  loss_rpn_box_reg: 0.0278 (0.0345)  time: 0.2731  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [30]  [ 890/1229]  eta: 0:01:33  lr: 0.000000  loss: 0.3592 (0.4314)  loss_classifier: 0.1202 (0.1530)  loss_box_reg: 0.1234 (0.1461)  loss_objectness: 0.0695 (0.0980)  loss_rpn_box_reg: 0.0182 (0.0343)  time: 0.2691  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [30]  [ 900/1229]  eta: 0:01:30  lr: 0.000000  loss: 0.3446 (0.4311)  loss_classifier: 0.1339 (0.1530)  loss_box_reg: 0.1127 (0.1457)  loss_objectness: 0.0816 (0.0982)  loss_rpn_box_reg: 0.0133 (0.0342)  time: 0.2727  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [30]  [ 910/1229]  eta: 0:01:27  lr: 0.000000  loss: 0.4181 (0.4319)  loss_classifier: 0.1503 (0.1532)  loss_box_reg: 0.1127 (0.1457)  loss_objectness: 0.1054 (0.0984)  loss_rpn_box_reg: 0.0279 (0.0345)  time: 0.2747  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [30]  [ 920/1229]  eta: 0:01:24  lr: 0.000000  loss: 0.4527 (0.4332)  loss_classifier: 0.1681 (0.1535)  loss_box_reg: 0.1530 (0.1462)  loss_objectness: 0.1060 (0.0987)  loss_rpn_box_reg: 0.0366 (0.0347)  time: 0.2742  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [30]  [ 930/1229]  eta: 0:01:22  lr: 0.000000  loss: 0.4653 (0.4339)  loss_classifier: 0.1499 (0.1537)  loss_box_reg: 0.1619 (0.1465)  loss_objectness: 0.1034 (0.0988)  loss_rpn_box_reg: 0.0224 (0.0349)  time: 0.2774  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [30]  [ 940/1229]  eta: 0:01:19  lr: 0.000000  loss: 0.3978 (0.4331)  loss_classifier: 0.1466 (0.1534)  loss_box_reg: 0.1047 (0.1462)  loss_objectness: 0.0823 (0.0986)  loss_rpn_box_reg: 0.0204 (0.0348)  time: 0.2731  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [30]  [ 950/1229]  eta: 0:01:16  lr: 0.000000  loss: 0.3978 (0.4339)  loss_classifier: 0.1433 (0.1537)  loss_box_reg: 0.1047 (0.1467)  loss_objectness: 0.0823 (0.0988)  loss_rpn_box_reg: 0.0203 (0.0348)  time: 0.2693  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [30]  [ 960/1229]  eta: 0:01:13  lr: 0.000000  loss: 0.4011 (0.4335)  loss_classifier: 0.1433 (0.1536)  loss_box_reg: 0.1395 (0.1465)  loss_objectness: 0.0980 (0.0988)  loss_rpn_box_reg: 0.0139 (0.0346)  time: 0.2696  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [30]  [ 970/1229]  eta: 0:01:11  lr: 0.000000  loss: 0.3785 (0.4336)  loss_classifier: 0.1311 (0.1536)  loss_box_reg: 0.1274 (0.1466)  loss_objectness: 0.0759 (0.0987)  loss_rpn_box_reg: 0.0170 (0.0347)  time: 0.2704  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [30]  [ 980/1229]  eta: 0:01:08  lr: 0.000000  loss: 0.3642 (0.4333)  loss_classifier: 0.1311 (0.1535)  loss_box_reg: 0.1246 (0.1466)  loss_objectness: 0.0773 (0.0987)  loss_rpn_box_reg: 0.0169 (0.0345)  time: 0.2705  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [30]  [ 990/1229]  eta: 0:01:05  lr: 0.000000  loss: 0.3642 (0.4335)  loss_classifier: 0.1477 (0.1536)  loss_box_reg: 0.1177 (0.1464)  loss_objectness: 0.0802 (0.0987)  loss_rpn_box_reg: 0.0212 (0.0348)  time: 0.2772  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [30]  [1000/1229]  eta: 0:01:02  lr: 0.000000  loss: 0.5159 (0.4344)  loss_classifier: 0.1868 (0.1541)  loss_box_reg: 0.1445 (0.1466)  loss_objectness: 0.1066 (0.0989)  loss_rpn_box_reg: 0.0261 (0.0348)  time: 0.2758  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [30]  [1010/1229]  eta: 0:01:00  lr: 0.000000  loss: 0.4591 (0.4350)  loss_classifier: 0.1631 (0.1543)  loss_box_reg: 0.1471 (0.1469)  loss_objectness: 0.1032 (0.0990)  loss_rpn_box_reg: 0.0221 (0.0348)  time: 0.2718  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [30]  [1020/1229]  eta: 0:00:57  lr: 0.000000  loss: 0.3861 (0.4348)  loss_classifier: 0.1475 (0.1543)  loss_box_reg: 0.1294 (0.1467)  loss_objectness: 0.0802 (0.0991)  loss_rpn_box_reg: 0.0229 (0.0348)  time: 0.2772  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [30]  [1030/1229]  eta: 0:00:54  lr: 0.000000  loss: 0.4578 (0.4356)  loss_classifier: 0.1740 (0.1547)  loss_box_reg: 0.1354 (0.1470)  loss_objectness: 0.0938 (0.0991)  loss_rpn_box_reg: 0.0256 (0.0348)  time: 0.2784  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [30]  [1040/1229]  eta: 0:00:51  lr: 0.000000  loss: 0.5065 (0.4362)  loss_classifier: 0.1805 (0.1549)  loss_box_reg: 0.1859 (0.1474)  loss_objectness: 0.0938 (0.0990)  loss_rpn_box_reg: 0.0300 (0.0349)  time: 0.2798  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [30]  [1050/1229]  eta: 0:00:49  lr: 0.000000  loss: 0.4185 (0.4351)  loss_classifier: 0.1477 (0.1546)  loss_box_reg: 0.1226 (0.1470)  loss_objectness: 0.0803 (0.0988)  loss_rpn_box_reg: 0.0204 (0.0347)  time: 0.2830  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [30]  [1060/1229]  eta: 0:00:46  lr: 0.000000  loss: 0.3218 (0.4350)  loss_classifier: 0.1243 (0.1546)  loss_box_reg: 0.1226 (0.1470)  loss_objectness: 0.0667 (0.0987)  loss_rpn_box_reg: 0.0096 (0.0347)  time: 0.2733  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [30]  [1070/1229]  eta: 0:00:43  lr: 0.000000  loss: 0.3766 (0.4355)  loss_classifier: 0.1328 (0.1548)  loss_box_reg: 0.1322 (0.1473)  loss_objectness: 0.0709 (0.0987)  loss_rpn_box_reg: 0.0222 (0.0347)  time: 0.2683  data: 0.1368  max mem: 1751\n",
      "Training Epoch: [30]  [1080/1229]  eta: 0:00:40  lr: 0.000000  loss: 0.3766 (0.4352)  loss_classifier: 0.1328 (0.1547)  loss_box_reg: 0.1179 (0.1472)  loss_objectness: 0.0709 (0.0986)  loss_rpn_box_reg: 0.0242 (0.0347)  time: 0.2780  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [30]  [1090/1229]  eta: 0:00:38  lr: 0.000000  loss: 0.3316 (0.4344)  loss_classifier: 0.1138 (0.1544)  loss_box_reg: 0.0985 (0.1469)  loss_objectness: 0.0831 (0.0985)  loss_rpn_box_reg: 0.0249 (0.0346)  time: 0.2712  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [30]  [1100/1229]  eta: 0:00:35  lr: 0.000000  loss: 0.2527 (0.4331)  loss_classifier: 0.0899 (0.1540)  loss_box_reg: 0.0767 (0.1464)  loss_objectness: 0.0715 (0.0982)  loss_rpn_box_reg: 0.0145 (0.0345)  time: 0.2648  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [30]  [1110/1229]  eta: 0:00:32  lr: 0.000000  loss: 0.2645 (0.4325)  loss_classifier: 0.0908 (0.1539)  loss_box_reg: 0.0751 (0.1460)  loss_objectness: 0.0691 (0.0982)  loss_rpn_box_reg: 0.0090 (0.0344)  time: 0.2720  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [30]  [1120/1229]  eta: 0:00:29  lr: 0.000000  loss: 0.3439 (0.4322)  loss_classifier: 0.1277 (0.1538)  loss_box_reg: 0.1127 (0.1459)  loss_objectness: 0.0829 (0.0982)  loss_rpn_box_reg: 0.0147 (0.0343)  time: 0.2782  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [30]  [1130/1229]  eta: 0:00:27  lr: 0.000000  loss: 0.3118 (0.4318)  loss_classifier: 0.1088 (0.1536)  loss_box_reg: 0.1011 (0.1458)  loss_objectness: 0.0699 (0.0981)  loss_rpn_box_reg: 0.0207 (0.0342)  time: 0.2715  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [30]  [1140/1229]  eta: 0:00:24  lr: 0.000000  loss: 0.3118 (0.4325)  loss_classifier: 0.1317 (0.1539)  loss_box_reg: 0.1092 (0.1463)  loss_objectness: 0.0756 (0.0981)  loss_rpn_box_reg: 0.0212 (0.0342)  time: 0.2696  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [30]  [1150/1229]  eta: 0:00:21  lr: 0.000000  loss: 0.4267 (0.4331)  loss_classifier: 0.1656 (0.1543)  loss_box_reg: 0.1218 (0.1465)  loss_objectness: 0.1032 (0.0982)  loss_rpn_box_reg: 0.0249 (0.0341)  time: 0.2802  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [30]  [1160/1229]  eta: 0:00:18  lr: 0.000000  loss: 0.4659 (0.4336)  loss_classifier: 0.1714 (0.1546)  loss_box_reg: 0.1396 (0.1468)  loss_objectness: 0.1032 (0.0981)  loss_rpn_box_reg: 0.0249 (0.0341)  time: 0.2776  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [30]  [1170/1229]  eta: 0:00:16  lr: 0.000000  loss: 0.4589 (0.4334)  loss_classifier: 0.1714 (0.1545)  loss_box_reg: 0.1453 (0.1466)  loss_objectness: 0.0917 (0.0981)  loss_rpn_box_reg: 0.0204 (0.0341)  time: 0.2738  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [30]  [1180/1229]  eta: 0:00:13  lr: 0.000000  loss: 0.3028 (0.4324)  loss_classifier: 0.1011 (0.1541)  loss_box_reg: 0.0773 (0.1464)  loss_objectness: 0.0653 (0.0979)  loss_rpn_box_reg: 0.0162 (0.0340)  time: 0.2684  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [30]  [1190/1229]  eta: 0:00:10  lr: 0.000000  loss: 0.2782 (0.4319)  loss_classifier: 0.1011 (0.1540)  loss_box_reg: 0.0806 (0.1462)  loss_objectness: 0.0619 (0.0979)  loss_rpn_box_reg: 0.0113 (0.0339)  time: 0.2681  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [30]  [1200/1229]  eta: 0:00:07  lr: 0.000000  loss: 0.3753 (0.4322)  loss_classifier: 0.1368 (0.1540)  loss_box_reg: 0.1484 (0.1464)  loss_objectness: 0.0794 (0.0979)  loss_rpn_box_reg: 0.0113 (0.0338)  time: 0.2682  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [30]  [1210/1229]  eta: 0:00:05  lr: 0.000000  loss: 0.3943 (0.4322)  loss_classifier: 0.1632 (0.1541)  loss_box_reg: 0.1545 (0.1465)  loss_objectness: 0.0841 (0.0978)  loss_rpn_box_reg: 0.0184 (0.0338)  time: 0.2718  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [30]  [1220/1229]  eta: 0:00:02  lr: 0.000000  loss: 0.3369 (0.4318)  loss_classifier: 0.1187 (0.1539)  loss_box_reg: 0.1198 (0.1464)  loss_objectness: 0.0868 (0.0977)  loss_rpn_box_reg: 0.0193 (0.0338)  time: 0.2781  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [30]  [1228/1229]  eta: 0:00:00  lr: 0.000000  loss: 0.4003 (0.4320)  loss_classifier: 0.1187 (0.1539)  loss_box_reg: 0.1243 (0.1464)  loss_objectness: 0.0797 (0.0978)  loss_rpn_box_reg: 0.0293 (0.0339)  time: 0.2743  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [30] Total time: 0:05:37 (0.2743 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:39  model_time: 0.2890 (0.2890)  evaluator_time: 0.0020 (0.0020)  time: 0.3220  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0800 (0.0822)  evaluator_time: 0.0040 (0.0086)  time: 0.1328  data: 0.0409  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0840 (0.0812)  evaluator_time: 0.0030 (0.0079)  time: 0.1249  data: 0.0359  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0740 (0.0803)  evaluator_time: 0.0040 (0.0077)  time: 0.1195  data: 0.0352  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0720 (0.0802)  evaluator_time: 0.0030 (0.0076)  time: 0.1165  data: 0.0335  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1243 s / it)\n",
      "Averaged stats: model_time: 0.0720 (0.0802)  evaluator_time: 0.0030 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [30]  [  0/308]  eta: 0:00:38  lr: 0.000000  loss: 0.1718 (0.1718)  loss_classifier: 0.0592 (0.0592)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0327 (0.0327)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1260  data: 0.0310  max mem: 1751\n",
      "Testing Epoch: [30]  [100/308]  eta: 0:00:29  lr: 0.000000  loss: 0.3140 (0.4809)  loss_classifier: 0.1337 (0.1543)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0577 (0.1022)  loss_rpn_box_reg: 0.0186 (0.0520)  time: 0.1402  data: 0.0375  max mem: 1751\n",
      "Testing Epoch: [30]  [200/308]  eta: 0:00:14  lr: 0.000000  loss: 0.3459 (0.4566)  loss_classifier: 0.1399 (0.1489)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0721 (0.0953)  loss_rpn_box_reg: 0.0197 (0.0491)  time: 0.1414  data: 0.0365  max mem: 1751\n",
      "Testing Epoch: [30]  [300/308]  eta: 0:00:01  lr: 0.000000  loss: 0.4571 (0.4533)  loss_classifier: 0.1564 (0.1491)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0802 (0.0926)  loss_rpn_box_reg: 0.0265 (0.0475)  time: 0.1385  data: 0.0433  max mem: 1751\n",
      "Testing Epoch: [30]  [307/308]  eta: 0:00:00  lr: 0.000000  loss: 0.4571 (0.4535)  loss_classifier: 0.1860 (0.1493)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0742 (0.0926)  loss_rpn_box_reg: 0.0271 (0.0471)  time: 0.1370  data: 0.0416  max mem: 1751\n",
      "Testing Epoch: [30] Total time: 0:00:42 (0.1375 s / it)\n",
      "Training Epoch: [31]  [   0/1229]  eta: 0:05:19  lr: 0.000000  loss: 0.1287 (0.1287)  loss_classifier: 0.0595 (0.0595)  loss_box_reg: 0.0385 (0.0385)  loss_objectness: 0.0291 (0.0291)  loss_rpn_box_reg: 0.0016 (0.0016)  time: 0.2600  data: 0.1270  max mem: 1751\n",
      "Training Epoch: [31]  [  10/1229]  eta: 0:05:31  lr: 0.000000  loss: 0.3461 (0.4543)  loss_classifier: 0.1216 (0.1583)  loss_box_reg: 0.1505 (0.1586)  loss_objectness: 0.0839 (0.0932)  loss_rpn_box_reg: 0.0155 (0.0443)  time: 0.2719  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [31]  [  20/1229]  eta: 0:05:31  lr: 0.000000  loss: 0.4324 (0.4540)  loss_classifier: 0.1509 (0.1634)  loss_box_reg: 0.1505 (0.1640)  loss_objectness: 0.0806 (0.0917)  loss_rpn_box_reg: 0.0190 (0.0349)  time: 0.2747  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [31]  [  30/1229]  eta: 0:05:27  lr: 0.000000  loss: 0.4676 (0.4593)  loss_classifier: 0.1785 (0.1686)  loss_box_reg: 0.1320 (0.1580)  loss_objectness: 0.0920 (0.0976)  loss_rpn_box_reg: 0.0218 (0.0351)  time: 0.2736  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [31]  [  40/1229]  eta: 0:05:27  lr: 0.000000  loss: 0.4203 (0.4509)  loss_classifier: 0.1473 (0.1632)  loss_box_reg: 0.1301 (0.1529)  loss_objectness: 0.1093 (0.1015)  loss_rpn_box_reg: 0.0218 (0.0333)  time: 0.2763  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [31]  [  50/1229]  eta: 0:05:25  lr: 0.000000  loss: 0.3566 (0.4267)  loss_classifier: 0.1282 (0.1548)  loss_box_reg: 0.1171 (0.1443)  loss_objectness: 0.0771 (0.0963)  loss_rpn_box_reg: 0.0185 (0.0313)  time: 0.2808  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [31]  [  60/1229]  eta: 0:05:21  lr: 0.000000  loss: 0.3334 (0.4342)  loss_classifier: 0.1189 (0.1581)  loss_box_reg: 0.1171 (0.1435)  loss_objectness: 0.0771 (0.1003)  loss_rpn_box_reg: 0.0185 (0.0324)  time: 0.2750  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [31]  [  70/1229]  eta: 0:05:19  lr: 0.000000  loss: 0.4569 (0.4402)  loss_classifier: 0.1558 (0.1602)  loss_box_reg: 0.1167 (0.1427)  loss_objectness: 0.0912 (0.1058)  loss_rpn_box_reg: 0.0266 (0.0315)  time: 0.2738  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [31]  [  80/1229]  eta: 0:05:15  lr: 0.000000  loss: 0.3087 (0.4239)  loss_classifier: 0.1077 (0.1544)  loss_box_reg: 0.0904 (0.1360)  loss_objectness: 0.0796 (0.1024)  loss_rpn_box_reg: 0.0131 (0.0311)  time: 0.2741  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [31]  [  90/1229]  eta: 0:05:12  lr: 0.000000  loss: 0.3087 (0.4267)  loss_classifier: 0.1077 (0.1549)  loss_box_reg: 0.1030 (0.1402)  loss_objectness: 0.0691 (0.1009)  loss_rpn_box_reg: 0.0118 (0.0307)  time: 0.2699  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [31]  [ 100/1229]  eta: 0:05:09  lr: 0.000000  loss: 0.3803 (0.4276)  loss_classifier: 0.1344 (0.1551)  loss_box_reg: 0.1198 (0.1409)  loss_objectness: 0.0776 (0.1012)  loss_rpn_box_reg: 0.0142 (0.0304)  time: 0.2712  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [31]  [ 110/1229]  eta: 0:05:06  lr: 0.000000  loss: 0.4343 (0.4392)  loss_classifier: 0.1521 (0.1591)  loss_box_reg: 0.1473 (0.1451)  loss_objectness: 0.0952 (0.1039)  loss_rpn_box_reg: 0.0184 (0.0312)  time: 0.2749  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [31]  [ 120/1229]  eta: 0:05:04  lr: 0.000000  loss: 0.4261 (0.4340)  loss_classifier: 0.1700 (0.1572)  loss_box_reg: 0.1259 (0.1442)  loss_objectness: 0.0907 (0.1020)  loss_rpn_box_reg: 0.0178 (0.0306)  time: 0.2743  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [31]  [ 130/1229]  eta: 0:05:01  lr: 0.000000  loss: 0.3868 (0.4404)  loss_classifier: 0.1470 (0.1599)  loss_box_reg: 0.1107 (0.1460)  loss_objectness: 0.0751 (0.1029)  loss_rpn_box_reg: 0.0183 (0.0317)  time: 0.2761  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [31]  [ 140/1229]  eta: 0:05:00  lr: 0.000000  loss: 0.4064 (0.4393)  loss_classifier: 0.1470 (0.1598)  loss_box_reg: 0.1469 (0.1464)  loss_objectness: 0.0751 (0.1014)  loss_rpn_box_reg: 0.0240 (0.0316)  time: 0.2846  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [31]  [ 150/1229]  eta: 0:04:57  lr: 0.000000  loss: 0.3887 (0.4402)  loss_classifier: 0.1370 (0.1586)  loss_box_reg: 0.1400 (0.1460)  loss_objectness: 0.0881 (0.1033)  loss_rpn_box_reg: 0.0240 (0.0323)  time: 0.2821  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [31]  [ 160/1229]  eta: 0:04:54  lr: 0.000000  loss: 0.3887 (0.4391)  loss_classifier: 0.1390 (0.1579)  loss_box_reg: 0.1293 (0.1461)  loss_objectness: 0.0921 (0.1034)  loss_rpn_box_reg: 0.0200 (0.0316)  time: 0.2754  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [31]  [ 170/1229]  eta: 0:04:52  lr: 0.000000  loss: 0.4418 (0.4408)  loss_classifier: 0.1659 (0.1584)  loss_box_reg: 0.1506 (0.1475)  loss_objectness: 0.0835 (0.1031)  loss_rpn_box_reg: 0.0191 (0.0317)  time: 0.2773  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [31]  [ 180/1229]  eta: 0:04:49  lr: 0.000000  loss: 0.3624 (0.4355)  loss_classifier: 0.1259 (0.1565)  loss_box_reg: 0.1292 (0.1467)  loss_objectness: 0.0608 (0.1008)  loss_rpn_box_reg: 0.0180 (0.0314)  time: 0.2814  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [31]  [ 190/1229]  eta: 0:04:47  lr: 0.000000  loss: 0.2959 (0.4356)  loss_classifier: 0.1073 (0.1565)  loss_box_reg: 0.1129 (0.1480)  loss_objectness: 0.0506 (0.0997)  loss_rpn_box_reg: 0.0180 (0.0315)  time: 0.2801  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [31]  [ 200/1229]  eta: 0:04:44  lr: 0.000000  loss: 0.2890 (0.4300)  loss_classifier: 0.1064 (0.1548)  loss_box_reg: 0.1005 (0.1458)  loss_objectness: 0.0574 (0.0984)  loss_rpn_box_reg: 0.0186 (0.0310)  time: 0.2753  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [31]  [ 210/1229]  eta: 0:04:41  lr: 0.000000  loss: 0.2942 (0.4289)  loss_classifier: 0.1267 (0.1544)  loss_box_reg: 0.0925 (0.1451)  loss_objectness: 0.0609 (0.0980)  loss_rpn_box_reg: 0.0172 (0.0315)  time: 0.2787  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [31]  [ 220/1229]  eta: 0:04:38  lr: 0.000000  loss: 0.2802 (0.4237)  loss_classifier: 0.1075 (0.1527)  loss_box_reg: 0.1065 (0.1437)  loss_objectness: 0.0686 (0.0967)  loss_rpn_box_reg: 0.0136 (0.0307)  time: 0.2784  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [31]  [ 230/1229]  eta: 0:04:35  lr: 0.000000  loss: 0.3055 (0.4214)  loss_classifier: 0.1182 (0.1523)  loss_box_reg: 0.1021 (0.1425)  loss_objectness: 0.0719 (0.0966)  loss_rpn_box_reg: 0.0133 (0.0300)  time: 0.2734  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [31]  [ 240/1229]  eta: 0:04:33  lr: 0.000000  loss: 0.3601 (0.4216)  loss_classifier: 0.1354 (0.1521)  loss_box_reg: 0.1021 (0.1422)  loss_objectness: 0.0753 (0.0968)  loss_rpn_box_reg: 0.0185 (0.0306)  time: 0.2743  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [31]  [ 250/1229]  eta: 0:04:29  lr: 0.000000  loss: 0.3878 (0.4203)  loss_classifier: 0.1192 (0.1514)  loss_box_reg: 0.1053 (0.1415)  loss_objectness: 0.0745 (0.0967)  loss_rpn_box_reg: 0.0267 (0.0308)  time: 0.2704  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [31]  [ 260/1229]  eta: 0:04:27  lr: 0.000000  loss: 0.3878 (0.4201)  loss_classifier: 0.1464 (0.1515)  loss_box_reg: 0.1178 (0.1416)  loss_objectness: 0.0870 (0.0965)  loss_rpn_box_reg: 0.0191 (0.0306)  time: 0.2708  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [31]  [ 270/1229]  eta: 0:04:24  lr: 0.000000  loss: 0.4531 (0.4247)  loss_classifier: 0.1534 (0.1529)  loss_box_reg: 0.1345 (0.1421)  loss_objectness: 0.0925 (0.0977)  loss_rpn_box_reg: 0.0251 (0.0319)  time: 0.2767  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [31]  [ 280/1229]  eta: 0:04:21  lr: 0.000000  loss: 0.4168 (0.4242)  loss_classifier: 0.1520 (0.1527)  loss_box_reg: 0.1210 (0.1417)  loss_objectness: 0.1006 (0.0977)  loss_rpn_box_reg: 0.0298 (0.0321)  time: 0.2755  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [31]  [ 290/1229]  eta: 0:04:18  lr: 0.000000  loss: 0.3948 (0.4240)  loss_classifier: 0.1410 (0.1527)  loss_box_reg: 0.1161 (0.1414)  loss_objectness: 0.1030 (0.0977)  loss_rpn_box_reg: 0.0255 (0.0322)  time: 0.2714  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [31]  [ 300/1229]  eta: 0:04:15  lr: 0.000000  loss: 0.3845 (0.4268)  loss_classifier: 0.1466 (0.1532)  loss_box_reg: 0.1028 (0.1426)  loss_objectness: 0.1047 (0.0986)  loss_rpn_box_reg: 0.0230 (0.0325)  time: 0.2722  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [31]  [ 310/1229]  eta: 0:04:12  lr: 0.000000  loss: 0.3465 (0.4253)  loss_classifier: 0.1261 (0.1523)  loss_box_reg: 0.1081 (0.1419)  loss_objectness: 0.0998 (0.0984)  loss_rpn_box_reg: 0.0251 (0.0327)  time: 0.2717  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [31]  [ 320/1229]  eta: 0:04:10  lr: 0.000000  loss: 0.3309 (0.4238)  loss_classifier: 0.1261 (0.1516)  loss_box_reg: 0.1081 (0.1409)  loss_objectness: 0.0947 (0.0984)  loss_rpn_box_reg: 0.0277 (0.0329)  time: 0.2707  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [31]  [ 330/1229]  eta: 0:04:07  lr: 0.000000  loss: 0.4071 (0.4250)  loss_classifier: 0.1316 (0.1521)  loss_box_reg: 0.1142 (0.1413)  loss_objectness: 0.0914 (0.0987)  loss_rpn_box_reg: 0.0279 (0.0328)  time: 0.2767  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [31]  [ 340/1229]  eta: 0:04:04  lr: 0.000000  loss: 0.3877 (0.4259)  loss_classifier: 0.1331 (0.1524)  loss_box_reg: 0.1340 (0.1419)  loss_objectness: 0.0914 (0.0987)  loss_rpn_box_reg: 0.0292 (0.0329)  time: 0.2776  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [31]  [ 350/1229]  eta: 0:04:02  lr: 0.000000  loss: 0.4727 (0.4308)  loss_classifier: 0.1777 (0.1541)  loss_box_reg: 0.1930 (0.1439)  loss_objectness: 0.0961 (0.0993)  loss_rpn_box_reg: 0.0394 (0.0335)  time: 0.2800  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [31]  [ 360/1229]  eta: 0:03:59  lr: 0.000000  loss: 0.5392 (0.4335)  loss_classifier: 0.1958 (0.1549)  loss_box_reg: 0.2092 (0.1453)  loss_objectness: 0.1161 (0.0998)  loss_rpn_box_reg: 0.0319 (0.0334)  time: 0.2816  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [31]  [ 370/1229]  eta: 0:03:56  lr: 0.000000  loss: 0.5048 (0.4353)  loss_classifier: 0.1754 (0.1556)  loss_box_reg: 0.1655 (0.1463)  loss_objectness: 0.1094 (0.1002)  loss_rpn_box_reg: 0.0296 (0.0333)  time: 0.2783  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [31]  [ 380/1229]  eta: 0:03:54  lr: 0.000000  loss: 0.4776 (0.4368)  loss_classifier: 0.1729 (0.1561)  loss_box_reg: 0.1434 (0.1473)  loss_objectness: 0.0925 (0.1003)  loss_rpn_box_reg: 0.0201 (0.0331)  time: 0.2754  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [31]  [ 390/1229]  eta: 0:03:51  lr: 0.000000  loss: 0.3590 (0.4350)  loss_classifier: 0.1327 (0.1553)  loss_box_reg: 0.1213 (0.1466)  loss_objectness: 0.0801 (0.1001)  loss_rpn_box_reg: 0.0164 (0.0330)  time: 0.2683  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [31]  [ 400/1229]  eta: 0:03:48  lr: 0.000000  loss: 0.3250 (0.4339)  loss_classifier: 0.1214 (0.1552)  loss_box_reg: 0.1190 (0.1465)  loss_objectness: 0.0590 (0.0994)  loss_rpn_box_reg: 0.0147 (0.0327)  time: 0.2636  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [31]  [ 410/1229]  eta: 0:03:45  lr: 0.000000  loss: 0.3250 (0.4330)  loss_classifier: 0.1125 (0.1546)  loss_box_reg: 0.0842 (0.1460)  loss_objectness: 0.0749 (0.0996)  loss_rpn_box_reg: 0.0137 (0.0328)  time: 0.2744  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [31]  [ 420/1229]  eta: 0:03:42  lr: 0.000000  loss: 0.3193 (0.4364)  loss_classifier: 0.1125 (0.1557)  loss_box_reg: 0.1020 (0.1479)  loss_objectness: 0.0829 (0.0998)  loss_rpn_box_reg: 0.0317 (0.0331)  time: 0.2855  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [31]  [ 430/1229]  eta: 0:03:39  lr: 0.000000  loss: 0.3193 (0.4342)  loss_classifier: 0.1113 (0.1550)  loss_box_reg: 0.1108 (0.1471)  loss_objectness: 0.0863 (0.0994)  loss_rpn_box_reg: 0.0125 (0.0328)  time: 0.2744  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [31]  [ 440/1229]  eta: 0:03:37  lr: 0.000000  loss: 0.3381 (0.4358)  loss_classifier: 0.1044 (0.1553)  loss_box_reg: 0.1108 (0.1484)  loss_objectness: 0.0949 (0.0994)  loss_rpn_box_reg: 0.0196 (0.0326)  time: 0.2665  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [31]  [ 450/1229]  eta: 0:03:34  lr: 0.000000  loss: 0.4505 (0.4379)  loss_classifier: 0.1449 (0.1560)  loss_box_reg: 0.1927 (0.1498)  loss_objectness: 0.0996 (0.0995)  loss_rpn_box_reg: 0.0276 (0.0326)  time: 0.2743  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [31]  [ 460/1229]  eta: 0:03:31  lr: 0.000000  loss: 0.4302 (0.4393)  loss_classifier: 0.1449 (0.1563)  loss_box_reg: 0.1631 (0.1504)  loss_objectness: 0.1004 (0.0995)  loss_rpn_box_reg: 0.0218 (0.0330)  time: 0.2780  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [31]  [ 470/1229]  eta: 0:03:28  lr: 0.000000  loss: 0.4701 (0.4405)  loss_classifier: 0.1646 (0.1568)  loss_box_reg: 0.1631 (0.1511)  loss_objectness: 0.0994 (0.0997)  loss_rpn_box_reg: 0.0355 (0.0330)  time: 0.2755  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [31]  [ 480/1229]  eta: 0:03:26  lr: 0.000000  loss: 0.4063 (0.4395)  loss_classifier: 0.1528 (0.1564)  loss_box_reg: 0.1356 (0.1502)  loss_objectness: 0.0994 (0.0998)  loss_rpn_box_reg: 0.0327 (0.0331)  time: 0.2692  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [31]  [ 490/1229]  eta: 0:03:23  lr: 0.000000  loss: 0.3856 (0.4400)  loss_classifier: 0.1302 (0.1562)  loss_box_reg: 0.1233 (0.1502)  loss_objectness: 0.0985 (0.0999)  loss_rpn_box_reg: 0.0258 (0.0337)  time: 0.2693  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [31]  [ 500/1229]  eta: 0:03:20  lr: 0.000000  loss: 0.3508 (0.4387)  loss_classifier: 0.1102 (0.1557)  loss_box_reg: 0.1012 (0.1497)  loss_objectness: 0.0750 (0.0996)  loss_rpn_box_reg: 0.0177 (0.0337)  time: 0.2771  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [31]  [ 510/1229]  eta: 0:03:18  lr: 0.000000  loss: 0.2482 (0.4352)  loss_classifier: 0.0859 (0.1545)  loss_box_reg: 0.0567 (0.1481)  loss_objectness: 0.0750 (0.0993)  loss_rpn_box_reg: 0.0114 (0.0333)  time: 0.2977  data: 0.1426  max mem: 1751\n",
      "Training Epoch: [31]  [ 520/1229]  eta: 0:03:15  lr: 0.000000  loss: 0.3544 (0.4374)  loss_classifier: 0.1221 (0.1552)  loss_box_reg: 0.1142 (0.1497)  loss_objectness: 0.0934 (0.0993)  loss_rpn_box_reg: 0.0142 (0.0332)  time: 0.2929  data: 0.1441  max mem: 1751\n",
      "Training Epoch: [31]  [ 530/1229]  eta: 0:03:12  lr: 0.000000  loss: 0.4492 (0.4382)  loss_classifier: 0.1755 (0.1557)  loss_box_reg: 0.1539 (0.1501)  loss_objectness: 0.0934 (0.0992)  loss_rpn_box_reg: 0.0255 (0.0332)  time: 0.2754  data: 0.1399  max mem: 1751\n",
      "Training Epoch: [31]  [ 540/1229]  eta: 0:03:09  lr: 0.000000  loss: 0.4298 (0.4379)  loss_classifier: 0.1660 (0.1556)  loss_box_reg: 0.1219 (0.1499)  loss_objectness: 0.1049 (0.0994)  loss_rpn_box_reg: 0.0231 (0.0330)  time: 0.2734  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [31]  [ 550/1229]  eta: 0:03:07  lr: 0.000000  loss: 0.3907 (0.4375)  loss_classifier: 0.1299 (0.1554)  loss_box_reg: 0.1089 (0.1497)  loss_objectness: 0.0794 (0.0991)  loss_rpn_box_reg: 0.0198 (0.0333)  time: 0.2723  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [31]  [ 560/1229]  eta: 0:03:04  lr: 0.000000  loss: 0.3736 (0.4374)  loss_classifier: 0.1153 (0.1554)  loss_box_reg: 0.1113 (0.1498)  loss_objectness: 0.0794 (0.0990)  loss_rpn_box_reg: 0.0173 (0.0332)  time: 0.2820  data: 0.1389  max mem: 1751\n",
      "Training Epoch: [31]  [ 570/1229]  eta: 0:03:01  lr: 0.000000  loss: 0.3195 (0.4361)  loss_classifier: 0.1087 (0.1548)  loss_box_reg: 0.0936 (0.1494)  loss_objectness: 0.0745 (0.0985)  loss_rpn_box_reg: 0.0164 (0.0334)  time: 0.2878  data: 0.1434  max mem: 1751\n",
      "Training Epoch: [31]  [ 580/1229]  eta: 0:02:59  lr: 0.000000  loss: 0.3781 (0.4370)  loss_classifier: 0.1147 (0.1550)  loss_box_reg: 0.1234 (0.1497)  loss_objectness: 0.0823 (0.0985)  loss_rpn_box_reg: 0.0205 (0.0338)  time: 0.2907  data: 0.1432  max mem: 1751\n",
      "Training Epoch: [31]  [ 590/1229]  eta: 0:02:56  lr: 0.000000  loss: 0.3781 (0.4362)  loss_classifier: 0.1216 (0.1547)  loss_box_reg: 0.1254 (0.1491)  loss_objectness: 0.0919 (0.0986)  loss_rpn_box_reg: 0.0205 (0.0339)  time: 0.2970  data: 0.1480  max mem: 1751\n",
      "Training Epoch: [31]  [ 600/1229]  eta: 0:02:54  lr: 0.000000  loss: 0.3695 (0.4372)  loss_classifier: 0.1114 (0.1552)  loss_box_reg: 0.1055 (0.1494)  loss_objectness: 0.0877 (0.0989)  loss_rpn_box_reg: 0.0168 (0.0337)  time: 0.3032  data: 0.1551  max mem: 1751\n",
      "Training Epoch: [31]  [ 610/1229]  eta: 0:02:51  lr: 0.000000  loss: 0.3766 (0.4365)  loss_classifier: 0.1482 (0.1551)  loss_box_reg: 0.1481 (0.1494)  loss_objectness: 0.0693 (0.0986)  loss_rpn_box_reg: 0.0168 (0.0335)  time: 0.3043  data: 0.1544  max mem: 1751\n",
      "Training Epoch: [31]  [ 620/1229]  eta: 0:02:49  lr: 0.000000  loss: 0.3538 (0.4367)  loss_classifier: 0.1320 (0.1552)  loss_box_reg: 0.1295 (0.1494)  loss_objectness: 0.0797 (0.0986)  loss_rpn_box_reg: 0.0176 (0.0335)  time: 0.3014  data: 0.1534  max mem: 1751\n",
      "Training Epoch: [31]  [ 630/1229]  eta: 0:02:46  lr: 0.000000  loss: 0.3538 (0.4356)  loss_classifier: 0.1320 (0.1548)  loss_box_reg: 0.1182 (0.1487)  loss_objectness: 0.0818 (0.0985)  loss_rpn_box_reg: 0.0213 (0.0335)  time: 0.3021  data: 0.1565  max mem: 1751\n",
      "Training Epoch: [31]  [ 640/1229]  eta: 0:02:44  lr: 0.000000  loss: 0.4467 (0.4374)  loss_classifier: 0.1692 (0.1556)  loss_box_reg: 0.1467 (0.1500)  loss_objectness: 0.0766 (0.0983)  loss_rpn_box_reg: 0.0273 (0.0334)  time: 0.3027  data: 0.1554  max mem: 1751\n",
      "Training Epoch: [31]  [ 650/1229]  eta: 0:02:41  lr: 0.000000  loss: 0.4840 (0.4384)  loss_classifier: 0.1869 (0.1561)  loss_box_reg: 0.1895 (0.1502)  loss_objectness: 0.0833 (0.0988)  loss_rpn_box_reg: 0.0252 (0.0333)  time: 0.2963  data: 0.1517  max mem: 1751\n",
      "Training Epoch: [31]  [ 660/1229]  eta: 0:02:38  lr: 0.000000  loss: 0.4243 (0.4378)  loss_classifier: 0.1588 (0.1558)  loss_box_reg: 0.1378 (0.1502)  loss_objectness: 0.0791 (0.0985)  loss_rpn_box_reg: 0.0197 (0.0332)  time: 0.2887  data: 0.1518  max mem: 1751\n",
      "Training Epoch: [31]  [ 670/1229]  eta: 0:02:36  lr: 0.000000  loss: 0.3628 (0.4371)  loss_classifier: 0.1373 (0.1558)  loss_box_reg: 0.1153 (0.1501)  loss_objectness: 0.0690 (0.0981)  loss_rpn_box_reg: 0.0141 (0.0330)  time: 0.2909  data: 0.1505  max mem: 1751\n",
      "Training Epoch: [31]  [ 680/1229]  eta: 0:02:33  lr: 0.000000  loss: 0.4596 (0.4391)  loss_classifier: 0.1748 (0.1565)  loss_box_reg: 0.1779 (0.1512)  loss_objectness: 0.0801 (0.0984)  loss_rpn_box_reg: 0.0177 (0.0329)  time: 0.2930  data: 0.1469  max mem: 1751\n",
      "Training Epoch: [31]  [ 690/1229]  eta: 0:02:30  lr: 0.000000  loss: 0.4401 (0.4374)  loss_classifier: 0.1460 (0.1559)  loss_box_reg: 0.1456 (0.1505)  loss_objectness: 0.0946 (0.0982)  loss_rpn_box_reg: 0.0235 (0.0327)  time: 0.2835  data: 0.1430  max mem: 1751\n",
      "Training Epoch: [31]  [ 700/1229]  eta: 0:02:27  lr: 0.000000  loss: 0.3191 (0.4365)  loss_classifier: 0.1350 (0.1557)  loss_box_reg: 0.1089 (0.1502)  loss_objectness: 0.0692 (0.0980)  loss_rpn_box_reg: 0.0170 (0.0326)  time: 0.2841  data: 0.1422  max mem: 1751\n",
      "Training Epoch: [31]  [ 710/1229]  eta: 0:02:25  lr: 0.000000  loss: 0.4491 (0.4374)  loss_classifier: 0.1520 (0.1561)  loss_box_reg: 0.1493 (0.1506)  loss_objectness: 0.0743 (0.0981)  loss_rpn_box_reg: 0.0220 (0.0326)  time: 0.2920  data: 0.1440  max mem: 1751\n",
      "Training Epoch: [31]  [ 720/1229]  eta: 0:02:22  lr: 0.000000  loss: 0.4268 (0.4371)  loss_classifier: 0.1597 (0.1561)  loss_box_reg: 0.1493 (0.1505)  loss_objectness: 0.0743 (0.0980)  loss_rpn_box_reg: 0.0182 (0.0325)  time: 0.2948  data: 0.1453  max mem: 1751\n",
      "Training Epoch: [31]  [ 730/1229]  eta: 0:02:19  lr: 0.000000  loss: 0.3232 (0.4373)  loss_classifier: 0.1178 (0.1562)  loss_box_reg: 0.1214 (0.1508)  loss_objectness: 0.0627 (0.0979)  loss_rpn_box_reg: 0.0208 (0.0325)  time: 0.2920  data: 0.1472  max mem: 1751\n",
      "Training Epoch: [31]  [ 740/1229]  eta: 0:02:17  lr: 0.000000  loss: 0.3370 (0.4375)  loss_classifier: 0.1266 (0.1562)  loss_box_reg: 0.1196 (0.1507)  loss_objectness: 0.0689 (0.0977)  loss_rpn_box_reg: 0.0231 (0.0328)  time: 0.2875  data: 0.1455  max mem: 1751\n",
      "Training Epoch: [31]  [ 750/1229]  eta: 0:02:14  lr: 0.000000  loss: 0.4438 (0.4384)  loss_classifier: 0.1536 (0.1564)  loss_box_reg: 0.1298 (0.1512)  loss_objectness: 0.0924 (0.0979)  loss_rpn_box_reg: 0.0249 (0.0329)  time: 0.2864  data: 0.1452  max mem: 1751\n",
      "Training Epoch: [31]  [ 760/1229]  eta: 0:02:11  lr: 0.000000  loss: 0.4438 (0.4391)  loss_classifier: 0.1550 (0.1566)  loss_box_reg: 0.1350 (0.1512)  loss_objectness: 0.1008 (0.0979)  loss_rpn_box_reg: 0.0179 (0.0334)  time: 0.2896  data: 0.1464  max mem: 1751\n",
      "Training Epoch: [31]  [ 770/1229]  eta: 0:02:08  lr: 0.000000  loss: 0.3223 (0.4384)  loss_classifier: 0.1213 (0.1563)  loss_box_reg: 0.1005 (0.1505)  loss_objectness: 0.0918 (0.0981)  loss_rpn_box_reg: 0.0179 (0.0336)  time: 0.2874  data: 0.1466  max mem: 1751\n",
      "Training Epoch: [31]  [ 780/1229]  eta: 0:02:05  lr: 0.000000  loss: 0.4102 (0.4392)  loss_classifier: 0.1247 (0.1565)  loss_box_reg: 0.1103 (0.1507)  loss_objectness: 0.0879 (0.0983)  loss_rpn_box_reg: 0.0286 (0.0338)  time: 0.2817  data: 0.1456  max mem: 1751\n",
      "Training Epoch: [31]  [ 790/1229]  eta: 0:02:03  lr: 0.000000  loss: 0.4263 (0.4388)  loss_classifier: 0.1279 (0.1562)  loss_box_reg: 0.1174 (0.1505)  loss_objectness: 0.0839 (0.0982)  loss_rpn_box_reg: 0.0286 (0.0339)  time: 0.2829  data: 0.1429  max mem: 1751\n",
      "Training Epoch: [31]  [ 800/1229]  eta: 0:02:00  lr: 0.000000  loss: 0.3320 (0.4387)  loss_classifier: 0.1129 (0.1562)  loss_box_reg: 0.0995 (0.1505)  loss_objectness: 0.0783 (0.0981)  loss_rpn_box_reg: 0.0143 (0.0339)  time: 0.2831  data: 0.1441  max mem: 1751\n",
      "Training Epoch: [31]  [ 810/1229]  eta: 0:01:57  lr: 0.000000  loss: 0.3124 (0.4374)  loss_classifier: 0.1198 (0.1558)  loss_box_reg: 0.0938 (0.1503)  loss_objectness: 0.0655 (0.0976)  loss_rpn_box_reg: 0.0140 (0.0336)  time: 0.2882  data: 0.1474  max mem: 1751\n",
      "Training Epoch: [31]  [ 820/1229]  eta: 0:01:54  lr: 0.000000  loss: 0.3576 (0.4375)  loss_classifier: 0.1333 (0.1559)  loss_box_reg: 0.0938 (0.1499)  loss_objectness: 0.0851 (0.0980)  loss_rpn_box_reg: 0.0154 (0.0337)  time: 0.2833  data: 0.1465  max mem: 1751\n",
      "Training Epoch: [31]  [ 830/1229]  eta: 0:01:52  lr: 0.000000  loss: 0.4083 (0.4370)  loss_classifier: 0.1439 (0.1559)  loss_box_reg: 0.0963 (0.1495)  loss_objectness: 0.1182 (0.0982)  loss_rpn_box_reg: 0.0176 (0.0335)  time: 0.2811  data: 0.1455  max mem: 1751\n",
      "Training Epoch: [31]  [ 840/1229]  eta: 0:01:49  lr: 0.000000  loss: 0.3880 (0.4368)  loss_classifier: 0.1407 (0.1558)  loss_box_reg: 0.1143 (0.1492)  loss_objectness: 0.0987 (0.0982)  loss_rpn_box_reg: 0.0188 (0.0336)  time: 0.2824  data: 0.1451  max mem: 1751\n",
      "Training Epoch: [31]  [ 850/1229]  eta: 0:01:46  lr: 0.000000  loss: 0.3880 (0.4374)  loss_classifier: 0.1311 (0.1559)  loss_box_reg: 0.1305 (0.1492)  loss_objectness: 0.1032 (0.0984)  loss_rpn_box_reg: 0.0295 (0.0338)  time: 0.2748  data: 0.1428  max mem: 1751\n",
      "Training Epoch: [31]  [ 860/1229]  eta: 0:01:43  lr: 0.000000  loss: 0.4496 (0.4389)  loss_classifier: 0.1825 (0.1563)  loss_box_reg: 0.1437 (0.1496)  loss_objectness: 0.1314 (0.0989)  loss_rpn_box_reg: 0.0296 (0.0341)  time: 0.2783  data: 0.1428  max mem: 1751\n",
      "Training Epoch: [31]  [ 870/1229]  eta: 0:01:40  lr: 0.000000  loss: 0.4210 (0.4387)  loss_classifier: 0.1459 (0.1563)  loss_box_reg: 0.1172 (0.1495)  loss_objectness: 0.1101 (0.0989)  loss_rpn_box_reg: 0.0275 (0.0340)  time: 0.2802  data: 0.1441  max mem: 1751\n",
      "Training Epoch: [31]  [ 880/1229]  eta: 0:01:37  lr: 0.000000  loss: 0.3242 (0.4387)  loss_classifier: 0.1118 (0.1562)  loss_box_reg: 0.1128 (0.1494)  loss_objectness: 0.0862 (0.0991)  loss_rpn_box_reg: 0.0150 (0.0339)  time: 0.2795  data: 0.1437  max mem: 1751\n",
      "Training Epoch: [31]  [ 890/1229]  eta: 0:01:35  lr: 0.000000  loss: 0.3548 (0.4384)  loss_classifier: 0.1118 (0.1562)  loss_box_reg: 0.1196 (0.1494)  loss_objectness: 0.0810 (0.0989)  loss_rpn_box_reg: 0.0176 (0.0338)  time: 0.2799  data: 0.1432  max mem: 1751\n",
      "Training Epoch: [31]  [ 900/1229]  eta: 0:01:32  lr: 0.000000  loss: 0.3743 (0.4377)  loss_classifier: 0.1443 (0.1560)  loss_box_reg: 0.1445 (0.1493)  loss_objectness: 0.0788 (0.0986)  loss_rpn_box_reg: 0.0176 (0.0339)  time: 0.2823  data: 0.1443  max mem: 1751\n",
      "Training Epoch: [31]  [ 910/1229]  eta: 0:01:29  lr: 0.000000  loss: 0.3743 (0.4380)  loss_classifier: 0.1409 (0.1561)  loss_box_reg: 0.1404 (0.1494)  loss_objectness: 0.0792 (0.0987)  loss_rpn_box_reg: 0.0187 (0.0339)  time: 0.2804  data: 0.1446  max mem: 1751\n",
      "Training Epoch: [31]  [ 920/1229]  eta: 0:01:26  lr: 0.000000  loss: 0.3943 (0.4376)  loss_classifier: 0.1409 (0.1559)  loss_box_reg: 0.1062 (0.1490)  loss_objectness: 0.0917 (0.0990)  loss_rpn_box_reg: 0.0161 (0.0338)  time: 0.2763  data: 0.1435  max mem: 1751\n",
      "Training Epoch: [31]  [ 930/1229]  eta: 0:01:23  lr: 0.000000  loss: 0.3973 (0.4377)  loss_classifier: 0.1431 (0.1558)  loss_box_reg: 0.1030 (0.1490)  loss_objectness: 0.0917 (0.0989)  loss_rpn_box_reg: 0.0194 (0.0340)  time: 0.2862  data: 0.1418  max mem: 1751\n",
      "Training Epoch: [31]  [ 940/1229]  eta: 0:01:21  lr: 0.000000  loss: 0.3906 (0.4373)  loss_classifier: 0.1414 (0.1555)  loss_box_reg: 0.1085 (0.1487)  loss_objectness: 0.0920 (0.0990)  loss_rpn_box_reg: 0.0239 (0.0340)  time: 0.2892  data: 0.1433  max mem: 1751\n",
      "Training Epoch: [31]  [ 950/1229]  eta: 0:01:18  lr: 0.000000  loss: 0.3852 (0.4381)  loss_classifier: 0.1324 (0.1559)  loss_box_reg: 0.1142 (0.1491)  loss_objectness: 0.1019 (0.0993)  loss_rpn_box_reg: 0.0239 (0.0339)  time: 0.2857  data: 0.1441  max mem: 1751\n",
      "Training Epoch: [31]  [ 960/1229]  eta: 0:01:15  lr: 0.000000  loss: 0.4532 (0.4383)  loss_classifier: 0.1614 (0.1559)  loss_box_reg: 0.1476 (0.1491)  loss_objectness: 0.1033 (0.0994)  loss_rpn_box_reg: 0.0237 (0.0339)  time: 0.2859  data: 0.1442  max mem: 1751\n",
      "Training Epoch: [31]  [ 970/1229]  eta: 0:01:12  lr: 0.000000  loss: 0.4461 (0.4381)  loss_classifier: 0.1553 (0.1558)  loss_box_reg: 0.1367 (0.1488)  loss_objectness: 0.0964 (0.0996)  loss_rpn_box_reg: 0.0237 (0.0339)  time: 0.2790  data: 0.1442  max mem: 1751\n",
      "Training Epoch: [31]  [ 980/1229]  eta: 0:01:09  lr: 0.000000  loss: 0.4262 (0.4397)  loss_classifier: 0.1556 (0.1563)  loss_box_reg: 0.1373 (0.1496)  loss_objectness: 0.0757 (0.0996)  loss_rpn_box_reg: 0.0265 (0.0342)  time: 0.2835  data: 0.1443  max mem: 1751\n",
      "Training Epoch: [31]  [ 990/1229]  eta: 0:01:07  lr: 0.000000  loss: 0.4113 (0.4397)  loss_classifier: 0.1587 (0.1563)  loss_box_reg: 0.1465 (0.1496)  loss_objectness: 0.0850 (0.0997)  loss_rpn_box_reg: 0.0270 (0.0341)  time: 0.2844  data: 0.1442  max mem: 1751\n",
      "Training Epoch: [31]  [1000/1229]  eta: 0:01:04  lr: 0.000000  loss: 0.3535 (0.4388)  loss_classifier: 0.1221 (0.1561)  loss_box_reg: 0.1384 (0.1492)  loss_objectness: 0.0844 (0.0995)  loss_rpn_box_reg: 0.0177 (0.0340)  time: 0.2852  data: 0.1442  max mem: 1751\n",
      "Training Epoch: [31]  [1010/1229]  eta: 0:01:01  lr: 0.000000  loss: 0.3717 (0.4392)  loss_classifier: 0.1351 (0.1562)  loss_box_reg: 0.1146 (0.1493)  loss_objectness: 0.0792 (0.0996)  loss_rpn_box_reg: 0.0184 (0.0342)  time: 0.2953  data: 0.1440  max mem: 1751\n",
      "Training Epoch: [31]  [1020/1229]  eta: 0:00:58  lr: 0.000000  loss: 0.3265 (0.4380)  loss_classifier: 0.1252 (0.1557)  loss_box_reg: 0.1044 (0.1490)  loss_objectness: 0.0650 (0.0993)  loss_rpn_box_reg: 0.0154 (0.0340)  time: 0.2953  data: 0.1417  max mem: 1751\n",
      "Training Epoch: [31]  [1030/1229]  eta: 0:00:55  lr: 0.000000  loss: 0.3334 (0.4380)  loss_classifier: 0.1418 (0.1558)  loss_box_reg: 0.1069 (0.1489)  loss_objectness: 0.0824 (0.0994)  loss_rpn_box_reg: 0.0145 (0.0340)  time: 0.2843  data: 0.1431  max mem: 1751\n",
      "Training Epoch: [31]  [1040/1229]  eta: 0:00:53  lr: 0.000000  loss: 0.3676 (0.4376)  loss_classifier: 0.1493 (0.1556)  loss_box_reg: 0.1354 (0.1489)  loss_objectness: 0.0878 (0.0992)  loss_rpn_box_reg: 0.0172 (0.0340)  time: 0.2819  data: 0.1422  max mem: 1751\n",
      "Training Epoch: [31]  [1050/1229]  eta: 0:00:50  lr: 0.000000  loss: 0.3640 (0.4381)  loss_classifier: 0.1195 (0.1557)  loss_box_reg: 0.1191 (0.1491)  loss_objectness: 0.0659 (0.0993)  loss_rpn_box_reg: 0.0180 (0.0340)  time: 0.2889  data: 0.1413  max mem: 1751\n",
      "Training Epoch: [31]  [1060/1229]  eta: 0:00:47  lr: 0.000000  loss: 0.3154 (0.4373)  loss_classifier: 0.1183 (0.1554)  loss_box_reg: 0.0983 (0.1489)  loss_objectness: 0.0659 (0.0989)  loss_rpn_box_reg: 0.0201 (0.0340)  time: 0.2905  data: 0.1426  max mem: 1751\n",
      "Training Epoch: [31]  [1070/1229]  eta: 0:00:44  lr: 0.000000  loss: 0.3202 (0.4368)  loss_classifier: 0.1183 (0.1553)  loss_box_reg: 0.1126 (0.1487)  loss_objectness: 0.0571 (0.0989)  loss_rpn_box_reg: 0.0252 (0.0339)  time: 0.2871  data: 0.1407  max mem: 1751\n",
      "Training Epoch: [31]  [1080/1229]  eta: 0:00:41  lr: 0.000000  loss: 0.4094 (0.4374)  loss_classifier: 0.1630 (0.1555)  loss_box_reg: 0.1366 (0.1490)  loss_objectness: 0.0847 (0.0988)  loss_rpn_box_reg: 0.0260 (0.0340)  time: 0.2845  data: 0.1401  max mem: 1751\n",
      "Training Epoch: [31]  [1090/1229]  eta: 0:00:39  lr: 0.000000  loss: 0.3973 (0.4372)  loss_classifier: 0.1226 (0.1554)  loss_box_reg: 0.1299 (0.1488)  loss_objectness: 0.1012 (0.0991)  loss_rpn_box_reg: 0.0133 (0.0339)  time: 0.2888  data: 0.1468  max mem: 1751\n",
      "Training Epoch: [31]  [1100/1229]  eta: 0:00:36  lr: 0.000000  loss: 0.3364 (0.4370)  loss_classifier: 0.1226 (0.1553)  loss_box_reg: 0.1240 (0.1486)  loss_objectness: 0.0952 (0.0991)  loss_rpn_box_reg: 0.0196 (0.0340)  time: 0.2926  data: 0.1527  max mem: 1751\n",
      "Training Epoch: [31]  [1110/1229]  eta: 0:00:33  lr: 0.000000  loss: 0.4127 (0.4366)  loss_classifier: 0.1418 (0.1551)  loss_box_reg: 0.1240 (0.1485)  loss_objectness: 0.0728 (0.0990)  loss_rpn_box_reg: 0.0229 (0.0339)  time: 0.2937  data: 0.1501  max mem: 1751\n",
      "Training Epoch: [31]  [1120/1229]  eta: 0:00:30  lr: 0.000000  loss: 0.3715 (0.4357)  loss_classifier: 0.1154 (0.1547)  loss_box_reg: 0.1100 (0.1481)  loss_objectness: 0.0750 (0.0989)  loss_rpn_box_reg: 0.0216 (0.0340)  time: 0.2887  data: 0.1469  max mem: 1751\n",
      "Training Epoch: [31]  [1130/1229]  eta: 0:00:27  lr: 0.000000  loss: 0.3715 (0.4360)  loss_classifier: 0.1235 (0.1548)  loss_box_reg: 0.1173 (0.1482)  loss_objectness: 0.0826 (0.0989)  loss_rpn_box_reg: 0.0195 (0.0340)  time: 0.2890  data: 0.1483  max mem: 1751\n",
      "Training Epoch: [31]  [1140/1229]  eta: 0:00:25  lr: 0.000000  loss: 0.3837 (0.4357)  loss_classifier: 0.1276 (0.1547)  loss_box_reg: 0.1111 (0.1480)  loss_objectness: 0.0844 (0.0989)  loss_rpn_box_reg: 0.0204 (0.0341)  time: 0.2891  data: 0.1486  max mem: 1751\n",
      "Training Epoch: [31]  [1150/1229]  eta: 0:00:22  lr: 0.000000  loss: 0.3523 (0.4347)  loss_classifier: 0.1218 (0.1544)  loss_box_reg: 0.0967 (0.1477)  loss_objectness: 0.0758 (0.0988)  loss_rpn_box_reg: 0.0146 (0.0339)  time: 0.2867  data: 0.1496  max mem: 1751\n",
      "Training Epoch: [31]  [1160/1229]  eta: 0:00:19  lr: 0.000000  loss: 0.3272 (0.4338)  loss_classifier: 0.1068 (0.1539)  loss_box_reg: 0.0967 (0.1474)  loss_objectness: 0.0718 (0.0986)  loss_rpn_box_reg: 0.0133 (0.0339)  time: 0.2924  data: 0.1515  max mem: 1751\n",
      "Training Epoch: [31]  [1170/1229]  eta: 0:00:16  lr: 0.000000  loss: 0.2619 (0.4324)  loss_classifier: 0.0914 (0.1534)  loss_box_reg: 0.0753 (0.1468)  loss_objectness: 0.0718 (0.0982)  loss_rpn_box_reg: 0.0133 (0.0339)  time: 0.3000  data: 0.1510  max mem: 1751\n",
      "Training Epoch: [31]  [1180/1229]  eta: 0:00:13  lr: 0.000000  loss: 0.2560 (0.4317)  loss_classifier: 0.1108 (0.1531)  loss_box_reg: 0.0721 (0.1466)  loss_objectness: 0.0741 (0.0982)  loss_rpn_box_reg: 0.0130 (0.0338)  time: 0.3004  data: 0.1490  max mem: 1751\n",
      "Training Epoch: [31]  [1190/1229]  eta: 0:00:11  lr: 0.000000  loss: 0.3234 (0.4316)  loss_classifier: 0.1137 (0.1531)  loss_box_reg: 0.0734 (0.1464)  loss_objectness: 0.0804 (0.0983)  loss_rpn_box_reg: 0.0209 (0.0338)  time: 0.2909  data: 0.1474  max mem: 1751\n",
      "Training Epoch: [31]  [1200/1229]  eta: 0:00:08  lr: 0.000000  loss: 0.3863 (0.4322)  loss_classifier: 0.1514 (0.1534)  loss_box_reg: 0.1149 (0.1466)  loss_objectness: 0.0945 (0.0984)  loss_rpn_box_reg: 0.0280 (0.0338)  time: 0.2831  data: 0.1475  max mem: 1751\n",
      "Training Epoch: [31]  [1210/1229]  eta: 0:00:05  lr: 0.000000  loss: 0.4879 (0.4329)  loss_classifier: 0.1716 (0.1537)  loss_box_reg: 0.1422 (0.1468)  loss_objectness: 0.0945 (0.0985)  loss_rpn_box_reg: 0.0246 (0.0339)  time: 0.2829  data: 0.1491  max mem: 1751\n",
      "Training Epoch: [31]  [1220/1229]  eta: 0:00:02  lr: 0.000000  loss: 0.4026 (0.4320)  loss_classifier: 0.1555 (0.1534)  loss_box_reg: 0.1034 (0.1464)  loss_objectness: 0.0675 (0.0983)  loss_rpn_box_reg: 0.0246 (0.0339)  time: 0.2889  data: 0.1484  max mem: 1751\n",
      "Training Epoch: [31]  [1228/1229]  eta: 0:00:00  lr: 0.000000  loss: 0.3341 (0.4317)  loss_classifier: 0.1270 (0.1534)  loss_box_reg: 0.0955 (0.1463)  loss_objectness: 0.0796 (0.0982)  loss_rpn_box_reg: 0.0206 (0.0338)  time: 0.2953  data: 0.1490  max mem: 1751\n",
      "Training Epoch: [31] Total time: 0:05:47 (0.2828 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:21  model_time: 0.2310 (0.2310)  evaluator_time: 0.0020 (0.0020)  time: 0.2650  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0790 (0.0814)  evaluator_time: 0.0040 (0.0089)  time: 0.1285  data: 0.0381  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0840 (0.0807)  evaluator_time: 0.0030 (0.0082)  time: 0.1237  data: 0.0342  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0720 (0.0801)  evaluator_time: 0.0040 (0.0080)  time: 0.1244  data: 0.0402  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0720 (0.0800)  evaluator_time: 0.0030 (0.0080)  time: 0.1213  data: 0.0388  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1264 s / it)\n",
      "Averaged stats: model_time: 0.0720 (0.0800)  evaluator_time: 0.0030 (0.0080)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [31]  [  0/308]  eta: 0:00:38  lr: 0.000000  loss: 0.1696 (0.1696)  loss_classifier: 0.0591 (0.0591)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0305 (0.0305)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1250  data: 0.0310  max mem: 1751\n",
      "Testing Epoch: [31]  [100/308]  eta: 0:00:29  lr: 0.000000  loss: 0.3191 (0.4798)  loss_classifier: 0.1335 (0.1545)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0565 (0.1010)  loss_rpn_box_reg: 0.0186 (0.0521)  time: 0.1452  data: 0.0427  max mem: 1751\n",
      "Testing Epoch: [31]  [200/308]  eta: 0:00:14  lr: 0.000000  loss: 0.3486 (0.4567)  loss_classifier: 0.1384 (0.1491)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0600 (0.0953)  loss_rpn_box_reg: 0.0197 (0.0491)  time: 0.1425  data: 0.0372  max mem: 1751\n",
      "Testing Epoch: [31]  [300/308]  eta: 0:00:01  lr: 0.000000  loss: 0.4686 (0.4537)  loss_classifier: 0.1538 (0.1493)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0809 (0.0928)  loss_rpn_box_reg: 0.0265 (0.0475)  time: 0.1328  data: 0.0375  max mem: 1751\n",
      "Testing Epoch: [31]  [307/308]  eta: 0:00:00  lr: 0.000000  loss: 0.4686 (0.4538)  loss_classifier: 0.1860 (0.1495)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0825 (0.0928)  loss_rpn_box_reg: 0.0271 (0.0470)  time: 0.1353  data: 0.0402  max mem: 1751\n",
      "Testing Epoch: [31] Total time: 0:00:42 (0.1376 s / it)\n",
      "Training Epoch: [32]  [   0/1229]  eta: 0:06:02  lr: 0.000000  loss: 0.1870 (0.1870)  loss_classifier: 0.0751 (0.0751)  loss_box_reg: 0.0612 (0.0612)  loss_objectness: 0.0436 (0.0436)  loss_rpn_box_reg: 0.0071 (0.0071)  time: 0.2950  data: 0.1370  max mem: 1751\n",
      "Training Epoch: [32]  [  10/1229]  eta: 0:05:33  lr: 0.000000  loss: 0.3934 (0.4789)  loss_classifier: 0.1544 (0.1597)  loss_box_reg: 0.1501 (0.1592)  loss_objectness: 0.0712 (0.1173)  loss_rpn_box_reg: 0.0243 (0.0426)  time: 0.2733  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [32]  [  20/1229]  eta: 0:05:34  lr: 0.000000  loss: 0.3558 (0.4231)  loss_classifier: 0.1337 (0.1440)  loss_box_reg: 0.1202 (0.1361)  loss_objectness: 0.0742 (0.1079)  loss_rpn_box_reg: 0.0229 (0.0351)  time: 0.2753  data: 0.1367  max mem: 1751\n",
      "Training Epoch: [32]  [  30/1229]  eta: 0:05:27  lr: 0.000000  loss: 0.3337 (0.4144)  loss_classifier: 0.1281 (0.1416)  loss_box_reg: 0.0967 (0.1305)  loss_objectness: 0.0881 (0.1078)  loss_rpn_box_reg: 0.0183 (0.0346)  time: 0.2736  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [32]  [  40/1229]  eta: 0:05:25  lr: 0.000000  loss: 0.3227 (0.3977)  loss_classifier: 0.1150 (0.1378)  loss_box_reg: 0.0967 (0.1274)  loss_objectness: 0.0853 (0.0994)  loss_rpn_box_reg: 0.0264 (0.0331)  time: 0.2718  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [32]  [  50/1229]  eta: 0:05:27  lr: 0.000000  loss: 0.3161 (0.3958)  loss_classifier: 0.1186 (0.1392)  loss_box_reg: 0.0958 (0.1293)  loss_objectness: 0.0670 (0.0969)  loss_rpn_box_reg: 0.0158 (0.0304)  time: 0.2842  data: 0.1395  max mem: 1751\n",
      "Training Epoch: [32]  [  60/1229]  eta: 0:05:24  lr: 0.000000  loss: 0.3887 (0.3935)  loss_classifier: 0.1322 (0.1393)  loss_box_reg: 0.0958 (0.1262)  loss_objectness: 0.0773 (0.0976)  loss_rpn_box_reg: 0.0158 (0.0304)  time: 0.2857  data: 0.1417  max mem: 1751\n",
      "Training Epoch: [32]  [  70/1229]  eta: 0:05:20  lr: 0.000000  loss: 0.3268 (0.3790)  loss_classifier: 0.1064 (0.1346)  loss_box_reg: 0.0943 (0.1212)  loss_objectness: 0.0862 (0.0952)  loss_rpn_box_reg: 0.0172 (0.0280)  time: 0.2747  data: 0.1397  max mem: 1751\n",
      "Training Epoch: [32]  [  80/1229]  eta: 0:05:18  lr: 0.000000  loss: 0.3290 (0.3911)  loss_classifier: 0.1171 (0.1390)  loss_box_reg: 0.1274 (0.1290)  loss_objectness: 0.0778 (0.0940)  loss_rpn_box_reg: 0.0187 (0.0292)  time: 0.2736  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [32]  [  90/1229]  eta: 0:05:16  lr: 0.000000  loss: 0.3601 (0.3947)  loss_classifier: 0.1465 (0.1410)  loss_box_reg: 0.1324 (0.1311)  loss_objectness: 0.0778 (0.0941)  loss_rpn_box_reg: 0.0202 (0.0285)  time: 0.2810  data: 0.1370  max mem: 1751\n",
      "Training Epoch: [32]  [ 100/1229]  eta: 0:05:13  lr: 0.000000  loss: 0.4094 (0.4063)  loss_classifier: 0.1664 (0.1459)  loss_box_reg: 0.1320 (0.1389)  loss_objectness: 0.0882 (0.0931)  loss_rpn_box_reg: 0.0239 (0.0284)  time: 0.2833  data: 0.1404  max mem: 1751\n",
      "Training Epoch: [32]  [ 110/1229]  eta: 0:05:11  lr: 0.000000  loss: 0.3994 (0.4085)  loss_classifier: 0.1367 (0.1470)  loss_box_reg: 0.1002 (0.1387)  loss_objectness: 0.0932 (0.0948)  loss_rpn_box_reg: 0.0239 (0.0279)  time: 0.2827  data: 0.1391  max mem: 1751\n",
      "Training Epoch: [32]  [ 120/1229]  eta: 0:05:08  lr: 0.000000  loss: 0.3257 (0.4059)  loss_classifier: 0.1128 (0.1462)  loss_box_reg: 0.0902 (0.1366)  loss_objectness: 0.0839 (0.0947)  loss_rpn_box_reg: 0.0178 (0.0284)  time: 0.2813  data: 0.1371  max mem: 1751\n",
      "Training Epoch: [32]  [ 130/1229]  eta: 0:05:05  lr: 0.000000  loss: 0.3049 (0.4041)  loss_classifier: 0.0929 (0.1441)  loss_box_reg: 0.0902 (0.1359)  loss_objectness: 0.0698 (0.0944)  loss_rpn_box_reg: 0.0226 (0.0297)  time: 0.2720  data: 0.1368  max mem: 1751\n",
      "Training Epoch: [32]  [ 140/1229]  eta: 0:05:02  lr: 0.000000  loss: 0.3802 (0.4069)  loss_classifier: 0.1445 (0.1449)  loss_box_reg: 0.1092 (0.1367)  loss_objectness: 0.0698 (0.0947)  loss_rpn_box_reg: 0.0257 (0.0306)  time: 0.2741  data: 0.1380  max mem: 1751\n",
      "Training Epoch: [32]  [ 150/1229]  eta: 0:05:00  lr: 0.000000  loss: 0.4204 (0.4100)  loss_classifier: 0.1445 (0.1457)  loss_box_reg: 0.1115 (0.1352)  loss_objectness: 0.0965 (0.0973)  loss_rpn_box_reg: 0.0272 (0.0318)  time: 0.2808  data: 0.1381  max mem: 1751\n",
      "Training Epoch: [32]  [ 160/1229]  eta: 0:04:57  lr: 0.000000  loss: 0.3098 (0.4064)  loss_classifier: 0.1166 (0.1441)  loss_box_reg: 0.0994 (0.1341)  loss_objectness: 0.0941 (0.0964)  loss_rpn_box_reg: 0.0221 (0.0318)  time: 0.2783  data: 0.1370  max mem: 1751\n",
      "Training Epoch: [32]  [ 170/1229]  eta: 0:04:54  lr: 0.000000  loss: 0.2950 (0.4047)  loss_classifier: 0.1050 (0.1428)  loss_box_reg: 0.0943 (0.1329)  loss_objectness: 0.0747 (0.0969)  loss_rpn_box_reg: 0.0178 (0.0320)  time: 0.2807  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [32]  [ 180/1229]  eta: 0:04:51  lr: 0.000000  loss: 0.3040 (0.4017)  loss_classifier: 0.1050 (0.1419)  loss_box_reg: 0.0771 (0.1317)  loss_objectness: 0.0832 (0.0965)  loss_rpn_box_reg: 0.0178 (0.0316)  time: 0.2786  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [32]  [ 190/1229]  eta: 0:04:49  lr: 0.000000  loss: 0.3812 (0.4084)  loss_classifier: 0.1421 (0.1445)  loss_box_reg: 0.1526 (0.1349)  loss_objectness: 0.0827 (0.0973)  loss_rpn_box_reg: 0.0207 (0.0317)  time: 0.2821  data: 0.1403  max mem: 1751\n",
      "Training Epoch: [32]  [ 200/1229]  eta: 0:04:47  lr: 0.000000  loss: 0.4132 (0.4093)  loss_classifier: 0.1421 (0.1449)  loss_box_reg: 0.1526 (0.1347)  loss_objectness: 0.0913 (0.0976)  loss_rpn_box_reg: 0.0234 (0.0320)  time: 0.2885  data: 0.1408  max mem: 1751\n",
      "Training Epoch: [32]  [ 210/1229]  eta: 0:04:44  lr: 0.000000  loss: 0.4074 (0.4131)  loss_classifier: 0.1337 (0.1458)  loss_box_reg: 0.1093 (0.1355)  loss_objectness: 0.1200 (0.0991)  loss_rpn_box_reg: 0.0253 (0.0327)  time: 0.2820  data: 0.1392  max mem: 1751\n",
      "Training Epoch: [32]  [ 220/1229]  eta: 0:04:41  lr: 0.000000  loss: 0.4220 (0.4123)  loss_classifier: 0.1398 (0.1458)  loss_box_reg: 0.1155 (0.1355)  loss_objectness: 0.1054 (0.0985)  loss_rpn_box_reg: 0.0262 (0.0325)  time: 0.2793  data: 0.1391  max mem: 1751\n",
      "Training Epoch: [32]  [ 230/1229]  eta: 0:04:38  lr: 0.000000  loss: 0.4403 (0.4197)  loss_classifier: 0.1415 (0.1478)  loss_box_reg: 0.1573 (0.1387)  loss_objectness: 0.0962 (0.0996)  loss_rpn_box_reg: 0.0282 (0.0336)  time: 0.2767  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [32]  [ 240/1229]  eta: 0:04:35  lr: 0.000000  loss: 0.5387 (0.4237)  loss_classifier: 0.1636 (0.1491)  loss_box_reg: 0.1624 (0.1398)  loss_objectness: 0.0954 (0.1009)  loss_rpn_box_reg: 0.0286 (0.0339)  time: 0.2714  data: 0.1373  max mem: 1751\n",
      "Training Epoch: [32]  [ 250/1229]  eta: 0:04:32  lr: 0.000000  loss: 0.3591 (0.4222)  loss_classifier: 0.1420 (0.1487)  loss_box_reg: 0.1199 (0.1388)  loss_objectness: 0.0857 (0.1012)  loss_rpn_box_reg: 0.0183 (0.0334)  time: 0.2757  data: 0.1412  max mem: 1751\n",
      "Training Epoch: [32]  [ 260/1229]  eta: 0:04:29  lr: 0.000000  loss: 0.3591 (0.4239)  loss_classifier: 0.1376 (0.1498)  loss_box_reg: 0.1199 (0.1401)  loss_objectness: 0.0857 (0.1010)  loss_rpn_box_reg: 0.0177 (0.0329)  time: 0.2800  data: 0.1393  max mem: 1751\n",
      "Training Epoch: [32]  [ 270/1229]  eta: 0:04:26  lr: 0.000000  loss: 0.3942 (0.4229)  loss_classifier: 0.1404 (0.1496)  loss_box_reg: 0.1431 (0.1398)  loss_objectness: 0.0848 (0.1007)  loss_rpn_box_reg: 0.0181 (0.0328)  time: 0.2740  data: 0.1370  max mem: 1751\n",
      "Training Epoch: [32]  [ 280/1229]  eta: 0:04:23  lr: 0.000000  loss: 0.3779 (0.4256)  loss_classifier: 0.1404 (0.1502)  loss_box_reg: 0.1205 (0.1407)  loss_objectness: 0.0982 (0.1012)  loss_rpn_box_reg: 0.0224 (0.0336)  time: 0.2709  data: 0.1384  max mem: 1751\n",
      "Training Epoch: [32]  [ 290/1229]  eta: 0:04:21  lr: 0.000000  loss: 0.3998 (0.4240)  loss_classifier: 0.1460 (0.1497)  loss_box_reg: 0.1099 (0.1399)  loss_objectness: 0.1038 (0.1008)  loss_rpn_box_reg: 0.0394 (0.0336)  time: 0.2796  data: 0.1380  max mem: 1751\n",
      "Training Epoch: [32]  [ 300/1229]  eta: 0:04:19  lr: 0.000000  loss: 0.3728 (0.4241)  loss_classifier: 0.1396 (0.1501)  loss_box_reg: 0.1077 (0.1399)  loss_objectness: 0.0831 (0.1007)  loss_rpn_box_reg: 0.0253 (0.0334)  time: 0.2893  data: 0.1392  max mem: 1751\n",
      "Training Epoch: [32]  [ 310/1229]  eta: 0:04:16  lr: 0.000000  loss: 0.3584 (0.4247)  loss_classifier: 0.1039 (0.1498)  loss_box_reg: 0.1246 (0.1408)  loss_objectness: 0.0770 (0.1001)  loss_rpn_box_reg: 0.0304 (0.0340)  time: 0.2854  data: 0.1397  max mem: 1751\n",
      "Training Epoch: [32]  [ 320/1229]  eta: 0:04:13  lr: 0.000000  loss: 0.3981 (0.4270)  loss_classifier: 0.1471 (0.1508)  loss_box_reg: 0.1367 (0.1422)  loss_objectness: 0.0847 (0.0998)  loss_rpn_box_reg: 0.0255 (0.0342)  time: 0.2799  data: 0.1400  max mem: 1751\n",
      "Training Epoch: [32]  [ 330/1229]  eta: 0:04:10  lr: 0.000000  loss: 0.4493 (0.4292)  loss_classifier: 0.1863 (0.1519)  loss_box_reg: 0.1411 (0.1431)  loss_objectness: 0.0850 (0.1001)  loss_rpn_box_reg: 0.0245 (0.0340)  time: 0.2849  data: 0.1395  max mem: 1751\n",
      "Training Epoch: [32]  [ 340/1229]  eta: 0:04:08  lr: 0.000000  loss: 0.3921 (0.4261)  loss_classifier: 0.1552 (0.1509)  loss_box_reg: 0.1012 (0.1416)  loss_objectness: 0.0820 (0.0998)  loss_rpn_box_reg: 0.0213 (0.0339)  time: 0.2860  data: 0.1371  max mem: 1751\n",
      "Training Epoch: [32]  [ 350/1229]  eta: 0:04:05  lr: 0.000000  loss: 0.3704 (0.4284)  loss_classifier: 0.1488 (0.1519)  loss_box_reg: 0.0900 (0.1424)  loss_objectness: 0.0913 (0.1003)  loss_rpn_box_reg: 0.0142 (0.0338)  time: 0.2811  data: 0.1385  max mem: 1751\n",
      "Training Epoch: [32]  [ 360/1229]  eta: 0:04:02  lr: 0.000000  loss: 0.4271 (0.4280)  loss_classifier: 0.1488 (0.1518)  loss_box_reg: 0.1494 (0.1431)  loss_objectness: 0.0718 (0.0994)  loss_rpn_box_reg: 0.0211 (0.0338)  time: 0.2757  data: 0.1399  max mem: 1751\n",
      "Training Epoch: [32]  [ 370/1229]  eta: 0:03:59  lr: 0.000000  loss: 0.4271 (0.4314)  loss_classifier: 0.1439 (0.1529)  loss_box_reg: 0.1450 (0.1450)  loss_objectness: 0.0718 (0.0995)  loss_rpn_box_reg: 0.0163 (0.0341)  time: 0.2749  data: 0.1382  max mem: 1751\n",
      "Training Epoch: [32]  [ 380/1229]  eta: 0:03:56  lr: 0.000000  loss: 0.3973 (0.4305)  loss_classifier: 0.1471 (0.1524)  loss_box_reg: 0.1285 (0.1447)  loss_objectness: 0.0909 (0.0992)  loss_rpn_box_reg: 0.0248 (0.0343)  time: 0.2777  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [32]  [ 390/1229]  eta: 0:03:54  lr: 0.000000  loss: 0.3856 (0.4300)  loss_classifier: 0.1288 (0.1521)  loss_box_reg: 0.1272 (0.1448)  loss_objectness: 0.0793 (0.0988)  loss_rpn_box_reg: 0.0248 (0.0343)  time: 0.2769  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [32]  [ 400/1229]  eta: 0:03:51  lr: 0.000000  loss: 0.3757 (0.4296)  loss_classifier: 0.1055 (0.1519)  loss_box_reg: 0.1020 (0.1440)  loss_objectness: 0.0835 (0.0991)  loss_rpn_box_reg: 0.0226 (0.0346)  time: 0.2781  data: 0.1377  max mem: 1751\n",
      "Training Epoch: [32]  [ 410/1229]  eta: 0:03:48  lr: 0.000000  loss: 0.3741 (0.4282)  loss_classifier: 0.0983 (0.1514)  loss_box_reg: 0.0943 (0.1436)  loss_objectness: 0.0836 (0.0989)  loss_rpn_box_reg: 0.0229 (0.0344)  time: 0.2725  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [32]  [ 420/1229]  eta: 0:03:45  lr: 0.000000  loss: 0.2921 (0.4262)  loss_classifier: 0.0925 (0.1507)  loss_box_reg: 0.0937 (0.1427)  loss_objectness: 0.0771 (0.0987)  loss_rpn_box_reg: 0.0202 (0.0340)  time: 0.2737  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [32]  [ 430/1229]  eta: 0:03:42  lr: 0.000000  loss: 0.2837 (0.4261)  loss_classifier: 0.0925 (0.1507)  loss_box_reg: 0.0994 (0.1427)  loss_objectness: 0.0602 (0.0985)  loss_rpn_box_reg: 0.0106 (0.0342)  time: 0.2800  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [32]  [ 440/1229]  eta: 0:03:39  lr: 0.000000  loss: 0.3099 (0.4259)  loss_classifier: 0.1173 (0.1508)  loss_box_reg: 0.1067 (0.1426)  loss_objectness: 0.0711 (0.0984)  loss_rpn_box_reg: 0.0131 (0.0340)  time: 0.2736  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [32]  [ 450/1229]  eta: 0:03:36  lr: 0.000000  loss: 0.3671 (0.4266)  loss_classifier: 0.1260 (0.1508)  loss_box_reg: 0.1445 (0.1429)  loss_objectness: 0.0778 (0.0984)  loss_rpn_box_reg: 0.0256 (0.0344)  time: 0.2740  data: 0.1367  max mem: 1751\n",
      "Training Epoch: [32]  [ 460/1229]  eta: 0:03:34  lr: 0.000000  loss: 0.3611 (0.4242)  loss_classifier: 0.1202 (0.1502)  loss_box_reg: 0.1027 (0.1422)  loss_objectness: 0.0677 (0.0978)  loss_rpn_box_reg: 0.0243 (0.0340)  time: 0.2742  data: 0.1376  max mem: 1751\n",
      "Training Epoch: [32]  [ 470/1229]  eta: 0:03:31  lr: 0.000000  loss: 0.3611 (0.4269)  loss_classifier: 0.1293 (0.1509)  loss_box_reg: 0.1027 (0.1431)  loss_objectness: 0.0852 (0.0984)  loss_rpn_box_reg: 0.0170 (0.0345)  time: 0.2721  data: 0.1376  max mem: 1751\n",
      "Training Epoch: [32]  [ 480/1229]  eta: 0:03:28  lr: 0.000000  loss: 0.4788 (0.4280)  loss_classifier: 0.1904 (0.1515)  loss_box_reg: 0.1744 (0.1439)  loss_objectness: 0.0893 (0.0983)  loss_rpn_box_reg: 0.0211 (0.0342)  time: 0.2793  data: 0.1389  max mem: 1751\n",
      "Training Epoch: [32]  [ 490/1229]  eta: 0:03:25  lr: 0.000000  loss: 0.3333 (0.4263)  loss_classifier: 0.1526 (0.1510)  loss_box_reg: 0.1147 (0.1439)  loss_objectness: 0.0720 (0.0976)  loss_rpn_box_reg: 0.0151 (0.0339)  time: 0.2790  data: 0.1387  max mem: 1751\n",
      "Training Epoch: [32]  [ 500/1229]  eta: 0:03:22  lr: 0.000000  loss: 0.3919 (0.4281)  loss_classifier: 0.1526 (0.1516)  loss_box_reg: 0.1334 (0.1448)  loss_objectness: 0.0649 (0.0979)  loss_rpn_box_reg: 0.0171 (0.0338)  time: 0.2758  data: 0.1403  max mem: 1751\n",
      "Training Epoch: [32]  [ 510/1229]  eta: 0:03:20  lr: 0.000000  loss: 0.4069 (0.4272)  loss_classifier: 0.1414 (0.1511)  loss_box_reg: 0.1488 (0.1443)  loss_objectness: 0.0841 (0.0981)  loss_rpn_box_reg: 0.0195 (0.0336)  time: 0.2831  data: 0.1417  max mem: 1751\n",
      "Training Epoch: [32]  [ 520/1229]  eta: 0:03:17  lr: 0.000000  loss: 0.3468 (0.4269)  loss_classifier: 0.1184 (0.1509)  loss_box_reg: 0.0973 (0.1441)  loss_objectness: 0.0841 (0.0982)  loss_rpn_box_reg: 0.0216 (0.0337)  time: 0.2877  data: 0.1396  max mem: 1751\n",
      "Training Epoch: [32]  [ 530/1229]  eta: 0:03:14  lr: 0.000000  loss: 0.3580 (0.4258)  loss_classifier: 0.1184 (0.1505)  loss_box_reg: 0.0854 (0.1436)  loss_objectness: 0.0965 (0.0980)  loss_rpn_box_reg: 0.0184 (0.0336)  time: 0.2842  data: 0.1396  max mem: 1751\n",
      "Training Epoch: [32]  [ 540/1229]  eta: 0:03:11  lr: 0.000000  loss: 0.3176 (0.4239)  loss_classifier: 0.1138 (0.1500)  loss_box_reg: 0.0710 (0.1425)  loss_objectness: 0.0965 (0.0981)  loss_rpn_box_reg: 0.0126 (0.0333)  time: 0.2761  data: 0.1401  max mem: 1751\n",
      "Training Epoch: [32]  [ 550/1229]  eta: 0:03:09  lr: 0.000000  loss: 0.3131 (0.4244)  loss_classifier: 0.1138 (0.1502)  loss_box_reg: 0.0922 (0.1428)  loss_objectness: 0.1021 (0.0983)  loss_rpn_box_reg: 0.0130 (0.0331)  time: 0.2718  data: 0.1370  max mem: 1751\n",
      "Training Epoch: [32]  [ 560/1229]  eta: 0:03:06  lr: 0.000000  loss: 0.3265 (0.4230)  loss_classifier: 0.1198 (0.1499)  loss_box_reg: 0.0988 (0.1424)  loss_objectness: 0.0811 (0.0979)  loss_rpn_box_reg: 0.0156 (0.0329)  time: 0.2712  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [32]  [ 570/1229]  eta: 0:03:03  lr: 0.000000  loss: 0.3764 (0.4266)  loss_classifier: 0.1428 (0.1510)  loss_box_reg: 0.1490 (0.1442)  loss_objectness: 0.0853 (0.0981)  loss_rpn_box_reg: 0.0194 (0.0331)  time: 0.2740  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [32]  [ 580/1229]  eta: 0:03:00  lr: 0.000000  loss: 0.4866 (0.4282)  loss_classifier: 0.1761 (0.1517)  loss_box_reg: 0.1853 (0.1449)  loss_objectness: 0.0996 (0.0985)  loss_rpn_box_reg: 0.0297 (0.0331)  time: 0.2782  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [32]  [ 590/1229]  eta: 0:02:57  lr: 0.000000  loss: 0.4566 (0.4285)  loss_classifier: 0.1497 (0.1519)  loss_box_reg: 0.1750 (0.1453)  loss_objectness: 0.0884 (0.0983)  loss_rpn_box_reg: 0.0170 (0.0329)  time: 0.2755  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [32]  [ 600/1229]  eta: 0:02:54  lr: 0.000000  loss: 0.2990 (0.4265)  loss_classifier: 0.1221 (0.1512)  loss_box_reg: 0.1063 (0.1446)  loss_objectness: 0.0707 (0.0980)  loss_rpn_box_reg: 0.0150 (0.0326)  time: 0.2764  data: 0.1381  max mem: 1751\n",
      "Training Epoch: [32]  [ 610/1229]  eta: 0:02:52  lr: 0.000000  loss: 0.3609 (0.4285)  loss_classifier: 0.1292 (0.1519)  loss_box_reg: 0.1191 (0.1454)  loss_objectness: 0.0753 (0.0983)  loss_rpn_box_reg: 0.0186 (0.0328)  time: 0.2778  data: 0.1378  max mem: 1751\n",
      "Training Epoch: [32]  [ 620/1229]  eta: 0:02:49  lr: 0.000000  loss: 0.4162 (0.4298)  loss_classifier: 0.1746 (0.1525)  loss_box_reg: 0.1548 (0.1461)  loss_objectness: 0.1136 (0.0983)  loss_rpn_box_reg: 0.0223 (0.0328)  time: 0.2738  data: 0.1372  max mem: 1751\n",
      "Training Epoch: [32]  [ 630/1229]  eta: 0:02:46  lr: 0.000000  loss: 0.4804 (0.4319)  loss_classifier: 0.1768 (0.1535)  loss_box_reg: 0.1646 (0.1471)  loss_objectness: 0.1136 (0.0985)  loss_rpn_box_reg: 0.0317 (0.0329)  time: 0.2752  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [32]  [ 640/1229]  eta: 0:02:43  lr: 0.000000  loss: 0.6056 (0.4339)  loss_classifier: 0.2164 (0.1542)  loss_box_reg: 0.1989 (0.1482)  loss_objectness: 0.1016 (0.0986)  loss_rpn_box_reg: 0.0355 (0.0329)  time: 0.2762  data: 0.1382  max mem: 1751\n",
      "Training Epoch: [32]  [ 650/1229]  eta: 0:02:40  lr: 0.000000  loss: 0.4169 (0.4335)  loss_classifier: 0.1478 (0.1540)  loss_box_reg: 0.1234 (0.1477)  loss_objectness: 0.1016 (0.0989)  loss_rpn_box_reg: 0.0275 (0.0330)  time: 0.2751  data: 0.1377  max mem: 1751\n",
      "Training Epoch: [32]  [ 660/1229]  eta: 0:02:38  lr: 0.000000  loss: 0.3610 (0.4329)  loss_classifier: 0.1321 (0.1538)  loss_box_reg: 0.0944 (0.1474)  loss_objectness: 0.0971 (0.0987)  loss_rpn_box_reg: 0.0222 (0.0330)  time: 0.2802  data: 0.1375  max mem: 1751\n",
      "Training Epoch: [32]  [ 670/1229]  eta: 0:02:35  lr: 0.000000  loss: 0.3324 (0.4338)  loss_classifier: 0.1321 (0.1540)  loss_box_reg: 0.1005 (0.1479)  loss_objectness: 0.0882 (0.0989)  loss_rpn_box_reg: 0.0275 (0.0331)  time: 0.2825  data: 0.1410  max mem: 1751\n",
      "Training Epoch: [32]  [ 680/1229]  eta: 0:02:32  lr: 0.000000  loss: 0.3671 (0.4327)  loss_classifier: 0.1312 (0.1537)  loss_box_reg: 0.1195 (0.1474)  loss_objectness: 0.0882 (0.0987)  loss_rpn_box_reg: 0.0181 (0.0328)  time: 0.2814  data: 0.1402  max mem: 1751\n",
      "Training Epoch: [32]  [ 690/1229]  eta: 0:02:29  lr: 0.000000  loss: 0.4198 (0.4329)  loss_classifier: 0.1508 (0.1539)  loss_box_reg: 0.1255 (0.1474)  loss_objectness: 0.0949 (0.0990)  loss_rpn_box_reg: 0.0181 (0.0327)  time: 0.2791  data: 0.1385  max mem: 1751\n",
      "Training Epoch: [32]  [ 700/1229]  eta: 0:02:27  lr: 0.000000  loss: 0.4759 (0.4342)  loss_classifier: 0.1578 (0.1543)  loss_box_reg: 0.1494 (0.1481)  loss_objectness: 0.1101 (0.0992)  loss_rpn_box_reg: 0.0204 (0.0326)  time: 0.2736  data: 0.1396  max mem: 1751\n",
      "Training Epoch: [32]  [ 710/1229]  eta: 0:02:24  lr: 0.000000  loss: 0.3977 (0.4333)  loss_classifier: 0.1422 (0.1541)  loss_box_reg: 0.1107 (0.1476)  loss_objectness: 0.0977 (0.0991)  loss_rpn_box_reg: 0.0199 (0.0325)  time: 0.2765  data: 0.1388  max mem: 1751\n",
      "Training Epoch: [32]  [ 720/1229]  eta: 0:02:21  lr: 0.000000  loss: 0.2857 (0.4313)  loss_classifier: 0.1040 (0.1534)  loss_box_reg: 0.0849 (0.1470)  loss_objectness: 0.0705 (0.0986)  loss_rpn_box_reg: 0.0149 (0.0323)  time: 0.2781  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [32]  [ 730/1229]  eta: 0:02:18  lr: 0.000000  loss: 0.2472 (0.4302)  loss_classifier: 0.1040 (0.1529)  loss_box_reg: 0.0786 (0.1465)  loss_objectness: 0.0663 (0.0985)  loss_rpn_box_reg: 0.0146 (0.0323)  time: 0.2796  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [32]  [ 740/1229]  eta: 0:02:15  lr: 0.000000  loss: 0.3047 (0.4311)  loss_classifier: 0.1068 (0.1532)  loss_box_reg: 0.1263 (0.1465)  loss_objectness: 0.0791 (0.0987)  loss_rpn_box_reg: 0.0190 (0.0326)  time: 0.2758  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [32]  [ 750/1229]  eta: 0:02:13  lr: 0.000000  loss: 0.4704 (0.4326)  loss_classifier: 0.1738 (0.1538)  loss_box_reg: 0.1610 (0.1469)  loss_objectness: 0.1168 (0.0992)  loss_rpn_box_reg: 0.0269 (0.0326)  time: 0.2671  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [32]  [ 760/1229]  eta: 0:02:10  lr: 0.000000  loss: 0.4704 (0.4340)  loss_classifier: 0.1606 (0.1541)  loss_box_reg: 0.1383 (0.1475)  loss_objectness: 0.1075 (0.0994)  loss_rpn_box_reg: 0.0307 (0.0330)  time: 0.2662  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [32]  [ 770/1229]  eta: 0:02:07  lr: 0.000000  loss: 0.3556 (0.4331)  loss_classifier: 0.1411 (0.1539)  loss_box_reg: 0.1327 (0.1472)  loss_objectness: 0.0772 (0.0992)  loss_rpn_box_reg: 0.0187 (0.0329)  time: 0.2692  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [32]  [ 780/1229]  eta: 0:02:04  lr: 0.000000  loss: 0.3925 (0.4347)  loss_classifier: 0.1389 (0.1547)  loss_box_reg: 0.1388 (0.1478)  loss_objectness: 0.0830 (0.0995)  loss_rpn_box_reg: 0.0146 (0.0328)  time: 0.2789  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [32]  [ 790/1229]  eta: 0:02:01  lr: 0.000000  loss: 0.3210 (0.4336)  loss_classifier: 0.1219 (0.1543)  loss_box_reg: 0.0958 (0.1475)  loss_objectness: 0.0699 (0.0991)  loss_rpn_box_reg: 0.0114 (0.0326)  time: 0.2834  data: 0.1378  max mem: 1751\n",
      "Training Epoch: [32]  [ 800/1229]  eta: 0:01:59  lr: 0.000000  loss: 0.2754 (0.4338)  loss_classifier: 0.1028 (0.1544)  loss_box_reg: 0.0717 (0.1476)  loss_objectness: 0.0554 (0.0990)  loss_rpn_box_reg: 0.0157 (0.0329)  time: 0.2857  data: 0.1398  max mem: 1751\n",
      "Training Epoch: [32]  [ 810/1229]  eta: 0:01:56  lr: 0.000000  loss: 0.2910 (0.4327)  loss_classifier: 0.1090 (0.1540)  loss_box_reg: 0.1006 (0.1473)  loss_objectness: 0.0679 (0.0987)  loss_rpn_box_reg: 0.0157 (0.0327)  time: 0.2828  data: 0.1373  max mem: 1751\n",
      "Training Epoch: [32]  [ 820/1229]  eta: 0:01:53  lr: 0.000000  loss: 0.3138 (0.4320)  loss_classifier: 0.1107 (0.1538)  loss_box_reg: 0.1077 (0.1471)  loss_objectness: 0.0679 (0.0985)  loss_rpn_box_reg: 0.0116 (0.0326)  time: 0.2779  data: 0.1377  max mem: 1751\n",
      "Training Epoch: [32]  [ 830/1229]  eta: 0:01:50  lr: 0.000000  loss: 0.3174 (0.4314)  loss_classifier: 0.1127 (0.1537)  loss_box_reg: 0.1136 (0.1466)  loss_objectness: 0.0569 (0.0986)  loss_rpn_box_reg: 0.0205 (0.0326)  time: 0.2836  data: 0.1373  max mem: 1751\n",
      "Training Epoch: [32]  [ 840/1229]  eta: 0:01:48  lr: 0.000000  loss: 0.3072 (0.4317)  loss_classifier: 0.1385 (0.1537)  loss_box_reg: 0.0957 (0.1470)  loss_objectness: 0.0742 (0.0984)  loss_rpn_box_reg: 0.0205 (0.0326)  time: 0.2820  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [32]  [ 850/1229]  eta: 0:01:45  lr: 0.000000  loss: 0.4918 (0.4326)  loss_classifier: 0.1638 (0.1538)  loss_box_reg: 0.1869 (0.1472)  loss_objectness: 0.0817 (0.0986)  loss_rpn_box_reg: 0.0200 (0.0329)  time: 0.2785  data: 0.1386  max mem: 1751\n",
      "Training Epoch: [32]  [ 860/1229]  eta: 0:01:42  lr: 0.000000  loss: 0.4590 (0.4328)  loss_classifier: 0.1570 (0.1539)  loss_box_reg: 0.1348 (0.1471)  loss_objectness: 0.1032 (0.0986)  loss_rpn_box_reg: 0.0243 (0.0332)  time: 0.2753  data: 0.1382  max mem: 1751\n",
      "Training Epoch: [32]  [ 870/1229]  eta: 0:01:39  lr: 0.000000  loss: 0.3877 (0.4332)  loss_classifier: 0.1519 (0.1541)  loss_box_reg: 0.1290 (0.1469)  loss_objectness: 0.1000 (0.0989)  loss_rpn_box_reg: 0.0221 (0.0332)  time: 0.2756  data: 0.1373  max mem: 1751\n",
      "Training Epoch: [32]  [ 880/1229]  eta: 0:01:36  lr: 0.000000  loss: 0.3773 (0.4322)  loss_classifier: 0.1383 (0.1538)  loss_box_reg: 0.1072 (0.1464)  loss_objectness: 0.0979 (0.0988)  loss_rpn_box_reg: 0.0180 (0.0332)  time: 0.2765  data: 0.1391  max mem: 1751\n",
      "Training Epoch: [32]  [ 890/1229]  eta: 0:01:34  lr: 0.000000  loss: 0.4252 (0.4333)  loss_classifier: 0.1404 (0.1541)  loss_box_reg: 0.1277 (0.1471)  loss_objectness: 0.0979 (0.0988)  loss_rpn_box_reg: 0.0296 (0.0333)  time: 0.2769  data: 0.1396  max mem: 1751\n",
      "Training Epoch: [32]  [ 900/1229]  eta: 0:01:31  lr: 0.000000  loss: 0.4026 (0.4319)  loss_classifier: 0.1249 (0.1536)  loss_box_reg: 0.1168 (0.1464)  loss_objectness: 0.0803 (0.0987)  loss_rpn_box_reg: 0.0187 (0.0332)  time: 0.2793  data: 0.1404  max mem: 1751\n",
      "Training Epoch: [32]  [ 910/1229]  eta: 0:01:28  lr: 0.000000  loss: 0.3245 (0.4324)  loss_classifier: 0.1012 (0.1538)  loss_box_reg: 0.0934 (0.1464)  loss_objectness: 0.0987 (0.0990)  loss_rpn_box_reg: 0.0202 (0.0332)  time: 0.2748  data: 0.1404  max mem: 1751\n",
      "Training Epoch: [32]  [ 920/1229]  eta: 0:01:25  lr: 0.000000  loss: 0.3728 (0.4321)  loss_classifier: 0.1282 (0.1537)  loss_box_reg: 0.1207 (0.1461)  loss_objectness: 0.0987 (0.0991)  loss_rpn_box_reg: 0.0235 (0.0331)  time: 0.2754  data: 0.1382  max mem: 1751\n",
      "Training Epoch: [32]  [ 930/1229]  eta: 0:01:23  lr: 0.000000  loss: 0.3530 (0.4328)  loss_classifier: 0.1321 (0.1539)  loss_box_reg: 0.1207 (0.1465)  loss_objectness: 0.1006 (0.0992)  loss_rpn_box_reg: 0.0250 (0.0332)  time: 0.2740  data: 0.1372  max mem: 1751\n",
      "Training Epoch: [32]  [ 940/1229]  eta: 0:01:20  lr: 0.000000  loss: 0.3929 (0.4321)  loss_classifier: 0.1421 (0.1538)  loss_box_reg: 0.1238 (0.1462)  loss_objectness: 0.0984 (0.0990)  loss_rpn_box_reg: 0.0250 (0.0332)  time: 0.2721  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [32]  [ 950/1229]  eta: 0:01:17  lr: 0.000000  loss: 0.2709 (0.4319)  loss_classifier: 0.1029 (0.1536)  loss_box_reg: 0.0778 (0.1461)  loss_objectness: 0.0672 (0.0989)  loss_rpn_box_reg: 0.0184 (0.0332)  time: 0.2763  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [32]  [ 960/1229]  eta: 0:01:14  lr: 0.000000  loss: 0.3257 (0.4322)  loss_classifier: 0.1293 (0.1537)  loss_box_reg: 0.1033 (0.1461)  loss_objectness: 0.0717 (0.0991)  loss_rpn_box_reg: 0.0140 (0.0333)  time: 0.2803  data: 0.1373  max mem: 1751\n",
      "Training Epoch: [32]  [ 970/1229]  eta: 0:01:11  lr: 0.000000  loss: 0.3257 (0.4318)  loss_classifier: 0.1293 (0.1536)  loss_box_reg: 0.1115 (0.1460)  loss_objectness: 0.0717 (0.0989)  loss_rpn_box_reg: 0.0142 (0.0332)  time: 0.2796  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [32]  [ 980/1229]  eta: 0:01:09  lr: 0.000000  loss: 0.3900 (0.4319)  loss_classifier: 0.1220 (0.1537)  loss_box_reg: 0.1155 (0.1462)  loss_objectness: 0.0837 (0.0989)  loss_rpn_box_reg: 0.0186 (0.0332)  time: 0.2780  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [32]  [ 990/1229]  eta: 0:01:06  lr: 0.000000  loss: 0.4032 (0.4321)  loss_classifier: 0.1410 (0.1538)  loss_box_reg: 0.1368 (0.1463)  loss_objectness: 0.0889 (0.0989)  loss_rpn_box_reg: 0.0244 (0.0332)  time: 0.2818  data: 0.1388  max mem: 1751\n",
      "Training Epoch: [32]  [1000/1229]  eta: 0:01:03  lr: 0.000000  loss: 0.4343 (0.4329)  loss_classifier: 0.1606 (0.1540)  loss_box_reg: 0.1382 (0.1465)  loss_objectness: 0.0948 (0.0990)  loss_rpn_box_reg: 0.0343 (0.0335)  time: 0.2809  data: 0.1381  max mem: 1751\n",
      "Training Epoch: [32]  [1010/1229]  eta: 0:01:00  lr: 0.000000  loss: 0.4183 (0.4324)  loss_classifier: 0.1521 (0.1538)  loss_box_reg: 0.1353 (0.1463)  loss_objectness: 0.0910 (0.0990)  loss_rpn_box_reg: 0.0265 (0.0333)  time: 0.2784  data: 0.1375  max mem: 1751\n",
      "Training Epoch: [32]  [1020/1229]  eta: 0:00:58  lr: 0.000000  loss: 0.4092 (0.4331)  loss_classifier: 0.1472 (0.1539)  loss_box_reg: 0.1301 (0.1465)  loss_objectness: 0.0891 (0.0991)  loss_rpn_box_reg: 0.0265 (0.0335)  time: 0.2781  data: 0.1380  max mem: 1751\n",
      "Training Epoch: [32]  [1030/1229]  eta: 0:00:55  lr: 0.000000  loss: 0.4821 (0.4335)  loss_classifier: 0.1538 (0.1541)  loss_box_reg: 0.1501 (0.1466)  loss_objectness: 0.1093 (0.0993)  loss_rpn_box_reg: 0.0267 (0.0336)  time: 0.2796  data: 0.1394  max mem: 1751\n",
      "Training Epoch: [32]  [1040/1229]  eta: 0:00:52  lr: 0.000000  loss: 0.4384 (0.4331)  loss_classifier: 0.1455 (0.1539)  loss_box_reg: 0.1299 (0.1464)  loss_objectness: 0.1019 (0.0993)  loss_rpn_box_reg: 0.0210 (0.0336)  time: 0.2817  data: 0.1409  max mem: 1751\n",
      "Training Epoch: [32]  [1050/1229]  eta: 0:00:49  lr: 0.000000  loss: 0.3970 (0.4326)  loss_classifier: 0.1455 (0.1538)  loss_box_reg: 0.1254 (0.1461)  loss_objectness: 0.1028 (0.0993)  loss_rpn_box_reg: 0.0191 (0.0335)  time: 0.2786  data: 0.1395  max mem: 1751\n",
      "Training Epoch: [32]  [1060/1229]  eta: 0:00:46  lr: 0.000000  loss: 0.4120 (0.4319)  loss_classifier: 0.1436 (0.1536)  loss_box_reg: 0.1036 (0.1459)  loss_objectness: 0.0884 (0.0991)  loss_rpn_box_reg: 0.0176 (0.0334)  time: 0.2763  data: 0.1378  max mem: 1751\n",
      "Training Epoch: [32]  [1070/1229]  eta: 0:00:44  lr: 0.000000  loss: 0.4332 (0.4326)  loss_classifier: 0.1597 (0.1539)  loss_box_reg: 0.1617 (0.1463)  loss_objectness: 0.0751 (0.0990)  loss_rpn_box_reg: 0.0186 (0.0335)  time: 0.2810  data: 0.1394  max mem: 1751\n",
      "Training Epoch: [32]  [1080/1229]  eta: 0:00:41  lr: 0.000000  loss: 0.4786 (0.4328)  loss_classifier: 0.1823 (0.1539)  loss_box_reg: 0.1766 (0.1465)  loss_objectness: 0.0868 (0.0989)  loss_rpn_box_reg: 0.0188 (0.0334)  time: 0.2861  data: 0.1409  max mem: 1751\n",
      "Training Epoch: [32]  [1090/1229]  eta: 0:00:38  lr: 0.000000  loss: 0.3710 (0.4320)  loss_classifier: 0.1222 (0.1537)  loss_box_reg: 0.1025 (0.1462)  loss_objectness: 0.0858 (0.0988)  loss_rpn_box_reg: 0.0188 (0.0333)  time: 0.2836  data: 0.1398  max mem: 1751\n",
      "Training Epoch: [32]  [1100/1229]  eta: 0:00:35  lr: 0.000000  loss: 0.3450 (0.4319)  loss_classifier: 0.1216 (0.1537)  loss_box_reg: 0.0936 (0.1460)  loss_objectness: 0.0844 (0.0989)  loss_rpn_box_reg: 0.0204 (0.0333)  time: 0.2812  data: 0.1402  max mem: 1751\n",
      "Training Epoch: [32]  [1110/1229]  eta: 0:00:33  lr: 0.000000  loss: 0.3090 (0.4306)  loss_classifier: 0.1158 (0.1533)  loss_box_reg: 0.0898 (0.1454)  loss_objectness: 0.0803 (0.0987)  loss_rpn_box_reg: 0.0180 (0.0332)  time: 0.2813  data: 0.1406  max mem: 1751\n",
      "Training Epoch: [32]  [1120/1229]  eta: 0:00:30  lr: 0.000000  loss: 0.3333 (0.4309)  loss_classifier: 0.1180 (0.1534)  loss_box_reg: 0.0925 (0.1453)  loss_objectness: 0.0803 (0.0989)  loss_rpn_box_reg: 0.0223 (0.0333)  time: 0.2750  data: 0.1406  max mem: 1751\n",
      "Training Epoch: [32]  [1130/1229]  eta: 0:00:27  lr: 0.000000  loss: 0.3588 (0.4309)  loss_classifier: 0.1251 (0.1535)  loss_box_reg: 0.1078 (0.1453)  loss_objectness: 0.1019 (0.0989)  loss_rpn_box_reg: 0.0276 (0.0333)  time: 0.2723  data: 0.1379  max mem: 1751\n",
      "Training Epoch: [32]  [1140/1229]  eta: 0:00:24  lr: 0.000000  loss: 0.4673 (0.4322)  loss_classifier: 0.1787 (0.1539)  loss_box_reg: 0.1455 (0.1457)  loss_objectness: 0.1053 (0.0991)  loss_rpn_box_reg: 0.0283 (0.0336)  time: 0.2785  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [32]  [1150/1229]  eta: 0:00:21  lr: 0.000000  loss: 0.5259 (0.4328)  loss_classifier: 0.1818 (0.1541)  loss_box_reg: 0.1599 (0.1458)  loss_objectness: 0.1108 (0.0993)  loss_rpn_box_reg: 0.0283 (0.0336)  time: 0.2815  data: 0.1410  max mem: 1751\n",
      "Training Epoch: [32]  [1160/1229]  eta: 0:00:19  lr: 0.000000  loss: 0.4065 (0.4334)  loss_classifier: 0.1418 (0.1542)  loss_box_reg: 0.1567 (0.1460)  loss_objectness: 0.1013 (0.0993)  loss_rpn_box_reg: 0.0315 (0.0338)  time: 0.2846  data: 0.1417  max mem: 1751\n",
      "Training Epoch: [32]  [1170/1229]  eta: 0:00:16  lr: 0.000000  loss: 0.5007 (0.4340)  loss_classifier: 0.1486 (0.1545)  loss_box_reg: 0.1567 (0.1463)  loss_objectness: 0.0713 (0.0992)  loss_rpn_box_reg: 0.0204 (0.0340)  time: 0.2784  data: 0.1380  max mem: 1751\n",
      "Training Epoch: [32]  [1180/1229]  eta: 0:00:13  lr: 0.000000  loss: 0.4007 (0.4341)  loss_classifier: 0.1611 (0.1545)  loss_box_reg: 0.1357 (0.1464)  loss_objectness: 0.0862 (0.0992)  loss_rpn_box_reg: 0.0204 (0.0339)  time: 0.2752  data: 0.1375  max mem: 1751\n",
      "Training Epoch: [32]  [1190/1229]  eta: 0:00:10  lr: 0.000000  loss: 0.3243 (0.4331)  loss_classifier: 0.1088 (0.1542)  loss_box_reg: 0.0872 (0.1460)  loss_objectness: 0.0857 (0.0991)  loss_rpn_box_reg: 0.0208 (0.0338)  time: 0.2810  data: 0.1378  max mem: 1751\n",
      "Training Epoch: [32]  [1200/1229]  eta: 0:00:08  lr: 0.000000  loss: 0.2704 (0.4327)  loss_classifier: 0.1030 (0.1541)  loss_box_reg: 0.0723 (0.1458)  loss_objectness: 0.0709 (0.0991)  loss_rpn_box_reg: 0.0163 (0.0338)  time: 0.2809  data: 0.1382  max mem: 1751\n",
      "Training Epoch: [32]  [1210/1229]  eta: 0:00:05  lr: 0.000000  loss: 0.3620 (0.4325)  loss_classifier: 0.1223 (0.1540)  loss_box_reg: 0.0876 (0.1457)  loss_objectness: 0.0705 (0.0990)  loss_rpn_box_reg: 0.0198 (0.0338)  time: 0.2816  data: 0.1403  max mem: 1751\n",
      "Training Epoch: [32]  [1220/1229]  eta: 0:00:02  lr: 0.000000  loss: 0.4615 (0.4336)  loss_classifier: 0.1608 (0.1544)  loss_box_reg: 0.1335 (0.1462)  loss_objectness: 0.0990 (0.0992)  loss_rpn_box_reg: 0.0312 (0.0338)  time: 0.2798  data: 0.1393  max mem: 1751\n",
      "Training Epoch: [32]  [1228/1229]  eta: 0:00:00  lr: 0.000000  loss: 0.4806 (0.4336)  loss_classifier: 0.1667 (0.1544)  loss_box_reg: 0.1335 (0.1460)  loss_objectness: 0.1104 (0.0994)  loss_rpn_box_reg: 0.0312 (0.0339)  time: 0.2758  data: 0.1373  max mem: 1751\n",
      "Training Epoch: [32] Total time: 0:05:42 (0.2783 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:57  model_time: 0.3480 (0.3480)  evaluator_time: 0.0020 (0.0020)  time: 0.3800  data: 0.0280  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0790 (0.0827)  evaluator_time: 0.0050 (0.0086)  time: 0.1271  data: 0.0357  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0830 (0.0814)  evaluator_time: 0.0030 (0.0079)  time: 0.1199  data: 0.0306  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0730 (0.0804)  evaluator_time: 0.0040 (0.0077)  time: 0.1195  data: 0.0354  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0730 (0.0803)  evaluator_time: 0.0020 (0.0077)  time: 0.1164  data: 0.0336  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1241 s / it)\n",
      "Averaged stats: model_time: 0.0730 (0.0803)  evaluator_time: 0.0020 (0.0077)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [32]  [  0/308]  eta: 0:00:38  lr: 0.000000  loss: 0.1702 (0.1702)  loss_classifier: 0.0592 (0.0592)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0311 (0.0311)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1240  data: 0.0280  max mem: 1751\n",
      "Testing Epoch: [32]  [100/308]  eta: 0:00:28  lr: 0.000000  loss: 0.3094 (0.4800)  loss_classifier: 0.1333 (0.1543)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0561 (0.1015)  loss_rpn_box_reg: 0.0186 (0.0520)  time: 0.1397  data: 0.0379  max mem: 1751\n",
      "Testing Epoch: [32]  [200/308]  eta: 0:00:14  lr: 0.000000  loss: 0.3579 (0.4567)  loss_classifier: 0.1388 (0.1489)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0662 (0.0955)  loss_rpn_box_reg: 0.0197 (0.0491)  time: 0.1383  data: 0.0326  max mem: 1751\n",
      "Testing Epoch: [32]  [300/308]  eta: 0:00:01  lr: 0.000000  loss: 0.4628 (0.4538)  loss_classifier: 0.1584 (0.1492)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0747 (0.0930)  loss_rpn_box_reg: 0.0265 (0.0475)  time: 0.1375  data: 0.0423  max mem: 1751\n",
      "Testing Epoch: [32]  [307/308]  eta: 0:00:00  lr: 0.000000  loss: 0.4608 (0.4540)  loss_classifier: 0.1860 (0.1495)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0747 (0.0931)  loss_rpn_box_reg: 0.0271 (0.0470)  time: 0.1307  data: 0.0360  max mem: 1751\n",
      "Testing Epoch: [32] Total time: 0:00:42 (0.1371 s / it)\n",
      "Training Epoch: [33]  [   0/1229]  eta: 0:05:13  lr: 0.000000  loss: 0.9788 (0.9788)  loss_classifier: 0.3181 (0.3181)  loss_box_reg: 0.4460 (0.4460)  loss_objectness: 0.1374 (0.1374)  loss_rpn_box_reg: 0.0773 (0.0773)  time: 0.2550  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [33]  [  10/1229]  eta: 0:05:40  lr: 0.000000  loss: 0.3707 (0.4010)  loss_classifier: 0.1523 (0.1482)  loss_box_reg: 0.1066 (0.1379)  loss_objectness: 0.0796 (0.0833)  loss_rpn_box_reg: 0.0193 (0.0316)  time: 0.2796  data: 0.1368  max mem: 1751\n",
      "Training Epoch: [33]  [  20/1229]  eta: 0:05:43  lr: 0.000000  loss: 0.3795 (0.4202)  loss_classifier: 0.1396 (0.1490)  loss_box_reg: 0.1100 (0.1441)  loss_objectness: 0.0796 (0.0922)  loss_rpn_box_reg: 0.0181 (0.0348)  time: 0.2854  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [33]  [  30/1229]  eta: 0:05:36  lr: 0.000000  loss: 0.4365 (0.4756)  loss_classifier: 0.1592 (0.1656)  loss_box_reg: 0.1157 (0.1670)  loss_objectness: 0.1223 (0.1019)  loss_rpn_box_reg: 0.0245 (0.0411)  time: 0.2811  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [33]  [  40/1229]  eta: 0:05:33  lr: 0.000000  loss: 0.4434 (0.4598)  loss_classifier: 0.1680 (0.1638)  loss_box_reg: 0.1161 (0.1624)  loss_objectness: 0.1159 (0.0979)  loss_rpn_box_reg: 0.0245 (0.0356)  time: 0.2760  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [33]  [  50/1229]  eta: 0:05:28  lr: 0.000000  loss: 0.4725 (0.4753)  loss_classifier: 0.1750 (0.1684)  loss_box_reg: 0.1483 (0.1648)  loss_objectness: 0.1159 (0.1054)  loss_rpn_box_reg: 0.0203 (0.0367)  time: 0.2751  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [33]  [  60/1229]  eta: 0:05:25  lr: 0.000000  loss: 0.4725 (0.4812)  loss_classifier: 0.1709 (0.1708)  loss_box_reg: 0.1776 (0.1677)  loss_objectness: 0.1162 (0.1058)  loss_rpn_box_reg: 0.0203 (0.0369)  time: 0.2753  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [33]  [  70/1229]  eta: 0:05:22  lr: 0.000000  loss: 0.4225 (0.4663)  loss_classifier: 0.1555 (0.1654)  loss_box_reg: 0.1451 (0.1599)  loss_objectness: 0.0924 (0.1040)  loss_rpn_box_reg: 0.0215 (0.0370)  time: 0.2790  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [33]  [  80/1229]  eta: 0:05:19  lr: 0.000000  loss: 0.4206 (0.4626)  loss_classifier: 0.1331 (0.1636)  loss_box_reg: 0.0951 (0.1577)  loss_objectness: 0.0854 (0.1038)  loss_rpn_box_reg: 0.0241 (0.0374)  time: 0.2767  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [33]  [  90/1229]  eta: 0:05:15  lr: 0.000000  loss: 0.4610 (0.4713)  loss_classifier: 0.1331 (0.1661)  loss_box_reg: 0.1521 (0.1612)  loss_objectness: 0.1012 (0.1057)  loss_rpn_box_reg: 0.0247 (0.0384)  time: 0.2731  data: 0.1384  max mem: 1751\n",
      "Training Epoch: [33]  [ 100/1229]  eta: 0:05:12  lr: 0.000000  loss: 0.5760 (0.4897)  loss_classifier: 0.1808 (0.1728)  loss_box_reg: 0.1694 (0.1687)  loss_objectness: 0.1029 (0.1095)  loss_rpn_box_reg: 0.0286 (0.0386)  time: 0.2726  data: 0.1401  max mem: 1751\n",
      "Training Epoch: [33]  [ 110/1229]  eta: 0:05:09  lr: 0.000000  loss: 0.4911 (0.4909)  loss_classifier: 0.1925 (0.1741)  loss_box_reg: 0.1697 (0.1703)  loss_objectness: 0.1098 (0.1096)  loss_rpn_box_reg: 0.0203 (0.0369)  time: 0.2748  data: 0.1382  max mem: 1751\n",
      "Training Epoch: [33]  [ 120/1229]  eta: 0:05:06  lr: 0.000000  loss: 0.3717 (0.4779)  loss_classifier: 0.1211 (0.1696)  loss_box_reg: 0.1031 (0.1636)  loss_objectness: 0.0999 (0.1092)  loss_rpn_box_reg: 0.0182 (0.0355)  time: 0.2723  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [33]  [ 130/1229]  eta: 0:05:03  lr: 0.000000  loss: 0.3454 (0.4760)  loss_classifier: 0.1177 (0.1687)  loss_box_reg: 0.1009 (0.1649)  loss_objectness: 0.0926 (0.1071)  loss_rpn_box_reg: 0.0190 (0.0353)  time: 0.2723  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [33]  [ 140/1229]  eta: 0:05:00  lr: 0.000000  loss: 0.4293 (0.4727)  loss_classifier: 0.1588 (0.1675)  loss_box_reg: 0.1455 (0.1634)  loss_objectness: 0.0746 (0.1065)  loss_rpn_box_reg: 0.0190 (0.0353)  time: 0.2744  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [33]  [ 150/1229]  eta: 0:04:57  lr: 0.000000  loss: 0.4133 (0.4653)  loss_classifier: 0.1465 (0.1648)  loss_box_reg: 0.1335 (0.1605)  loss_objectness: 0.0850 (0.1050)  loss_rpn_box_reg: 0.0224 (0.0349)  time: 0.2733  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [33]  [ 160/1229]  eta: 0:04:54  lr: 0.000000  loss: 0.3361 (0.4555)  loss_classifier: 0.1228 (0.1619)  loss_box_reg: 0.0956 (0.1570)  loss_objectness: 0.0846 (0.1026)  loss_rpn_box_reg: 0.0145 (0.0339)  time: 0.2714  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [33]  [ 170/1229]  eta: 0:04:52  lr: 0.000000  loss: 0.3240 (0.4478)  loss_classifier: 0.1195 (0.1590)  loss_box_reg: 0.0962 (0.1535)  loss_objectness: 0.0703 (0.1019)  loss_rpn_box_reg: 0.0136 (0.0333)  time: 0.2756  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [33]  [ 180/1229]  eta: 0:04:48  lr: 0.000000  loss: 0.2670 (0.4429)  loss_classifier: 0.1050 (0.1571)  loss_box_reg: 0.0814 (0.1514)  loss_objectness: 0.0750 (0.1011)  loss_rpn_box_reg: 0.0222 (0.0333)  time: 0.2747  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [33]  [ 190/1229]  eta: 0:04:46  lr: 0.000000  loss: 0.3832 (0.4443)  loss_classifier: 0.1263 (0.1580)  loss_box_reg: 0.0814 (0.1515)  loss_objectness: 0.0878 (0.1016)  loss_rpn_box_reg: 0.0228 (0.0333)  time: 0.2748  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [33]  [ 200/1229]  eta: 0:04:43  lr: 0.000000  loss: 0.2953 (0.4412)  loss_classifier: 0.1155 (0.1569)  loss_box_reg: 0.1014 (0.1506)  loss_objectness: 0.0740 (0.1010)  loss_rpn_box_reg: 0.0172 (0.0327)  time: 0.2786  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [33]  [ 210/1229]  eta: 0:04:40  lr: 0.000000  loss: 0.2953 (0.4378)  loss_classifier: 0.1042 (0.1558)  loss_box_reg: 0.1014 (0.1495)  loss_objectness: 0.0740 (0.1003)  loss_rpn_box_reg: 0.0145 (0.0323)  time: 0.2704  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [33]  [ 220/1229]  eta: 0:04:37  lr: 0.000000  loss: 0.3396 (0.4356)  loss_classifier: 0.1345 (0.1550)  loss_box_reg: 0.1132 (0.1490)  loss_objectness: 0.0831 (0.0994)  loss_rpn_box_reg: 0.0188 (0.0322)  time: 0.2730  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [33]  [ 230/1229]  eta: 0:04:35  lr: 0.000000  loss: 0.3452 (0.4345)  loss_classifier: 0.1195 (0.1545)  loss_box_reg: 0.1158 (0.1479)  loss_objectness: 0.0705 (0.0998)  loss_rpn_box_reg: 0.0188 (0.0322)  time: 0.2780  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [33]  [ 240/1229]  eta: 0:04:32  lr: 0.000000  loss: 0.4047 (0.4334)  loss_classifier: 0.1195 (0.1540)  loss_box_reg: 0.1160 (0.1477)  loss_objectness: 0.0728 (0.0994)  loss_rpn_box_reg: 0.0188 (0.0324)  time: 0.2748  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [33]  [ 250/1229]  eta: 0:04:29  lr: 0.000000  loss: 0.4622 (0.4373)  loss_classifier: 0.1752 (0.1554)  loss_box_reg: 0.1520 (0.1487)  loss_objectness: 0.0960 (0.1006)  loss_rpn_box_reg: 0.0260 (0.0327)  time: 0.2703  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [33]  [ 260/1229]  eta: 0:04:26  lr: 0.000000  loss: 0.5162 (0.4414)  loss_classifier: 0.1836 (0.1568)  loss_box_reg: 0.1732 (0.1511)  loss_objectness: 0.1114 (0.1009)  loss_rpn_box_reg: 0.0286 (0.0326)  time: 0.2687  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [33]  [ 270/1229]  eta: 0:04:23  lr: 0.000000  loss: 0.5308 (0.4432)  loss_classifier: 0.1727 (0.1572)  loss_box_reg: 0.1785 (0.1520)  loss_objectness: 0.0799 (0.1006)  loss_rpn_box_reg: 0.0249 (0.0335)  time: 0.2763  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [33]  [ 280/1229]  eta: 0:04:20  lr: 0.000000  loss: 0.5352 (0.4430)  loss_classifier: 0.1575 (0.1573)  loss_box_reg: 0.1785 (0.1517)  loss_objectness: 0.0940 (0.1003)  loss_rpn_box_reg: 0.0201 (0.0336)  time: 0.2749  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [33]  [ 290/1229]  eta: 0:04:18  lr: 0.000000  loss: 0.4359 (0.4431)  loss_classifier: 0.1510 (0.1570)  loss_box_reg: 0.1643 (0.1519)  loss_objectness: 0.0940 (0.1000)  loss_rpn_box_reg: 0.0210 (0.0342)  time: 0.2716  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [33]  [ 300/1229]  eta: 0:04:15  lr: 0.000000  loss: 0.4262 (0.4412)  loss_classifier: 0.1475 (0.1565)  loss_box_reg: 0.1383 (0.1511)  loss_objectness: 0.0736 (0.0994)  loss_rpn_box_reg: 0.0264 (0.0342)  time: 0.2724  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [33]  [ 310/1229]  eta: 0:04:12  lr: 0.000000  loss: 0.3726 (0.4408)  loss_classifier: 0.1379 (0.1564)  loss_box_reg: 0.1184 (0.1510)  loss_objectness: 0.0835 (0.0991)  loss_rpn_box_reg: 0.0194 (0.0343)  time: 0.2761  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [33]  [ 320/1229]  eta: 0:04:09  lr: 0.000000  loss: 0.3617 (0.4412)  loss_classifier: 0.1288 (0.1561)  loss_box_reg: 0.1114 (0.1508)  loss_objectness: 0.0907 (0.1002)  loss_rpn_box_reg: 0.0195 (0.0341)  time: 0.2795  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [33]  [ 330/1229]  eta: 0:04:07  lr: 0.000000  loss: 0.5404 (0.4451)  loss_classifier: 0.1626 (0.1579)  loss_box_reg: 0.1465 (0.1518)  loss_objectness: 0.1246 (0.1010)  loss_rpn_box_reg: 0.0270 (0.0345)  time: 0.2793  data: 0.1372  max mem: 1751\n",
      "Training Epoch: [33]  [ 340/1229]  eta: 0:04:04  lr: 0.000000  loss: 0.5404 (0.4468)  loss_classifier: 0.1902 (0.1582)  loss_box_reg: 0.1783 (0.1525)  loss_objectness: 0.1109 (0.1014)  loss_rpn_box_reg: 0.0286 (0.0347)  time: 0.2828  data: 0.1385  max mem: 1751\n",
      "Training Epoch: [33]  [ 350/1229]  eta: 0:04:01  lr: 0.000000  loss: 0.3666 (0.4446)  loss_classifier: 0.1357 (0.1575)  loss_box_reg: 0.1139 (0.1513)  loss_objectness: 0.0897 (0.1015)  loss_rpn_box_reg: 0.0189 (0.0343)  time: 0.2747  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [33]  [ 360/1229]  eta: 0:03:59  lr: 0.000000  loss: 0.3868 (0.4456)  loss_classifier: 0.1332 (0.1579)  loss_box_reg: 0.0997 (0.1519)  loss_objectness: 0.0893 (0.1016)  loss_rpn_box_reg: 0.0172 (0.0343)  time: 0.2682  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [33]  [ 370/1229]  eta: 0:03:56  lr: 0.000000  loss: 0.4230 (0.4444)  loss_classifier: 0.1385 (0.1574)  loss_box_reg: 0.1100 (0.1511)  loss_objectness: 0.0883 (0.1016)  loss_rpn_box_reg: 0.0201 (0.0343)  time: 0.2718  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [33]  [ 380/1229]  eta: 0:03:53  lr: 0.000000  loss: 0.3932 (0.4443)  loss_classifier: 0.1267 (0.1572)  loss_box_reg: 0.1229 (0.1512)  loss_objectness: 0.0883 (0.1015)  loss_rpn_box_reg: 0.0211 (0.0345)  time: 0.2753  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [33]  [ 390/1229]  eta: 0:03:50  lr: 0.000000  loss: 0.3318 (0.4431)  loss_classifier: 0.1230 (0.1563)  loss_box_reg: 0.0934 (0.1503)  loss_objectness: 0.0755 (0.1012)  loss_rpn_box_reg: 0.0225 (0.0353)  time: 0.2762  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [33]  [ 400/1229]  eta: 0:03:48  lr: 0.000000  loss: 0.2741 (0.4425)  loss_classifier: 0.0969 (0.1563)  loss_box_reg: 0.0804 (0.1503)  loss_objectness: 0.0751 (0.1010)  loss_rpn_box_reg: 0.0161 (0.0349)  time: 0.2761  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [33]  [ 410/1229]  eta: 0:03:45  lr: 0.000000  loss: 0.3813 (0.4426)  loss_classifier: 0.1388 (0.1563)  loss_box_reg: 0.1095 (0.1502)  loss_objectness: 0.0827 (0.1010)  loss_rpn_box_reg: 0.0164 (0.0350)  time: 0.2735  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [33]  [ 420/1229]  eta: 0:03:42  lr: 0.000000  loss: 0.4345 (0.4465)  loss_classifier: 0.1697 (0.1580)  loss_box_reg: 0.1560 (0.1515)  loss_objectness: 0.0893 (0.1017)  loss_rpn_box_reg: 0.0250 (0.0354)  time: 0.2738  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [33]  [ 430/1229]  eta: 0:03:39  lr: 0.000000  loss: 0.5478 (0.4480)  loss_classifier: 0.1920 (0.1584)  loss_box_reg: 0.1831 (0.1520)  loss_objectness: 0.0901 (0.1021)  loss_rpn_box_reg: 0.0283 (0.0355)  time: 0.2766  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [33]  [ 440/1229]  eta: 0:03:37  lr: 0.000000  loss: 0.4367 (0.4472)  loss_classifier: 0.1456 (0.1582)  loss_box_reg: 0.1444 (0.1515)  loss_objectness: 0.0943 (0.1022)  loss_rpn_box_reg: 0.0311 (0.0354)  time: 0.2803  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [33]  [ 450/1229]  eta: 0:03:34  lr: 0.000000  loss: 0.3881 (0.4462)  loss_classifier: 0.1436 (0.1580)  loss_box_reg: 0.1044 (0.1511)  loss_objectness: 0.0910 (0.1020)  loss_rpn_box_reg: 0.0260 (0.0351)  time: 0.2819  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [33]  [ 460/1229]  eta: 0:03:31  lr: 0.000000  loss: 0.3444 (0.4441)  loss_classifier: 0.1300 (0.1571)  loss_box_reg: 0.1044 (0.1503)  loss_objectness: 0.0838 (0.1017)  loss_rpn_box_reg: 0.0161 (0.0350)  time: 0.2747  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [33]  [ 470/1229]  eta: 0:03:29  lr: 0.000000  loss: 0.3374 (0.4437)  loss_classifier: 0.1170 (0.1569)  loss_box_reg: 0.1187 (0.1500)  loss_objectness: 0.0703 (0.1012)  loss_rpn_box_reg: 0.0165 (0.0355)  time: 0.2755  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [33]  [ 480/1229]  eta: 0:03:26  lr: 0.000000  loss: 0.3945 (0.4448)  loss_classifier: 0.1170 (0.1573)  loss_box_reg: 0.1289 (0.1500)  loss_objectness: 0.0833 (0.1017)  loss_rpn_box_reg: 0.0307 (0.0358)  time: 0.2784  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [33]  [ 490/1229]  eta: 0:03:23  lr: 0.000000  loss: 0.4230 (0.4439)  loss_classifier: 0.1200 (0.1569)  loss_box_reg: 0.0972 (0.1494)  loss_objectness: 0.1077 (0.1017)  loss_rpn_box_reg: 0.0242 (0.0358)  time: 0.2752  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [33]  [ 500/1229]  eta: 0:03:20  lr: 0.000000  loss: 0.3827 (0.4436)  loss_classifier: 0.1486 (0.1570)  loss_box_reg: 0.1357 (0.1493)  loss_objectness: 0.0996 (0.1018)  loss_rpn_box_reg: 0.0233 (0.0356)  time: 0.2753  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [33]  [ 510/1229]  eta: 0:03:17  lr: 0.000000  loss: 0.3827 (0.4429)  loss_classifier: 0.1465 (0.1568)  loss_box_reg: 0.1010 (0.1491)  loss_objectness: 0.0933 (0.1017)  loss_rpn_box_reg: 0.0190 (0.0354)  time: 0.2727  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [33]  [ 520/1229]  eta: 0:03:15  lr: 0.000000  loss: 0.3830 (0.4421)  loss_classifier: 0.1312 (0.1565)  loss_box_reg: 0.1094 (0.1487)  loss_objectness: 0.0995 (0.1017)  loss_rpn_box_reg: 0.0190 (0.0352)  time: 0.2674  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [33]  [ 530/1229]  eta: 0:03:12  lr: 0.000000  loss: 0.3465 (0.4420)  loss_classifier: 0.1312 (0.1564)  loss_box_reg: 0.1198 (0.1490)  loss_objectness: 0.0860 (0.1015)  loss_rpn_box_reg: 0.0167 (0.0352)  time: 0.2727  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [33]  [ 540/1229]  eta: 0:03:09  lr: 0.000000  loss: 0.3470 (0.4420)  loss_classifier: 0.1342 (0.1564)  loss_box_reg: 0.1302 (0.1490)  loss_objectness: 0.0860 (0.1013)  loss_rpn_box_reg: 0.0167 (0.0352)  time: 0.2810  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [33]  [ 550/1229]  eta: 0:03:06  lr: 0.000000  loss: 0.3973 (0.4422)  loss_classifier: 0.1342 (0.1563)  loss_box_reg: 0.0985 (0.1486)  loss_objectness: 0.0886 (0.1019)  loss_rpn_box_reg: 0.0324 (0.0354)  time: 0.2756  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [33]  [ 560/1229]  eta: 0:03:04  lr: 0.000000  loss: 0.3973 (0.4421)  loss_classifier: 0.1169 (0.1563)  loss_box_reg: 0.0853 (0.1485)  loss_objectness: 0.0819 (0.1020)  loss_rpn_box_reg: 0.0278 (0.0353)  time: 0.2730  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [33]  [ 570/1229]  eta: 0:03:01  lr: 0.000000  loss: 0.3725 (0.4398)  loss_classifier: 0.1411 (0.1555)  loss_box_reg: 0.1024 (0.1475)  loss_objectness: 0.0865 (0.1018)  loss_rpn_box_reg: 0.0186 (0.0350)  time: 0.2731  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [33]  [ 580/1229]  eta: 0:02:58  lr: 0.000000  loss: 0.3256 (0.4396)  loss_classifier: 0.1305 (0.1556)  loss_box_reg: 0.1036 (0.1476)  loss_objectness: 0.0852 (0.1016)  loss_rpn_box_reg: 0.0186 (0.0348)  time: 0.2728  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [33]  [ 590/1229]  eta: 0:02:55  lr: 0.000000  loss: 0.3841 (0.4395)  loss_classifier: 0.1371 (0.1557)  loss_box_reg: 0.1288 (0.1472)  loss_objectness: 0.0920 (0.1019)  loss_rpn_box_reg: 0.0195 (0.0347)  time: 0.2751  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [33]  [ 600/1229]  eta: 0:02:53  lr: 0.000000  loss: 0.4171 (0.4395)  loss_classifier: 0.1566 (0.1559)  loss_box_reg: 0.1288 (0.1469)  loss_objectness: 0.1038 (0.1022)  loss_rpn_box_reg: 0.0220 (0.0346)  time: 0.2754  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [33]  [ 610/1229]  eta: 0:02:50  lr: 0.000000  loss: 0.4098 (0.4386)  loss_classifier: 0.1477 (0.1555)  loss_box_reg: 0.1346 (0.1464)  loss_objectness: 0.0951 (0.1022)  loss_rpn_box_reg: 0.0238 (0.0345)  time: 0.2770  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [33]  [ 620/1229]  eta: 0:02:47  lr: 0.000000  loss: 0.4205 (0.4412)  loss_classifier: 0.1602 (0.1565)  loss_box_reg: 0.1388 (0.1477)  loss_objectness: 0.0959 (0.1024)  loss_rpn_box_reg: 0.0253 (0.0346)  time: 0.2756  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [33]  [ 630/1229]  eta: 0:02:44  lr: 0.000000  loss: 0.4008 (0.4418)  loss_classifier: 0.1624 (0.1567)  loss_box_reg: 0.1985 (0.1484)  loss_objectness: 0.0846 (0.1023)  loss_rpn_box_reg: 0.0249 (0.0344)  time: 0.2703  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [33]  [ 640/1229]  eta: 0:02:41  lr: 0.000000  loss: 0.3692 (0.4400)  loss_classifier: 0.1276 (0.1560)  loss_box_reg: 0.1065 (0.1476)  loss_objectness: 0.0846 (0.1022)  loss_rpn_box_reg: 0.0144 (0.0342)  time: 0.2676  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [33]  [ 650/1229]  eta: 0:02:39  lr: 0.000000  loss: 0.3653 (0.4393)  loss_classifier: 0.1262 (0.1558)  loss_box_reg: 0.1065 (0.1476)  loss_objectness: 0.0872 (0.1019)  loss_rpn_box_reg: 0.0144 (0.0340)  time: 0.2717  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [33]  [ 660/1229]  eta: 0:02:36  lr: 0.000000  loss: 0.4034 (0.4404)  loss_classifier: 0.1511 (0.1563)  loss_box_reg: 0.1482 (0.1479)  loss_objectness: 0.0876 (0.1022)  loss_rpn_box_reg: 0.0232 (0.0341)  time: 0.2750  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [33]  [ 670/1229]  eta: 0:02:33  lr: 0.000000  loss: 0.4174 (0.4409)  loss_classifier: 0.1465 (0.1563)  loss_box_reg: 0.1482 (0.1476)  loss_objectness: 0.1109 (0.1026)  loss_rpn_box_reg: 0.0373 (0.0344)  time: 0.2717  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [33]  [ 680/1229]  eta: 0:02:30  lr: 0.000000  loss: 0.3304 (0.4398)  loss_classifier: 0.1234 (0.1560)  loss_box_reg: 0.0915 (0.1473)  loss_objectness: 0.1081 (0.1024)  loss_rpn_box_reg: 0.0164 (0.0342)  time: 0.2670  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [33]  [ 690/1229]  eta: 0:02:28  lr: 0.000000  loss: 0.3145 (0.4383)  loss_classifier: 0.1032 (0.1555)  loss_box_reg: 0.0910 (0.1469)  loss_objectness: 0.0689 (0.1019)  loss_rpn_box_reg: 0.0094 (0.0340)  time: 0.2699  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [33]  [ 700/1229]  eta: 0:02:25  lr: 0.000000  loss: 0.2769 (0.4376)  loss_classifier: 0.1032 (0.1553)  loss_box_reg: 0.0844 (0.1464)  loss_objectness: 0.0625 (0.1017)  loss_rpn_box_reg: 0.0135 (0.0342)  time: 0.2736  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [33]  [ 710/1229]  eta: 0:02:22  lr: 0.000000  loss: 0.3487 (0.4377)  loss_classifier: 0.1228 (0.1555)  loss_box_reg: 0.1202 (0.1467)  loss_objectness: 0.0665 (0.1015)  loss_rpn_box_reg: 0.0164 (0.0340)  time: 0.2767  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [33]  [ 720/1229]  eta: 0:02:19  lr: 0.000000  loss: 0.3853 (0.4370)  loss_classifier: 0.1383 (0.1553)  loss_box_reg: 0.1416 (0.1464)  loss_objectness: 0.0763 (0.1012)  loss_rpn_box_reg: 0.0187 (0.0341)  time: 0.2759  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [33]  [ 730/1229]  eta: 0:02:17  lr: 0.000000  loss: 0.3850 (0.4364)  loss_classifier: 0.1127 (0.1550)  loss_box_reg: 0.1151 (0.1461)  loss_objectness: 0.0684 (0.1011)  loss_rpn_box_reg: 0.0186 (0.0343)  time: 0.2772  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [33]  [ 740/1229]  eta: 0:02:14  lr: 0.000000  loss: 0.3570 (0.4355)  loss_classifier: 0.1053 (0.1546)  loss_box_reg: 0.1012 (0.1454)  loss_objectness: 0.0673 (0.1010)  loss_rpn_box_reg: 0.0154 (0.0345)  time: 0.2818  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [33]  [ 750/1229]  eta: 0:02:11  lr: 0.000000  loss: 0.4069 (0.4360)  loss_classifier: 0.1573 (0.1548)  loss_box_reg: 0.1055 (0.1460)  loss_objectness: 0.0793 (0.1009)  loss_rpn_box_reg: 0.0257 (0.0344)  time: 0.2781  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [33]  [ 760/1229]  eta: 0:02:08  lr: 0.000000  loss: 0.5039 (0.4365)  loss_classifier: 0.1573 (0.1549)  loss_box_reg: 0.1632 (0.1459)  loss_objectness: 0.0888 (0.1013)  loss_rpn_box_reg: 0.0243 (0.0344)  time: 0.2756  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [33]  [ 770/1229]  eta: 0:02:06  lr: 0.000000  loss: 0.3659 (0.4355)  loss_classifier: 0.1263 (0.1545)  loss_box_reg: 0.0872 (0.1456)  loss_objectness: 0.0947 (0.1011)  loss_rpn_box_reg: 0.0136 (0.0343)  time: 0.2772  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [33]  [ 780/1229]  eta: 0:02:03  lr: 0.000000  loss: 0.3659 (0.4357)  loss_classifier: 0.1294 (0.1546)  loss_box_reg: 0.1224 (0.1456)  loss_objectness: 0.0817 (0.1012)  loss_rpn_box_reg: 0.0154 (0.0342)  time: 0.2782  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [33]  [ 790/1229]  eta: 0:02:00  lr: 0.000000  loss: 0.3774 (0.4357)  loss_classifier: 0.1481 (0.1546)  loss_box_reg: 0.1432 (0.1457)  loss_objectness: 0.0927 (0.1010)  loss_rpn_box_reg: 0.0184 (0.0344)  time: 0.2752  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [33]  [ 800/1229]  eta: 0:01:57  lr: 0.000000  loss: 0.3774 (0.4361)  loss_classifier: 0.1492 (0.1548)  loss_box_reg: 0.1343 (0.1462)  loss_objectness: 0.0876 (0.1008)  loss_rpn_box_reg: 0.0241 (0.0343)  time: 0.2709  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [33]  [ 810/1229]  eta: 0:01:55  lr: 0.000000  loss: 0.3737 (0.4359)  loss_classifier: 0.1346 (0.1548)  loss_box_reg: 0.1270 (0.1460)  loss_objectness: 0.0845 (0.1009)  loss_rpn_box_reg: 0.0253 (0.0343)  time: 0.2727  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [33]  [ 820/1229]  eta: 0:01:52  lr: 0.000000  loss: 0.3713 (0.4351)  loss_classifier: 0.1301 (0.1545)  loss_box_reg: 0.1270 (0.1457)  loss_objectness: 0.0805 (0.1007)  loss_rpn_box_reg: 0.0196 (0.0342)  time: 0.2795  data: 0.1371  max mem: 1751\n",
      "Training Epoch: [33]  [ 830/1229]  eta: 0:01:49  lr: 0.000000  loss: 0.3115 (0.4342)  loss_classifier: 0.1058 (0.1542)  loss_box_reg: 0.0912 (0.1453)  loss_objectness: 0.0765 (0.1005)  loss_rpn_box_reg: 0.0182 (0.0342)  time: 0.2758  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [33]  [ 840/1229]  eta: 0:01:46  lr: 0.000000  loss: 0.4661 (0.4364)  loss_classifier: 0.1556 (0.1550)  loss_box_reg: 0.1208 (0.1461)  loss_objectness: 0.0836 (0.1009)  loss_rpn_box_reg: 0.0387 (0.0344)  time: 0.2741  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [33]  [ 850/1229]  eta: 0:01:44  lr: 0.000000  loss: 0.5630 (0.4376)  loss_classifier: 0.2090 (0.1554)  loss_box_reg: 0.2103 (0.1466)  loss_objectness: 0.1058 (0.1010)  loss_rpn_box_reg: 0.0387 (0.0346)  time: 0.2765  data: 0.1368  max mem: 1751\n",
      "Training Epoch: [33]  [ 860/1229]  eta: 0:01:41  lr: 0.000000  loss: 0.4642 (0.4374)  loss_classifier: 0.1497 (0.1554)  loss_box_reg: 0.1754 (0.1467)  loss_objectness: 0.0857 (0.1008)  loss_rpn_box_reg: 0.0229 (0.0345)  time: 0.2752  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [33]  [ 870/1229]  eta: 0:01:38  lr: 0.000000  loss: 0.3476 (0.4371)  loss_classifier: 0.1322 (0.1554)  loss_box_reg: 0.1047 (0.1464)  loss_objectness: 0.0834 (0.1009)  loss_rpn_box_reg: 0.0236 (0.0345)  time: 0.2754  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [33]  [ 880/1229]  eta: 0:01:35  lr: 0.000000  loss: 0.4898 (0.4383)  loss_classifier: 0.1501 (0.1556)  loss_box_reg: 0.1438 (0.1468)  loss_objectness: 0.1115 (0.1014)  loss_rpn_box_reg: 0.0278 (0.0346)  time: 0.2708  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [33]  [ 890/1229]  eta: 0:01:33  lr: 0.000000  loss: 0.3946 (0.4381)  loss_classifier: 0.1464 (0.1553)  loss_box_reg: 0.1301 (0.1464)  loss_objectness: 0.1019 (0.1013)  loss_rpn_box_reg: 0.0233 (0.0351)  time: 0.2727  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [33]  [ 900/1229]  eta: 0:01:30  lr: 0.000000  loss: 0.3793 (0.4388)  loss_classifier: 0.1405 (0.1555)  loss_box_reg: 0.0997 (0.1468)  loss_objectness: 0.0809 (0.1014)  loss_rpn_box_reg: 0.0190 (0.0351)  time: 0.2783  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [33]  [ 910/1229]  eta: 0:01:27  lr: 0.000000  loss: 0.5191 (0.4399)  loss_classifier: 0.1860 (0.1559)  loss_box_reg: 0.1749 (0.1473)  loss_objectness: 0.0981 (0.1015)  loss_rpn_box_reg: 0.0201 (0.0351)  time: 0.2831  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [33]  [ 920/1229]  eta: 0:01:25  lr: 0.000000  loss: 0.4599 (0.4392)  loss_classifier: 0.1606 (0.1557)  loss_box_reg: 0.1484 (0.1471)  loss_objectness: 0.0783 (0.1014)  loss_rpn_box_reg: 0.0201 (0.0350)  time: 0.2829  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [33]  [ 930/1229]  eta: 0:01:22  lr: 0.000000  loss: 0.3714 (0.4398)  loss_classifier: 0.1296 (0.1559)  loss_box_reg: 0.1464 (0.1473)  loss_objectness: 0.0874 (0.1016)  loss_rpn_box_reg: 0.0252 (0.0351)  time: 0.2727  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [33]  [ 940/1229]  eta: 0:01:19  lr: 0.000000  loss: 0.4490 (0.4404)  loss_classifier: 0.1547 (0.1561)  loss_box_reg: 0.1494 (0.1475)  loss_objectness: 0.0874 (0.1017)  loss_rpn_box_reg: 0.0252 (0.0351)  time: 0.2706  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [33]  [ 950/1229]  eta: 0:01:16  lr: 0.000000  loss: 0.2821 (0.4397)  loss_classifier: 0.1091 (0.1558)  loss_box_reg: 0.1037 (0.1474)  loss_objectness: 0.0708 (0.1015)  loss_rpn_box_reg: 0.0213 (0.0350)  time: 0.2783  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [33]  [ 960/1229]  eta: 0:01:13  lr: 0.000000  loss: 0.2821 (0.4398)  loss_classifier: 0.0989 (0.1558)  loss_box_reg: 0.0862 (0.1475)  loss_objectness: 0.0745 (0.1015)  loss_rpn_box_reg: 0.0213 (0.0350)  time: 0.2772  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [33]  [ 970/1229]  eta: 0:01:11  lr: 0.000000  loss: 0.4395 (0.4408)  loss_classifier: 0.1492 (0.1561)  loss_box_reg: 0.1199 (0.1480)  loss_objectness: 0.1075 (0.1016)  loss_rpn_box_reg: 0.0202 (0.0351)  time: 0.2750  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [33]  [ 980/1229]  eta: 0:01:08  lr: 0.000000  loss: 0.4189 (0.4402)  loss_classifier: 0.1259 (0.1559)  loss_box_reg: 0.1299 (0.1479)  loss_objectness: 0.0922 (0.1013)  loss_rpn_box_reg: 0.0198 (0.0350)  time: 0.2773  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [33]  [ 990/1229]  eta: 0:01:05  lr: 0.000000  loss: 0.3683 (0.4406)  loss_classifier: 0.1205 (0.1559)  loss_box_reg: 0.1299 (0.1479)  loss_objectness: 0.0835 (0.1017)  loss_rpn_box_reg: 0.0205 (0.0351)  time: 0.2774  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [33]  [1000/1229]  eta: 0:01:03  lr: 0.000000  loss: 0.4705 (0.4409)  loss_classifier: 0.1636 (0.1559)  loss_box_reg: 0.1470 (0.1481)  loss_objectness: 0.0877 (0.1017)  loss_rpn_box_reg: 0.0229 (0.0351)  time: 0.2756  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [33]  [1010/1229]  eta: 0:01:00  lr: 0.000000  loss: 0.3258 (0.4402)  loss_classifier: 0.1279 (0.1558)  loss_box_reg: 0.1230 (0.1477)  loss_objectness: 0.0877 (0.1016)  loss_rpn_box_reg: 0.0208 (0.0351)  time: 0.2772  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [33]  [1020/1229]  eta: 0:00:57  lr: 0.000000  loss: 0.3307 (0.4402)  loss_classifier: 0.1279 (0.1559)  loss_box_reg: 0.0894 (0.1478)  loss_objectness: 0.0779 (0.1015)  loss_rpn_box_reg: 0.0211 (0.0350)  time: 0.2831  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [33]  [1030/1229]  eta: 0:00:54  lr: 0.000000  loss: 0.3754 (0.4395)  loss_classifier: 0.1373 (0.1558)  loss_box_reg: 0.1153 (0.1475)  loss_objectness: 0.0725 (0.1013)  loss_rpn_box_reg: 0.0200 (0.0349)  time: 0.2831  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [33]  [1040/1229]  eta: 0:00:52  lr: 0.000000  loss: 0.3290 (0.4392)  loss_classifier: 0.1316 (0.1557)  loss_box_reg: 0.1153 (0.1475)  loss_objectness: 0.0736 (0.1013)  loss_rpn_box_reg: 0.0166 (0.0347)  time: 0.2754  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [33]  [1050/1229]  eta: 0:00:49  lr: 0.000000  loss: 0.4349 (0.4407)  loss_classifier: 0.1454 (0.1562)  loss_box_reg: 0.1359 (0.1481)  loss_objectness: 0.1030 (0.1016)  loss_rpn_box_reg: 0.0166 (0.0347)  time: 0.2717  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [33]  [1060/1229]  eta: 0:00:46  lr: 0.000000  loss: 0.4091 (0.4408)  loss_classifier: 0.1476 (0.1563)  loss_box_reg: 0.1310 (0.1482)  loss_objectness: 0.0897 (0.1016)  loss_rpn_box_reg: 0.0269 (0.0347)  time: 0.2766  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [33]  [1070/1229]  eta: 0:00:43  lr: 0.000000  loss: 0.3975 (0.4409)  loss_classifier: 0.1444 (0.1563)  loss_box_reg: 0.1094 (0.1482)  loss_objectness: 0.0897 (0.1017)  loss_rpn_box_reg: 0.0292 (0.0348)  time: 0.2767  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [33]  [1080/1229]  eta: 0:00:41  lr: 0.000000  loss: 0.4027 (0.4405)  loss_classifier: 0.1431 (0.1562)  loss_box_reg: 0.1278 (0.1482)  loss_objectness: 0.0743 (0.1015)  loss_rpn_box_reg: 0.0212 (0.0346)  time: 0.2729  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [33]  [1090/1229]  eta: 0:00:38  lr: 0.000000  loss: 0.3890 (0.4397)  loss_classifier: 0.1431 (0.1559)  loss_box_reg: 0.1104 (0.1478)  loss_objectness: 0.0734 (0.1015)  loss_rpn_box_reg: 0.0149 (0.0345)  time: 0.2757  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [33]  [1100/1229]  eta: 0:00:35  lr: 0.000000  loss: 0.3950 (0.4401)  loss_classifier: 0.1517 (0.1561)  loss_box_reg: 0.1306 (0.1481)  loss_objectness: 0.0935 (0.1015)  loss_rpn_box_reg: 0.0230 (0.0345)  time: 0.2796  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [33]  [1110/1229]  eta: 0:00:32  lr: 0.000000  loss: 0.4505 (0.4397)  loss_classifier: 0.1522 (0.1559)  loss_box_reg: 0.1479 (0.1478)  loss_objectness: 0.0869 (0.1015)  loss_rpn_box_reg: 0.0198 (0.0344)  time: 0.2763  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [33]  [1120/1229]  eta: 0:00:30  lr: 0.000000  loss: 0.3443 (0.4392)  loss_classifier: 0.1342 (0.1558)  loss_box_reg: 0.1079 (0.1476)  loss_objectness: 0.0980 (0.1016)  loss_rpn_box_reg: 0.0191 (0.0343)  time: 0.2699  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [33]  [1130/1229]  eta: 0:00:27  lr: 0.000000  loss: 0.3216 (0.4385)  loss_classifier: 0.1232 (0.1555)  loss_box_reg: 0.1019 (0.1474)  loss_objectness: 0.0874 (0.1014)  loss_rpn_box_reg: 0.0194 (0.0342)  time: 0.2662  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [33]  [1140/1229]  eta: 0:00:24  lr: 0.000000  loss: 0.3216 (0.4383)  loss_classifier: 0.1110 (0.1555)  loss_box_reg: 0.1053 (0.1471)  loss_objectness: 0.0757 (0.1016)  loss_rpn_box_reg: 0.0190 (0.0341)  time: 0.2742  data: 0.1387  max mem: 1751\n",
      "Training Epoch: [33]  [1150/1229]  eta: 0:00:21  lr: 0.000000  loss: 0.3457 (0.4384)  loss_classifier: 0.1249 (0.1555)  loss_box_reg: 0.1053 (0.1470)  loss_objectness: 0.0885 (0.1016)  loss_rpn_box_reg: 0.0214 (0.0343)  time: 0.2809  data: 0.1446  max mem: 1751\n",
      "Training Epoch: [33]  [1160/1229]  eta: 0:00:18  lr: 0.000000  loss: 0.2215 (0.4373)  loss_classifier: 0.0829 (0.1551)  loss_box_reg: 0.0754 (0.1466)  loss_objectness: 0.0650 (0.1014)  loss_rpn_box_reg: 0.0179 (0.0342)  time: 0.2818  data: 0.1405  max mem: 1751\n",
      "Training Epoch: [33]  [1170/1229]  eta: 0:00:16  lr: 0.000000  loss: 0.2745 (0.4374)  loss_classifier: 0.1119 (0.1551)  loss_box_reg: 0.0945 (0.1466)  loss_objectness: 0.0681 (0.1015)  loss_rpn_box_reg: 0.0116 (0.0342)  time: 0.2792  data: 0.1374  max mem: 1751\n",
      "Training Epoch: [33]  [1180/1229]  eta: 0:00:13  lr: 0.000000  loss: 0.3485 (0.4369)  loss_classifier: 0.1282 (0.1550)  loss_box_reg: 0.1105 (0.1463)  loss_objectness: 0.0842 (0.1015)  loss_rpn_box_reg: 0.0176 (0.0341)  time: 0.2726  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [33]  [1190/1229]  eta: 0:00:10  lr: 0.000000  loss: 0.3485 (0.4370)  loss_classifier: 0.1282 (0.1550)  loss_box_reg: 0.1105 (0.1464)  loss_objectness: 0.0915 (0.1015)  loss_rpn_box_reg: 0.0253 (0.0341)  time: 0.2745  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [33]  [1200/1229]  eta: 0:00:07  lr: 0.000000  loss: 0.3380 (0.4368)  loss_classifier: 0.1075 (0.1549)  loss_box_reg: 0.1155 (0.1463)  loss_objectness: 0.0826 (0.1015)  loss_rpn_box_reg: 0.0221 (0.0340)  time: 0.2795  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [33]  [1210/1229]  eta: 0:00:05  lr: 0.000000  loss: 0.3936 (0.4368)  loss_classifier: 0.1214 (0.1549)  loss_box_reg: 0.1155 (0.1462)  loss_objectness: 0.0875 (0.1017)  loss_rpn_box_reg: 0.0184 (0.0340)  time: 0.2776  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [33]  [1220/1229]  eta: 0:00:02  lr: 0.000000  loss: 0.3912 (0.4364)  loss_classifier: 0.1351 (0.1548)  loss_box_reg: 0.0992 (0.1460)  loss_objectness: 0.1125 (0.1016)  loss_rpn_box_reg: 0.0164 (0.0340)  time: 0.2809  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [33]  [1228/1229]  eta: 0:00:00  lr: 0.000000  loss: 0.3738 (0.4360)  loss_classifier: 0.1223 (0.1546)  loss_box_reg: 0.0882 (0.1458)  loss_objectness: 0.0879 (0.1016)  loss_rpn_box_reg: 0.0126 (0.0340)  time: 0.2773  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [33] Total time: 0:05:38 (0.2755 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:43  model_time: 0.3020 (0.3020)  evaluator_time: 0.0020 (0.0020)  time: 0.3350  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0780 (0.0821)  evaluator_time: 0.0040 (0.0086)  time: 0.1271  data: 0.0357  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0830 (0.0811)  evaluator_time: 0.0030 (0.0079)  time: 0.1257  data: 0.0357  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0720 (0.0802)  evaluator_time: 0.0040 (0.0076)  time: 0.1240  data: 0.0404  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0720 (0.0801)  evaluator_time: 0.0020 (0.0076)  time: 0.1159  data: 0.0336  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1241 s / it)\n",
      "Averaged stats: model_time: 0.0720 (0.0801)  evaluator_time: 0.0020 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [33]  [  0/308]  eta: 0:00:38  lr: 0.000000  loss: 0.1664 (0.1664)  loss_classifier: 0.0596 (0.0596)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0268 (0.0268)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1240  data: 0.0290  max mem: 1751\n",
      "Testing Epoch: [33]  [100/308]  eta: 0:00:28  lr: 0.000000  loss: 0.3126 (0.4795)  loss_classifier: 0.1350 (0.1546)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0568 (0.1009)  loss_rpn_box_reg: 0.0186 (0.0518)  time: 0.1437  data: 0.0423  max mem: 1751\n",
      "Testing Epoch: [33]  [200/308]  eta: 0:00:14  lr: 0.000000  loss: 0.3496 (0.4560)  loss_classifier: 0.1395 (0.1490)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0583 (0.0947)  loss_rpn_box_reg: 0.0197 (0.0490)  time: 0.1380  data: 0.0328  max mem: 1751\n",
      "Testing Epoch: [33]  [300/308]  eta: 0:00:01  lr: 0.000000  loss: 0.4575 (0.4532)  loss_classifier: 0.1587 (0.1493)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0736 (0.0923)  loss_rpn_box_reg: 0.0265 (0.0474)  time: 0.1383  data: 0.0427  max mem: 1751\n",
      "Testing Epoch: [33]  [307/308]  eta: 0:00:00  lr: 0.000000  loss: 0.4575 (0.4532)  loss_classifier: 0.1860 (0.1495)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0698 (0.0923)  loss_rpn_box_reg: 0.0271 (0.0470)  time: 0.1371  data: 0.0412  max mem: 1751\n",
      "Testing Epoch: [33] Total time: 0:00:42 (0.1377 s / it)\n",
      "Training Epoch: [34]  [   0/1229]  eta: 0:05:25  lr: 0.000000  loss: 0.5316 (0.5316)  loss_classifier: 0.2010 (0.2010)  loss_box_reg: 0.2203 (0.2203)  loss_objectness: 0.0874 (0.0874)  loss_rpn_box_reg: 0.0228 (0.0228)  time: 0.2650  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [34]  [  10/1229]  eta: 0:05:39  lr: 0.000000  loss: 0.4086 (0.4081)  loss_classifier: 0.1594 (0.1607)  loss_box_reg: 0.1248 (0.1423)  loss_objectness: 0.0842 (0.0862)  loss_rpn_box_reg: 0.0128 (0.0189)  time: 0.2788  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [34]  [  20/1229]  eta: 0:05:34  lr: 0.000000  loss: 0.4005 (0.4047)  loss_classifier: 0.1385 (0.1537)  loss_box_reg: 0.1035 (0.1444)  loss_objectness: 0.0842 (0.0879)  loss_rpn_box_reg: 0.0128 (0.0187)  time: 0.2768  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [34]  [  30/1229]  eta: 0:05:27  lr: 0.000000  loss: 0.4251 (0.4175)  loss_classifier: 0.1321 (0.1528)  loss_box_reg: 0.1157 (0.1491)  loss_objectness: 0.0984 (0.0914)  loss_rpn_box_reg: 0.0224 (0.0242)  time: 0.2698  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [34]  [  40/1229]  eta: 0:05:23  lr: 0.000000  loss: 0.4448 (0.4221)  loss_classifier: 0.1321 (0.1518)  loss_box_reg: 0.1148 (0.1460)  loss_objectness: 0.0984 (0.0964)  loss_rpn_box_reg: 0.0266 (0.0280)  time: 0.2685  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [34]  [  50/1229]  eta: 0:05:23  lr: 0.000000  loss: 0.3303 (0.4027)  loss_classifier: 0.1161 (0.1446)  loss_box_reg: 0.1007 (0.1361)  loss_objectness: 0.0753 (0.0944)  loss_rpn_box_reg: 0.0257 (0.0276)  time: 0.2771  data: 0.1378  max mem: 1751\n",
      "Training Epoch: [34]  [  60/1229]  eta: 0:05:22  lr: 0.000000  loss: 0.3303 (0.4036)  loss_classifier: 0.1207 (0.1461)  loss_box_reg: 0.0993 (0.1356)  loss_objectness: 0.0753 (0.0949)  loss_rpn_box_reg: 0.0147 (0.0270)  time: 0.2823  data: 0.1370  max mem: 1751\n",
      "Training Epoch: [34]  [  70/1229]  eta: 0:05:19  lr: 0.000000  loss: 0.4704 (0.4188)  loss_classifier: 0.1659 (0.1513)  loss_box_reg: 0.1279 (0.1400)  loss_objectness: 0.1047 (0.0989)  loss_rpn_box_reg: 0.0198 (0.0286)  time: 0.2797  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [34]  [  80/1229]  eta: 0:05:16  lr: 0.000000  loss: 0.3665 (0.4230)  loss_classifier: 0.1222 (0.1505)  loss_box_reg: 0.1442 (0.1407)  loss_objectness: 0.1082 (0.1017)  loss_rpn_box_reg: 0.0197 (0.0301)  time: 0.2749  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [34]  [  90/1229]  eta: 0:05:13  lr: 0.000000  loss: 0.3310 (0.4136)  loss_classifier: 0.1121 (0.1477)  loss_box_reg: 0.1125 (0.1388)  loss_objectness: 0.0642 (0.0983)  loss_rpn_box_reg: 0.0182 (0.0288)  time: 0.2736  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [34]  [ 100/1229]  eta: 0:05:11  lr: 0.000000  loss: 0.3888 (0.4316)  loss_classifier: 0.1422 (0.1537)  loss_box_reg: 0.1466 (0.1457)  loss_objectness: 0.0804 (0.1007)  loss_rpn_box_reg: 0.0208 (0.0315)  time: 0.2778  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [34]  [ 110/1229]  eta: 0:05:08  lr: 0.000000  loss: 0.4042 (0.4267)  loss_classifier: 0.1588 (0.1525)  loss_box_reg: 0.1448 (0.1441)  loss_objectness: 0.0856 (0.1000)  loss_rpn_box_reg: 0.0160 (0.0301)  time: 0.2774  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [34]  [ 120/1229]  eta: 0:05:06  lr: 0.000000  loss: 0.3439 (0.4254)  loss_classifier: 0.1237 (0.1525)  loss_box_reg: 0.1005 (0.1424)  loss_objectness: 0.0758 (0.0989)  loss_rpn_box_reg: 0.0160 (0.0316)  time: 0.2761  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [34]  [ 130/1229]  eta: 0:05:03  lr: 0.000000  loss: 0.3439 (0.4222)  loss_classifier: 0.1385 (0.1518)  loss_box_reg: 0.0844 (0.1409)  loss_objectness: 0.0859 (0.0989)  loss_rpn_box_reg: 0.0176 (0.0306)  time: 0.2782  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [34]  [ 140/1229]  eta: 0:05:00  lr: 0.000000  loss: 0.3820 (0.4205)  loss_classifier: 0.1356 (0.1512)  loss_box_reg: 0.0873 (0.1413)  loss_objectness: 0.0804 (0.0978)  loss_rpn_box_reg: 0.0176 (0.0302)  time: 0.2759  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [34]  [ 150/1229]  eta: 0:04:57  lr: 0.000000  loss: 0.3691 (0.4169)  loss_classifier: 0.1356 (0.1501)  loss_box_reg: 0.0873 (0.1406)  loss_objectness: 0.0747 (0.0963)  loss_rpn_box_reg: 0.0170 (0.0300)  time: 0.2708  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [34]  [ 160/1229]  eta: 0:04:54  lr: 0.000000  loss: 0.3701 (0.4212)  loss_classifier: 0.1387 (0.1512)  loss_box_reg: 0.1030 (0.1413)  loss_objectness: 0.0907 (0.0971)  loss_rpn_box_reg: 0.0170 (0.0316)  time: 0.2741  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [34]  [ 170/1229]  eta: 0:04:53  lr: 0.000000  loss: 0.3722 (0.4196)  loss_classifier: 0.1387 (0.1506)  loss_box_reg: 0.1031 (0.1423)  loss_objectness: 0.0828 (0.0959)  loss_rpn_box_reg: 0.0171 (0.0308)  time: 0.2863  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [34]  [ 180/1229]  eta: 0:04:49  lr: 0.000000  loss: 0.2682 (0.4141)  loss_classifier: 0.1026 (0.1489)  loss_box_reg: 0.0858 (0.1398)  loss_objectness: 0.0800 (0.0955)  loss_rpn_box_reg: 0.0149 (0.0299)  time: 0.2815  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [34]  [ 190/1229]  eta: 0:04:47  lr: 0.000000  loss: 0.3345 (0.4167)  loss_classifier: 0.1176 (0.1504)  loss_box_reg: 0.1036 (0.1415)  loss_objectness: 0.0809 (0.0952)  loss_rpn_box_reg: 0.0147 (0.0296)  time: 0.2732  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [34]  [ 200/1229]  eta: 0:04:44  lr: 0.000000  loss: 0.3548 (0.4169)  loss_classifier: 0.1483 (0.1508)  loss_box_reg: 0.1185 (0.1412)  loss_objectness: 0.0978 (0.0954)  loss_rpn_box_reg: 0.0194 (0.0294)  time: 0.2755  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [34]  [ 210/1229]  eta: 0:04:41  lr: 0.000000  loss: 0.3230 (0.4166)  loss_classifier: 0.1249 (0.1501)  loss_box_reg: 0.1138 (0.1404)  loss_objectness: 0.1042 (0.0965)  loss_rpn_box_reg: 0.0194 (0.0296)  time: 0.2735  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [34]  [ 220/1229]  eta: 0:04:38  lr: 0.000000  loss: 0.3055 (0.4143)  loss_classifier: 0.1017 (0.1492)  loss_box_reg: 0.0971 (0.1404)  loss_objectness: 0.0703 (0.0955)  loss_rpn_box_reg: 0.0187 (0.0293)  time: 0.2778  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [34]  [ 230/1229]  eta: 0:04:36  lr: 0.000000  loss: 0.3592 (0.4157)  loss_classifier: 0.1339 (0.1500)  loss_box_reg: 0.0971 (0.1405)  loss_objectness: 0.0701 (0.0957)  loss_rpn_box_reg: 0.0210 (0.0294)  time: 0.2800  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [34]  [ 240/1229]  eta: 0:04:33  lr: 0.000000  loss: 0.3681 (0.4162)  loss_classifier: 0.1406 (0.1501)  loss_box_reg: 0.0961 (0.1410)  loss_objectness: 0.0762 (0.0954)  loss_rpn_box_reg: 0.0293 (0.0297)  time: 0.2764  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [34]  [ 250/1229]  eta: 0:04:30  lr: 0.000000  loss: 0.3348 (0.4151)  loss_classifier: 0.1304 (0.1496)  loss_box_reg: 0.1282 (0.1412)  loss_objectness: 0.0640 (0.0947)  loss_rpn_box_reg: 0.0213 (0.0295)  time: 0.2734  data: 0.1297  max mem: 1751\n",
      "Training Epoch: [34]  [ 260/1229]  eta: 0:04:27  lr: 0.000000  loss: 0.3623 (0.4155)  loss_classifier: 0.1411 (0.1500)  loss_box_reg: 0.1272 (0.1414)  loss_objectness: 0.0737 (0.0944)  loss_rpn_box_reg: 0.0175 (0.0297)  time: 0.2760  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [34]  [ 270/1229]  eta: 0:04:24  lr: 0.000000  loss: 0.4054 (0.4200)  loss_classifier: 0.1541 (0.1514)  loss_box_reg: 0.1241 (0.1432)  loss_objectness: 0.1090 (0.0958)  loss_rpn_box_reg: 0.0175 (0.0296)  time: 0.2745  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [34]  [ 280/1229]  eta: 0:04:21  lr: 0.000000  loss: 0.4054 (0.4195)  loss_classifier: 0.1400 (0.1514)  loss_box_reg: 0.1301 (0.1427)  loss_objectness: 0.0971 (0.0960)  loss_rpn_box_reg: 0.0227 (0.0293)  time: 0.2713  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [34]  [ 290/1229]  eta: 0:04:19  lr: 0.000000  loss: 0.3680 (0.4209)  loss_classifier: 0.1231 (0.1519)  loss_box_reg: 0.0908 (0.1436)  loss_objectness: 0.0846 (0.0963)  loss_rpn_box_reg: 0.0169 (0.0291)  time: 0.2811  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [34]  [ 300/1229]  eta: 0:04:16  lr: 0.000000  loss: 0.3581 (0.4194)  loss_classifier: 0.1210 (0.1514)  loss_box_reg: 0.1061 (0.1431)  loss_objectness: 0.0846 (0.0961)  loss_rpn_box_reg: 0.0153 (0.0288)  time: 0.2842  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [34]  [ 310/1229]  eta: 0:04:14  lr: 0.000000  loss: 0.4371 (0.4236)  loss_classifier: 0.1506 (0.1528)  loss_box_reg: 0.1600 (0.1447)  loss_objectness: 0.0880 (0.0971)  loss_rpn_box_reg: 0.0235 (0.0291)  time: 0.2779  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [34]  [ 320/1229]  eta: 0:04:11  lr: 0.000000  loss: 0.4928 (0.4251)  loss_classifier: 0.1876 (0.1530)  loss_box_reg: 0.1671 (0.1450)  loss_objectness: 0.0955 (0.0976)  loss_rpn_box_reg: 0.0341 (0.0295)  time: 0.2723  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [34]  [ 330/1229]  eta: 0:04:08  lr: 0.000000  loss: 0.4435 (0.4237)  loss_classifier: 0.1514 (0.1524)  loss_box_reg: 0.1351 (0.1441)  loss_objectness: 0.0912 (0.0976)  loss_rpn_box_reg: 0.0294 (0.0296)  time: 0.2683  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [34]  [ 340/1229]  eta: 0:04:05  lr: 0.000000  loss: 0.3272 (0.4233)  loss_classifier: 0.1161 (0.1523)  loss_box_reg: 0.1095 (0.1436)  loss_objectness: 0.0785 (0.0981)  loss_rpn_box_reg: 0.0164 (0.0293)  time: 0.2692  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [34]  [ 350/1229]  eta: 0:04:02  lr: 0.000000  loss: 0.2933 (0.4222)  loss_classifier: 0.1124 (0.1516)  loss_box_reg: 0.0900 (0.1423)  loss_objectness: 0.0795 (0.0985)  loss_rpn_box_reg: 0.0110 (0.0298)  time: 0.2701  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [34]  [ 360/1229]  eta: 0:03:59  lr: 0.000000  loss: 0.3720 (0.4232)  loss_classifier: 0.1237 (0.1516)  loss_box_reg: 0.0958 (0.1424)  loss_objectness: 0.1041 (0.0989)  loss_rpn_box_reg: 0.0123 (0.0302)  time: 0.2670  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [34]  [ 370/1229]  eta: 0:03:56  lr: 0.000000  loss: 0.3755 (0.4223)  loss_classifier: 0.1377 (0.1514)  loss_box_reg: 0.0958 (0.1419)  loss_objectness: 0.0971 (0.0989)  loss_rpn_box_reg: 0.0154 (0.0301)  time: 0.2711  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [34]  [ 380/1229]  eta: 0:03:54  lr: 0.000000  loss: 0.3905 (0.4269)  loss_classifier: 0.1410 (0.1528)  loss_box_reg: 0.1153 (0.1443)  loss_objectness: 0.0987 (0.0992)  loss_rpn_box_reg: 0.0185 (0.0305)  time: 0.2797  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [34]  [ 390/1229]  eta: 0:03:51  lr: 0.000000  loss: 0.3905 (0.4259)  loss_classifier: 0.1335 (0.1524)  loss_box_reg: 0.1505 (0.1445)  loss_objectness: 0.0906 (0.0984)  loss_rpn_box_reg: 0.0188 (0.0306)  time: 0.2796  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [34]  [ 400/1229]  eta: 0:03:48  lr: 0.000000  loss: 0.3928 (0.4267)  loss_classifier: 0.1312 (0.1528)  loss_box_reg: 0.1225 (0.1449)  loss_objectness: 0.0767 (0.0983)  loss_rpn_box_reg: 0.0238 (0.0307)  time: 0.2691  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [34]  [ 410/1229]  eta: 0:03:45  lr: 0.000000  loss: 0.4204 (0.4274)  loss_classifier: 0.1569 (0.1530)  loss_box_reg: 0.1225 (0.1451)  loss_objectness: 0.0780 (0.0982)  loss_rpn_box_reg: 0.0279 (0.0311)  time: 0.2669  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [34]  [ 420/1229]  eta: 0:03:42  lr: 0.000000  loss: 0.3578 (0.4279)  loss_classifier: 0.1360 (0.1533)  loss_box_reg: 0.1102 (0.1455)  loss_objectness: 0.0791 (0.0981)  loss_rpn_box_reg: 0.0243 (0.0310)  time: 0.2718  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [34]  [ 430/1229]  eta: 0:03:39  lr: 0.000000  loss: 0.2672 (0.4247)  loss_classifier: 0.0938 (0.1520)  loss_box_reg: 0.0630 (0.1442)  loss_objectness: 0.0788 (0.0977)  loss_rpn_box_reg: 0.0163 (0.0308)  time: 0.2763  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [34]  [ 440/1229]  eta: 0:03:37  lr: 0.000000  loss: 0.2755 (0.4252)  loss_classifier: 0.0938 (0.1524)  loss_box_reg: 0.0906 (0.1448)  loss_objectness: 0.0801 (0.0976)  loss_rpn_box_reg: 0.0118 (0.0305)  time: 0.2821  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [34]  [ 450/1229]  eta: 0:03:34  lr: 0.000000  loss: 0.3482 (0.4228)  loss_classifier: 0.1471 (0.1517)  loss_box_reg: 0.0990 (0.1436)  loss_objectness: 0.0862 (0.0973)  loss_rpn_box_reg: 0.0121 (0.0302)  time: 0.2823  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [34]  [ 460/1229]  eta: 0:03:31  lr: 0.000000  loss: 0.3193 (0.4209)  loss_classifier: 0.1072 (0.1511)  loss_box_reg: 0.0883 (0.1429)  loss_objectness: 0.0822 (0.0969)  loss_rpn_box_reg: 0.0139 (0.0300)  time: 0.2789  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [34]  [ 470/1229]  eta: 0:03:29  lr: 0.000000  loss: 0.3083 (0.4212)  loss_classifier: 0.1085 (0.1515)  loss_box_reg: 0.1066 (0.1430)  loss_objectness: 0.0897 (0.0967)  loss_rpn_box_reg: 0.0222 (0.0299)  time: 0.2774  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [34]  [ 480/1229]  eta: 0:03:26  lr: 0.000000  loss: 0.4166 (0.4249)  loss_classifier: 0.1682 (0.1527)  loss_box_reg: 0.1071 (0.1443)  loss_objectness: 0.0953 (0.0971)  loss_rpn_box_reg: 0.0334 (0.0307)  time: 0.2813  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [34]  [ 490/1229]  eta: 0:03:23  lr: 0.000000  loss: 0.4166 (0.4253)  loss_classifier: 0.1494 (0.1529)  loss_box_reg: 0.0964 (0.1442)  loss_objectness: 0.1080 (0.0973)  loss_rpn_box_reg: 0.0288 (0.0309)  time: 0.2793  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [34]  [ 500/1229]  eta: 0:03:20  lr: 0.000000  loss: 0.4052 (0.4260)  loss_classifier: 0.1449 (0.1531)  loss_box_reg: 0.1158 (0.1445)  loss_objectness: 0.1077 (0.0976)  loss_rpn_box_reg: 0.0245 (0.0309)  time: 0.2713  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [34]  [ 510/1229]  eta: 0:03:18  lr: 0.000000  loss: 0.4416 (0.4267)  loss_classifier: 0.1547 (0.1533)  loss_box_reg: 0.1254 (0.1446)  loss_objectness: 0.0885 (0.0980)  loss_rpn_box_reg: 0.0245 (0.0309)  time: 0.2709  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [34]  [ 520/1229]  eta: 0:03:15  lr: 0.000000  loss: 0.3768 (0.4251)  loss_classifier: 0.1355 (0.1528)  loss_box_reg: 0.0936 (0.1438)  loss_objectness: 0.0822 (0.0979)  loss_rpn_box_reg: 0.0181 (0.0306)  time: 0.2777  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [34]  [ 530/1229]  eta: 0:03:12  lr: 0.000000  loss: 0.4110 (0.4268)  loss_classifier: 0.1381 (0.1535)  loss_box_reg: 0.0991 (0.1440)  loss_objectness: 0.1004 (0.0984)  loss_rpn_box_reg: 0.0181 (0.0309)  time: 0.2752  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [34]  [ 540/1229]  eta: 0:03:09  lr: 0.000000  loss: 0.4949 (0.4281)  loss_classifier: 0.1985 (0.1539)  loss_box_reg: 0.1665 (0.1446)  loss_objectness: 0.1170 (0.0985)  loss_rpn_box_reg: 0.0368 (0.0311)  time: 0.2695  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [34]  [ 550/1229]  eta: 0:03:07  lr: 0.000000  loss: 0.4651 (0.4281)  loss_classifier: 0.1523 (0.1538)  loss_box_reg: 0.1167 (0.1449)  loss_objectness: 0.0919 (0.0983)  loss_rpn_box_reg: 0.0327 (0.0312)  time: 0.2728  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [34]  [ 560/1229]  eta: 0:03:04  lr: 0.000000  loss: 0.3884 (0.4285)  loss_classifier: 0.1523 (0.1540)  loss_box_reg: 0.1167 (0.1449)  loss_objectness: 0.0884 (0.0983)  loss_rpn_box_reg: 0.0230 (0.0313)  time: 0.2711  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [34]  [ 570/1229]  eta: 0:03:01  lr: 0.000000  loss: 0.3769 (0.4284)  loss_classifier: 0.1382 (0.1539)  loss_box_reg: 0.1228 (0.1451)  loss_objectness: 0.0803 (0.0982)  loss_rpn_box_reg: 0.0132 (0.0312)  time: 0.2663  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [34]  [ 580/1229]  eta: 0:02:58  lr: 0.000000  loss: 0.3713 (0.4285)  loss_classifier: 0.1382 (0.1541)  loss_box_reg: 0.1414 (0.1454)  loss_objectness: 0.0699 (0.0978)  loss_rpn_box_reg: 0.0200 (0.0312)  time: 0.2688  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [34]  [ 590/1229]  eta: 0:02:55  lr: 0.000000  loss: 0.4522 (0.4283)  loss_classifier: 0.1527 (0.1539)  loss_box_reg: 0.1299 (0.1453)  loss_objectness: 0.0763 (0.0979)  loss_rpn_box_reg: 0.0214 (0.0313)  time: 0.2762  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [34]  [ 600/1229]  eta: 0:02:53  lr: 0.000000  loss: 0.4568 (0.4282)  loss_classifier: 0.1411 (0.1538)  loss_box_reg: 0.1299 (0.1454)  loss_objectness: 0.0974 (0.0978)  loss_rpn_box_reg: 0.0152 (0.0313)  time: 0.2812  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [34]  [ 610/1229]  eta: 0:02:50  lr: 0.000000  loss: 0.3592 (0.4278)  loss_classifier: 0.1207 (0.1536)  loss_box_reg: 0.1268 (0.1455)  loss_objectness: 0.0745 (0.0975)  loss_rpn_box_reg: 0.0166 (0.0311)  time: 0.2806  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [34]  [ 620/1229]  eta: 0:02:47  lr: 0.000000  loss: 0.3024 (0.4262)  loss_classifier: 0.1063 (0.1531)  loss_box_reg: 0.1013 (0.1450)  loss_objectness: 0.0630 (0.0972)  loss_rpn_box_reg: 0.0153 (0.0310)  time: 0.2766  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [34]  [ 630/1229]  eta: 0:02:44  lr: 0.000000  loss: 0.3882 (0.4276)  loss_classifier: 0.1295 (0.1535)  loss_box_reg: 0.1312 (0.1458)  loss_objectness: 0.0740 (0.0972)  loss_rpn_box_reg: 0.0168 (0.0311)  time: 0.2768  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [34]  [ 640/1229]  eta: 0:02:42  lr: 0.000000  loss: 0.3990 (0.4280)  loss_classifier: 0.1570 (0.1536)  loss_box_reg: 0.1483 (0.1460)  loss_objectness: 0.0740 (0.0971)  loss_rpn_box_reg: 0.0210 (0.0312)  time: 0.2712  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [34]  [ 650/1229]  eta: 0:02:39  lr: 0.000000  loss: 0.4547 (0.4286)  loss_classifier: 0.1583 (0.1539)  loss_box_reg: 0.1262 (0.1462)  loss_objectness: 0.0829 (0.0974)  loss_rpn_box_reg: 0.0210 (0.0311)  time: 0.2615  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [34]  [ 660/1229]  eta: 0:02:36  lr: 0.000000  loss: 0.5119 (0.4296)  loss_classifier: 0.1732 (0.1542)  loss_box_reg: 0.1700 (0.1467)  loss_objectness: 0.1044 (0.0977)  loss_rpn_box_reg: 0.0217 (0.0311)  time: 0.2641  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [34]  [ 670/1229]  eta: 0:02:33  lr: 0.000000  loss: 0.3509 (0.4284)  loss_classifier: 0.1301 (0.1539)  loss_box_reg: 0.1096 (0.1461)  loss_objectness: 0.0858 (0.0975)  loss_rpn_box_reg: 0.0213 (0.0310)  time: 0.2731  data: 0.1295  max mem: 1751\n",
      "Training Epoch: [34]  [ 680/1229]  eta: 0:02:30  lr: 0.000000  loss: 0.3505 (0.4286)  loss_classifier: 0.1222 (0.1537)  loss_box_reg: 0.0905 (0.1461)  loss_objectness: 0.0806 (0.0974)  loss_rpn_box_reg: 0.0245 (0.0315)  time: 0.2707  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [34]  [ 690/1229]  eta: 0:02:28  lr: 0.000000  loss: 0.4299 (0.4300)  loss_classifier: 0.1343 (0.1540)  loss_box_reg: 0.1309 (0.1463)  loss_objectness: 0.0940 (0.0978)  loss_rpn_box_reg: 0.0392 (0.0318)  time: 0.2669  data: 0.1304  max mem: 1751\n",
      "Training Epoch: [34]  [ 700/1229]  eta: 0:02:25  lr: 0.000000  loss: 0.4952 (0.4315)  loss_classifier: 0.1792 (0.1544)  loss_box_reg: 0.1309 (0.1463)  loss_objectness: 0.1284 (0.0985)  loss_rpn_box_reg: 0.0397 (0.0323)  time: 0.2710  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [34]  [ 710/1229]  eta: 0:02:22  lr: 0.000000  loss: 0.4088 (0.4302)  loss_classifier: 0.1442 (0.1541)  loss_box_reg: 0.0922 (0.1455)  loss_objectness: 0.1034 (0.0984)  loss_rpn_box_reg: 0.0293 (0.0323)  time: 0.2773  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [34]  [ 720/1229]  eta: 0:02:19  lr: 0.000000  loss: 0.3585 (0.4315)  loss_classifier: 0.1298 (0.1546)  loss_box_reg: 0.0949 (0.1462)  loss_objectness: 0.0719 (0.0984)  loss_rpn_box_reg: 0.0157 (0.0323)  time: 0.2795  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [34]  [ 730/1229]  eta: 0:02:17  lr: 0.000000  loss: 0.4119 (0.4310)  loss_classifier: 0.1417 (0.1544)  loss_box_reg: 0.1046 (0.1462)  loss_objectness: 0.0958 (0.0983)  loss_rpn_box_reg: 0.0157 (0.0322)  time: 0.2767  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [34]  [ 740/1229]  eta: 0:02:14  lr: 0.000000  loss: 0.3648 (0.4297)  loss_classifier: 0.1267 (0.1540)  loss_box_reg: 0.0953 (0.1457)  loss_objectness: 0.0586 (0.0979)  loss_rpn_box_reg: 0.0150 (0.0320)  time: 0.2747  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [34]  [ 750/1229]  eta: 0:02:11  lr: 0.000000  loss: 0.3671 (0.4301)  loss_classifier: 0.1470 (0.1540)  loss_box_reg: 0.1046 (0.1460)  loss_objectness: 0.0921 (0.0982)  loss_rpn_box_reg: 0.0150 (0.0319)  time: 0.2702  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [34]  [ 760/1229]  eta: 0:02:08  lr: 0.000000  loss: 0.3288 (0.4304)  loss_classifier: 0.1283 (0.1540)  loss_box_reg: 0.1043 (0.1462)  loss_objectness: 0.0902 (0.0981)  loss_rpn_box_reg: 0.0175 (0.0320)  time: 0.2739  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [34]  [ 770/1229]  eta: 0:02:06  lr: 0.000000  loss: 0.3118 (0.4302)  loss_classifier: 0.1283 (0.1539)  loss_box_reg: 0.1057 (0.1460)  loss_objectness: 0.0846 (0.0981)  loss_rpn_box_reg: 0.0245 (0.0322)  time: 0.2846  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [34]  [ 780/1229]  eta: 0:02:03  lr: 0.000000  loss: 0.4048 (0.4320)  loss_classifier: 0.1481 (0.1544)  loss_box_reg: 0.1197 (0.1469)  loss_objectness: 0.0989 (0.0981)  loss_rpn_box_reg: 0.0264 (0.0326)  time: 0.2862  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [34]  [ 790/1229]  eta: 0:02:00  lr: 0.000000  loss: 0.3758 (0.4321)  loss_classifier: 0.1399 (0.1543)  loss_box_reg: 0.1180 (0.1468)  loss_objectness: 0.1021 (0.0984)  loss_rpn_box_reg: 0.0305 (0.0325)  time: 0.2750  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [34]  [ 800/1229]  eta: 0:01:57  lr: 0.000000  loss: 0.3351 (0.4316)  loss_classifier: 0.1180 (0.1542)  loss_box_reg: 0.0966 (0.1465)  loss_objectness: 0.0861 (0.0985)  loss_rpn_box_reg: 0.0173 (0.0324)  time: 0.2685  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [34]  [ 810/1229]  eta: 0:01:55  lr: 0.000000  loss: 0.3800 (0.4314)  loss_classifier: 0.1423 (0.1542)  loss_box_reg: 0.1110 (0.1461)  loss_objectness: 0.0868 (0.0988)  loss_rpn_box_reg: 0.0173 (0.0323)  time: 0.2740  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [34]  [ 820/1229]  eta: 0:01:52  lr: 0.000000  loss: 0.4454 (0.4321)  loss_classifier: 0.1609 (0.1546)  loss_box_reg: 0.1365 (0.1466)  loss_objectness: 0.0868 (0.0987)  loss_rpn_box_reg: 0.0157 (0.0322)  time: 0.2803  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [34]  [ 830/1229]  eta: 0:01:49  lr: 0.000000  loss: 0.4201 (0.4321)  loss_classifier: 0.1508 (0.1546)  loss_box_reg: 0.1576 (0.1467)  loss_objectness: 0.0865 (0.0987)  loss_rpn_box_reg: 0.0178 (0.0321)  time: 0.2757  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [34]  [ 840/1229]  eta: 0:01:46  lr: 0.000000  loss: 0.3958 (0.4327)  loss_classifier: 0.1423 (0.1548)  loss_box_reg: 0.1318 (0.1468)  loss_objectness: 0.0946 (0.0988)  loss_rpn_box_reg: 0.0212 (0.0322)  time: 0.2700  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [34]  [ 850/1229]  eta: 0:01:44  lr: 0.000000  loss: 0.4068 (0.4327)  loss_classifier: 0.1488 (0.1548)  loss_box_reg: 0.1161 (0.1470)  loss_objectness: 0.0840 (0.0987)  loss_rpn_box_reg: 0.0204 (0.0321)  time: 0.2721  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [34]  [ 860/1229]  eta: 0:01:41  lr: 0.000000  loss: 0.2997 (0.4317)  loss_classifier: 0.1113 (0.1544)  loss_box_reg: 0.0885 (0.1467)  loss_objectness: 0.0684 (0.0987)  loss_rpn_box_reg: 0.0134 (0.0320)  time: 0.2745  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [34]  [ 870/1229]  eta: 0:01:38  lr: 0.000000  loss: 0.3605 (0.4331)  loss_classifier: 0.1270 (0.1549)  loss_box_reg: 0.1161 (0.1473)  loss_objectness: 0.0939 (0.0989)  loss_rpn_box_reg: 0.0227 (0.0319)  time: 0.2712  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [34]  [ 880/1229]  eta: 0:01:35  lr: 0.000000  loss: 0.5068 (0.4340)  loss_classifier: 0.1505 (0.1553)  loss_box_reg: 0.1251 (0.1477)  loss_objectness: 0.0959 (0.0991)  loss_rpn_box_reg: 0.0288 (0.0319)  time: 0.2703  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [34]  [ 890/1229]  eta: 0:01:33  lr: 0.000000  loss: 0.4541 (0.4338)  loss_classifier: 0.1459 (0.1552)  loss_box_reg: 0.1221 (0.1476)  loss_objectness: 0.0781 (0.0988)  loss_rpn_box_reg: 0.0288 (0.0322)  time: 0.2682  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [34]  [ 900/1229]  eta: 0:01:30  lr: 0.000000  loss: 0.3164 (0.4328)  loss_classifier: 0.1144 (0.1548)  loss_box_reg: 0.1112 (0.1473)  loss_objectness: 0.0629 (0.0986)  loss_rpn_box_reg: 0.0146 (0.0321)  time: 0.2653  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [34]  [ 910/1229]  eta: 0:01:27  lr: 0.000000  loss: 0.3359 (0.4328)  loss_classifier: 0.1219 (0.1549)  loss_box_reg: 0.1159 (0.1473)  loss_objectness: 0.0764 (0.0986)  loss_rpn_box_reg: 0.0140 (0.0321)  time: 0.2671  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [34]  [ 920/1229]  eta: 0:01:24  lr: 0.000000  loss: 0.3897 (0.4322)  loss_classifier: 0.1416 (0.1546)  loss_box_reg: 0.1417 (0.1471)  loss_objectness: 0.0918 (0.0985)  loss_rpn_box_reg: 0.0283 (0.0320)  time: 0.2715  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [34]  [ 930/1229]  eta: 0:01:22  lr: 0.000000  loss: 0.3685 (0.4324)  loss_classifier: 0.1416 (0.1547)  loss_box_reg: 0.1417 (0.1472)  loss_objectness: 0.0856 (0.0985)  loss_rpn_box_reg: 0.0227 (0.0321)  time: 0.2738  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [34]  [ 940/1229]  eta: 0:01:19  lr: 0.000000  loss: 0.4866 (0.4336)  loss_classifier: 0.1688 (0.1550)  loss_box_reg: 0.1476 (0.1475)  loss_objectness: 0.1116 (0.0988)  loss_rpn_box_reg: 0.0267 (0.0323)  time: 0.2764  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [34]  [ 950/1229]  eta: 0:01:16  lr: 0.000000  loss: 0.4625 (0.4337)  loss_classifier: 0.1581 (0.1551)  loss_box_reg: 0.1429 (0.1475)  loss_objectness: 0.1070 (0.0989)  loss_rpn_box_reg: 0.0273 (0.0323)  time: 0.2744  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [34]  [ 960/1229]  eta: 0:01:13  lr: 0.000000  loss: 0.4206 (0.4342)  loss_classifier: 0.1488 (0.1552)  loss_box_reg: 0.1324 (0.1477)  loss_objectness: 0.0947 (0.0990)  loss_rpn_box_reg: 0.0268 (0.0324)  time: 0.2710  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [34]  [ 970/1229]  eta: 0:01:11  lr: 0.000000  loss: 0.3870 (0.4338)  loss_classifier: 0.1377 (0.1551)  loss_box_reg: 0.1270 (0.1476)  loss_objectness: 0.0824 (0.0989)  loss_rpn_box_reg: 0.0258 (0.0323)  time: 0.2710  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [34]  [ 980/1229]  eta: 0:01:08  lr: 0.000000  loss: 0.4457 (0.4343)  loss_classifier: 0.1544 (0.1553)  loss_box_reg: 0.1270 (0.1475)  loss_objectness: 0.0983 (0.0992)  loss_rpn_box_reg: 0.0258 (0.0324)  time: 0.2721  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [34]  [ 990/1229]  eta: 0:01:05  lr: 0.000000  loss: 0.4457 (0.4338)  loss_classifier: 0.1520 (0.1551)  loss_box_reg: 0.1083 (0.1471)  loss_objectness: 0.0947 (0.0991)  loss_rpn_box_reg: 0.0264 (0.0325)  time: 0.2715  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [34]  [1000/1229]  eta: 0:01:02  lr: 0.000000  loss: 0.3802 (0.4334)  loss_classifier: 0.1384 (0.1548)  loss_box_reg: 0.1038 (0.1470)  loss_objectness: 0.0755 (0.0991)  loss_rpn_box_reg: 0.0264 (0.0325)  time: 0.2651  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [34]  [1010/1229]  eta: 0:01:00  lr: 0.000000  loss: 0.3389 (0.4329)  loss_classifier: 0.1089 (0.1547)  loss_box_reg: 0.1045 (0.1469)  loss_objectness: 0.0702 (0.0989)  loss_rpn_box_reg: 0.0212 (0.0324)  time: 0.2701  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [34]  [1020/1229]  eta: 0:00:57  lr: 0.000000  loss: 0.2897 (0.4324)  loss_classifier: 0.1089 (0.1545)  loss_box_reg: 0.1045 (0.1466)  loss_objectness: 0.0702 (0.0987)  loss_rpn_box_reg: 0.0168 (0.0326)  time: 0.2762  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [34]  [1030/1229]  eta: 0:00:54  lr: 0.000000  loss: 0.2813 (0.4314)  loss_classifier: 0.1187 (0.1541)  loss_box_reg: 0.0872 (0.1462)  loss_objectness: 0.0651 (0.0986)  loss_rpn_box_reg: 0.0133 (0.0325)  time: 0.2716  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [34]  [1040/1229]  eta: 0:00:51  lr: 0.000000  loss: 0.3619 (0.4313)  loss_classifier: 0.1071 (0.1539)  loss_box_reg: 0.1033 (0.1459)  loss_objectness: 0.0754 (0.0986)  loss_rpn_box_reg: 0.0145 (0.0329)  time: 0.2709  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [34]  [1050/1229]  eta: 0:00:49  lr: 0.000000  loss: 0.3619 (0.4310)  loss_classifier: 0.1071 (0.1537)  loss_box_reg: 0.1035 (0.1459)  loss_objectness: 0.0755 (0.0985)  loss_rpn_box_reg: 0.0290 (0.0330)  time: 0.2729  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [34]  [1060/1229]  eta: 0:00:46  lr: 0.000000  loss: 0.3442 (0.4322)  loss_classifier: 0.1299 (0.1540)  loss_box_reg: 0.1035 (0.1463)  loss_objectness: 0.0798 (0.0988)  loss_rpn_box_reg: 0.0253 (0.0331)  time: 0.2743  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [34]  [1070/1229]  eta: 0:00:43  lr: 0.000000  loss: 0.4254 (0.4321)  loss_classifier: 0.1400 (0.1539)  loss_box_reg: 0.1266 (0.1462)  loss_objectness: 0.0798 (0.0987)  loss_rpn_box_reg: 0.0310 (0.0333)  time: 0.2728  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [34]  [1080/1229]  eta: 0:00:40  lr: 0.000000  loss: 0.4014 (0.4321)  loss_classifier: 0.1504 (0.1540)  loss_box_reg: 0.1249 (0.1462)  loss_objectness: 0.0972 (0.0988)  loss_rpn_box_reg: 0.0259 (0.0332)  time: 0.2701  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [34]  [1090/1229]  eta: 0:00:38  lr: 0.000000  loss: 0.4014 (0.4325)  loss_classifier: 0.1504 (0.1539)  loss_box_reg: 0.1115 (0.1462)  loss_objectness: 0.0904 (0.0988)  loss_rpn_box_reg: 0.0206 (0.0336)  time: 0.2729  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [34]  [1100/1229]  eta: 0:00:35  lr: 0.000000  loss: 0.3709 (0.4324)  loss_classifier: 0.1425 (0.1540)  loss_box_reg: 0.1215 (0.1462)  loss_objectness: 0.0740 (0.0986)  loss_rpn_box_reg: 0.0225 (0.0335)  time: 0.2710  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [34]  [1110/1229]  eta: 0:00:32  lr: 0.000000  loss: 0.3365 (0.4318)  loss_classifier: 0.1262 (0.1538)  loss_box_reg: 0.1215 (0.1461)  loss_objectness: 0.0709 (0.0985)  loss_rpn_box_reg: 0.0158 (0.0334)  time: 0.2711  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [34]  [1120/1229]  eta: 0:00:29  lr: 0.000000  loss: 0.3708 (0.4319)  loss_classifier: 0.1409 (0.1538)  loss_box_reg: 0.1260 (0.1462)  loss_objectness: 0.0722 (0.0985)  loss_rpn_box_reg: 0.0158 (0.0334)  time: 0.2770  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [34]  [1130/1229]  eta: 0:00:27  lr: 0.000000  loss: 0.3812 (0.4317)  loss_classifier: 0.1316 (0.1536)  loss_box_reg: 0.1360 (0.1461)  loss_objectness: 0.0770 (0.0986)  loss_rpn_box_reg: 0.0234 (0.0335)  time: 0.2708  data: 0.1305  max mem: 1751\n",
      "Training Epoch: [34]  [1140/1229]  eta: 0:00:24  lr: 0.000000  loss: 0.4370 (0.4322)  loss_classifier: 0.1390 (0.1537)  loss_box_reg: 0.1440 (0.1463)  loss_objectness: 0.0783 (0.0985)  loss_rpn_box_reg: 0.0320 (0.0336)  time: 0.2633  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [34]  [1150/1229]  eta: 0:00:21  lr: 0.000000  loss: 0.3894 (0.4314)  loss_classifier: 0.1420 (0.1535)  loss_box_reg: 0.1079 (0.1459)  loss_objectness: 0.0867 (0.0984)  loss_rpn_box_reg: 0.0191 (0.0336)  time: 0.2700  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [34]  [1160/1229]  eta: 0:00:18  lr: 0.000000  loss: 0.3523 (0.4318)  loss_classifier: 0.1324 (0.1536)  loss_box_reg: 0.1165 (0.1462)  loss_objectness: 0.0799 (0.0983)  loss_rpn_box_reg: 0.0170 (0.0336)  time: 0.2695  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [34]  [1170/1229]  eta: 0:00:16  lr: 0.000000  loss: 0.4761 (0.4328)  loss_classifier: 0.1570 (0.1539)  loss_box_reg: 0.1641 (0.1467)  loss_objectness: 0.0711 (0.0984)  loss_rpn_box_reg: 0.0307 (0.0337)  time: 0.2693  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [34]  [1180/1229]  eta: 0:00:13  lr: 0.000000  loss: 0.3098 (0.4320)  loss_classifier: 0.1220 (0.1537)  loss_box_reg: 0.0967 (0.1462)  loss_objectness: 0.0892 (0.0984)  loss_rpn_box_reg: 0.0276 (0.0338)  time: 0.2766  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [34]  [1190/1229]  eta: 0:00:10  lr: 0.000000  loss: 0.3716 (0.4332)  loss_classifier: 0.1288 (0.1540)  loss_box_reg: 0.1030 (0.1466)  loss_objectness: 0.0946 (0.0986)  loss_rpn_box_reg: 0.0228 (0.0340)  time: 0.2755  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [34]  [1200/1229]  eta: 0:00:07  lr: 0.000000  loss: 0.3716 (0.4334)  loss_classifier: 0.1346 (0.1541)  loss_box_reg: 0.1526 (0.1466)  loss_objectness: 0.0946 (0.0987)  loss_rpn_box_reg: 0.0228 (0.0339)  time: 0.2762  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [34]  [1210/1229]  eta: 0:00:05  lr: 0.000000  loss: 0.4488 (0.4339)  loss_classifier: 0.1686 (0.1544)  loss_box_reg: 0.1315 (0.1468)  loss_objectness: 0.0974 (0.0989)  loss_rpn_box_reg: 0.0225 (0.0339)  time: 0.2771  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [34]  [1220/1229]  eta: 0:00:02  lr: 0.000000  loss: 0.4106 (0.4335)  loss_classifier: 0.1213 (0.1542)  loss_box_reg: 0.1454 (0.1467)  loss_objectness: 0.0923 (0.0988)  loss_rpn_box_reg: 0.0225 (0.0338)  time: 0.2712  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [34]  [1228/1229]  eta: 0:00:00  lr: 0.000000  loss: 0.3475 (0.4331)  loss_classifier: 0.1192 (0.1540)  loss_box_reg: 0.1249 (0.1466)  loss_objectness: 0.0879 (0.0987)  loss_rpn_box_reg: 0.0214 (0.0338)  time: 0.2696  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [34] Total time: 0:05:36 (0.2740 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:21  model_time: 0.2290 (0.2290)  evaluator_time: 0.0020 (0.0020)  time: 0.2630  data: 0.0300  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0790 (0.0817)  evaluator_time: 0.0040 (0.0085)  time: 0.1267  data: 0.0358  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0840 (0.0809)  evaluator_time: 0.0030 (0.0078)  time: 0.1207  data: 0.0306  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0730 (0.0803)  evaluator_time: 0.0040 (0.0076)  time: 0.1194  data: 0.0351  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0730 (0.0802)  evaluator_time: 0.0030 (0.0076)  time: 0.1166  data: 0.0335  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1239 s / it)\n",
      "Averaged stats: model_time: 0.0730 (0.0802)  evaluator_time: 0.0030 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [34]  [  0/308]  eta: 0:00:37  lr: 0.000000  loss: 0.1625 (0.1625)  loss_classifier: 0.0593 (0.0593)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0233 (0.0233)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1210  data: 0.0280  max mem: 1751\n",
      "Testing Epoch: [34]  [100/308]  eta: 0:00:29  lr: 0.000000  loss: 0.3082 (0.4810)  loss_classifier: 0.1334 (0.1546)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0549 (0.1018)  loss_rpn_box_reg: 0.0186 (0.0523)  time: 0.1401  data: 0.0377  max mem: 1751\n",
      "Testing Epoch: [34]  [200/308]  eta: 0:00:15  lr: 0.000000  loss: 0.3508 (0.4566)  loss_classifier: 0.1393 (0.1491)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0630 (0.0951)  loss_rpn_box_reg: 0.0197 (0.0493)  time: 0.1396  data: 0.0335  max mem: 1751\n",
      "Testing Epoch: [34]  [300/308]  eta: 0:00:01  lr: 0.000000  loss: 0.4636 (0.4538)  loss_classifier: 0.1561 (0.1492)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0745 (0.0929)  loss_rpn_box_reg: 0.0265 (0.0476)  time: 0.1332  data: 0.0376  max mem: 1751\n",
      "Testing Epoch: [34]  [307/308]  eta: 0:00:00  lr: 0.000000  loss: 0.4636 (0.4539)  loss_classifier: 0.1860 (0.1494)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0776 (0.0929)  loss_rpn_box_reg: 0.0271 (0.0471)  time: 0.1313  data: 0.0359  max mem: 1751\n",
      "Testing Epoch: [34] Total time: 0:00:42 (0.1380 s / it)\n",
      "Training Epoch: [35]  [   0/1229]  eta: 0:05:41  lr: 0.000000  loss: 0.2751 (0.2751)  loss_classifier: 0.1075 (0.1075)  loss_box_reg: 0.0837 (0.0837)  loss_objectness: 0.0798 (0.0798)  loss_rpn_box_reg: 0.0041 (0.0041)  time: 0.2780  data: 0.1220  max mem: 1751\n",
      "Training Epoch: [35]  [  10/1229]  eta: 0:05:48  lr: 0.000000  loss: 0.4962 (0.5294)  loss_classifier: 0.1656 (0.1846)  loss_box_reg: 0.1469 (0.1894)  loss_objectness: 0.1198 (0.1197)  loss_rpn_box_reg: 0.0425 (0.0357)  time: 0.2863  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [35]  [  20/1229]  eta: 0:05:39  lr: 0.000000  loss: 0.5122 (0.5351)  loss_classifier: 0.1674 (0.1953)  loss_box_reg: 0.1469 (0.1892)  loss_objectness: 0.1063 (0.1182)  loss_rpn_box_reg: 0.0281 (0.0324)  time: 0.2807  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [35]  [  30/1229]  eta: 0:05:35  lr: 0.000000  loss: 0.4210 (0.5141)  loss_classifier: 0.1649 (0.1854)  loss_box_reg: 0.1105 (0.1793)  loss_objectness: 0.0977 (0.1110)  loss_rpn_box_reg: 0.0198 (0.0383)  time: 0.2760  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [35]  [  40/1229]  eta: 0:05:30  lr: 0.000000  loss: 0.3937 (0.5052)  loss_classifier: 0.1649 (0.1852)  loss_box_reg: 0.1105 (0.1755)  loss_objectness: 0.0916 (0.1090)  loss_rpn_box_reg: 0.0198 (0.0354)  time: 0.2747  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [35]  [  50/1229]  eta: 0:05:26  lr: 0.000000  loss: 0.4262 (0.4963)  loss_classifier: 0.1661 (0.1806)  loss_box_reg: 0.1307 (0.1711)  loss_objectness: 0.0816 (0.1061)  loss_rpn_box_reg: 0.0235 (0.0384)  time: 0.2730  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [35]  [  60/1229]  eta: 0:05:24  lr: 0.000000  loss: 0.4105 (0.4891)  loss_classifier: 0.1392 (0.1777)  loss_box_reg: 0.0927 (0.1705)  loss_objectness: 0.0902 (0.1050)  loss_rpn_box_reg: 0.0211 (0.0359)  time: 0.2786  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [35]  [  70/1229]  eta: 0:05:19  lr: 0.000000  loss: 0.4187 (0.4846)  loss_classifier: 0.1539 (0.1742)  loss_box_reg: 0.0978 (0.1643)  loss_objectness: 0.1031 (0.1092)  loss_rpn_box_reg: 0.0211 (0.0370)  time: 0.2725  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [35]  [  80/1229]  eta: 0:05:16  lr: 0.000000  loss: 0.3520 (0.4636)  loss_classifier: 0.1240 (0.1668)  loss_box_reg: 0.0901 (0.1555)  loss_objectness: 0.0952 (0.1053)  loss_rpn_box_reg: 0.0257 (0.0359)  time: 0.2670  data: 0.1292  max mem: 1751\n",
      "Training Epoch: [35]  [  90/1229]  eta: 0:05:13  lr: 0.000000  loss: 0.3728 (0.4775)  loss_classifier: 0.1240 (0.1709)  loss_box_reg: 0.1199 (0.1624)  loss_objectness: 0.0757 (0.1070)  loss_rpn_box_reg: 0.0236 (0.0371)  time: 0.2718  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [35]  [ 100/1229]  eta: 0:05:10  lr: 0.000000  loss: 0.4719 (0.4677)  loss_classifier: 0.1685 (0.1674)  loss_box_reg: 0.1639 (0.1590)  loss_objectness: 0.0907 (0.1051)  loss_rpn_box_reg: 0.0230 (0.0362)  time: 0.2731  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [35]  [ 110/1229]  eta: 0:05:07  lr: 0.000000  loss: 0.4257 (0.4641)  loss_classifier: 0.1685 (0.1663)  loss_box_reg: 0.1276 (0.1572)  loss_objectness: 0.0969 (0.1055)  loss_rpn_box_reg: 0.0170 (0.0350)  time: 0.2736  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [35]  [ 120/1229]  eta: 0:05:04  lr: 0.000000  loss: 0.4257 (0.4660)  loss_classifier: 0.1714 (0.1674)  loss_box_reg: 0.1371 (0.1608)  loss_objectness: 0.0963 (0.1039)  loss_rpn_box_reg: 0.0177 (0.0340)  time: 0.2720  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [35]  [ 130/1229]  eta: 0:05:01  lr: 0.000000  loss: 0.3341 (0.4602)  loss_classifier: 0.1161 (0.1651)  loss_box_reg: 0.1008 (0.1559)  loss_objectness: 0.0917 (0.1055)  loss_rpn_box_reg: 0.0157 (0.0337)  time: 0.2745  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [35]  [ 140/1229]  eta: 0:04:59  lr: 0.000000  loss: 0.3972 (0.4681)  loss_classifier: 0.1351 (0.1687)  loss_box_reg: 0.1179 (0.1597)  loss_objectness: 0.1141 (0.1057)  loss_rpn_box_reg: 0.0268 (0.0340)  time: 0.2758  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [35]  [ 150/1229]  eta: 0:04:56  lr: 0.000000  loss: 0.4316 (0.4654)  loss_classifier: 0.1493 (0.1679)  loss_box_reg: 0.1490 (0.1589)  loss_objectness: 0.0976 (0.1056)  loss_rpn_box_reg: 0.0166 (0.0330)  time: 0.2733  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [35]  [ 160/1229]  eta: 0:04:52  lr: 0.000000  loss: 0.3580 (0.4709)  loss_classifier: 0.1476 (0.1697)  loss_box_reg: 0.1179 (0.1623)  loss_objectness: 0.0913 (0.1060)  loss_rpn_box_reg: 0.0166 (0.0329)  time: 0.2684  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [35]  [ 170/1229]  eta: 0:04:50  lr: 0.000000  loss: 0.3244 (0.4644)  loss_classifier: 0.1201 (0.1672)  loss_box_reg: 0.1186 (0.1606)  loss_objectness: 0.0870 (0.1044)  loss_rpn_box_reg: 0.0172 (0.0322)  time: 0.2704  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [35]  [ 180/1229]  eta: 0:04:47  lr: 0.000000  loss: 0.3623 (0.4618)  loss_classifier: 0.1201 (0.1662)  loss_box_reg: 0.1186 (0.1595)  loss_objectness: 0.0776 (0.1038)  loss_rpn_box_reg: 0.0176 (0.0323)  time: 0.2783  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [35]  [ 190/1229]  eta: 0:04:44  lr: 0.000000  loss: 0.4050 (0.4604)  loss_classifier: 0.1415 (0.1660)  loss_box_reg: 0.1376 (0.1603)  loss_objectness: 0.0726 (0.1023)  loss_rpn_box_reg: 0.0176 (0.0317)  time: 0.2758  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [35]  [ 200/1229]  eta: 0:04:42  lr: 0.000000  loss: 0.3550 (0.4609)  loss_classifier: 0.1316 (0.1656)  loss_box_reg: 0.1285 (0.1613)  loss_objectness: 0.0762 (0.1022)  loss_rpn_box_reg: 0.0161 (0.0318)  time: 0.2752  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [35]  [ 210/1229]  eta: 0:04:39  lr: 0.000000  loss: 0.4564 (0.4619)  loss_classifier: 0.1649 (0.1661)  loss_box_reg: 0.1238 (0.1608)  loss_objectness: 0.1030 (0.1037)  loss_rpn_box_reg: 0.0218 (0.0313)  time: 0.2751  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [35]  [ 220/1229]  eta: 0:04:36  lr: 0.000000  loss: 0.4449 (0.4587)  loss_classifier: 0.1649 (0.1652)  loss_box_reg: 0.1035 (0.1589)  loss_objectness: 0.1100 (0.1033)  loss_rpn_box_reg: 0.0200 (0.0313)  time: 0.2713  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [35]  [ 230/1229]  eta: 0:04:33  lr: 0.000000  loss: 0.2972 (0.4560)  loss_classifier: 0.1202 (0.1644)  loss_box_reg: 0.0903 (0.1578)  loss_objectness: 0.0697 (0.1026)  loss_rpn_box_reg: 0.0123 (0.0312)  time: 0.2719  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [35]  [ 240/1229]  eta: 0:04:31  lr: 0.000000  loss: 0.4454 (0.4561)  loss_classifier: 0.1460 (0.1638)  loss_box_reg: 0.1309 (0.1577)  loss_objectness: 0.0875 (0.1034)  loss_rpn_box_reg: 0.0157 (0.0312)  time: 0.2749  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [35]  [ 250/1229]  eta: 0:04:28  lr: 0.000000  loss: 0.4454 (0.4533)  loss_classifier: 0.1569 (0.1633)  loss_box_reg: 0.1309 (0.1570)  loss_objectness: 0.0792 (0.1024)  loss_rpn_box_reg: 0.0173 (0.0307)  time: 0.2736  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [35]  [ 260/1229]  eta: 0:04:25  lr: 0.000000  loss: 0.3077 (0.4483)  loss_classifier: 0.1240 (0.1614)  loss_box_reg: 0.0889 (0.1542)  loss_objectness: 0.0681 (0.1024)  loss_rpn_box_reg: 0.0139 (0.0303)  time: 0.2693  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [35]  [ 270/1229]  eta: 0:04:22  lr: 0.000000  loss: 0.2561 (0.4449)  loss_classifier: 0.0976 (0.1603)  loss_box_reg: 0.0753 (0.1524)  loss_objectness: 0.0812 (0.1020)  loss_rpn_box_reg: 0.0151 (0.0302)  time: 0.2669  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [35]  [ 280/1229]  eta: 0:04:19  lr: 0.000000  loss: 0.3551 (0.4449)  loss_classifier: 0.1262 (0.1601)  loss_box_reg: 0.0983 (0.1525)  loss_objectness: 0.0854 (0.1021)  loss_rpn_box_reg: 0.0218 (0.0302)  time: 0.2728  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [35]  [ 290/1229]  eta: 0:04:16  lr: 0.000000  loss: 0.4055 (0.4424)  loss_classifier: 0.1385 (0.1594)  loss_box_reg: 0.1059 (0.1510)  loss_objectness: 0.0979 (0.1018)  loss_rpn_box_reg: 0.0212 (0.0301)  time: 0.2739  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [35]  [ 300/1229]  eta: 0:04:14  lr: 0.000000  loss: 0.3842 (0.4415)  loss_classifier: 0.1306 (0.1589)  loss_box_reg: 0.1019 (0.1504)  loss_objectness: 0.0870 (0.1019)  loss_rpn_box_reg: 0.0168 (0.0302)  time: 0.2693  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [35]  [ 310/1229]  eta: 0:04:11  lr: 0.000000  loss: 0.3299 (0.4392)  loss_classifier: 0.1168 (0.1579)  loss_box_reg: 0.1086 (0.1499)  loss_objectness: 0.0677 (0.1010)  loss_rpn_box_reg: 0.0198 (0.0304)  time: 0.2702  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [35]  [ 320/1229]  eta: 0:04:08  lr: 0.000000  loss: 0.3482 (0.4395)  loss_classifier: 0.1183 (0.1585)  loss_box_reg: 0.1112 (0.1496)  loss_objectness: 0.0835 (0.1013)  loss_rpn_box_reg: 0.0198 (0.0301)  time: 0.2730  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [35]  [ 330/1229]  eta: 0:04:05  lr: 0.000000  loss: 0.4077 (0.4400)  loss_classifier: 0.1670 (0.1587)  loss_box_reg: 0.1370 (0.1498)  loss_objectness: 0.0953 (0.1010)  loss_rpn_box_reg: 0.0187 (0.0304)  time: 0.2773  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [35]  [ 340/1229]  eta: 0:04:03  lr: 0.000000  loss: 0.4173 (0.4404)  loss_classifier: 0.1525 (0.1592)  loss_box_reg: 0.1445 (0.1496)  loss_objectness: 0.0912 (0.1012)  loss_rpn_box_reg: 0.0216 (0.0304)  time: 0.2765  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [35]  [ 350/1229]  eta: 0:04:00  lr: 0.000000  loss: 0.3229 (0.4383)  loss_classifier: 0.1359 (0.1584)  loss_box_reg: 0.1012 (0.1487)  loss_objectness: 0.1004 (0.1008)  loss_rpn_box_reg: 0.0245 (0.0304)  time: 0.2795  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [35]  [ 360/1229]  eta: 0:03:57  lr: 0.000000  loss: 0.2851 (0.4368)  loss_classifier: 0.0922 (0.1579)  loss_box_reg: 0.0921 (0.1486)  loss_objectness: 0.0805 (0.1004)  loss_rpn_box_reg: 0.0166 (0.0300)  time: 0.2762  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [35]  [ 370/1229]  eta: 0:03:55  lr: 0.000000  loss: 0.4337 (0.4395)  loss_classifier: 0.1305 (0.1584)  loss_box_reg: 0.1422 (0.1496)  loss_objectness: 0.0891 (0.1009)  loss_rpn_box_reg: 0.0187 (0.0306)  time: 0.2760  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [35]  [ 380/1229]  eta: 0:03:52  lr: 0.000000  loss: 0.4337 (0.4379)  loss_classifier: 0.1255 (0.1575)  loss_box_reg: 0.1359 (0.1486)  loss_objectness: 0.1126 (0.1014)  loss_rpn_box_reg: 0.0199 (0.0304)  time: 0.2768  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [35]  [ 390/1229]  eta: 0:03:49  lr: 0.000000  loss: 0.3817 (0.4380)  loss_classifier: 0.1032 (0.1572)  loss_box_reg: 0.0928 (0.1487)  loss_objectness: 0.0946 (0.1015)  loss_rpn_box_reg: 0.0175 (0.0305)  time: 0.2677  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [35]  [ 400/1229]  eta: 0:03:47  lr: 0.000000  loss: 0.3398 (0.4353)  loss_classifier: 0.1102 (0.1564)  loss_box_reg: 0.0901 (0.1475)  loss_objectness: 0.0761 (0.1010)  loss_rpn_box_reg: 0.0175 (0.0305)  time: 0.2753  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [35]  [ 410/1229]  eta: 0:03:44  lr: 0.000000  loss: 0.3631 (0.4346)  loss_classifier: 0.1255 (0.1561)  loss_box_reg: 0.0910 (0.1471)  loss_objectness: 0.0722 (0.1006)  loss_rpn_box_reg: 0.0152 (0.0308)  time: 0.2809  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [35]  [ 420/1229]  eta: 0:03:41  lr: 0.000000  loss: 0.3445 (0.4335)  loss_classifier: 0.1257 (0.1556)  loss_box_reg: 0.1052 (0.1466)  loss_objectness: 0.0691 (0.1002)  loss_rpn_box_reg: 0.0219 (0.0311)  time: 0.2740  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [35]  [ 430/1229]  eta: 0:03:38  lr: 0.000000  loss: 0.3449 (0.4347)  loss_classifier: 0.1387 (0.1559)  loss_box_reg: 0.1180 (0.1466)  loss_objectness: 0.0770 (0.1008)  loss_rpn_box_reg: 0.0219 (0.0314)  time: 0.2729  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [35]  [ 440/1229]  eta: 0:03:36  lr: 0.000000  loss: 0.4078 (0.4358)  loss_classifier: 0.1500 (0.1562)  loss_box_reg: 0.1209 (0.1468)  loss_objectness: 0.1075 (0.1012)  loss_rpn_box_reg: 0.0250 (0.0316)  time: 0.2766  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [35]  [ 450/1229]  eta: 0:03:33  lr: 0.000000  loss: 0.3460 (0.4367)  loss_classifier: 0.1449 (0.1567)  loss_box_reg: 0.1383 (0.1476)  loss_objectness: 0.0827 (0.1009)  loss_rpn_box_reg: 0.0175 (0.0315)  time: 0.2745  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [35]  [ 460/1229]  eta: 0:03:30  lr: 0.000000  loss: 0.3456 (0.4364)  loss_classifier: 0.1417 (0.1565)  loss_box_reg: 0.1355 (0.1475)  loss_objectness: 0.0755 (0.1008)  loss_rpn_box_reg: 0.0234 (0.0315)  time: 0.2764  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [35]  [ 470/1229]  eta: 0:03:27  lr: 0.000000  loss: 0.3181 (0.4350)  loss_classifier: 0.1136 (0.1561)  loss_box_reg: 0.1040 (0.1473)  loss_objectness: 0.0755 (0.1003)  loss_rpn_box_reg: 0.0238 (0.0313)  time: 0.2706  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [35]  [ 480/1229]  eta: 0:03:25  lr: 0.000000  loss: 0.3392 (0.4355)  loss_classifier: 0.1376 (0.1563)  loss_box_reg: 0.1434 (0.1477)  loss_objectness: 0.0778 (0.1004)  loss_rpn_box_reg: 0.0164 (0.0312)  time: 0.2666  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [35]  [ 490/1229]  eta: 0:03:22  lr: 0.000000  loss: 0.3271 (0.4330)  loss_classifier: 0.1278 (0.1552)  loss_box_reg: 0.1068 (0.1469)  loss_objectness: 0.0819 (0.0999)  loss_rpn_box_reg: 0.0164 (0.0310)  time: 0.2726  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [35]  [ 500/1229]  eta: 0:03:19  lr: 0.000000  loss: 0.2800 (0.4313)  loss_classifier: 0.0893 (0.1545)  loss_box_reg: 0.0790 (0.1462)  loss_objectness: 0.0819 (0.0996)  loss_rpn_box_reg: 0.0203 (0.0311)  time: 0.2666  data: 0.1291  max mem: 1751\n",
      "Training Epoch: [35]  [ 510/1229]  eta: 0:03:16  lr: 0.000000  loss: 0.3443 (0.4331)  loss_classifier: 0.1094 (0.1551)  loss_box_reg: 0.0830 (0.1457)  loss_objectness: 0.1014 (0.1003)  loss_rpn_box_reg: 0.0217 (0.0320)  time: 0.2643  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [35]  [ 520/1229]  eta: 0:03:13  lr: 0.000000  loss: 0.3670 (0.4354)  loss_classifier: 0.1538 (0.1562)  loss_box_reg: 0.1263 (0.1473)  loss_objectness: 0.1183 (0.1000)  loss_rpn_box_reg: 0.0214 (0.0319)  time: 0.2715  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [35]  [ 530/1229]  eta: 0:03:11  lr: 0.000000  loss: 0.3657 (0.4345)  loss_classifier: 0.1466 (0.1561)  loss_box_reg: 0.1436 (0.1473)  loss_objectness: 0.0676 (0.0995)  loss_rpn_box_reg: 0.0178 (0.0316)  time: 0.2815  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [35]  [ 540/1229]  eta: 0:03:08  lr: 0.000000  loss: 0.3268 (0.4329)  loss_classifier: 0.1230 (0.1556)  loss_box_reg: 0.1020 (0.1466)  loss_objectness: 0.0697 (0.0992)  loss_rpn_box_reg: 0.0172 (0.0315)  time: 0.2795  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [35]  [ 550/1229]  eta: 0:03:05  lr: 0.000000  loss: 0.3178 (0.4328)  loss_classifier: 0.1215 (0.1556)  loss_box_reg: 0.1005 (0.1466)  loss_objectness: 0.0802 (0.0992)  loss_rpn_box_reg: 0.0223 (0.0314)  time: 0.2745  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [35]  [ 560/1229]  eta: 0:03:03  lr: 0.000000  loss: 0.3569 (0.4327)  loss_classifier: 0.1268 (0.1553)  loss_box_reg: 0.1029 (0.1461)  loss_objectness: 0.0983 (0.0998)  loss_rpn_box_reg: 0.0242 (0.0314)  time: 0.2738  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [35]  [ 570/1229]  eta: 0:03:00  lr: 0.000000  loss: 0.4637 (0.4340)  loss_classifier: 0.1605 (0.1558)  loss_box_reg: 0.1235 (0.1466)  loss_objectness: 0.1097 (0.1001)  loss_rpn_box_reg: 0.0239 (0.0315)  time: 0.2721  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [35]  [ 580/1229]  eta: 0:02:57  lr: 0.000000  loss: 0.4708 (0.4341)  loss_classifier: 0.1626 (0.1559)  loss_box_reg: 0.1559 (0.1464)  loss_objectness: 0.0898 (0.1001)  loss_rpn_box_reg: 0.0239 (0.0317)  time: 0.2732  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [35]  [ 590/1229]  eta: 0:02:54  lr: 0.000000  loss: 0.3776 (0.4338)  loss_classifier: 0.1420 (0.1559)  loss_box_reg: 0.1249 (0.1464)  loss_objectness: 0.0806 (0.0999)  loss_rpn_box_reg: 0.0309 (0.0317)  time: 0.2743  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [35]  [ 600/1229]  eta: 0:02:52  lr: 0.000000  loss: 0.3711 (0.4335)  loss_classifier: 0.1420 (0.1557)  loss_box_reg: 0.1249 (0.1466)  loss_objectness: 0.0807 (0.0995)  loss_rpn_box_reg: 0.0282 (0.0316)  time: 0.2780  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [35]  [ 610/1229]  eta: 0:02:49  lr: 0.000000  loss: 0.3431 (0.4329)  loss_classifier: 0.1329 (0.1556)  loss_box_reg: 0.0898 (0.1463)  loss_objectness: 0.0873 (0.0996)  loss_rpn_box_reg: 0.0213 (0.0315)  time: 0.2779  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [35]  [ 620/1229]  eta: 0:02:46  lr: 0.000000  loss: 0.3431 (0.4329)  loss_classifier: 0.1329 (0.1558)  loss_box_reg: 0.0872 (0.1461)  loss_objectness: 0.0826 (0.0994)  loss_rpn_box_reg: 0.0267 (0.0316)  time: 0.2777  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [35]  [ 630/1229]  eta: 0:02:44  lr: 0.000000  loss: 0.4129 (0.4325)  loss_classifier: 0.1505 (0.1554)  loss_box_reg: 0.0956 (0.1458)  loss_objectness: 0.0964 (0.0995)  loss_rpn_box_reg: 0.0190 (0.0317)  time: 0.2771  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [35]  [ 640/1229]  eta: 0:02:41  lr: 0.000000  loss: 0.4129 (0.4331)  loss_classifier: 0.1534 (0.1558)  loss_box_reg: 0.1403 (0.1463)  loss_objectness: 0.0964 (0.0994)  loss_rpn_box_reg: 0.0167 (0.0317)  time: 0.2787  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [35]  [ 650/1229]  eta: 0:02:38  lr: 0.000000  loss: 0.3650 (0.4317)  loss_classifier: 0.1300 (0.1552)  loss_box_reg: 0.1255 (0.1456)  loss_objectness: 0.0718 (0.0993)  loss_rpn_box_reg: 0.0167 (0.0316)  time: 0.2759  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [35]  [ 660/1229]  eta: 0:02:35  lr: 0.000000  loss: 0.3353 (0.4336)  loss_classifier: 0.1232 (0.1558)  loss_box_reg: 0.1163 (0.1462)  loss_objectness: 0.1043 (0.0995)  loss_rpn_box_reg: 0.0230 (0.0321)  time: 0.2700  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [35]  [ 670/1229]  eta: 0:02:33  lr: 0.000000  loss: 0.4549 (0.4341)  loss_classifier: 0.1566 (0.1558)  loss_box_reg: 0.1478 (0.1466)  loss_objectness: 0.1050 (0.0995)  loss_rpn_box_reg: 0.0212 (0.0322)  time: 0.2739  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [35]  [ 680/1229]  eta: 0:02:30  lr: 0.000000  loss: 0.4256 (0.4331)  loss_classifier: 0.1478 (0.1555)  loss_box_reg: 0.1086 (0.1462)  loss_objectness: 0.0813 (0.0993)  loss_rpn_box_reg: 0.0185 (0.0321)  time: 0.2814  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [35]  [ 690/1229]  eta: 0:02:27  lr: 0.000000  loss: 0.3436 (0.4336)  loss_classifier: 0.1249 (0.1556)  loss_box_reg: 0.1086 (0.1465)  loss_objectness: 0.0849 (0.0994)  loss_rpn_box_reg: 0.0198 (0.0321)  time: 0.2814  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [35]  [ 700/1229]  eta: 0:02:25  lr: 0.000000  loss: 0.4085 (0.4337)  loss_classifier: 0.1484 (0.1555)  loss_box_reg: 0.1227 (0.1465)  loss_objectness: 0.0937 (0.0993)  loss_rpn_box_reg: 0.0246 (0.0323)  time: 0.2752  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [35]  [ 710/1229]  eta: 0:02:22  lr: 0.000000  loss: 0.3783 (0.4336)  loss_classifier: 0.1335 (0.1554)  loss_box_reg: 0.1202 (0.1464)  loss_objectness: 0.0925 (0.0993)  loss_rpn_box_reg: 0.0248 (0.0324)  time: 0.2722  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [35]  [ 720/1229]  eta: 0:02:19  lr: 0.000000  loss: 0.2669 (0.4326)  loss_classifier: 0.0945 (0.1549)  loss_box_reg: 0.0977 (0.1462)  loss_objectness: 0.0764 (0.0990)  loss_rpn_box_reg: 0.0190 (0.0325)  time: 0.2669  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [35]  [ 730/1229]  eta: 0:02:16  lr: 0.000000  loss: 0.4441 (0.4338)  loss_classifier: 0.1417 (0.1553)  loss_box_reg: 0.1259 (0.1468)  loss_objectness: 0.0764 (0.0992)  loss_rpn_box_reg: 0.0190 (0.0325)  time: 0.2675  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [35]  [ 740/1229]  eta: 0:02:13  lr: 0.000000  loss: 0.5032 (0.4349)  loss_classifier: 0.1718 (0.1557)  loss_box_reg: 0.1555 (0.1471)  loss_objectness: 0.1149 (0.0995)  loss_rpn_box_reg: 0.0309 (0.0326)  time: 0.2728  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [35]  [ 750/1229]  eta: 0:02:11  lr: 0.000000  loss: 0.3752 (0.4343)  loss_classifier: 0.1337 (0.1554)  loss_box_reg: 0.0956 (0.1465)  loss_objectness: 0.1058 (0.0998)  loss_rpn_box_reg: 0.0305 (0.0327)  time: 0.2742  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [35]  [ 760/1229]  eta: 0:02:08  lr: 0.000000  loss: 0.3605 (0.4347)  loss_classifier: 0.1043 (0.1556)  loss_box_reg: 0.0988 (0.1467)  loss_objectness: 0.1005 (0.0998)  loss_rpn_box_reg: 0.0166 (0.0327)  time: 0.2774  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [35]  [ 770/1229]  eta: 0:02:05  lr: 0.000000  loss: 0.4421 (0.4343)  loss_classifier: 0.1660 (0.1555)  loss_box_reg: 0.1260 (0.1466)  loss_objectness: 0.1005 (0.0997)  loss_rpn_box_reg: 0.0156 (0.0325)  time: 0.2720  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [35]  [ 780/1229]  eta: 0:02:02  lr: 0.000000  loss: 0.3122 (0.4344)  loss_classifier: 0.1233 (0.1555)  loss_box_reg: 0.1163 (0.1469)  loss_objectness: 0.0827 (0.0996)  loss_rpn_box_reg: 0.0148 (0.0324)  time: 0.2651  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [35]  [ 790/1229]  eta: 0:02:00  lr: 0.000000  loss: 0.3543 (0.4339)  loss_classifier: 0.1233 (0.1553)  loss_box_reg: 0.1237 (0.1467)  loss_objectness: 0.0701 (0.0992)  loss_rpn_box_reg: 0.0231 (0.0327)  time: 0.2695  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [35]  [ 800/1229]  eta: 0:01:57  lr: 0.000000  loss: 0.3543 (0.4334)  loss_classifier: 0.1085 (0.1549)  loss_box_reg: 0.0914 (0.1466)  loss_objectness: 0.0722 (0.0992)  loss_rpn_box_reg: 0.0242 (0.0328)  time: 0.2731  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [35]  [ 810/1229]  eta: 0:01:54  lr: 0.000000  loss: 0.2366 (0.4318)  loss_classifier: 0.0872 (0.1543)  loss_box_reg: 0.0634 (0.1457)  loss_objectness: 0.0828 (0.0990)  loss_rpn_box_reg: 0.0140 (0.0327)  time: 0.2727  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [35]  [ 820/1229]  eta: 0:01:51  lr: 0.000000  loss: 0.2663 (0.4309)  loss_classifier: 0.1023 (0.1541)  loss_box_reg: 0.0665 (0.1453)  loss_objectness: 0.0651 (0.0988)  loss_rpn_box_reg: 0.0139 (0.0327)  time: 0.2683  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [35]  [ 830/1229]  eta: 0:01:49  lr: 0.000000  loss: 0.2932 (0.4304)  loss_classifier: 0.1140 (0.1540)  loss_box_reg: 0.1014 (0.1452)  loss_objectness: 0.0656 (0.0987)  loss_rpn_box_reg: 0.0161 (0.0325)  time: 0.2664  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [35]  [ 840/1229]  eta: 0:01:46  lr: 0.000000  loss: 0.3209 (0.4314)  loss_classifier: 0.1171 (0.1542)  loss_box_reg: 0.1134 (0.1456)  loss_objectness: 0.0656 (0.0988)  loss_rpn_box_reg: 0.0243 (0.0327)  time: 0.2715  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [35]  [ 850/1229]  eta: 0:01:43  lr: 0.000000  loss: 0.4365 (0.4318)  loss_classifier: 0.1414 (0.1544)  loss_box_reg: 0.1198 (0.1453)  loss_objectness: 0.0963 (0.0992)  loss_rpn_box_reg: 0.0286 (0.0328)  time: 0.2748  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [35]  [ 860/1229]  eta: 0:01:40  lr: 0.000000  loss: 0.3872 (0.4314)  loss_classifier: 0.1414 (0.1542)  loss_box_reg: 0.1248 (0.1452)  loss_objectness: 0.0963 (0.0993)  loss_rpn_box_reg: 0.0197 (0.0328)  time: 0.2690  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [35]  [ 870/1229]  eta: 0:01:38  lr: 0.000000  loss: 0.3872 (0.4317)  loss_classifier: 0.1458 (0.1543)  loss_box_reg: 0.1159 (0.1450)  loss_objectness: 0.0859 (0.0996)  loss_rpn_box_reg: 0.0188 (0.0327)  time: 0.2719  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [35]  [ 880/1229]  eta: 0:01:35  lr: 0.000000  loss: 0.4098 (0.4314)  loss_classifier: 0.1458 (0.1543)  loss_box_reg: 0.0979 (0.1448)  loss_objectness: 0.0859 (0.0997)  loss_rpn_box_reg: 0.0168 (0.0327)  time: 0.2814  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [35]  [ 890/1229]  eta: 0:01:32  lr: 0.000000  loss: 0.4221 (0.4310)  loss_classifier: 0.1261 (0.1541)  loss_box_reg: 0.0979 (0.1444)  loss_objectness: 0.0896 (0.0997)  loss_rpn_box_reg: 0.0159 (0.0328)  time: 0.2812  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [35]  [ 900/1229]  eta: 0:01:30  lr: 0.000000  loss: 0.4874 (0.4325)  loss_classifier: 0.1736 (0.1545)  loss_box_reg: 0.1335 (0.1450)  loss_objectness: 0.0939 (0.0998)  loss_rpn_box_reg: 0.0358 (0.0332)  time: 0.2796  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [35]  [ 910/1229]  eta: 0:01:27  lr: 0.000000  loss: 0.5291 (0.4330)  loss_classifier: 0.1925 (0.1546)  loss_box_reg: 0.1487 (0.1452)  loss_objectness: 0.1072 (0.1000)  loss_rpn_box_reg: 0.0319 (0.0332)  time: 0.2716  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [35]  [ 920/1229]  eta: 0:01:24  lr: 0.000000  loss: 0.3011 (0.4315)  loss_classifier: 0.0986 (0.1541)  loss_box_reg: 0.0721 (0.1443)  loss_objectness: 0.0932 (0.1000)  loss_rpn_box_reg: 0.0209 (0.0331)  time: 0.2696  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [35]  [ 930/1229]  eta: 0:01:21  lr: 0.000000  loss: 0.3237 (0.4323)  loss_classifier: 0.1024 (0.1544)  loss_box_reg: 0.0608 (0.1446)  loss_objectness: 0.0904 (0.1002)  loss_rpn_box_reg: 0.0196 (0.0331)  time: 0.2763  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [35]  [ 940/1229]  eta: 0:01:19  lr: 0.000000  loss: 0.4582 (0.4341)  loss_classifier: 0.1665 (0.1547)  loss_box_reg: 0.1812 (0.1453)  loss_objectness: 0.0982 (0.1003)  loss_rpn_box_reg: 0.0200 (0.0338)  time: 0.2722  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [35]  [ 950/1229]  eta: 0:01:16  lr: 0.000000  loss: 0.4403 (0.4346)  loss_classifier: 0.1514 (0.1549)  loss_box_reg: 0.1372 (0.1458)  loss_objectness: 0.0871 (0.1002)  loss_rpn_box_reg: 0.0151 (0.0336)  time: 0.2707  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [35]  [ 960/1229]  eta: 0:01:13  lr: 0.000000  loss: 0.3840 (0.4340)  loss_classifier: 0.1349 (0.1547)  loss_box_reg: 0.1237 (0.1454)  loss_objectness: 0.0791 (0.1002)  loss_rpn_box_reg: 0.0247 (0.0338)  time: 0.2701  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [35]  [ 970/1229]  eta: 0:01:10  lr: 0.000000  loss: 0.3816 (0.4331)  loss_classifier: 0.1120 (0.1543)  loss_box_reg: 0.1138 (0.1449)  loss_objectness: 0.0799 (0.1000)  loss_rpn_box_reg: 0.0273 (0.0338)  time: 0.2699  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [35]  [ 980/1229]  eta: 0:01:08  lr: 0.000000  loss: 0.3294 (0.4326)  loss_classifier: 0.1311 (0.1542)  loss_box_reg: 0.1121 (0.1448)  loss_objectness: 0.0799 (0.0999)  loss_rpn_box_reg: 0.0245 (0.0337)  time: 0.2767  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [35]  [ 990/1229]  eta: 0:01:05  lr: 0.000000  loss: 0.3945 (0.4325)  loss_classifier: 0.1394 (0.1542)  loss_box_reg: 0.1255 (0.1447)  loss_objectness: 0.0890 (0.1000)  loss_rpn_box_reg: 0.0222 (0.0336)  time: 0.2758  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [35]  [1000/1229]  eta: 0:01:02  lr: 0.000000  loss: 0.3945 (0.4319)  loss_classifier: 0.1365 (0.1539)  loss_box_reg: 0.1075 (0.1443)  loss_objectness: 0.0896 (0.1001)  loss_rpn_box_reg: 0.0214 (0.0336)  time: 0.2709  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [35]  [1010/1229]  eta: 0:00:59  lr: 0.000000  loss: 0.4147 (0.4325)  loss_classifier: 0.1528 (0.1541)  loss_box_reg: 0.1087 (0.1445)  loss_objectness: 0.1156 (0.1003)  loss_rpn_box_reg: 0.0217 (0.0336)  time: 0.2719  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [35]  [1020/1229]  eta: 0:00:57  lr: 0.000000  loss: 0.4772 (0.4327)  loss_classifier: 0.1643 (0.1541)  loss_box_reg: 0.1656 (0.1448)  loss_objectness: 0.0963 (0.1001)  loss_rpn_box_reg: 0.0218 (0.0337)  time: 0.2750  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [35]  [1030/1229]  eta: 0:00:54  lr: 0.000000  loss: 0.4032 (0.4335)  loss_classifier: 0.1643 (0.1544)  loss_box_reg: 0.1746 (0.1452)  loss_objectness: 0.0963 (0.1002)  loss_rpn_box_reg: 0.0271 (0.0338)  time: 0.2794  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [35]  [1040/1229]  eta: 0:00:51  lr: 0.000000  loss: 0.5309 (0.4342)  loss_classifier: 0.1974 (0.1547)  loss_box_reg: 0.1746 (0.1453)  loss_objectness: 0.1125 (0.1003)  loss_rpn_box_reg: 0.0257 (0.0339)  time: 0.2785  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [35]  [1050/1229]  eta: 0:00:49  lr: 0.000000  loss: 0.3687 (0.4337)  loss_classifier: 0.1401 (0.1545)  loss_box_reg: 0.0908 (0.1452)  loss_objectness: 0.0886 (0.1002)  loss_rpn_box_reg: 0.0257 (0.0339)  time: 0.2773  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [35]  [1060/1229]  eta: 0:00:46  lr: 0.000000  loss: 0.3448 (0.4336)  loss_classifier: 0.1173 (0.1543)  loss_box_reg: 0.1042 (0.1451)  loss_objectness: 0.0716 (0.1001)  loss_rpn_box_reg: 0.0308 (0.0341)  time: 0.2838  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [35]  [1070/1229]  eta: 0:00:43  lr: 0.000000  loss: 0.4575 (0.4344)  loss_classifier: 0.1437 (0.1545)  loss_box_reg: 0.1486 (0.1454)  loss_objectness: 0.0772 (0.1001)  loss_rpn_box_reg: 0.0352 (0.0344)  time: 0.2766  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [35]  [1080/1229]  eta: 0:00:40  lr: 0.000000  loss: 0.3939 (0.4340)  loss_classifier: 0.1444 (0.1544)  loss_box_reg: 0.0903 (0.1452)  loss_objectness: 0.0761 (0.1001)  loss_rpn_box_reg: 0.0189 (0.0343)  time: 0.2744  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [35]  [1090/1229]  eta: 0:00:38  lr: 0.000000  loss: 0.3692 (0.4347)  loss_classifier: 0.1410 (0.1546)  loss_box_reg: 0.1122 (0.1456)  loss_objectness: 0.0826 (0.1001)  loss_rpn_box_reg: 0.0183 (0.0343)  time: 0.2787  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [35]  [1100/1229]  eta: 0:00:35  lr: 0.000000  loss: 0.4810 (0.4363)  loss_classifier: 0.1713 (0.1552)  loss_box_reg: 0.1427 (0.1463)  loss_objectness: 0.1073 (0.1004)  loss_rpn_box_reg: 0.0203 (0.0344)  time: 0.2735  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [35]  [1110/1229]  eta: 0:00:32  lr: 0.000000  loss: 0.5092 (0.4372)  loss_classifier: 0.1759 (0.1555)  loss_box_reg: 0.1609 (0.1468)  loss_objectness: 0.1227 (0.1005)  loss_rpn_box_reg: 0.0203 (0.0345)  time: 0.2731  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [35]  [1120/1229]  eta: 0:00:29  lr: 0.000000  loss: 0.4197 (0.4372)  loss_classifier: 0.1600 (0.1555)  loss_box_reg: 0.1523 (0.1469)  loss_objectness: 0.0703 (0.1004)  loss_rpn_box_reg: 0.0189 (0.0344)  time: 0.2755  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [35]  [1130/1229]  eta: 0:00:27  lr: 0.000000  loss: 0.4006 (0.4376)  loss_classifier: 0.1472 (0.1556)  loss_box_reg: 0.1170 (0.1470)  loss_objectness: 0.1055 (0.1006)  loss_rpn_box_reg: 0.0204 (0.0345)  time: 0.2755  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [35]  [1140/1229]  eta: 0:00:24  lr: 0.000000  loss: 0.3522 (0.4367)  loss_classifier: 0.1415 (0.1553)  loss_box_reg: 0.1170 (0.1466)  loss_objectness: 0.0914 (0.1004)  loss_rpn_box_reg: 0.0174 (0.0344)  time: 0.2738  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [35]  [1150/1229]  eta: 0:00:21  lr: 0.000000  loss: 0.3165 (0.4366)  loss_classifier: 0.1219 (0.1552)  loss_box_reg: 0.1150 (0.1463)  loss_objectness: 0.0699 (0.1006)  loss_rpn_box_reg: 0.0131 (0.0344)  time: 0.2739  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [35]  [1160/1229]  eta: 0:00:18  lr: 0.000000  loss: 0.3825 (0.4368)  loss_classifier: 0.1516 (0.1554)  loss_box_reg: 0.1165 (0.1463)  loss_objectness: 0.1067 (0.1008)  loss_rpn_box_reg: 0.0205 (0.0343)  time: 0.2723  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [35]  [1170/1229]  eta: 0:00:16  lr: 0.000000  loss: 0.4585 (0.4371)  loss_classifier: 0.1616 (0.1555)  loss_box_reg: 0.1621 (0.1466)  loss_objectness: 0.1022 (0.1007)  loss_rpn_box_reg: 0.0215 (0.0342)  time: 0.2712  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [35]  [1180/1229]  eta: 0:00:13  lr: 0.000000  loss: 0.3550 (0.4368)  loss_classifier: 0.1454 (0.1553)  loss_box_reg: 0.1461 (0.1466)  loss_objectness: 0.0668 (0.1006)  loss_rpn_box_reg: 0.0211 (0.0342)  time: 0.2701  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [35]  [1190/1229]  eta: 0:00:10  lr: 0.000000  loss: 0.3004 (0.4363)  loss_classifier: 0.1122 (0.1552)  loss_box_reg: 0.0906 (0.1462)  loss_objectness: 0.0668 (0.1007)  loss_rpn_box_reg: 0.0193 (0.0341)  time: 0.2703  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [35]  [1200/1229]  eta: 0:00:07  lr: 0.000000  loss: 0.3300 (0.4362)  loss_classifier: 0.1351 (0.1552)  loss_box_reg: 0.0941 (0.1463)  loss_objectness: 0.0800 (0.1007)  loss_rpn_box_reg: 0.0182 (0.0340)  time: 0.2678  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [35]  [1210/1229]  eta: 0:00:05  lr: 0.000000  loss: 0.3300 (0.4354)  loss_classifier: 0.1022 (0.1550)  loss_box_reg: 0.0991 (0.1461)  loss_objectness: 0.0740 (0.1004)  loss_rpn_box_reg: 0.0161 (0.0339)  time: 0.2729  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [35]  [1220/1229]  eta: 0:00:02  lr: 0.000000  loss: 0.2764 (0.4354)  loss_classifier: 0.0996 (0.1550)  loss_box_reg: 0.0692 (0.1461)  loss_objectness: 0.0697 (0.1004)  loss_rpn_box_reg: 0.0185 (0.0340)  time: 0.2853  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [35]  [1228/1229]  eta: 0:00:00  lr: 0.000000  loss: 0.3573 (0.4356)  loss_classifier: 0.1560 (0.1550)  loss_box_reg: 0.1022 (0.1462)  loss_objectness: 0.0858 (0.1003)  loss_rpn_box_reg: 0.0278 (0.0340)  time: 0.2855  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [35] Total time: 0:05:36 (0.2741 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:49  model_time: 0.3220 (0.3220)  evaluator_time: 0.0010 (0.0010)  time: 0.3550  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0830 (0.0828)  evaluator_time: 0.0050 (0.0085)  time: 0.1277  data: 0.0357  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0840 (0.0815)  evaluator_time: 0.0030 (0.0078)  time: 0.1202  data: 0.0306  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0740 (0.0808)  evaluator_time: 0.0040 (0.0076)  time: 0.1206  data: 0.0353  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0730 (0.0807)  evaluator_time: 0.0020 (0.0076)  time: 0.1170  data: 0.0337  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1246 s / it)\n",
      "Averaged stats: model_time: 0.0730 (0.0807)  evaluator_time: 0.0020 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [35]  [  0/308]  eta: 0:00:37  lr: 0.000000  loss: 0.1645 (0.1645)  loss_classifier: 0.0590 (0.0590)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0255 (0.0255)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1230  data: 0.0291  max mem: 1751\n",
      "Testing Epoch: [35]  [100/308]  eta: 0:00:29  lr: 0.000000  loss: 0.3202 (0.4804)  loss_classifier: 0.1333 (0.1546)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0571 (0.1017)  loss_rpn_box_reg: 0.0186 (0.0518)  time: 0.1404  data: 0.0386  max mem: 1751\n",
      "Testing Epoch: [35]  [200/308]  eta: 0:00:14  lr: 0.000000  loss: 0.3518 (0.4566)  loss_classifier: 0.1400 (0.1491)  loss_box_reg: 0.1251 (0.1633)  loss_objectness: 0.0682 (0.0952)  loss_rpn_box_reg: 0.0197 (0.0490)  time: 0.1376  data: 0.0318  max mem: 1751\n",
      "Testing Epoch: [35]  [300/308]  eta: 0:00:01  lr: 0.000000  loss: 0.4723 (0.4531)  loss_classifier: 0.1564 (0.1493)  loss_box_reg: 0.1796 (0.1642)  loss_objectness: 0.0797 (0.0922)  loss_rpn_box_reg: 0.0265 (0.0474)  time: 0.1317  data: 0.0373  max mem: 1751\n",
      "Testing Epoch: [35]  [307/308]  eta: 0:00:00  lr: 0.000000  loss: 0.4723 (0.4533)  loss_classifier: 0.1860 (0.1496)  loss_box_reg: 0.1748 (0.1645)  loss_objectness: 0.0727 (0.0923)  loss_rpn_box_reg: 0.0271 (0.0470)  time: 0.1293  data: 0.0353  max mem: 1751\n",
      "Testing Epoch: [35] Total time: 0:00:42 (0.1375 s / it)\n",
      "Training Epoch: [36]  [   0/1229]  eta: 0:05:06  lr: 0.000000  loss: 0.4471 (0.4471)  loss_classifier: 0.1440 (0.1440)  loss_box_reg: 0.1251 (0.1251)  loss_objectness: 0.1165 (0.1165)  loss_rpn_box_reg: 0.0616 (0.0616)  time: 0.2490  data: 0.1260  max mem: 1751\n",
      "Training Epoch: [36]  [  10/1229]  eta: 0:05:29  lr: 0.000000  loss: 0.4307 (0.4355)  loss_classifier: 0.1440 (0.1556)  loss_box_reg: 0.1251 (0.1678)  loss_objectness: 0.0739 (0.0852)  loss_rpn_box_reg: 0.0184 (0.0269)  time: 0.2704  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [36]  [  20/1229]  eta: 0:05:28  lr: 0.000000  loss: 0.3643 (0.4196)  loss_classifier: 0.1377 (0.1490)  loss_box_reg: 0.1129 (0.1542)  loss_objectness: 0.0688 (0.0831)  loss_rpn_box_reg: 0.0170 (0.0334)  time: 0.2732  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [36]  [  30/1229]  eta: 0:05:30  lr: 0.000000  loss: 0.3296 (0.3822)  loss_classifier: 0.1160 (0.1349)  loss_box_reg: 0.1102 (0.1393)  loss_objectness: 0.0641 (0.0771)  loss_rpn_box_reg: 0.0129 (0.0308)  time: 0.2781  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [36]  [  40/1229]  eta: 0:05:29  lr: 0.000000  loss: 0.3178 (0.3926)  loss_classifier: 0.1154 (0.1405)  loss_box_reg: 0.1139 (0.1435)  loss_objectness: 0.0652 (0.0784)  loss_rpn_box_reg: 0.0161 (0.0303)  time: 0.2820  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [36]  [  50/1229]  eta: 0:05:27  lr: 0.000000  loss: 0.3377 (0.3829)  loss_classifier: 0.1301 (0.1385)  loss_box_reg: 0.1262 (0.1378)  loss_objectness: 0.0772 (0.0786)  loss_rpn_box_reg: 0.0170 (0.0280)  time: 0.2809  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [36]  [  60/1229]  eta: 0:05:24  lr: 0.000000  loss: 0.4013 (0.4092)  loss_classifier: 0.1547 (0.1479)  loss_box_reg: 0.1495 (0.1474)  loss_objectness: 0.0772 (0.0848)  loss_rpn_box_reg: 0.0210 (0.0291)  time: 0.2779  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [36]  [  70/1229]  eta: 0:05:21  lr: 0.000000  loss: 0.5453 (0.4260)  loss_classifier: 0.1857 (0.1551)  loss_box_reg: 0.1748 (0.1506)  loss_objectness: 0.0913 (0.0894)  loss_rpn_box_reg: 0.0351 (0.0309)  time: 0.2761  data: 0.1370  max mem: 1751\n",
      "Training Epoch: [36]  [  80/1229]  eta: 0:05:16  lr: 0.000000  loss: 0.4568 (0.4357)  loss_classifier: 0.1550 (0.1575)  loss_box_reg: 0.1503 (0.1532)  loss_objectness: 0.0903 (0.0916)  loss_rpn_box_reg: 0.0290 (0.0334)  time: 0.2694  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [36]  [  90/1229]  eta: 0:05:14  lr: 0.000000  loss: 0.4132 (0.4310)  loss_classifier: 0.1532 (0.1554)  loss_box_reg: 0.1420 (0.1513)  loss_objectness: 0.0699 (0.0918)  loss_rpn_box_reg: 0.0265 (0.0326)  time: 0.2742  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [36]  [ 100/1229]  eta: 0:05:11  lr: 0.000000  loss: 0.4068 (0.4374)  loss_classifier: 0.1451 (0.1574)  loss_box_reg: 0.1335 (0.1563)  loss_objectness: 0.0739 (0.0917)  loss_rpn_box_reg: 0.0177 (0.0320)  time: 0.2805  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [36]  [ 110/1229]  eta: 0:05:09  lr: 0.000000  loss: 0.4371 (0.4468)  loss_classifier: 0.1699 (0.1587)  loss_box_reg: 0.1510 (0.1543)  loss_objectness: 0.0906 (0.0963)  loss_rpn_box_reg: 0.0315 (0.0375)  time: 0.2751  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [36]  [ 120/1229]  eta: 0:05:06  lr: 0.000000  loss: 0.4359 (0.4518)  loss_classifier: 0.1699 (0.1601)  loss_box_reg: 0.1510 (0.1554)  loss_objectness: 0.1016 (0.0973)  loss_rpn_box_reg: 0.0334 (0.0391)  time: 0.2751  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [36]  [ 130/1229]  eta: 0:05:03  lr: 0.000000  loss: 0.3574 (0.4449)  loss_classifier: 0.1146 (0.1578)  loss_box_reg: 0.1027 (0.1513)  loss_objectness: 0.0897 (0.0975)  loss_rpn_box_reg: 0.0165 (0.0382)  time: 0.2727  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [36]  [ 140/1229]  eta: 0:04:59  lr: 0.000000  loss: 0.3407 (0.4415)  loss_classifier: 0.1064 (0.1566)  loss_box_reg: 0.0921 (0.1509)  loss_objectness: 0.0781 (0.0960)  loss_rpn_box_reg: 0.0165 (0.0380)  time: 0.2707  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [36]  [ 150/1229]  eta: 0:04:57  lr: 0.000000  loss: 0.4383 (0.4449)  loss_classifier: 0.1581 (0.1575)  loss_box_reg: 0.1577 (0.1549)  loss_objectness: 0.0751 (0.0952)  loss_rpn_box_reg: 0.0218 (0.0373)  time: 0.2761  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [36]  [ 160/1229]  eta: 0:04:54  lr: 0.000000  loss: 0.4383 (0.4371)  loss_classifier: 0.1409 (0.1546)  loss_box_reg: 0.1234 (0.1507)  loss_objectness: 0.0751 (0.0954)  loss_rpn_box_reg: 0.0189 (0.0364)  time: 0.2751  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [36]  [ 170/1229]  eta: 0:04:51  lr: 0.000000  loss: 0.3776 (0.4411)  loss_classifier: 0.1191 (0.1552)  loss_box_reg: 0.0912 (0.1525)  loss_objectness: 0.0866 (0.0972)  loss_rpn_box_reg: 0.0189 (0.0362)  time: 0.2713  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [36]  [ 180/1229]  eta: 0:04:47  lr: 0.000000  loss: 0.3776 (0.4380)  loss_classifier: 0.1237 (0.1534)  loss_box_reg: 0.1122 (0.1508)  loss_objectness: 0.0850 (0.0967)  loss_rpn_box_reg: 0.0281 (0.0371)  time: 0.2678  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [36]  [ 190/1229]  eta: 0:04:45  lr: 0.000000  loss: 0.2859 (0.4339)  loss_classifier: 0.0914 (0.1520)  loss_box_reg: 0.0757 (0.1494)  loss_objectness: 0.0749 (0.0959)  loss_rpn_box_reg: 0.0190 (0.0367)  time: 0.2687  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [36]  [ 200/1229]  eta: 0:04:43  lr: 0.000000  loss: 0.2955 (0.4353)  loss_classifier: 0.1107 (0.1523)  loss_box_reg: 0.0892 (0.1501)  loss_objectness: 0.0782 (0.0961)  loss_rpn_box_reg: 0.0191 (0.0368)  time: 0.2802  data: 0.1378  max mem: 1751\n",
      "Training Epoch: [36]  [ 210/1229]  eta: 0:04:40  lr: 0.000000  loss: 0.3994 (0.4324)  loss_classifier: 0.1415 (0.1516)  loss_box_reg: 0.1475 (0.1491)  loss_objectness: 0.0868 (0.0957)  loss_rpn_box_reg: 0.0177 (0.0360)  time: 0.2793  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [36]  [ 220/1229]  eta: 0:04:37  lr: 0.000000  loss: 0.3893 (0.4325)  loss_classifier: 0.1385 (0.1519)  loss_box_reg: 0.1136 (0.1489)  loss_objectness: 0.0918 (0.0957)  loss_rpn_box_reg: 0.0155 (0.0359)  time: 0.2706  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [36]  [ 230/1229]  eta: 0:04:34  lr: 0.000000  loss: 0.3893 (0.4366)  loss_classifier: 0.1627 (0.1542)  loss_box_reg: 0.1332 (0.1498)  loss_objectness: 0.0968 (0.0968)  loss_rpn_box_reg: 0.0214 (0.0358)  time: 0.2691  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [36]  [ 240/1229]  eta: 0:04:31  lr: 0.000000  loss: 0.3850 (0.4356)  loss_classifier: 0.1517 (0.1538)  loss_box_reg: 0.0950 (0.1477)  loss_objectness: 0.1017 (0.0985)  loss_rpn_box_reg: 0.0203 (0.0356)  time: 0.2717  data: 0.1352  max mem: 1751\n",
      "Training Epoch: [36]  [ 250/1229]  eta: 0:04:28  lr: 0.000000  loss: 0.2987 (0.4343)  loss_classifier: 0.1161 (0.1529)  loss_box_reg: 0.0748 (0.1476)  loss_objectness: 0.1034 (0.0989)  loss_rpn_box_reg: 0.0137 (0.0350)  time: 0.2738  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [36]  [ 260/1229]  eta: 0:04:26  lr: 0.000000  loss: 0.3043 (0.4303)  loss_classifier: 0.0951 (0.1513)  loss_box_reg: 0.0854 (0.1460)  loss_objectness: 0.0752 (0.0979)  loss_rpn_box_reg: 0.0152 (0.0351)  time: 0.2767  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [36]  [ 270/1229]  eta: 0:04:22  lr: 0.000000  loss: 0.3350 (0.4292)  loss_classifier: 0.1284 (0.1513)  loss_box_reg: 0.0934 (0.1460)  loss_objectness: 0.0778 (0.0974)  loss_rpn_box_reg: 0.0184 (0.0345)  time: 0.2709  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [36]  [ 280/1229]  eta: 0:04:20  lr: 0.000000  loss: 0.3678 (0.4278)  loss_classifier: 0.1383 (0.1507)  loss_box_reg: 0.1306 (0.1458)  loss_objectness: 0.0784 (0.0967)  loss_rpn_box_reg: 0.0188 (0.0345)  time: 0.2712  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [36]  [ 290/1229]  eta: 0:04:17  lr: 0.000000  loss: 0.3776 (0.4284)  loss_classifier: 0.1395 (0.1510)  loss_box_reg: 0.1362 (0.1467)  loss_objectness: 0.0740 (0.0964)  loss_rpn_box_reg: 0.0280 (0.0343)  time: 0.2730  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [36]  [ 300/1229]  eta: 0:04:14  lr: 0.000000  loss: 0.4029 (0.4291)  loss_classifier: 0.1527 (0.1510)  loss_box_reg: 0.1242 (0.1471)  loss_objectness: 0.0618 (0.0961)  loss_rpn_box_reg: 0.0204 (0.0349)  time: 0.2719  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [36]  [ 310/1229]  eta: 0:04:12  lr: 0.000000  loss: 0.4015 (0.4295)  loss_classifier: 0.1515 (0.1514)  loss_box_reg: 0.1172 (0.1478)  loss_objectness: 0.0618 (0.0956)  loss_rpn_box_reg: 0.0172 (0.0347)  time: 0.2774  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [36]  [ 320/1229]  eta: 0:04:09  lr: 0.000000  loss: 0.4623 (0.4322)  loss_classifier: 0.1608 (0.1525)  loss_box_reg: 0.1344 (0.1484)  loss_objectness: 0.0882 (0.0963)  loss_rpn_box_reg: 0.0234 (0.0350)  time: 0.2730  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [36]  [ 330/1229]  eta: 0:04:06  lr: 0.000000  loss: 0.4619 (0.4316)  loss_classifier: 0.1401 (0.1521)  loss_box_reg: 0.1138 (0.1478)  loss_objectness: 0.1154 (0.0968)  loss_rpn_box_reg: 0.0255 (0.0349)  time: 0.2694  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [36]  [ 340/1229]  eta: 0:04:03  lr: 0.000000  loss: 0.3320 (0.4306)  loss_classifier: 0.1299 (0.1521)  loss_box_reg: 0.0927 (0.1474)  loss_objectness: 0.0657 (0.0963)  loss_rpn_box_reg: 0.0190 (0.0349)  time: 0.2694  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [36]  [ 350/1229]  eta: 0:04:00  lr: 0.000000  loss: 0.3085 (0.4296)  loss_classifier: 0.1373 (0.1517)  loss_box_reg: 0.0875 (0.1466)  loss_objectness: 0.0619 (0.0966)  loss_rpn_box_reg: 0.0201 (0.0348)  time: 0.2715  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [36]  [ 360/1229]  eta: 0:03:57  lr: 0.000000  loss: 0.3365 (0.4279)  loss_classifier: 0.1193 (0.1512)  loss_box_reg: 0.0875 (0.1458)  loss_objectness: 0.0779 (0.0965)  loss_rpn_box_reg: 0.0205 (0.0344)  time: 0.2721  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [36]  [ 370/1229]  eta: 0:03:55  lr: 0.000000  loss: 0.3746 (0.4286)  loss_classifier: 0.1469 (0.1515)  loss_box_reg: 0.1112 (0.1462)  loss_objectness: 0.0750 (0.0963)  loss_rpn_box_reg: 0.0231 (0.0347)  time: 0.2719  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [36]  [ 380/1229]  eta: 0:03:52  lr: 0.000000  loss: 0.4810 (0.4317)  loss_classifier: 0.1495 (0.1527)  loss_box_reg: 0.1592 (0.1478)  loss_objectness: 0.0838 (0.0964)  loss_rpn_box_reg: 0.0251 (0.0348)  time: 0.2781  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [36]  [ 390/1229]  eta: 0:03:49  lr: 0.000000  loss: 0.3764 (0.4319)  loss_classifier: 0.1449 (0.1524)  loss_box_reg: 0.1415 (0.1474)  loss_objectness: 0.0914 (0.0966)  loss_rpn_box_reg: 0.0277 (0.0354)  time: 0.2800  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [36]  [ 400/1229]  eta: 0:03:47  lr: 0.000000  loss: 0.3614 (0.4301)  loss_classifier: 0.1124 (0.1519)  loss_box_reg: 0.0937 (0.1462)  loss_objectness: 0.0912 (0.0969)  loss_rpn_box_reg: 0.0222 (0.0350)  time: 0.2725  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [36]  [ 410/1229]  eta: 0:03:44  lr: 0.000000  loss: 0.4003 (0.4329)  loss_classifier: 0.1393 (0.1532)  loss_box_reg: 0.1235 (0.1478)  loss_objectness: 0.0959 (0.0972)  loss_rpn_box_reg: 0.0222 (0.0347)  time: 0.2707  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [36]  [ 420/1229]  eta: 0:03:41  lr: 0.000000  loss: 0.4089 (0.4321)  loss_classifier: 0.1420 (0.1529)  loss_box_reg: 0.1401 (0.1476)  loss_objectness: 0.0865 (0.0968)  loss_rpn_box_reg: 0.0239 (0.0348)  time: 0.2748  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [36]  [ 430/1229]  eta: 0:03:38  lr: 0.000000  loss: 0.3650 (0.4317)  loss_classifier: 0.1302 (0.1529)  loss_box_reg: 0.1049 (0.1473)  loss_objectness: 0.0865 (0.0971)  loss_rpn_box_reg: 0.0166 (0.0344)  time: 0.2697  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [36]  [ 440/1229]  eta: 0:03:35  lr: 0.000000  loss: 0.3829 (0.4315)  loss_classifier: 0.1287 (0.1530)  loss_box_reg: 0.1207 (0.1474)  loss_objectness: 0.1001 (0.0971)  loss_rpn_box_reg: 0.0164 (0.0340)  time: 0.2694  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [36]  [ 450/1229]  eta: 0:03:33  lr: 0.000000  loss: 0.3169 (0.4300)  loss_classifier: 0.1177 (0.1526)  loss_box_reg: 0.1086 (0.1470)  loss_objectness: 0.0639 (0.0967)  loss_rpn_box_reg: 0.0149 (0.0337)  time: 0.2761  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [36]  [ 460/1229]  eta: 0:03:30  lr: 0.000000  loss: 0.3275 (0.4301)  loss_classifier: 0.1183 (0.1525)  loss_box_reg: 0.1086 (0.1470)  loss_objectness: 0.0694 (0.0966)  loss_rpn_box_reg: 0.0211 (0.0339)  time: 0.2756  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [36]  [ 470/1229]  eta: 0:03:27  lr: 0.000000  loss: 0.3968 (0.4303)  loss_classifier: 0.1349 (0.1526)  loss_box_reg: 0.1617 (0.1472)  loss_objectness: 0.0826 (0.0966)  loss_rpn_box_reg: 0.0235 (0.0339)  time: 0.2706  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [36]  [ 480/1229]  eta: 0:03:24  lr: 0.000000  loss: 0.4727 (0.4311)  loss_classifier: 0.1516 (0.1529)  loss_box_reg: 0.1635 (0.1475)  loss_objectness: 0.0997 (0.0970)  loss_rpn_box_reg: 0.0200 (0.0337)  time: 0.2705  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [36]  [ 490/1229]  eta: 0:03:22  lr: 0.000000  loss: 0.4038 (0.4302)  loss_classifier: 0.1313 (0.1527)  loss_box_reg: 0.1198 (0.1471)  loss_objectness: 0.0997 (0.0968)  loss_rpn_box_reg: 0.0174 (0.0335)  time: 0.2717  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [36]  [ 500/1229]  eta: 0:03:19  lr: 0.000000  loss: 0.3199 (0.4289)  loss_classifier: 0.1081 (0.1523)  loss_box_reg: 0.0917 (0.1463)  loss_objectness: 0.0878 (0.0970)  loss_rpn_box_reg: 0.0149 (0.0334)  time: 0.2748  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [36]  [ 510/1229]  eta: 0:03:16  lr: 0.000000  loss: 0.3199 (0.4284)  loss_classifier: 0.1256 (0.1523)  loss_box_reg: 0.0953 (0.1463)  loss_objectness: 0.0818 (0.0968)  loss_rpn_box_reg: 0.0132 (0.0331)  time: 0.2750  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [36]  [ 520/1229]  eta: 0:03:14  lr: 0.000000  loss: 0.4166 (0.4284)  loss_classifier: 0.1527 (0.1523)  loss_box_reg: 0.1168 (0.1459)  loss_objectness: 0.0818 (0.0970)  loss_rpn_box_reg: 0.0244 (0.0331)  time: 0.2711  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [36]  [ 530/1229]  eta: 0:03:11  lr: 0.000000  loss: 0.4070 (0.4300)  loss_classifier: 0.1505 (0.1530)  loss_box_reg: 0.1116 (0.1463)  loss_objectness: 0.0995 (0.0974)  loss_rpn_box_reg: 0.0301 (0.0334)  time: 0.2767  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [36]  [ 540/1229]  eta: 0:03:08  lr: 0.000000  loss: 0.3873 (0.4299)  loss_classifier: 0.1309 (0.1528)  loss_box_reg: 0.1193 (0.1462)  loss_objectness: 0.0887 (0.0974)  loss_rpn_box_reg: 0.0280 (0.0336)  time: 0.2769  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [36]  [ 550/1229]  eta: 0:03:05  lr: 0.000000  loss: 0.3741 (0.4307)  loss_classifier: 0.1309 (0.1530)  loss_box_reg: 0.1246 (0.1469)  loss_objectness: 0.0698 (0.0971)  loss_rpn_box_reg: 0.0223 (0.0337)  time: 0.2717  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [36]  [ 560/1229]  eta: 0:03:03  lr: 0.000000  loss: 0.3075 (0.4291)  loss_classifier: 0.1250 (0.1524)  loss_box_reg: 0.1019 (0.1460)  loss_objectness: 0.0662 (0.0968)  loss_rpn_box_reg: 0.0204 (0.0339)  time: 0.2767  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [36]  [ 570/1229]  eta: 0:03:00  lr: 0.000000  loss: 0.2935 (0.4303)  loss_classifier: 0.1250 (0.1529)  loss_box_reg: 0.0950 (0.1465)  loss_objectness: 0.0778 (0.0971)  loss_rpn_box_reg: 0.0226 (0.0339)  time: 0.2769  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [36]  [ 580/1229]  eta: 0:02:57  lr: 0.000000  loss: 0.3565 (0.4290)  loss_classifier: 0.1298 (0.1525)  loss_box_reg: 0.1005 (0.1459)  loss_objectness: 0.0783 (0.0969)  loss_rpn_box_reg: 0.0184 (0.0337)  time: 0.2670  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [36]  [ 590/1229]  eta: 0:02:54  lr: 0.000000  loss: 0.4090 (0.4311)  loss_classifier: 0.1466 (0.1534)  loss_box_reg: 0.1313 (0.1468)  loss_objectness: 0.0803 (0.0970)  loss_rpn_box_reg: 0.0184 (0.0340)  time: 0.2646  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [36]  [ 600/1229]  eta: 0:02:52  lr: 0.000000  loss: 0.4914 (0.4305)  loss_classifier: 0.1466 (0.1529)  loss_box_reg: 0.1335 (0.1464)  loss_objectness: 0.0913 (0.0971)  loss_rpn_box_reg: 0.0232 (0.0340)  time: 0.2686  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [36]  [ 610/1229]  eta: 0:02:49  lr: 0.000000  loss: 0.4203 (0.4308)  loss_classifier: 0.1261 (0.1529)  loss_box_reg: 0.1443 (0.1467)  loss_objectness: 0.0863 (0.0971)  loss_rpn_box_reg: 0.0232 (0.0341)  time: 0.2707  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [36]  [ 620/1229]  eta: 0:02:46  lr: 0.000000  loss: 0.4203 (0.4304)  loss_classifier: 0.1311 (0.1527)  loss_box_reg: 0.1549 (0.1463)  loss_objectness: 0.0860 (0.0970)  loss_rpn_box_reg: 0.0296 (0.0344)  time: 0.2697  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [36]  [ 630/1229]  eta: 0:02:43  lr: 0.000000  loss: 0.4156 (0.4308)  loss_classifier: 0.1276 (0.1527)  loss_box_reg: 0.1287 (0.1464)  loss_objectness: 0.0997 (0.0972)  loss_rpn_box_reg: 0.0288 (0.0345)  time: 0.2695  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [36]  [ 640/1229]  eta: 0:02:40  lr: 0.000000  loss: 0.4384 (0.4314)  loss_classifier: 0.1377 (0.1528)  loss_box_reg: 0.1287 (0.1460)  loss_objectness: 0.1123 (0.0980)  loss_rpn_box_reg: 0.0264 (0.0347)  time: 0.2725  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [36]  [ 650/1229]  eta: 0:02:38  lr: 0.000000  loss: 0.3733 (0.4305)  loss_classifier: 0.1190 (0.1526)  loss_box_reg: 0.0909 (0.1454)  loss_objectness: 0.1001 (0.0979)  loss_rpn_box_reg: 0.0252 (0.0345)  time: 0.2751  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [36]  [ 660/1229]  eta: 0:02:35  lr: 0.000000  loss: 0.2892 (0.4293)  loss_classifier: 0.1052 (0.1522)  loss_box_reg: 0.0651 (0.1445)  loss_objectness: 0.0971 (0.0982)  loss_rpn_box_reg: 0.0181 (0.0345)  time: 0.2793  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [36]  [ 670/1229]  eta: 0:02:32  lr: 0.000000  loss: 0.3436 (0.4297)  loss_classifier: 0.1052 (0.1522)  loss_box_reg: 0.0763 (0.1444)  loss_objectness: 0.0901 (0.0982)  loss_rpn_box_reg: 0.0244 (0.0348)  time: 0.2752  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [36]  [ 680/1229]  eta: 0:02:30  lr: 0.000000  loss: 0.4402 (0.4304)  loss_classifier: 0.1666 (0.1525)  loss_box_reg: 0.1469 (0.1447)  loss_objectness: 0.0901 (0.0983)  loss_rpn_box_reg: 0.0275 (0.0349)  time: 0.2722  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [36]  [ 690/1229]  eta: 0:02:27  lr: 0.000000  loss: 0.3470 (0.4303)  loss_classifier: 0.1259 (0.1524)  loss_box_reg: 0.1458 (0.1448)  loss_objectness: 0.0732 (0.0982)  loss_rpn_box_reg: 0.0186 (0.0348)  time: 0.2754  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [36]  [ 700/1229]  eta: 0:02:24  lr: 0.000000  loss: 0.3507 (0.4290)  loss_classifier: 0.1084 (0.1518)  loss_box_reg: 0.1090 (0.1443)  loss_objectness: 0.0730 (0.0980)  loss_rpn_box_reg: 0.0169 (0.0350)  time: 0.2735  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [36]  [ 710/1229]  eta: 0:02:21  lr: 0.000000  loss: 0.3541 (0.4288)  loss_classifier: 0.1289 (0.1517)  loss_box_reg: 0.1125 (0.1443)  loss_objectness: 0.0615 (0.0977)  loss_rpn_box_reg: 0.0223 (0.0351)  time: 0.2728  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [36]  [ 720/1229]  eta: 0:02:19  lr: 0.000000  loss: 0.3706 (0.4286)  loss_classifier: 0.1333 (0.1514)  loss_box_reg: 0.1267 (0.1442)  loss_objectness: 0.0738 (0.0978)  loss_rpn_box_reg: 0.0170 (0.0351)  time: 0.2700  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [36]  [ 730/1229]  eta: 0:02:16  lr: 0.000000  loss: 0.3356 (0.4285)  loss_classifier: 0.1209 (0.1516)  loss_box_reg: 0.1267 (0.1444)  loss_objectness: 0.0743 (0.0976)  loss_rpn_box_reg: 0.0132 (0.0350)  time: 0.2704  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [36]  [ 740/1229]  eta: 0:02:13  lr: 0.000000  loss: 0.3779 (0.4296)  loss_classifier: 0.1360 (0.1519)  loss_box_reg: 0.1306 (0.1450)  loss_objectness: 0.0658 (0.0977)  loss_rpn_box_reg: 0.0250 (0.0350)  time: 0.2775  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [36]  [ 750/1229]  eta: 0:02:10  lr: 0.000000  loss: 0.4946 (0.4308)  loss_classifier: 0.1570 (0.1522)  loss_box_reg: 0.1311 (0.1451)  loss_objectness: 0.1298 (0.0985)  loss_rpn_box_reg: 0.0293 (0.0350)  time: 0.2752  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [36]  [ 760/1229]  eta: 0:02:08  lr: 0.000000  loss: 0.5122 (0.4309)  loss_classifier: 0.1874 (0.1523)  loss_box_reg: 0.1302 (0.1449)  loss_objectness: 0.1313 (0.0985)  loss_rpn_box_reg: 0.0229 (0.0351)  time: 0.2723  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [36]  [ 770/1229]  eta: 0:02:05  lr: 0.000000  loss: 0.4827 (0.4320)  loss_classifier: 0.1777 (0.1528)  loss_box_reg: 0.1265 (0.1454)  loss_objectness: 0.1119 (0.0987)  loss_rpn_box_reg: 0.0263 (0.0351)  time: 0.2767  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [36]  [ 780/1229]  eta: 0:02:02  lr: 0.000000  loss: 0.3951 (0.4311)  loss_classifier: 0.1395 (0.1525)  loss_box_reg: 0.1160 (0.1450)  loss_objectness: 0.1071 (0.0987)  loss_rpn_box_reg: 0.0186 (0.0349)  time: 0.2729  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [36]  [ 790/1229]  eta: 0:02:00  lr: 0.000000  loss: 0.3407 (0.4308)  loss_classifier: 0.1147 (0.1523)  loss_box_reg: 0.1036 (0.1447)  loss_objectness: 0.0847 (0.0987)  loss_rpn_box_reg: 0.0124 (0.0350)  time: 0.2700  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [36]  [ 800/1229]  eta: 0:01:57  lr: 0.000000  loss: 0.3031 (0.4311)  loss_classifier: 0.1172 (0.1525)  loss_box_reg: 0.0969 (0.1448)  loss_objectness: 0.0652 (0.0988)  loss_rpn_box_reg: 0.0233 (0.0350)  time: 0.2697  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [36]  [ 810/1229]  eta: 0:01:54  lr: 0.000000  loss: 0.4044 (0.4312)  loss_classifier: 0.1377 (0.1525)  loss_box_reg: 0.1111 (0.1449)  loss_objectness: 0.0893 (0.0989)  loss_rpn_box_reg: 0.0240 (0.0349)  time: 0.2708  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [36]  [ 820/1229]  eta: 0:01:51  lr: 0.000000  loss: 0.3155 (0.4305)  loss_classifier: 0.1190 (0.1522)  loss_box_reg: 0.1082 (0.1446)  loss_objectness: 0.0754 (0.0988)  loss_rpn_box_reg: 0.0171 (0.0349)  time: 0.2670  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [36]  [ 830/1229]  eta: 0:01:49  lr: 0.000000  loss: 0.3675 (0.4309)  loss_classifier: 0.1501 (0.1525)  loss_box_reg: 0.1180 (0.1448)  loss_objectness: 0.0658 (0.0989)  loss_rpn_box_reg: 0.0183 (0.0348)  time: 0.2748  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [36]  [ 840/1229]  eta: 0:01:46  lr: 0.000000  loss: 0.4316 (0.4311)  loss_classifier: 0.1613 (0.1525)  loss_box_reg: 0.1393 (0.1450)  loss_objectness: 0.0942 (0.0988)  loss_rpn_box_reg: 0.0203 (0.0348)  time: 0.2810  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [36]  [ 850/1229]  eta: 0:01:43  lr: 0.000000  loss: 0.3829 (0.4308)  loss_classifier: 0.1304 (0.1523)  loss_box_reg: 0.0973 (0.1446)  loss_objectness: 0.0997 (0.0990)  loss_rpn_box_reg: 0.0173 (0.0349)  time: 0.2745  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [36]  [ 860/1229]  eta: 0:01:40  lr: 0.000000  loss: 0.3905 (0.4305)  loss_classifier: 0.1444 (0.1523)  loss_box_reg: 0.1201 (0.1445)  loss_objectness: 0.1076 (0.0989)  loss_rpn_box_reg: 0.0266 (0.0348)  time: 0.2743  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [36]  [ 870/1229]  eta: 0:01:38  lr: 0.000000  loss: 0.4450 (0.4318)  loss_classifier: 0.1647 (0.1527)  loss_box_reg: 0.1334 (0.1449)  loss_objectness: 0.1076 (0.0994)  loss_rpn_box_reg: 0.0266 (0.0347)  time: 0.2707  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [36]  [ 880/1229]  eta: 0:01:35  lr: 0.000000  loss: 0.3125 (0.4305)  loss_classifier: 0.1151 (0.1523)  loss_box_reg: 0.1169 (0.1445)  loss_objectness: 0.0721 (0.0990)  loss_rpn_box_reg: 0.0200 (0.0346)  time: 0.2722  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [36]  [ 890/1229]  eta: 0:01:32  lr: 0.000000  loss: 0.2912 (0.4296)  loss_classifier: 0.0996 (0.1520)  loss_box_reg: 0.0911 (0.1443)  loss_objectness: 0.0721 (0.0989)  loss_rpn_box_reg: 0.0191 (0.0344)  time: 0.2745  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [36]  [ 900/1229]  eta: 0:01:29  lr: 0.000000  loss: 0.3769 (0.4303)  loss_classifier: 0.1549 (0.1523)  loss_box_reg: 0.0911 (0.1445)  loss_objectness: 0.0898 (0.0991)  loss_rpn_box_reg: 0.0247 (0.0344)  time: 0.2712  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [36]  [ 910/1229]  eta: 0:01:27  lr: 0.000000  loss: 0.3769 (0.4292)  loss_classifier: 0.1277 (0.1519)  loss_box_reg: 0.0826 (0.1440)  loss_objectness: 0.0915 (0.0989)  loss_rpn_box_reg: 0.0254 (0.0343)  time: 0.2726  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [36]  [ 920/1229]  eta: 0:01:24  lr: 0.000000  loss: 0.3476 (0.4294)  loss_classifier: 0.1191 (0.1520)  loss_box_reg: 0.0876 (0.1439)  loss_objectness: 0.1030 (0.0992)  loss_rpn_box_reg: 0.0240 (0.0342)  time: 0.2744  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [36]  [ 930/1229]  eta: 0:01:21  lr: 0.000000  loss: 0.3503 (0.4290)  loss_classifier: 0.1361 (0.1519)  loss_box_reg: 0.0969 (0.1436)  loss_objectness: 0.1030 (0.0993)  loss_rpn_box_reg: 0.0227 (0.0341)  time: 0.2681  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [36]  [ 940/1229]  eta: 0:01:18  lr: 0.000000  loss: 0.2739 (0.4282)  loss_classifier: 0.1050 (0.1517)  loss_box_reg: 0.0969 (0.1434)  loss_objectness: 0.0641 (0.0990)  loss_rpn_box_reg: 0.0151 (0.0340)  time: 0.2669  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [36]  [ 950/1229]  eta: 0:01:16  lr: 0.000000  loss: 0.3976 (0.4281)  loss_classifier: 0.1142 (0.1517)  loss_box_reg: 0.0963 (0.1433)  loss_objectness: 0.0760 (0.0990)  loss_rpn_box_reg: 0.0221 (0.0340)  time: 0.2734  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [36]  [ 960/1229]  eta: 0:01:13  lr: 0.000000  loss: 0.4122 (0.4284)  loss_classifier: 0.1517 (0.1518)  loss_box_reg: 0.1147 (0.1434)  loss_objectness: 0.0927 (0.0991)  loss_rpn_box_reg: 0.0282 (0.0340)  time: 0.2732  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [36]  [ 970/1229]  eta: 0:01:10  lr: 0.000000  loss: 0.3605 (0.4282)  loss_classifier: 0.1405 (0.1517)  loss_box_reg: 0.0839 (0.1430)  loss_objectness: 0.0788 (0.0994)  loss_rpn_box_reg: 0.0129 (0.0341)  time: 0.2687  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [36]  [ 980/1229]  eta: 0:01:08  lr: 0.000000  loss: 0.3605 (0.4273)  loss_classifier: 0.1350 (0.1514)  loss_box_reg: 0.0751 (0.1426)  loss_objectness: 0.0788 (0.0992)  loss_rpn_box_reg: 0.0141 (0.0340)  time: 0.2747  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [36]  [ 990/1229]  eta: 0:01:05  lr: 0.000000  loss: 0.2941 (0.4258)  loss_classifier: 0.1014 (0.1509)  loss_box_reg: 0.0612 (0.1418)  loss_objectness: 0.0788 (0.0992)  loss_rpn_box_reg: 0.0141 (0.0339)  time: 0.2779  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [36]  [1000/1229]  eta: 0:01:02  lr: 0.000000  loss: 0.3325 (0.4265)  loss_classifier: 0.1221 (0.1511)  loss_box_reg: 0.0817 (0.1421)  loss_objectness: 0.0780 (0.0994)  loss_rpn_box_reg: 0.0178 (0.0339)  time: 0.2768  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [36]  [1010/1229]  eta: 0:00:59  lr: 0.000000  loss: 0.5036 (0.4274)  loss_classifier: 0.1791 (0.1513)  loss_box_reg: 0.1711 (0.1426)  loss_objectness: 0.0982 (0.0995)  loss_rpn_box_reg: 0.0286 (0.0340)  time: 0.2725  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [36]  [1020/1229]  eta: 0:00:57  lr: 0.000000  loss: 0.4844 (0.4279)  loss_classifier: 0.1791 (0.1516)  loss_box_reg: 0.1711 (0.1428)  loss_objectness: 0.0975 (0.0996)  loss_rpn_box_reg: 0.0286 (0.0339)  time: 0.2691  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [36]  [1030/1229]  eta: 0:00:54  lr: 0.000000  loss: 0.3332 (0.4268)  loss_classifier: 0.1348 (0.1513)  loss_box_reg: 0.0930 (0.1424)  loss_objectness: 0.0745 (0.0994)  loss_rpn_box_reg: 0.0150 (0.0337)  time: 0.2683  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [36]  [1040/1229]  eta: 0:00:51  lr: 0.000000  loss: 0.3657 (0.4282)  loss_classifier: 0.1462 (0.1518)  loss_box_reg: 0.1152 (0.1429)  loss_objectness: 0.0752 (0.0997)  loss_rpn_box_reg: 0.0150 (0.0338)  time: 0.2678  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [36]  [1050/1229]  eta: 0:00:48  lr: 0.000000  loss: 0.5099 (0.4286)  loss_classifier: 0.1691 (0.1518)  loss_box_reg: 0.1938 (0.1431)  loss_objectness: 0.1164 (0.0998)  loss_rpn_box_reg: 0.0285 (0.0339)  time: 0.2706  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [36]  [1060/1229]  eta: 0:00:46  lr: 0.000000  loss: 0.4749 (0.4289)  loss_classifier: 0.1615 (0.1519)  loss_box_reg: 0.1505 (0.1433)  loss_objectness: 0.1015 (0.0998)  loss_rpn_box_reg: 0.0270 (0.0339)  time: 0.2743  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [36]  [1070/1229]  eta: 0:00:43  lr: 0.000000  loss: 0.5520 (0.4303)  loss_classifier: 0.1880 (0.1524)  loss_box_reg: 0.1641 (0.1439)  loss_objectness: 0.1021 (0.0999)  loss_rpn_box_reg: 0.0270 (0.0341)  time: 0.2791  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [36]  [1080/1229]  eta: 0:00:40  lr: 0.000000  loss: 0.3859 (0.4303)  loss_classifier: 0.1448 (0.1524)  loss_box_reg: 0.1281 (0.1439)  loss_objectness: 0.1026 (0.0999)  loss_rpn_box_reg: 0.0257 (0.0340)  time: 0.2748  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [36]  [1090/1229]  eta: 0:00:37  lr: 0.000000  loss: 0.3859 (0.4305)  loss_classifier: 0.1371 (0.1525)  loss_box_reg: 0.1281 (0.1440)  loss_objectness: 0.0957 (0.0999)  loss_rpn_box_reg: 0.0176 (0.0340)  time: 0.2713  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [36]  [1100/1229]  eta: 0:00:35  lr: 0.000000  loss: 0.4444 (0.4304)  loss_classifier: 0.1603 (0.1525)  loss_box_reg: 0.1288 (0.1441)  loss_objectness: 0.0944 (0.0998)  loss_rpn_box_reg: 0.0171 (0.0339)  time: 0.2776  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [36]  [1110/1229]  eta: 0:00:32  lr: 0.000000  loss: 0.4102 (0.4302)  loss_classifier: 0.1592 (0.1526)  loss_box_reg: 0.1335 (0.1439)  loss_objectness: 0.0947 (0.0999)  loss_rpn_box_reg: 0.0161 (0.0338)  time: 0.2793  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [36]  [1120/1229]  eta: 0:00:29  lr: 0.000000  loss: 0.4102 (0.4303)  loss_classifier: 0.1484 (0.1527)  loss_box_reg: 0.1293 (0.1442)  loss_objectness: 0.0767 (0.0997)  loss_rpn_box_reg: 0.0139 (0.0338)  time: 0.2774  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [36]  [1130/1229]  eta: 0:00:27  lr: 0.000000  loss: 0.3654 (0.4310)  loss_classifier: 0.1455 (0.1529)  loss_box_reg: 0.1252 (0.1444)  loss_objectness: 0.0767 (0.0998)  loss_rpn_box_reg: 0.0179 (0.0339)  time: 0.2738  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [36]  [1140/1229]  eta: 0:00:24  lr: 0.000000  loss: 0.4555 (0.4311)  loss_classifier: 0.1492 (0.1530)  loss_box_reg: 0.1327 (0.1444)  loss_objectness: 0.0932 (0.0998)  loss_rpn_box_reg: 0.0189 (0.0338)  time: 0.2733  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [36]  [1150/1229]  eta: 0:00:21  lr: 0.000000  loss: 0.4555 (0.4320)  loss_classifier: 0.1738 (0.1534)  loss_box_reg: 0.1556 (0.1451)  loss_objectness: 0.0932 (0.0997)  loss_rpn_box_reg: 0.0189 (0.0339)  time: 0.2751  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [36]  [1160/1229]  eta: 0:00:18  lr: 0.000000  loss: 0.3615 (0.4317)  loss_classifier: 0.1361 (0.1532)  loss_box_reg: 0.1384 (0.1449)  loss_objectness: 0.0932 (0.0996)  loss_rpn_box_reg: 0.0188 (0.0338)  time: 0.2748  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [36]  [1170/1229]  eta: 0:00:16  lr: 0.000000  loss: 0.3597 (0.4320)  loss_classifier: 0.1361 (0.1534)  loss_box_reg: 0.1256 (0.1452)  loss_objectness: 0.0705 (0.0996)  loss_rpn_box_reg: 0.0160 (0.0338)  time: 0.2790  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [36]  [1180/1229]  eta: 0:00:13  lr: 0.000000  loss: 0.3966 (0.4320)  loss_classifier: 0.1428 (0.1534)  loss_box_reg: 0.1243 (0.1452)  loss_objectness: 0.0747 (0.0996)  loss_rpn_box_reg: 0.0262 (0.0339)  time: 0.2804  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [36]  [1190/1229]  eta: 0:00:10  lr: 0.000000  loss: 0.3966 (0.4324)  loss_classifier: 0.1428 (0.1536)  loss_box_reg: 0.1195 (0.1454)  loss_objectness: 0.0891 (0.0996)  loss_rpn_box_reg: 0.0319 (0.0339)  time: 0.2718  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [36]  [1200/1229]  eta: 0:00:07  lr: 0.000000  loss: 0.3313 (0.4322)  loss_classifier: 0.1191 (0.1534)  loss_box_reg: 0.1039 (0.1451)  loss_objectness: 0.1022 (0.0997)  loss_rpn_box_reg: 0.0280 (0.0339)  time: 0.2705  data: 0.1313  max mem: 1751\n",
      "Training Epoch: [36]  [1210/1229]  eta: 0:00:05  lr: 0.000000  loss: 0.4501 (0.4331)  loss_classifier: 0.1523 (0.1538)  loss_box_reg: 0.0972 (0.1454)  loss_objectness: 0.1022 (0.0999)  loss_rpn_box_reg: 0.0259 (0.0340)  time: 0.2813  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [36]  [1220/1229]  eta: 0:00:02  lr: 0.000000  loss: 0.4582 (0.4326)  loss_classifier: 0.1565 (0.1537)  loss_box_reg: 0.1260 (0.1452)  loss_objectness: 0.0978 (0.0999)  loss_rpn_box_reg: 0.0248 (0.0339)  time: 0.2775  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [36]  [1228/1229]  eta: 0:00:00  lr: 0.000000  loss: 0.3824 (0.4323)  loss_classifier: 0.1398 (0.1535)  loss_box_reg: 0.1161 (0.1451)  loss_objectness: 0.0748 (0.0997)  loss_rpn_box_reg: 0.0199 (0.0339)  time: 0.2718  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [36] Total time: 0:05:36 (0.2736 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:56  model_time: 0.3430 (0.3430)  evaluator_time: 0.0020 (0.0020)  time: 0.3770  data: 0.0300  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0780 (0.0830)  evaluator_time: 0.0040 (0.0085)  time: 0.1275  data: 0.0358  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0830 (0.0816)  evaluator_time: 0.0030 (0.0077)  time: 0.1208  data: 0.0314  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0770 (0.0808)  evaluator_time: 0.0040 (0.0076)  time: 0.1200  data: 0.0351  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0750 (0.0806)  evaluator_time: 0.0020 (0.0075)  time: 0.1222  data: 0.0388  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1247 s / it)\n",
      "Averaged stats: model_time: 0.0750 (0.0806)  evaluator_time: 0.0020 (0.0075)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [36]  [  0/308]  eta: 0:00:39  lr: 0.000000  loss: 0.1635 (0.1635)  loss_classifier: 0.0591 (0.0591)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0246 (0.0246)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1270  data: 0.0310  max mem: 1751\n",
      "Testing Epoch: [36]  [100/308]  eta: 0:00:28  lr: 0.000000  loss: 0.3158 (0.4807)  loss_classifier: 0.1340 (0.1546)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0563 (0.1019)  loss_rpn_box_reg: 0.0186 (0.0519)  time: 0.1409  data: 0.0386  max mem: 1751\n",
      "Testing Epoch: [36]  [200/308]  eta: 0:00:14  lr: 0.000000  loss: 0.3570 (0.4567)  loss_classifier: 0.1393 (0.1491)  loss_box_reg: 0.1251 (0.1633)  loss_objectness: 0.0671 (0.0953)  loss_rpn_box_reg: 0.0197 (0.0491)  time: 0.1392  data: 0.0324  max mem: 1751\n",
      "Testing Epoch: [36]  [300/308]  eta: 0:00:01  lr: 0.000000  loss: 0.4624 (0.4537)  loss_classifier: 0.1573 (0.1493)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0787 (0.0928)  loss_rpn_box_reg: 0.0265 (0.0475)  time: 0.1328  data: 0.0373  max mem: 1751\n",
      "Testing Epoch: [36]  [307/308]  eta: 0:00:00  lr: 0.000000  loss: 0.4624 (0.4539)  loss_classifier: 0.1860 (0.1495)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0763 (0.0929)  loss_rpn_box_reg: 0.0271 (0.0470)  time: 0.1304  data: 0.0353  max mem: 1751\n",
      "Testing Epoch: [36] Total time: 0:00:42 (0.1371 s / it)\n",
      "Training Epoch: [37]  [   0/1229]  eta: 0:04:59  lr: 0.000000  loss: 0.5102 (0.5102)  loss_classifier: 0.1718 (0.1718)  loss_box_reg: 0.1854 (0.1854)  loss_objectness: 0.1221 (0.1221)  loss_rpn_box_reg: 0.0310 (0.0310)  time: 0.2440  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [37]  [  10/1229]  eta: 0:05:41  lr: 0.000000  loss: 0.5055 (0.5098)  loss_classifier: 0.1860 (0.1765)  loss_box_reg: 0.1628 (0.1673)  loss_objectness: 0.1158 (0.1293)  loss_rpn_box_reg: 0.0204 (0.0366)  time: 0.2800  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [37]  [  20/1229]  eta: 0:05:33  lr: 0.000000  loss: 0.4692 (0.4655)  loss_classifier: 0.1481 (0.1624)  loss_box_reg: 0.1556 (0.1637)  loss_objectness: 0.0804 (0.1075)  loss_rpn_box_reg: 0.0135 (0.0319)  time: 0.2774  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [37]  [  30/1229]  eta: 0:05:32  lr: 0.000000  loss: 0.4134 (0.4742)  loss_classifier: 0.1405 (0.1637)  loss_box_reg: 0.1569 (0.1669)  loss_objectness: 0.0697 (0.1026)  loss_rpn_box_reg: 0.0246 (0.0411)  time: 0.2756  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [37]  [  40/1229]  eta: 0:05:29  lr: 0.000000  loss: 0.4981 (0.4922)  loss_classifier: 0.1525 (0.1690)  loss_box_reg: 0.1572 (0.1685)  loss_objectness: 0.0765 (0.1092)  loss_rpn_box_reg: 0.0437 (0.0454)  time: 0.2778  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [37]  [  50/1229]  eta: 0:05:25  lr: 0.000000  loss: 0.4187 (0.4716)  loss_classifier: 0.1528 (0.1640)  loss_box_reg: 0.1172 (0.1633)  loss_objectness: 0.1003 (0.1048)  loss_rpn_box_reg: 0.0146 (0.0397)  time: 0.2737  data: 0.1371  max mem: 1751\n",
      "Training Epoch: [37]  [  60/1229]  eta: 0:05:21  lr: 0.000000  loss: 0.3809 (0.4610)  loss_classifier: 0.1379 (0.1621)  loss_box_reg: 0.1015 (0.1589)  loss_objectness: 0.0819 (0.1019)  loss_rpn_box_reg: 0.0137 (0.0381)  time: 0.2717  data: 0.1376  max mem: 1751\n",
      "Training Epoch: [37]  [  70/1229]  eta: 0:05:17  lr: 0.000000  loss: 0.4320 (0.4712)  loss_classifier: 0.1379 (0.1632)  loss_box_reg: 0.1415 (0.1622)  loss_objectness: 0.0872 (0.1024)  loss_rpn_box_reg: 0.0191 (0.0434)  time: 0.2696  data: 0.1366  max mem: 1751\n",
      "Training Epoch: [37]  [  80/1229]  eta: 0:05:15  lr: 0.000000  loss: 0.5036 (0.4614)  loss_classifier: 0.1381 (0.1616)  loss_box_reg: 0.1415 (0.1586)  loss_objectness: 0.0761 (0.0996)  loss_rpn_box_reg: 0.0244 (0.0416)  time: 0.2712  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [37]  [  90/1229]  eta: 0:05:11  lr: 0.000000  loss: 0.4180 (0.4624)  loss_classifier: 0.1509 (0.1616)  loss_box_reg: 0.1532 (0.1588)  loss_objectness: 0.0888 (0.1006)  loss_rpn_box_reg: 0.0199 (0.0415)  time: 0.2709  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [37]  [ 100/1229]  eta: 0:05:08  lr: 0.000000  loss: 0.4458 (0.4671)  loss_classifier: 0.1542 (0.1630)  loss_box_reg: 0.1243 (0.1569)  loss_objectness: 0.1068 (0.1053)  loss_rpn_box_reg: 0.0224 (0.0418)  time: 0.2700  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [37]  [ 110/1229]  eta: 0:05:06  lr: 0.000000  loss: 0.4420 (0.4623)  loss_classifier: 0.1254 (0.1615)  loss_box_reg: 0.0782 (0.1547)  loss_objectness: 0.1094 (0.1047)  loss_rpn_box_reg: 0.0211 (0.0413)  time: 0.2753  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [37]  [ 120/1229]  eta: 0:05:03  lr: 0.000000  loss: 0.3138 (0.4543)  loss_classifier: 0.1085 (0.1584)  loss_box_reg: 0.0757 (0.1513)  loss_objectness: 0.0705 (0.1036)  loss_rpn_box_reg: 0.0173 (0.0410)  time: 0.2764  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [37]  [ 130/1229]  eta: 0:05:00  lr: 0.000000  loss: 0.2613 (0.4422)  loss_classifier: 0.0892 (0.1544)  loss_box_reg: 0.0784 (0.1466)  loss_objectness: 0.0714 (0.1018)  loss_rpn_box_reg: 0.0151 (0.0393)  time: 0.2726  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [37]  [ 140/1229]  eta: 0:04:58  lr: 0.000000  loss: 0.2613 (0.4358)  loss_classifier: 0.0906 (0.1515)  loss_box_reg: 0.0850 (0.1458)  loss_objectness: 0.0714 (0.0995)  loss_rpn_box_reg: 0.0130 (0.0390)  time: 0.2727  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [37]  [ 150/1229]  eta: 0:04:55  lr: 0.000000  loss: 0.3985 (0.4435)  loss_classifier: 0.1274 (0.1543)  loss_box_reg: 0.1161 (0.1492)  loss_objectness: 0.0891 (0.1014)  loss_rpn_box_reg: 0.0223 (0.0386)  time: 0.2745  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [37]  [ 160/1229]  eta: 0:04:52  lr: 0.000000  loss: 0.4984 (0.4448)  loss_classifier: 0.1718 (0.1542)  loss_box_reg: 0.1628 (0.1504)  loss_objectness: 0.0975 (0.1006)  loss_rpn_box_reg: 0.0292 (0.0396)  time: 0.2751  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [37]  [ 170/1229]  eta: 0:04:50  lr: 0.000000  loss: 0.3916 (0.4407)  loss_classifier: 0.1483 (0.1533)  loss_box_reg: 0.1035 (0.1490)  loss_objectness: 0.0803 (0.0999)  loss_rpn_box_reg: 0.0225 (0.0386)  time: 0.2798  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [37]  [ 180/1229]  eta: 0:04:47  lr: 0.000000  loss: 0.3983 (0.4400)  loss_classifier: 0.1525 (0.1533)  loss_box_reg: 0.1017 (0.1486)  loss_objectness: 0.0803 (0.1001)  loss_rpn_box_reg: 0.0168 (0.0381)  time: 0.2783  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [37]  [ 190/1229]  eta: 0:04:45  lr: 0.000000  loss: 0.3133 (0.4340)  loss_classifier: 0.1176 (0.1518)  loss_box_reg: 0.1082 (0.1470)  loss_objectness: 0.0617 (0.0985)  loss_rpn_box_reg: 0.0136 (0.0368)  time: 0.2787  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [37]  [ 200/1229]  eta: 0:04:42  lr: 0.000000  loss: 0.2834 (0.4276)  loss_classifier: 0.1161 (0.1499)  loss_box_reg: 0.1039 (0.1449)  loss_objectness: 0.0615 (0.0971)  loss_rpn_box_reg: 0.0127 (0.0359)  time: 0.2785  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [37]  [ 210/1229]  eta: 0:04:39  lr: 0.000000  loss: 0.3034 (0.4266)  loss_classifier: 0.1176 (0.1499)  loss_box_reg: 0.0880 (0.1440)  loss_objectness: 0.0730 (0.0970)  loss_rpn_box_reg: 0.0163 (0.0356)  time: 0.2728  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [37]  [ 220/1229]  eta: 0:04:36  lr: 0.000000  loss: 0.3289 (0.4268)  loss_classifier: 0.1176 (0.1504)  loss_box_reg: 0.1208 (0.1447)  loss_objectness: 0.0826 (0.0963)  loss_rpn_box_reg: 0.0251 (0.0353)  time: 0.2716  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [37]  [ 230/1229]  eta: 0:04:34  lr: 0.000000  loss: 0.4671 (0.4330)  loss_classifier: 0.1641 (0.1529)  loss_box_reg: 0.1802 (0.1475)  loss_objectness: 0.0888 (0.0975)  loss_rpn_box_reg: 0.0302 (0.0351)  time: 0.2738  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [37]  [ 240/1229]  eta: 0:04:31  lr: 0.000000  loss: 0.4490 (0.4311)  loss_classifier: 0.1490 (0.1520)  loss_box_reg: 0.1182 (0.1468)  loss_objectness: 0.0967 (0.0974)  loss_rpn_box_reg: 0.0300 (0.0348)  time: 0.2745  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [37]  [ 250/1229]  eta: 0:04:28  lr: 0.000000  loss: 0.3484 (0.4329)  loss_classifier: 0.1171 (0.1517)  loss_box_reg: 0.0859 (0.1455)  loss_objectness: 0.1034 (0.0993)  loss_rpn_box_reg: 0.0228 (0.0363)  time: 0.2733  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [37]  [ 260/1229]  eta: 0:04:25  lr: 0.000000  loss: 0.3161 (0.4275)  loss_classifier: 0.1171 (0.1501)  loss_box_reg: 0.0851 (0.1436)  loss_objectness: 0.0992 (0.0983)  loss_rpn_box_reg: 0.0172 (0.0355)  time: 0.2717  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [37]  [ 270/1229]  eta: 0:04:22  lr: 0.000000  loss: 0.3294 (0.4256)  loss_classifier: 0.1183 (0.1494)  loss_box_reg: 0.0934 (0.1424)  loss_objectness: 0.0777 (0.0984)  loss_rpn_box_reg: 0.0180 (0.0354)  time: 0.2706  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [37]  [ 280/1229]  eta: 0:04:20  lr: 0.000000  loss: 0.3719 (0.4289)  loss_classifier: 0.1350 (0.1505)  loss_box_reg: 0.1062 (0.1433)  loss_objectness: 0.0855 (0.0989)  loss_rpn_box_reg: 0.0256 (0.0362)  time: 0.2769  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [37]  [ 290/1229]  eta: 0:04:17  lr: 0.000000  loss: 0.4464 (0.4302)  loss_classifier: 0.1533 (0.1511)  loss_box_reg: 0.1393 (0.1438)  loss_objectness: 0.0865 (0.0995)  loss_rpn_box_reg: 0.0175 (0.0358)  time: 0.2743  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [37]  [ 300/1229]  eta: 0:04:14  lr: 0.000000  loss: 0.3833 (0.4290)  loss_classifier: 0.1229 (0.1507)  loss_box_reg: 0.1157 (0.1432)  loss_objectness: 0.0864 (0.0996)  loss_rpn_box_reg: 0.0154 (0.0356)  time: 0.2702  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [37]  [ 310/1229]  eta: 0:04:11  lr: 0.000000  loss: 0.3744 (0.4300)  loss_classifier: 0.1273 (0.1513)  loss_box_reg: 0.1222 (0.1437)  loss_objectness: 0.0702 (0.0995)  loss_rpn_box_reg: 0.0182 (0.0355)  time: 0.2729  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [37]  [ 320/1229]  eta: 0:04:09  lr: 0.000000  loss: 0.4659 (0.4336)  loss_classifier: 0.1573 (0.1521)  loss_box_reg: 0.1229 (0.1438)  loss_objectness: 0.1318 (0.1012)  loss_rpn_box_reg: 0.0365 (0.0365)  time: 0.2715  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [37]  [ 330/1229]  eta: 0:04:06  lr: 0.000000  loss: 0.4492 (0.4340)  loss_classifier: 0.1290 (0.1522)  loss_box_reg: 0.1157 (0.1442)  loss_objectness: 0.1243 (0.1012)  loss_rpn_box_reg: 0.0306 (0.0364)  time: 0.2760  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [37]  [ 340/1229]  eta: 0:04:03  lr: 0.000000  loss: 0.3620 (0.4323)  loss_classifier: 0.1273 (0.1518)  loss_box_reg: 0.0905 (0.1433)  loss_objectness: 0.0879 (0.1013)  loss_rpn_box_reg: 0.0167 (0.0359)  time: 0.2794  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [37]  [ 350/1229]  eta: 0:04:01  lr: 0.000000  loss: 0.3625 (0.4314)  loss_classifier: 0.1396 (0.1519)  loss_box_reg: 0.1028 (0.1431)  loss_objectness: 0.0814 (0.1008)  loss_rpn_box_reg: 0.0146 (0.0356)  time: 0.2746  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [37]  [ 360/1229]  eta: 0:03:58  lr: 0.000000  loss: 0.4451 (0.4333)  loss_classifier: 0.1776 (0.1527)  loss_box_reg: 0.1500 (0.1433)  loss_objectness: 0.1013 (0.1013)  loss_rpn_box_reg: 0.0313 (0.0359)  time: 0.2712  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [37]  [ 370/1229]  eta: 0:03:55  lr: 0.000000  loss: 0.4982 (0.4355)  loss_classifier: 0.1809 (0.1537)  loss_box_reg: 0.1433 (0.1436)  loss_objectness: 0.1119 (0.1021)  loss_rpn_box_reg: 0.0299 (0.0362)  time: 0.2686  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [37]  [ 380/1229]  eta: 0:03:52  lr: 0.000000  loss: 0.4074 (0.4333)  loss_classifier: 0.1346 (0.1528)  loss_box_reg: 0.1332 (0.1427)  loss_objectness: 0.1013 (0.1018)  loss_rpn_box_reg: 0.0180 (0.0361)  time: 0.2717  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [37]  [ 390/1229]  eta: 0:03:49  lr: 0.000000  loss: 0.3214 (0.4348)  loss_classifier: 0.1160 (0.1534)  loss_box_reg: 0.1126 (0.1437)  loss_objectness: 0.0813 (0.1018)  loss_rpn_box_reg: 0.0162 (0.0359)  time: 0.2759  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [37]  [ 400/1229]  eta: 0:03:47  lr: 0.000000  loss: 0.3123 (0.4330)  loss_classifier: 0.1199 (0.1531)  loss_box_reg: 0.0978 (0.1428)  loss_objectness: 0.0551 (0.1016)  loss_rpn_box_reg: 0.0162 (0.0355)  time: 0.2721  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [37]  [ 410/1229]  eta: 0:03:44  lr: 0.000000  loss: 0.3214 (0.4320)  loss_classifier: 0.1267 (0.1530)  loss_box_reg: 0.0952 (0.1424)  loss_objectness: 0.0744 (0.1013)  loss_rpn_box_reg: 0.0125 (0.0353)  time: 0.2699  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [37]  [ 420/1229]  eta: 0:03:41  lr: 0.000000  loss: 0.3834 (0.4314)  loss_classifier: 0.1493 (0.1528)  loss_box_reg: 0.1047 (0.1427)  loss_objectness: 0.0764 (0.1009)  loss_rpn_box_reg: 0.0133 (0.0351)  time: 0.2691  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [37]  [ 430/1229]  eta: 0:03:38  lr: 0.000000  loss: 0.3620 (0.4318)  loss_classifier: 0.1493 (0.1529)  loss_box_reg: 0.1296 (0.1427)  loss_objectness: 0.0877 (0.1008)  loss_rpn_box_reg: 0.0145 (0.0353)  time: 0.2671  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [37]  [ 440/1229]  eta: 0:03:35  lr: 0.000000  loss: 0.3620 (0.4310)  loss_classifier: 0.1327 (0.1526)  loss_box_reg: 0.1225 (0.1422)  loss_objectness: 0.0877 (0.1011)  loss_rpn_box_reg: 0.0145 (0.0351)  time: 0.2707  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [37]  [ 450/1229]  eta: 0:03:33  lr: 0.000000  loss: 0.3132 (0.4284)  loss_classifier: 0.1327 (0.1518)  loss_box_reg: 0.1016 (0.1414)  loss_objectness: 0.0707 (0.1004)  loss_rpn_box_reg: 0.0141 (0.0348)  time: 0.2774  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [37]  [ 460/1229]  eta: 0:03:30  lr: 0.000000  loss: 0.3236 (0.4281)  loss_classifier: 0.1215 (0.1516)  loss_box_reg: 0.1105 (0.1413)  loss_objectness: 0.0787 (0.1003)  loss_rpn_box_reg: 0.0173 (0.0348)  time: 0.2786  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [37]  [ 470/1229]  eta: 0:03:27  lr: 0.000000  loss: 0.3993 (0.4274)  loss_classifier: 0.1350 (0.1512)  loss_box_reg: 0.1105 (0.1409)  loss_objectness: 0.0875 (0.1005)  loss_rpn_box_reg: 0.0205 (0.0347)  time: 0.2764  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [37]  [ 480/1229]  eta: 0:03:24  lr: 0.000000  loss: 0.4140 (0.4292)  loss_classifier: 0.1489 (0.1519)  loss_box_reg: 0.1418 (0.1417)  loss_objectness: 0.1065 (0.1008)  loss_rpn_box_reg: 0.0204 (0.0349)  time: 0.2702  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [37]  [ 490/1229]  eta: 0:03:22  lr: 0.000000  loss: 0.3505 (0.4282)  loss_classifier: 0.1235 (0.1515)  loss_box_reg: 0.1283 (0.1414)  loss_objectness: 0.1065 (0.1005)  loss_rpn_box_reg: 0.0241 (0.0348)  time: 0.2634  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [37]  [ 500/1229]  eta: 0:03:19  lr: 0.000000  loss: 0.3473 (0.4279)  loss_classifier: 0.1235 (0.1515)  loss_box_reg: 0.1225 (0.1415)  loss_objectness: 0.0806 (0.1002)  loss_rpn_box_reg: 0.0191 (0.0346)  time: 0.2678  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [37]  [ 510/1229]  eta: 0:03:16  lr: 0.000000  loss: 0.3279 (0.4262)  loss_classifier: 0.1191 (0.1510)  loss_box_reg: 0.0950 (0.1408)  loss_objectness: 0.0911 (0.1001)  loss_rpn_box_reg: 0.0191 (0.0344)  time: 0.2717  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [37]  [ 520/1229]  eta: 0:03:13  lr: 0.000000  loss: 0.3192 (0.4246)  loss_classifier: 0.1191 (0.1505)  loss_box_reg: 0.0858 (0.1399)  loss_objectness: 0.0835 (0.1000)  loss_rpn_box_reg: 0.0155 (0.0342)  time: 0.2682  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [37]  [ 530/1229]  eta: 0:03:11  lr: 0.000000  loss: 0.3192 (0.4223)  loss_classifier: 0.1072 (0.1498)  loss_box_reg: 0.1007 (0.1392)  loss_objectness: 0.0679 (0.0994)  loss_rpn_box_reg: 0.0141 (0.0339)  time: 0.2714  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [37]  [ 540/1229]  eta: 0:03:08  lr: 0.000000  loss: 0.3378 (0.4218)  loss_classifier: 0.1108 (0.1496)  loss_box_reg: 0.1315 (0.1396)  loss_objectness: 0.0679 (0.0990)  loss_rpn_box_reg: 0.0175 (0.0337)  time: 0.2778  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [37]  [ 550/1229]  eta: 0:03:05  lr: 0.000000  loss: 0.3668 (0.4216)  loss_classifier: 0.1157 (0.1494)  loss_box_reg: 0.1355 (0.1395)  loss_objectness: 0.0785 (0.0989)  loss_rpn_box_reg: 0.0256 (0.0339)  time: 0.2753  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [37]  [ 560/1229]  eta: 0:03:02  lr: 0.000000  loss: 0.3765 (0.4219)  loss_classifier: 0.1245 (0.1495)  loss_box_reg: 0.1086 (0.1394)  loss_objectness: 0.0808 (0.0988)  loss_rpn_box_reg: 0.0346 (0.0341)  time: 0.2732  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [37]  [ 570/1229]  eta: 0:03:00  lr: 0.000000  loss: 0.3457 (0.4220)  loss_classifier: 0.1343 (0.1495)  loss_box_reg: 0.1086 (0.1394)  loss_objectness: 0.0809 (0.0987)  loss_rpn_box_reg: 0.0321 (0.0344)  time: 0.2753  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [37]  [ 580/1229]  eta: 0:02:57  lr: 0.000000  loss: 0.3279 (0.4222)  loss_classifier: 0.1172 (0.1496)  loss_box_reg: 0.1075 (0.1397)  loss_objectness: 0.0809 (0.0987)  loss_rpn_box_reg: 0.0163 (0.0342)  time: 0.2740  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [37]  [ 590/1229]  eta: 0:02:54  lr: 0.000000  loss: 0.3517 (0.4218)  loss_classifier: 0.1212 (0.1495)  loss_box_reg: 0.1108 (0.1394)  loss_objectness: 0.0835 (0.0985)  loss_rpn_box_reg: 0.0235 (0.0343)  time: 0.2767  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [37]  [ 600/1229]  eta: 0:02:52  lr: 0.000000  loss: 0.4093 (0.4225)  loss_classifier: 0.1340 (0.1495)  loss_box_reg: 0.1346 (0.1400)  loss_objectness: 0.0786 (0.0986)  loss_rpn_box_reg: 0.0276 (0.0344)  time: 0.2772  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [37]  [ 610/1229]  eta: 0:02:49  lr: 0.000000  loss: 0.4177 (0.4236)  loss_classifier: 0.1517 (0.1498)  loss_box_reg: 0.1450 (0.1403)  loss_objectness: 0.0852 (0.0988)  loss_rpn_box_reg: 0.0211 (0.0346)  time: 0.2824  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [37]  [ 620/1229]  eta: 0:02:46  lr: 0.000000  loss: 0.4221 (0.4241)  loss_classifier: 0.1445 (0.1500)  loss_box_reg: 0.1504 (0.1407)  loss_objectness: 0.1002 (0.0987)  loss_rpn_box_reg: 0.0232 (0.0347)  time: 0.2820  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [37]  [ 630/1229]  eta: 0:02:43  lr: 0.000000  loss: 0.4221 (0.4233)  loss_classifier: 0.1444 (0.1498)  loss_box_reg: 0.1405 (0.1405)  loss_objectness: 0.0887 (0.0986)  loss_rpn_box_reg: 0.0205 (0.0344)  time: 0.2722  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [37]  [ 640/1229]  eta: 0:02:41  lr: 0.000000  loss: 0.3697 (0.4238)  loss_classifier: 0.1444 (0.1499)  loss_box_reg: 0.1198 (0.1401)  loss_objectness: 0.1079 (0.0993)  loss_rpn_box_reg: 0.0179 (0.0346)  time: 0.2728  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [37]  [ 650/1229]  eta: 0:02:38  lr: 0.000000  loss: 0.3658 (0.4238)  loss_classifier: 0.1436 (0.1500)  loss_box_reg: 0.1198 (0.1402)  loss_objectness: 0.0817 (0.0988)  loss_rpn_box_reg: 0.0254 (0.0348)  time: 0.2782  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [37]  [ 660/1229]  eta: 0:02:35  lr: 0.000000  loss: 0.3504 (0.4266)  loss_classifier: 0.1436 (0.1510)  loss_box_reg: 0.1376 (0.1411)  loss_objectness: 0.0817 (0.0996)  loss_rpn_box_reg: 0.0290 (0.0349)  time: 0.2783  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [37]  [ 670/1229]  eta: 0:02:33  lr: 0.000000  loss: 0.4653 (0.4280)  loss_classifier: 0.1694 (0.1515)  loss_box_reg: 0.1306 (0.1417)  loss_objectness: 0.1281 (0.0999)  loss_rpn_box_reg: 0.0222 (0.0349)  time: 0.2730  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [37]  [ 680/1229]  eta: 0:02:30  lr: 0.000000  loss: 0.4098 (0.4274)  loss_classifier: 0.1545 (0.1513)  loss_box_reg: 0.1135 (0.1413)  loss_objectness: 0.0983 (0.1001)  loss_rpn_box_reg: 0.0174 (0.0347)  time: 0.2769  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [37]  [ 690/1229]  eta: 0:02:27  lr: 0.000000  loss: 0.3233 (0.4265)  loss_classifier: 0.1294 (0.1510)  loss_box_reg: 0.0867 (0.1411)  loss_objectness: 0.0876 (0.0998)  loss_rpn_box_reg: 0.0167 (0.0345)  time: 0.2772  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [37]  [ 700/1229]  eta: 0:02:24  lr: 0.000000  loss: 0.3614 (0.4275)  loss_classifier: 0.1443 (0.1513)  loss_box_reg: 0.1290 (0.1419)  loss_objectness: 0.0836 (0.0998)  loss_rpn_box_reg: 0.0239 (0.0344)  time: 0.2688  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [37]  [ 710/1229]  eta: 0:02:22  lr: 0.000000  loss: 0.3905 (0.4282)  loss_classifier: 0.1465 (0.1518)  loss_box_reg: 0.1378 (0.1423)  loss_objectness: 0.0760 (0.0997)  loss_rpn_box_reg: 0.0244 (0.0344)  time: 0.2700  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [37]  [ 720/1229]  eta: 0:02:19  lr: 0.000000  loss: 0.4621 (0.4288)  loss_classifier: 0.1586 (0.1520)  loss_box_reg: 0.1378 (0.1425)  loss_objectness: 0.0745 (0.0999)  loss_rpn_box_reg: 0.0343 (0.0344)  time: 0.2720  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [37]  [ 730/1229]  eta: 0:02:16  lr: 0.000000  loss: 0.4570 (0.4294)  loss_classifier: 0.1534 (0.1521)  loss_box_reg: 0.1311 (0.1427)  loss_objectness: 0.0980 (0.1003)  loss_rpn_box_reg: 0.0284 (0.0343)  time: 0.2705  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [37]  [ 740/1229]  eta: 0:02:13  lr: 0.000000  loss: 0.4827 (0.4313)  loss_classifier: 0.1713 (0.1527)  loss_box_reg: 0.1530 (0.1434)  loss_objectness: 0.1209 (0.1006)  loss_rpn_box_reg: 0.0248 (0.0346)  time: 0.2747  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [37]  [ 750/1229]  eta: 0:02:11  lr: 0.000000  loss: 0.5032 (0.4318)  loss_classifier: 0.1971 (0.1531)  loss_box_reg: 0.1553 (0.1437)  loss_objectness: 0.1005 (0.1006)  loss_rpn_box_reg: 0.0241 (0.0344)  time: 0.2787  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [37]  [ 760/1229]  eta: 0:02:08  lr: 0.000000  loss: 0.4022 (0.4322)  loss_classifier: 0.1384 (0.1531)  loss_box_reg: 0.1377 (0.1437)  loss_objectness: 0.0931 (0.1008)  loss_rpn_box_reg: 0.0215 (0.0346)  time: 0.2748  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [37]  [ 770/1229]  eta: 0:02:05  lr: 0.000000  loss: 0.3999 (0.4314)  loss_classifier: 0.1384 (0.1530)  loss_box_reg: 0.1097 (0.1432)  loss_objectness: 0.0926 (0.1006)  loss_rpn_box_reg: 0.0284 (0.0346)  time: 0.2743  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [37]  [ 780/1229]  eta: 0:02:03  lr: 0.000000  loss: 0.3889 (0.4310)  loss_classifier: 0.1345 (0.1528)  loss_box_reg: 0.1036 (0.1430)  loss_objectness: 0.0965 (0.1007)  loss_rpn_box_reg: 0.0250 (0.0345)  time: 0.2802  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [37]  [ 790/1229]  eta: 0:02:00  lr: 0.000000  loss: 0.3625 (0.4312)  loss_classifier: 0.1259 (0.1529)  loss_box_reg: 0.1196 (0.1433)  loss_objectness: 0.0851 (0.1005)  loss_rpn_box_reg: 0.0233 (0.0345)  time: 0.2799  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [37]  [ 800/1229]  eta: 0:01:57  lr: 0.000000  loss: 0.4569 (0.4320)  loss_classifier: 0.1566 (0.1532)  loss_box_reg: 0.1240 (0.1435)  loss_objectness: 0.0822 (0.1008)  loss_rpn_box_reg: 0.0237 (0.0345)  time: 0.2742  data: 0.1287  max mem: 1751\n",
      "Training Epoch: [37]  [ 810/1229]  eta: 0:01:54  lr: 0.000000  loss: 0.4569 (0.4323)  loss_classifier: 0.1591 (0.1533)  loss_box_reg: 0.1240 (0.1436)  loss_objectness: 0.1124 (0.1008)  loss_rpn_box_reg: 0.0316 (0.0346)  time: 0.2754  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [37]  [ 820/1229]  eta: 0:01:52  lr: 0.000000  loss: 0.3485 (0.4313)  loss_classifier: 0.1108 (0.1530)  loss_box_reg: 0.1047 (0.1430)  loss_objectness: 0.0922 (0.1008)  loss_rpn_box_reg: 0.0197 (0.0345)  time: 0.2757  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [37]  [ 830/1229]  eta: 0:01:49  lr: 0.000000  loss: 0.3378 (0.4305)  loss_classifier: 0.1235 (0.1528)  loss_box_reg: 0.0989 (0.1427)  loss_objectness: 0.0677 (0.1005)  loss_rpn_box_reg: 0.0132 (0.0344)  time: 0.2731  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [37]  [ 840/1229]  eta: 0:01:46  lr: 0.000000  loss: 0.4174 (0.4312)  loss_classifier: 0.1420 (0.1530)  loss_box_reg: 0.1512 (0.1431)  loss_objectness: 0.0855 (0.1006)  loss_rpn_box_reg: 0.0142 (0.0344)  time: 0.2736  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [37]  [ 850/1229]  eta: 0:01:43  lr: 0.000000  loss: 0.4402 (0.4315)  loss_classifier: 0.1459 (0.1531)  loss_box_reg: 0.1639 (0.1432)  loss_objectness: 0.0920 (0.1007)  loss_rpn_box_reg: 0.0237 (0.0344)  time: 0.2760  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [37]  [ 860/1229]  eta: 0:01:41  lr: 0.000000  loss: 0.3675 (0.4324)  loss_classifier: 0.1469 (0.1533)  loss_box_reg: 0.1431 (0.1437)  loss_objectness: 0.0741 (0.1008)  loss_rpn_box_reg: 0.0325 (0.0346)  time: 0.2781  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [37]  [ 870/1229]  eta: 0:01:38  lr: 0.000000  loss: 0.3735 (0.4325)  loss_classifier: 0.1417 (0.1533)  loss_box_reg: 0.1431 (0.1438)  loss_objectness: 0.1045 (0.1010)  loss_rpn_box_reg: 0.0326 (0.0345)  time: 0.2680  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [37]  [ 880/1229]  eta: 0:01:35  lr: 0.000000  loss: 0.3926 (0.4333)  loss_classifier: 0.1417 (0.1537)  loss_box_reg: 0.1486 (0.1441)  loss_objectness: 0.0903 (0.1010)  loss_rpn_box_reg: 0.0224 (0.0344)  time: 0.2616  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [37]  [ 890/1229]  eta: 0:01:32  lr: 0.000000  loss: 0.3926 (0.4334)  loss_classifier: 0.1394 (0.1538)  loss_box_reg: 0.1293 (0.1442)  loss_objectness: 0.0806 (0.1010)  loss_rpn_box_reg: 0.0141 (0.0344)  time: 0.2722  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [37]  [ 900/1229]  eta: 0:01:30  lr: 0.000000  loss: 0.4364 (0.4342)  loss_classifier: 0.1394 (0.1541)  loss_box_reg: 0.1300 (0.1444)  loss_objectness: 0.0906 (0.1012)  loss_rpn_box_reg: 0.0217 (0.0346)  time: 0.2797  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [37]  [ 910/1229]  eta: 0:01:27  lr: 0.000000  loss: 0.4041 (0.4341)  loss_classifier: 0.1316 (0.1540)  loss_box_reg: 0.1498 (0.1443)  loss_objectness: 0.0945 (0.1012)  loss_rpn_box_reg: 0.0217 (0.0346)  time: 0.2724  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [37]  [ 920/1229]  eta: 0:01:24  lr: 0.000000  loss: 0.3795 (0.4341)  loss_classifier: 0.1301 (0.1541)  loss_box_reg: 0.1208 (0.1442)  loss_objectness: 0.0927 (0.1012)  loss_rpn_box_reg: 0.0149 (0.0345)  time: 0.2731  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [37]  [ 930/1229]  eta: 0:01:21  lr: 0.000000  loss: 0.4226 (0.4344)  loss_classifier: 0.1404 (0.1542)  loss_box_reg: 0.1204 (0.1444)  loss_objectness: 0.0897 (0.1012)  loss_rpn_box_reg: 0.0187 (0.0345)  time: 0.2773  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [37]  [ 940/1229]  eta: 0:01:19  lr: 0.000000  loss: 0.4697 (0.4344)  loss_classifier: 0.1404 (0.1542)  loss_box_reg: 0.1204 (0.1445)  loss_objectness: 0.0885 (0.1012)  loss_rpn_box_reg: 0.0150 (0.0345)  time: 0.2792  data: 0.1320  max mem: 1751\n",
      "Training Epoch: [37]  [ 950/1229]  eta: 0:01:16  lr: 0.000000  loss: 0.4187 (0.4353)  loss_classifier: 0.1638 (0.1546)  loss_box_reg: 0.1484 (0.1451)  loss_objectness: 0.0823 (0.1011)  loss_rpn_box_reg: 0.0175 (0.0345)  time: 0.2797  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [37]  [ 960/1229]  eta: 0:01:13  lr: 0.000000  loss: 0.4187 (0.4354)  loss_classifier: 0.1570 (0.1545)  loss_box_reg: 0.1439 (0.1449)  loss_objectness: 0.0875 (0.1013)  loss_rpn_box_reg: 0.0285 (0.0346)  time: 0.2710  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [37]  [ 970/1229]  eta: 0:01:10  lr: 0.000000  loss: 0.3181 (0.4348)  loss_classifier: 0.1254 (0.1544)  loss_box_reg: 0.1097 (0.1447)  loss_objectness: 0.0916 (0.1012)  loss_rpn_box_reg: 0.0240 (0.0345)  time: 0.2695  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [37]  [ 980/1229]  eta: 0:01:08  lr: 0.000000  loss: 0.3231 (0.4350)  loss_classifier: 0.1315 (0.1544)  loss_box_reg: 0.1097 (0.1447)  loss_objectness: 0.0778 (0.1014)  loss_rpn_box_reg: 0.0240 (0.0345)  time: 0.2745  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [37]  [ 990/1229]  eta: 0:01:05  lr: 0.000000  loss: 0.3451 (0.4350)  loss_classifier: 0.1196 (0.1544)  loss_box_reg: 0.0945 (0.1448)  loss_objectness: 0.0819 (0.1012)  loss_rpn_box_reg: 0.0255 (0.0347)  time: 0.2808  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [37]  [1000/1229]  eta: 0:01:02  lr: 0.000000  loss: 0.3550 (0.4351)  loss_classifier: 0.1194 (0.1544)  loss_box_reg: 0.1015 (0.1448)  loss_objectness: 0.0819 (0.1014)  loss_rpn_box_reg: 0.0173 (0.0346)  time: 0.2822  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [37]  [1010/1229]  eta: 0:01:00  lr: 0.000000  loss: 0.3871 (0.4362)  loss_classifier: 0.1172 (0.1547)  loss_box_reg: 0.1018 (0.1453)  loss_objectness: 0.1026 (0.1017)  loss_rpn_box_reg: 0.0212 (0.0345)  time: 0.2719  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [37]  [1020/1229]  eta: 0:00:57  lr: 0.000000  loss: 0.3871 (0.4364)  loss_classifier: 0.1158 (0.1547)  loss_box_reg: 0.1075 (0.1456)  loss_objectness: 0.1016 (0.1016)  loss_rpn_box_reg: 0.0266 (0.0347)  time: 0.2715  data: 0.1312  max mem: 1751\n",
      "Training Epoch: [37]  [1030/1229]  eta: 0:00:54  lr: 0.000000  loss: 0.3207 (0.4358)  loss_classifier: 0.1158 (0.1545)  loss_box_reg: 0.0944 (0.1454)  loss_objectness: 0.0715 (0.1014)  loss_rpn_box_reg: 0.0205 (0.0345)  time: 0.2745  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [37]  [1040/1229]  eta: 0:00:51  lr: 0.000000  loss: 0.3977 (0.4361)  loss_classifier: 0.1285 (0.1547)  loss_box_reg: 0.0962 (0.1457)  loss_objectness: 0.0836 (0.1013)  loss_rpn_box_reg: 0.0153 (0.0344)  time: 0.2735  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [37]  [1050/1229]  eta: 0:00:49  lr: 0.000000  loss: 0.2871 (0.4350)  loss_classifier: 0.1243 (0.1544)  loss_box_reg: 0.0742 (0.1453)  loss_objectness: 0.0780 (0.1010)  loss_rpn_box_reg: 0.0150 (0.0343)  time: 0.2805  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [37]  [1060/1229]  eta: 0:00:46  lr: 0.000000  loss: 0.2759 (0.4347)  loss_classifier: 0.1069 (0.1543)  loss_box_reg: 0.0620 (0.1452)  loss_objectness: 0.0697 (0.1009)  loss_rpn_box_reg: 0.0187 (0.0342)  time: 0.2783  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [37]  [1070/1229]  eta: 0:00:43  lr: 0.000000  loss: 0.2672 (0.4343)  loss_classifier: 0.1054 (0.1542)  loss_box_reg: 0.0803 (0.1451)  loss_objectness: 0.0806 (0.1009)  loss_rpn_box_reg: 0.0187 (0.0341)  time: 0.2709  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [37]  [1080/1229]  eta: 0:00:40  lr: 0.000000  loss: 0.3548 (0.4337)  loss_classifier: 0.1222 (0.1541)  loss_box_reg: 0.1165 (0.1450)  loss_objectness: 0.0762 (0.1005)  loss_rpn_box_reg: 0.0142 (0.0341)  time: 0.2716  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [37]  [1090/1229]  eta: 0:00:38  lr: 0.000000  loss: 0.4007 (0.4337)  loss_classifier: 0.1429 (0.1540)  loss_box_reg: 0.1321 (0.1450)  loss_objectness: 0.0762 (0.1006)  loss_rpn_box_reg: 0.0142 (0.0341)  time: 0.2677  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [37]  [1100/1229]  eta: 0:00:35  lr: 0.000000  loss: 0.4305 (0.4343)  loss_classifier: 0.1420 (0.1540)  loss_box_reg: 0.1417 (0.1454)  loss_objectness: 0.1069 (0.1008)  loss_rpn_box_reg: 0.0283 (0.0341)  time: 0.2662  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [37]  [1110/1229]  eta: 0:00:32  lr: 0.000000  loss: 0.3171 (0.4330)  loss_classifier: 0.1081 (0.1537)  loss_box_reg: 0.1017 (0.1450)  loss_objectness: 0.0698 (0.1004)  loss_rpn_box_reg: 0.0132 (0.0339)  time: 0.2717  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [37]  [1120/1229]  eta: 0:00:29  lr: 0.000000  loss: 0.2610 (0.4322)  loss_classifier: 0.0959 (0.1534)  loss_box_reg: 0.0987 (0.1447)  loss_objectness: 0.0661 (0.1003)  loss_rpn_box_reg: 0.0132 (0.0338)  time: 0.2768  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [37]  [1130/1229]  eta: 0:00:27  lr: 0.000000  loss: 0.3535 (0.4327)  loss_classifier: 0.1296 (0.1535)  loss_box_reg: 0.1252 (0.1451)  loss_objectness: 0.0843 (0.1002)  loss_rpn_box_reg: 0.0194 (0.0339)  time: 0.2778  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [37]  [1140/1229]  eta: 0:00:24  lr: 0.000000  loss: 0.4901 (0.4341)  loss_classifier: 0.1880 (0.1540)  loss_box_reg: 0.1624 (0.1455)  loss_objectness: 0.0970 (0.1006)  loss_rpn_box_reg: 0.0272 (0.0340)  time: 0.2730  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [37]  [1150/1229]  eta: 0:00:21  lr: 0.000000  loss: 0.4901 (0.4341)  loss_classifier: 0.1860 (0.1540)  loss_box_reg: 0.1260 (0.1454)  loss_objectness: 0.0970 (0.1006)  loss_rpn_box_reg: 0.0316 (0.0341)  time: 0.2756  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [37]  [1160/1229]  eta: 0:00:18  lr: 0.000000  loss: 0.4231 (0.4345)  loss_classifier: 0.1801 (0.1543)  loss_box_reg: 0.1316 (0.1456)  loss_objectness: 0.0932 (0.1006)  loss_rpn_box_reg: 0.0242 (0.0340)  time: 0.2770  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [37]  [1170/1229]  eta: 0:00:16  lr: 0.000000  loss: 0.3795 (0.4336)  loss_classifier: 0.1267 (0.1540)  loss_box_reg: 0.1046 (0.1452)  loss_objectness: 0.0933 (0.1005)  loss_rpn_box_reg: 0.0235 (0.0340)  time: 0.2722  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [37]  [1180/1229]  eta: 0:00:13  lr: 0.000000  loss: 0.3049 (0.4334)  loss_classifier: 0.1044 (0.1539)  loss_box_reg: 0.0807 (0.1453)  loss_objectness: 0.0730 (0.1003)  loss_rpn_box_reg: 0.0125 (0.0338)  time: 0.2780  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [37]  [1190/1229]  eta: 0:00:10  lr: 0.000000  loss: 0.3897 (0.4329)  loss_classifier: 0.1473 (0.1539)  loss_box_reg: 0.1042 (0.1451)  loss_objectness: 0.0861 (0.1002)  loss_rpn_box_reg: 0.0124 (0.0337)  time: 0.2779  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [37]  [1200/1229]  eta: 0:00:07  lr: 0.000000  loss: 0.3940 (0.4324)  loss_classifier: 0.1216 (0.1537)  loss_box_reg: 0.0986 (0.1447)  loss_objectness: 0.0939 (0.1002)  loss_rpn_box_reg: 0.0228 (0.0337)  time: 0.2692  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [37]  [1210/1229]  eta: 0:00:05  lr: 0.000000  loss: 0.3086 (0.4324)  loss_classifier: 0.1044 (0.1537)  loss_box_reg: 0.0786 (0.1447)  loss_objectness: 0.0757 (0.1002)  loss_rpn_box_reg: 0.0230 (0.0339)  time: 0.2632  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [37]  [1220/1229]  eta: 0:00:02  lr: 0.000000  loss: 0.4379 (0.4332)  loss_classifier: 0.1569 (0.1540)  loss_box_reg: 0.1274 (0.1449)  loss_objectness: 0.0752 (0.1003)  loss_rpn_box_reg: 0.0307 (0.0339)  time: 0.2645  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [37]  [1228/1229]  eta: 0:00:00  lr: 0.000000  loss: 0.4549 (0.4340)  loss_classifier: 0.1609 (0.1542)  loss_box_reg: 0.1610 (0.1453)  loss_objectness: 0.1104 (0.1005)  loss_rpn_box_reg: 0.0307 (0.0340)  time: 0.2742  data: 0.1375  max mem: 1751\n",
      "Training Epoch: [37] Total time: 0:05:36 (0.2740 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:48  model_time: 0.3180 (0.3180)  evaluator_time: 0.0020 (0.0020)  time: 0.3510  data: 0.0280  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0780 (0.0826)  evaluator_time: 0.0040 (0.0086)  time: 0.1265  data: 0.0356  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0840 (0.0814)  evaluator_time: 0.0030 (0.0079)  time: 0.1203  data: 0.0306  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0740 (0.0805)  evaluator_time: 0.0040 (0.0076)  time: 0.1250  data: 0.0407  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0740 (0.0804)  evaluator_time: 0.0030 (0.0076)  time: 0.1217  data: 0.0390  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1244 s / it)\n",
      "Averaged stats: model_time: 0.0740 (0.0804)  evaluator_time: 0.0030 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [37]  [  0/308]  eta: 0:00:40  lr: 0.000000  loss: 0.1663 (0.1663)  loss_classifier: 0.0589 (0.0589)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0275 (0.0275)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1300  data: 0.0290  max mem: 1751\n",
      "Testing Epoch: [37]  [100/308]  eta: 0:00:28  lr: 0.000000  loss: 0.3204 (0.4794)  loss_classifier: 0.1328 (0.1549)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0557 (0.1006)  loss_rpn_box_reg: 0.0186 (0.0516)  time: 0.1400  data: 0.0375  max mem: 1751\n",
      "Testing Epoch: [37]  [200/308]  eta: 0:00:14  lr: 0.000000  loss: 0.3575 (0.4566)  loss_classifier: 0.1388 (0.1492)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0670 (0.0951)  loss_rpn_box_reg: 0.0197 (0.0490)  time: 0.1375  data: 0.0321  max mem: 1751\n",
      "Testing Epoch: [37]  [300/308]  eta: 0:00:01  lr: 0.000000  loss: 0.4736 (0.4536)  loss_classifier: 0.1550 (0.1494)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0784 (0.0927)  loss_rpn_box_reg: 0.0265 (0.0474)  time: 0.1334  data: 0.0371  max mem: 1751\n",
      "Testing Epoch: [37]  [307/308]  eta: 0:00:00  lr: 0.000000  loss: 0.4736 (0.4538)  loss_classifier: 0.1860 (0.1496)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0784 (0.0928)  loss_rpn_box_reg: 0.0271 (0.0470)  time: 0.1303  data: 0.0348  max mem: 1751\n",
      "Testing Epoch: [37] Total time: 0:00:42 (0.1372 s / it)\n",
      "Training Epoch: [38]  [   0/1229]  eta: 0:05:41  lr: 0.000000  loss: 0.2818 (0.2818)  loss_classifier: 0.1053 (0.1053)  loss_box_reg: 0.0870 (0.0870)  loss_objectness: 0.0814 (0.0814)  loss_rpn_box_reg: 0.0079 (0.0079)  time: 0.2780  data: 0.1230  max mem: 1751\n",
      "Training Epoch: [38]  [  10/1229]  eta: 0:05:27  lr: 0.000000  loss: 0.5582 (0.4993)  loss_classifier: 0.1500 (0.1775)  loss_box_reg: 0.1534 (0.1577)  loss_objectness: 0.1296 (0.1209)  loss_rpn_box_reg: 0.0286 (0.0432)  time: 0.2688  data: 0.1376  max mem: 1751\n",
      "Training Epoch: [38]  [  20/1229]  eta: 0:05:23  lr: 0.000000  loss: 0.3858 (0.4198)  loss_classifier: 0.1317 (0.1526)  loss_box_reg: 0.1179 (0.1365)  loss_objectness: 0.0972 (0.1002)  loss_rpn_box_reg: 0.0205 (0.0304)  time: 0.2672  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [38]  [  30/1229]  eta: 0:05:24  lr: 0.000000  loss: 0.3155 (0.4305)  loss_classifier: 0.1250 (0.1576)  loss_box_reg: 0.1179 (0.1438)  loss_objectness: 0.0745 (0.1007)  loss_rpn_box_reg: 0.0156 (0.0284)  time: 0.2710  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [38]  [  40/1229]  eta: 0:05:21  lr: 0.000000  loss: 0.3834 (0.4218)  loss_classifier: 0.1449 (0.1541)  loss_box_reg: 0.1172 (0.1406)  loss_objectness: 0.0870 (0.1005)  loss_rpn_box_reg: 0.0172 (0.0266)  time: 0.2727  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [38]  [  50/1229]  eta: 0:05:18  lr: 0.000000  loss: 0.3958 (0.4377)  loss_classifier: 0.1453 (0.1588)  loss_box_reg: 0.1040 (0.1492)  loss_objectness: 0.0921 (0.1012)  loss_rpn_box_reg: 0.0200 (0.0285)  time: 0.2706  data: 0.1343  max mem: 1751\n",
      "Training Epoch: [38]  [  60/1229]  eta: 0:05:15  lr: 0.000000  loss: 0.3498 (0.4117)  loss_classifier: 0.1102 (0.1486)  loss_box_reg: 0.1025 (0.1401)  loss_objectness: 0.0737 (0.0949)  loss_rpn_box_reg: 0.0202 (0.0280)  time: 0.2698  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [38]  [  70/1229]  eta: 0:05:14  lr: 0.000000  loss: 0.3498 (0.4235)  loss_classifier: 0.1102 (0.1523)  loss_box_reg: 0.1033 (0.1462)  loss_objectness: 0.0772 (0.0964)  loss_rpn_box_reg: 0.0262 (0.0287)  time: 0.2739  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [38]  [  80/1229]  eta: 0:05:10  lr: 0.000000  loss: 0.4529 (0.4295)  loss_classifier: 0.1517 (0.1540)  loss_box_reg: 0.1520 (0.1469)  loss_objectness: 0.1016 (0.0994)  loss_rpn_box_reg: 0.0262 (0.0293)  time: 0.2718  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [38]  [  90/1229]  eta: 0:05:08  lr: 0.000000  loss: 0.4317 (0.4434)  loss_classifier: 0.1517 (0.1605)  loss_box_reg: 0.1526 (0.1522)  loss_objectness: 0.1126 (0.1010)  loss_rpn_box_reg: 0.0194 (0.0296)  time: 0.2693  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [38]  [ 100/1229]  eta: 0:05:06  lr: 0.000000  loss: 0.4317 (0.4454)  loss_classifier: 0.1516 (0.1608)  loss_box_reg: 0.1454 (0.1538)  loss_objectness: 0.1009 (0.1008)  loss_rpn_box_reg: 0.0202 (0.0300)  time: 0.2762  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [38]  [ 110/1229]  eta: 0:05:04  lr: 0.000000  loss: 0.3577 (0.4348)  loss_classifier: 0.1399 (0.1570)  loss_box_reg: 0.0978 (0.1474)  loss_objectness: 0.0994 (0.1007)  loss_rpn_box_reg: 0.0202 (0.0298)  time: 0.2773  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [38]  [ 120/1229]  eta: 0:05:01  lr: 0.000000  loss: 0.3571 (0.4361)  loss_classifier: 0.1262 (0.1569)  loss_box_reg: 0.0912 (0.1485)  loss_objectness: 0.0748 (0.1007)  loss_rpn_box_reg: 0.0220 (0.0299)  time: 0.2729  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [38]  [ 130/1229]  eta: 0:04:58  lr: 0.000000  loss: 0.3760 (0.4365)  loss_classifier: 0.1538 (0.1572)  loss_box_reg: 0.1233 (0.1491)  loss_objectness: 0.0665 (0.1004)  loss_rpn_box_reg: 0.0240 (0.0299)  time: 0.2714  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [38]  [ 140/1229]  eta: 0:04:56  lr: 0.000000  loss: 0.4455 (0.4377)  loss_classifier: 0.1519 (0.1571)  loss_box_reg: 0.1526 (0.1491)  loss_objectness: 0.0867 (0.1013)  loss_rpn_box_reg: 0.0240 (0.0303)  time: 0.2772  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [38]  [ 150/1229]  eta: 0:04:54  lr: 0.000000  loss: 0.3987 (0.4315)  loss_classifier: 0.1411 (0.1552)  loss_box_reg: 0.1223 (0.1481)  loss_objectness: 0.0818 (0.0989)  loss_rpn_box_reg: 0.0139 (0.0294)  time: 0.2782  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [38]  [ 160/1229]  eta: 0:04:51  lr: 0.000000  loss: 0.3680 (0.4311)  loss_classifier: 0.1281 (0.1550)  loss_box_reg: 0.1267 (0.1485)  loss_objectness: 0.0644 (0.0986)  loss_rpn_box_reg: 0.0175 (0.0291)  time: 0.2718  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [38]  [ 170/1229]  eta: 0:04:48  lr: 0.000000  loss: 0.4196 (0.4396)  loss_classifier: 0.1445 (0.1583)  loss_box_reg: 0.1422 (0.1521)  loss_objectness: 0.0919 (0.0988)  loss_rpn_box_reg: 0.0250 (0.0304)  time: 0.2675  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [38]  [ 180/1229]  eta: 0:04:45  lr: 0.000000  loss: 0.4161 (0.4376)  loss_classifier: 0.1281 (0.1568)  loss_box_reg: 0.1240 (0.1514)  loss_objectness: 0.0880 (0.0992)  loss_rpn_box_reg: 0.0250 (0.0301)  time: 0.2652  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [38]  [ 190/1229]  eta: 0:04:42  lr: 0.000000  loss: 0.3648 (0.4401)  loss_classifier: 0.1278 (0.1571)  loss_box_reg: 0.1362 (0.1542)  loss_objectness: 0.0836 (0.0987)  loss_rpn_box_reg: 0.0213 (0.0301)  time: 0.2654  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [38]  [ 200/1229]  eta: 0:04:38  lr: 0.000000  loss: 0.3648 (0.4378)  loss_classifier: 0.1278 (0.1561)  loss_box_reg: 0.1138 (0.1527)  loss_objectness: 0.0835 (0.0981)  loss_rpn_box_reg: 0.0245 (0.0310)  time: 0.2648  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [38]  [ 210/1229]  eta: 0:04:36  lr: 0.000000  loss: 0.3207 (0.4358)  loss_classifier: 0.1304 (0.1557)  loss_box_reg: 0.1077 (0.1521)  loss_objectness: 0.0835 (0.0976)  loss_rpn_box_reg: 0.0153 (0.0304)  time: 0.2701  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [38]  [ 220/1229]  eta: 0:04:33  lr: 0.000000  loss: 0.3571 (0.4341)  loss_classifier: 0.1332 (0.1550)  loss_box_reg: 0.1001 (0.1505)  loss_objectness: 0.0818 (0.0979)  loss_rpn_box_reg: 0.0153 (0.0308)  time: 0.2711  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [38]  [ 230/1229]  eta: 0:04:30  lr: 0.000000  loss: 0.3571 (0.4323)  loss_classifier: 0.1252 (0.1542)  loss_box_reg: 0.1001 (0.1491)  loss_objectness: 0.0967 (0.0984)  loss_rpn_box_reg: 0.0190 (0.0306)  time: 0.2686  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [38]  [ 240/1229]  eta: 0:04:28  lr: 0.000000  loss: 0.3638 (0.4320)  loss_classifier: 0.1188 (0.1545)  loss_box_reg: 0.1321 (0.1490)  loss_objectness: 0.0967 (0.0983)  loss_rpn_box_reg: 0.0188 (0.0303)  time: 0.2744  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [38]  [ 250/1229]  eta: 0:04:25  lr: 0.000000  loss: 0.3638 (0.4325)  loss_classifier: 0.1188 (0.1538)  loss_box_reg: 0.0873 (0.1481)  loss_objectness: 0.0807 (0.0987)  loss_rpn_box_reg: 0.0195 (0.0320)  time: 0.2725  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [38]  [ 260/1229]  eta: 0:04:23  lr: 0.000000  loss: 0.3570 (0.4324)  loss_classifier: 0.1158 (0.1538)  loss_box_reg: 0.0781 (0.1478)  loss_objectness: 0.0914 (0.0990)  loss_rpn_box_reg: 0.0254 (0.0318)  time: 0.2770  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [38]  [ 270/1229]  eta: 0:04:20  lr: 0.000000  loss: 0.3905 (0.4308)  loss_classifier: 0.1427 (0.1537)  loss_box_reg: 0.0943 (0.1471)  loss_objectness: 0.0914 (0.0987)  loss_rpn_box_reg: 0.0215 (0.0313)  time: 0.2822  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [38]  [ 280/1229]  eta: 0:04:18  lr: 0.000000  loss: 0.3913 (0.4322)  loss_classifier: 0.1427 (0.1543)  loss_box_reg: 0.1249 (0.1479)  loss_objectness: 0.0673 (0.0981)  loss_rpn_box_reg: 0.0194 (0.0318)  time: 0.2792  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [38]  [ 290/1229]  eta: 0:04:15  lr: 0.000000  loss: 0.3615 (0.4313)  loss_classifier: 0.1118 (0.1536)  loss_box_reg: 0.1088 (0.1473)  loss_objectness: 0.0695 (0.0978)  loss_rpn_box_reg: 0.0194 (0.0326)  time: 0.2754  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [38]  [ 300/1229]  eta: 0:04:12  lr: 0.000000  loss: 0.3020 (0.4276)  loss_classifier: 0.1118 (0.1524)  loss_box_reg: 0.1021 (0.1459)  loss_objectness: 0.0667 (0.0972)  loss_rpn_box_reg: 0.0136 (0.0321)  time: 0.2707  data: 0.1315  max mem: 1751\n",
      "Training Epoch: [38]  [ 310/1229]  eta: 0:04:09  lr: 0.000000  loss: 0.3020 (0.4260)  loss_classifier: 0.1202 (0.1517)  loss_box_reg: 0.1033 (0.1454)  loss_objectness: 0.0600 (0.0966)  loss_rpn_box_reg: 0.0152 (0.0323)  time: 0.2687  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [38]  [ 320/1229]  eta: 0:04:07  lr: 0.000000  loss: 0.3400 (0.4265)  loss_classifier: 0.1203 (0.1517)  loss_box_reg: 0.1033 (0.1453)  loss_objectness: 0.0618 (0.0967)  loss_rpn_box_reg: 0.0256 (0.0328)  time: 0.2755  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [38]  [ 330/1229]  eta: 0:04:04  lr: 0.000000  loss: 0.3080 (0.4243)  loss_classifier: 0.1154 (0.1513)  loss_box_reg: 0.1030 (0.1446)  loss_objectness: 0.0596 (0.0960)  loss_rpn_box_reg: 0.0180 (0.0325)  time: 0.2788  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [38]  [ 340/1229]  eta: 0:04:02  lr: 0.000000  loss: 0.3577 (0.4258)  loss_classifier: 0.1449 (0.1522)  loss_box_reg: 0.1052 (0.1451)  loss_objectness: 0.0722 (0.0962)  loss_rpn_box_reg: 0.0148 (0.0323)  time: 0.2719  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [38]  [ 350/1229]  eta: 0:03:59  lr: 0.000000  loss: 0.3698 (0.4244)  loss_classifier: 0.1501 (0.1517)  loss_box_reg: 0.1028 (0.1438)  loss_objectness: 0.0919 (0.0962)  loss_rpn_box_reg: 0.0148 (0.0327)  time: 0.2732  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [38]  [ 360/1229]  eta: 0:03:56  lr: 0.000000  loss: 0.3698 (0.4268)  loss_classifier: 0.1267 (0.1524)  loss_box_reg: 0.0951 (0.1443)  loss_objectness: 0.1144 (0.0974)  loss_rpn_box_reg: 0.0210 (0.0328)  time: 0.2783  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [38]  [ 370/1229]  eta: 0:03:54  lr: 0.000000  loss: 0.3851 (0.4259)  loss_classifier: 0.1389 (0.1519)  loss_box_reg: 0.1206 (0.1443)  loss_objectness: 0.0970 (0.0970)  loss_rpn_box_reg: 0.0234 (0.0327)  time: 0.2742  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [38]  [ 380/1229]  eta: 0:03:51  lr: 0.000000  loss: 0.3812 (0.4260)  loss_classifier: 0.1324 (0.1518)  loss_box_reg: 0.1206 (0.1446)  loss_objectness: 0.0821 (0.0968)  loss_rpn_box_reg: 0.0220 (0.0327)  time: 0.2711  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [38]  [ 390/1229]  eta: 0:03:48  lr: 0.000000  loss: 0.4059 (0.4274)  loss_classifier: 0.1638 (0.1525)  loss_box_reg: 0.1306 (0.1450)  loss_objectness: 0.1039 (0.0974)  loss_rpn_box_reg: 0.0238 (0.0325)  time: 0.2754  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [38]  [ 400/1229]  eta: 0:03:45  lr: 0.000000  loss: 0.4887 (0.4305)  loss_classifier: 0.1833 (0.1533)  loss_box_reg: 0.1454 (0.1465)  loss_objectness: 0.1046 (0.0975)  loss_rpn_box_reg: 0.0288 (0.0332)  time: 0.2697  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [38]  [ 410/1229]  eta: 0:03:43  lr: 0.000000  loss: 0.4020 (0.4299)  loss_classifier: 0.1372 (0.1533)  loss_box_reg: 0.1029 (0.1461)  loss_objectness: 0.0916 (0.0975)  loss_rpn_box_reg: 0.0216 (0.0331)  time: 0.2700  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [38]  [ 420/1229]  eta: 0:03:40  lr: 0.000000  loss: 0.3882 (0.4318)  loss_classifier: 0.1323 (0.1537)  loss_box_reg: 0.1008 (0.1466)  loss_objectness: 0.0988 (0.0980)  loss_rpn_box_reg: 0.0191 (0.0335)  time: 0.2692  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [38]  [ 430/1229]  eta: 0:03:37  lr: 0.000000  loss: 0.4417 (0.4329)  loss_classifier: 0.1320 (0.1541)  loss_box_reg: 0.1375 (0.1464)  loss_objectness: 0.1083 (0.0987)  loss_rpn_box_reg: 0.0201 (0.0337)  time: 0.2650  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [38]  [ 440/1229]  eta: 0:03:34  lr: 0.000000  loss: 0.4421 (0.4342)  loss_classifier: 0.1447 (0.1546)  loss_box_reg: 0.1440 (0.1471)  loss_objectness: 0.1014 (0.0990)  loss_rpn_box_reg: 0.0179 (0.0336)  time: 0.2724  data: 0.1303  max mem: 1751\n",
      "Training Epoch: [38]  [ 450/1229]  eta: 0:03:32  lr: 0.000000  loss: 0.4222 (0.4326)  loss_classifier: 0.1356 (0.1539)  loss_box_reg: 0.1107 (0.1460)  loss_objectness: 0.0854 (0.0990)  loss_rpn_box_reg: 0.0311 (0.0337)  time: 0.2742  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [38]  [ 460/1229]  eta: 0:03:29  lr: 0.000000  loss: 0.3207 (0.4308)  loss_classifier: 0.1078 (0.1533)  loss_box_reg: 0.0896 (0.1454)  loss_objectness: 0.0741 (0.0987)  loss_rpn_box_reg: 0.0207 (0.0334)  time: 0.2687  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [38]  [ 470/1229]  eta: 0:03:26  lr: 0.000000  loss: 0.3929 (0.4327)  loss_classifier: 0.1405 (0.1539)  loss_box_reg: 0.1594 (0.1462)  loss_objectness: 0.0769 (0.0989)  loss_rpn_box_reg: 0.0171 (0.0338)  time: 0.2706  data: 0.1306  max mem: 1751\n",
      "Training Epoch: [38]  [ 480/1229]  eta: 0:03:23  lr: 0.000000  loss: 0.4222 (0.4333)  loss_classifier: 0.1416 (0.1540)  loss_box_reg: 0.1594 (0.1461)  loss_objectness: 0.1035 (0.0992)  loss_rpn_box_reg: 0.0183 (0.0339)  time: 0.2738  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [38]  [ 490/1229]  eta: 0:03:21  lr: 0.000000  loss: 0.4222 (0.4336)  loss_classifier: 0.1544 (0.1543)  loss_box_reg: 0.1320 (0.1460)  loss_objectness: 0.1033 (0.0995)  loss_rpn_box_reg: 0.0230 (0.0337)  time: 0.2715  data: 0.1309  max mem: 1751\n",
      "Training Epoch: [38]  [ 500/1229]  eta: 0:03:18  lr: 0.000000  loss: 0.3205 (0.4310)  loss_classifier: 0.1199 (0.1536)  loss_box_reg: 0.1030 (0.1452)  loss_objectness: 0.0839 (0.0989)  loss_rpn_box_reg: 0.0148 (0.0333)  time: 0.2723  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [38]  [ 510/1229]  eta: 0:03:15  lr: 0.000000  loss: 0.3177 (0.4331)  loss_classifier: 0.1233 (0.1543)  loss_box_reg: 0.1010 (0.1468)  loss_objectness: 0.0839 (0.0989)  loss_rpn_box_reg: 0.0179 (0.0332)  time: 0.2790  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [38]  [ 520/1229]  eta: 0:03:13  lr: 0.000000  loss: 0.3663 (0.4327)  loss_classifier: 0.1376 (0.1541)  loss_box_reg: 0.1344 (0.1466)  loss_objectness: 0.0934 (0.0991)  loss_rpn_box_reg: 0.0181 (0.0329)  time: 0.2754  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [38]  [ 530/1229]  eta: 0:03:10  lr: 0.000000  loss: 0.2659 (0.4323)  loss_classifier: 0.1118 (0.1540)  loss_box_reg: 0.0838 (0.1461)  loss_objectness: 0.0747 (0.0991)  loss_rpn_box_reg: 0.0105 (0.0331)  time: 0.2712  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [38]  [ 540/1229]  eta: 0:03:07  lr: 0.000000  loss: 0.2792 (0.4317)  loss_classifier: 0.1118 (0.1538)  loss_box_reg: 0.0819 (0.1455)  loss_objectness: 0.0766 (0.0993)  loss_rpn_box_reg: 0.0102 (0.0330)  time: 0.2744  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [38]  [ 550/1229]  eta: 0:03:04  lr: 0.000000  loss: 0.3914 (0.4329)  loss_classifier: 0.1366 (0.1542)  loss_box_reg: 0.1356 (0.1463)  loss_objectness: 0.0846 (0.0995)  loss_rpn_box_reg: 0.0225 (0.0329)  time: 0.2688  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [38]  [ 560/1229]  eta: 0:03:02  lr: 0.000000  loss: 0.4623 (0.4336)  loss_classifier: 0.1566 (0.1545)  loss_box_reg: 0.1630 (0.1462)  loss_objectness: 0.0768 (0.0996)  loss_rpn_box_reg: 0.0240 (0.0333)  time: 0.2713  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [38]  [ 570/1229]  eta: 0:02:59  lr: 0.000000  loss: 0.3163 (0.4319)  loss_classifier: 0.1016 (0.1540)  loss_box_reg: 0.0829 (0.1455)  loss_objectness: 0.0734 (0.0993)  loss_rpn_box_reg: 0.0227 (0.0331)  time: 0.2786  data: 0.1373  max mem: 1751\n",
      "Training Epoch: [38]  [ 580/1229]  eta: 0:02:57  lr: 0.000000  loss: 0.3382 (0.4318)  loss_classifier: 0.1088 (0.1541)  loss_box_reg: 0.0892 (0.1455)  loss_objectness: 0.0787 (0.0991)  loss_rpn_box_reg: 0.0227 (0.0331)  time: 0.2882  data: 0.1376  max mem: 1751\n",
      "Training Epoch: [38]  [ 590/1229]  eta: 0:02:54  lr: 0.000000  loss: 0.3947 (0.4326)  loss_classifier: 0.1511 (0.1544)  loss_box_reg: 0.1176 (0.1456)  loss_objectness: 0.0969 (0.0996)  loss_rpn_box_reg: 0.0226 (0.0330)  time: 0.2869  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [38]  [ 600/1229]  eta: 0:02:51  lr: 0.000000  loss: 0.3396 (0.4318)  loss_classifier: 0.1196 (0.1540)  loss_box_reg: 0.1190 (0.1454)  loss_objectness: 0.0929 (0.0996)  loss_rpn_box_reg: 0.0145 (0.0328)  time: 0.2699  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [38]  [ 610/1229]  eta: 0:02:48  lr: 0.000000  loss: 0.4442 (0.4334)  loss_classifier: 0.1418 (0.1547)  loss_box_reg: 0.1315 (0.1461)  loss_objectness: 0.0860 (0.0998)  loss_rpn_box_reg: 0.0137 (0.0328)  time: 0.2668  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [38]  [ 620/1229]  eta: 0:02:46  lr: 0.000000  loss: 0.4672 (0.4340)  loss_classifier: 0.1722 (0.1548)  loss_box_reg: 0.1478 (0.1466)  loss_objectness: 0.1065 (0.0997)  loss_rpn_box_reg: 0.0251 (0.0329)  time: 0.2762  data: 0.1367  max mem: 1751\n",
      "Training Epoch: [38]  [ 630/1229]  eta: 0:02:43  lr: 0.000000  loss: 0.4307 (0.4338)  loss_classifier: 0.1561 (0.1547)  loss_box_reg: 0.1350 (0.1465)  loss_objectness: 0.0805 (0.0993)  loss_rpn_box_reg: 0.0311 (0.0332)  time: 0.2790  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [38]  [ 640/1229]  eta: 0:02:40  lr: 0.000000  loss: 0.4593 (0.4346)  loss_classifier: 0.1339 (0.1551)  loss_box_reg: 0.1309 (0.1464)  loss_objectness: 0.0745 (0.0997)  loss_rpn_box_reg: 0.0283 (0.0335)  time: 0.2798  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [38]  [ 650/1229]  eta: 0:02:38  lr: 0.000000  loss: 0.4752 (0.4367)  loss_classifier: 0.1715 (0.1559)  loss_box_reg: 0.1433 (0.1475)  loss_objectness: 0.0809 (0.0999)  loss_rpn_box_reg: 0.0283 (0.0334)  time: 0.2755  data: 0.1358  max mem: 1751\n",
      "Training Epoch: [38]  [ 660/1229]  eta: 0:02:35  lr: 0.000000  loss: 0.4354 (0.4373)  loss_classifier: 0.1707 (0.1562)  loss_box_reg: 0.1836 (0.1479)  loss_objectness: 0.0737 (0.0999)  loss_rpn_box_reg: 0.0307 (0.0333)  time: 0.2692  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [38]  [ 670/1229]  eta: 0:02:32  lr: 0.000000  loss: 0.3564 (0.4362)  loss_classifier: 0.1313 (0.1558)  loss_box_reg: 0.1143 (0.1472)  loss_objectness: 0.0692 (0.0999)  loss_rpn_box_reg: 0.0294 (0.0333)  time: 0.2688  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [38]  [ 680/1229]  eta: 0:02:29  lr: 0.000000  loss: 0.3912 (0.4352)  loss_classifier: 0.1307 (0.1553)  loss_box_reg: 0.1191 (0.1467)  loss_objectness: 0.0752 (0.0998)  loss_rpn_box_reg: 0.0129 (0.0334)  time: 0.2728  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [38]  [ 690/1229]  eta: 0:02:27  lr: 0.000000  loss: 0.3996 (0.4355)  loss_classifier: 0.1399 (0.1555)  loss_box_reg: 0.1329 (0.1467)  loss_objectness: 0.0925 (0.0999)  loss_rpn_box_reg: 0.0172 (0.0334)  time: 0.2808  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [38]  [ 700/1229]  eta: 0:02:24  lr: 0.000000  loss: 0.3988 (0.4348)  loss_classifier: 0.1399 (0.1551)  loss_box_reg: 0.1095 (0.1464)  loss_objectness: 0.0868 (0.0999)  loss_rpn_box_reg: 0.0245 (0.0334)  time: 0.2789  data: 0.1377  max mem: 1751\n",
      "Training Epoch: [38]  [ 710/1229]  eta: 0:02:21  lr: 0.000000  loss: 0.3353 (0.4352)  loss_classifier: 0.1259 (0.1553)  loss_box_reg: 0.1095 (0.1467)  loss_objectness: 0.0854 (0.0999)  loss_rpn_box_reg: 0.0264 (0.0334)  time: 0.2751  data: 0.1401  max mem: 1751\n",
      "Training Epoch: [38]  [ 720/1229]  eta: 0:02:19  lr: 0.000000  loss: 0.3571 (0.4343)  loss_classifier: 0.1399 (0.1553)  loss_box_reg: 0.0995 (0.1463)  loss_objectness: 0.0819 (0.0995)  loss_rpn_box_reg: 0.0186 (0.0332)  time: 0.2796  data: 0.1371  max mem: 1751\n",
      "Training Epoch: [38]  [ 730/1229]  eta: 0:02:16  lr: 0.000000  loss: 0.3222 (0.4340)  loss_classifier: 0.1284 (0.1551)  loss_box_reg: 0.0958 (0.1463)  loss_objectness: 0.0640 (0.0995)  loss_rpn_box_reg: 0.0116 (0.0332)  time: 0.2756  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [38]  [ 740/1229]  eta: 0:02:13  lr: 0.000000  loss: 0.3013 (0.4345)  loss_classifier: 0.1243 (0.1553)  loss_box_reg: 0.1006 (0.1469)  loss_objectness: 0.0873 (0.0993)  loss_rpn_box_reg: 0.0111 (0.0330)  time: 0.2732  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [38]  [ 750/1229]  eta: 0:02:10  lr: 0.000000  loss: 0.3318 (0.4339)  loss_classifier: 0.1259 (0.1551)  loss_box_reg: 0.1265 (0.1468)  loss_objectness: 0.0707 (0.0991)  loss_rpn_box_reg: 0.0169 (0.0329)  time: 0.2746  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [38]  [ 760/1229]  eta: 0:02:08  lr: 0.000000  loss: 0.3318 (0.4339)  loss_classifier: 0.1259 (0.1552)  loss_box_reg: 0.1254 (0.1472)  loss_objectness: 0.0614 (0.0988)  loss_rpn_box_reg: 0.0248 (0.0327)  time: 0.2732  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [38]  [ 770/1229]  eta: 0:02:05  lr: 0.000000  loss: 0.3273 (0.4338)  loss_classifier: 0.1144 (0.1551)  loss_box_reg: 0.1207 (0.1472)  loss_objectness: 0.0655 (0.0989)  loss_rpn_box_reg: 0.0188 (0.0326)  time: 0.2725  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [38]  [ 780/1229]  eta: 0:02:02  lr: 0.000000  loss: 0.3187 (0.4344)  loss_classifier: 0.1144 (0.1554)  loss_box_reg: 0.0934 (0.1475)  loss_objectness: 0.0837 (0.0989)  loss_rpn_box_reg: 0.0188 (0.0326)  time: 0.2778  data: 0.1345  max mem: 1751\n",
      "Training Epoch: [38]  [ 790/1229]  eta: 0:02:00  lr: 0.000000  loss: 0.3755 (0.4345)  loss_classifier: 0.1455 (0.1554)  loss_box_reg: 0.1046 (0.1474)  loss_objectness: 0.0912 (0.0990)  loss_rpn_box_reg: 0.0134 (0.0327)  time: 0.2774  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [38]  [ 800/1229]  eta: 0:01:57  lr: 0.000000  loss: 0.4271 (0.4357)  loss_classifier: 0.1510 (0.1558)  loss_box_reg: 0.1448 (0.1481)  loss_objectness: 0.0926 (0.0989)  loss_rpn_box_reg: 0.0189 (0.0329)  time: 0.2735  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [38]  [ 810/1229]  eta: 0:01:54  lr: 0.000000  loss: 0.4143 (0.4347)  loss_classifier: 0.1434 (0.1554)  loss_box_reg: 0.1125 (0.1478)  loss_objectness: 0.0839 (0.0987)  loss_rpn_box_reg: 0.0287 (0.0328)  time: 0.2749  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [38]  [ 820/1229]  eta: 0:01:51  lr: 0.000000  loss: 0.3143 (0.4343)  loss_classifier: 0.1401 (0.1553)  loss_box_reg: 0.1119 (0.1479)  loss_objectness: 0.0807 (0.0985)  loss_rpn_box_reg: 0.0213 (0.0326)  time: 0.2781  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [38]  [ 830/1229]  eta: 0:01:49  lr: 0.000000  loss: 0.2992 (0.4340)  loss_classifier: 0.1403 (0.1552)  loss_box_reg: 0.0900 (0.1478)  loss_objectness: 0.0859 (0.0985)  loss_rpn_box_reg: 0.0213 (0.0326)  time: 0.2848  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [38]  [ 840/1229]  eta: 0:01:46  lr: 0.000000  loss: 0.4105 (0.4350)  loss_classifier: 0.1395 (0.1554)  loss_box_reg: 0.1583 (0.1483)  loss_objectness: 0.0859 (0.0986)  loss_rpn_box_reg: 0.0224 (0.0327)  time: 0.2770  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [38]  [ 850/1229]  eta: 0:01:43  lr: 0.000000  loss: 0.4499 (0.4350)  loss_classifier: 0.1501 (0.1555)  loss_box_reg: 0.1639 (0.1482)  loss_objectness: 0.0831 (0.0985)  loss_rpn_box_reg: 0.0246 (0.0328)  time: 0.2745  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [38]  [ 860/1229]  eta: 0:01:41  lr: 0.000000  loss: 0.4120 (0.4350)  loss_classifier: 0.1501 (0.1556)  loss_box_reg: 0.1289 (0.1482)  loss_objectness: 0.0804 (0.0985)  loss_rpn_box_reg: 0.0247 (0.0328)  time: 0.2767  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [38]  [ 870/1229]  eta: 0:01:38  lr: 0.000000  loss: 0.3323 (0.4350)  loss_classifier: 0.1301 (0.1555)  loss_box_reg: 0.1288 (0.1481)  loss_objectness: 0.0743 (0.0984)  loss_rpn_box_reg: 0.0136 (0.0330)  time: 0.2755  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [38]  [ 880/1229]  eta: 0:01:35  lr: 0.000000  loss: 0.5082 (0.4363)  loss_classifier: 0.1505 (0.1557)  loss_box_reg: 0.1288 (0.1486)  loss_objectness: 0.0828 (0.0987)  loss_rpn_box_reg: 0.0261 (0.0333)  time: 0.2780  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [38]  [ 890/1229]  eta: 0:01:32  lr: 0.000000  loss: 0.5082 (0.4363)  loss_classifier: 0.1713 (0.1556)  loss_box_reg: 0.0988 (0.1484)  loss_objectness: 0.1030 (0.0988)  loss_rpn_box_reg: 0.0329 (0.0335)  time: 0.2745  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [38]  [ 900/1229]  eta: 0:01:30  lr: 0.000000  loss: 0.3358 (0.4370)  loss_classifier: 0.0986 (0.1558)  loss_box_reg: 0.1063 (0.1488)  loss_objectness: 0.1030 (0.0989)  loss_rpn_box_reg: 0.0198 (0.0335)  time: 0.2751  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [38]  [ 910/1229]  eta: 0:01:27  lr: 0.000000  loss: 0.3417 (0.4362)  loss_classifier: 0.1084 (0.1555)  loss_box_reg: 0.1063 (0.1484)  loss_objectness: 0.0730 (0.0988)  loss_rpn_box_reg: 0.0240 (0.0335)  time: 0.2738  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [38]  [ 920/1229]  eta: 0:01:24  lr: 0.000000  loss: 0.4110 (0.4372)  loss_classifier: 0.1572 (0.1559)  loss_box_reg: 0.1013 (0.1487)  loss_objectness: 0.0709 (0.0990)  loss_rpn_box_reg: 0.0278 (0.0336)  time: 0.2722  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [38]  [ 930/1229]  eta: 0:01:21  lr: 0.000000  loss: 0.4405 (0.4364)  loss_classifier: 0.1572 (0.1556)  loss_box_reg: 0.1095 (0.1485)  loss_objectness: 0.0729 (0.0987)  loss_rpn_box_reg: 0.0245 (0.0335)  time: 0.2736  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [38]  [ 940/1229]  eta: 0:01:19  lr: 0.000000  loss: 0.3774 (0.4375)  loss_classifier: 0.1273 (0.1560)  loss_box_reg: 0.1095 (0.1489)  loss_objectness: 0.0876 (0.0989)  loss_rpn_box_reg: 0.0262 (0.0338)  time: 0.2743  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [38]  [ 950/1229]  eta: 0:01:16  lr: 0.000000  loss: 0.3461 (0.4364)  loss_classifier: 0.1249 (0.1555)  loss_box_reg: 0.1056 (0.1483)  loss_objectness: 0.0876 (0.0989)  loss_rpn_box_reg: 0.0330 (0.0338)  time: 0.2761  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [38]  [ 960/1229]  eta: 0:01:13  lr: 0.000000  loss: 0.3735 (0.4368)  loss_classifier: 0.1626 (0.1556)  loss_box_reg: 0.1056 (0.1484)  loss_objectness: 0.0768 (0.0990)  loss_rpn_box_reg: 0.0236 (0.0338)  time: 0.2730  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [38]  [ 970/1229]  eta: 0:01:10  lr: 0.000000  loss: 0.4358 (0.4365)  loss_classifier: 0.1517 (0.1554)  loss_box_reg: 0.1170 (0.1480)  loss_objectness: 0.0953 (0.0991)  loss_rpn_box_reg: 0.0286 (0.0340)  time: 0.2666  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [38]  [ 980/1229]  eta: 0:01:08  lr: 0.000000  loss: 0.3794 (0.4362)  loss_classifier: 0.1362 (0.1554)  loss_box_reg: 0.0956 (0.1479)  loss_objectness: 0.0876 (0.0990)  loss_rpn_box_reg: 0.0172 (0.0339)  time: 0.2672  data: 0.1323  max mem: 1751\n",
      "Training Epoch: [38]  [ 990/1229]  eta: 0:01:05  lr: 0.000000  loss: 0.3716 (0.4355)  loss_classifier: 0.1334 (0.1552)  loss_box_reg: 0.1003 (0.1477)  loss_objectness: 0.0608 (0.0988)  loss_rpn_box_reg: 0.0227 (0.0339)  time: 0.2746  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [38]  [1000/1229]  eta: 0:01:02  lr: 0.000000  loss: 0.3112 (0.4346)  loss_classifier: 0.1163 (0.1549)  loss_box_reg: 0.0972 (0.1472)  loss_objectness: 0.0606 (0.0987)  loss_rpn_box_reg: 0.0220 (0.0338)  time: 0.2703  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [38]  [1010/1229]  eta: 0:00:59  lr: 0.000000  loss: 0.3121 (0.4334)  loss_classifier: 0.1200 (0.1545)  loss_box_reg: 0.0929 (0.1468)  loss_objectness: 0.0586 (0.0984)  loss_rpn_box_reg: 0.0163 (0.0336)  time: 0.2703  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [38]  [1020/1229]  eta: 0:00:57  lr: 0.000000  loss: 0.3207 (0.4329)  loss_classifier: 0.1204 (0.1544)  loss_box_reg: 0.0981 (0.1463)  loss_objectness: 0.0761 (0.0986)  loss_rpn_box_reg: 0.0204 (0.0336)  time: 0.2761  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [38]  [1030/1229]  eta: 0:00:54  lr: 0.000000  loss: 0.4071 (0.4338)  loss_classifier: 0.1516 (0.1547)  loss_box_reg: 0.1238 (0.1467)  loss_objectness: 0.0993 (0.0986)  loss_rpn_box_reg: 0.0257 (0.0338)  time: 0.2751  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [38]  [1040/1229]  eta: 0:00:51  lr: 0.000000  loss: 0.3980 (0.4338)  loss_classifier: 0.1516 (0.1545)  loss_box_reg: 0.1509 (0.1465)  loss_objectness: 0.0978 (0.0989)  loss_rpn_box_reg: 0.0279 (0.0340)  time: 0.2696  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [38]  [1050/1229]  eta: 0:00:48  lr: 0.000000  loss: 0.3336 (0.4333)  loss_classifier: 0.1152 (0.1543)  loss_box_reg: 0.0941 (0.1462)  loss_objectness: 0.0973 (0.0989)  loss_rpn_box_reg: 0.0272 (0.0339)  time: 0.2660  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [38]  [1060/1229]  eta: 0:00:46  lr: 0.000000  loss: 0.4097 (0.4338)  loss_classifier: 0.1531 (0.1545)  loss_box_reg: 0.1219 (0.1461)  loss_objectness: 0.0973 (0.0992)  loss_rpn_box_reg: 0.0241 (0.0339)  time: 0.2722  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [38]  [1070/1229]  eta: 0:00:43  lr: 0.000000  loss: 0.4229 (0.4340)  loss_classifier: 0.1620 (0.1547)  loss_box_reg: 0.1027 (0.1461)  loss_objectness: 0.0977 (0.0992)  loss_rpn_box_reg: 0.0261 (0.0340)  time: 0.2726  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [38]  [1080/1229]  eta: 0:00:40  lr: 0.000000  loss: 0.3640 (0.4335)  loss_classifier: 0.1360 (0.1546)  loss_box_reg: 0.1140 (0.1459)  loss_objectness: 0.0876 (0.0992)  loss_rpn_box_reg: 0.0235 (0.0339)  time: 0.2720  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [38]  [1090/1229]  eta: 0:00:38  lr: 0.000000  loss: 0.3640 (0.4334)  loss_classifier: 0.1188 (0.1545)  loss_box_reg: 0.1140 (0.1459)  loss_objectness: 0.0900 (0.0992)  loss_rpn_box_reg: 0.0193 (0.0338)  time: 0.2699  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [38]  [1100/1229]  eta: 0:00:35  lr: 0.000000  loss: 0.4271 (0.4339)  loss_classifier: 0.1527 (0.1547)  loss_box_reg: 0.1311 (0.1461)  loss_objectness: 0.0900 (0.0993)  loss_rpn_box_reg: 0.0254 (0.0339)  time: 0.2726  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [38]  [1110/1229]  eta: 0:00:32  lr: 0.000000  loss: 0.4576 (0.4338)  loss_classifier: 0.1603 (0.1547)  loss_box_reg: 0.1212 (0.1460)  loss_objectness: 0.0906 (0.0993)  loss_rpn_box_reg: 0.0241 (0.0337)  time: 0.2776  data: 0.1368  max mem: 1751\n",
      "Training Epoch: [38]  [1120/1229]  eta: 0:00:29  lr: 0.000000  loss: 0.3795 (0.4331)  loss_classifier: 0.1510 (0.1546)  loss_box_reg: 0.0966 (0.1458)  loss_objectness: 0.0812 (0.0991)  loss_rpn_box_reg: 0.0202 (0.0336)  time: 0.2781  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [38]  [1130/1229]  eta: 0:00:27  lr: 0.000000  loss: 0.3681 (0.4339)  loss_classifier: 0.1439 (0.1548)  loss_box_reg: 0.1089 (0.1461)  loss_objectness: 0.0748 (0.0991)  loss_rpn_box_reg: 0.0210 (0.0339)  time: 0.2735  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [38]  [1140/1229]  eta: 0:00:24  lr: 0.000000  loss: 0.3681 (0.4334)  loss_classifier: 0.1334 (0.1546)  loss_box_reg: 0.1089 (0.1458)  loss_objectness: 0.0931 (0.0991)  loss_rpn_box_reg: 0.0266 (0.0339)  time: 0.2680  data: 0.1316  max mem: 1751\n",
      "Training Epoch: [38]  [1150/1229]  eta: 0:00:21  lr: 0.000000  loss: 0.4421 (0.4343)  loss_classifier: 0.1707 (0.1549)  loss_box_reg: 0.1487 (0.1463)  loss_objectness: 0.1028 (0.0993)  loss_rpn_box_reg: 0.0258 (0.0339)  time: 0.2777  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [38]  [1160/1229]  eta: 0:00:18  lr: 0.000000  loss: 0.4796 (0.4358)  loss_classifier: 0.1779 (0.1553)  loss_box_reg: 0.2029 (0.1468)  loss_objectness: 0.1072 (0.0995)  loss_rpn_box_reg: 0.0310 (0.0341)  time: 0.2820  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [38]  [1170/1229]  eta: 0:00:16  lr: 0.000000  loss: 0.4632 (0.4360)  loss_classifier: 0.1731 (0.1554)  loss_box_reg: 0.1407 (0.1469)  loss_objectness: 0.1154 (0.0997)  loss_rpn_box_reg: 0.0291 (0.0341)  time: 0.2780  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [38]  [1180/1229]  eta: 0:00:13  lr: 0.000000  loss: 0.3852 (0.4360)  loss_classifier: 0.1562 (0.1554)  loss_box_reg: 0.1305 (0.1468)  loss_objectness: 0.1100 (0.0997)  loss_rpn_box_reg: 0.0231 (0.0340)  time: 0.2776  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [38]  [1190/1229]  eta: 0:00:10  lr: 0.000000  loss: 0.3511 (0.4355)  loss_classifier: 0.1192 (0.1552)  loss_box_reg: 0.0948 (0.1465)  loss_objectness: 0.0836 (0.0997)  loss_rpn_box_reg: 0.0178 (0.0340)  time: 0.2778  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [38]  [1200/1229]  eta: 0:00:07  lr: 0.000000  loss: 0.3026 (0.4355)  loss_classifier: 0.1058 (0.1552)  loss_box_reg: 0.0948 (0.1466)  loss_objectness: 0.0836 (0.0997)  loss_rpn_box_reg: 0.0160 (0.0340)  time: 0.2793  data: 0.1324  max mem: 1751\n",
      "Training Epoch: [38]  [1210/1229]  eta: 0:00:05  lr: 0.000000  loss: 0.3026 (0.4347)  loss_classifier: 0.1149 (0.1548)  loss_box_reg: 0.0987 (0.1462)  loss_objectness: 0.0801 (0.0996)  loss_rpn_box_reg: 0.0160 (0.0340)  time: 0.2774  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [38]  [1220/1229]  eta: 0:00:02  lr: 0.000000  loss: 0.3305 (0.4344)  loss_classifier: 0.0977 (0.1546)  loss_box_reg: 0.0820 (0.1463)  loss_objectness: 0.0797 (0.0995)  loss_rpn_box_reg: 0.0257 (0.0339)  time: 0.2752  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [38]  [1228/1229]  eta: 0:00:00  lr: 0.000000  loss: 0.3429 (0.4344)  loss_classifier: 0.1088 (0.1546)  loss_box_reg: 0.1070 (0.1464)  loss_objectness: 0.0882 (0.0994)  loss_rpn_box_reg: 0.0249 (0.0339)  time: 0.2761  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [38] Total time: 0:05:36 (0.2739 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:21  model_time: 0.2290 (0.2290)  evaluator_time: 0.0020 (0.0020)  time: 0.2630  data: 0.0300  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0800 (0.0815)  evaluator_time: 0.0040 (0.0085)  time: 0.1272  data: 0.0360  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0830 (0.0808)  evaluator_time: 0.0030 (0.0078)  time: 0.1203  data: 0.0307  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0740 (0.0801)  evaluator_time: 0.0040 (0.0076)  time: 0.1197  data: 0.0354  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0720 (0.0800)  evaluator_time: 0.0030 (0.0075)  time: 0.1217  data: 0.0388  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1240 s / it)\n",
      "Averaged stats: model_time: 0.0720 (0.0800)  evaluator_time: 0.0030 (0.0075)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [38]  [  0/308]  eta: 0:00:37  lr: 0.000000  loss: 0.1678 (0.1678)  loss_classifier: 0.0585 (0.0585)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0295 (0.0295)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1230  data: 0.0290  max mem: 1751\n",
      "Testing Epoch: [38]  [100/308]  eta: 0:00:28  lr: 0.000000  loss: 0.3111 (0.4814)  loss_classifier: 0.1340 (0.1545)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0542 (0.1025)  loss_rpn_box_reg: 0.0186 (0.0521)  time: 0.1390  data: 0.0378  max mem: 1751\n",
      "Testing Epoch: [38]  [200/308]  eta: 0:00:14  lr: 0.000000  loss: 0.3591 (0.4569)  loss_classifier: 0.1381 (0.1491)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0633 (0.0954)  loss_rpn_box_reg: 0.0197 (0.0492)  time: 0.1386  data: 0.0326  max mem: 1751\n",
      "Testing Epoch: [38]  [300/308]  eta: 0:00:01  lr: 0.000000  loss: 0.4687 (0.4532)  loss_classifier: 0.1558 (0.1493)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0769 (0.0923)  loss_rpn_box_reg: 0.0265 (0.0476)  time: 0.1338  data: 0.0382  max mem: 1751\n",
      "Testing Epoch: [38]  [307/308]  eta: 0:00:00  lr: 0.000000  loss: 0.4687 (0.4534)  loss_classifier: 0.1860 (0.1495)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0785 (0.0924)  loss_rpn_box_reg: 0.0271 (0.0471)  time: 0.1322  data: 0.0366  max mem: 1751\n",
      "Testing Epoch: [38] Total time: 0:00:42 (0.1373 s / it)\n",
      "Training Epoch: [39]  [   0/1229]  eta: 0:05:53  lr: 0.000000  loss: 0.5168 (0.5168)  loss_classifier: 0.1875 (0.1875)  loss_box_reg: 0.1609 (0.1609)  loss_objectness: 0.1055 (0.1055)  loss_rpn_box_reg: 0.0629 (0.0629)  time: 0.2880  data: 0.1280  max mem: 1751\n",
      "Training Epoch: [39]  [  10/1229]  eta: 0:05:31  lr: 0.000000  loss: 0.3379 (0.3679)  loss_classifier: 0.1465 (0.1365)  loss_box_reg: 0.1036 (0.1167)  loss_objectness: 0.0874 (0.0927)  loss_rpn_box_reg: 0.0183 (0.0220)  time: 0.2718  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [39]  [  20/1229]  eta: 0:05:28  lr: 0.000000  loss: 0.3547 (0.3830)  loss_classifier: 0.1334 (0.1407)  loss_box_reg: 0.1187 (0.1225)  loss_objectness: 0.0874 (0.0983)  loss_rpn_box_reg: 0.0157 (0.0215)  time: 0.2712  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [39]  [  30/1229]  eta: 0:05:24  lr: 0.000000  loss: 0.3828 (0.3793)  loss_classifier: 0.1334 (0.1394)  loss_box_reg: 0.1250 (0.1209)  loss_objectness: 0.0930 (0.0953)  loss_rpn_box_reg: 0.0175 (0.0236)  time: 0.2694  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [39]  [  40/1229]  eta: 0:05:21  lr: 0.000000  loss: 0.3958 (0.3985)  loss_classifier: 0.1398 (0.1431)  loss_box_reg: 0.1250 (0.1260)  loss_objectness: 0.0843 (0.1018)  loss_rpn_box_reg: 0.0196 (0.0277)  time: 0.2682  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [39]  [  50/1229]  eta: 0:05:20  lr: 0.000000  loss: 0.4046 (0.4000)  loss_classifier: 0.1477 (0.1426)  loss_box_reg: 0.1207 (0.1275)  loss_objectness: 0.0728 (0.0988)  loss_rpn_box_reg: 0.0196 (0.0311)  time: 0.2738  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [39]  [  60/1229]  eta: 0:05:19  lr: 0.000000  loss: 0.3705 (0.4061)  loss_classifier: 0.1216 (0.1442)  loss_box_reg: 0.1135 (0.1281)  loss_objectness: 0.0834 (0.1016)  loss_rpn_box_reg: 0.0292 (0.0323)  time: 0.2803  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [39]  [  70/1229]  eta: 0:05:16  lr: 0.000000  loss: 0.4135 (0.4118)  loss_classifier: 0.1260 (0.1469)  loss_box_reg: 0.1372 (0.1341)  loss_objectness: 0.0944 (0.1006)  loss_rpn_box_reg: 0.0209 (0.0302)  time: 0.2770  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [39]  [  80/1229]  eta: 0:05:14  lr: 0.000000  loss: 0.4663 (0.4224)  loss_classifier: 0.1428 (0.1497)  loss_box_reg: 0.1390 (0.1400)  loss_objectness: 0.0871 (0.1014)  loss_rpn_box_reg: 0.0209 (0.0313)  time: 0.2727  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [39]  [  90/1229]  eta: 0:05:11  lr: 0.000000  loss: 0.3734 (0.4158)  loss_classifier: 0.1356 (0.1488)  loss_box_reg: 0.1075 (0.1395)  loss_objectness: 0.0834 (0.0984)  loss_rpn_box_reg: 0.0161 (0.0291)  time: 0.2748  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [39]  [ 100/1229]  eta: 0:05:09  lr: 0.000000  loss: 0.3373 (0.4178)  loss_classifier: 0.1257 (0.1491)  loss_box_reg: 0.1075 (0.1399)  loss_objectness: 0.0691 (0.0990)  loss_rpn_box_reg: 0.0138 (0.0299)  time: 0.2796  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [39]  [ 110/1229]  eta: 0:05:08  lr: 0.000000  loss: 0.3761 (0.4207)  loss_classifier: 0.1323 (0.1502)  loss_box_reg: 0.1245 (0.1399)  loss_objectness: 0.1048 (0.1011)  loss_rpn_box_reg: 0.0138 (0.0294)  time: 0.2864  data: 0.1387  max mem: 1751\n",
      "Training Epoch: [39]  [ 120/1229]  eta: 0:05:05  lr: 0.000000  loss: 0.3141 (0.4188)  loss_classifier: 0.1129 (0.1496)  loss_box_reg: 0.0834 (0.1378)  loss_objectness: 0.0913 (0.1001)  loss_rpn_box_reg: 0.0153 (0.0314)  time: 0.2824  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [39]  [ 130/1229]  eta: 0:05:02  lr: 0.000000  loss: 0.3141 (0.4195)  loss_classifier: 0.1172 (0.1505)  loss_box_reg: 0.1278 (0.1381)  loss_objectness: 0.0761 (0.0998)  loss_rpn_box_reg: 0.0171 (0.0312)  time: 0.2703  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [39]  [ 140/1229]  eta: 0:04:59  lr: 0.000000  loss: 0.4134 (0.4209)  loss_classifier: 0.1583 (0.1513)  loss_box_reg: 0.1388 (0.1387)  loss_objectness: 0.0891 (0.0992)  loss_rpn_box_reg: 0.0191 (0.0316)  time: 0.2685  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [39]  [ 150/1229]  eta: 0:04:56  lr: 0.000000  loss: 0.4134 (0.4230)  loss_classifier: 0.1261 (0.1513)  loss_box_reg: 0.1388 (0.1378)  loss_objectness: 0.0984 (0.1019)  loss_rpn_box_reg: 0.0337 (0.0320)  time: 0.2715  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [39]  [ 160/1229]  eta: 0:04:53  lr: 0.000000  loss: 0.3844 (0.4186)  loss_classifier: 0.1245 (0.1499)  loss_box_reg: 0.1047 (0.1357)  loss_objectness: 0.0799 (0.1017)  loss_rpn_box_reg: 0.0250 (0.0313)  time: 0.2710  data: 0.1318  max mem: 1751\n",
      "Training Epoch: [39]  [ 170/1229]  eta: 0:04:50  lr: 0.000000  loss: 0.3407 (0.4220)  loss_classifier: 0.1245 (0.1510)  loss_box_reg: 0.1161 (0.1382)  loss_objectness: 0.0827 (0.1016)  loss_rpn_box_reg: 0.0227 (0.0312)  time: 0.2722  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [39]  [ 180/1229]  eta: 0:04:47  lr: 0.000000  loss: 0.4534 (0.4260)  loss_classifier: 0.1583 (0.1522)  loss_box_reg: 0.1313 (0.1390)  loss_objectness: 0.0910 (0.1030)  loss_rpn_box_reg: 0.0258 (0.0318)  time: 0.2725  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [39]  [ 190/1229]  eta: 0:04:45  lr: 0.000000  loss: 0.4260 (0.4263)  loss_classifier: 0.1538 (0.1520)  loss_box_reg: 0.0933 (0.1394)  loss_objectness: 0.1180 (0.1032)  loss_rpn_box_reg: 0.0154 (0.0317)  time: 0.2770  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [39]  [ 200/1229]  eta: 0:04:42  lr: 0.000000  loss: 0.4074 (0.4287)  loss_classifier: 0.1349 (0.1526)  loss_box_reg: 0.0911 (0.1411)  loss_objectness: 0.0994 (0.1038)  loss_rpn_box_reg: 0.0152 (0.0313)  time: 0.2744  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [39]  [ 210/1229]  eta: 0:04:39  lr: 0.000000  loss: 0.4305 (0.4355)  loss_classifier: 0.1602 (0.1556)  loss_box_reg: 0.1202 (0.1440)  loss_objectness: 0.0926 (0.1045)  loss_rpn_box_reg: 0.0185 (0.0315)  time: 0.2734  data: 0.1322  max mem: 1751\n",
      "Training Epoch: [39]  [ 220/1229]  eta: 0:04:36  lr: 0.000000  loss: 0.4147 (0.4356)  loss_classifier: 0.1583 (0.1559)  loss_box_reg: 0.1202 (0.1438)  loss_objectness: 0.0825 (0.1043)  loss_rpn_box_reg: 0.0215 (0.0316)  time: 0.2774  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [39]  [ 230/1229]  eta: 0:04:33  lr: 0.000000  loss: 0.3053 (0.4315)  loss_classifier: 0.1058 (0.1539)  loss_box_reg: 0.0826 (0.1419)  loss_objectness: 0.0825 (0.1044)  loss_rpn_box_reg: 0.0126 (0.0314)  time: 0.2720  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [39]  [ 240/1229]  eta: 0:04:31  lr: 0.000000  loss: 0.3203 (0.4318)  loss_classifier: 0.1042 (0.1537)  loss_box_reg: 0.0919 (0.1420)  loss_objectness: 0.0853 (0.1043)  loss_rpn_box_reg: 0.0239 (0.0318)  time: 0.2693  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [39]  [ 250/1229]  eta: 0:04:29  lr: 0.000000  loss: 0.4097 (0.4367)  loss_classifier: 0.1401 (0.1555)  loss_box_reg: 0.1289 (0.1437)  loss_objectness: 0.0886 (0.1047)  loss_rpn_box_reg: 0.0248 (0.0327)  time: 0.2855  data: 0.1307  max mem: 1751\n",
      "Training Epoch: [39]  [ 260/1229]  eta: 0:04:26  lr: 0.000000  loss: 0.4162 (0.4350)  loss_classifier: 0.1429 (0.1547)  loss_box_reg: 0.1207 (0.1437)  loss_objectness: 0.0705 (0.1040)  loss_rpn_box_reg: 0.0180 (0.0326)  time: 0.2841  data: 0.1302  max mem: 1751\n",
      "Training Epoch: [39]  [ 270/1229]  eta: 0:04:23  lr: 0.000000  loss: 0.3251 (0.4364)  loss_classifier: 0.1285 (0.1552)  loss_box_reg: 0.1036 (0.1438)  loss_objectness: 0.0701 (0.1045)  loss_rpn_box_reg: 0.0180 (0.0329)  time: 0.2672  data: 0.1317  max mem: 1751\n",
      "Training Epoch: [39]  [ 280/1229]  eta: 0:04:20  lr: 0.000000  loss: 0.3933 (0.4367)  loss_classifier: 0.1539 (0.1550)  loss_box_reg: 0.1299 (0.1437)  loss_objectness: 0.1067 (0.1050)  loss_rpn_box_reg: 0.0204 (0.0331)  time: 0.2719  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [39]  [ 290/1229]  eta: 0:04:17  lr: 0.000000  loss: 0.3392 (0.4351)  loss_classifier: 0.1163 (0.1544)  loss_box_reg: 0.1116 (0.1436)  loss_objectness: 0.0972 (0.1043)  loss_rpn_box_reg: 0.0204 (0.0327)  time: 0.2736  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [39]  [ 300/1229]  eta: 0:04:14  lr: 0.000000  loss: 0.3392 (0.4346)  loss_classifier: 0.1361 (0.1547)  loss_box_reg: 0.1116 (0.1434)  loss_objectness: 0.0972 (0.1043)  loss_rpn_box_reg: 0.0132 (0.0321)  time: 0.2695  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [39]  [ 310/1229]  eta: 0:04:12  lr: 0.000000  loss: 0.3456 (0.4327)  loss_classifier: 0.1417 (0.1543)  loss_box_reg: 0.1008 (0.1429)  loss_objectness: 0.0889 (0.1035)  loss_rpn_box_reg: 0.0138 (0.0321)  time: 0.2710  data: 0.1328  max mem: 1751\n",
      "Training Epoch: [39]  [ 320/1229]  eta: 0:04:09  lr: 0.000000  loss: 0.3489 (0.4331)  loss_classifier: 0.1364 (0.1546)  loss_box_reg: 0.1039 (0.1430)  loss_objectness: 0.0748 (0.1031)  loss_rpn_box_reg: 0.0250 (0.0324)  time: 0.2764  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [39]  [ 330/1229]  eta: 0:04:06  lr: 0.000000  loss: 0.4161 (0.4349)  loss_classifier: 0.1368 (0.1549)  loss_box_reg: 0.1270 (0.1440)  loss_objectness: 0.0799 (0.1036)  loss_rpn_box_reg: 0.0221 (0.0324)  time: 0.2727  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [39]  [ 340/1229]  eta: 0:04:03  lr: 0.000000  loss: 0.4583 (0.4379)  loss_classifier: 0.1621 (0.1560)  loss_box_reg: 0.1366 (0.1458)  loss_objectness: 0.0910 (0.1035)  loss_rpn_box_reg: 0.0217 (0.0326)  time: 0.2687  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [39]  [ 350/1229]  eta: 0:04:01  lr: 0.000000  loss: 0.3136 (0.4349)  loss_classifier: 0.1231 (0.1552)  loss_box_reg: 0.0883 (0.1443)  loss_objectness: 0.0755 (0.1028)  loss_rpn_box_reg: 0.0161 (0.0326)  time: 0.2747  data: 0.1325  max mem: 1751\n",
      "Training Epoch: [39]  [ 360/1229]  eta: 0:03:57  lr: 0.000000  loss: 0.2809 (0.4337)  loss_classifier: 0.0922 (0.1542)  loss_box_reg: 0.0830 (0.1433)  loss_objectness: 0.0648 (0.1026)  loss_rpn_box_reg: 0.0129 (0.0335)  time: 0.2706  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [39]  [ 370/1229]  eta: 0:03:55  lr: 0.000000  loss: 0.3417 (0.4347)  loss_classifier: 0.0972 (0.1544)  loss_box_reg: 0.1240 (0.1440)  loss_objectness: 0.1063 (0.1029)  loss_rpn_box_reg: 0.0154 (0.0334)  time: 0.2720  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [39]  [ 380/1229]  eta: 0:03:52  lr: 0.000000  loss: 0.3831 (0.4342)  loss_classifier: 0.1251 (0.1539)  loss_box_reg: 0.1171 (0.1439)  loss_objectness: 0.0979 (0.1030)  loss_rpn_box_reg: 0.0156 (0.0334)  time: 0.2773  data: 0.1354  max mem: 1751\n",
      "Training Epoch: [39]  [ 390/1229]  eta: 0:03:49  lr: 0.000000  loss: 0.4140 (0.4339)  loss_classifier: 0.1321 (0.1537)  loss_box_reg: 0.1171 (0.1440)  loss_objectness: 0.0913 (0.1027)  loss_rpn_box_reg: 0.0242 (0.0334)  time: 0.2732  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [39]  [ 400/1229]  eta: 0:03:47  lr: 0.000000  loss: 0.4691 (0.4364)  loss_classifier: 0.1692 (0.1549)  loss_box_reg: 0.1755 (0.1452)  loss_objectness: 0.0890 (0.1031)  loss_rpn_box_reg: 0.0252 (0.0332)  time: 0.2787  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [39]  [ 410/1229]  eta: 0:03:44  lr: 0.000000  loss: 0.5231 (0.4413)  loss_classifier: 0.1805 (0.1564)  loss_box_reg: 0.1788 (0.1464)  loss_objectness: 0.1278 (0.1044)  loss_rpn_box_reg: 0.0298 (0.0340)  time: 0.2822  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [39]  [ 420/1229]  eta: 0:03:42  lr: 0.000000  loss: 0.3789 (0.4388)  loss_classifier: 0.1533 (0.1557)  loss_box_reg: 0.0996 (0.1454)  loss_objectness: 0.1118 (0.1040)  loss_rpn_box_reg: 0.0229 (0.0337)  time: 0.2813  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [39]  [ 430/1229]  eta: 0:03:39  lr: 0.000000  loss: 0.3674 (0.4403)  loss_classifier: 0.1389 (0.1562)  loss_box_reg: 0.1116 (0.1463)  loss_objectness: 0.0807 (0.1040)  loss_rpn_box_reg: 0.0225 (0.0338)  time: 0.2734  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [39]  [ 440/1229]  eta: 0:03:36  lr: 0.000000  loss: 0.3925 (0.4387)  loss_classifier: 0.1389 (0.1555)  loss_box_reg: 0.1125 (0.1460)  loss_objectness: 0.0857 (0.1035)  loss_rpn_box_reg: 0.0188 (0.0337)  time: 0.2694  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [39]  [ 450/1229]  eta: 0:03:33  lr: 0.000000  loss: 0.4014 (0.4402)  loss_classifier: 0.1118 (0.1562)  loss_box_reg: 0.1036 (0.1469)  loss_objectness: 0.0857 (0.1035)  loss_rpn_box_reg: 0.0188 (0.0336)  time: 0.2728  data: 0.1339  max mem: 1751\n",
      "Training Epoch: [39]  [ 460/1229]  eta: 0:03:30  lr: 0.000000  loss: 0.5193 (0.4439)  loss_classifier: 0.1887 (0.1575)  loss_box_reg: 0.1809 (0.1489)  loss_objectness: 0.1049 (0.1036)  loss_rpn_box_reg: 0.0227 (0.0339)  time: 0.2713  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [39]  [ 470/1229]  eta: 0:03:28  lr: 0.000000  loss: 0.2946 (0.4411)  loss_classifier: 0.1110 (0.1567)  loss_box_reg: 0.0988 (0.1478)  loss_objectness: 0.0822 (0.1029)  loss_rpn_box_reg: 0.0207 (0.0336)  time: 0.2699  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [39]  [ 480/1229]  eta: 0:03:25  lr: 0.000000  loss: 0.3509 (0.4438)  loss_classifier: 0.1265 (0.1574)  loss_box_reg: 0.1083 (0.1486)  loss_objectness: 0.0827 (0.1034)  loss_rpn_box_reg: 0.0207 (0.0343)  time: 0.2701  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [39]  [ 490/1229]  eta: 0:03:22  lr: 0.000000  loss: 0.4922 (0.4432)  loss_classifier: 0.1731 (0.1573)  loss_box_reg: 0.1370 (0.1487)  loss_objectness: 0.0853 (0.1031)  loss_rpn_box_reg: 0.0185 (0.0341)  time: 0.2739  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [39]  [ 500/1229]  eta: 0:03:19  lr: 0.000000  loss: 0.3844 (0.4414)  loss_classifier: 0.1401 (0.1567)  loss_box_reg: 0.1226 (0.1482)  loss_objectness: 0.0701 (0.1027)  loss_rpn_box_reg: 0.0154 (0.0337)  time: 0.2766  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [39]  [ 510/1229]  eta: 0:03:17  lr: 0.000000  loss: 0.3570 (0.4417)  loss_classifier: 0.1292 (0.1571)  loss_box_reg: 0.1250 (0.1484)  loss_objectness: 0.0701 (0.1027)  loss_rpn_box_reg: 0.0155 (0.0335)  time: 0.2786  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [39]  [ 520/1229]  eta: 0:03:14  lr: 0.000000  loss: 0.3449 (0.4412)  loss_classifier: 0.1238 (0.1572)  loss_box_reg: 0.1223 (0.1482)  loss_objectness: 0.0803 (0.1024)  loss_rpn_box_reg: 0.0209 (0.0333)  time: 0.2769  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [39]  [ 530/1229]  eta: 0:03:11  lr: 0.000000  loss: 0.3449 (0.4420)  loss_classifier: 0.1565 (0.1577)  loss_box_reg: 0.1133 (0.1483)  loss_objectness: 0.0742 (0.1027)  loss_rpn_box_reg: 0.0261 (0.0333)  time: 0.2735  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [39]  [ 540/1229]  eta: 0:03:08  lr: 0.000000  loss: 0.4003 (0.4419)  loss_classifier: 0.1565 (0.1576)  loss_box_reg: 0.1133 (0.1483)  loss_objectness: 0.0725 (0.1024)  loss_rpn_box_reg: 0.0282 (0.0335)  time: 0.2717  data: 0.1359  max mem: 1751\n",
      "Training Epoch: [39]  [ 550/1229]  eta: 0:03:06  lr: 0.000000  loss: 0.3155 (0.4439)  loss_classifier: 0.1298 (0.1583)  loss_box_reg: 0.1149 (0.1495)  loss_objectness: 0.0768 (0.1022)  loss_rpn_box_reg: 0.0250 (0.0339)  time: 0.2754  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [39]  [ 560/1229]  eta: 0:03:03  lr: 0.000000  loss: 0.3431 (0.4445)  loss_classifier: 0.1329 (0.1584)  loss_box_reg: 0.1149 (0.1492)  loss_objectness: 0.0907 (0.1028)  loss_rpn_box_reg: 0.0190 (0.0341)  time: 0.2742  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [39]  [ 570/1229]  eta: 0:03:00  lr: 0.000000  loss: 0.3431 (0.4433)  loss_classifier: 0.1329 (0.1582)  loss_box_reg: 0.1088 (0.1489)  loss_objectness: 0.0861 (0.1024)  loss_rpn_box_reg: 0.0160 (0.0339)  time: 0.2710  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [39]  [ 580/1229]  eta: 0:02:57  lr: 0.000000  loss: 0.3702 (0.4429)  loss_classifier: 0.1577 (0.1582)  loss_box_reg: 0.1230 (0.1489)  loss_objectness: 0.0748 (0.1020)  loss_rpn_box_reg: 0.0167 (0.0339)  time: 0.2750  data: 0.1319  max mem: 1751\n",
      "Training Epoch: [39]  [ 590/1229]  eta: 0:02:55  lr: 0.000000  loss: 0.3274 (0.4403)  loss_classifier: 0.1282 (0.1572)  loss_box_reg: 0.0789 (0.1477)  loss_objectness: 0.0748 (0.1015)  loss_rpn_box_reg: 0.0206 (0.0339)  time: 0.2746  data: 0.1349  max mem: 1751\n",
      "Training Epoch: [39]  [ 600/1229]  eta: 0:02:52  lr: 0.000000  loss: 0.2871 (0.4387)  loss_classifier: 0.0905 (0.1566)  loss_box_reg: 0.0728 (0.1469)  loss_objectness: 0.0821 (0.1014)  loss_rpn_box_reg: 0.0147 (0.0338)  time: 0.2721  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [39]  [ 610/1229]  eta: 0:02:49  lr: 0.000000  loss: 0.2982 (0.4375)  loss_classifier: 0.1179 (0.1563)  loss_box_reg: 0.0928 (0.1465)  loss_objectness: 0.0764 (0.1011)  loss_rpn_box_reg: 0.0132 (0.0335)  time: 0.2719  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [39]  [ 620/1229]  eta: 0:02:46  lr: 0.000000  loss: 0.3714 (0.4376)  loss_classifier: 0.1635 (0.1562)  loss_box_reg: 0.1058 (0.1462)  loss_objectness: 0.0765 (0.1015)  loss_rpn_box_reg: 0.0164 (0.0336)  time: 0.2687  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [39]  [ 630/1229]  eta: 0:02:44  lr: 0.000000  loss: 0.3513 (0.4363)  loss_classifier: 0.1406 (0.1559)  loss_box_reg: 0.1017 (0.1457)  loss_objectness: 0.0949 (0.1012)  loss_rpn_box_reg: 0.0167 (0.0334)  time: 0.2690  data: 0.1310  max mem: 1751\n",
      "Training Epoch: [39]  [ 640/1229]  eta: 0:02:41  lr: 0.000000  loss: 0.3029 (0.4354)  loss_classifier: 0.1232 (0.1556)  loss_box_reg: 0.1017 (0.1459)  loss_objectness: 0.0588 (0.1007)  loss_rpn_box_reg: 0.0145 (0.0332)  time: 0.2708  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [39]  [ 650/1229]  eta: 0:02:38  lr: 0.000000  loss: 0.2874 (0.4345)  loss_classifier: 0.1118 (0.1553)  loss_box_reg: 0.0867 (0.1454)  loss_objectness: 0.0533 (0.1004)  loss_rpn_box_reg: 0.0186 (0.0334)  time: 0.2769  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [39]  [ 660/1229]  eta: 0:02:35  lr: 0.000000  loss: 0.3288 (0.4342)  loss_classifier: 0.1241 (0.1553)  loss_box_reg: 0.0867 (0.1452)  loss_objectness: 0.0853 (0.1006)  loss_rpn_box_reg: 0.0215 (0.0332)  time: 0.2740  data: 0.1321  max mem: 1751\n",
      "Training Epoch: [39]  [ 670/1229]  eta: 0:02:33  lr: 0.000000  loss: 0.4402 (0.4343)  loss_classifier: 0.1500 (0.1554)  loss_box_reg: 0.1169 (0.1452)  loss_objectness: 0.0884 (0.1006)  loss_rpn_box_reg: 0.0188 (0.0332)  time: 0.2685  data: 0.1311  max mem: 1751\n",
      "Training Epoch: [39]  [ 680/1229]  eta: 0:02:30  lr: 0.000000  loss: 0.4564 (0.4366)  loss_classifier: 0.1660 (0.1560)  loss_box_reg: 0.1455 (0.1462)  loss_objectness: 0.1178 (0.1011)  loss_rpn_box_reg: 0.0202 (0.0333)  time: 0.2730  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [39]  [ 690/1229]  eta: 0:02:27  lr: 0.000000  loss: 0.3936 (0.4362)  loss_classifier: 0.1517 (0.1560)  loss_box_reg: 0.1277 (0.1461)  loss_objectness: 0.0857 (0.1009)  loss_rpn_box_reg: 0.0280 (0.0333)  time: 0.2792  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [39]  [ 700/1229]  eta: 0:02:24  lr: 0.000000  loss: 0.3787 (0.4363)  loss_classifier: 0.1488 (0.1560)  loss_box_reg: 0.1204 (0.1461)  loss_objectness: 0.0743 (0.1007)  loss_rpn_box_reg: 0.0223 (0.0335)  time: 0.2809  data: 0.1346  max mem: 1751\n",
      "Training Epoch: [39]  [ 710/1229]  eta: 0:02:22  lr: 0.000000  loss: 0.4022 (0.4367)  loss_classifier: 0.1636 (0.1561)  loss_box_reg: 0.1099 (0.1458)  loss_objectness: 0.0767 (0.1007)  loss_rpn_box_reg: 0.0223 (0.0340)  time: 0.2726  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [39]  [ 720/1229]  eta: 0:02:19  lr: 0.000000  loss: 0.3839 (0.4376)  loss_classifier: 0.1266 (0.1563)  loss_box_reg: 0.1061 (0.1462)  loss_objectness: 0.1007 (0.1009)  loss_rpn_box_reg: 0.0292 (0.0343)  time: 0.2720  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [39]  [ 730/1229]  eta: 0:02:16  lr: 0.000000  loss: 0.3612 (0.4379)  loss_classifier: 0.1266 (0.1564)  loss_box_reg: 0.1061 (0.1462)  loss_objectness: 0.1108 (0.1009)  loss_rpn_box_reg: 0.0337 (0.0344)  time: 0.2728  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [39]  [ 740/1229]  eta: 0:02:14  lr: 0.000000  loss: 0.4372 (0.4391)  loss_classifier: 0.1475 (0.1569)  loss_box_reg: 0.1434 (0.1466)  loss_objectness: 0.1108 (0.1013)  loss_rpn_box_reg: 0.0253 (0.0343)  time: 0.2757  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [39]  [ 750/1229]  eta: 0:02:11  lr: 0.000000  loss: 0.4709 (0.4393)  loss_classifier: 0.1368 (0.1567)  loss_box_reg: 0.1602 (0.1466)  loss_objectness: 0.0914 (0.1014)  loss_rpn_box_reg: 0.0330 (0.0346)  time: 0.2745  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [39]  [ 760/1229]  eta: 0:02:08  lr: 0.000000  loss: 0.3450 (0.4390)  loss_classifier: 0.1119 (0.1565)  loss_box_reg: 0.0781 (0.1464)  loss_objectness: 0.0840 (0.1014)  loss_rpn_box_reg: 0.0243 (0.0347)  time: 0.2685  data: 0.1314  max mem: 1751\n",
      "Training Epoch: [39]  [ 770/1229]  eta: 0:02:05  lr: 0.000000  loss: 0.4120 (0.4402)  loss_classifier: 0.1641 (0.1568)  loss_box_reg: 0.1559 (0.1471)  loss_objectness: 0.0816 (0.1014)  loss_rpn_box_reg: 0.0293 (0.0348)  time: 0.2695  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [39]  [ 780/1229]  eta: 0:02:02  lr: 0.000000  loss: 0.4103 (0.4402)  loss_classifier: 0.1641 (0.1568)  loss_box_reg: 0.1477 (0.1470)  loss_objectness: 0.1078 (0.1014)  loss_rpn_box_reg: 0.0307 (0.0349)  time: 0.2700  data: 0.1338  max mem: 1751\n",
      "Training Epoch: [39]  [ 790/1229]  eta: 0:02:00  lr: 0.000000  loss: 0.2961 (0.4400)  loss_classifier: 0.1117 (0.1567)  loss_box_reg: 0.0947 (0.1472)  loss_objectness: 0.0868 (0.1012)  loss_rpn_box_reg: 0.0164 (0.0348)  time: 0.2748  data: 0.1308  max mem: 1751\n",
      "Training Epoch: [39]  [ 800/1229]  eta: 0:01:57  lr: 0.000000  loss: 0.2774 (0.4384)  loss_classifier: 0.1027 (0.1563)  loss_box_reg: 0.0783 (0.1468)  loss_objectness: 0.0641 (0.1007)  loss_rpn_box_reg: 0.0124 (0.0345)  time: 0.2807  data: 0.1301  max mem: 1751\n",
      "Training Epoch: [39]  [ 810/1229]  eta: 0:01:54  lr: 0.000000  loss: 0.4129 (0.4396)  loss_classifier: 0.1405 (0.1568)  loss_box_reg: 0.1210 (0.1475)  loss_objectness: 0.0641 (0.1008)  loss_rpn_box_reg: 0.0188 (0.0345)  time: 0.2832  data: 0.1333  max mem: 1751\n",
      "Training Epoch: [39]  [ 820/1229]  eta: 0:01:52  lr: 0.000000  loss: 0.4129 (0.4391)  loss_classifier: 0.1366 (0.1566)  loss_box_reg: 0.1210 (0.1474)  loss_objectness: 0.0860 (0.1006)  loss_rpn_box_reg: 0.0188 (0.0345)  time: 0.2800  data: 0.1365  max mem: 1751\n",
      "Training Epoch: [39]  [ 830/1229]  eta: 0:01:49  lr: 0.000000  loss: 0.3668 (0.4388)  loss_classifier: 0.1362 (0.1564)  loss_box_reg: 0.1243 (0.1474)  loss_objectness: 0.0860 (0.1006)  loss_rpn_box_reg: 0.0166 (0.0343)  time: 0.2727  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [39]  [ 840/1229]  eta: 0:01:46  lr: 0.000000  loss: 0.3975 (0.4387)  loss_classifier: 0.1384 (0.1564)  loss_box_reg: 0.1338 (0.1475)  loss_objectness: 0.0884 (0.1006)  loss_rpn_box_reg: 0.0211 (0.0342)  time: 0.2701  data: 0.1337  max mem: 1751\n",
      "Training Epoch: [39]  [ 850/1229]  eta: 0:01:43  lr: 0.000000  loss: 0.3744 (0.4380)  loss_classifier: 0.1306 (0.1562)  loss_box_reg: 0.1149 (0.1473)  loss_objectness: 0.0880 (0.1005)  loss_rpn_box_reg: 0.0192 (0.0340)  time: 0.2727  data: 0.1350  max mem: 1751\n",
      "Training Epoch: [39]  [ 860/1229]  eta: 0:01:41  lr: 0.000000  loss: 0.3832 (0.4380)  loss_classifier: 0.1196 (0.1561)  loss_box_reg: 0.1042 (0.1472)  loss_objectness: 0.1180 (0.1006)  loss_rpn_box_reg: 0.0192 (0.0342)  time: 0.2767  data: 0.1364  max mem: 1751\n",
      "Training Epoch: [39]  [ 870/1229]  eta: 0:01:38  lr: 0.000000  loss: 0.3832 (0.4378)  loss_classifier: 0.1294 (0.1561)  loss_box_reg: 0.0984 (0.1470)  loss_objectness: 0.0924 (0.1006)  loss_rpn_box_reg: 0.0195 (0.0341)  time: 0.2879  data: 0.1347  max mem: 1751\n",
      "Training Epoch: [39]  [ 880/1229]  eta: 0:01:35  lr: 0.000000  loss: 0.3269 (0.4367)  loss_classifier: 0.1241 (0.1558)  loss_box_reg: 0.1077 (0.1466)  loss_objectness: 0.0857 (0.1004)  loss_rpn_box_reg: 0.0182 (0.0340)  time: 0.2849  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [39]  [ 890/1229]  eta: 0:01:33  lr: 0.000000  loss: 0.4399 (0.4378)  loss_classifier: 0.1628 (0.1559)  loss_box_reg: 0.1407 (0.1468)  loss_objectness: 0.0943 (0.1008)  loss_rpn_box_reg: 0.0201 (0.0344)  time: 0.2736  data: 0.1336  max mem: 1751\n",
      "Training Epoch: [39]  [ 900/1229]  eta: 0:01:30  lr: 0.000000  loss: 0.3993 (0.4369)  loss_classifier: 0.1536 (0.1557)  loss_box_reg: 0.1117 (0.1463)  loss_objectness: 0.0943 (0.1006)  loss_rpn_box_reg: 0.0244 (0.0343)  time: 0.2803  data: 0.1344  max mem: 1751\n",
      "Training Epoch: [39]  [ 910/1229]  eta: 0:01:27  lr: 0.000000  loss: 0.2649 (0.4356)  loss_classifier: 0.1130 (0.1553)  loss_box_reg: 0.0757 (0.1457)  loss_objectness: 0.0664 (0.1004)  loss_rpn_box_reg: 0.0218 (0.0342)  time: 0.2787  data: 0.1348  max mem: 1751\n",
      "Training Epoch: [39]  [ 920/1229]  eta: 0:01:24  lr: 0.000000  loss: 0.3690 (0.4365)  loss_classifier: 0.1185 (0.1554)  loss_box_reg: 0.1107 (0.1462)  loss_objectness: 0.0708 (0.1006)  loss_rpn_box_reg: 0.0234 (0.0343)  time: 0.2732  data: 0.1356  max mem: 1751\n",
      "Training Epoch: [39]  [ 930/1229]  eta: 0:01:22  lr: 0.000000  loss: 0.4014 (0.4364)  loss_classifier: 0.1440 (0.1554)  loss_box_reg: 0.1203 (0.1459)  loss_objectness: 0.0986 (0.1007)  loss_rpn_box_reg: 0.0259 (0.0344)  time: 0.2709  data: 0.1361  max mem: 1751\n",
      "Training Epoch: [39]  [ 940/1229]  eta: 0:01:19  lr: 0.000000  loss: 0.3333 (0.4354)  loss_classifier: 0.1227 (0.1551)  loss_box_reg: 0.0931 (0.1455)  loss_objectness: 0.0873 (0.1006)  loss_rpn_box_reg: 0.0148 (0.0343)  time: 0.2671  data: 0.1334  max mem: 1751\n",
      "Training Epoch: [39]  [ 950/1229]  eta: 0:01:16  lr: 0.000000  loss: 0.3333 (0.4350)  loss_classifier: 0.1227 (0.1550)  loss_box_reg: 0.1105 (0.1452)  loss_objectness: 0.1005 (0.1006)  loss_rpn_box_reg: 0.0160 (0.0341)  time: 0.2670  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [39]  [ 960/1229]  eta: 0:01:13  lr: 0.000000  loss: 0.4920 (0.4371)  loss_classifier: 0.1655 (0.1558)  loss_box_reg: 0.1548 (0.1461)  loss_objectness: 0.1011 (0.1007)  loss_rpn_box_reg: 0.0286 (0.0345)  time: 0.2740  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [39]  [ 970/1229]  eta: 0:01:11  lr: 0.000000  loss: 0.4920 (0.4368)  loss_classifier: 0.1655 (0.1557)  loss_box_reg: 0.1550 (0.1461)  loss_objectness: 0.0847 (0.1005)  loss_rpn_box_reg: 0.0329 (0.0345)  time: 0.2775  data: 0.1329  max mem: 1751\n",
      "Training Epoch: [39]  [ 980/1229]  eta: 0:01:08  lr: 0.000000  loss: 0.4570 (0.4384)  loss_classifier: 0.1646 (0.1562)  loss_box_reg: 0.1294 (0.1469)  loss_objectness: 0.0931 (0.1007)  loss_rpn_box_reg: 0.0124 (0.0346)  time: 0.2741  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [39]  [ 990/1229]  eta: 0:01:05  lr: 0.000000  loss: 0.3704 (0.4372)  loss_classifier: 0.1302 (0.1557)  loss_box_reg: 0.1252 (0.1465)  loss_objectness: 0.0863 (0.1005)  loss_rpn_box_reg: 0.0164 (0.0345)  time: 0.2722  data: 0.1382  max mem: 1751\n",
      "Training Epoch: [39]  [1000/1229]  eta: 0:01:02  lr: 0.000000  loss: 0.3654 (0.4379)  loss_classifier: 0.1294 (0.1561)  loss_box_reg: 0.1074 (0.1464)  loss_objectness: 0.0905 (0.1008)  loss_rpn_box_reg: 0.0237 (0.0346)  time: 0.2753  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [39]  [1010/1229]  eta: 0:01:00  lr: 0.000000  loss: 0.3669 (0.4374)  loss_classifier: 0.1294 (0.1559)  loss_box_reg: 0.1096 (0.1462)  loss_objectness: 0.0951 (0.1007)  loss_rpn_box_reg: 0.0237 (0.0346)  time: 0.2735  data: 0.1369  max mem: 1751\n",
      "Training Epoch: [39]  [1020/1229]  eta: 0:00:57  lr: 0.000000  loss: 0.3756 (0.4367)  loss_classifier: 0.1204 (0.1557)  loss_box_reg: 0.1093 (0.1457)  loss_objectness: 0.0959 (0.1008)  loss_rpn_box_reg: 0.0230 (0.0345)  time: 0.2666  data: 0.1353  max mem: 1751\n",
      "Training Epoch: [39]  [1030/1229]  eta: 0:00:54  lr: 0.000000  loss: 0.3159 (0.4355)  loss_classifier: 0.1204 (0.1553)  loss_box_reg: 0.0997 (0.1452)  loss_objectness: 0.0959 (0.1006)  loss_rpn_box_reg: 0.0230 (0.0344)  time: 0.2692  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [39]  [1040/1229]  eta: 0:00:51  lr: 0.000000  loss: 0.3111 (0.4351)  loss_classifier: 0.1209 (0.1553)  loss_box_reg: 0.0856 (0.1451)  loss_objectness: 0.0684 (0.1005)  loss_rpn_box_reg: 0.0199 (0.0343)  time: 0.2677  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [39]  [1050/1229]  eta: 0:00:49  lr: 0.000000  loss: 0.3359 (0.4346)  loss_classifier: 0.1283 (0.1551)  loss_box_reg: 0.1063 (0.1448)  loss_objectness: 0.0905 (0.1005)  loss_rpn_box_reg: 0.0176 (0.0343)  time: 0.2691  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [39]  [1060/1229]  eta: 0:00:46  lr: 0.000000  loss: 0.3232 (0.4341)  loss_classifier: 0.1189 (0.1550)  loss_box_reg: 0.1063 (0.1446)  loss_objectness: 0.0799 (0.1003)  loss_rpn_box_reg: 0.0140 (0.0342)  time: 0.2761  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [39]  [1070/1229]  eta: 0:00:43  lr: 0.000000  loss: 0.3915 (0.4346)  loss_classifier: 0.1323 (0.1552)  loss_box_reg: 0.0967 (0.1448)  loss_objectness: 0.0825 (0.1004)  loss_rpn_box_reg: 0.0194 (0.0342)  time: 0.2791  data: 0.1355  max mem: 1751\n",
      "Training Epoch: [39]  [1080/1229]  eta: 0:00:40  lr: 0.000000  loss: 0.3634 (0.4340)  loss_classifier: 0.1321 (0.1551)  loss_box_reg: 0.0967 (0.1446)  loss_objectness: 0.0991 (0.1004)  loss_rpn_box_reg: 0.0167 (0.0340)  time: 0.2772  data: 0.1360  max mem: 1751\n",
      "Training Epoch: [39]  [1090/1229]  eta: 0:00:38  lr: 0.000000  loss: 0.4627 (0.4352)  loss_classifier: 0.1586 (0.1554)  loss_box_reg: 0.1311 (0.1453)  loss_objectness: 0.0691 (0.1004)  loss_rpn_box_reg: 0.0181 (0.0341)  time: 0.2720  data: 0.1351  max mem: 1751\n",
      "Training Epoch: [39]  [1100/1229]  eta: 0:00:35  lr: 0.000000  loss: 0.4878 (0.4354)  loss_classifier: 0.1628 (0.1554)  loss_box_reg: 0.1919 (0.1457)  loss_objectness: 0.0772 (0.1002)  loss_rpn_box_reg: 0.0222 (0.0341)  time: 0.2728  data: 0.1341  max mem: 1751\n",
      "Training Epoch: [39]  [1110/1229]  eta: 0:00:32  lr: 0.000000  loss: 0.4314 (0.4358)  loss_classifier: 0.1528 (0.1555)  loss_box_reg: 0.1687 (0.1458)  loss_objectness: 0.0781 (0.1003)  loss_rpn_box_reg: 0.0228 (0.0342)  time: 0.2735  data: 0.1340  max mem: 1751\n",
      "Training Epoch: [39]  [1120/1229]  eta: 0:00:29  lr: 0.000000  loss: 0.4897 (0.4371)  loss_classifier: 0.1785 (0.1559)  loss_box_reg: 0.1841 (0.1465)  loss_objectness: 0.1008 (0.1005)  loss_rpn_box_reg: 0.0270 (0.0341)  time: 0.2762  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [39]  [1130/1229]  eta: 0:00:27  lr: 0.000000  loss: 0.4930 (0.4372)  loss_classifier: 0.1620 (0.1559)  loss_box_reg: 0.1738 (0.1466)  loss_objectness: 0.1090 (0.1006)  loss_rpn_box_reg: 0.0220 (0.0342)  time: 0.2777  data: 0.1331  max mem: 1751\n",
      "Training Epoch: [39]  [1140/1229]  eta: 0:00:24  lr: 0.000000  loss: 0.4727 (0.4378)  loss_classifier: 0.1387 (0.1561)  loss_box_reg: 0.1274 (0.1468)  loss_objectness: 0.1143 (0.1007)  loss_rpn_box_reg: 0.0217 (0.0342)  time: 0.2738  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [39]  [1150/1229]  eta: 0:00:21  lr: 0.000000  loss: 0.4059 (0.4378)  loss_classifier: 0.1404 (0.1561)  loss_box_reg: 0.1299 (0.1467)  loss_objectness: 0.1107 (0.1008)  loss_rpn_box_reg: 0.0210 (0.0342)  time: 0.2704  data: 0.1357  max mem: 1751\n",
      "Training Epoch: [39]  [1160/1229]  eta: 0:00:18  lr: 0.000000  loss: 0.4114 (0.4377)  loss_classifier: 0.1471 (0.1560)  loss_box_reg: 0.1281 (0.1466)  loss_objectness: 0.1107 (0.1010)  loss_rpn_box_reg: 0.0210 (0.0342)  time: 0.2677  data: 0.1342  max mem: 1751\n",
      "Training Epoch: [39]  [1170/1229]  eta: 0:00:16  lr: 0.000000  loss: 0.4361 (0.4376)  loss_classifier: 0.1658 (0.1560)  loss_box_reg: 0.0922 (0.1465)  loss_objectness: 0.1000 (0.1009)  loss_rpn_box_reg: 0.0226 (0.0342)  time: 0.2667  data: 0.1362  max mem: 1751\n",
      "Training Epoch: [39]  [1180/1229]  eta: 0:00:13  lr: 0.000000  loss: 0.2806 (0.4368)  loss_classifier: 0.1196 (0.1558)  loss_box_reg: 0.0970 (0.1462)  loss_objectness: 0.0800 (0.1008)  loss_rpn_box_reg: 0.0148 (0.0341)  time: 0.2721  data: 0.1363  max mem: 1751\n",
      "Training Epoch: [39]  [1190/1229]  eta: 0:00:10  lr: 0.000000  loss: 0.2975 (0.4377)  loss_classifier: 0.1196 (0.1561)  loss_box_reg: 0.0975 (0.1464)  loss_objectness: 0.1096 (0.1010)  loss_rpn_box_reg: 0.0228 (0.0342)  time: 0.2753  data: 0.1330  max mem: 1751\n",
      "Training Epoch: [39]  [1200/1229]  eta: 0:00:07  lr: 0.000000  loss: 0.3791 (0.4377)  loss_classifier: 0.1580 (0.1560)  loss_box_reg: 0.1130 (0.1466)  loss_objectness: 0.1036 (0.1008)  loss_rpn_box_reg: 0.0327 (0.0343)  time: 0.2702  data: 0.1326  max mem: 1751\n",
      "Training Epoch: [39]  [1210/1229]  eta: 0:00:05  lr: 0.000000  loss: 0.3791 (0.4379)  loss_classifier: 0.1580 (0.1560)  loss_box_reg: 0.1504 (0.1467)  loss_objectness: 0.0860 (0.1009)  loss_rpn_box_reg: 0.0263 (0.0343)  time: 0.2652  data: 0.1327  max mem: 1751\n",
      "Training Epoch: [39]  [1220/1229]  eta: 0:00:02  lr: 0.000000  loss: 0.3912 (0.4385)  loss_classifier: 0.1449 (0.1563)  loss_box_reg: 0.1516 (0.1470)  loss_objectness: 0.0860 (0.1010)  loss_rpn_box_reg: 0.0286 (0.0343)  time: 0.2697  data: 0.1332  max mem: 1751\n",
      "Training Epoch: [39]  [1228/1229]  eta: 0:00:00  lr: 0.000000  loss: 0.3538 (0.4375)  loss_classifier: 0.1313 (0.1559)  loss_box_reg: 0.1030 (0.1466)  loss_objectness: 0.0648 (0.1008)  loss_rpn_box_reg: 0.0258 (0.0342)  time: 0.2813  data: 0.1335  max mem: 1751\n",
      "Training Epoch: [39] Total time: 0:05:36 (0.2741 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:29  model_time: 0.2550 (0.2550)  evaluator_time: 0.0030 (0.0030)  time: 0.2890  data: 0.0290  max mem: 1751\n",
      "Test:  [100/308]  eta: 0:00:26  model_time: 0.0800 (0.0820)  evaluator_time: 0.0040 (0.0086)  time: 0.1276  data: 0.0359  max mem: 1751\n",
      "Test:  [200/308]  eta: 0:00:13  model_time: 0.0830 (0.0811)  evaluator_time: 0.0030 (0.0078)  time: 0.1201  data: 0.0306  max mem: 1751\n",
      "Test:  [300/308]  eta: 0:00:00  model_time: 0.0730 (0.0804)  evaluator_time: 0.0040 (0.0076)  time: 0.1196  data: 0.0350  max mem: 1751\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0730 (0.0802)  evaluator_time: 0.0020 (0.0076)  time: 0.1165  data: 0.0336  max mem: 1751\n",
      "Test: Total time: 0:00:38 (0.1240 s / it)\n",
      "Averaged stats: model_time: 0.0730 (0.0802)  evaluator_time: 0.0020 (0.0076)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "Testing Epoch: [39]  [  0/308]  eta: 0:00:37  lr: 0.000000  loss: 0.1646 (0.1646)  loss_classifier: 0.0591 (0.0591)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0256 (0.0256)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 0.1210  data: 0.0280  max mem: 1751\n",
      "Testing Epoch: [39]  [100/308]  eta: 0:00:28  lr: 0.000000  loss: 0.3194 (0.4796)  loss_classifier: 0.1345 (0.1547)  loss_box_reg: 0.1175 (0.1723)  loss_objectness: 0.0555 (0.1010)  loss_rpn_box_reg: 0.0186 (0.0517)  time: 0.1394  data: 0.0374  max mem: 1751\n",
      "Testing Epoch: [39]  [200/308]  eta: 0:00:14  lr: 0.000000  loss: 0.3489 (0.4562)  loss_classifier: 0.1377 (0.1491)  loss_box_reg: 0.1251 (0.1632)  loss_objectness: 0.0641 (0.0949)  loss_rpn_box_reg: 0.0197 (0.0490)  time: 0.1376  data: 0.0318  max mem: 1751\n",
      "Testing Epoch: [39]  [300/308]  eta: 0:00:01  lr: 0.000000  loss: 0.4592 (0.4537)  loss_classifier: 0.1559 (0.1494)  loss_box_reg: 0.1796 (0.1641)  loss_objectness: 0.0780 (0.0928)  loss_rpn_box_reg: 0.0265 (0.0474)  time: 0.1323  data: 0.0375  max mem: 1751\n",
      "Testing Epoch: [39]  [307/308]  eta: 0:00:00  lr: 0.000000  loss: 0.4592 (0.4538)  loss_classifier: 0.1860 (0.1496)  loss_box_reg: 0.1748 (0.1644)  loss_objectness: 0.0731 (0.0928)  loss_rpn_box_reg: 0.0271 (0.0469)  time: 0.1309  data: 0.0361  max mem: 1751\n",
      "Testing Epoch: [39] Total time: 0:00:42 (0.1375 s / it)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\caffe2\\serialize\\inline_container.cc:300] . unexpected pos 39309184 vs 39309080",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36msave\u001B[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001B[0m\n\u001B[0;32m    378\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0m_open_zipfile_writer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mopened_zipfile\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 379\u001B[1;33m                 \u001B[0m_save\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mopened_zipfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_module\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_protocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    380\u001B[0m                 \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36m_save\u001B[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001B[0m\n\u001B[0;32m    498\u001B[0m         \u001B[0mnum_bytes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstorage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mstorage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0melement_size\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 499\u001B[1;33m         \u001B[0mzip_file\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrite_record\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstorage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_ptr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_bytes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    500\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mOSError\u001B[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_620/3819277074.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mMODEL_TYPE\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_classes\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitem_list\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m \u001B[0mtrain_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevaluation_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mNUM_EPOCHS\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mMODEL_TYPE\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mMODEL_TYPE\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Git\\Torch_CLIP_FRCNN\\engine.py\u001B[0m in \u001B[0;36mtrain_model\u001B[1;34m(model, train_dataset, validation_dataset, num_epochs, MODEL_TYPE)\u001B[0m\n\u001B[0;32m    197\u001B[0m                           global_step=(epoch))\n\u001B[0;32m    198\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 199\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstate_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34mf'{MODEL_TYPE}_epoch_{epoch}.pth'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    200\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36msave\u001B[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001B[0m\n\u001B[0;32m    378\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0m_open_zipfile_writer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mopened_zipfile\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    379\u001B[0m                 \u001B[0m_save\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mopened_zipfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_module\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_protocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 380\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    381\u001B[0m         \u001B[0m_legacy_save\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_module\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_protocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    382\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36m__exit__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    257\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    258\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 259\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfile_like\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrite_end_of_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    260\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuffer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflush\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: [enforce fail at ..\\caffe2\\serialize\\inline_container.cc:300] . unexpected pos 39309184 vs 39309080"
     ]
    }
   ],
   "source": [
    "MODEL_TYPE='CLIP-FRCNN'\n",
    "\n",
    "# CLIP-FRCNN creates a FRCNN using CLIP features as the model backbone\n",
    "# Fully custom vanilla uses a pre-trained resnet50 backbone, and generates new anchor generator and roi pooling\n",
    "# Custom-Vanilla uses the pre-trained FRCNN from pytorch and replaces the roi heads only\n",
    "\n",
    "model = create_model(MODEL_TYPE, num_classes=(len(item_list)+1))\n",
    "train_model(model, train_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "acbb3df601244291b8b2fb9ea1137573",
      "32b6ec3046e64d04b4134553dc434fe0",
      "d8c6a316609d4ca5bfee139b93177ef5",
      "a1645bdfb02b42fba268f7000f183639",
      "4a4788a4fd6841788b20cfbf54a3d10b",
      "5d836b94d13e459d82429606496e4d4f",
      "a410071b34034a91aeda7ef1114969c2",
      "c063e7d90f6a4027b53d1b70c8c07742"
     ]
    },
    "id": "bHa6KRbEWuxz",
    "outputId": "3b4ebd0b-aa69-4a4d-b73c-b8cf24d8b461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Training Epoch: [0]  [   0/1229]  eta: 0:09:46  lr: 0.000010  loss: 2.7297 (2.7297)  loss_classifier: 1.8907 (1.8907)  loss_box_reg: 0.0239 (0.0239)  loss_objectness: 0.7061 (0.7061)  loss_rpn_box_reg: 0.1090 (0.1090)  time: 0.4770  data: 0.1310  max mem: 3239\n",
      "Training Epoch: [0]  [  10/1229]  eta: 0:08:21  lr: 0.000060  loss: 2.6521 (2.6988)  loss_classifier: 1.8757 (1.8517)  loss_box_reg: 0.0388 (0.0390)  loss_objectness: 0.6960 (0.6970)  loss_rpn_box_reg: 0.0922 (0.1111)  time: 0.4113  data: 0.1485  max mem: 3713\n",
      "Training Epoch: [0]  [  20/1229]  eta: 0:07:25  lr: 0.000110  loss: 2.5596 (2.5217)  loss_classifier: 1.7424 (1.6794)  loss_box_reg: 0.0388 (0.0368)  loss_objectness: 0.6896 (0.6891)  loss_rpn_box_reg: 0.0475 (0.1164)  time: 0.3627  data: 0.1444  max mem: 3713\n",
      "Training Epoch: [0]  [  30/1229]  eta: 0:07:02  lr: 0.000160  loss: 1.9389 (2.2141)  loss_classifier: 1.0558 (1.3762)  loss_box_reg: 0.0410 (0.0451)  loss_objectness: 0.6697 (0.6796)  loss_rpn_box_reg: 0.0417 (0.1132)  time: 0.3205  data: 0.1414  max mem: 3713\n",
      "Training Epoch: [0]  [  40/1229]  eta: 0:06:50  lr: 0.000210  loss: 1.1842 (1.9413)  loss_classifier: 0.3916 (1.1191)  loss_box_reg: 0.0466 (0.0495)  loss_objectness: 0.6327 (0.6637)  loss_rpn_box_reg: 0.0601 (0.1089)  time: 0.3214  data: 0.1429  max mem: 3713\n",
      "Training Epoch: [0]  [  50/1229]  eta: 0:06:50  lr: 0.000260  loss: 1.0235 (1.7450)  loss_classifier: 0.2925 (0.9482)  loss_box_reg: 0.0451 (0.0517)  loss_objectness: 0.5838 (0.6427)  loss_rpn_box_reg: 0.0615 (0.1024)  time: 0.3419  data: 0.1521  max mem: 3713\n",
      "Training Epoch: [0]  [  60/1229]  eta: 0:06:42  lr: 0.000310  loss: 0.8468 (1.6144)  loss_classifier: 0.2040 (0.8386)  loss_box_reg: 0.0535 (0.0543)  loss_objectness: 0.5325 (0.6213)  loss_rpn_box_reg: 0.0481 (0.1002)  time: 0.3424  data: 0.1510  max mem: 3713\n",
      "Training Epoch: [0]  [  70/1229]  eta: 0:06:34  lr: 0.000360  loss: 0.9589 (1.5231)  loss_classifier: 0.2647 (0.7662)  loss_box_reg: 0.0586 (0.0572)  loss_objectness: 0.5124 (0.6020)  loss_rpn_box_reg: 0.0639 (0.0976)  time: 0.3193  data: 0.1396  max mem: 3713\n",
      "Training Epoch: [0]  [  80/1229]  eta: 0:06:27  lr: 0.000410  loss: 0.9589 (1.4503)  loss_classifier: 0.2784 (0.7096)  loss_box_reg: 0.0633 (0.0620)  loss_objectness: 0.4647 (0.5822)  loss_rpn_box_reg: 0.0823 (0.0964)  time: 0.3154  data: 0.1375  max mem: 3713\n",
      "Training Epoch: [0]  [  90/1229]  eta: 0:06:22  lr: 0.000460  loss: 0.8817 (1.3822)  loss_classifier: 0.2657 (0.6598)  loss_box_reg: 0.0568 (0.0648)  loss_objectness: 0.4131 (0.5619)  loss_rpn_box_reg: 0.0540 (0.0958)  time: 0.3208  data: 0.1380  max mem: 3713\n",
      "Training Epoch: [0]  [ 100/1229]  eta: 0:06:16  lr: 0.000509  loss: 0.6891 (1.3096)  loss_classifier: 0.2044 (0.6138)  loss_box_reg: 0.0549 (0.0626)  loss_objectness: 0.3688 (0.5421)  loss_rpn_box_reg: 0.0360 (0.0911)  time: 0.3203  data: 0.1403  max mem: 3713\n",
      "Training Epoch: [0]  [ 110/1229]  eta: 0:06:12  lr: 0.000559  loss: 0.6639 (1.2598)  loss_classifier: 0.2044 (0.5782)  loss_box_reg: 0.0559 (0.0643)  loss_objectness: 0.3565 (0.5239)  loss_rpn_box_reg: 0.0360 (0.0934)  time: 0.3195  data: 0.1379  max mem: 3728\n",
      "Training Epoch: [0]  [ 120/1229]  eta: 0:06:07  lr: 0.000609  loss: 0.6971 (1.2156)  loss_classifier: 0.2290 (0.5482)  loss_box_reg: 0.0828 (0.0663)  loss_objectness: 0.3122 (0.5078)  loss_rpn_box_reg: 0.0620 (0.0933)  time: 0.3209  data: 0.1351  max mem: 3728\n",
      "Training Epoch: [0]  [ 130/1229]  eta: 0:06:02  lr: 0.000659  loss: 0.6607 (1.1727)  loss_classifier: 0.1898 (0.5198)  loss_box_reg: 0.0828 (0.0673)  loss_objectness: 0.3045 (0.4924)  loss_rpn_box_reg: 0.0602 (0.0932)  time: 0.3141  data: 0.1349  max mem: 3728\n",
      "Training Epoch: [0]  [ 140/1229]  eta: 0:05:58  lr: 0.000709  loss: 0.6408 (1.1384)  loss_classifier: 0.1501 (0.4961)  loss_box_reg: 0.0672 (0.0692)  loss_objectness: 0.2875 (0.4796)  loss_rpn_box_reg: 0.0822 (0.0935)  time: 0.3157  data: 0.1386  max mem: 3728\n",
      "Training Epoch: [0]  [ 150/1229]  eta: 0:05:54  lr: 0.000759  loss: 0.7152 (1.1162)  loss_classifier: 0.1665 (0.4791)  loss_box_reg: 0.0608 (0.0720)  loss_objectness: 0.3117 (0.4702)  loss_rpn_box_reg: 0.0822 (0.0948)  time: 0.3192  data: 0.1414  max mem: 3728\n",
      "Training Epoch: [0]  [ 160/1229]  eta: 0:05:50  lr: 0.000809  loss: 0.7064 (1.0883)  loss_classifier: 0.1718 (0.4599)  loss_box_reg: 0.0608 (0.0715)  loss_objectness: 0.2865 (0.4620)  loss_rpn_box_reg: 0.0813 (0.0948)  time: 0.3147  data: 0.1410  max mem: 3728\n",
      "Training Epoch: [0]  [ 170/1229]  eta: 0:05:46  lr: 0.000859  loss: 0.5387 (1.0616)  loss_classifier: 0.1657 (0.4411)  loss_box_reg: 0.0501 (0.0707)  loss_objectness: 0.2622 (0.4544)  loss_rpn_box_reg: 0.0370 (0.0954)  time: 0.3144  data: 0.1386  max mem: 3728\n",
      "Training Epoch: [0]  [ 180/1229]  eta: 0:05:41  lr: 0.000909  loss: 0.4938 (1.0314)  loss_classifier: 0.1381 (0.4246)  loss_box_reg: 0.0500 (0.0706)  loss_objectness: 0.2507 (0.4432)  loss_rpn_box_reg: 0.0522 (0.0930)  time: 0.3070  data: 0.1356  max mem: 3728\n",
      "Training Epoch: [0]  [ 190/1229]  eta: 0:05:37  lr: 0.000959  loss: 0.4751 (1.0100)  loss_classifier: 0.1359 (0.4115)  loss_box_reg: 0.0561 (0.0723)  loss_objectness: 0.2564 (0.4343)  loss_rpn_box_reg: 0.0527 (0.0918)  time: 0.3065  data: 0.1364  max mem: 3728\n",
      "Training Epoch: [0]  [ 200/1229]  eta: 0:05:33  lr: 0.001009  loss: 0.4342 (0.9804)  loss_classifier: 0.1059 (0.3964)  loss_box_reg: 0.0458 (0.0711)  loss_objectness: 0.2327 (0.4233)  loss_rpn_box_reg: 0.0520 (0.0896)  time: 0.3151  data: 0.1374  max mem: 3728\n",
      "Training Epoch: [0]  [ 210/1229]  eta: 0:05:30  lr: 0.001059  loss: 0.4966 (0.9653)  loss_classifier: 0.1209 (0.3854)  loss_box_reg: 0.0500 (0.0726)  loss_objectness: 0.2396 (0.4172)  loss_rpn_box_reg: 0.0520 (0.0901)  time: 0.3145  data: 0.1370  max mem: 3728\n",
      "Training Epoch: [0]  [ 220/1229]  eta: 0:05:25  lr: 0.001109  loss: 0.5869 (0.9572)  loss_classifier: 0.1438 (0.3766)  loss_box_reg: 0.1199 (0.0773)  loss_objectness: 0.2554 (0.4111)  loss_rpn_box_reg: 0.0722 (0.0922)  time: 0.3083  data: 0.1359  max mem: 3728\n",
      "Training Epoch: [0]  [ 230/1229]  eta: 0:05:22  lr: 0.001159  loss: 0.5136 (0.9362)  loss_classifier: 0.1159 (0.3655)  loss_box_reg: 0.0524 (0.0758)  loss_objectness: 0.2339 (0.4038)  loss_rpn_box_reg: 0.0432 (0.0911)  time: 0.3076  data: 0.1357  max mem: 3728\n",
      "Training Epoch: [0]  [ 240/1229]  eta: 0:05:18  lr: 0.001209  loss: 0.4240 (0.9243)  loss_classifier: 0.1149 (0.3577)  loss_box_reg: 0.0616 (0.0791)  loss_objectness: 0.2203 (0.3962)  loss_rpn_box_reg: 0.0451 (0.0913)  time: 0.3138  data: 0.1341  max mem: 3728\n",
      "Training Epoch: [0]  [ 250/1229]  eta: 0:05:14  lr: 0.001259  loss: 0.4996 (0.9057)  loss_classifier: 0.1402 (0.3491)  loss_box_reg: 0.0908 (0.0787)  loss_objectness: 0.1989 (0.3885)  loss_rpn_box_reg: 0.0467 (0.0895)  time: 0.3119  data: 0.1337  max mem: 3728\n",
      "Training Epoch: [0]  [ 260/1229]  eta: 0:05:10  lr: 0.001309  loss: 0.5180 (0.8943)  loss_classifier: 0.1398 (0.3416)  loss_box_reg: 0.0670 (0.0791)  loss_objectness: 0.1999 (0.3842)  loss_rpn_box_reg: 0.0467 (0.0894)  time: 0.3053  data: 0.1359  max mem: 3728\n",
      "Training Epoch: [0]  [ 270/1229]  eta: 0:05:07  lr: 0.001359  loss: 0.5890 (0.8919)  loss_classifier: 0.1627 (0.3355)  loss_box_reg: 0.0911 (0.0804)  loss_objectness: 0.2517 (0.3842)  loss_rpn_box_reg: 0.0519 (0.0919)  time: 0.3094  data: 0.1363  max mem: 3728\n",
      "Training Epoch: [0]  [ 280/1229]  eta: 0:05:03  lr: 0.001409  loss: 0.5606 (0.8819)  loss_classifier: 0.1627 (0.3301)  loss_box_reg: 0.0952 (0.0813)  loss_objectness: 0.2217 (0.3791)  loss_rpn_box_reg: 0.0556 (0.0915)  time: 0.3120  data: 0.1375  max mem: 3728\n",
      "Training Epoch: [0]  [ 290/1229]  eta: 0:05:00  lr: 0.001459  loss: 0.5087 (0.8707)  loss_classifier: 0.1433 (0.3243)  loss_box_reg: 0.0995 (0.0830)  loss_objectness: 0.2133 (0.3736)  loss_rpn_box_reg: 0.0439 (0.0899)  time: 0.3064  data: 0.1363  max mem: 3728\n",
      "Training Epoch: [0]  [ 300/1229]  eta: 0:04:56  lr: 0.001508  loss: 0.5071 (0.8594)  loss_classifier: 0.1319 (0.3187)  loss_box_reg: 0.0943 (0.0841)  loss_objectness: 0.2021 (0.3678)  loss_rpn_box_reg: 0.0444 (0.0888)  time: 0.3093  data: 0.1335  max mem: 3728\n",
      "Training Epoch: [0]  [ 310/1229]  eta: 0:04:53  lr: 0.001558  loss: 0.5130 (0.8528)  loss_classifier: 0.1312 (0.3139)  loss_box_reg: 0.0943 (0.0857)  loss_objectness: 0.2236 (0.3643)  loss_rpn_box_reg: 0.0581 (0.0888)  time: 0.3201  data: 0.1334  max mem: 3728\n",
      "Training Epoch: [0]  [ 320/1229]  eta: 0:04:50  lr: 0.001608  loss: 0.4770 (0.8415)  loss_classifier: 0.1254 (0.3081)  loss_box_reg: 0.0939 (0.0860)  loss_objectness: 0.1757 (0.3593)  loss_rpn_box_reg: 0.0464 (0.0881)  time: 0.3241  data: 0.1334  max mem: 3728\n",
      "Training Epoch: [0]  [ 330/1229]  eta: 0:04:47  lr: 0.001658  loss: 0.4402 (0.8357)  loss_classifier: 0.1196 (0.3043)  loss_box_reg: 0.0718 (0.0861)  loss_objectness: 0.1811 (0.3568)  loss_rpn_box_reg: 0.0486 (0.0885)  time: 0.3190  data: 0.1358  max mem: 3728\n",
      "Training Epoch: [0]  [ 340/1229]  eta: 0:04:44  lr: 0.001708  loss: 0.4805 (0.8293)  loss_classifier: 0.1213 (0.3004)  loss_box_reg: 0.0684 (0.0872)  loss_objectness: 0.1901 (0.3527)  loss_rpn_box_reg: 0.0541 (0.0890)  time: 0.3191  data: 0.1395  max mem: 3728\n",
      "Training Epoch: [0]  [ 350/1229]  eta: 0:04:40  lr: 0.001758  loss: 0.4917 (0.8227)  loss_classifier: 0.1213 (0.2963)  loss_box_reg: 0.0684 (0.0875)  loss_objectness: 0.1895 (0.3484)  loss_rpn_box_reg: 0.0901 (0.0904)  time: 0.3154  data: 0.1394  max mem: 3728\n",
      "Training Epoch: [0]  [ 360/1229]  eta: 0:04:37  lr: 0.001808  loss: 0.5175 (0.8171)  loss_classifier: 0.1393 (0.2926)  loss_box_reg: 0.0812 (0.0881)  loss_objectness: 0.2043 (0.3450)  loss_rpn_box_reg: 0.0602 (0.0914)  time: 0.3154  data: 0.1418  max mem: 3728\n",
      "Training Epoch: [0]  [ 370/1229]  eta: 0:04:34  lr: 0.001858  loss: 0.4679 (0.8091)  loss_classifier: 0.1476 (0.2884)  loss_box_reg: 0.0812 (0.0880)  loss_objectness: 0.2042 (0.3418)  loss_rpn_box_reg: 0.0380 (0.0910)  time: 0.3228  data: 0.1426  max mem: 3728\n",
      "Training Epoch: [0]  [ 380/1229]  eta: 0:04:31  lr: 0.001908  loss: 0.3824 (0.8040)  loss_classifier: 0.1476 (0.2838)  loss_box_reg: 0.0476 (0.0874)  loss_objectness: 0.1975 (0.3402)  loss_rpn_box_reg: 0.0372 (0.0926)  time: 0.3179  data: 0.1400  max mem: 3728\n",
      "Training Epoch: [0]  [ 390/1229]  eta: 0:04:28  lr: 0.001958  loss: 0.4294 (0.7967)  loss_classifier: 0.1200 (0.2804)  loss_box_reg: 0.0953 (0.0878)  loss_objectness: 0.1845 (0.3368)  loss_rpn_box_reg: 0.0362 (0.0918)  time: 0.3182  data: 0.1406  max mem: 3728\n",
      "Training Epoch: [0]  [ 400/1229]  eta: 0:04:25  lr: 0.002008  loss: 0.5681 (0.7966)  loss_classifier: 0.1881 (0.2793)  loss_box_reg: 0.1236 (0.0908)  loss_objectness: 0.2109 (0.3340)  loss_rpn_box_reg: 0.0553 (0.0925)  time: 0.3268  data: 0.1430  max mem: 3728\n",
      "Training Epoch: [0]  [ 410/1229]  eta: 0:04:21  lr: 0.002058  loss: 0.6258 (0.7930)  loss_classifier: 0.2327 (0.2778)  loss_box_reg: 0.1865 (0.0924)  loss_objectness: 0.2252 (0.3311)  loss_rpn_box_reg: 0.0609 (0.0917)  time: 0.3238  data: 0.1425  max mem: 3730\n",
      "Training Epoch: [0]  [ 420/1229]  eta: 0:04:18  lr: 0.002108  loss: 0.5521 (0.7881)  loss_classifier: 0.1778 (0.2756)  loss_box_reg: 0.1314 (0.0940)  loss_objectness: 0.2093 (0.3277)  loss_rpn_box_reg: 0.0461 (0.0907)  time: 0.3210  data: 0.1401  max mem: 3730\n",
      "Training Epoch: [0]  [ 430/1229]  eta: 0:04:15  lr: 0.002158  loss: 0.4960 (0.7811)  loss_classifier: 0.1516 (0.2723)  loss_box_reg: 0.1003 (0.0938)  loss_objectness: 0.1853 (0.3247)  loss_rpn_box_reg: 0.0445 (0.0904)  time: 0.3236  data: 0.1397  max mem: 3730\n",
      "Training Epoch: [0]  [ 440/1229]  eta: 0:04:12  lr: 0.002208  loss: 0.4343 (0.7749)  loss_classifier: 0.1247 (0.2696)  loss_box_reg: 0.0692 (0.0940)  loss_objectness: 0.1709 (0.3212)  loss_rpn_box_reg: 0.0499 (0.0901)  time: 0.3233  data: 0.1423  max mem: 3730\n",
      "Training Epoch: [0]  [ 450/1229]  eta: 0:04:09  lr: 0.002258  loss: 0.5311 (0.7716)  loss_classifier: 0.1530 (0.2674)  loss_box_reg: 0.1009 (0.0951)  loss_objectness: 0.1737 (0.3187)  loss_rpn_box_reg: 0.0665 (0.0904)  time: 0.3207  data: 0.1436  max mem: 3730\n",
      "Training Epoch: [0]  [ 460/1229]  eta: 0:04:06  lr: 0.002308  loss: 0.4583 (0.7657)  loss_classifier: 0.1280 (0.2639)  loss_box_reg: 0.0729 (0.0942)  loss_objectness: 0.1740 (0.3154)  loss_rpn_box_reg: 0.0665 (0.0922)  time: 0.3221  data: 0.1404  max mem: 3730\n",
      "Training Epoch: [0]  [ 470/1229]  eta: 0:04:02  lr: 0.002358  loss: 0.4704 (0.7638)  loss_classifier: 0.1342 (0.2633)  loss_box_reg: 0.0659 (0.0954)  loss_objectness: 0.1740 (0.3131)  loss_rpn_box_reg: 0.0837 (0.0921)  time: 0.3195  data: 0.1396  max mem: 3730\n",
      "Training Epoch: [0]  [ 480/1229]  eta: 0:03:59  lr: 0.002408  loss: 0.6219 (0.7597)  loss_classifier: 0.1959 (0.2613)  loss_box_reg: 0.1108 (0.0957)  loss_objectness: 0.2000 (0.3106)  loss_rpn_box_reg: 0.0840 (0.0921)  time: 0.3142  data: 0.1397  max mem: 3730\n",
      "Training Epoch: [0]  [ 490/1229]  eta: 0:03:56  lr: 0.002458  loss: 0.5689 (0.7552)  loss_classifier: 0.1545 (0.2590)  loss_box_reg: 0.0986 (0.0958)  loss_objectness: 0.1762 (0.3081)  loss_rpn_box_reg: 0.0627 (0.0923)  time: 0.3147  data: 0.1386  max mem: 3730\n",
      "Training Epoch: [0]  [ 500/1229]  eta: 0:03:53  lr: 0.002507  loss: 0.4963 (0.7521)  loss_classifier: 0.1419 (0.2574)  loss_box_reg: 0.0837 (0.0965)  loss_objectness: 0.1762 (0.3059)  loss_rpn_box_reg: 0.0703 (0.0923)  time: 0.3198  data: 0.1377  max mem: 3730\n",
      "Training Epoch: [0]  [ 510/1229]  eta: 0:03:49  lr: 0.002557  loss: 0.6640 (0.7506)  loss_classifier: 0.1552 (0.2560)  loss_box_reg: 0.1301 (0.0975)  loss_objectness: 0.1954 (0.3046)  loss_rpn_box_reg: 0.0674 (0.0924)  time: 0.3217  data: 0.1383  max mem: 3730\n",
      "Training Epoch: [0]  [ 520/1229]  eta: 0:03:46  lr: 0.002607  loss: 0.5203 (0.7454)  loss_classifier: 0.1552 (0.2540)  loss_box_reg: 0.0961 (0.0975)  loss_objectness: 0.1732 (0.3020)  loss_rpn_box_reg: 0.0562 (0.0919)  time: 0.3223  data: 0.1377  max mem: 3730\n",
      "Training Epoch: [0]  [ 530/1229]  eta: 0:03:43  lr: 0.002657  loss: 0.4839 (0.7404)  loss_classifier: 0.1349 (0.2520)  loss_box_reg: 0.0821 (0.0978)  loss_objectness: 0.1353 (0.2989)  loss_rpn_box_reg: 0.0547 (0.0916)  time: 0.3230  data: 0.1355  max mem: 3730\n",
      "Training Epoch: [0]  [ 540/1229]  eta: 0:03:40  lr: 0.002707  loss: 0.4895 (0.7399)  loss_classifier: 0.1431 (0.2514)  loss_box_reg: 0.1080 (0.0996)  loss_objectness: 0.1523 (0.2970)  loss_rpn_box_reg: 0.0611 (0.0920)  time: 0.3139  data: 0.1369  max mem: 3730\n",
      "Training Epoch: [0]  [ 550/1229]  eta: 0:03:37  lr: 0.002757  loss: 0.5329 (0.7364)  loss_classifier: 0.1431 (0.2498)  loss_box_reg: 0.1080 (0.1000)  loss_objectness: 0.1692 (0.2949)  loss_rpn_box_reg: 0.0501 (0.0918)  time: 0.3105  data: 0.1398  max mem: 3730\n",
      "Training Epoch: [0]  [ 560/1229]  eta: 0:03:33  lr: 0.002807  loss: 0.4944 (0.7332)  loss_classifier: 0.1509 (0.2485)  loss_box_reg: 0.1109 (0.1008)  loss_objectness: 0.1393 (0.2924)  loss_rpn_box_reg: 0.0340 (0.0915)  time: 0.3191  data: 0.1380  max mem: 3730\n",
      "Training Epoch: [0]  [ 570/1229]  eta: 0:03:30  lr: 0.002857  loss: 0.4989 (0.7312)  loss_classifier: 0.1750 (0.2470)  loss_box_reg: 0.1020 (0.1011)  loss_objectness: 0.1658 (0.2915)  loss_rpn_box_reg: 0.0423 (0.0917)  time: 0.3224  data: 0.1349  max mem: 3730\n",
      "Training Epoch: [0]  [ 580/1229]  eta: 0:03:27  lr: 0.002907  loss: 0.4314 (0.7267)  loss_classifier: 0.1258 (0.2452)  loss_box_reg: 0.0952 (0.1014)  loss_objectness: 0.1417 (0.2888)  loss_rpn_box_reg: 0.0423 (0.0912)  time: 0.3224  data: 0.1360  max mem: 3730\n",
      "Training Epoch: [0]  [ 590/1229]  eta: 0:03:24  lr: 0.002957  loss: 0.4416 (0.7232)  loss_classifier: 0.1283 (0.2440)  loss_box_reg: 0.0936 (0.1013)  loss_objectness: 0.1339 (0.2867)  loss_rpn_box_reg: 0.0356 (0.0912)  time: 0.3277  data: 0.1363  max mem: 3730\n",
      "Training Epoch: [0]  [ 600/1229]  eta: 0:03:21  lr: 0.003007  loss: 0.4594 (0.7187)  loss_classifier: 0.1471 (0.2424)  loss_box_reg: 0.0914 (0.1012)  loss_objectness: 0.1439 (0.2844)  loss_rpn_box_reg: 0.0606 (0.0907)  time: 0.3248  data: 0.1397  max mem: 3730\n",
      "Training Epoch: [0]  [ 610/1229]  eta: 0:03:18  lr: 0.003057  loss: 0.5446 (0.7174)  loss_classifier: 0.1471 (0.2416)  loss_box_reg: 0.0914 (0.1017)  loss_objectness: 0.1693 (0.2831)  loss_rpn_box_reg: 0.0726 (0.0910)  time: 0.3196  data: 0.1422  max mem: 3730\n",
      "Training Epoch: [0]  [ 620/1229]  eta: 0:03:14  lr: 0.003107  loss: 0.6265 (0.7152)  loss_classifier: 0.1488 (0.2409)  loss_box_reg: 0.1134 (0.1024)  loss_objectness: 0.1848 (0.2816)  loss_rpn_box_reg: 0.0693 (0.0904)  time: 0.3213  data: 0.1408  max mem: 3730\n",
      "Training Epoch: [0]  [ 630/1229]  eta: 0:03:11  lr: 0.003157  loss: 0.4775 (0.7108)  loss_classifier: 0.1488 (0.2393)  loss_box_reg: 0.1185 (0.1024)  loss_objectness: 0.1516 (0.2792)  loss_rpn_box_reg: 0.0374 (0.0898)  time: 0.3233  data: 0.1392  max mem: 3730\n",
      "Training Epoch: [0]  [ 640/1229]  eta: 0:03:08  lr: 0.003207  loss: 0.4102 (0.7081)  loss_classifier: 0.1502 (0.2383)  loss_box_reg: 0.0973 (0.1027)  loss_objectness: 0.1283 (0.2777)  loss_rpn_box_reg: 0.0274 (0.0894)  time: 0.3222  data: 0.1407  max mem: 3730\n",
      "Training Epoch: [0]  [ 650/1229]  eta: 0:03:05  lr: 0.003257  loss: 0.4006 (0.7053)  loss_classifier: 0.1214 (0.2370)  loss_box_reg: 0.0806 (0.1027)  loss_objectness: 0.1795 (0.2764)  loss_rpn_box_reg: 0.0394 (0.0892)  time: 0.3265  data: 0.1419  max mem: 3730\n",
      "Training Epoch: [0]  [ 660/1229]  eta: 0:03:02  lr: 0.003307  loss: 0.5469 (0.7040)  loss_classifier: 0.1495 (0.2364)  loss_box_reg: 0.1264 (0.1034)  loss_objectness: 0.1868 (0.2752)  loss_rpn_box_reg: 0.0433 (0.0890)  time: 0.3271  data: 0.1400  max mem: 3730\n",
      "Training Epoch: [0]  [ 670/1229]  eta: 0:02:58  lr: 0.003357  loss: 0.6179 (0.7031)  loss_classifier: 0.1659 (0.2355)  loss_box_reg: 0.1396 (0.1040)  loss_objectness: 0.1913 (0.2742)  loss_rpn_box_reg: 0.0632 (0.0894)  time: 0.3185  data: 0.1416  max mem: 3730\n",
      "Training Epoch: [0]  [ 680/1229]  eta: 0:02:55  lr: 0.003407  loss: 0.5467 (0.7005)  loss_classifier: 0.1535 (0.2344)  loss_box_reg: 0.1091 (0.1041)  loss_objectness: 0.1790 (0.2724)  loss_rpn_box_reg: 0.0648 (0.0896)  time: 0.3148  data: 0.1411  max mem: 3730\n",
      "Training Epoch: [0]  [ 690/1229]  eta: 0:02:52  lr: 0.003457  loss: 0.7097 (0.7012)  loss_classifier: 0.1626 (0.2342)  loss_box_reg: 0.1184 (0.1052)  loss_objectness: 0.1849 (0.2721)  loss_rpn_box_reg: 0.0720 (0.0898)  time: 0.3168  data: 0.1399  max mem: 3730\n",
      "Training Epoch: [0]  [ 700/1229]  eta: 0:02:49  lr: 0.003506  loss: 0.7391 (0.6999)  loss_classifier: 0.1893 (0.2332)  loss_box_reg: 0.1403 (0.1054)  loss_objectness: 0.2036 (0.2712)  loss_rpn_box_reg: 0.0774 (0.0901)  time: 0.3231  data: 0.1406  max mem: 3730\n",
      "Training Epoch: [0]  [ 710/1229]  eta: 0:02:46  lr: 0.003556  loss: 0.6260 (0.6981)  loss_classifier: 0.1571 (0.2325)  loss_box_reg: 0.1236 (0.1058)  loss_objectness: 0.1722 (0.2700)  loss_rpn_box_reg: 0.0630 (0.0898)  time: 0.3287  data: 0.1411  max mem: 3730\n",
      "Training Epoch: [0]  [ 720/1229]  eta: 0:02:43  lr: 0.003606  loss: 0.6440 (0.6980)  loss_classifier: 0.1749 (0.2321)  loss_box_reg: 0.1221 (0.1064)  loss_objectness: 0.1779 (0.2690)  loss_rpn_box_reg: 0.0638 (0.0905)  time: 0.3264  data: 0.1408  max mem: 3730\n",
      "Training Epoch: [0]  [ 730/1229]  eta: 0:02:40  lr: 0.003656  loss: 0.6289 (0.6963)  loss_classifier: 0.1793 (0.2315)  loss_box_reg: 0.1145 (0.1067)  loss_objectness: 0.1779 (0.2677)  loss_rpn_box_reg: 0.0606 (0.0905)  time: 0.3308  data: 0.1491  max mem: 3730\n",
      "Training Epoch: [0]  [ 740/1229]  eta: 0:02:36  lr: 0.003706  loss: 0.5095 (0.6948)  loss_classifier: 0.1793 (0.2310)  loss_box_reg: 0.0944 (0.1072)  loss_objectness: 0.1649 (0.2664)  loss_rpn_box_reg: 0.0422 (0.0902)  time: 0.3365  data: 0.1532  max mem: 3730\n",
      "Training Epoch: [0]  [ 750/1229]  eta: 0:02:33  lr: 0.003756  loss: 0.4659 (0.6927)  loss_classifier: 0.1762 (0.2301)  loss_box_reg: 0.0993 (0.1073)  loss_objectness: 0.1451 (0.2652)  loss_rpn_box_reg: 0.0530 (0.0900)  time: 0.3233  data: 0.1444  max mem: 3730\n",
      "Training Epoch: [0]  [ 760/1229]  eta: 0:02:30  lr: 0.003806  loss: 0.4674 (0.6916)  loss_classifier: 0.1762 (0.2296)  loss_box_reg: 0.1133 (0.1077)  loss_objectness: 0.1451 (0.2644)  loss_rpn_box_reg: 0.0612 (0.0899)  time: 0.3167  data: 0.1413  max mem: 3730\n",
      "Training Epoch: [0]  [ 770/1229]  eta: 0:02:27  lr: 0.003856  loss: 0.5235 (0.6911)  loss_classifier: 0.1781 (0.2295)  loss_box_reg: 0.1213 (0.1084)  loss_objectness: 0.1361 (0.2631)  loss_rpn_box_reg: 0.0682 (0.0901)  time: 0.3297  data: 0.1451  max mem: 3730\n",
      "Training Epoch: [0]  [ 780/1229]  eta: 0:02:24  lr: 0.003906  loss: 0.5251 (0.6900)  loss_classifier: 0.1780 (0.2291)  loss_box_reg: 0.1515 (0.1089)  loss_objectness: 0.1558 (0.2619)  loss_rpn_box_reg: 0.0533 (0.0901)  time: 0.3338  data: 0.1487  max mem: 3730\n",
      "Training Epoch: [0]  [ 790/1229]  eta: 0:02:20  lr: 0.003956  loss: 0.6065 (0.6883)  loss_classifier: 0.1866 (0.2283)  loss_box_reg: 0.1515 (0.1093)  loss_objectness: 0.1527 (0.2605)  loss_rpn_box_reg: 0.0533 (0.0902)  time: 0.3295  data: 0.1525  max mem: 3730\n",
      "Training Epoch: [0]  [ 800/1229]  eta: 0:02:17  lr: 0.004006  loss: 0.6313 (0.6876)  loss_classifier: 0.1866 (0.2278)  loss_box_reg: 0.1311 (0.1098)  loss_objectness: 0.1255 (0.2594)  loss_rpn_box_reg: 0.0861 (0.0906)  time: 0.3403  data: 0.1519  max mem: 3730\n",
      "Training Epoch: [0]  [ 810/1229]  eta: 0:02:14  lr: 0.004056  loss: 0.6109 (0.6863)  loss_classifier: 0.1780 (0.2275)  loss_box_reg: 0.1390 (0.1102)  loss_objectness: 0.1474 (0.2582)  loss_rpn_box_reg: 0.0837 (0.0905)  time: 0.3370  data: 0.1462  max mem: 3730\n",
      "Training Epoch: [0]  [ 820/1229]  eta: 0:02:11  lr: 0.004106  loss: 0.5483 (0.6846)  loss_classifier: 0.1780 (0.2270)  loss_box_reg: 0.1390 (0.1104)  loss_objectness: 0.1520 (0.2571)  loss_rpn_box_reg: 0.0598 (0.0901)  time: 0.3227  data: 0.1451  max mem: 3730\n",
      "Training Epoch: [0]  [ 830/1229]  eta: 0:02:08  lr: 0.004156  loss: 0.4471 (0.6822)  loss_classifier: 0.1520 (0.2259)  loss_box_reg: 0.1001 (0.1102)  loss_objectness: 0.1289 (0.2559)  loss_rpn_box_reg: 0.0491 (0.0900)  time: 0.3312  data: 0.1428  max mem: 3730\n",
      "Training Epoch: [0]  [ 840/1229]  eta: 0:02:05  lr: 0.004206  loss: 0.3828 (0.6788)  loss_classifier: 0.1187 (0.2246)  loss_box_reg: 0.0850 (0.1099)  loss_objectness: 0.1152 (0.2545)  loss_rpn_box_reg: 0.0380 (0.0898)  time: 0.3346  data: 0.1405  max mem: 3730\n",
      "Training Epoch: [0]  [ 850/1229]  eta: 0:02:02  lr: 0.004256  loss: 0.3702 (0.6766)  loss_classifier: 0.1142 (0.2237)  loss_box_reg: 0.0732 (0.1099)  loss_objectness: 0.1261 (0.2534)  loss_rpn_box_reg: 0.0314 (0.0896)  time: 0.3286  data: 0.1421  max mem: 3730\n",
      "Training Epoch: [0]  [ 860/1229]  eta: 0:01:58  lr: 0.004306  loss: 0.3524 (0.6733)  loss_classifier: 0.1131 (0.2226)  loss_box_reg: 0.0732 (0.1094)  loss_objectness: 0.1596 (0.2523)  loss_rpn_box_reg: 0.0339 (0.0890)  time: 0.3298  data: 0.1442  max mem: 3730\n",
      "Training Epoch: [0]  [ 870/1229]  eta: 0:01:55  lr: 0.004356  loss: 0.3308 (0.6702)  loss_classifier: 0.1131 (0.2217)  loss_box_reg: 0.0676 (0.1094)  loss_objectness: 0.1443 (0.2507)  loss_rpn_box_reg: 0.0339 (0.0884)  time: 0.3289  data: 0.1468  max mem: 3730\n",
      "Training Epoch: [0]  [ 880/1229]  eta: 0:01:52  lr: 0.004406  loss: 0.4041 (0.6687)  loss_classifier: 0.1391 (0.2210)  loss_box_reg: 0.1143 (0.1098)  loss_objectness: 0.0879 (0.2494)  loss_rpn_box_reg: 0.0399 (0.0885)  time: 0.3318  data: 0.1466  max mem: 3730\n",
      "Training Epoch: [0]  [ 890/1229]  eta: 0:01:49  lr: 0.004456  loss: 0.5328 (0.6682)  loss_classifier: 0.1490 (0.2206)  loss_box_reg: 0.1143 (0.1100)  loss_objectness: 0.1244 (0.2485)  loss_rpn_box_reg: 0.0534 (0.0891)  time: 0.3342  data: 0.1455  max mem: 3730\n",
      "Training Epoch: [0]  [ 900/1229]  eta: 0:01:46  lr: 0.004505  loss: 0.5785 (0.6677)  loss_classifier: 0.1526 (0.2202)  loss_box_reg: 0.1060 (0.1103)  loss_objectness: 0.1383 (0.2479)  loss_rpn_box_reg: 0.0649 (0.0893)  time: 0.3301  data: 0.1454  max mem: 3730\n",
      "Training Epoch: [0]  [ 910/1229]  eta: 0:01:42  lr: 0.004555  loss: 0.5236 (0.6666)  loss_classifier: 0.1596 (0.2198)  loss_box_reg: 0.1060 (0.1107)  loss_objectness: 0.1729 (0.2470)  loss_rpn_box_reg: 0.0645 (0.0891)  time: 0.3317  data: 0.1472  max mem: 3730\n",
      "Training Epoch: [0]  [ 920/1229]  eta: 0:01:39  lr: 0.004605  loss: 0.4698 (0.6662)  loss_classifier: 0.1572 (0.2197)  loss_box_reg: 0.1046 (0.1116)  loss_objectness: 0.1509 (0.2462)  loss_rpn_box_reg: 0.0404 (0.0887)  time: 0.3303  data: 0.1468  max mem: 3730\n",
      "Training Epoch: [0]  [ 930/1229]  eta: 0:01:36  lr: 0.004655  loss: 0.4732 (0.6647)  loss_classifier: 0.1603 (0.2193)  loss_box_reg: 0.1415 (0.1120)  loss_objectness: 0.1425 (0.2451)  loss_rpn_box_reg: 0.0404 (0.0882)  time: 0.3263  data: 0.1434  max mem: 3730\n",
      "Training Epoch: [0]  [ 940/1229]  eta: 0:01:33  lr: 0.004705  loss: 0.5856 (0.6636)  loss_classifier: 0.1881 (0.2188)  loss_box_reg: 0.1303 (0.1123)  loss_objectness: 0.1610 (0.2443)  loss_rpn_box_reg: 0.0550 (0.0883)  time: 0.3277  data: 0.1440  max mem: 3730\n",
      "Training Epoch: [0]  [ 950/1229]  eta: 0:01:30  lr: 0.004755  loss: 0.6278 (0.6624)  loss_classifier: 0.1881 (0.2184)  loss_box_reg: 0.1245 (0.1127)  loss_objectness: 0.1610 (0.2434)  loss_rpn_box_reg: 0.0595 (0.0880)  time: 0.3265  data: 0.1462  max mem: 3730\n",
      "Training Epoch: [0]  [ 960/1229]  eta: 0:01:26  lr: 0.004805  loss: 0.4432 (0.6603)  loss_classifier: 0.1482 (0.2177)  loss_box_reg: 0.0989 (0.1125)  loss_objectness: 0.1370 (0.2425)  loss_rpn_box_reg: 0.0391 (0.0877)  time: 0.3252  data: 0.1479  max mem: 3730\n",
      "Training Epoch: [0]  [ 970/1229]  eta: 0:01:23  lr: 0.004855  loss: 0.4432 (0.6599)  loss_classifier: 0.1691 (0.2174)  loss_box_reg: 0.0934 (0.1125)  loss_objectness: 0.1405 (0.2420)  loss_rpn_box_reg: 0.0521 (0.0880)  time: 0.3250  data: 0.1466  max mem: 3730\n",
      "Training Epoch: [0]  [ 980/1229]  eta: 0:01:20  lr: 0.004905  loss: 0.5246 (0.6598)  loss_classifier: 0.1781 (0.2170)  loss_box_reg: 0.1063 (0.1127)  loss_objectness: 0.1769 (0.2419)  loss_rpn_box_reg: 0.0523 (0.0882)  time: 0.3243  data: 0.1475  max mem: 3730\n",
      "Training Epoch: [0]  [ 990/1229]  eta: 0:01:17  lr: 0.004955  loss: 0.4904 (0.6580)  loss_classifier: 0.1455 (0.2165)  loss_box_reg: 0.0891 (0.1126)  loss_objectness: 0.1769 (0.2411)  loss_rpn_box_reg: 0.0395 (0.0878)  time: 0.3236  data: 0.1476  max mem: 3730\n",
      "Training Epoch: [0]  [1000/1229]  eta: 0:01:13  lr: 0.005000  loss: 0.3768 (0.6554)  loss_classifier: 0.1364 (0.2157)  loss_box_reg: 0.0850 (0.1125)  loss_objectness: 0.1403 (0.2399)  loss_rpn_box_reg: 0.0348 (0.0873)  time: 0.3305  data: 0.1436  max mem: 3730\n",
      "Training Epoch: [0]  [1010/1229]  eta: 0:01:10  lr: 0.005000  loss: 0.4874 (0.6545)  loss_classifier: 0.1431 (0.2152)  loss_box_reg: 0.1033 (0.1127)  loss_objectness: 0.1290 (0.2392)  loss_rpn_box_reg: 0.0312 (0.0874)  time: 0.3257  data: 0.1425  max mem: 3730\n",
      "Training Epoch: [0]  [1020/1229]  eta: 0:01:07  lr: 0.005000  loss: 0.5007 (0.6532)  loss_classifier: 0.1444 (0.2149)  loss_box_reg: 0.1113 (0.1129)  loss_objectness: 0.1473 (0.2384)  loss_rpn_box_reg: 0.0352 (0.0869)  time: 0.3205  data: 0.1449  max mem: 3730\n",
      "Training Epoch: [0]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.5007 (0.6526)  loss_classifier: 0.1711 (0.2149)  loss_box_reg: 0.1480 (0.1136)  loss_objectness: 0.1470 (0.2376)  loss_rpn_box_reg: 0.0396 (0.0865)  time: 0.3295  data: 0.1454  max mem: 3730\n",
      "Training Epoch: [0]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.4569 (0.6510)  loss_classifier: 0.1803 (0.2145)  loss_box_reg: 0.1206 (0.1136)  loss_objectness: 0.1356 (0.2367)  loss_rpn_box_reg: 0.0252 (0.0862)  time: 0.3299  data: 0.1429  max mem: 3730\n",
      "Training Epoch: [0]  [1050/1229]  eta: 0:00:57  lr: 0.005000  loss: 0.4569 (0.6505)  loss_classifier: 0.1759 (0.2142)  loss_box_reg: 0.1042 (0.1135)  loss_objectness: 0.1383 (0.2363)  loss_rpn_box_reg: 0.0290 (0.0865)  time: 0.3284  data: 0.1430  max mem: 3730\n",
      "Training Epoch: [0]  [1060/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.4834 (0.6491)  loss_classifier: 0.1685 (0.2137)  loss_box_reg: 0.0828 (0.1134)  loss_objectness: 0.1416 (0.2358)  loss_rpn_box_reg: 0.0424 (0.0863)  time: 0.3231  data: 0.1441  max mem: 3730\n",
      "Training Epoch: [0]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.5575 (0.6488)  loss_classifier: 0.1834 (0.2137)  loss_box_reg: 0.1339 (0.1139)  loss_objectness: 0.1416 (0.2351)  loss_rpn_box_reg: 0.0492 (0.0861)  time: 0.3242  data: 0.1463  max mem: 3743\n",
      "Training Epoch: [0]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.5034 (0.6467)  loss_classifier: 0.1678 (0.2130)  loss_box_reg: 0.1231 (0.1137)  loss_objectness: 0.1385 (0.2343)  loss_rpn_box_reg: 0.0322 (0.0857)  time: 0.3317  data: 0.1457  max mem: 3743\n",
      "Training Epoch: [0]  [1090/1229]  eta: 0:00:44  lr: 0.005000  loss: 0.4830 (0.6459)  loss_classifier: 0.1693 (0.2130)  loss_box_reg: 0.1245 (0.1142)  loss_objectness: 0.1238 (0.2334)  loss_rpn_box_reg: 0.0372 (0.0854)  time: 0.3396  data: 0.1487  max mem: 3743\n",
      "Training Epoch: [0]  [1100/1229]  eta: 0:00:41  lr: 0.005000  loss: 0.5733 (0.6456)  loss_classifier: 0.1924 (0.2128)  loss_box_reg: 0.1563 (0.1148)  loss_objectness: 0.1238 (0.2329)  loss_rpn_box_reg: 0.0507 (0.0851)  time: 0.3372  data: 0.1488  max mem: 3743\n",
      "Training Epoch: [0]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.4520 (0.6444)  loss_classifier: 0.1623 (0.2125)  loss_box_reg: 0.1075 (0.1150)  loss_objectness: 0.1426 (0.2322)  loss_rpn_box_reg: 0.0284 (0.0847)  time: 0.3213  data: 0.1436  max mem: 3743\n",
      "Training Epoch: [0]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4281 (0.6431)  loss_classifier: 0.1497 (0.2119)  loss_box_reg: 0.0960 (0.1151)  loss_objectness: 0.1331 (0.2317)  loss_rpn_box_reg: 0.0233 (0.0843)  time: 0.3229  data: 0.1451  max mem: 3743\n",
      "Training Epoch: [0]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.4838 (0.6428)  loss_classifier: 0.1476 (0.2118)  loss_box_reg: 0.1100 (0.1154)  loss_objectness: 0.1295 (0.2314)  loss_rpn_box_reg: 0.0376 (0.0842)  time: 0.3246  data: 0.1433  max mem: 3743\n",
      "Training Epoch: [0]  [1140/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.5606 (0.6418)  loss_classifier: 0.1587 (0.2116)  loss_box_reg: 0.1354 (0.1157)  loss_objectness: 0.1569 (0.2309)  loss_rpn_box_reg: 0.0390 (0.0837)  time: 0.3155  data: 0.1421  max mem: 3743\n",
      "Training Epoch: [0]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.5606 (0.6410)  loss_classifier: 0.1803 (0.2114)  loss_box_reg: 0.1354 (0.1158)  loss_objectness: 0.1778 (0.2304)  loss_rpn_box_reg: 0.0447 (0.0835)  time: 0.3167  data: 0.1442  max mem: 3743\n",
      "Training Epoch: [0]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.4542 (0.6399)  loss_classifier: 0.1569 (0.2110)  loss_box_reg: 0.0923 (0.1159)  loss_objectness: 0.1650 (0.2296)  loss_rpn_box_reg: 0.0346 (0.0833)  time: 0.3278  data: 0.1429  max mem: 3743\n",
      "Training Epoch: [0]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.4190 (0.6397)  loss_classifier: 0.1569 (0.2109)  loss_box_reg: 0.0952 (0.1161)  loss_objectness: 0.1548 (0.2293)  loss_rpn_box_reg: 0.0461 (0.0833)  time: 0.3292  data: 0.1424  max mem: 3743\n",
      "Training Epoch: [0]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.4919 (0.6398)  loss_classifier: 0.1768 (0.2109)  loss_box_reg: 0.0952 (0.1166)  loss_objectness: 0.1523 (0.2288)  loss_rpn_box_reg: 0.0499 (0.0836)  time: 0.3229  data: 0.1427  max mem: 3743\n",
      "Training Epoch: [0]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.4672 (0.6394)  loss_classifier: 0.1464 (0.2107)  loss_box_reg: 0.0950 (0.1170)  loss_objectness: 0.1170 (0.2283)  loss_rpn_box_reg: 0.0568 (0.0834)  time: 0.3302  data: 0.1434  max mem: 3745\n",
      "Training Epoch: [0]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.4327 (0.6378)  loss_classifier: 0.1334 (0.2102)  loss_box_reg: 0.0950 (0.1171)  loss_objectness: 0.1174 (0.2275)  loss_rpn_box_reg: 0.0353 (0.0830)  time: 0.3327  data: 0.1430  max mem: 3745\n",
      "Training Epoch: [0]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.4327 (0.6369)  loss_classifier: 0.1477 (0.2099)  loss_box_reg: 0.1128 (0.1173)  loss_objectness: 0.1233 (0.2268)  loss_rpn_box_reg: 0.0353 (0.0828)  time: 0.3286  data: 0.1424  max mem: 3745\n",
      "Training Epoch: [0]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.4594 (0.6361)  loss_classifier: 0.1443 (0.2095)  loss_box_reg: 0.1023 (0.1173)  loss_objectness: 0.1370 (0.2265)  loss_rpn_box_reg: 0.0417 (0.0828)  time: 0.3262  data: 0.1427  max mem: 3745\n",
      "Training Epoch: [0]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4510 (0.6347)  loss_classifier: 0.1371 (0.2090)  loss_box_reg: 0.1004 (0.1173)  loss_objectness: 0.1187 (0.2257)  loss_rpn_box_reg: 0.0417 (0.0827)  time: 0.3236  data: 0.1412  max mem: 3745\n",
      "Training Epoch: [0] Total time: 0:06:37 (0.3237 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:57  model_time: 0.3470 (0.3470)  evaluator_time: 0.0020 (0.0020)  time: 0.3820  data: 0.0310  max mem: 3745\n",
      "Test:  [100/308]  eta: 0:00:31  model_time: 0.0980 (0.1054)  evaluator_time: 0.0030 (0.0055)  time: 0.1487  data: 0.0384  max mem: 3745\n",
      "Test:  [200/308]  eta: 0:00:16  model_time: 0.1090 (0.1044)  evaluator_time: 0.0030 (0.0051)  time: 0.1471  data: 0.0341  max mem: 3745\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0920 (0.1032)  evaluator_time: 0.0020 (0.0053)  time: 0.1412  data: 0.0387  max mem: 3745\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0900 (0.1030)  evaluator_time: 0.0020 (0.0053)  time: 0.1385  data: 0.0371  max mem: 3745\n",
      "Test: Total time: 0:00:45 (0.1476 s / it)\n",
      "Averaged stats: model_time: 0.0900 (0.1030)  evaluator_time: 0.0020 (0.0053)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.039\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.092\n",
      "Testing Epoch: [0]  [  0/308]  eta: 0:00:47  lr: 0.005000  loss: 0.2337 (0.2337)  loss_classifier: 0.0607 (0.0607)  loss_box_reg: 0.0510 (0.0510)  loss_objectness: 0.0956 (0.0956)  loss_rpn_box_reg: 0.0265 (0.0265)  time: 0.1540  data: 0.0330  max mem: 3745\n",
      "Testing Epoch: [0]  [100/308]  eta: 0:00:36  lr: 0.005000  loss: 0.3694 (0.5516)  loss_classifier: 0.1481 (0.1787)  loss_box_reg: 0.1049 (0.1597)  loss_objectness: 0.1048 (0.1420)  loss_rpn_box_reg: 0.0334 (0.0712)  time: 0.1765  data: 0.0434  max mem: 3948\n",
      "Testing Epoch: [0]  [200/308]  eta: 0:00:18  lr: 0.005000  loss: 0.4861 (0.5244)  loss_classifier: 0.1354 (0.1693)  loss_box_reg: 0.1177 (0.1510)  loss_objectness: 0.1259 (0.1372)  loss_rpn_box_reg: 0.0354 (0.0668)  time: 0.1774  data: 0.0379  max mem: 3948\n",
      "Testing Epoch: [0]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5694 (0.5254)  loss_classifier: 0.1843 (0.1705)  loss_box_reg: 0.1458 (0.1536)  loss_objectness: 0.1479 (0.1361)  loss_rpn_box_reg: 0.0427 (0.0652)  time: 0.1664  data: 0.0412  max mem: 3948\n",
      "Testing Epoch: [0]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.5324 (0.5252)  loss_classifier: 0.1815 (0.1709)  loss_box_reg: 0.1451 (0.1537)  loss_objectness: 0.1413 (0.1361)  loss_rpn_box_reg: 0.0428 (0.0646)  time: 0.1639  data: 0.0393  max mem: 3948\n",
      "Testing Epoch: [0] Total time: 0:00:53 (0.1741 s / it)\n",
      "Training Epoch: [1]  [   0/1229]  eta: 0:06:54  lr: 0.005000  loss: 0.5877 (0.5877)  loss_classifier: 0.1874 (0.1874)  loss_box_reg: 0.1212 (0.1212)  loss_objectness: 0.2116 (0.2116)  loss_rpn_box_reg: 0.0675 (0.0675)  time: 0.3370  data: 0.1720  max mem: 3948\n",
      "Training Epoch: [1]  [  10/1229]  eta: 0:06:33  lr: 0.005000  loss: 0.3053 (0.4150)  loss_classifier: 0.0996 (0.1388)  loss_box_reg: 0.0632 (0.0833)  loss_objectness: 0.1150 (0.1484)  loss_rpn_box_reg: 0.0256 (0.0446)  time: 0.3226  data: 0.1479  max mem: 3948\n",
      "Training Epoch: [1]  [  20/1229]  eta: 0:06:39  lr: 0.005000  loss: 0.3952 (0.4726)  loss_classifier: 0.1496 (0.1579)  loss_box_reg: 0.0900 (0.1090)  loss_objectness: 0.1150 (0.1535)  loss_rpn_box_reg: 0.0267 (0.0522)  time: 0.3303  data: 0.1441  max mem: 3948\n",
      "Training Epoch: [1]  [  30/1229]  eta: 0:06:36  lr: 0.005000  loss: 0.5550 (0.5298)  loss_classifier: 0.1880 (0.1728)  loss_box_reg: 0.1438 (0.1237)  loss_objectness: 0.1352 (0.1711)  loss_rpn_box_reg: 0.0435 (0.0621)  time: 0.3354  data: 0.1463  max mem: 3948\n",
      "Training Epoch: [1]  [  40/1229]  eta: 0:06:30  lr: 0.005000  loss: 0.5767 (0.5746)  loss_classifier: 0.1880 (0.1878)  loss_box_reg: 0.1536 (0.1373)  loss_objectness: 0.1823 (0.1763)  loss_rpn_box_reg: 0.0775 (0.0733)  time: 0.3265  data: 0.1461  max mem: 3948\n",
      "Training Epoch: [1]  [  50/1229]  eta: 0:06:24  lr: 0.005000  loss: 0.5952 (0.5767)  loss_classifier: 0.2021 (0.1882)  loss_box_reg: 0.1683 (0.1428)  loss_objectness: 0.1633 (0.1709)  loss_rpn_box_reg: 0.0683 (0.0748)  time: 0.3196  data: 0.1442  max mem: 3948\n",
      "Training Epoch: [1]  [  60/1229]  eta: 0:06:23  lr: 0.005000  loss: 0.5663 (0.5920)  loss_classifier: 0.1916 (0.1912)  loss_box_reg: 0.1473 (0.1474)  loss_objectness: 0.1550 (0.1776)  loss_rpn_box_reg: 0.0494 (0.0759)  time: 0.3263  data: 0.1445  max mem: 3948\n",
      "Training Epoch: [1]  [  70/1229]  eta: 0:06:17  lr: 0.005000  loss: 0.6027 (0.6181)  loss_classifier: 0.2029 (0.2028)  loss_box_reg: 0.1704 (0.1616)  loss_objectness: 0.1505 (0.1765)  loss_rpn_box_reg: 0.0591 (0.0772)  time: 0.3236  data: 0.1429  max mem: 3948\n",
      "Training Epoch: [1]  [  80/1229]  eta: 0:06:13  lr: 0.005000  loss: 0.5608 (0.6006)  loss_classifier: 0.2029 (0.1979)  loss_box_reg: 0.1704 (0.1563)  loss_objectness: 0.1364 (0.1714)  loss_rpn_box_reg: 0.0501 (0.0749)  time: 0.3154  data: 0.1424  max mem: 3948\n",
      "Training Epoch: [1]  [  90/1229]  eta: 0:06:09  lr: 0.005000  loss: 0.4010 (0.5867)  loss_classifier: 0.1324 (0.1935)  loss_box_reg: 0.0742 (0.1500)  loss_objectness: 0.1255 (0.1660)  loss_rpn_box_reg: 0.0368 (0.0773)  time: 0.3211  data: 0.1429  max mem: 3948\n",
      "Training Epoch: [1]  [ 100/1229]  eta: 0:06:06  lr: 0.005000  loss: 0.5385 (0.5930)  loss_classifier: 0.1625 (0.1951)  loss_box_reg: 0.1080 (0.1527)  loss_objectness: 0.1505 (0.1674)  loss_rpn_box_reg: 0.0492 (0.0778)  time: 0.3238  data: 0.1430  max mem: 3948\n",
      "Training Epoch: [1]  [ 110/1229]  eta: 0:06:03  lr: 0.005000  loss: 0.5491 (0.5873)  loss_classifier: 0.1682 (0.1941)  loss_box_reg: 0.1158 (0.1512)  loss_objectness: 0.1532 (0.1655)  loss_rpn_box_reg: 0.0665 (0.0765)  time: 0.3253  data: 0.1422  max mem: 3948\n",
      "Training Epoch: [1]  [ 120/1229]  eta: 0:06:01  lr: 0.005000  loss: 0.4944 (0.5857)  loss_classifier: 0.1707 (0.1930)  loss_box_reg: 0.0853 (0.1506)  loss_objectness: 0.1239 (0.1653)  loss_rpn_box_reg: 0.0410 (0.0769)  time: 0.3322  data: 0.1492  max mem: 3948\n",
      "Training Epoch: [1]  [ 130/1229]  eta: 0:05:59  lr: 0.005000  loss: 0.4944 (0.5861)  loss_classifier: 0.1494 (0.1918)  loss_box_reg: 0.0853 (0.1490)  loss_objectness: 0.1391 (0.1663)  loss_rpn_box_reg: 0.0336 (0.0790)  time: 0.3408  data: 0.1520  max mem: 3948\n",
      "Training Epoch: [1]  [ 140/1229]  eta: 0:05:57  lr: 0.005000  loss: 0.3776 (0.5811)  loss_classifier: 0.1304 (0.1903)  loss_box_reg: 0.0943 (0.1480)  loss_objectness: 0.1357 (0.1668)  loss_rpn_box_reg: 0.0302 (0.0760)  time: 0.3410  data: 0.1455  max mem: 3948\n",
      "Training Epoch: [1]  [ 150/1229]  eta: 0:05:54  lr: 0.005000  loss: 0.5593 (0.5875)  loss_classifier: 0.1464 (0.1912)  loss_box_reg: 0.1331 (0.1505)  loss_objectness: 0.1709 (0.1688)  loss_rpn_box_reg: 0.0381 (0.0771)  time: 0.3339  data: 0.1418  max mem: 3948\n",
      "Training Epoch: [1]  [ 160/1229]  eta: 0:05:51  lr: 0.005000  loss: 0.5691 (0.5888)  loss_classifier: 0.1996 (0.1921)  loss_box_reg: 0.1505 (0.1511)  loss_objectness: 0.1717 (0.1681)  loss_rpn_box_reg: 0.0713 (0.0775)  time: 0.3315  data: 0.1410  max mem: 3948\n",
      "Training Epoch: [1]  [ 170/1229]  eta: 0:05:47  lr: 0.005000  loss: 0.5110 (0.5858)  loss_classifier: 0.1702 (0.1907)  loss_box_reg: 0.1384 (0.1499)  loss_objectness: 0.1430 (0.1671)  loss_rpn_box_reg: 0.0373 (0.0782)  time: 0.3282  data: 0.1409  max mem: 3948\n",
      "Training Epoch: [1]  [ 180/1229]  eta: 0:05:44  lr: 0.005000  loss: 0.4675 (0.5811)  loss_classifier: 0.1566 (0.1900)  loss_box_reg: 0.1278 (0.1483)  loss_objectness: 0.1430 (0.1665)  loss_rpn_box_reg: 0.0342 (0.0762)  time: 0.3264  data: 0.1408  max mem: 3948\n",
      "Training Epoch: [1]  [ 190/1229]  eta: 0:05:40  lr: 0.005000  loss: 0.3929 (0.5727)  loss_classifier: 0.1292 (0.1874)  loss_box_reg: 0.0804 (0.1459)  loss_objectness: 0.1241 (0.1648)  loss_rpn_box_reg: 0.0274 (0.0746)  time: 0.3278  data: 0.1402  max mem: 3948\n",
      "Training Epoch: [1]  [ 200/1229]  eta: 0:05:37  lr: 0.005000  loss: 0.4637 (0.5767)  loss_classifier: 0.1548 (0.1899)  loss_box_reg: 0.1245 (0.1489)  loss_objectness: 0.1254 (0.1643)  loss_rpn_box_reg: 0.0290 (0.0737)  time: 0.3259  data: 0.1410  max mem: 3948\n",
      "Training Epoch: [1]  [ 210/1229]  eta: 0:05:33  lr: 0.005000  loss: 0.4900 (0.5724)  loss_classifier: 0.1888 (0.1893)  loss_box_reg: 0.1336 (0.1479)  loss_objectness: 0.1337 (0.1636)  loss_rpn_box_reg: 0.0328 (0.0716)  time: 0.3243  data: 0.1445  max mem: 3948\n",
      "Training Epoch: [1]  [ 220/1229]  eta: 0:05:30  lr: 0.005000  loss: 0.4872 (0.5707)  loss_classifier: 0.1722 (0.1890)  loss_box_reg: 0.1223 (0.1477)  loss_objectness: 0.1337 (0.1637)  loss_rpn_box_reg: 0.0318 (0.0703)  time: 0.3248  data: 0.1446  max mem: 3948\n",
      "Training Epoch: [1]  [ 230/1229]  eta: 0:05:26  lr: 0.005000  loss: 0.4258 (0.5634)  loss_classifier: 0.1449 (0.1869)  loss_box_reg: 0.1223 (0.1462)  loss_objectness: 0.1271 (0.1618)  loss_rpn_box_reg: 0.0223 (0.0685)  time: 0.3222  data: 0.1430  max mem: 3948\n",
      "Training Epoch: [1]  [ 240/1229]  eta: 0:05:23  lr: 0.005000  loss: 0.3821 (0.5615)  loss_classifier: 0.1307 (0.1865)  loss_box_reg: 0.1057 (0.1463)  loss_objectness: 0.1106 (0.1614)  loss_rpn_box_reg: 0.0210 (0.0673)  time: 0.3240  data: 0.1427  max mem: 3948\n",
      "Training Epoch: [1]  [ 250/1229]  eta: 0:05:20  lr: 0.005000  loss: 0.5186 (0.5671)  loss_classifier: 0.1610 (0.1868)  loss_box_reg: 0.1248 (0.1466)  loss_objectness: 0.1702 (0.1644)  loss_rpn_box_reg: 0.0532 (0.0694)  time: 0.3321  data: 0.1449  max mem: 3948\n",
      "Training Epoch: [1]  [ 260/1229]  eta: 0:05:17  lr: 0.005000  loss: 0.4692 (0.5630)  loss_classifier: 0.1579 (0.1856)  loss_box_reg: 0.1233 (0.1460)  loss_objectness: 0.1293 (0.1627)  loss_rpn_box_reg: 0.0601 (0.0687)  time: 0.3312  data: 0.1477  max mem: 3948\n",
      "Training Epoch: [1]  [ 270/1229]  eta: 0:05:13  lr: 0.005000  loss: 0.4302 (0.5613)  loss_classifier: 0.1535 (0.1847)  loss_box_reg: 0.1170 (0.1452)  loss_objectness: 0.1293 (0.1625)  loss_rpn_box_reg: 0.0290 (0.0689)  time: 0.3228  data: 0.1417  max mem: 3948\n",
      "Training Epoch: [1]  [ 280/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.4942 (0.5585)  loss_classifier: 0.1563 (0.1841)  loss_box_reg: 0.1171 (0.1453)  loss_objectness: 0.1347 (0.1614)  loss_rpn_box_reg: 0.0313 (0.0678)  time: 0.3194  data: 0.1371  max mem: 3948\n",
      "Training Epoch: [1]  [ 290/1229]  eta: 0:05:07  lr: 0.005000  loss: 0.4942 (0.5609)  loss_classifier: 0.1748 (0.1854)  loss_box_reg: 0.1426 (0.1463)  loss_objectness: 0.1219 (0.1610)  loss_rpn_box_reg: 0.0313 (0.0682)  time: 0.3235  data: 0.1444  max mem: 3948\n",
      "Training Epoch: [1]  [ 300/1229]  eta: 0:05:03  lr: 0.005000  loss: 0.4742 (0.5596)  loss_classifier: 0.1696 (0.1840)  loss_box_reg: 0.1426 (0.1455)  loss_objectness: 0.1009 (0.1614)  loss_rpn_box_reg: 0.0308 (0.0687)  time: 0.3250  data: 0.1458  max mem: 3948\n",
      "Training Epoch: [1]  [ 310/1229]  eta: 0:05:00  lr: 0.005000  loss: 0.4738 (0.5635)  loss_classifier: 0.1574 (0.1850)  loss_box_reg: 0.1216 (0.1469)  loss_objectness: 0.1273 (0.1619)  loss_rpn_box_reg: 0.0330 (0.0698)  time: 0.3230  data: 0.1405  max mem: 3948\n",
      "Training Epoch: [1]  [ 320/1229]  eta: 0:04:56  lr: 0.005000  loss: 0.4722 (0.5590)  loss_classifier: 0.1537 (0.1829)  loss_box_reg: 0.1029 (0.1449)  loss_objectness: 0.1273 (0.1611)  loss_rpn_box_reg: 0.0330 (0.0701)  time: 0.3197  data: 0.1400  max mem: 3948\n",
      "Training Epoch: [1]  [ 330/1229]  eta: 0:04:53  lr: 0.005000  loss: 0.4162 (0.5588)  loss_classifier: 0.1145 (0.1821)  loss_box_reg: 0.0854 (0.1444)  loss_objectness: 0.1194 (0.1618)  loss_rpn_box_reg: 0.0263 (0.0704)  time: 0.3168  data: 0.1415  max mem: 3948\n",
      "Training Epoch: [1]  [ 340/1229]  eta: 0:04:49  lr: 0.005000  loss: 0.5334 (0.5581)  loss_classifier: 0.1609 (0.1824)  loss_box_reg: 0.1368 (0.1446)  loss_objectness: 0.1501 (0.1616)  loss_rpn_box_reg: 0.0341 (0.0695)  time: 0.3181  data: 0.1437  max mem: 3948\n",
      "Training Epoch: [1]  [ 350/1229]  eta: 0:04:46  lr: 0.005000  loss: 0.5426 (0.5573)  loss_classifier: 0.1786 (0.1821)  loss_box_reg: 0.1372 (0.1446)  loss_objectness: 0.1450 (0.1611)  loss_rpn_box_reg: 0.0417 (0.0695)  time: 0.3225  data: 0.1435  max mem: 3948\n",
      "Training Epoch: [1]  [ 360/1229]  eta: 0:04:43  lr: 0.005000  loss: 0.5494 (0.5577)  loss_classifier: 0.1681 (0.1825)  loss_box_reg: 0.1839 (0.1458)  loss_objectness: 0.1193 (0.1603)  loss_rpn_box_reg: 0.0499 (0.0691)  time: 0.3213  data: 0.1419  max mem: 3948\n",
      "Training Epoch: [1]  [ 370/1229]  eta: 0:04:39  lr: 0.005000  loss: 0.5036 (0.5570)  loss_classifier: 0.1771 (0.1827)  loss_box_reg: 0.1357 (0.1457)  loss_objectness: 0.1308 (0.1598)  loss_rpn_box_reg: 0.0446 (0.0688)  time: 0.3235  data: 0.1429  max mem: 3948\n",
      "Training Epoch: [1]  [ 380/1229]  eta: 0:04:36  lr: 0.005000  loss: 0.4719 (0.5578)  loss_classifier: 0.1604 (0.1825)  loss_box_reg: 0.1300 (0.1455)  loss_objectness: 0.1506 (0.1604)  loss_rpn_box_reg: 0.0317 (0.0694)  time: 0.3247  data: 0.1428  max mem: 3948\n",
      "Training Epoch: [1]  [ 390/1229]  eta: 0:04:33  lr: 0.005000  loss: 0.5451 (0.5562)  loss_classifier: 0.1404 (0.1821)  loss_box_reg: 0.1256 (0.1451)  loss_objectness: 0.1738 (0.1604)  loss_rpn_box_reg: 0.0215 (0.0687)  time: 0.3225  data: 0.1417  max mem: 3948\n",
      "Training Epoch: [1]  [ 400/1229]  eta: 0:04:29  lr: 0.005000  loss: 0.4385 (0.5518)  loss_classifier: 0.1198 (0.1807)  loss_box_reg: 0.0882 (0.1439)  loss_objectness: 0.1170 (0.1593)  loss_rpn_box_reg: 0.0198 (0.0680)  time: 0.3205  data: 0.1410  max mem: 3948\n",
      "Training Epoch: [1]  [ 410/1229]  eta: 0:04:26  lr: 0.005000  loss: 0.4509 (0.5500)  loss_classifier: 0.1224 (0.1801)  loss_box_reg: 0.0834 (0.1433)  loss_objectness: 0.1138 (0.1588)  loss_rpn_box_reg: 0.0233 (0.0678)  time: 0.3279  data: 0.1427  max mem: 3948\n",
      "Training Epoch: [1]  [ 420/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.4534 (0.5487)  loss_classifier: 0.1544 (0.1802)  loss_box_reg: 0.0834 (0.1434)  loss_objectness: 0.1138 (0.1579)  loss_rpn_box_reg: 0.0372 (0.0671)  time: 0.3331  data: 0.1421  max mem: 3948\n",
      "Training Epoch: [1]  [ 430/1229]  eta: 0:04:20  lr: 0.005000  loss: 0.3809 (0.5455)  loss_classifier: 0.1354 (0.1794)  loss_box_reg: 0.1036 (0.1426)  loss_objectness: 0.1015 (0.1568)  loss_rpn_box_reg: 0.0306 (0.0667)  time: 0.3310  data: 0.1374  max mem: 3948\n",
      "Training Epoch: [1]  [ 440/1229]  eta: 0:04:16  lr: 0.005000  loss: 0.3809 (0.5420)  loss_classifier: 0.1344 (0.1785)  loss_box_reg: 0.0899 (0.1417)  loss_objectness: 0.1046 (0.1557)  loss_rpn_box_reg: 0.0298 (0.0660)  time: 0.3243  data: 0.1368  max mem: 3948\n",
      "Training Epoch: [1]  [ 450/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.4491 (0.5417)  loss_classifier: 0.1443 (0.1784)  loss_box_reg: 0.0897 (0.1414)  loss_objectness: 0.1371 (0.1564)  loss_rpn_box_reg: 0.0289 (0.0655)  time: 0.3231  data: 0.1378  max mem: 3948\n",
      "Training Epoch: [1]  [ 460/1229]  eta: 0:04:10  lr: 0.005000  loss: 0.5665 (0.5432)  loss_classifier: 0.1542 (0.1788)  loss_box_reg: 0.1059 (0.1418)  loss_objectness: 0.1568 (0.1568)  loss_rpn_box_reg: 0.0434 (0.0658)  time: 0.3367  data: 0.1422  max mem: 3948\n",
      "Training Epoch: [1]  [ 470/1229]  eta: 0:04:07  lr: 0.005000  loss: 0.6176 (0.5448)  loss_classifier: 0.1865 (0.1797)  loss_box_reg: 0.1592 (0.1426)  loss_objectness: 0.1241 (0.1568)  loss_rpn_box_reg: 0.0434 (0.0656)  time: 0.3280  data: 0.1447  max mem: 3948\n",
      "Training Epoch: [1]  [ 480/1229]  eta: 0:04:04  lr: 0.005000  loss: 0.6276 (0.5477)  loss_classifier: 0.1865 (0.1806)  loss_box_reg: 0.1618 (0.1436)  loss_objectness: 0.1462 (0.1572)  loss_rpn_box_reg: 0.0479 (0.0663)  time: 0.3166  data: 0.1406  max mem: 3948\n",
      "Training Epoch: [1]  [ 490/1229]  eta: 0:04:00  lr: 0.005000  loss: 0.6875 (0.5513)  loss_classifier: 0.2407 (0.1820)  loss_box_reg: 0.1859 (0.1446)  loss_objectness: 0.1477 (0.1577)  loss_rpn_box_reg: 0.0532 (0.0670)  time: 0.3185  data: 0.1409  max mem: 3948\n",
      "Training Epoch: [1]  [ 500/1229]  eta: 0:03:57  lr: 0.005000  loss: 0.6203 (0.5503)  loss_classifier: 0.1967 (0.1819)  loss_box_reg: 0.1308 (0.1444)  loss_objectness: 0.1339 (0.1570)  loss_rpn_box_reg: 0.0532 (0.0670)  time: 0.3230  data: 0.1427  max mem: 3948\n",
      "Training Epoch: [1]  [ 510/1229]  eta: 0:03:54  lr: 0.005000  loss: 0.4625 (0.5505)  loss_classifier: 0.1681 (0.1819)  loss_box_reg: 0.0800 (0.1442)  loss_objectness: 0.1392 (0.1570)  loss_rpn_box_reg: 0.0442 (0.0674)  time: 0.3279  data: 0.1411  max mem: 3948\n",
      "Training Epoch: [1]  [ 520/1229]  eta: 0:03:50  lr: 0.005000  loss: 0.5567 (0.5526)  loss_classifier: 0.1844 (0.1826)  loss_box_reg: 0.1807 (0.1456)  loss_objectness: 0.1507 (0.1568)  loss_rpn_box_reg: 0.0417 (0.0677)  time: 0.3239  data: 0.1419  max mem: 3948\n",
      "Training Epoch: [1]  [ 530/1229]  eta: 0:03:47  lr: 0.005000  loss: 0.7064 (0.5558)  loss_classifier: 0.2483 (0.1837)  loss_box_reg: 0.2118 (0.1469)  loss_objectness: 0.1443 (0.1571)  loss_rpn_box_reg: 0.0399 (0.0680)  time: 0.3227  data: 0.1473  max mem: 3948\n",
      "Training Epoch: [1]  [ 540/1229]  eta: 0:03:44  lr: 0.005000  loss: 0.6976 (0.5577)  loss_classifier: 0.2189 (0.1846)  loss_box_reg: 0.1896 (0.1477)  loss_objectness: 0.1784 (0.1574)  loss_rpn_box_reg: 0.0478 (0.0681)  time: 0.3248  data: 0.1457  max mem: 3948\n",
      "Training Epoch: [1]  [ 550/1229]  eta: 0:03:40  lr: 0.005000  loss: 0.5499 (0.5598)  loss_classifier: 0.2189 (0.1857)  loss_box_reg: 0.1640 (0.1485)  loss_objectness: 0.1638 (0.1575)  loss_rpn_box_reg: 0.0478 (0.0681)  time: 0.3205  data: 0.1418  max mem: 3948\n",
      "Training Epoch: [1]  [ 560/1229]  eta: 0:03:37  lr: 0.005000  loss: 0.4888 (0.5591)  loss_classifier: 0.1866 (0.1856)  loss_box_reg: 0.1295 (0.1485)  loss_objectness: 0.1329 (0.1568)  loss_rpn_box_reg: 0.0355 (0.0681)  time: 0.3280  data: 0.1468  max mem: 3948\n",
      "Training Epoch: [1]  [ 570/1229]  eta: 0:03:34  lr: 0.005000  loss: 0.5402 (0.5599)  loss_classifier: 0.1662 (0.1856)  loss_box_reg: 0.1175 (0.1486)  loss_objectness: 0.1329 (0.1573)  loss_rpn_box_reg: 0.0355 (0.0684)  time: 0.3383  data: 0.1472  max mem: 3948\n",
      "Training Epoch: [1]  [ 580/1229]  eta: 0:03:31  lr: 0.005000  loss: 0.3970 (0.5586)  loss_classifier: 0.1311 (0.1851)  loss_box_reg: 0.1069 (0.1484)  loss_objectness: 0.1437 (0.1567)  loss_rpn_box_reg: 0.0267 (0.0685)  time: 0.3316  data: 0.1439  max mem: 3948\n",
      "Training Epoch: [1]  [ 590/1229]  eta: 0:03:28  lr: 0.005000  loss: 0.3435 (0.5563)  loss_classifier: 0.1204 (0.1844)  loss_box_reg: 0.0811 (0.1477)  loss_objectness: 0.0972 (0.1562)  loss_rpn_box_reg: 0.0223 (0.0680)  time: 0.3306  data: 0.1441  max mem: 3948\n",
      "Training Epoch: [1]  [ 600/1229]  eta: 0:03:25  lr: 0.005000  loss: 0.4101 (0.5541)  loss_classifier: 0.1324 (0.1839)  loss_box_reg: 0.0772 (0.1473)  loss_objectness: 0.1160 (0.1556)  loss_rpn_box_reg: 0.0257 (0.0673)  time: 0.3323  data: 0.1404  max mem: 3948\n",
      "Training Epoch: [1]  [ 610/1229]  eta: 0:03:21  lr: 0.005000  loss: 0.3469 (0.5517)  loss_classifier: 0.1312 (0.1831)  loss_box_reg: 0.0860 (0.1467)  loss_objectness: 0.1162 (0.1550)  loss_rpn_box_reg: 0.0241 (0.0669)  time: 0.3265  data: 0.1386  max mem: 3948\n",
      "Training Epoch: [1]  [ 620/1229]  eta: 0:03:18  lr: 0.005000  loss: 0.3469 (0.5498)  loss_classifier: 0.1148 (0.1823)  loss_box_reg: 0.0891 (0.1462)  loss_objectness: 0.1081 (0.1547)  loss_rpn_box_reg: 0.0215 (0.0666)  time: 0.3252  data: 0.1418  max mem: 3948\n",
      "Training Epoch: [1]  [ 630/1229]  eta: 0:03:15  lr: 0.005000  loss: 0.3551 (0.5472)  loss_classifier: 0.1191 (0.1816)  loss_box_reg: 0.0904 (0.1454)  loss_objectness: 0.1081 (0.1542)  loss_rpn_box_reg: 0.0268 (0.0661)  time: 0.3273  data: 0.1422  max mem: 3948\n",
      "Training Epoch: [1]  [ 640/1229]  eta: 0:03:12  lr: 0.005000  loss: 0.4294 (0.5464)  loss_classifier: 0.1363 (0.1815)  loss_box_reg: 0.1047 (0.1454)  loss_objectness: 0.1151 (0.1538)  loss_rpn_box_reg: 0.0279 (0.0656)  time: 0.3287  data: 0.1408  max mem: 3948\n",
      "Training Epoch: [1]  [ 650/1229]  eta: 0:03:08  lr: 0.005000  loss: 0.4323 (0.5446)  loss_classifier: 0.1555 (0.1810)  loss_box_reg: 0.1180 (0.1450)  loss_objectness: 0.1083 (0.1534)  loss_rpn_box_reg: 0.0239 (0.0653)  time: 0.3234  data: 0.1414  max mem: 3948\n",
      "Training Epoch: [1]  [ 660/1229]  eta: 0:03:05  lr: 0.005000  loss: 0.4397 (0.5437)  loss_classifier: 0.1588 (0.1809)  loss_box_reg: 0.1191 (0.1451)  loss_objectness: 0.1083 (0.1530)  loss_rpn_box_reg: 0.0244 (0.0647)  time: 0.3234  data: 0.1418  max mem: 3948\n",
      "Training Epoch: [1]  [ 670/1229]  eta: 0:03:02  lr: 0.005000  loss: 0.5011 (0.5435)  loss_classifier: 0.1815 (0.1808)  loss_box_reg: 0.1543 (0.1449)  loss_objectness: 0.1358 (0.1530)  loss_rpn_box_reg: 0.0286 (0.0648)  time: 0.3281  data: 0.1435  max mem: 3948\n",
      "Training Epoch: [1]  [ 680/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.6333 (0.5451)  loss_classifier: 0.1936 (0.1815)  loss_box_reg: 0.1604 (0.1458)  loss_objectness: 0.1512 (0.1531)  loss_rpn_box_reg: 0.0614 (0.0648)  time: 0.3221  data: 0.1450  max mem: 3948\n",
      "Training Epoch: [1]  [ 690/1229]  eta: 0:02:55  lr: 0.005000  loss: 0.5625 (0.5449)  loss_classifier: 0.1847 (0.1812)  loss_box_reg: 0.1587 (0.1458)  loss_objectness: 0.1284 (0.1529)  loss_rpn_box_reg: 0.0594 (0.0650)  time: 0.3184  data: 0.1407  max mem: 3948\n",
      "Training Epoch: [1]  [ 700/1229]  eta: 0:02:52  lr: 0.005000  loss: 0.5104 (0.5433)  loss_classifier: 0.1433 (0.1807)  loss_box_reg: 0.1098 (0.1452)  loss_objectness: 0.1162 (0.1524)  loss_rpn_box_reg: 0.0309 (0.0649)  time: 0.3201  data: 0.1395  max mem: 3948\n",
      "Training Epoch: [1]  [ 710/1229]  eta: 0:02:49  lr: 0.005000  loss: 0.4623 (0.5442)  loss_classifier: 0.1553 (0.1810)  loss_box_reg: 0.0966 (0.1456)  loss_objectness: 0.1334 (0.1527)  loss_rpn_box_reg: 0.0533 (0.0648)  time: 0.3266  data: 0.1411  max mem: 3948\n",
      "Training Epoch: [1]  [ 720/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.4669 (0.5435)  loss_classifier: 0.1553 (0.1809)  loss_box_reg: 0.1107 (0.1453)  loss_objectness: 0.1608 (0.1529)  loss_rpn_box_reg: 0.0427 (0.0644)  time: 0.3307  data: 0.1433  max mem: 3948\n",
      "Training Epoch: [1]  [ 730/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.4107 (0.5418)  loss_classifier: 0.1310 (0.1804)  loss_box_reg: 0.0826 (0.1448)  loss_objectness: 0.1261 (0.1524)  loss_rpn_box_reg: 0.0273 (0.0642)  time: 0.3307  data: 0.1453  max mem: 3948\n",
      "Training Epoch: [1]  [ 740/1229]  eta: 0:02:39  lr: 0.005000  loss: 0.3054 (0.5392)  loss_classifier: 0.1162 (0.1797)  loss_box_reg: 0.0826 (0.1441)  loss_objectness: 0.0778 (0.1517)  loss_rpn_box_reg: 0.0231 (0.0637)  time: 0.3286  data: 0.1421  max mem: 3948\n",
      "Training Epoch: [1]  [ 750/1229]  eta: 0:02:36  lr: 0.005000  loss: 0.3054 (0.5389)  loss_classifier: 0.1222 (0.1797)  loss_box_reg: 0.0832 (0.1439)  loss_objectness: 0.0793 (0.1518)  loss_rpn_box_reg: 0.0184 (0.0636)  time: 0.3281  data: 0.1403  max mem: 3948\n",
      "Training Epoch: [1]  [ 760/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.4023 (0.5381)  loss_classifier: 0.1471 (0.1794)  loss_box_reg: 0.1112 (0.1437)  loss_objectness: 0.1127 (0.1515)  loss_rpn_box_reg: 0.0227 (0.0635)  time: 0.3278  data: 0.1398  max mem: 3948\n",
      "Training Epoch: [1]  [ 770/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.5394 (0.5392)  loss_classifier: 0.1943 (0.1800)  loss_box_reg: 0.1457 (0.1443)  loss_objectness: 0.1127 (0.1513)  loss_rpn_box_reg: 0.0378 (0.0636)  time: 0.3219  data: 0.1413  max mem: 3948\n",
      "Training Epoch: [1]  [ 780/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.6123 (0.5402)  loss_classifier: 0.2105 (0.1803)  loss_box_reg: 0.1849 (0.1447)  loss_objectness: 0.1244 (0.1511)  loss_rpn_box_reg: 0.0469 (0.0640)  time: 0.3193  data: 0.1439  max mem: 3948\n",
      "Training Epoch: [1]  [ 790/1229]  eta: 0:02:23  lr: 0.005000  loss: 0.4871 (0.5397)  loss_classifier: 0.1719 (0.1798)  loss_box_reg: 0.1285 (0.1443)  loss_objectness: 0.1218 (0.1510)  loss_rpn_box_reg: 0.0498 (0.0647)  time: 0.3239  data: 0.1437  max mem: 3948\n",
      "Training Epoch: [1]  [ 800/1229]  eta: 0:02:19  lr: 0.005000  loss: 0.3923 (0.5393)  loss_classifier: 0.1073 (0.1795)  loss_box_reg: 0.0915 (0.1441)  loss_objectness: 0.1145 (0.1508)  loss_rpn_box_reg: 0.0400 (0.0649)  time: 0.3252  data: 0.1408  max mem: 3948\n",
      "Training Epoch: [1]  [ 810/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.4708 (0.5396)  loss_classifier: 0.1403 (0.1792)  loss_box_reg: 0.1008 (0.1440)  loss_objectness: 0.1473 (0.1510)  loss_rpn_box_reg: 0.0411 (0.0654)  time: 0.3218  data: 0.1374  max mem: 3948\n",
      "Training Epoch: [1]  [ 820/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.4474 (0.5388)  loss_classifier: 0.1362 (0.1787)  loss_box_reg: 0.1041 (0.1438)  loss_objectness: 0.1299 (0.1510)  loss_rpn_box_reg: 0.0294 (0.0654)  time: 0.3209  data: 0.1377  max mem: 3948\n",
      "Training Epoch: [1]  [ 830/1229]  eta: 0:02:09  lr: 0.005000  loss: 0.4088 (0.5388)  loss_classifier: 0.1169 (0.1786)  loss_box_reg: 0.0734 (0.1437)  loss_objectness: 0.1299 (0.1511)  loss_rpn_box_reg: 0.0294 (0.0654)  time: 0.3236  data: 0.1416  max mem: 3948\n",
      "Training Epoch: [1]  [ 840/1229]  eta: 0:02:06  lr: 0.005000  loss: 0.4734 (0.5389)  loss_classifier: 0.1416 (0.1784)  loss_box_reg: 0.1157 (0.1438)  loss_objectness: 0.1345 (0.1510)  loss_rpn_box_reg: 0.0419 (0.0657)  time: 0.3260  data: 0.1450  max mem: 3948\n",
      "Training Epoch: [1]  [ 850/1229]  eta: 0:02:03  lr: 0.005000  loss: 0.4770 (0.5389)  loss_classifier: 0.1451 (0.1784)  loss_box_reg: 0.1295 (0.1437)  loss_objectness: 0.1345 (0.1512)  loss_rpn_box_reg: 0.0411 (0.0656)  time: 0.3267  data: 0.1444  max mem: 3948\n",
      "Training Epoch: [1]  [ 860/1229]  eta: 0:02:00  lr: 0.005000  loss: 0.3546 (0.5371)  loss_classifier: 0.1233 (0.1780)  loss_box_reg: 0.1029 (0.1432)  loss_objectness: 0.0991 (0.1508)  loss_rpn_box_reg: 0.0229 (0.0652)  time: 0.3219  data: 0.1425  max mem: 3948\n",
      "Training Epoch: [1]  [ 870/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.3925 (0.5364)  loss_classifier: 0.1372 (0.1778)  loss_box_reg: 0.0970 (0.1429)  loss_objectness: 0.1123 (0.1507)  loss_rpn_box_reg: 0.0219 (0.0649)  time: 0.3157  data: 0.1431  max mem: 3948\n",
      "Training Epoch: [1]  [ 880/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.4474 (0.5357)  loss_classifier: 0.1289 (0.1775)  loss_box_reg: 0.1085 (0.1428)  loss_objectness: 0.1458 (0.1507)  loss_rpn_box_reg: 0.0274 (0.0648)  time: 0.3225  data: 0.1432  max mem: 3948\n",
      "Training Epoch: [1]  [ 890/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.4183 (0.5348)  loss_classifier: 0.1173 (0.1772)  loss_box_reg: 0.0977 (0.1426)  loss_objectness: 0.1302 (0.1506)  loss_rpn_box_reg: 0.0240 (0.0645)  time: 0.3259  data: 0.1432  max mem: 3948\n",
      "Training Epoch: [1]  [ 900/1229]  eta: 0:01:47  lr: 0.005000  loss: 0.4477 (0.5346)  loss_classifier: 0.1499 (0.1770)  loss_box_reg: 0.1059 (0.1425)  loss_objectness: 0.1119 (0.1503)  loss_rpn_box_reg: 0.0361 (0.0649)  time: 0.3237  data: 0.1423  max mem: 3948\n",
      "Training Epoch: [1]  [ 910/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.4540 (0.5352)  loss_classifier: 0.1513 (0.1772)  loss_box_reg: 0.1256 (0.1426)  loss_objectness: 0.1160 (0.1505)  loss_rpn_box_reg: 0.0361 (0.0649)  time: 0.3221  data: 0.1431  max mem: 3948\n",
      "Training Epoch: [1]  [ 920/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.4395 (0.5343)  loss_classifier: 0.1546 (0.1770)  loss_box_reg: 0.1604 (0.1424)  loss_objectness: 0.1286 (0.1501)  loss_rpn_box_reg: 0.0280 (0.0648)  time: 0.3246  data: 0.1453  max mem: 3948\n",
      "Training Epoch: [1]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.3670 (0.5333)  loss_classifier: 0.1310 (0.1767)  loss_box_reg: 0.0948 (0.1419)  loss_objectness: 0.1171 (0.1500)  loss_rpn_box_reg: 0.0236 (0.0647)  time: 0.3310  data: 0.1432  max mem: 3948\n",
      "Training Epoch: [1]  [ 940/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.4367 (0.5337)  loss_classifier: 0.1640 (0.1770)  loss_box_reg: 0.1174 (0.1424)  loss_objectness: 0.1020 (0.1497)  loss_rpn_box_reg: 0.0261 (0.0646)  time: 0.3286  data: 0.1420  max mem: 3948\n",
      "Training Epoch: [1]  [ 950/1229]  eta: 0:01:30  lr: 0.005000  loss: 0.5112 (0.5328)  loss_classifier: 0.1684 (0.1768)  loss_box_reg: 0.1357 (0.1423)  loss_objectness: 0.1029 (0.1494)  loss_rpn_box_reg: 0.0297 (0.0642)  time: 0.3300  data: 0.1449  max mem: 3948\n",
      "Training Epoch: [1]  [ 960/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.4237 (0.5324)  loss_classifier: 0.1462 (0.1766)  loss_box_reg: 0.0906 (0.1420)  loss_objectness: 0.1190 (0.1495)  loss_rpn_box_reg: 0.0358 (0.0643)  time: 0.3289  data: 0.1449  max mem: 3948\n",
      "Training Epoch: [1]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.4159 (0.5327)  loss_classifier: 0.1320 (0.1766)  loss_box_reg: 0.1039 (0.1420)  loss_objectness: 0.1404 (0.1497)  loss_rpn_box_reg: 0.0472 (0.0644)  time: 0.3251  data: 0.1426  max mem: 3948\n",
      "Training Epoch: [1]  [ 980/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.4408 (0.5317)  loss_classifier: 0.1343 (0.1763)  loss_box_reg: 0.1039 (0.1416)  loss_objectness: 0.1243 (0.1494)  loss_rpn_box_reg: 0.0377 (0.0644)  time: 0.3227  data: 0.1404  max mem: 3948\n",
      "Training Epoch: [1]  [ 990/1229]  eta: 0:01:17  lr: 0.005000  loss: 0.3931 (0.5323)  loss_classifier: 0.1343 (0.1764)  loss_box_reg: 0.0945 (0.1420)  loss_objectness: 0.1288 (0.1494)  loss_rpn_box_reg: 0.0351 (0.0645)  time: 0.3196  data: 0.1390  max mem: 3948\n",
      "Training Epoch: [1]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.4283 (0.5318)  loss_classifier: 0.1471 (0.1761)  loss_box_reg: 0.0909 (0.1417)  loss_objectness: 0.1332 (0.1496)  loss_rpn_box_reg: 0.0352 (0.0645)  time: 0.3245  data: 0.1419  max mem: 3948\n",
      "Training Epoch: [1]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.5116 (0.5323)  loss_classifier: 0.1542 (0.1762)  loss_box_reg: 0.0997 (0.1417)  loss_objectness: 0.1726 (0.1498)  loss_rpn_box_reg: 0.0469 (0.0645)  time: 0.3231  data: 0.1421  max mem: 3948\n",
      "Training Epoch: [1]  [1020/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.5328 (0.5328)  loss_classifier: 0.1853 (0.1765)  loss_box_reg: 0.1366 (0.1420)  loss_objectness: 0.1519 (0.1498)  loss_rpn_box_reg: 0.0469 (0.0644)  time: 0.3237  data: 0.1367  max mem: 3948\n",
      "Training Epoch: [1]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.4643 (0.5315)  loss_classifier: 0.1503 (0.1762)  loss_box_reg: 0.1241 (0.1418)  loss_objectness: 0.1312 (0.1494)  loss_rpn_box_reg: 0.0373 (0.0641)  time: 0.3240  data: 0.1347  max mem: 3948\n",
      "Training Epoch: [1]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.4562 (0.5319)  loss_classifier: 0.1442 (0.1765)  loss_box_reg: 0.1151 (0.1420)  loss_objectness: 0.1057 (0.1493)  loss_rpn_box_reg: 0.0355 (0.0641)  time: 0.3217  data: 0.1393  max mem: 3948\n",
      "Training Epoch: [1]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.5528 (0.5326)  loss_classifier: 0.2142 (0.1769)  loss_box_reg: 0.1367 (0.1423)  loss_objectness: 0.1349 (0.1494)  loss_rpn_box_reg: 0.0363 (0.0640)  time: 0.3218  data: 0.1404  max mem: 3948\n",
      "Training Epoch: [1]  [1060/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.5841 (0.5329)  loss_classifier: 0.1977 (0.1771)  loss_box_reg: 0.1695 (0.1425)  loss_objectness: 0.1349 (0.1493)  loss_rpn_box_reg: 0.0466 (0.0640)  time: 0.3226  data: 0.1421  max mem: 3948\n",
      "Training Epoch: [1]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.4528 (0.5327)  loss_classifier: 0.1733 (0.1770)  loss_box_reg: 0.1320 (0.1424)  loss_objectness: 0.1160 (0.1494)  loss_rpn_box_reg: 0.0492 (0.0639)  time: 0.3230  data: 0.1426  max mem: 3948\n",
      "Training Epoch: [1]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.4648 (0.5329)  loss_classifier: 0.1659 (0.1772)  loss_box_reg: 0.0827 (0.1426)  loss_objectness: 0.1198 (0.1495)  loss_rpn_box_reg: 0.0451 (0.0636)  time: 0.3198  data: 0.1423  max mem: 3948\n",
      "Training Epoch: [1]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.5479 (0.5331)  loss_classifier: 0.1671 (0.1772)  loss_box_reg: 0.1392 (0.1426)  loss_objectness: 0.1395 (0.1498)  loss_rpn_box_reg: 0.0451 (0.0635)  time: 0.3183  data: 0.1416  max mem: 3948\n",
      "Training Epoch: [1]  [1100/1229]  eta: 0:00:41  lr: 0.005000  loss: 0.3948 (0.5323)  loss_classifier: 0.1439 (0.1768)  loss_box_reg: 0.0955 (0.1424)  loss_objectness: 0.1041 (0.1496)  loss_rpn_box_reg: 0.0241 (0.0635)  time: 0.3217  data: 0.1390  max mem: 3948\n",
      "Training Epoch: [1]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.3948 (0.5328)  loss_classifier: 0.1451 (0.1771)  loss_box_reg: 0.0955 (0.1426)  loss_objectness: 0.1041 (0.1496)  loss_rpn_box_reg: 0.0266 (0.0634)  time: 0.3254  data: 0.1416  max mem: 3948\n",
      "Training Epoch: [1]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4504 (0.5318)  loss_classifier: 0.1476 (0.1768)  loss_box_reg: 0.0984 (0.1421)  loss_objectness: 0.1334 (0.1496)  loss_rpn_box_reg: 0.0339 (0.0634)  time: 0.3276  data: 0.1461  max mem: 3948\n",
      "Training Epoch: [1]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.4504 (0.5325)  loss_classifier: 0.1610 (0.1770)  loss_box_reg: 0.1168 (0.1424)  loss_objectness: 0.1476 (0.1497)  loss_rpn_box_reg: 0.0356 (0.0634)  time: 0.3241  data: 0.1459  max mem: 3948\n",
      "Training Epoch: [1]  [1140/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.4751 (0.5314)  loss_classifier: 0.1610 (0.1766)  loss_box_reg: 0.1065 (0.1421)  loss_objectness: 0.1476 (0.1494)  loss_rpn_box_reg: 0.0356 (0.0632)  time: 0.3182  data: 0.1441  max mem: 3948\n",
      "Training Epoch: [1]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.3406 (0.5307)  loss_classifier: 0.1108 (0.1763)  loss_box_reg: 0.0665 (0.1417)  loss_objectness: 0.1151 (0.1494)  loss_rpn_box_reg: 0.0250 (0.0633)  time: 0.3269  data: 0.1472  max mem: 3948\n",
      "Training Epoch: [1]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.3204 (0.5296)  loss_classifier: 0.1093 (0.1759)  loss_box_reg: 0.0939 (0.1413)  loss_objectness: 0.1032 (0.1491)  loss_rpn_box_reg: 0.0250 (0.0633)  time: 0.3343  data: 0.1455  max mem: 3948\n",
      "Training Epoch: [1]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.3298 (0.5294)  loss_classifier: 0.1233 (0.1758)  loss_box_reg: 0.0939 (0.1412)  loss_objectness: 0.1036 (0.1492)  loss_rpn_box_reg: 0.0245 (0.0633)  time: 0.3334  data: 0.1432  max mem: 3948\n",
      "Training Epoch: [1]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.4546 (0.5294)  loss_classifier: 0.1366 (0.1757)  loss_box_reg: 0.1096 (0.1412)  loss_objectness: 0.1082 (0.1492)  loss_rpn_box_reg: 0.0275 (0.0633)  time: 0.3284  data: 0.1454  max mem: 3948\n",
      "Training Epoch: [1]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.4594 (0.5296)  loss_classifier: 0.1591 (0.1758)  loss_box_reg: 0.1392 (0.1415)  loss_objectness: 0.1284 (0.1492)  loss_rpn_box_reg: 0.0342 (0.0631)  time: 0.3224  data: 0.1459  max mem: 3948\n",
      "Training Epoch: [1]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.4937 (0.5293)  loss_classifier: 0.1729 (0.1758)  loss_box_reg: 0.1433 (0.1416)  loss_objectness: 0.1245 (0.1490)  loss_rpn_box_reg: 0.0325 (0.0630)  time: 0.3225  data: 0.1442  max mem: 3948\n",
      "Training Epoch: [1]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.5151 (0.5309)  loss_classifier: 0.1941 (0.1764)  loss_box_reg: 0.1433 (0.1420)  loss_objectness: 0.1135 (0.1493)  loss_rpn_box_reg: 0.0333 (0.0631)  time: 0.3297  data: 0.1445  max mem: 3948\n",
      "Training Epoch: [1]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.5151 (0.5303)  loss_classifier: 0.2036 (0.1762)  loss_box_reg: 0.1327 (0.1419)  loss_objectness: 0.1451 (0.1493)  loss_rpn_box_reg: 0.0387 (0.0629)  time: 0.3345  data: 0.1454  max mem: 3948\n",
      "Training Epoch: [1]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4994 (0.5302)  loss_classifier: 0.1895 (0.1763)  loss_box_reg: 0.1108 (0.1420)  loss_objectness: 0.1366 (0.1492)  loss_rpn_box_reg: 0.0283 (0.0627)  time: 0.3329  data: 0.1442  max mem: 3948\n",
      "Training Epoch: [1] Total time: 0:06:40 (0.3256 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:37  model_time: 0.2770 (0.2770)  evaluator_time: 0.0060 (0.0060)  time: 0.3170  data: 0.0310  max mem: 3948\n",
      "Test:  [100/308]  eta: 0:00:33  model_time: 0.1020 (0.1101)  evaluator_time: 0.0090 (0.0102)  time: 0.1618  data: 0.0405  max mem: 3948\n",
      "Test:  [200/308]  eta: 0:00:17  model_time: 0.1110 (0.1101)  evaluator_time: 0.0050 (0.0095)  time: 0.1559  data: 0.0328  max mem: 3948\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0970 (0.1093)  evaluator_time: 0.0060 (0.0095)  time: 0.1518  data: 0.0383  max mem: 3948\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.1010 (0.1091)  evaluator_time: 0.0050 (0.0094)  time: 0.1477  data: 0.0362  max mem: 3948\n",
      "Test: Total time: 0:00:48 (0.1576 s / it)\n",
      "Averaged stats: model_time: 0.1010 (0.1091)  evaluator_time: 0.0050 (0.0094)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.23s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.096\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.207\n",
      "Testing Epoch: [1]  [  0/308]  eta: 0:00:46  lr: 0.005000  loss: 0.2265 (0.2265)  loss_classifier: 0.0778 (0.0778)  loss_box_reg: 0.0570 (0.0570)  loss_objectness: 0.0830 (0.0830)  loss_rpn_box_reg: 0.0086 (0.0086)  time: 0.1510  data: 0.0290  max mem: 3948\n",
      "Testing Epoch: [1]  [100/308]  eta: 0:00:36  lr: 0.005000  loss: 0.3642 (0.5334)  loss_classifier: 0.1536 (0.1791)  loss_box_reg: 0.1133 (0.1597)  loss_objectness: 0.0882 (0.1286)  loss_rpn_box_reg: 0.0246 (0.0659)  time: 0.1789  data: 0.0423  max mem: 3948\n",
      "Testing Epoch: [1]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.5291 (0.5088)  loss_classifier: 0.1510 (0.1722)  loss_box_reg: 0.1400 (0.1524)  loss_objectness: 0.0927 (0.1221)  loss_rpn_box_reg: 0.0342 (0.0622)  time: 0.1793  data: 0.0367  max mem: 3948\n",
      "Testing Epoch: [1]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5520 (0.5095)  loss_classifier: 0.1902 (0.1730)  loss_box_reg: 0.1496 (0.1560)  loss_objectness: 0.1140 (0.1204)  loss_rpn_box_reg: 0.0306 (0.0601)  time: 0.1706  data: 0.0429  max mem: 3961\n",
      "Testing Epoch: [1]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.5337 (0.5093)  loss_classifier: 0.1694 (0.1731)  loss_box_reg: 0.1496 (0.1563)  loss_objectness: 0.1140 (0.1205)  loss_rpn_box_reg: 0.0306 (0.0595)  time: 0.1694  data: 0.0418  max mem: 3961\n",
      "Testing Epoch: [1] Total time: 0:00:54 (0.1761 s / it)\n",
      "Training Epoch: [2]  [   0/1229]  eta: 0:06:40  lr: 0.005000  loss: 0.9018 (0.9018)  loss_classifier: 0.3168 (0.3168)  loss_box_reg: 0.2448 (0.2448)  loss_objectness: 0.2612 (0.2612)  loss_rpn_box_reg: 0.0790 (0.0790)  time: 0.3260  data: 0.1540  max mem: 3961\n",
      "Training Epoch: [2]  [  10/1229]  eta: 0:06:40  lr: 0.005000  loss: 0.5172 (0.5149)  loss_classifier: 0.1358 (0.1740)  loss_box_reg: 0.1129 (0.1401)  loss_objectness: 0.1189 (0.1525)  loss_rpn_box_reg: 0.0309 (0.0484)  time: 0.3287  data: 0.1424  max mem: 3961\n",
      "Training Epoch: [2]  [  20/1229]  eta: 0:06:29  lr: 0.005000  loss: 0.4367 (0.4725)  loss_classifier: 0.1358 (0.1605)  loss_box_reg: 0.1109 (0.1386)  loss_objectness: 0.1016 (0.1313)  loss_rpn_box_reg: 0.0258 (0.0422)  time: 0.3222  data: 0.1416  max mem: 3961\n",
      "Training Epoch: [2]  [  30/1229]  eta: 0:06:28  lr: 0.005000  loss: 0.4975 (0.4874)  loss_classifier: 0.1493 (0.1658)  loss_box_reg: 0.1109 (0.1380)  loss_objectness: 0.1041 (0.1378)  loss_rpn_box_reg: 0.0316 (0.0458)  time: 0.3208  data: 0.1421  max mem: 3961\n",
      "Training Epoch: [2]  [  40/1229]  eta: 0:06:26  lr: 0.005000  loss: 0.5188 (0.4708)  loss_classifier: 0.1493 (0.1606)  loss_box_reg: 0.0962 (0.1343)  loss_objectness: 0.1210 (0.1328)  loss_rpn_box_reg: 0.0368 (0.0431)  time: 0.3285  data: 0.1418  max mem: 3961\n",
      "Training Epoch: [2]  [  50/1229]  eta: 0:06:22  lr: 0.005000  loss: 0.3487 (0.4582)  loss_classifier: 0.1055 (0.1542)  loss_box_reg: 0.0888 (0.1301)  loss_objectness: 0.0917 (0.1310)  loss_rpn_box_reg: 0.0361 (0.0429)  time: 0.3266  data: 0.1406  max mem: 3961\n",
      "Training Epoch: [2]  [  60/1229]  eta: 0:06:17  lr: 0.005000  loss: 0.3487 (0.4503)  loss_classifier: 0.1055 (0.1512)  loss_box_reg: 0.0647 (0.1248)  loss_objectness: 0.0880 (0.1309)  loss_rpn_box_reg: 0.0331 (0.0434)  time: 0.3186  data: 0.1404  max mem: 3961\n",
      "Training Epoch: [2]  [  70/1229]  eta: 0:06:15  lr: 0.005000  loss: 0.4508 (0.4777)  loss_classifier: 0.1646 (0.1614)  loss_box_reg: 0.0947 (0.1343)  loss_objectness: 0.1370 (0.1340)  loss_rpn_box_reg: 0.0359 (0.0480)  time: 0.3213  data: 0.1435  max mem: 3961\n",
      "Training Epoch: [2]  [  80/1229]  eta: 0:06:12  lr: 0.005000  loss: 0.4429 (0.4681)  loss_classifier: 0.1603 (0.1588)  loss_box_reg: 0.1215 (0.1326)  loss_objectness: 0.1102 (0.1300)  loss_rpn_box_reg: 0.0389 (0.0467)  time: 0.3260  data: 0.1420  max mem: 3961\n",
      "Training Epoch: [2]  [  90/1229]  eta: 0:06:09  lr: 0.005000  loss: 0.3513 (0.4685)  loss_classifier: 0.1306 (0.1591)  loss_box_reg: 0.1206 (0.1349)  loss_objectness: 0.0905 (0.1274)  loss_rpn_box_reg: 0.0284 (0.0470)  time: 0.3248  data: 0.1393  max mem: 3961\n",
      "Training Epoch: [2]  [ 100/1229]  eta: 0:06:05  lr: 0.005000  loss: 0.4556 (0.4799)  loss_classifier: 0.1581 (0.1639)  loss_box_reg: 0.1261 (0.1380)  loss_objectness: 0.1124 (0.1304)  loss_rpn_box_reg: 0.0356 (0.0476)  time: 0.3228  data: 0.1397  max mem: 3961\n",
      "Training Epoch: [2]  [ 110/1229]  eta: 0:06:01  lr: 0.005000  loss: 0.4032 (0.4756)  loss_classifier: 0.1487 (0.1622)  loss_box_reg: 0.1043 (0.1366)  loss_objectness: 0.1337 (0.1302)  loss_rpn_box_reg: 0.0214 (0.0465)  time: 0.3197  data: 0.1395  max mem: 3961\n",
      "Training Epoch: [2]  [ 120/1229]  eta: 0:05:59  lr: 0.005000  loss: 0.3011 (0.4651)  loss_classifier: 0.1029 (0.1586)  loss_box_reg: 0.0871 (0.1326)  loss_objectness: 0.1082 (0.1282)  loss_rpn_box_reg: 0.0214 (0.0458)  time: 0.3257  data: 0.1410  max mem: 3961\n",
      "Training Epoch: [2]  [ 130/1229]  eta: 0:05:55  lr: 0.005000  loss: 0.4536 (0.4745)  loss_classifier: 0.1500 (0.1610)  loss_box_reg: 0.1120 (0.1358)  loss_objectness: 0.1341 (0.1315)  loss_rpn_box_reg: 0.0260 (0.0461)  time: 0.3242  data: 0.1433  max mem: 3961\n",
      "Training Epoch: [2]  [ 140/1229]  eta: 0:05:52  lr: 0.005000  loss: 0.4995 (0.4724)  loss_classifier: 0.1628 (0.1603)  loss_box_reg: 0.1365 (0.1353)  loss_objectness: 0.1252 (0.1309)  loss_rpn_box_reg: 0.0268 (0.0459)  time: 0.3230  data: 0.1411  max mem: 3961\n",
      "Training Epoch: [2]  [ 150/1229]  eta: 0:05:50  lr: 0.005000  loss: 0.5503 (0.4835)  loss_classifier: 0.1904 (0.1641)  loss_box_reg: 0.1469 (0.1381)  loss_objectness: 0.1145 (0.1333)  loss_rpn_box_reg: 0.0456 (0.0480)  time: 0.3339  data: 0.1387  max mem: 3961\n",
      "Training Epoch: [2]  [ 160/1229]  eta: 0:05:48  lr: 0.005000  loss: 0.5503 (0.4872)  loss_classifier: 0.2050 (0.1659)  loss_box_reg: 0.1469 (0.1390)  loss_objectness: 0.1141 (0.1337)  loss_rpn_box_reg: 0.0488 (0.0487)  time: 0.3380  data: 0.1381  max mem: 3961\n",
      "Training Epoch: [2]  [ 170/1229]  eta: 0:05:45  lr: 0.005000  loss: 0.4771 (0.4893)  loss_classifier: 0.1702 (0.1655)  loss_box_reg: 0.1070 (0.1397)  loss_objectness: 0.1126 (0.1335)  loss_rpn_box_reg: 0.0480 (0.0506)  time: 0.3342  data: 0.1367  max mem: 3961\n",
      "Training Epoch: [2]  [ 180/1229]  eta: 0:05:41  lr: 0.005000  loss: 0.4954 (0.4907)  loss_classifier: 0.1523 (0.1660)  loss_box_reg: 0.1270 (0.1398)  loss_objectness: 0.1126 (0.1332)  loss_rpn_box_reg: 0.0414 (0.0518)  time: 0.3272  data: 0.1385  max mem: 3961\n",
      "Training Epoch: [2]  [ 190/1229]  eta: 0:05:38  lr: 0.005000  loss: 0.5196 (0.4944)  loss_classifier: 0.1523 (0.1672)  loss_box_reg: 0.1564 (0.1411)  loss_objectness: 0.1171 (0.1332)  loss_rpn_box_reg: 0.0358 (0.0529)  time: 0.3251  data: 0.1392  max mem: 3961\n",
      "Training Epoch: [2]  [ 200/1229]  eta: 0:05:35  lr: 0.005000  loss: 0.4970 (0.4912)  loss_classifier: 0.1570 (0.1664)  loss_box_reg: 0.1426 (0.1396)  loss_objectness: 0.1161 (0.1322)  loss_rpn_box_reg: 0.0359 (0.0529)  time: 0.3274  data: 0.1399  max mem: 3961\n",
      "Training Epoch: [2]  [ 210/1229]  eta: 0:05:31  lr: 0.005000  loss: 0.4598 (0.4898)  loss_classifier: 0.1441 (0.1659)  loss_box_reg: 0.0984 (0.1391)  loss_objectness: 0.1030 (0.1321)  loss_rpn_box_reg: 0.0309 (0.0528)  time: 0.3234  data: 0.1376  max mem: 3961\n",
      "Training Epoch: [2]  [ 220/1229]  eta: 0:05:28  lr: 0.005000  loss: 0.3955 (0.4893)  loss_classifier: 0.1441 (0.1659)  loss_box_reg: 0.0928 (0.1378)  loss_objectness: 0.1125 (0.1323)  loss_rpn_box_reg: 0.0219 (0.0532)  time: 0.3207  data: 0.1366  max mem: 3961\n",
      "Training Epoch: [2]  [ 230/1229]  eta: 0:05:25  lr: 0.005000  loss: 0.4368 (0.4903)  loss_classifier: 0.1518 (0.1664)  loss_box_reg: 0.1283 (0.1379)  loss_objectness: 0.0969 (0.1318)  loss_rpn_box_reg: 0.0371 (0.0542)  time: 0.3314  data: 0.1466  max mem: 3961\n",
      "Training Epoch: [2]  [ 240/1229]  eta: 0:05:22  lr: 0.005000  loss: 0.4815 (0.4891)  loss_classifier: 0.1580 (0.1660)  loss_box_reg: 0.1274 (0.1373)  loss_objectness: 0.1054 (0.1321)  loss_rpn_box_reg: 0.0371 (0.0537)  time: 0.3345  data: 0.1530  max mem: 3961\n",
      "Training Epoch: [2]  [ 250/1229]  eta: 0:05:19  lr: 0.005000  loss: 0.4541 (0.4898)  loss_classifier: 0.1509 (0.1662)  loss_box_reg: 0.1098 (0.1377)  loss_objectness: 0.1076 (0.1318)  loss_rpn_box_reg: 0.0280 (0.0540)  time: 0.3343  data: 0.1516  max mem: 3961\n",
      "Training Epoch: [2]  [ 260/1229]  eta: 0:05:16  lr: 0.005000  loss: 0.4229 (0.4892)  loss_classifier: 0.1334 (0.1652)  loss_box_reg: 0.1114 (0.1373)  loss_objectness: 0.1198 (0.1326)  loss_rpn_box_reg: 0.0277 (0.0541)  time: 0.3351  data: 0.1463  max mem: 3961\n",
      "Training Epoch: [2]  [ 270/1229]  eta: 0:05:13  lr: 0.005000  loss: 0.4229 (0.4870)  loss_classifier: 0.1334 (0.1648)  loss_box_reg: 0.1114 (0.1366)  loss_objectness: 0.1198 (0.1321)  loss_rpn_box_reg: 0.0278 (0.0536)  time: 0.3333  data: 0.1422  max mem: 3961\n",
      "Training Epoch: [2]  [ 280/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.3456 (0.4845)  loss_classifier: 0.1223 (0.1646)  loss_box_reg: 0.1170 (0.1366)  loss_objectness: 0.0901 (0.1307)  loss_rpn_box_reg: 0.0271 (0.0526)  time: 0.3305  data: 0.1403  max mem: 3961\n",
      "Training Epoch: [2]  [ 290/1229]  eta: 0:05:07  lr: 0.005000  loss: 0.3933 (0.4859)  loss_classifier: 0.1478 (0.1657)  loss_box_reg: 0.1144 (0.1370)  loss_objectness: 0.0958 (0.1309)  loss_rpn_box_reg: 0.0360 (0.0523)  time: 0.3266  data: 0.1396  max mem: 3961\n",
      "Training Epoch: [2]  [ 300/1229]  eta: 0:05:03  lr: 0.005000  loss: 0.4919 (0.4881)  loss_classifier: 0.1608 (0.1660)  loss_box_reg: 0.1144 (0.1384)  loss_objectness: 0.1318 (0.1309)  loss_rpn_box_reg: 0.0464 (0.0528)  time: 0.3230  data: 0.1424  max mem: 3961\n",
      "Training Epoch: [2]  [ 310/1229]  eta: 0:05:00  lr: 0.005000  loss: 0.3786 (0.4828)  loss_classifier: 0.1236 (0.1641)  loss_box_reg: 0.1005 (0.1367)  loss_objectness: 0.1189 (0.1302)  loss_rpn_box_reg: 0.0317 (0.0518)  time: 0.3188  data: 0.1425  max mem: 3961\n",
      "Training Epoch: [2]  [ 320/1229]  eta: 0:04:57  lr: 0.005000  loss: 0.3786 (0.4819)  loss_classifier: 0.1236 (0.1639)  loss_box_reg: 0.0987 (0.1361)  loss_objectness: 0.0988 (0.1308)  loss_rpn_box_reg: 0.0215 (0.0512)  time: 0.3267  data: 0.1423  max mem: 3961\n",
      "Training Epoch: [2]  [ 330/1229]  eta: 0:04:53  lr: 0.005000  loss: 0.4137 (0.4795)  loss_classifier: 0.1428 (0.1630)  loss_box_reg: 0.1007 (0.1349)  loss_objectness: 0.0863 (0.1308)  loss_rpn_box_reg: 0.0230 (0.0509)  time: 0.3280  data: 0.1431  max mem: 3961\n",
      "Training Epoch: [2]  [ 340/1229]  eta: 0:04:50  lr: 0.005000  loss: 0.4133 (0.4814)  loss_classifier: 0.1468 (0.1643)  loss_box_reg: 0.1153 (0.1356)  loss_objectness: 0.0986 (0.1312)  loss_rpn_box_reg: 0.0252 (0.0503)  time: 0.3222  data: 0.1424  max mem: 3961\n",
      "Training Epoch: [2]  [ 350/1229]  eta: 0:04:46  lr: 0.005000  loss: 0.4666 (0.4815)  loss_classifier: 0.1478 (0.1644)  loss_box_reg: 0.1289 (0.1355)  loss_objectness: 0.1221 (0.1314)  loss_rpn_box_reg: 0.0270 (0.0503)  time: 0.3211  data: 0.1395  max mem: 3961\n",
      "Training Epoch: [2]  [ 360/1229]  eta: 0:04:43  lr: 0.005000  loss: 0.4323 (0.4862)  loss_classifier: 0.1381 (0.1649)  loss_box_reg: 0.1051 (0.1357)  loss_objectness: 0.1438 (0.1332)  loss_rpn_box_reg: 0.0372 (0.0523)  time: 0.3213  data: 0.1382  max mem: 3961\n",
      "Training Epoch: [2]  [ 370/1229]  eta: 0:04:40  lr: 0.005000  loss: 0.4885 (0.4890)  loss_classifier: 0.1812 (0.1659)  loss_box_reg: 0.1378 (0.1372)  loss_objectness: 0.1541 (0.1334)  loss_rpn_box_reg: 0.0388 (0.0525)  time: 0.3195  data: 0.1394  max mem: 3961\n",
      "Training Epoch: [2]  [ 380/1229]  eta: 0:04:36  lr: 0.005000  loss: 0.5976 (0.4914)  loss_classifier: 0.2060 (0.1669)  loss_box_reg: 0.1859 (0.1384)  loss_objectness: 0.1215 (0.1336)  loss_rpn_box_reg: 0.0437 (0.0526)  time: 0.3201  data: 0.1401  max mem: 3961\n",
      "Training Epoch: [2]  [ 390/1229]  eta: 0:04:33  lr: 0.005000  loss: 0.5460 (0.4915)  loss_classifier: 0.1762 (0.1668)  loss_box_reg: 0.1474 (0.1383)  loss_objectness: 0.1215 (0.1340)  loss_rpn_box_reg: 0.0387 (0.0524)  time: 0.3241  data: 0.1402  max mem: 3961\n",
      "Training Epoch: [2]  [ 400/1229]  eta: 0:04:30  lr: 0.005000  loss: 0.4492 (0.4907)  loss_classifier: 0.1391 (0.1662)  loss_box_reg: 0.1082 (0.1375)  loss_objectness: 0.1451 (0.1343)  loss_rpn_box_reg: 0.0349 (0.0527)  time: 0.3264  data: 0.1399  max mem: 3961\n",
      "Training Epoch: [2]  [ 410/1229]  eta: 0:04:27  lr: 0.005000  loss: 0.3877 (0.4878)  loss_classifier: 0.1391 (0.1654)  loss_box_reg: 0.1081 (0.1365)  loss_objectness: 0.1137 (0.1338)  loss_rpn_box_reg: 0.0303 (0.0521)  time: 0.3296  data: 0.1391  max mem: 3961\n",
      "Training Epoch: [2]  [ 420/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.3313 (0.4877)  loss_classifier: 0.1216 (0.1651)  loss_box_reg: 0.0634 (0.1362)  loss_objectness: 0.1071 (0.1336)  loss_rpn_box_reg: 0.0303 (0.0529)  time: 0.3277  data: 0.1388  max mem: 3961\n",
      "Training Epoch: [2]  [ 430/1229]  eta: 0:04:20  lr: 0.005000  loss: 0.5569 (0.4904)  loss_classifier: 0.1510 (0.1659)  loss_box_reg: 0.1461 (0.1379)  loss_objectness: 0.1308 (0.1337)  loss_rpn_box_reg: 0.0494 (0.0529)  time: 0.3264  data: 0.1414  max mem: 3961\n",
      "Training Epoch: [2]  [ 440/1229]  eta: 0:04:17  lr: 0.005000  loss: 0.5419 (0.4902)  loss_classifier: 0.1901 (0.1659)  loss_box_reg: 0.1461 (0.1377)  loss_objectness: 0.1365 (0.1338)  loss_rpn_box_reg: 0.0344 (0.0527)  time: 0.3226  data: 0.1418  max mem: 3961\n",
      "Training Epoch: [2]  [ 450/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.5419 (0.4933)  loss_classifier: 0.1853 (0.1668)  loss_box_reg: 0.1401 (0.1383)  loss_objectness: 0.1369 (0.1348)  loss_rpn_box_reg: 0.0296 (0.0534)  time: 0.3187  data: 0.1410  max mem: 3961\n",
      "Training Epoch: [2]  [ 460/1229]  eta: 0:04:10  lr: 0.005000  loss: 0.5825 (0.4961)  loss_classifier: 0.2077 (0.1680)  loss_box_reg: 0.1765 (0.1395)  loss_objectness: 0.1657 (0.1353)  loss_rpn_box_reg: 0.0385 (0.0532)  time: 0.3206  data: 0.1427  max mem: 3961\n",
      "Training Epoch: [2]  [ 470/1229]  eta: 0:04:07  lr: 0.005000  loss: 0.4564 (0.4966)  loss_classifier: 0.1610 (0.1681)  loss_box_reg: 0.1134 (0.1394)  loss_objectness: 0.1396 (0.1357)  loss_rpn_box_reg: 0.0365 (0.0534)  time: 0.3338  data: 0.1434  max mem: 3961\n",
      "Training Epoch: [2]  [ 480/1229]  eta: 0:04:04  lr: 0.005000  loss: 0.4520 (0.4975)  loss_classifier: 0.1571 (0.1686)  loss_box_reg: 0.1011 (0.1393)  loss_objectness: 0.1273 (0.1361)  loss_rpn_box_reg: 0.0350 (0.0535)  time: 0.3373  data: 0.1435  max mem: 3961\n",
      "Training Epoch: [2]  [ 490/1229]  eta: 0:04:00  lr: 0.005000  loss: 0.4696 (0.4974)  loss_classifier: 0.1830 (0.1686)  loss_box_reg: 0.1190 (0.1391)  loss_objectness: 0.1236 (0.1364)  loss_rpn_box_reg: 0.0355 (0.0532)  time: 0.3254  data: 0.1428  max mem: 3961\n",
      "Training Epoch: [2]  [ 500/1229]  eta: 0:03:57  lr: 0.005000  loss: 0.4002 (0.4982)  loss_classifier: 0.1668 (0.1692)  loss_box_reg: 0.1367 (0.1396)  loss_objectness: 0.1127 (0.1364)  loss_rpn_box_reg: 0.0427 (0.0530)  time: 0.3280  data: 0.1416  max mem: 3961\n",
      "Training Epoch: [2]  [ 510/1229]  eta: 0:03:54  lr: 0.005000  loss: 0.3963 (0.4970)  loss_classifier: 0.1502 (0.1688)  loss_box_reg: 0.1340 (0.1394)  loss_objectness: 0.0985 (0.1360)  loss_rpn_box_reg: 0.0364 (0.0527)  time: 0.3274  data: 0.1408  max mem: 3961\n",
      "Training Epoch: [2]  [ 520/1229]  eta: 0:03:51  lr: 0.005000  loss: 0.3405 (0.4960)  loss_classifier: 0.1345 (0.1688)  loss_box_reg: 0.0901 (0.1392)  loss_objectness: 0.1077 (0.1357)  loss_rpn_box_reg: 0.0261 (0.0523)  time: 0.3228  data: 0.1416  max mem: 3961\n",
      "Training Epoch: [2]  [ 530/1229]  eta: 0:03:47  lr: 0.005000  loss: 0.3578 (0.4961)  loss_classifier: 0.1345 (0.1687)  loss_box_reg: 0.0671 (0.1386)  loss_objectness: 0.1154 (0.1357)  loss_rpn_box_reg: 0.0261 (0.0531)  time: 0.3235  data: 0.1425  max mem: 3961\n",
      "Training Epoch: [2]  [ 540/1229]  eta: 0:03:44  lr: 0.005000  loss: 0.4259 (0.4978)  loss_classifier: 0.1523 (0.1693)  loss_box_reg: 0.1344 (0.1398)  loss_objectness: 0.0990 (0.1355)  loss_rpn_box_reg: 0.0307 (0.0532)  time: 0.3223  data: 0.1421  max mem: 3961\n",
      "Training Epoch: [2]  [ 550/1229]  eta: 0:03:41  lr: 0.005000  loss: 0.5404 (0.4987)  loss_classifier: 0.2277 (0.1700)  loss_box_reg: 0.2024 (0.1409)  loss_objectness: 0.0981 (0.1349)  loss_rpn_box_reg: 0.0322 (0.0529)  time: 0.3185  data: 0.1408  max mem: 3961\n",
      "Training Epoch: [2]  [ 560/1229]  eta: 0:03:37  lr: 0.005000  loss: 0.5003 (0.5001)  loss_classifier: 0.1862 (0.1706)  loss_box_reg: 0.1432 (0.1416)  loss_objectness: 0.1095 (0.1351)  loss_rpn_box_reg: 0.0330 (0.0528)  time: 0.3218  data: 0.1415  max mem: 3961\n",
      "Training Epoch: [2]  [ 570/1229]  eta: 0:03:34  lr: 0.005000  loss: 0.4829 (0.4994)  loss_classifier: 0.1789 (0.1710)  loss_box_reg: 0.1341 (0.1415)  loss_objectness: 0.1142 (0.1345)  loss_rpn_box_reg: 0.0249 (0.0524)  time: 0.3300  data: 0.1427  max mem: 3961\n",
      "Training Epoch: [2]  [ 580/1229]  eta: 0:03:31  lr: 0.005000  loss: 0.4036 (0.4990)  loss_classifier: 0.1511 (0.1710)  loss_box_reg: 0.1433 (0.1417)  loss_objectness: 0.0992 (0.1341)  loss_rpn_box_reg: 0.0182 (0.0522)  time: 0.3330  data: 0.1419  max mem: 3961\n",
      "Training Epoch: [2]  [ 590/1229]  eta: 0:03:28  lr: 0.005000  loss: 0.3854 (0.4980)  loss_classifier: 0.1491 (0.1706)  loss_box_reg: 0.1311 (0.1415)  loss_objectness: 0.1028 (0.1339)  loss_rpn_box_reg: 0.0334 (0.0520)  time: 0.3277  data: 0.1427  max mem: 3961\n",
      "Training Epoch: [2]  [ 600/1229]  eta: 0:03:25  lr: 0.005000  loss: 0.3748 (0.4977)  loss_classifier: 0.1438 (0.1704)  loss_box_reg: 0.1209 (0.1413)  loss_objectness: 0.1028 (0.1340)  loss_rpn_box_reg: 0.0268 (0.0520)  time: 0.3258  data: 0.1450  max mem: 3961\n",
      "Training Epoch: [2]  [ 610/1229]  eta: 0:03:21  lr: 0.005000  loss: 0.4908 (0.4986)  loss_classifier: 0.1584 (0.1705)  loss_box_reg: 0.1239 (0.1414)  loss_objectness: 0.1368 (0.1344)  loss_rpn_box_reg: 0.0451 (0.0523)  time: 0.3256  data: 0.1453  max mem: 3961\n",
      "Training Epoch: [2]  [ 620/1229]  eta: 0:03:18  lr: 0.005000  loss: 0.5095 (0.4995)  loss_classifier: 0.1584 (0.1708)  loss_box_reg: 0.1239 (0.1415)  loss_objectness: 0.1308 (0.1345)  loss_rpn_box_reg: 0.0590 (0.0527)  time: 0.3266  data: 0.1448  max mem: 3961\n",
      "Training Epoch: [2]  [ 630/1229]  eta: 0:03:15  lr: 0.005000  loss: 0.4250 (0.4991)  loss_classifier: 0.1477 (0.1705)  loss_box_reg: 0.1165 (0.1411)  loss_objectness: 0.1432 (0.1348)  loss_rpn_box_reg: 0.0383 (0.0528)  time: 0.3249  data: 0.1416  max mem: 3961\n",
      "Training Epoch: [2]  [ 640/1229]  eta: 0:03:11  lr: 0.005000  loss: 0.4002 (0.4988)  loss_classifier: 0.1304 (0.1704)  loss_box_reg: 0.1002 (0.1409)  loss_objectness: 0.1438 (0.1347)  loss_rpn_box_reg: 0.0264 (0.0528)  time: 0.3187  data: 0.1395  max mem: 3961\n",
      "Training Epoch: [2]  [ 650/1229]  eta: 0:03:08  lr: 0.005000  loss: 0.4565 (0.4991)  loss_classifier: 0.1431 (0.1705)  loss_box_reg: 0.0891 (0.1406)  loss_objectness: 0.1084 (0.1350)  loss_rpn_box_reg: 0.0278 (0.0530)  time: 0.3251  data: 0.1421  max mem: 3961\n",
      "Training Epoch: [2]  [ 660/1229]  eta: 0:03:05  lr: 0.005000  loss: 0.4399 (0.4980)  loss_classifier: 0.1486 (0.1702)  loss_box_reg: 0.0925 (0.1401)  loss_objectness: 0.1084 (0.1349)  loss_rpn_box_reg: 0.0347 (0.0528)  time: 0.3291  data: 0.1429  max mem: 3961\n",
      "Training Epoch: [2]  [ 670/1229]  eta: 0:03:02  lr: 0.005000  loss: 0.3940 (0.4997)  loss_classifier: 0.1534 (0.1708)  loss_box_reg: 0.1130 (0.1407)  loss_objectness: 0.1117 (0.1352)  loss_rpn_box_reg: 0.0347 (0.0530)  time: 0.3246  data: 0.1424  max mem: 3961\n",
      "Training Epoch: [2]  [ 680/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.4663 (0.4987)  loss_classifier: 0.1912 (0.1706)  loss_box_reg: 0.1201 (0.1404)  loss_objectness: 0.1117 (0.1348)  loss_rpn_box_reg: 0.0400 (0.0528)  time: 0.3163  data: 0.1422  max mem: 3961\n",
      "Training Epoch: [2]  [ 690/1229]  eta: 0:02:55  lr: 0.005000  loss: 0.4848 (0.5000)  loss_classifier: 0.1921 (0.1712)  loss_box_reg: 0.1401 (0.1412)  loss_objectness: 0.1314 (0.1350)  loss_rpn_box_reg: 0.0386 (0.0527)  time: 0.3193  data: 0.1438  max mem: 3961\n",
      "Training Epoch: [2]  [ 700/1229]  eta: 0:02:52  lr: 0.005000  loss: 0.6123 (0.5022)  loss_classifier: 0.1890 (0.1716)  loss_box_reg: 0.1694 (0.1419)  loss_objectness: 0.1641 (0.1354)  loss_rpn_box_reg: 0.0393 (0.0533)  time: 0.3245  data: 0.1465  max mem: 3961\n",
      "Training Epoch: [2]  [ 710/1229]  eta: 0:02:49  lr: 0.005000  loss: 0.5503 (0.5014)  loss_classifier: 0.1617 (0.1713)  loss_box_reg: 0.1273 (0.1415)  loss_objectness: 0.1641 (0.1354)  loss_rpn_box_reg: 0.0346 (0.0532)  time: 0.3247  data: 0.1471  max mem: 3961\n",
      "Training Epoch: [2]  [ 720/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.5503 (0.5030)  loss_classifier: 0.1665 (0.1717)  loss_box_reg: 0.1323 (0.1421)  loss_objectness: 0.1272 (0.1356)  loss_rpn_box_reg: 0.0309 (0.0537)  time: 0.3288  data: 0.1449  max mem: 3961\n",
      "Training Epoch: [2]  [ 730/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.5611 (0.5028)  loss_classifier: 0.1665 (0.1713)  loss_box_reg: 0.1470 (0.1417)  loss_objectness: 0.1323 (0.1359)  loss_rpn_box_reg: 0.0383 (0.0539)  time: 0.3273  data: 0.1441  max mem: 3961\n",
      "Training Epoch: [2]  [ 740/1229]  eta: 0:02:39  lr: 0.005000  loss: 0.5611 (0.5040)  loss_classifier: 0.1755 (0.1716)  loss_box_reg: 0.1280 (0.1422)  loss_objectness: 0.1612 (0.1363)  loss_rpn_box_reg: 0.0387 (0.0539)  time: 0.3200  data: 0.1439  max mem: 3961\n",
      "Training Epoch: [2]  [ 750/1229]  eta: 0:02:35  lr: 0.005000  loss: 0.4868 (0.5037)  loss_classifier: 0.1755 (0.1714)  loss_box_reg: 0.1280 (0.1423)  loss_objectness: 0.1413 (0.1360)  loss_rpn_box_reg: 0.0375 (0.0539)  time: 0.3189  data: 0.1421  max mem: 3961\n",
      "Training Epoch: [2]  [ 760/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.4708 (0.5046)  loss_classifier: 0.1722 (0.1717)  loss_box_reg: 0.1251 (0.1426)  loss_objectness: 0.0941 (0.1362)  loss_rpn_box_reg: 0.0328 (0.0541)  time: 0.3240  data: 0.1419  max mem: 3961\n",
      "Training Epoch: [2]  [ 770/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.4708 (0.5037)  loss_classifier: 0.1392 (0.1712)  loss_box_reg: 0.1251 (0.1424)  loss_objectness: 0.0965 (0.1361)  loss_rpn_box_reg: 0.0426 (0.0540)  time: 0.3172  data: 0.1421  max mem: 3961\n",
      "Training Epoch: [2]  [ 780/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.4657 (0.5046)  loss_classifier: 0.1773 (0.1716)  loss_box_reg: 0.0854 (0.1422)  loss_objectness: 0.1101 (0.1364)  loss_rpn_box_reg: 0.0355 (0.0544)  time: 0.3138  data: 0.1440  max mem: 3961\n",
      "Training Epoch: [2]  [ 790/1229]  eta: 0:02:22  lr: 0.005000  loss: 0.4604 (0.5051)  loss_classifier: 0.1854 (0.1719)  loss_box_reg: 0.1270 (0.1424)  loss_objectness: 0.1264 (0.1365)  loss_rpn_box_reg: 0.0269 (0.0543)  time: 0.3191  data: 0.1447  max mem: 3961\n",
      "Training Epoch: [2]  [ 800/1229]  eta: 0:02:19  lr: 0.005000  loss: 0.4521 (0.5056)  loss_classifier: 0.1623 (0.1721)  loss_box_reg: 0.1270 (0.1427)  loss_objectness: 0.1264 (0.1365)  loss_rpn_box_reg: 0.0385 (0.0543)  time: 0.3200  data: 0.1431  max mem: 3961\n",
      "Training Epoch: [2]  [ 810/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.5549 (0.5063)  loss_classifier: 0.1669 (0.1723)  loss_box_reg: 0.1164 (0.1428)  loss_objectness: 0.1275 (0.1367)  loss_rpn_box_reg: 0.0398 (0.0545)  time: 0.3249  data: 0.1425  max mem: 3961\n",
      "Training Epoch: [2]  [ 820/1229]  eta: 0:02:12  lr: 0.005000  loss: 0.5549 (0.5060)  loss_classifier: 0.1832 (0.1723)  loss_box_reg: 0.1164 (0.1428)  loss_objectness: 0.1222 (0.1366)  loss_rpn_box_reg: 0.0369 (0.0543)  time: 0.3221  data: 0.1420  max mem: 3961\n",
      "Training Epoch: [2]  [ 830/1229]  eta: 0:02:09  lr: 0.005000  loss: 0.3979 (0.5057)  loss_classifier: 0.1404 (0.1720)  loss_box_reg: 0.0960 (0.1424)  loss_objectness: 0.1222 (0.1367)  loss_rpn_box_reg: 0.0391 (0.0546)  time: 0.3178  data: 0.1419  max mem: 3961\n",
      "Training Epoch: [2]  [ 840/1229]  eta: 0:02:06  lr: 0.005000  loss: 0.3641 (0.5045)  loss_classifier: 0.1215 (0.1716)  loss_box_reg: 0.0691 (0.1419)  loss_objectness: 0.1093 (0.1365)  loss_rpn_box_reg: 0.0425 (0.0544)  time: 0.3201  data: 0.1418  max mem: 3961\n",
      "Training Epoch: [2]  [ 850/1229]  eta: 0:02:03  lr: 0.005000  loss: 0.3179 (0.5036)  loss_classifier: 0.1245 (0.1713)  loss_box_reg: 0.0840 (0.1416)  loss_objectness: 0.0941 (0.1362)  loss_rpn_box_reg: 0.0149 (0.0545)  time: 0.3213  data: 0.1418  max mem: 3961\n",
      "Training Epoch: [2]  [ 860/1229]  eta: 0:01:59  lr: 0.005000  loss: 0.3724 (0.5031)  loss_classifier: 0.1394 (0.1713)  loss_box_reg: 0.1022 (0.1415)  loss_objectness: 0.1046 (0.1360)  loss_rpn_box_reg: 0.0185 (0.0542)  time: 0.3180  data: 0.1411  max mem: 3961\n",
      "Training Epoch: [2]  [ 870/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.4626 (0.5042)  loss_classifier: 0.1720 (0.1714)  loss_box_reg: 0.1218 (0.1415)  loss_objectness: 0.1314 (0.1370)  loss_rpn_box_reg: 0.0223 (0.0543)  time: 0.3196  data: 0.1434  max mem: 3961\n",
      "Training Epoch: [2]  [ 880/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.4910 (0.5054)  loss_classifier: 0.1729 (0.1719)  loss_box_reg: 0.1651 (0.1421)  loss_objectness: 0.1425 (0.1371)  loss_rpn_box_reg: 0.0261 (0.0543)  time: 0.3233  data: 0.1434  max mem: 3961\n",
      "Training Epoch: [2]  [ 890/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.5075 (0.5067)  loss_classifier: 0.1729 (0.1723)  loss_box_reg: 0.1651 (0.1428)  loss_objectness: 0.1268 (0.1370)  loss_rpn_box_reg: 0.0353 (0.0546)  time: 0.3186  data: 0.1421  max mem: 3961\n",
      "Training Epoch: [2]  [ 900/1229]  eta: 0:01:46  lr: 0.005000  loss: 0.5075 (0.5091)  loss_classifier: 0.1768 (0.1730)  loss_box_reg: 0.1630 (0.1437)  loss_objectness: 0.1195 (0.1373)  loss_rpn_box_reg: 0.0774 (0.0552)  time: 0.3233  data: 0.1431  max mem: 3961\n",
      "Training Epoch: [2]  [ 910/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.5331 (0.5102)  loss_classifier: 0.1876 (0.1734)  loss_box_reg: 0.1722 (0.1441)  loss_objectness: 0.1194 (0.1374)  loss_rpn_box_reg: 0.0629 (0.0552)  time: 0.3258  data: 0.1449  max mem: 3961\n",
      "Training Epoch: [2]  [ 920/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.4519 (0.5089)  loss_classifier: 0.1680 (0.1731)  loss_box_reg: 0.1199 (0.1435)  loss_objectness: 0.1194 (0.1374)  loss_rpn_box_reg: 0.0306 (0.0549)  time: 0.3236  data: 0.1449  max mem: 3961\n",
      "Training Epoch: [2]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.4088 (0.5096)  loss_classifier: 0.1627 (0.1732)  loss_box_reg: 0.0837 (0.1437)  loss_objectness: 0.1283 (0.1375)  loss_rpn_box_reg: 0.0306 (0.0551)  time: 0.3262  data: 0.1437  max mem: 3961\n",
      "Training Epoch: [2]  [ 940/1229]  eta: 0:01:33  lr: 0.005000  loss: 0.5037 (0.5092)  loss_classifier: 0.1649 (0.1731)  loss_box_reg: 0.1312 (0.1437)  loss_objectness: 0.1283 (0.1375)  loss_rpn_box_reg: 0.0374 (0.0549)  time: 0.3267  data: 0.1428  max mem: 3961\n",
      "Training Epoch: [2]  [ 950/1229]  eta: 0:01:30  lr: 0.005000  loss: 0.4403 (0.5090)  loss_classifier: 0.1281 (0.1730)  loss_box_reg: 0.0973 (0.1435)  loss_objectness: 0.1262 (0.1377)  loss_rpn_box_reg: 0.0308 (0.0548)  time: 0.3273  data: 0.1416  max mem: 3961\n",
      "Training Epoch: [2]  [ 960/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.4523 (0.5094)  loss_classifier: 0.1434 (0.1732)  loss_box_reg: 0.1093 (0.1436)  loss_objectness: 0.1236 (0.1377)  loss_rpn_box_reg: 0.0353 (0.0549)  time: 0.3248  data: 0.1394  max mem: 3961\n",
      "Training Epoch: [2]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.4866 (0.5088)  loss_classifier: 0.1618 (0.1728)  loss_box_reg: 0.1164 (0.1434)  loss_objectness: 0.1054 (0.1376)  loss_rpn_box_reg: 0.0412 (0.0550)  time: 0.3213  data: 0.1386  max mem: 3961\n",
      "Training Epoch: [2]  [ 980/1229]  eta: 0:01:20  lr: 0.005000  loss: 0.4787 (0.5089)  loss_classifier: 0.1663 (0.1730)  loss_box_reg: 0.1351 (0.1436)  loss_objectness: 0.1054 (0.1374)  loss_rpn_box_reg: 0.0328 (0.0548)  time: 0.3222  data: 0.1394  max mem: 3961\n",
      "Training Epoch: [2]  [ 990/1229]  eta: 0:01:17  lr: 0.005000  loss: 0.5688 (0.5111)  loss_classifier: 0.1970 (0.1735)  loss_box_reg: 0.1647 (0.1444)  loss_objectness: 0.1437 (0.1380)  loss_rpn_box_reg: 0.0328 (0.0553)  time: 0.3242  data: 0.1401  max mem: 3961\n",
      "Training Epoch: [2]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.6399 (0.5122)  loss_classifier: 0.2019 (0.1739)  loss_box_reg: 0.1901 (0.1449)  loss_objectness: 0.1352 (0.1378)  loss_rpn_box_reg: 0.0354 (0.0556)  time: 0.3231  data: 0.1413  max mem: 3961\n",
      "Training Epoch: [2]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.5317 (0.5123)  loss_classifier: 0.1697 (0.1738)  loss_box_reg: 0.1685 (0.1450)  loss_objectness: 0.1047 (0.1377)  loss_rpn_box_reg: 0.0370 (0.0558)  time: 0.3227  data: 0.1400  max mem: 3961\n",
      "Training Epoch: [2]  [1020/1229]  eta: 0:01:07  lr: 0.005000  loss: 0.4292 (0.5121)  loss_classifier: 0.1328 (0.1735)  loss_box_reg: 0.0897 (0.1448)  loss_objectness: 0.0986 (0.1376)  loss_rpn_box_reg: 0.0363 (0.0563)  time: 0.3310  data: 0.1412  max mem: 3961\n",
      "Training Epoch: [2]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.4292 (0.5126)  loss_classifier: 0.1404 (0.1737)  loss_box_reg: 0.1074 (0.1450)  loss_objectness: 0.1055 (0.1376)  loss_rpn_box_reg: 0.0342 (0.0563)  time: 0.3323  data: 0.1417  max mem: 3961\n",
      "Training Epoch: [2]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.3401 (0.5116)  loss_classifier: 0.1571 (0.1734)  loss_box_reg: 0.0966 (0.1448)  loss_objectness: 0.1059 (0.1374)  loss_rpn_box_reg: 0.0257 (0.0561)  time: 0.3286  data: 0.1402  max mem: 3961\n",
      "Training Epoch: [2]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.4277 (0.5115)  loss_classifier: 0.1161 (0.1732)  loss_box_reg: 0.0940 (0.1447)  loss_objectness: 0.1099 (0.1374)  loss_rpn_box_reg: 0.0257 (0.0562)  time: 0.3285  data: 0.1391  max mem: 3961\n",
      "Training Epoch: [2]  [1060/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.4892 (0.5110)  loss_classifier: 0.1593 (0.1730)  loss_box_reg: 0.1238 (0.1445)  loss_objectness: 0.1099 (0.1372)  loss_rpn_box_reg: 0.0369 (0.0563)  time: 0.3220  data: 0.1396  max mem: 3961\n",
      "Training Epoch: [2]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.4823 (0.5126)  loss_classifier: 0.1695 (0.1737)  loss_box_reg: 0.1333 (0.1455)  loss_objectness: 0.1066 (0.1372)  loss_rpn_box_reg: 0.0357 (0.0564)  time: 0.3178  data: 0.1435  max mem: 3961\n",
      "Training Epoch: [2]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.3629 (0.5110)  loss_classifier: 0.1259 (0.1730)  loss_box_reg: 0.1045 (0.1448)  loss_objectness: 0.1036 (0.1369)  loss_rpn_box_reg: 0.0211 (0.0564)  time: 0.3173  data: 0.1436  max mem: 3961\n",
      "Training Epoch: [2]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.4409 (0.5124)  loss_classifier: 0.1355 (0.1734)  loss_box_reg: 0.0851 (0.1450)  loss_objectness: 0.1283 (0.1373)  loss_rpn_box_reg: 0.0337 (0.0567)  time: 0.3239  data: 0.1395  max mem: 3961\n",
      "Training Epoch: [2]  [1100/1229]  eta: 0:00:41  lr: 0.005000  loss: 0.4649 (0.5116)  loss_classifier: 0.1589 (0.1732)  loss_box_reg: 0.1083 (0.1447)  loss_objectness: 0.1346 (0.1372)  loss_rpn_box_reg: 0.0428 (0.0566)  time: 0.3242  data: 0.1375  max mem: 3961\n",
      "Training Epoch: [2]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.3800 (0.5102)  loss_classifier: 0.1250 (0.1726)  loss_box_reg: 0.0967 (0.1442)  loss_objectness: 0.1181 (0.1370)  loss_rpn_box_reg: 0.0230 (0.0564)  time: 0.3210  data: 0.1403  max mem: 3961\n",
      "Training Epoch: [2]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4060 (0.5092)  loss_classifier: 0.1139 (0.1722)  loss_box_reg: 0.0813 (0.1438)  loss_objectness: 0.1073 (0.1368)  loss_rpn_box_reg: 0.0216 (0.0564)  time: 0.3244  data: 0.1410  max mem: 3961\n",
      "Training Epoch: [2]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.4066 (0.5095)  loss_classifier: 0.1139 (0.1723)  loss_box_reg: 0.0882 (0.1440)  loss_objectness: 0.1073 (0.1368)  loss_rpn_box_reg: 0.0267 (0.0564)  time: 0.3293  data: 0.1396  max mem: 3961\n",
      "Training Epoch: [2]  [1140/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.3985 (0.5090)  loss_classifier: 0.1331 (0.1721)  loss_box_reg: 0.1446 (0.1440)  loss_objectness: 0.1092 (0.1365)  loss_rpn_box_reg: 0.0405 (0.0564)  time: 0.3275  data: 0.1396  max mem: 3961\n",
      "Training Epoch: [2]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.4380 (0.5086)  loss_classifier: 0.1466 (0.1720)  loss_box_reg: 0.1426 (0.1440)  loss_objectness: 0.1066 (0.1363)  loss_rpn_box_reg: 0.0365 (0.0564)  time: 0.3218  data: 0.1401  max mem: 3961\n",
      "Training Epoch: [2]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.4149 (0.5081)  loss_classifier: 0.1466 (0.1718)  loss_box_reg: 0.0996 (0.1438)  loss_objectness: 0.1090 (0.1362)  loss_rpn_box_reg: 0.0239 (0.0563)  time: 0.3282  data: 0.1395  max mem: 3961\n",
      "Training Epoch: [2]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.4941 (0.5087)  loss_classifier: 0.1762 (0.1720)  loss_box_reg: 0.1460 (0.1442)  loss_objectness: 0.1187 (0.1362)  loss_rpn_box_reg: 0.0347 (0.0563)  time: 0.3319  data: 0.1405  max mem: 3961\n",
      "Training Epoch: [2]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.4941 (0.5084)  loss_classifier: 0.1762 (0.1720)  loss_box_reg: 0.1553 (0.1443)  loss_objectness: 0.1040 (0.1360)  loss_rpn_box_reg: 0.0331 (0.0561)  time: 0.3245  data: 0.1411  max mem: 3961\n",
      "Training Epoch: [2]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.4594 (0.5086)  loss_classifier: 0.1719 (0.1720)  loss_box_reg: 0.1449 (0.1445)  loss_objectness: 0.0986 (0.1360)  loss_rpn_box_reg: 0.0337 (0.0560)  time: 0.3256  data: 0.1399  max mem: 3961\n",
      "Training Epoch: [2]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.5044 (0.5090)  loss_classifier: 0.1873 (0.1722)  loss_box_reg: 0.1445 (0.1449)  loss_objectness: 0.1279 (0.1360)  loss_rpn_box_reg: 0.0339 (0.0559)  time: 0.3290  data: 0.1412  max mem: 3961\n",
      "Training Epoch: [2]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.5044 (0.5093)  loss_classifier: 0.1847 (0.1725)  loss_box_reg: 0.1265 (0.1448)  loss_objectness: 0.1370 (0.1363)  loss_rpn_box_reg: 0.0348 (0.0557)  time: 0.3279  data: 0.1429  max mem: 3961\n",
      "Training Epoch: [2]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.5509 (0.5096)  loss_classifier: 0.1704 (0.1726)  loss_box_reg: 0.1265 (0.1452)  loss_objectness: 0.1308 (0.1363)  loss_rpn_box_reg: 0.0348 (0.0555)  time: 0.3258  data: 0.1432  max mem: 3961\n",
      "Training Epoch: [2]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4711 (0.5095)  loss_classifier: 0.1473 (0.1724)  loss_box_reg: 0.1147 (0.1448)  loss_objectness: 0.1417 (0.1367)  loss_rpn_box_reg: 0.0325 (0.0556)  time: 0.3230  data: 0.1418  max mem: 3961\n",
      "Training Epoch: [2] Total time: 0:06:39 (0.3249 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:39  model_time: 0.2910 (0.2910)  evaluator_time: 0.0010 (0.0010)  time: 0.3240  data: 0.0300  max mem: 3961\n",
      "Test:  [100/308]  eta: 0:00:32  model_time: 0.1050 (0.1108)  evaluator_time: 0.0030 (0.0046)  time: 0.1600  data: 0.0437  max mem: 3961\n",
      "Test:  [200/308]  eta: 0:00:16  model_time: 0.1140 (0.1103)  evaluator_time: 0.0020 (0.0045)  time: 0.1572  data: 0.0386  max mem: 3961\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0990 (0.1094)  evaluator_time: 0.0030 (0.0045)  time: 0.1524  data: 0.0440  max mem: 3961\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0990 (0.1092)  evaluator_time: 0.0020 (0.0045)  time: 0.1492  data: 0.0424  max mem: 3961\n",
      "Test: Total time: 0:00:46 (0.1525 s / it)\n",
      "Averaged stats: model_time: 0.0990 (0.1092)  evaluator_time: 0.0020 (0.0045)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.113\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.086\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.093\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.168\n",
      "Testing Epoch: [2]  [  0/308]  eta: 0:00:49  lr: 0.005000  loss: 0.2087 (0.2087)  loss_classifier: 0.0688 (0.0688)  loss_box_reg: 0.0672 (0.0672)  loss_objectness: 0.0575 (0.0575)  loss_rpn_box_reg: 0.0152 (0.0152)  time: 0.1610  data: 0.0310  max mem: 3961\n",
      "Testing Epoch: [2]  [100/308]  eta: 0:00:36  lr: 0.005000  loss: 0.3208 (0.5227)  loss_classifier: 0.1386 (0.1791)  loss_box_reg: 0.1067 (0.1631)  loss_objectness: 0.0885 (0.1227)  loss_rpn_box_reg: 0.0199 (0.0578)  time: 0.1777  data: 0.0414  max mem: 3961\n",
      "Testing Epoch: [2]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.4578 (0.5027)  loss_classifier: 0.1618 (0.1728)  loss_box_reg: 0.1463 (0.1564)  loss_objectness: 0.0923 (0.1168)  loss_rpn_box_reg: 0.0255 (0.0566)  time: 0.1789  data: 0.0362  max mem: 3961\n",
      "Testing Epoch: [2]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5189 (0.5031)  loss_classifier: 0.1864 (0.1737)  loss_box_reg: 0.1569 (0.1590)  loss_objectness: 0.1142 (0.1149)  loss_rpn_box_reg: 0.0325 (0.0555)  time: 0.1695  data: 0.0409  max mem: 3969\n",
      "Testing Epoch: [2]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.4617 (0.5026)  loss_classifier: 0.1676 (0.1738)  loss_box_reg: 0.1387 (0.1591)  loss_objectness: 0.1090 (0.1148)  loss_rpn_box_reg: 0.0325 (0.0549)  time: 0.1711  data: 0.0431  max mem: 3969\n",
      "Testing Epoch: [2] Total time: 0:00:54 (0.1764 s / it)\n",
      "Training Epoch: [3]  [   0/1229]  eta: 0:07:21  lr: 0.005000  loss: 0.5130 (0.5130)  loss_classifier: 0.2291 (0.2291)  loss_box_reg: 0.1904 (0.1904)  loss_objectness: 0.0621 (0.0621)  loss_rpn_box_reg: 0.0313 (0.0313)  time: 0.3590  data: 0.1530  max mem: 3969\n",
      "Training Epoch: [3]  [  10/1229]  eta: 0:06:42  lr: 0.005000  loss: 0.4587 (0.4448)  loss_classifier: 0.1431 (0.1458)  loss_box_reg: 0.0802 (0.1030)  loss_objectness: 0.1104 (0.1256)  loss_rpn_box_reg: 0.0313 (0.0703)  time: 0.3303  data: 0.1398  max mem: 3969\n",
      "Training Epoch: [3]  [  20/1229]  eta: 0:06:27  lr: 0.005000  loss: 0.5674 (0.5770)  loss_classifier: 0.1627 (0.1908)  loss_box_reg: 0.1376 (0.1603)  loss_objectness: 0.1513 (0.1547)  loss_rpn_box_reg: 0.0384 (0.0713)  time: 0.3184  data: 0.1420  max mem: 3969\n",
      "Training Epoch: [3]  [  30/1229]  eta: 0:06:23  lr: 0.005000  loss: 0.4896 (0.5613)  loss_classifier: 0.1987 (0.1892)  loss_box_reg: 0.1889 (0.1578)  loss_objectness: 0.1460 (0.1439)  loss_rpn_box_reg: 0.0474 (0.0704)  time: 0.3139  data: 0.1447  max mem: 3969\n",
      "Training Epoch: [3]  [  40/1229]  eta: 0:06:21  lr: 0.005000  loss: 0.4869 (0.5647)  loss_classifier: 0.1623 (0.1926)  loss_box_reg: 0.1416 (0.1673)  loss_objectness: 0.1098 (0.1425)  loss_rpn_box_reg: 0.0374 (0.0624)  time: 0.3207  data: 0.1433  max mem: 3969\n",
      "Training Epoch: [3]  [  50/1229]  eta: 0:06:17  lr: 0.005000  loss: 0.4374 (0.5440)  loss_classifier: 0.1552 (0.1839)  loss_box_reg: 0.1281 (0.1615)  loss_objectness: 0.1231 (0.1397)  loss_rpn_box_reg: 0.0366 (0.0588)  time: 0.3211  data: 0.1401  max mem: 3969\n",
      "Training Epoch: [3]  [  60/1229]  eta: 0:06:14  lr: 0.005000  loss: 0.3462 (0.5294)  loss_classifier: 0.1263 (0.1803)  loss_box_reg: 0.0942 (0.1554)  loss_objectness: 0.1071 (0.1367)  loss_rpn_box_reg: 0.0170 (0.0569)  time: 0.3208  data: 0.1392  max mem: 3969\n",
      "Training Epoch: [3]  [  70/1229]  eta: 0:06:13  lr: 0.005000  loss: 0.3421 (0.5104)  loss_classifier: 0.1263 (0.1747)  loss_box_reg: 0.0806 (0.1482)  loss_objectness: 0.0971 (0.1332)  loss_rpn_box_reg: 0.0180 (0.0543)  time: 0.3285  data: 0.1431  max mem: 3969\n",
      "Training Epoch: [3]  [  80/1229]  eta: 0:06:11  lr: 0.005000  loss: 0.3977 (0.5064)  loss_classifier: 0.1231 (0.1738)  loss_box_reg: 0.0896 (0.1490)  loss_objectness: 0.0854 (0.1314)  loss_rpn_box_reg: 0.0209 (0.0523)  time: 0.3314  data: 0.1451  max mem: 3969\n",
      "Training Epoch: [3]  [  90/1229]  eta: 0:06:09  lr: 0.005000  loss: 0.3486 (0.4896)  loss_classifier: 0.1231 (0.1680)  loss_box_reg: 0.0896 (0.1434)  loss_objectness: 0.0832 (0.1283)  loss_rpn_box_reg: 0.0186 (0.0499)  time: 0.3298  data: 0.1466  max mem: 3969\n",
      "Training Epoch: [3]  [ 100/1229]  eta: 0:06:05  lr: 0.005000  loss: 0.3686 (0.4943)  loss_classifier: 0.1324 (0.1693)  loss_box_reg: 0.0930 (0.1474)  loss_objectness: 0.0978 (0.1293)  loss_rpn_box_reg: 0.0301 (0.0483)  time: 0.3268  data: 0.1461  max mem: 3969\n",
      "Training Epoch: [3]  [ 110/1229]  eta: 0:06:02  lr: 0.005000  loss: 0.4830 (0.5056)  loss_classifier: 0.1634 (0.1737)  loss_box_reg: 0.1408 (0.1536)  loss_objectness: 0.1399 (0.1303)  loss_rpn_box_reg: 0.0301 (0.0480)  time: 0.3248  data: 0.1437  max mem: 3969\n",
      "Training Epoch: [3]  [ 120/1229]  eta: 0:06:00  lr: 0.005000  loss: 0.4209 (0.5043)  loss_classifier: 0.1655 (0.1736)  loss_box_reg: 0.1258 (0.1514)  loss_objectness: 0.1337 (0.1315)  loss_rpn_box_reg: 0.0283 (0.0479)  time: 0.3279  data: 0.1440  max mem: 3969\n",
      "Training Epoch: [3]  [ 130/1229]  eta: 0:05:57  lr: 0.005000  loss: 0.4639 (0.5052)  loss_classifier: 0.1727 (0.1735)  loss_box_reg: 0.0977 (0.1510)  loss_objectness: 0.1210 (0.1321)  loss_rpn_box_reg: 0.0356 (0.0486)  time: 0.3317  data: 0.1468  max mem: 3969\n",
      "Training Epoch: [3]  [ 140/1229]  eta: 0:05:54  lr: 0.005000  loss: 0.4246 (0.5056)  loss_classifier: 0.1394 (0.1731)  loss_box_reg: 0.1188 (0.1510)  loss_objectness: 0.1161 (0.1330)  loss_rpn_box_reg: 0.0356 (0.0486)  time: 0.3297  data: 0.1435  max mem: 3969\n",
      "Training Epoch: [3]  [ 150/1229]  eta: 0:05:51  lr: 0.005000  loss: 0.4246 (0.5064)  loss_classifier: 0.1341 (0.1722)  loss_box_reg: 0.1188 (0.1497)  loss_objectness: 0.0968 (0.1340)  loss_rpn_box_reg: 0.0284 (0.0506)  time: 0.3264  data: 0.1383  max mem: 3969\n",
      "Training Epoch: [3]  [ 160/1229]  eta: 0:05:47  lr: 0.005000  loss: 0.3005 (0.5046)  loss_classifier: 0.1049 (0.1713)  loss_box_reg: 0.0827 (0.1488)  loss_objectness: 0.0955 (0.1327)  loss_rpn_box_reg: 0.0235 (0.0518)  time: 0.3267  data: 0.1402  max mem: 3969\n",
      "Training Epoch: [3]  [ 170/1229]  eta: 0:05:45  lr: 0.005000  loss: 0.3359 (0.5035)  loss_classifier: 0.1227 (0.1709)  loss_box_reg: 0.0985 (0.1492)  loss_objectness: 0.1077 (0.1323)  loss_rpn_box_reg: 0.0233 (0.0511)  time: 0.3276  data: 0.1431  max mem: 3969\n",
      "Training Epoch: [3]  [ 180/1229]  eta: 0:05:42  lr: 0.005000  loss: 0.4583 (0.5020)  loss_classifier: 0.1309 (0.1691)  loss_box_reg: 0.0975 (0.1465)  loss_objectness: 0.1226 (0.1336)  loss_rpn_box_reg: 0.0290 (0.0527)  time: 0.3346  data: 0.1437  max mem: 3969\n",
      "Training Epoch: [3]  [ 190/1229]  eta: 0:05:39  lr: 0.005000  loss: 0.5468 (0.5056)  loss_classifier: 0.1529 (0.1704)  loss_box_reg: 0.1123 (0.1473)  loss_objectness: 0.1647 (0.1350)  loss_rpn_box_reg: 0.0346 (0.0530)  time: 0.3380  data: 0.1435  max mem: 3969\n",
      "Training Epoch: [3]  [ 200/1229]  eta: 0:05:36  lr: 0.005000  loss: 0.4723 (0.5011)  loss_classifier: 0.1430 (0.1682)  loss_box_reg: 0.1266 (0.1451)  loss_objectness: 0.1217 (0.1338)  loss_rpn_box_reg: 0.0346 (0.0541)  time: 0.3323  data: 0.1413  max mem: 3969\n",
      "Training Epoch: [3]  [ 210/1229]  eta: 0:05:33  lr: 0.005000  loss: 0.4089 (0.4960)  loss_classifier: 0.1108 (0.1661)  loss_box_reg: 0.0938 (0.1422)  loss_objectness: 0.1136 (0.1336)  loss_rpn_box_reg: 0.0332 (0.0542)  time: 0.3271  data: 0.1407  max mem: 3969\n",
      "Training Epoch: [3]  [ 220/1229]  eta: 0:05:29  lr: 0.005000  loss: 0.4089 (0.4952)  loss_classifier: 0.1194 (0.1658)  loss_box_reg: 0.1051 (0.1422)  loss_objectness: 0.1066 (0.1335)  loss_rpn_box_reg: 0.0251 (0.0537)  time: 0.3229  data: 0.1433  max mem: 3969\n",
      "Training Epoch: [3]  [ 230/1229]  eta: 0:05:26  lr: 0.005000  loss: 0.4526 (0.4920)  loss_classifier: 0.1204 (0.1637)  loss_box_reg: 0.1263 (0.1404)  loss_objectness: 0.1023 (0.1327)  loss_rpn_box_reg: 0.0294 (0.0552)  time: 0.3233  data: 0.1424  max mem: 3969\n",
      "Training Epoch: [3]  [ 240/1229]  eta: 0:05:23  lr: 0.005000  loss: 0.3281 (0.4904)  loss_classifier: 0.1064 (0.1626)  loss_box_reg: 0.0814 (0.1394)  loss_objectness: 0.1088 (0.1328)  loss_rpn_box_reg: 0.0294 (0.0555)  time: 0.3319  data: 0.1425  max mem: 3969\n",
      "Training Epoch: [3]  [ 250/1229]  eta: 0:05:20  lr: 0.005000  loss: 0.4496 (0.4948)  loss_classifier: 0.1412 (0.1644)  loss_box_reg: 0.1327 (0.1417)  loss_objectness: 0.1142 (0.1329)  loss_rpn_box_reg: 0.0400 (0.0559)  time: 0.3315  data: 0.1425  max mem: 3969\n",
      "Training Epoch: [3]  [ 260/1229]  eta: 0:05:16  lr: 0.005000  loss: 0.4685 (0.4978)  loss_classifier: 0.1654 (0.1657)  loss_box_reg: 0.1587 (0.1431)  loss_objectness: 0.1321 (0.1332)  loss_rpn_box_reg: 0.0319 (0.0559)  time: 0.3218  data: 0.1423  max mem: 3969\n",
      "Training Epoch: [3]  [ 270/1229]  eta: 0:05:13  lr: 0.005000  loss: 0.4048 (0.4940)  loss_classifier: 0.1411 (0.1648)  loss_box_reg: 0.1107 (0.1426)  loss_objectness: 0.0984 (0.1320)  loss_rpn_box_reg: 0.0203 (0.0546)  time: 0.3239  data: 0.1429  max mem: 3969\n",
      "Training Epoch: [3]  [ 280/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.4292 (0.4939)  loss_classifier: 0.1549 (0.1649)  loss_box_reg: 0.1195 (0.1426)  loss_objectness: 0.1126 (0.1320)  loss_rpn_box_reg: 0.0210 (0.0544)  time: 0.3288  data: 0.1432  max mem: 3969\n",
      "Training Epoch: [3]  [ 290/1229]  eta: 0:05:06  lr: 0.005000  loss: 0.5126 (0.4935)  loss_classifier: 0.1594 (0.1654)  loss_box_reg: 0.1285 (0.1434)  loss_objectness: 0.1201 (0.1312)  loss_rpn_box_reg: 0.0244 (0.0535)  time: 0.3265  data: 0.1426  max mem: 3969\n",
      "Training Epoch: [3]  [ 300/1229]  eta: 0:05:05  lr: 0.005000  loss: 0.4302 (0.4933)  loss_classifier: 0.1480 (0.1658)  loss_box_reg: 0.1148 (0.1441)  loss_objectness: 0.1103 (0.1309)  loss_rpn_box_reg: 0.0232 (0.0526)  time: 0.3493  data: 0.1415  max mem: 3969\n",
      "Training Epoch: [3]  [ 310/1229]  eta: 0:05:01  lr: 0.005000  loss: 0.4302 (0.4901)  loss_classifier: 0.1425 (0.1651)  loss_box_reg: 0.1107 (0.1427)  loss_objectness: 0.1124 (0.1304)  loss_rpn_box_reg: 0.0232 (0.0519)  time: 0.3482  data: 0.1416  max mem: 3969\n",
      "Training Epoch: [3]  [ 320/1229]  eta: 0:04:58  lr: 0.005000  loss: 0.4763 (0.4944)  loss_classifier: 0.1537 (0.1666)  loss_box_reg: 0.1347 (0.1445)  loss_objectness: 0.1123 (0.1310)  loss_rpn_box_reg: 0.0307 (0.0523)  time: 0.3319  data: 0.1451  max mem: 3969\n",
      "Training Epoch: [3]  [ 330/1229]  eta: 0:04:55  lr: 0.005000  loss: 0.5458 (0.4983)  loss_classifier: 0.2023 (0.1680)  loss_box_reg: 0.1591 (0.1463)  loss_objectness: 0.1305 (0.1313)  loss_rpn_box_reg: 0.0351 (0.0527)  time: 0.3354  data: 0.1470  max mem: 3969\n",
      "Training Epoch: [3]  [ 340/1229]  eta: 0:04:52  lr: 0.005000  loss: 0.5458 (0.5034)  loss_classifier: 0.1765 (0.1694)  loss_box_reg: 0.1557 (0.1473)  loss_objectness: 0.1443 (0.1319)  loss_rpn_box_reg: 0.0387 (0.0547)  time: 0.3388  data: 0.1455  max mem: 3969\n",
      "Training Epoch: [3]  [ 350/1229]  eta: 0:04:49  lr: 0.005000  loss: 0.5249 (0.5039)  loss_classifier: 0.1556 (0.1692)  loss_box_reg: 0.1452 (0.1474)  loss_objectness: 0.1478 (0.1319)  loss_rpn_box_reg: 0.0593 (0.0554)  time: 0.3337  data: 0.1435  max mem: 3969\n",
      "Training Epoch: [3]  [ 360/1229]  eta: 0:04:45  lr: 0.005000  loss: 0.4120 (0.5033)  loss_classifier: 0.1342 (0.1687)  loss_box_reg: 0.1157 (0.1473)  loss_objectness: 0.1112 (0.1319)  loss_rpn_box_reg: 0.0581 (0.0554)  time: 0.3273  data: 0.1424  max mem: 3969\n",
      "Training Epoch: [3]  [ 370/1229]  eta: 0:04:43  lr: 0.005000  loss: 0.4365 (0.5051)  loss_classifier: 0.1379 (0.1697)  loss_box_reg: 0.1325 (0.1482)  loss_objectness: 0.1273 (0.1322)  loss_rpn_box_reg: 0.0462 (0.0550)  time: 0.3420  data: 0.1456  max mem: 3969\n",
      "Training Epoch: [3]  [ 380/1229]  eta: 0:04:39  lr: 0.005000  loss: 0.4365 (0.5027)  loss_classifier: 0.1622 (0.1691)  loss_box_reg: 0.1250 (0.1474)  loss_objectness: 0.1119 (0.1313)  loss_rpn_box_reg: 0.0232 (0.0549)  time: 0.3405  data: 0.1438  max mem: 3969\n",
      "Training Epoch: [3]  [ 390/1229]  eta: 0:04:36  lr: 0.005000  loss: 0.4277 (0.5035)  loss_classifier: 0.1622 (0.1692)  loss_box_reg: 0.1159 (0.1472)  loss_objectness: 0.1023 (0.1318)  loss_rpn_box_reg: 0.0357 (0.0552)  time: 0.3298  data: 0.1391  max mem: 3969\n",
      "Training Epoch: [3]  [ 400/1229]  eta: 0:04:33  lr: 0.005000  loss: 0.3366 (0.4995)  loss_classifier: 0.1222 (0.1682)  loss_box_reg: 0.0922 (0.1457)  loss_objectness: 0.0927 (0.1311)  loss_rpn_box_reg: 0.0302 (0.0545)  time: 0.3269  data: 0.1375  max mem: 3969\n",
      "Training Epoch: [3]  [ 410/1229]  eta: 0:04:29  lr: 0.005000  loss: 0.3030 (0.4971)  loss_classifier: 0.1184 (0.1674)  loss_box_reg: 0.0863 (0.1448)  loss_objectness: 0.0927 (0.1304)  loss_rpn_box_reg: 0.0302 (0.0545)  time: 0.3248  data: 0.1388  max mem: 3969\n",
      "Training Epoch: [3]  [ 420/1229]  eta: 0:04:26  lr: 0.005000  loss: 0.3866 (0.4949)  loss_classifier: 0.1248 (0.1668)  loss_box_reg: 0.1018 (0.1444)  loss_objectness: 0.1017 (0.1298)  loss_rpn_box_reg: 0.0334 (0.0538)  time: 0.3275  data: 0.1416  max mem: 3969\n",
      "Training Epoch: [3]  [ 430/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.4965 (0.4962)  loss_classifier: 0.1592 (0.1673)  loss_box_reg: 0.1471 (0.1451)  loss_objectness: 0.1314 (0.1302)  loss_rpn_box_reg: 0.0252 (0.0535)  time: 0.3280  data: 0.1412  max mem: 3969\n",
      "Training Epoch: [3]  [ 440/1229]  eta: 0:04:19  lr: 0.005000  loss: 0.5510 (0.4998)  loss_classifier: 0.2088 (0.1682)  loss_box_reg: 0.1688 (0.1463)  loss_objectness: 0.1364 (0.1309)  loss_rpn_box_reg: 0.0285 (0.0544)  time: 0.3298  data: 0.1401  max mem: 3969\n",
      "Training Epoch: [3]  [ 450/1229]  eta: 0:04:16  lr: 0.005000  loss: 0.4537 (0.4990)  loss_classifier: 0.1994 (0.1681)  loss_box_reg: 0.1393 (0.1459)  loss_objectness: 0.1140 (0.1303)  loss_rpn_box_reg: 0.0305 (0.0547)  time: 0.3286  data: 0.1377  max mem: 3969\n",
      "Training Epoch: [3]  [ 460/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.3851 (0.4969)  loss_classifier: 0.1397 (0.1672)  loss_box_reg: 0.0949 (0.1448)  loss_objectness: 0.1140 (0.1301)  loss_rpn_box_reg: 0.0399 (0.0547)  time: 0.3278  data: 0.1384  max mem: 3969\n",
      "Training Epoch: [3]  [ 470/1229]  eta: 0:04:09  lr: 0.005000  loss: 0.4446 (0.4984)  loss_classifier: 0.1442 (0.1674)  loss_box_reg: 0.1055 (0.1447)  loss_objectness: 0.1375 (0.1309)  loss_rpn_box_reg: 0.0526 (0.0554)  time: 0.3301  data: 0.1428  max mem: 3969\n",
      "Training Epoch: [3]  [ 480/1229]  eta: 0:04:06  lr: 0.005000  loss: 0.4837 (0.4978)  loss_classifier: 0.1566 (0.1672)  loss_box_reg: 0.1420 (0.1446)  loss_objectness: 0.1421 (0.1304)  loss_rpn_box_reg: 0.0313 (0.0555)  time: 0.3262  data: 0.1434  max mem: 3969\n",
      "Training Epoch: [3]  [ 490/1229]  eta: 0:04:03  lr: 0.005000  loss: 0.4772 (0.4989)  loss_classifier: 0.1673 (0.1677)  loss_box_reg: 0.1022 (0.1442)  loss_objectness: 0.1421 (0.1313)  loss_rpn_box_reg: 0.0398 (0.0557)  time: 0.3204  data: 0.1399  max mem: 3969\n",
      "Training Epoch: [3]  [ 500/1229]  eta: 0:03:59  lr: 0.005000  loss: 0.4038 (0.4964)  loss_classifier: 0.1079 (0.1666)  loss_box_reg: 0.0653 (0.1429)  loss_objectness: 0.1656 (0.1317)  loss_rpn_box_reg: 0.0384 (0.0551)  time: 0.3162  data: 0.1382  max mem: 3969\n",
      "Training Epoch: [3]  [ 510/1229]  eta: 0:03:56  lr: 0.005000  loss: 0.2956 (0.4940)  loss_classifier: 0.0955 (0.1662)  loss_box_reg: 0.0684 (0.1419)  loss_objectness: 0.1218 (0.1312)  loss_rpn_box_reg: 0.0189 (0.0547)  time: 0.3237  data: 0.1388  max mem: 3969\n",
      "Training Epoch: [3]  [ 520/1229]  eta: 0:03:52  lr: 0.005000  loss: 0.4112 (0.4941)  loss_classifier: 0.1348 (0.1664)  loss_box_reg: 0.0872 (0.1423)  loss_objectness: 0.0932 (0.1310)  loss_rpn_box_reg: 0.0213 (0.0544)  time: 0.3241  data: 0.1358  max mem: 3969\n",
      "Training Epoch: [3]  [ 530/1229]  eta: 0:03:49  lr: 0.005000  loss: 0.4383 (0.4944)  loss_classifier: 0.1809 (0.1671)  loss_box_reg: 0.1208 (0.1424)  loss_objectness: 0.1095 (0.1310)  loss_rpn_box_reg: 0.0191 (0.0539)  time: 0.3252  data: 0.1365  max mem: 3969\n",
      "Training Epoch: [3]  [ 540/1229]  eta: 0:03:46  lr: 0.005000  loss: 0.3678 (0.4914)  loss_classifier: 0.1365 (0.1661)  loss_box_reg: 0.0868 (0.1413)  loss_objectness: 0.1122 (0.1306)  loss_rpn_box_reg: 0.0208 (0.0534)  time: 0.3225  data: 0.1376  max mem: 3969\n",
      "Training Epoch: [3]  [ 550/1229]  eta: 0:03:43  lr: 0.005000  loss: 0.3503 (0.4887)  loss_classifier: 0.1101 (0.1652)  loss_box_reg: 0.0777 (0.1405)  loss_objectness: 0.1045 (0.1297)  loss_rpn_box_reg: 0.0273 (0.0533)  time: 0.3231  data: 0.1360  max mem: 3969\n",
      "Training Epoch: [3]  [ 560/1229]  eta: 0:03:39  lr: 0.005000  loss: 0.4120 (0.4892)  loss_classifier: 0.1512 (0.1653)  loss_box_reg: 0.1176 (0.1407)  loss_objectness: 0.1034 (0.1299)  loss_rpn_box_reg: 0.0245 (0.0533)  time: 0.3242  data: 0.1365  max mem: 3969\n",
      "Training Epoch: [3]  [ 570/1229]  eta: 0:03:36  lr: 0.005000  loss: 0.4649 (0.4888)  loss_classifier: 0.1590 (0.1653)  loss_box_reg: 0.1324 (0.1409)  loss_objectness: 0.1132 (0.1294)  loss_rpn_box_reg: 0.0245 (0.0532)  time: 0.3174  data: 0.1357  max mem: 3969\n",
      "Training Epoch: [3]  [ 580/1229]  eta: 0:03:32  lr: 0.005000  loss: 0.4907 (0.4895)  loss_classifier: 0.1630 (0.1653)  loss_box_reg: 0.1414 (0.1410)  loss_objectness: 0.1132 (0.1293)  loss_rpn_box_reg: 0.0302 (0.0539)  time: 0.3214  data: 0.1325  max mem: 3969\n",
      "Training Epoch: [3]  [ 590/1229]  eta: 0:03:29  lr: 0.005000  loss: 0.4678 (0.4896)  loss_classifier: 0.1630 (0.1653)  loss_box_reg: 0.1402 (0.1410)  loss_objectness: 0.1249 (0.1295)  loss_rpn_box_reg: 0.0257 (0.0538)  time: 0.3172  data: 0.1329  max mem: 3969\n",
      "Training Epoch: [3]  [ 600/1229]  eta: 0:03:25  lr: 0.005000  loss: 0.4678 (0.4903)  loss_classifier: 0.1652 (0.1657)  loss_box_reg: 0.1559 (0.1415)  loss_objectness: 0.1160 (0.1297)  loss_rpn_box_reg: 0.0348 (0.0535)  time: 0.3116  data: 0.1366  max mem: 3969\n",
      "Training Epoch: [3]  [ 610/1229]  eta: 0:03:22  lr: 0.005000  loss: 0.4835 (0.4914)  loss_classifier: 0.1552 (0.1659)  loss_box_reg: 0.1130 (0.1419)  loss_objectness: 0.1271 (0.1301)  loss_rpn_box_reg: 0.0349 (0.0535)  time: 0.3133  data: 0.1365  max mem: 3969\n",
      "Training Epoch: [3]  [ 620/1229]  eta: 0:03:19  lr: 0.005000  loss: 0.4767 (0.4927)  loss_classifier: 0.1447 (0.1663)  loss_box_reg: 0.1105 (0.1427)  loss_objectness: 0.1260 (0.1299)  loss_rpn_box_reg: 0.0286 (0.0538)  time: 0.3141  data: 0.1355  max mem: 3969\n",
      "Training Epoch: [3]  [ 630/1229]  eta: 0:03:15  lr: 0.005000  loss: 0.5195 (0.4936)  loss_classifier: 0.1770 (0.1667)  loss_box_reg: 0.1362 (0.1430)  loss_objectness: 0.1260 (0.1301)  loss_rpn_box_reg: 0.0362 (0.0538)  time: 0.3167  data: 0.1357  max mem: 3969\n",
      "Training Epoch: [3]  [ 640/1229]  eta: 0:03:12  lr: 0.005000  loss: 0.4542 (0.4944)  loss_classifier: 0.1612 (0.1668)  loss_box_reg: 0.1482 (0.1428)  loss_objectness: 0.1179 (0.1305)  loss_rpn_box_reg: 0.0377 (0.0543)  time: 0.3165  data: 0.1354  max mem: 3969\n",
      "Training Epoch: [3]  [ 650/1229]  eta: 0:03:09  lr: 0.005000  loss: 0.3612 (0.4939)  loss_classifier: 0.1325 (0.1666)  loss_box_reg: 0.1150 (0.1431)  loss_objectness: 0.1103 (0.1302)  loss_rpn_box_reg: 0.0372 (0.0540)  time: 0.3159  data: 0.1362  max mem: 3969\n",
      "Training Epoch: [3]  [ 660/1229]  eta: 0:03:05  lr: 0.005000  loss: 0.3500 (0.4941)  loss_classifier: 0.1325 (0.1666)  loss_box_reg: 0.1150 (0.1429)  loss_objectness: 0.0927 (0.1301)  loss_rpn_box_reg: 0.0305 (0.0544)  time: 0.3316  data: 0.1391  max mem: 3969\n",
      "Training Epoch: [3]  [ 670/1229]  eta: 0:03:02  lr: 0.005000  loss: 0.3573 (0.4930)  loss_classifier: 0.1286 (0.1664)  loss_box_reg: 0.0962 (0.1427)  loss_objectness: 0.0927 (0.1297)  loss_rpn_box_reg: 0.0290 (0.0541)  time: 0.3334  data: 0.1418  max mem: 3969\n",
      "Training Epoch: [3]  [ 680/1229]  eta: 0:02:59  lr: 0.005000  loss: 0.4043 (0.4931)  loss_classifier: 0.1457 (0.1665)  loss_box_reg: 0.0968 (0.1430)  loss_objectness: 0.0891 (0.1296)  loss_rpn_box_reg: 0.0257 (0.0539)  time: 0.3253  data: 0.1430  max mem: 3969\n",
      "Training Epoch: [3]  [ 690/1229]  eta: 0:02:56  lr: 0.005000  loss: 0.4587 (0.4936)  loss_classifier: 0.1731 (0.1667)  loss_box_reg: 0.1243 (0.1430)  loss_objectness: 0.1119 (0.1296)  loss_rpn_box_reg: 0.0319 (0.0542)  time: 0.3316  data: 0.1436  max mem: 3969\n",
      "Training Epoch: [3]  [ 700/1229]  eta: 0:02:52  lr: 0.005000  loss: 0.4834 (0.4939)  loss_classifier: 0.1812 (0.1668)  loss_box_reg: 0.1429 (0.1429)  loss_objectness: 0.1320 (0.1299)  loss_rpn_box_reg: 0.0499 (0.0544)  time: 0.3305  data: 0.1420  max mem: 3969\n",
      "Training Epoch: [3]  [ 710/1229]  eta: 0:02:49  lr: 0.005000  loss: 0.4859 (0.4932)  loss_classifier: 0.1582 (0.1666)  loss_box_reg: 0.1301 (0.1426)  loss_objectness: 0.1228 (0.1299)  loss_rpn_box_reg: 0.0384 (0.0541)  time: 0.3242  data: 0.1410  max mem: 3969\n",
      "Training Epoch: [3]  [ 720/1229]  eta: 0:02:46  lr: 0.005000  loss: 0.4491 (0.4930)  loss_classifier: 0.1579 (0.1665)  loss_box_reg: 0.1071 (0.1426)  loss_objectness: 0.1244 (0.1301)  loss_rpn_box_reg: 0.0374 (0.0538)  time: 0.3263  data: 0.1413  max mem: 3969\n",
      "Training Epoch: [3]  [ 730/1229]  eta: 0:02:43  lr: 0.005000  loss: 0.5051 (0.4940)  loss_classifier: 0.1726 (0.1671)  loss_box_reg: 0.1125 (0.1428)  loss_objectness: 0.1395 (0.1304)  loss_rpn_box_reg: 0.0336 (0.0536)  time: 0.3282  data: 0.1385  max mem: 3969\n",
      "Training Epoch: [3]  [ 740/1229]  eta: 0:02:39  lr: 0.005000  loss: 0.4935 (0.4935)  loss_classifier: 0.1720 (0.1670)  loss_box_reg: 0.1484 (0.1429)  loss_objectness: 0.1215 (0.1303)  loss_rpn_box_reg: 0.0299 (0.0533)  time: 0.3262  data: 0.1384  max mem: 3969\n",
      "Training Epoch: [3]  [ 750/1229]  eta: 0:02:36  lr: 0.005000  loss: 0.4568 (0.4932)  loss_classifier: 0.1382 (0.1669)  loss_box_reg: 0.1318 (0.1429)  loss_objectness: 0.1100 (0.1301)  loss_rpn_box_reg: 0.0246 (0.0532)  time: 0.3232  data: 0.1420  max mem: 3969\n",
      "Training Epoch: [3]  [ 760/1229]  eta: 0:02:33  lr: 0.005000  loss: 0.4639 (0.4938)  loss_classifier: 0.1673 (0.1672)  loss_box_reg: 0.1445 (0.1436)  loss_objectness: 0.1101 (0.1299)  loss_rpn_box_reg: 0.0318 (0.0531)  time: 0.3218  data: 0.1435  max mem: 3969\n",
      "Training Epoch: [3]  [ 770/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.3942 (0.4924)  loss_classifier: 0.1206 (0.1668)  loss_box_reg: 0.1087 (0.1429)  loss_objectness: 0.1101 (0.1298)  loss_rpn_box_reg: 0.0285 (0.0529)  time: 0.3205  data: 0.1422  max mem: 3969\n",
      "Training Epoch: [3]  [ 780/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.4031 (0.4922)  loss_classifier: 0.1557 (0.1670)  loss_box_reg: 0.0726 (0.1429)  loss_objectness: 0.0922 (0.1296)  loss_rpn_box_reg: 0.0286 (0.0527)  time: 0.3244  data: 0.1423  max mem: 3969\n",
      "Training Epoch: [3]  [ 790/1229]  eta: 0:02:23  lr: 0.005000  loss: 0.4720 (0.4933)  loss_classifier: 0.1635 (0.1669)  loss_box_reg: 0.1367 (0.1428)  loss_objectness: 0.0922 (0.1301)  loss_rpn_box_reg: 0.0359 (0.0534)  time: 0.3245  data: 0.1397  max mem: 3969\n",
      "Training Epoch: [3]  [ 800/1229]  eta: 0:02:20  lr: 0.005000  loss: 0.4355 (0.4934)  loss_classifier: 0.1438 (0.1670)  loss_box_reg: 0.1145 (0.1428)  loss_objectness: 0.1282 (0.1302)  loss_rpn_box_reg: 0.0330 (0.0535)  time: 0.3191  data: 0.1388  max mem: 3969\n",
      "Training Epoch: [3]  [ 810/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.5095 (0.4947)  loss_classifier: 0.1813 (0.1674)  loss_box_reg: 0.1262 (0.1433)  loss_objectness: 0.1282 (0.1305)  loss_rpn_box_reg: 0.0330 (0.0535)  time: 0.3209  data: 0.1421  max mem: 3969\n",
      "Training Epoch: [3]  [ 820/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.5136 (0.4944)  loss_classifier: 0.1813 (0.1672)  loss_box_reg: 0.1391 (0.1429)  loss_objectness: 0.1366 (0.1307)  loss_rpn_box_reg: 0.0333 (0.0536)  time: 0.3277  data: 0.1417  max mem: 3969\n",
      "Training Epoch: [3]  [ 830/1229]  eta: 0:02:10  lr: 0.005000  loss: 0.4390 (0.4937)  loss_classifier: 0.1528 (0.1670)  loss_box_reg: 0.1138 (0.1427)  loss_objectness: 0.1035 (0.1306)  loss_rpn_box_reg: 0.0304 (0.0534)  time: 0.3342  data: 0.1402  max mem: 3969\n",
      "Training Epoch: [3]  [ 840/1229]  eta: 0:02:07  lr: 0.005000  loss: 0.3846 (0.4938)  loss_classifier: 0.1528 (0.1673)  loss_box_reg: 0.1187 (0.1427)  loss_objectness: 0.0993 (0.1306)  loss_rpn_box_reg: 0.0279 (0.0532)  time: 0.3307  data: 0.1419  max mem: 3969\n",
      "Training Epoch: [3]  [ 850/1229]  eta: 0:02:03  lr: 0.005000  loss: 0.4004 (0.4927)  loss_classifier: 0.1541 (0.1670)  loss_box_reg: 0.1187 (0.1425)  loss_objectness: 0.0950 (0.1302)  loss_rpn_box_reg: 0.0190 (0.0530)  time: 0.3289  data: 0.1407  max mem: 3969\n",
      "Training Epoch: [3]  [ 860/1229]  eta: 0:02:00  lr: 0.005000  loss: 0.4249 (0.4928)  loss_classifier: 0.1522 (0.1671)  loss_box_reg: 0.0925 (0.1423)  loss_objectness: 0.1212 (0.1305)  loss_rpn_box_reg: 0.0238 (0.0530)  time: 0.3283  data: 0.1378  max mem: 3969\n",
      "Training Epoch: [3]  [ 870/1229]  eta: 0:01:57  lr: 0.005000  loss: 0.4225 (0.4916)  loss_classifier: 0.1334 (0.1666)  loss_box_reg: 0.0925 (0.1418)  loss_objectness: 0.1225 (0.1303)  loss_rpn_box_reg: 0.0385 (0.0529)  time: 0.3209  data: 0.1365  max mem: 3969\n",
      "Training Epoch: [3]  [ 880/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.4244 (0.4922)  loss_classifier: 0.1401 (0.1669)  loss_box_reg: 0.1114 (0.1421)  loss_objectness: 0.1209 (0.1303)  loss_rpn_box_reg: 0.0365 (0.0529)  time: 0.3233  data: 0.1379  max mem: 3969\n",
      "Training Epoch: [3]  [ 890/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.4763 (0.4925)  loss_classifier: 0.1786 (0.1671)  loss_box_reg: 0.1595 (0.1423)  loss_objectness: 0.1327 (0.1303)  loss_rpn_box_reg: 0.0352 (0.0527)  time: 0.3319  data: 0.1436  max mem: 3969\n",
      "Training Epoch: [3]  [ 900/1229]  eta: 0:01:47  lr: 0.005000  loss: 0.5435 (0.4943)  loss_classifier: 0.1824 (0.1676)  loss_box_reg: 0.1531 (0.1427)  loss_objectness: 0.1332 (0.1311)  loss_rpn_box_reg: 0.0397 (0.0530)  time: 0.3330  data: 0.1428  max mem: 3969\n",
      "Training Epoch: [3]  [ 910/1229]  eta: 0:01:44  lr: 0.005000  loss: 0.5813 (0.4946)  loss_classifier: 0.1754 (0.1676)  loss_box_reg: 0.1477 (0.1429)  loss_objectness: 0.1322 (0.1310)  loss_rpn_box_reg: 0.0437 (0.0531)  time: 0.3241  data: 0.1386  max mem: 3969\n",
      "Training Epoch: [3]  [ 920/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.5299 (0.4957)  loss_classifier: 0.1894 (0.1681)  loss_box_reg: 0.1477 (0.1432)  loss_objectness: 0.1195 (0.1311)  loss_rpn_box_reg: 0.0537 (0.0533)  time: 0.3251  data: 0.1390  max mem: 3969\n",
      "Training Epoch: [3]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.5965 (0.4973)  loss_classifier: 0.2144 (0.1685)  loss_box_reg: 0.1857 (0.1440)  loss_objectness: 0.1314 (0.1313)  loss_rpn_box_reg: 0.0550 (0.0535)  time: 0.3253  data: 0.1410  max mem: 3969\n",
      "Training Epoch: [3]  [ 940/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.5657 (0.4970)  loss_classifier: 0.1815 (0.1685)  loss_box_reg: 0.1857 (0.1440)  loss_objectness: 0.1224 (0.1310)  loss_rpn_box_reg: 0.0326 (0.0535)  time: 0.3203  data: 0.1411  max mem: 3969\n",
      "Training Epoch: [3]  [ 950/1229]  eta: 0:01:31  lr: 0.005000  loss: 0.5205 (0.4982)  loss_classifier: 0.1875 (0.1690)  loss_box_reg: 0.1609 (0.1445)  loss_objectness: 0.1190 (0.1313)  loss_rpn_box_reg: 0.0312 (0.0533)  time: 0.3235  data: 0.1415  max mem: 3969\n",
      "Training Epoch: [3]  [ 960/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.5517 (0.4989)  loss_classifier: 0.1814 (0.1691)  loss_box_reg: 0.1609 (0.1449)  loss_objectness: 0.1423 (0.1314)  loss_rpn_box_reg: 0.0341 (0.0536)  time: 0.3235  data: 0.1411  max mem: 3969\n",
      "Training Epoch: [3]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.5045 (0.4998)  loss_classifier: 0.1628 (0.1693)  loss_box_reg: 0.1227 (0.1449)  loss_objectness: 0.1226 (0.1317)  loss_rpn_box_reg: 0.0275 (0.0539)  time: 0.3237  data: 0.1417  max mem: 3969\n",
      "Training Epoch: [3]  [ 980/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.4260 (0.4993)  loss_classifier: 0.1628 (0.1693)  loss_box_reg: 0.1145 (0.1446)  loss_objectness: 0.1184 (0.1317)  loss_rpn_box_reg: 0.0275 (0.0537)  time: 0.3240  data: 0.1422  max mem: 3969\n",
      "Training Epoch: [3]  [ 990/1229]  eta: 0:01:17  lr: 0.005000  loss: 0.4559 (0.4996)  loss_classifier: 0.1564 (0.1693)  loss_box_reg: 0.1200 (0.1446)  loss_objectness: 0.1145 (0.1318)  loss_rpn_box_reg: 0.0295 (0.0539)  time: 0.3196  data: 0.1398  max mem: 3969\n",
      "Training Epoch: [3]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.4420 (0.4998)  loss_classifier: 0.1562 (0.1694)  loss_box_reg: 0.1240 (0.1448)  loss_objectness: 0.1088 (0.1317)  loss_rpn_box_reg: 0.0277 (0.0540)  time: 0.3194  data: 0.1400  max mem: 3969\n",
      "Training Epoch: [3]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.4198 (0.4993)  loss_classifier: 0.1562 (0.1693)  loss_box_reg: 0.1284 (0.1448)  loss_objectness: 0.0954 (0.1313)  loss_rpn_box_reg: 0.0277 (0.0538)  time: 0.3249  data: 0.1396  max mem: 3969\n",
      "Training Epoch: [3]  [1020/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.4198 (0.4987)  loss_classifier: 0.1669 (0.1693)  loss_box_reg: 0.1402 (0.1447)  loss_objectness: 0.0897 (0.1310)  loss_rpn_box_reg: 0.0326 (0.0537)  time: 0.3263  data: 0.1386  max mem: 3969\n",
      "Training Epoch: [3]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.4035 (0.4984)  loss_classifier: 0.1523 (0.1692)  loss_box_reg: 0.1431 (0.1447)  loss_objectness: 0.0897 (0.1309)  loss_rpn_box_reg: 0.0310 (0.0537)  time: 0.3287  data: 0.1398  max mem: 3969\n",
      "Training Epoch: [3]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.3734 (0.4976)  loss_classifier: 0.1440 (0.1690)  loss_box_reg: 0.1045 (0.1444)  loss_objectness: 0.0920 (0.1307)  loss_rpn_box_reg: 0.0231 (0.0535)  time: 0.3256  data: 0.1410  max mem: 3969\n",
      "Training Epoch: [3]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.4243 (0.4983)  loss_classifier: 0.1489 (0.1692)  loss_box_reg: 0.1167 (0.1448)  loss_objectness: 0.1272 (0.1308)  loss_rpn_box_reg: 0.0273 (0.0535)  time: 0.3219  data: 0.1408  max mem: 3969\n",
      "Training Epoch: [3]  [1060/1229]  eta: 0:00:55  lr: 0.005000  loss: 0.5926 (0.4993)  loss_classifier: 0.1656 (0.1697)  loss_box_reg: 0.1676 (0.1452)  loss_objectness: 0.1381 (0.1310)  loss_rpn_box_reg: 0.0359 (0.0534)  time: 0.3240  data: 0.1404  max mem: 3969\n",
      "Training Epoch: [3]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.4200 (0.4985)  loss_classifier: 0.1277 (0.1694)  loss_box_reg: 0.1185 (0.1450)  loss_objectness: 0.1066 (0.1308)  loss_rpn_box_reg: 0.0265 (0.0533)  time: 0.3316  data: 0.1398  max mem: 3969\n",
      "Training Epoch: [3]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.4399 (0.4987)  loss_classifier: 0.1544 (0.1696)  loss_box_reg: 0.1560 (0.1453)  loss_objectness: 0.0992 (0.1306)  loss_rpn_box_reg: 0.0254 (0.0531)  time: 0.3280  data: 0.1390  max mem: 3969\n",
      "Training Epoch: [3]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.4797 (0.4988)  loss_classifier: 0.1706 (0.1697)  loss_box_reg: 0.1578 (0.1455)  loss_objectness: 0.0993 (0.1306)  loss_rpn_box_reg: 0.0248 (0.0530)  time: 0.3177  data: 0.1402  max mem: 3969\n",
      "Training Epoch: [3]  [1100/1229]  eta: 0:00:42  lr: 0.005000  loss: 0.3590 (0.4980)  loss_classifier: 0.1305 (0.1694)  loss_box_reg: 0.0996 (0.1453)  loss_objectness: 0.1010 (0.1303)  loss_rpn_box_reg: 0.0244 (0.0530)  time: 0.3196  data: 0.1418  max mem: 3969\n",
      "Training Epoch: [3]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.3522 (0.4975)  loss_classifier: 0.1162 (0.1692)  loss_box_reg: 0.0797 (0.1451)  loss_objectness: 0.1054 (0.1302)  loss_rpn_box_reg: 0.0307 (0.0529)  time: 0.3239  data: 0.1409  max mem: 3969\n",
      "Training Epoch: [3]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4126 (0.4969)  loss_classifier: 0.1162 (0.1690)  loss_box_reg: 0.0882 (0.1449)  loss_objectness: 0.1291 (0.1303)  loss_rpn_box_reg: 0.0346 (0.0528)  time: 0.3212  data: 0.1377  max mem: 3969\n",
      "Training Epoch: [3]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.4217 (0.4963)  loss_classifier: 0.1313 (0.1688)  loss_box_reg: 0.0969 (0.1447)  loss_objectness: 0.1100 (0.1300)  loss_rpn_box_reg: 0.0275 (0.0528)  time: 0.3236  data: 0.1413  max mem: 3969\n",
      "Training Epoch: [3]  [1140/1229]  eta: 0:00:29  lr: 0.005000  loss: 0.4232 (0.4964)  loss_classifier: 0.1552 (0.1689)  loss_box_reg: 0.1229 (0.1450)  loss_objectness: 0.0996 (0.1300)  loss_rpn_box_reg: 0.0191 (0.0525)  time: 0.3235  data: 0.1429  max mem: 3969\n",
      "Training Epoch: [3]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.4772 (0.4964)  loss_classifier: 0.1707 (0.1690)  loss_box_reg: 0.1687 (0.1451)  loss_objectness: 0.0996 (0.1298)  loss_rpn_box_reg: 0.0251 (0.0524)  time: 0.3202  data: 0.1389  max mem: 3969\n",
      "Training Epoch: [3]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.4311 (0.4964)  loss_classifier: 0.1656 (0.1689)  loss_box_reg: 0.1599 (0.1452)  loss_objectness: 0.0861 (0.1299)  loss_rpn_box_reg: 0.0261 (0.0524)  time: 0.3249  data: 0.1379  max mem: 3969\n",
      "Training Epoch: [3]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.4311 (0.4966)  loss_classifier: 0.1594 (0.1690)  loss_box_reg: 0.0889 (0.1450)  loss_objectness: 0.1339 (0.1303)  loss_rpn_box_reg: 0.0347 (0.0524)  time: 0.3290  data: 0.1398  max mem: 3969\n",
      "Training Epoch: [3]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.4174 (0.4965)  loss_classifier: 0.1594 (0.1691)  loss_box_reg: 0.0889 (0.1452)  loss_objectness: 0.1016 (0.1300)  loss_rpn_box_reg: 0.0331 (0.0523)  time: 0.3304  data: 0.1421  max mem: 3969\n",
      "Training Epoch: [3]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.4972 (0.4978)  loss_classifier: 0.1821 (0.1696)  loss_box_reg: 0.1423 (0.1457)  loss_objectness: 0.1116 (0.1303)  loss_rpn_box_reg: 0.0264 (0.0522)  time: 0.3308  data: 0.1434  max mem: 3969\n",
      "Training Epoch: [3]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.5051 (0.4977)  loss_classifier: 0.1892 (0.1696)  loss_box_reg: 0.1278 (0.1458)  loss_objectness: 0.1437 (0.1302)  loss_rpn_box_reg: 0.0264 (0.0521)  time: 0.3257  data: 0.1418  max mem: 3969\n",
      "Training Epoch: [3]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.3358 (0.4971)  loss_classifier: 0.1121 (0.1695)  loss_box_reg: 0.0878 (0.1456)  loss_objectness: 0.1109 (0.1301)  loss_rpn_box_reg: 0.0257 (0.0520)  time: 0.3202  data: 0.1376  max mem: 3969\n",
      "Training Epoch: [3]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.3781 (0.4970)  loss_classifier: 0.1328 (0.1695)  loss_box_reg: 0.0965 (0.1455)  loss_objectness: 0.1106 (0.1301)  loss_rpn_box_reg: 0.0288 (0.0519)  time: 0.3224  data: 0.1414  max mem: 3969\n",
      "Training Epoch: [3]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4691 (0.4971)  loss_classifier: 0.1505 (0.1694)  loss_box_reg: 0.1189 (0.1456)  loss_objectness: 0.1109 (0.1301)  loss_rpn_box_reg: 0.0341 (0.0520)  time: 0.3288  data: 0.1421  max mem: 3969\n",
      "Training Epoch: [3] Total time: 0:06:40 (0.3262 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:06:24  model_time: 0.3710 (0.3710)  evaluator_time: 0.0020 (0.0020)  time: 1.2490  data: 0.0300  max mem: 3969\n",
      "Test:  [100/308]  eta: 0:00:35  model_time: 0.1060 (0.1126)  evaluator_time: 0.0060 (0.0088)  time: 0.1660  data: 0.0444  max mem: 3969\n",
      "Test:  [200/308]  eta: 0:00:17  model_time: 0.1150 (0.1116)  evaluator_time: 0.0030 (0.0079)  time: 0.1611  data: 0.0387  max mem: 3969\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.1030 (0.1113)  evaluator_time: 0.0040 (0.0078)  time: 0.1647  data: 0.0476  max mem: 3969\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.1030 (0.1112)  evaluator_time: 0.0030 (0.0078)  time: 0.1576  data: 0.0445  max mem: 3969\n",
      "Test: Total time: 0:00:49 (0.1619 s / it)\n",
      "Averaged stats: model_time: 0.1030 (0.1112)  evaluator_time: 0.0030 (0.0078)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.17s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.020\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.127\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.220\n",
      "Testing Epoch: [3]  [  0/308]  eta: 0:00:48  lr: 0.005000  loss: 0.1792 (0.1792)  loss_classifier: 0.0575 (0.0575)  loss_box_reg: 0.0550 (0.0550)  loss_objectness: 0.0473 (0.0473)  loss_rpn_box_reg: 0.0193 (0.0193)  time: 0.1580  data: 0.0300  max mem: 3969\n",
      "Testing Epoch: [3]  [100/308]  eta: 0:00:37  lr: 0.005000  loss: 0.3377 (0.5161)  loss_classifier: 0.1292 (0.1675)  loss_box_reg: 0.1171 (0.1665)  loss_objectness: 0.0773 (0.1185)  loss_rpn_box_reg: 0.0226 (0.0636)  time: 0.1826  data: 0.0466  max mem: 3969\n",
      "Testing Epoch: [3]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.4148 (0.4898)  loss_classifier: 0.1328 (0.1593)  loss_box_reg: 0.1413 (0.1582)  loss_objectness: 0.0923 (0.1125)  loss_rpn_box_reg: 0.0283 (0.0598)  time: 0.1782  data: 0.0361  max mem: 3969\n",
      "Testing Epoch: [3]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5462 (0.4895)  loss_classifier: 0.1773 (0.1602)  loss_box_reg: 0.1671 (0.1617)  loss_objectness: 0.1000 (0.1095)  loss_rpn_box_reg: 0.0405 (0.0581)  time: 0.1751  data: 0.0463  max mem: 3973\n",
      "Testing Epoch: [3]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.5462 (0.4895)  loss_classifier: 0.1773 (0.1606)  loss_box_reg: 0.1694 (0.1619)  loss_objectness: 0.1000 (0.1094)  loss_rpn_box_reg: 0.0405 (0.0575)  time: 0.1725  data: 0.0438  max mem: 3973\n",
      "Testing Epoch: [3] Total time: 0:00:54 (0.1769 s / it)\n",
      "Training Epoch: [4]  [   0/1229]  eta: 0:06:39  lr: 0.005000  loss: 0.5490 (0.5490)  loss_classifier: 0.2293 (0.2293)  loss_box_reg: 0.1558 (0.1558)  loss_objectness: 0.1307 (0.1307)  loss_rpn_box_reg: 0.0333 (0.0333)  time: 0.3250  data: 0.1480  max mem: 3973\n",
      "Training Epoch: [4]  [  10/1229]  eta: 0:06:48  lr: 0.005000  loss: 0.4630 (0.5008)  loss_classifier: 0.1737 (0.1630)  loss_box_reg: 0.1384 (0.1185)  loss_objectness: 0.1307 (0.1453)  loss_rpn_box_reg: 0.0333 (0.0740)  time: 0.3355  data: 0.1483  max mem: 3973\n",
      "Training Epoch: [4]  [  20/1229]  eta: 0:06:48  lr: 0.005000  loss: 0.4491 (0.4723)  loss_classifier: 0.1450 (0.1582)  loss_box_reg: 0.0942 (0.1169)  loss_objectness: 0.1123 (0.1328)  loss_rpn_box_reg: 0.0322 (0.0644)  time: 0.3383  data: 0.1519  max mem: 3973\n",
      "Training Epoch: [4]  [  30/1229]  eta: 0:06:46  lr: 0.005000  loss: 0.4882 (0.4842)  loss_classifier: 0.1542 (0.1605)  loss_box_reg: 0.1220 (0.1390)  loss_objectness: 0.1007 (0.1228)  loss_rpn_box_reg: 0.0351 (0.0619)  time: 0.3412  data: 0.1544  max mem: 3973\n",
      "Training Epoch: [4]  [  40/1229]  eta: 0:06:41  lr: 0.005000  loss: 0.4651 (0.4836)  loss_classifier: 0.1542 (0.1632)  loss_box_reg: 0.1430 (0.1357)  loss_objectness: 0.1126 (0.1290)  loss_rpn_box_reg: 0.0299 (0.0557)  time: 0.3376  data: 0.1534  max mem: 3973\n",
      "Training Epoch: [4]  [  50/1229]  eta: 0:06:39  lr: 0.005000  loss: 0.5186 (0.5027)  loss_classifier: 0.1611 (0.1673)  loss_box_reg: 0.1430 (0.1450)  loss_objectness: 0.1297 (0.1315)  loss_rpn_box_reg: 0.0350 (0.0590)  time: 0.3386  data: 0.1520  max mem: 3973\n",
      "Training Epoch: [4]  [  60/1229]  eta: 0:06:35  lr: 0.005000  loss: 0.5222 (0.5069)  loss_classifier: 0.1838 (0.1690)  loss_box_reg: 0.1509 (0.1447)  loss_objectness: 0.1222 (0.1325)  loss_rpn_box_reg: 0.0334 (0.0608)  time: 0.3401  data: 0.1510  max mem: 3973\n",
      "Training Epoch: [4]  [  70/1229]  eta: 0:06:30  lr: 0.005000  loss: 0.4560 (0.5023)  loss_classifier: 0.1708 (0.1683)  loss_box_reg: 0.1506 (0.1491)  loss_objectness: 0.1093 (0.1295)  loss_rpn_box_reg: 0.0202 (0.0554)  time: 0.3332  data: 0.1518  max mem: 3973\n",
      "Training Epoch: [4]  [  80/1229]  eta: 0:06:29  lr: 0.005000  loss: 0.5109 (0.5163)  loss_classifier: 0.1708 (0.1747)  loss_box_reg: 0.1757 (0.1550)  loss_objectness: 0.1256 (0.1296)  loss_rpn_box_reg: 0.0260 (0.0571)  time: 0.3396  data: 0.1536  max mem: 3973\n",
      "Training Epoch: [4]  [  90/1229]  eta: 0:06:27  lr: 0.005000  loss: 0.4316 (0.5134)  loss_classifier: 0.1629 (0.1749)  loss_box_reg: 0.1757 (0.1540)  loss_objectness: 0.1207 (0.1269)  loss_rpn_box_reg: 0.0365 (0.0576)  time: 0.3487  data: 0.1548  max mem: 3973\n",
      "Training Epoch: [4]  [ 100/1229]  eta: 0:06:23  lr: 0.005000  loss: 0.3801 (0.5102)  loss_classifier: 0.1406 (0.1760)  loss_box_reg: 0.1160 (0.1557)  loss_objectness: 0.0863 (0.1246)  loss_rpn_box_reg: 0.0278 (0.0539)  time: 0.3443  data: 0.1514  max mem: 3973\n",
      "Training Epoch: [4]  [ 110/1229]  eta: 0:06:18  lr: 0.005000  loss: 0.2890 (0.4995)  loss_classifier: 0.0907 (0.1714)  loss_box_reg: 0.0909 (0.1523)  loss_objectness: 0.0805 (0.1229)  loss_rpn_box_reg: 0.0144 (0.0529)  time: 0.3334  data: 0.1457  max mem: 3973\n",
      "Training Epoch: [4]  [ 120/1229]  eta: 0:06:15  lr: 0.005000  loss: 0.3844 (0.4998)  loss_classifier: 0.1469 (0.1713)  loss_box_reg: 0.1172 (0.1520)  loss_objectness: 0.0805 (0.1222)  loss_rpn_box_reg: 0.0253 (0.0542)  time: 0.3333  data: 0.1451  max mem: 3973\n",
      "Training Epoch: [4]  [ 130/1229]  eta: 0:06:11  lr: 0.005000  loss: 0.3708 (0.4864)  loss_classifier: 0.1272 (0.1672)  loss_box_reg: 0.1187 (0.1491)  loss_objectness: 0.0786 (0.1186)  loss_rpn_box_reg: 0.0198 (0.0515)  time: 0.3362  data: 0.1440  max mem: 3973\n",
      "Training Epoch: [4]  [ 140/1229]  eta: 0:06:06  lr: 0.005000  loss: 0.2994 (0.4812)  loss_classifier: 0.1151 (0.1652)  loss_box_reg: 0.0968 (0.1479)  loss_objectness: 0.0635 (0.1165)  loss_rpn_box_reg: 0.0150 (0.0517)  time: 0.3258  data: 0.1419  max mem: 3973\n",
      "Training Epoch: [4]  [ 150/1229]  eta: 0:06:02  lr: 0.005000  loss: 0.4630 (0.4851)  loss_classifier: 0.1341 (0.1648)  loss_box_reg: 0.1004 (0.1467)  loss_objectness: 0.1104 (0.1197)  loss_rpn_box_reg: 0.0203 (0.0539)  time: 0.3239  data: 0.1421  max mem: 3973\n",
      "Training Epoch: [4]  [ 160/1229]  eta: 0:05:58  lr: 0.005000  loss: 0.4308 (0.4823)  loss_classifier: 0.1341 (0.1640)  loss_box_reg: 0.1000 (0.1463)  loss_objectness: 0.1173 (0.1190)  loss_rpn_box_reg: 0.0242 (0.0530)  time: 0.3236  data: 0.1415  max mem: 3973\n",
      "Training Epoch: [4]  [ 170/1229]  eta: 0:05:54  lr: 0.005000  loss: 0.4554 (0.4844)  loss_classifier: 0.1579 (0.1652)  loss_box_reg: 0.1427 (0.1466)  loss_objectness: 0.1173 (0.1204)  loss_rpn_box_reg: 0.0264 (0.0522)  time: 0.3222  data: 0.1420  max mem: 3973\n",
      "Training Epoch: [4]  [ 180/1229]  eta: 0:05:51  lr: 0.005000  loss: 0.4554 (0.4840)  loss_classifier: 0.1579 (0.1642)  loss_box_reg: 0.1347 (0.1459)  loss_objectness: 0.1065 (0.1204)  loss_rpn_box_reg: 0.0292 (0.0534)  time: 0.3313  data: 0.1420  max mem: 3973\n",
      "Training Epoch: [4]  [ 190/1229]  eta: 0:05:47  lr: 0.005000  loss: 0.3788 (0.4829)  loss_classifier: 0.1369 (0.1639)  loss_box_reg: 0.0959 (0.1440)  loss_objectness: 0.1243 (0.1210)  loss_rpn_box_reg: 0.0292 (0.0540)  time: 0.3331  data: 0.1413  max mem: 3973\n",
      "Training Epoch: [4]  [ 200/1229]  eta: 0:05:43  lr: 0.005000  loss: 0.3788 (0.4790)  loss_classifier: 0.1300 (0.1627)  loss_box_reg: 0.0748 (0.1416)  loss_objectness: 0.1316 (0.1218)  loss_rpn_box_reg: 0.0240 (0.0528)  time: 0.3264  data: 0.1431  max mem: 3973\n",
      "Training Epoch: [4]  [ 210/1229]  eta: 0:05:40  lr: 0.005000  loss: 0.3244 (0.4748)  loss_classifier: 0.1053 (0.1609)  loss_box_reg: 0.0844 (0.1400)  loss_objectness: 0.1409 (0.1223)  loss_rpn_box_reg: 0.0285 (0.0516)  time: 0.3252  data: 0.1452  max mem: 3973\n",
      "Training Epoch: [4]  [ 220/1229]  eta: 0:05:36  lr: 0.005000  loss: 0.4131 (0.4796)  loss_classifier: 0.1334 (0.1622)  loss_box_reg: 0.1161 (0.1430)  loss_objectness: 0.1086 (0.1226)  loss_rpn_box_reg: 0.0347 (0.0517)  time: 0.3249  data: 0.1444  max mem: 3973\n",
      "Training Epoch: [4]  [ 230/1229]  eta: 0:05:32  lr: 0.005000  loss: 0.5312 (0.4829)  loss_classifier: 0.1634 (0.1635)  loss_box_reg: 0.1722 (0.1453)  loss_objectness: 0.1086 (0.1231)  loss_rpn_box_reg: 0.0364 (0.0510)  time: 0.3209  data: 0.1437  max mem: 3973\n",
      "Training Epoch: [4]  [ 240/1229]  eta: 0:05:28  lr: 0.005000  loss: 0.5478 (0.4859)  loss_classifier: 0.1963 (0.1647)  loss_box_reg: 0.1829 (0.1487)  loss_objectness: 0.0904 (0.1220)  loss_rpn_box_reg: 0.0316 (0.0504)  time: 0.3202  data: 0.1428  max mem: 3973\n",
      "Training Epoch: [4]  [ 250/1229]  eta: 0:05:24  lr: 0.005000  loss: 0.4905 (0.4860)  loss_classifier: 0.1582 (0.1656)  loss_box_reg: 0.1586 (0.1489)  loss_objectness: 0.0866 (0.1219)  loss_rpn_box_reg: 0.0284 (0.0497)  time: 0.3247  data: 0.1420  max mem: 3973\n",
      "Training Epoch: [4]  [ 260/1229]  eta: 0:05:21  lr: 0.005000  loss: 0.4683 (0.4858)  loss_classifier: 0.1582 (0.1655)  loss_box_reg: 0.1319 (0.1490)  loss_objectness: 0.1005 (0.1217)  loss_rpn_box_reg: 0.0228 (0.0496)  time: 0.3279  data: 0.1417  max mem: 3973\n",
      "Training Epoch: [4]  [ 270/1229]  eta: 0:05:17  lr: 0.005000  loss: 0.4789 (0.4877)  loss_classifier: 0.1657 (0.1658)  loss_box_reg: 0.1086 (0.1490)  loss_objectness: 0.1005 (0.1221)  loss_rpn_box_reg: 0.0302 (0.0508)  time: 0.3230  data: 0.1406  max mem: 3973\n",
      "Training Epoch: [4]  [ 280/1229]  eta: 0:05:13  lr: 0.005000  loss: 0.5108 (0.4918)  loss_classifier: 0.1608 (0.1671)  loss_box_reg: 0.1414 (0.1505)  loss_objectness: 0.1072 (0.1222)  loss_rpn_box_reg: 0.0299 (0.0520)  time: 0.3182  data: 0.1375  max mem: 3973\n",
      "Training Epoch: [4]  [ 290/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.5219 (0.4943)  loss_classifier: 0.1895 (0.1684)  loss_box_reg: 0.1686 (0.1521)  loss_objectness: 0.1118 (0.1221)  loss_rpn_box_reg: 0.0279 (0.0517)  time: 0.3211  data: 0.1355  max mem: 3973\n",
      "Training Epoch: [4]  [ 300/1229]  eta: 0:05:06  lr: 0.005000  loss: 0.4012 (0.4913)  loss_classifier: 0.1599 (0.1677)  loss_box_reg: 0.1366 (0.1516)  loss_objectness: 0.0889 (0.1210)  loss_rpn_box_reg: 0.0279 (0.0511)  time: 0.3230  data: 0.1404  max mem: 3973\n",
      "Training Epoch: [4]  [ 310/1229]  eta: 0:05:03  lr: 0.005000  loss: 0.3336 (0.4918)  loss_classifier: 0.1353 (0.1679)  loss_box_reg: 0.1071 (0.1515)  loss_objectness: 0.0944 (0.1213)  loss_rpn_box_reg: 0.0306 (0.0512)  time: 0.3235  data: 0.1430  max mem: 3973\n",
      "Training Epoch: [4]  [ 320/1229]  eta: 0:04:59  lr: 0.005000  loss: 0.4190 (0.4929)  loss_classifier: 0.1512 (0.1684)  loss_box_reg: 0.0897 (0.1515)  loss_objectness: 0.1220 (0.1219)  loss_rpn_box_reg: 0.0268 (0.0511)  time: 0.3242  data: 0.1420  max mem: 3973\n",
      "Training Epoch: [4]  [ 330/1229]  eta: 0:04:56  lr: 0.005000  loss: 0.4699 (0.4913)  loss_classifier: 0.1657 (0.1683)  loss_box_reg: 0.0897 (0.1506)  loss_objectness: 0.1188 (0.1215)  loss_rpn_box_reg: 0.0257 (0.0509)  time: 0.3286  data: 0.1407  max mem: 3973\n",
      "Training Epoch: [4]  [ 340/1229]  eta: 0:04:53  lr: 0.005000  loss: 0.3973 (0.4911)  loss_classifier: 0.1520 (0.1683)  loss_box_reg: 0.0910 (0.1500)  loss_objectness: 0.0925 (0.1218)  loss_rpn_box_reg: 0.0257 (0.0510)  time: 0.3315  data: 0.1403  max mem: 3973\n",
      "Training Epoch: [4]  [ 350/1229]  eta: 0:04:49  lr: 0.005000  loss: 0.3886 (0.4880)  loss_classifier: 0.1463 (0.1675)  loss_box_reg: 0.1072 (0.1495)  loss_objectness: 0.0863 (0.1209)  loss_rpn_box_reg: 0.0223 (0.0501)  time: 0.3230  data: 0.1436  max mem: 3973\n",
      "Training Epoch: [4]  [ 360/1229]  eta: 0:04:46  lr: 0.005000  loss: 0.4145 (0.4874)  loss_classifier: 0.1529 (0.1676)  loss_box_reg: 0.1122 (0.1496)  loss_objectness: 0.1026 (0.1203)  loss_rpn_box_reg: 0.0257 (0.0499)  time: 0.3202  data: 0.1453  max mem: 3973\n",
      "Training Epoch: [4]  [ 370/1229]  eta: 0:04:42  lr: 0.005000  loss: 0.4474 (0.4882)  loss_classifier: 0.1599 (0.1678)  loss_box_reg: 0.1122 (0.1497)  loss_objectness: 0.1115 (0.1203)  loss_rpn_box_reg: 0.0296 (0.0503)  time: 0.3245  data: 0.1425  max mem: 3973\n",
      "Training Epoch: [4]  [ 380/1229]  eta: 0:04:39  lr: 0.005000  loss: 0.4824 (0.4905)  loss_classifier: 0.1732 (0.1688)  loss_box_reg: 0.1555 (0.1508)  loss_objectness: 0.1136 (0.1202)  loss_rpn_box_reg: 0.0417 (0.0507)  time: 0.3271  data: 0.1405  max mem: 3973\n",
      "Training Epoch: [4]  [ 390/1229]  eta: 0:04:36  lr: 0.005000  loss: 0.4719 (0.4880)  loss_classifier: 0.1607 (0.1678)  loss_box_reg: 0.1067 (0.1497)  loss_objectness: 0.1127 (0.1200)  loss_rpn_box_reg: 0.0382 (0.0506)  time: 0.3358  data: 0.1440  max mem: 3973\n",
      "Training Epoch: [4]  [ 400/1229]  eta: 0:04:33  lr: 0.005000  loss: 0.3445 (0.4868)  loss_classifier: 0.1254 (0.1675)  loss_box_reg: 0.1067 (0.1496)  loss_objectness: 0.0911 (0.1195)  loss_rpn_box_reg: 0.0257 (0.0501)  time: 0.3458  data: 0.1493  max mem: 3973\n",
      "Training Epoch: [4]  [ 410/1229]  eta: 0:04:30  lr: 0.005000  loss: 0.3652 (0.4889)  loss_classifier: 0.1333 (0.1679)  loss_box_reg: 0.1150 (0.1502)  loss_objectness: 0.0911 (0.1199)  loss_rpn_box_reg: 0.0276 (0.0509)  time: 0.3445  data: 0.1509  max mem: 3973\n",
      "Training Epoch: [4]  [ 420/1229]  eta: 0:04:27  lr: 0.005000  loss: 0.4845 (0.4912)  loss_classifier: 0.1476 (0.1683)  loss_box_reg: 0.1150 (0.1507)  loss_objectness: 0.1135 (0.1201)  loss_rpn_box_reg: 0.0311 (0.0521)  time: 0.3318  data: 0.1497  max mem: 3973\n",
      "Training Epoch: [4]  [ 430/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.3763 (0.4901)  loss_classifier: 0.1281 (0.1677)  loss_box_reg: 0.1035 (0.1502)  loss_objectness: 0.1102 (0.1202)  loss_rpn_box_reg: 0.0339 (0.0520)  time: 0.3191  data: 0.1470  max mem: 3973\n",
      "Training Epoch: [4]  [ 440/1229]  eta: 0:04:20  lr: 0.005000  loss: 0.3145 (0.4898)  loss_classifier: 0.1248 (0.1678)  loss_box_reg: 0.1014 (0.1499)  loss_objectness: 0.1015 (0.1204)  loss_rpn_box_reg: 0.0257 (0.0516)  time: 0.3189  data: 0.1433  max mem: 3973\n",
      "Training Epoch: [4]  [ 450/1229]  eta: 0:04:16  lr: 0.005000  loss: 0.4095 (0.4889)  loss_classifier: 0.1394 (0.1676)  loss_box_reg: 0.0952 (0.1497)  loss_objectness: 0.1015 (0.1201)  loss_rpn_box_reg: 0.0239 (0.0514)  time: 0.3262  data: 0.1412  max mem: 3973\n",
      "Training Epoch: [4]  [ 460/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.4485 (0.4876)  loss_classifier: 0.1394 (0.1670)  loss_box_reg: 0.1257 (0.1497)  loss_objectness: 0.0862 (0.1196)  loss_rpn_box_reg: 0.0235 (0.0512)  time: 0.3278  data: 0.1404  max mem: 3973\n",
      "Training Epoch: [4]  [ 470/1229]  eta: 0:04:10  lr: 0.005000  loss: 0.4675 (0.4903)  loss_classifier: 0.1677 (0.1674)  loss_box_reg: 0.1474 (0.1501)  loss_objectness: 0.1139 (0.1212)  loss_rpn_box_reg: 0.0334 (0.0516)  time: 0.3266  data: 0.1390  max mem: 3973\n",
      "Training Epoch: [4]  [ 480/1229]  eta: 0:04:06  lr: 0.005000  loss: 0.5464 (0.4927)  loss_classifier: 0.1677 (0.1682)  loss_box_reg: 0.1598 (0.1511)  loss_objectness: 0.1710 (0.1222)  loss_rpn_box_reg: 0.0379 (0.0512)  time: 0.3234  data: 0.1382  max mem: 3973\n",
      "Training Epoch: [4]  [ 490/1229]  eta: 0:04:03  lr: 0.005000  loss: 0.4780 (0.4955)  loss_classifier: 0.1659 (0.1694)  loss_box_reg: 0.1489 (0.1519)  loss_objectness: 0.1466 (0.1230)  loss_rpn_box_reg: 0.0417 (0.0513)  time: 0.3228  data: 0.1403  max mem: 3973\n",
      "Training Epoch: [4]  [ 500/1229]  eta: 0:04:00  lr: 0.005000  loss: 0.4424 (0.4949)  loss_classifier: 0.1611 (0.1692)  loss_box_reg: 0.1295 (0.1518)  loss_objectness: 0.1090 (0.1226)  loss_rpn_box_reg: 0.0286 (0.0513)  time: 0.3259  data: 0.1434  max mem: 3973\n",
      "Training Epoch: [4]  [ 510/1229]  eta: 0:03:56  lr: 0.005000  loss: 0.3596 (0.4945)  loss_classifier: 0.1356 (0.1692)  loss_box_reg: 0.1331 (0.1518)  loss_objectness: 0.0926 (0.1227)  loss_rpn_box_reg: 0.0207 (0.0509)  time: 0.3233  data: 0.1430  max mem: 3973\n",
      "Training Epoch: [4]  [ 520/1229]  eta: 0:03:53  lr: 0.005000  loss: 0.3486 (0.4902)  loss_classifier: 0.1192 (0.1676)  loss_box_reg: 0.0873 (0.1501)  loss_objectness: 0.0931 (0.1222)  loss_rpn_box_reg: 0.0182 (0.0504)  time: 0.3209  data: 0.1396  max mem: 3973\n",
      "Training Epoch: [4]  [ 530/1229]  eta: 0:03:49  lr: 0.005000  loss: 0.3879 (0.4903)  loss_classifier: 0.1261 (0.1676)  loss_box_reg: 0.1224 (0.1503)  loss_objectness: 0.0931 (0.1221)  loss_rpn_box_reg: 0.0235 (0.0504)  time: 0.3235  data: 0.1394  max mem: 3973\n",
      "Training Epoch: [4]  [ 540/1229]  eta: 0:03:46  lr: 0.005000  loss: 0.4417 (0.4904)  loss_classifier: 0.1575 (0.1676)  loss_box_reg: 0.1589 (0.1501)  loss_objectness: 0.1294 (0.1222)  loss_rpn_box_reg: 0.0456 (0.0506)  time: 0.3262  data: 0.1412  max mem: 3973\n",
      "Training Epoch: [4]  [ 550/1229]  eta: 0:03:43  lr: 0.005000  loss: 0.4071 (0.4894)  loss_classifier: 0.1381 (0.1673)  loss_box_reg: 0.0992 (0.1493)  loss_objectness: 0.1138 (0.1223)  loss_rpn_box_reg: 0.0365 (0.0505)  time: 0.3255  data: 0.1411  max mem: 3973\n",
      "Training Epoch: [4]  [ 560/1229]  eta: 0:03:39  lr: 0.005000  loss: 0.4071 (0.4901)  loss_classifier: 0.1454 (0.1677)  loss_box_reg: 0.1046 (0.1493)  loss_objectness: 0.1022 (0.1224)  loss_rpn_box_reg: 0.0369 (0.0507)  time: 0.3265  data: 0.1424  max mem: 3973\n",
      "Training Epoch: [4]  [ 570/1229]  eta: 0:03:36  lr: 0.005000  loss: 0.4825 (0.4908)  loss_classifier: 0.1752 (0.1682)  loss_box_reg: 0.1338 (0.1496)  loss_objectness: 0.1094 (0.1223)  loss_rpn_box_reg: 0.0369 (0.0507)  time: 0.3304  data: 0.1415  max mem: 3973\n",
      "Training Epoch: [4]  [ 580/1229]  eta: 0:03:33  lr: 0.005000  loss: 0.4112 (0.4899)  loss_classifier: 0.1742 (0.1679)  loss_box_reg: 0.1126 (0.1489)  loss_objectness: 0.1201 (0.1226)  loss_rpn_box_reg: 0.0279 (0.0506)  time: 0.3271  data: 0.1392  max mem: 3973\n",
      "Training Epoch: [4]  [ 590/1229]  eta: 0:03:29  lr: 0.005000  loss: 0.3968 (0.4895)  loss_classifier: 0.1416 (0.1679)  loss_box_reg: 0.1061 (0.1489)  loss_objectness: 0.1089 (0.1224)  loss_rpn_box_reg: 0.0252 (0.0503)  time: 0.3196  data: 0.1409  max mem: 3973\n",
      "Training Epoch: [4]  [ 600/1229]  eta: 0:03:26  lr: 0.005000  loss: 0.3968 (0.4880)  loss_classifier: 0.1139 (0.1674)  loss_box_reg: 0.1061 (0.1482)  loss_objectness: 0.1023 (0.1222)  loss_rpn_box_reg: 0.0197 (0.0501)  time: 0.3213  data: 0.1401  max mem: 3973\n",
      "Training Epoch: [4]  [ 610/1229]  eta: 0:03:23  lr: 0.005000  loss: 0.5223 (0.4896)  loss_classifier: 0.1722 (0.1681)  loss_box_reg: 0.1825 (0.1492)  loss_objectness: 0.1031 (0.1223)  loss_rpn_box_reg: 0.0214 (0.0500)  time: 0.3270  data: 0.1397  max mem: 3973\n",
      "Training Epoch: [4]  [ 620/1229]  eta: 0:03:20  lr: 0.005000  loss: 0.5379 (0.4900)  loss_classifier: 0.1926 (0.1681)  loss_box_reg: 0.1165 (0.1492)  loss_objectness: 0.1148 (0.1226)  loss_rpn_box_reg: 0.0256 (0.0501)  time: 0.3303  data: 0.1407  max mem: 3973\n",
      "Training Epoch: [4]  [ 630/1229]  eta: 0:03:16  lr: 0.005000  loss: 0.3082 (0.4888)  loss_classifier: 0.1149 (0.1678)  loss_box_reg: 0.0862 (0.1487)  loss_objectness: 0.1100 (0.1224)  loss_rpn_box_reg: 0.0256 (0.0499)  time: 0.3283  data: 0.1436  max mem: 3973\n",
      "Training Epoch: [4]  [ 640/1229]  eta: 0:03:13  lr: 0.005000  loss: 0.3692 (0.4892)  loss_classifier: 0.1268 (0.1680)  loss_box_reg: 0.1041 (0.1486)  loss_objectness: 0.0930 (0.1224)  loss_rpn_box_reg: 0.0260 (0.0502)  time: 0.3305  data: 0.1449  max mem: 3973\n",
      "Training Epoch: [4]  [ 650/1229]  eta: 0:03:10  lr: 0.005000  loss: 0.4164 (0.4887)  loss_classifier: 0.1369 (0.1680)  loss_box_reg: 0.1103 (0.1482)  loss_objectness: 0.0945 (0.1223)  loss_rpn_box_reg: 0.0358 (0.0503)  time: 0.3372  data: 0.1432  max mem: 3973\n",
      "Training Epoch: [4]  [ 660/1229]  eta: 0:03:06  lr: 0.005000  loss: 0.4741 (0.4901)  loss_classifier: 0.1490 (0.1684)  loss_box_reg: 0.1145 (0.1487)  loss_objectness: 0.1066 (0.1227)  loss_rpn_box_reg: 0.0381 (0.0503)  time: 0.3288  data: 0.1430  max mem: 3973\n",
      "Training Epoch: [4]  [ 670/1229]  eta: 0:03:03  lr: 0.005000  loss: 0.5613 (0.4917)  loss_classifier: 0.1853 (0.1691)  loss_box_reg: 0.1592 (0.1491)  loss_objectness: 0.1185 (0.1228)  loss_rpn_box_reg: 0.0432 (0.0506)  time: 0.3225  data: 0.1427  max mem: 3973\n",
      "Training Epoch: [4]  [ 680/1229]  eta: 0:03:00  lr: 0.005000  loss: 0.4762 (0.4927)  loss_classifier: 0.1636 (0.1690)  loss_box_reg: 0.1134 (0.1490)  loss_objectness: 0.1322 (0.1236)  loss_rpn_box_reg: 0.0530 (0.0512)  time: 0.3244  data: 0.1424  max mem: 3973\n",
      "Training Epoch: [4]  [ 690/1229]  eta: 0:02:57  lr: 0.005000  loss: 0.3905 (0.4905)  loss_classifier: 0.1295 (0.1684)  loss_box_reg: 0.0845 (0.1481)  loss_objectness: 0.1120 (0.1231)  loss_rpn_box_reg: 0.0332 (0.0508)  time: 0.3248  data: 0.1402  max mem: 3973\n",
      "Training Epoch: [4]  [ 700/1229]  eta: 0:02:53  lr: 0.005000  loss: 0.3609 (0.4908)  loss_classifier: 0.1431 (0.1684)  loss_box_reg: 0.0944 (0.1481)  loss_objectness: 0.0984 (0.1231)  loss_rpn_box_reg: 0.0296 (0.0512)  time: 0.3249  data: 0.1408  max mem: 3973\n",
      "Training Epoch: [4]  [ 710/1229]  eta: 0:02:50  lr: 0.005000  loss: 0.4259 (0.4898)  loss_classifier: 0.1524 (0.1680)  loss_box_reg: 0.1199 (0.1479)  loss_objectness: 0.1089 (0.1230)  loss_rpn_box_reg: 0.0296 (0.0509)  time: 0.3251  data: 0.1410  max mem: 3973\n",
      "Training Epoch: [4]  [ 720/1229]  eta: 0:02:47  lr: 0.005000  loss: 0.4293 (0.4898)  loss_classifier: 0.1524 (0.1681)  loss_box_reg: 0.1469 (0.1480)  loss_objectness: 0.1088 (0.1231)  loss_rpn_box_reg: 0.0211 (0.0506)  time: 0.3319  data: 0.1436  max mem: 3973\n",
      "Training Epoch: [4]  [ 730/1229]  eta: 0:02:43  lr: 0.005000  loss: 0.4216 (0.4887)  loss_classifier: 0.1278 (0.1677)  loss_box_reg: 0.1272 (0.1477)  loss_objectness: 0.0918 (0.1226)  loss_rpn_box_reg: 0.0184 (0.0506)  time: 0.3371  data: 0.1464  max mem: 3973\n",
      "Training Epoch: [4]  [ 740/1229]  eta: 0:02:40  lr: 0.005000  loss: 0.3409 (0.4885)  loss_classifier: 0.1167 (0.1676)  loss_box_reg: 0.1010 (0.1476)  loss_objectness: 0.0989 (0.1228)  loss_rpn_box_reg: 0.0292 (0.0505)  time: 0.3310  data: 0.1434  max mem: 3973\n",
      "Training Epoch: [4]  [ 750/1229]  eta: 0:02:37  lr: 0.005000  loss: 0.4311 (0.4888)  loss_classifier: 0.1435 (0.1678)  loss_box_reg: 0.1010 (0.1476)  loss_objectness: 0.1228 (0.1230)  loss_rpn_box_reg: 0.0322 (0.0504)  time: 0.3227  data: 0.1429  max mem: 3973\n",
      "Training Epoch: [4]  [ 760/1229]  eta: 0:02:34  lr: 0.005000  loss: 0.4531 (0.4897)  loss_classifier: 0.1625 (0.1679)  loss_box_reg: 0.1154 (0.1478)  loss_objectness: 0.1238 (0.1234)  loss_rpn_box_reg: 0.0260 (0.0505)  time: 0.3259  data: 0.1436  max mem: 3973\n",
      "Training Epoch: [4]  [ 770/1229]  eta: 0:02:30  lr: 0.005000  loss: 0.4531 (0.4896)  loss_classifier: 0.1452 (0.1679)  loss_box_reg: 0.1102 (0.1478)  loss_objectness: 0.1133 (0.1234)  loss_rpn_box_reg: 0.0437 (0.0504)  time: 0.3284  data: 0.1410  max mem: 3973\n",
      "Training Epoch: [4]  [ 780/1229]  eta: 0:02:27  lr: 0.005000  loss: 0.4990 (0.4915)  loss_classifier: 0.1847 (0.1686)  loss_box_reg: 0.1247 (0.1485)  loss_objectness: 0.1175 (0.1236)  loss_rpn_box_reg: 0.0522 (0.0508)  time: 0.3318  data: 0.1431  max mem: 3973\n",
      "Training Epoch: [4]  [ 790/1229]  eta: 0:02:24  lr: 0.005000  loss: 0.4666 (0.4907)  loss_classifier: 0.1299 (0.1682)  loss_box_reg: 0.1247 (0.1480)  loss_objectness: 0.1362 (0.1238)  loss_rpn_box_reg: 0.0419 (0.0508)  time: 0.3366  data: 0.1437  max mem: 3973\n",
      "Training Epoch: [4]  [ 800/1229]  eta: 0:02:20  lr: 0.005000  loss: 0.4221 (0.4911)  loss_classifier: 0.1419 (0.1683)  loss_box_reg: 0.1234 (0.1483)  loss_objectness: 0.1050 (0.1238)  loss_rpn_box_reg: 0.0242 (0.0507)  time: 0.3308  data: 0.1420  max mem: 3973\n",
      "Training Epoch: [4]  [ 810/1229]  eta: 0:02:17  lr: 0.005000  loss: 0.4695 (0.4911)  loss_classifier: 0.1569 (0.1682)  loss_box_reg: 0.1571 (0.1486)  loss_objectness: 0.0978 (0.1237)  loss_rpn_box_reg: 0.0242 (0.0506)  time: 0.3263  data: 0.1443  max mem: 3973\n",
      "Training Epoch: [4]  [ 820/1229]  eta: 0:02:14  lr: 0.005000  loss: 0.4695 (0.4917)  loss_classifier: 0.1510 (0.1684)  loss_box_reg: 0.1092 (0.1483)  loss_objectness: 0.1036 (0.1241)  loss_rpn_box_reg: 0.0206 (0.0509)  time: 0.3221  data: 0.1439  max mem: 3973\n",
      "Training Epoch: [4]  [ 830/1229]  eta: 0:02:11  lr: 0.005000  loss: 0.4565 (0.4915)  loss_classifier: 0.1537 (0.1683)  loss_box_reg: 0.1278 (0.1482)  loss_objectness: 0.1353 (0.1242)  loss_rpn_box_reg: 0.0331 (0.0508)  time: 0.3193  data: 0.1444  max mem: 3973\n",
      "Training Epoch: [4]  [ 840/1229]  eta: 0:02:07  lr: 0.005000  loss: 0.5375 (0.4932)  loss_classifier: 0.2004 (0.1692)  loss_box_reg: 0.1688 (0.1492)  loss_objectness: 0.1313 (0.1241)  loss_rpn_box_reg: 0.0333 (0.0507)  time: 0.3181  data: 0.1440  max mem: 3973\n",
      "Training Epoch: [4]  [ 850/1229]  eta: 0:02:04  lr: 0.005000  loss: 0.5375 (0.4922)  loss_classifier: 0.1838 (0.1687)  loss_box_reg: 0.1684 (0.1486)  loss_objectness: 0.1064 (0.1241)  loss_rpn_box_reg: 0.0310 (0.0508)  time: 0.3184  data: 0.1424  max mem: 3973\n",
      "Training Epoch: [4]  [ 860/1229]  eta: 0:02:01  lr: 0.005000  loss: 0.2891 (0.4911)  loss_classifier: 0.1018 (0.1683)  loss_box_reg: 0.0918 (0.1482)  loss_objectness: 0.0990 (0.1240)  loss_rpn_box_reg: 0.0276 (0.0506)  time: 0.3224  data: 0.1407  max mem: 3973\n",
      "Training Epoch: [4]  [ 870/1229]  eta: 0:01:57  lr: 0.005000  loss: 0.3889 (0.4904)  loss_classifier: 0.1312 (0.1680)  loss_box_reg: 0.0866 (0.1477)  loss_objectness: 0.1092 (0.1240)  loss_rpn_box_reg: 0.0309 (0.0506)  time: 0.3225  data: 0.1412  max mem: 3973\n",
      "Training Epoch: [4]  [ 880/1229]  eta: 0:01:54  lr: 0.005000  loss: 0.3981 (0.4901)  loss_classifier: 0.1321 (0.1678)  loss_box_reg: 0.0960 (0.1476)  loss_objectness: 0.0997 (0.1238)  loss_rpn_box_reg: 0.0456 (0.0509)  time: 0.3264  data: 0.1425  max mem: 3973\n",
      "Training Epoch: [4]  [ 890/1229]  eta: 0:01:51  lr: 0.005000  loss: 0.3981 (0.4893)  loss_classifier: 0.1400 (0.1675)  loss_box_reg: 0.1186 (0.1475)  loss_objectness: 0.0872 (0.1236)  loss_rpn_box_reg: 0.0207 (0.0507)  time: 0.3294  data: 0.1412  max mem: 3973\n",
      "Training Epoch: [4]  [ 900/1229]  eta: 0:01:47  lr: 0.005000  loss: 0.4072 (0.4889)  loss_classifier: 0.1426 (0.1674)  loss_box_reg: 0.1138 (0.1472)  loss_objectness: 0.1092 (0.1237)  loss_rpn_box_reg: 0.0200 (0.0506)  time: 0.3278  data: 0.1433  max mem: 3973\n",
      "Training Epoch: [4]  [ 910/1229]  eta: 0:01:44  lr: 0.005000  loss: 0.3913 (0.4876)  loss_classifier: 0.1306 (0.1669)  loss_box_reg: 0.0744 (0.1467)  loss_objectness: 0.1133 (0.1236)  loss_rpn_box_reg: 0.0209 (0.0504)  time: 0.3229  data: 0.1431  max mem: 3973\n",
      "Training Epoch: [4]  [ 920/1229]  eta: 0:01:41  lr: 0.005000  loss: 0.3729 (0.4867)  loss_classifier: 0.1253 (0.1666)  loss_box_reg: 0.1036 (0.1462)  loss_objectness: 0.1027 (0.1236)  loss_rpn_box_reg: 0.0222 (0.0502)  time: 0.3184  data: 0.1411  max mem: 3973\n",
      "Training Epoch: [4]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.4327 (0.4857)  loss_classifier: 0.1439 (0.1663)  loss_box_reg: 0.1036 (0.1459)  loss_objectness: 0.1027 (0.1233)  loss_rpn_box_reg: 0.0222 (0.0502)  time: 0.3202  data: 0.1424  max mem: 3973\n",
      "Training Epoch: [4]  [ 940/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.4713 (0.4868)  loss_classifier: 0.1524 (0.1668)  loss_box_reg: 0.1260 (0.1463)  loss_objectness: 0.0835 (0.1233)  loss_rpn_box_reg: 0.0326 (0.0505)  time: 0.3295  data: 0.1431  max mem: 3973\n",
      "Training Epoch: [4]  [ 950/1229]  eta: 0:01:31  lr: 0.005000  loss: 0.4521 (0.4868)  loss_classifier: 0.1524 (0.1668)  loss_box_reg: 0.1139 (0.1461)  loss_objectness: 0.1060 (0.1234)  loss_rpn_box_reg: 0.0285 (0.0505)  time: 0.3293  data: 0.1426  max mem: 3973\n",
      "Training Epoch: [4]  [ 960/1229]  eta: 0:01:28  lr: 0.005000  loss: 0.3485 (0.4868)  loss_classifier: 0.1167 (0.1666)  loss_box_reg: 0.0839 (0.1460)  loss_objectness: 0.1129 (0.1235)  loss_rpn_box_reg: 0.0217 (0.0507)  time: 0.3219  data: 0.1412  max mem: 3973\n",
      "Training Epoch: [4]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.3360 (0.4861)  loss_classifier: 0.1241 (0.1664)  loss_box_reg: 0.0984 (0.1457)  loss_objectness: 0.0973 (0.1237)  loss_rpn_box_reg: 0.0244 (0.0505)  time: 0.3257  data: 0.1409  max mem: 3973\n",
      "Training Epoch: [4]  [ 980/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.3047 (0.4851)  loss_classifier: 0.1247 (0.1662)  loss_box_reg: 0.0984 (0.1454)  loss_objectness: 0.0786 (0.1232)  loss_rpn_box_reg: 0.0174 (0.0502)  time: 0.3228  data: 0.1415  max mem: 3973\n",
      "Training Epoch: [4]  [ 990/1229]  eta: 0:01:18  lr: 0.005000  loss: 0.3845 (0.4852)  loss_classifier: 0.1289 (0.1660)  loss_box_reg: 0.1120 (0.1454)  loss_objectness: 0.0818 (0.1235)  loss_rpn_box_reg: 0.0316 (0.0504)  time: 0.3180  data: 0.1412  max mem: 3973\n",
      "Training Epoch: [4]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.4428 (0.4860)  loss_classifier: 0.1378 (0.1664)  loss_box_reg: 0.1377 (0.1461)  loss_objectness: 0.0988 (0.1233)  loss_rpn_box_reg: 0.0419 (0.0502)  time: 0.3171  data: 0.1418  max mem: 3973\n",
      "Training Epoch: [4]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.4428 (0.4854)  loss_classifier: 0.1378 (0.1662)  loss_box_reg: 0.1458 (0.1460)  loss_objectness: 0.0982 (0.1232)  loss_rpn_box_reg: 0.0213 (0.0499)  time: 0.3190  data: 0.1425  max mem: 3973\n",
      "Training Epoch: [4]  [1020/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.4324 (0.4857)  loss_classifier: 0.1659 (0.1664)  loss_box_reg: 0.1347 (0.1462)  loss_objectness: 0.1062 (0.1232)  loss_rpn_box_reg: 0.0314 (0.0499)  time: 0.3241  data: 0.1438  max mem: 3973\n",
      "Training Epoch: [4]  [1030/1229]  eta: 0:01:05  lr: 0.005000  loss: 0.5483 (0.4870)  loss_classifier: 0.1808 (0.1666)  loss_box_reg: 0.1527 (0.1465)  loss_objectness: 0.1292 (0.1236)  loss_rpn_box_reg: 0.0452 (0.0503)  time: 0.3309  data: 0.1450  max mem: 3973\n",
      "Training Epoch: [4]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.4620 (0.4862)  loss_classifier: 0.1383 (0.1663)  loss_box_reg: 0.1048 (0.1462)  loss_objectness: 0.1284 (0.1235)  loss_rpn_box_reg: 0.0386 (0.0502)  time: 0.3278  data: 0.1428  max mem: 3973\n",
      "Training Epoch: [4]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.3900 (0.4864)  loss_classifier: 0.1342 (0.1664)  loss_box_reg: 0.1048 (0.1463)  loss_objectness: 0.1063 (0.1236)  loss_rpn_box_reg: 0.0231 (0.0501)  time: 0.3258  data: 0.1392  max mem: 3973\n",
      "Training Epoch: [4]  [1060/1229]  eta: 0:00:55  lr: 0.005000  loss: 0.4232 (0.4862)  loss_classifier: 0.1458 (0.1663)  loss_box_reg: 0.1474 (0.1462)  loss_objectness: 0.1073 (0.1236)  loss_rpn_box_reg: 0.0223 (0.0501)  time: 0.3304  data: 0.1405  max mem: 3973\n",
      "Training Epoch: [4]  [1070/1229]  eta: 0:00:52  lr: 0.005000  loss: 0.4702 (0.4873)  loss_classifier: 0.1480 (0.1666)  loss_box_reg: 0.1283 (0.1465)  loss_objectness: 0.1271 (0.1240)  loss_rpn_box_reg: 0.0336 (0.0502)  time: 0.3203  data: 0.1415  max mem: 3973\n",
      "Training Epoch: [4]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.4713 (0.4871)  loss_classifier: 0.1570 (0.1665)  loss_box_reg: 0.1201 (0.1464)  loss_objectness: 0.1230 (0.1240)  loss_rpn_box_reg: 0.0336 (0.0501)  time: 0.3158  data: 0.1411  max mem: 3973\n",
      "Training Epoch: [4]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.4178 (0.4869)  loss_classifier: 0.1422 (0.1665)  loss_box_reg: 0.1350 (0.1464)  loss_objectness: 0.1230 (0.1241)  loss_rpn_box_reg: 0.0267 (0.0499)  time: 0.3230  data: 0.1419  max mem: 3973\n",
      "Training Epoch: [4]  [1100/1229]  eta: 0:00:42  lr: 0.005000  loss: 0.4178 (0.4874)  loss_classifier: 0.1609 (0.1667)  loss_box_reg: 0.1378 (0.1466)  loss_objectness: 0.1107 (0.1240)  loss_rpn_box_reg: 0.0238 (0.0501)  time: 0.3292  data: 0.1384  max mem: 3973\n",
      "Training Epoch: [4]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.3934 (0.4867)  loss_classifier: 0.1372 (0.1664)  loss_box_reg: 0.1158 (0.1462)  loss_objectness: 0.1018 (0.1240)  loss_rpn_box_reg: 0.0221 (0.0502)  time: 0.3268  data: 0.1395  max mem: 3973\n",
      "Training Epoch: [4]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.3802 (0.4861)  loss_classifier: 0.1295 (0.1663)  loss_box_reg: 0.1012 (0.1461)  loss_objectness: 0.0934 (0.1237)  loss_rpn_box_reg: 0.0191 (0.0499)  time: 0.3267  data: 0.1419  max mem: 3973\n",
      "Training Epoch: [4]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.3758 (0.4851)  loss_classifier: 0.1312 (0.1659)  loss_box_reg: 0.1082 (0.1456)  loss_objectness: 0.1082 (0.1239)  loss_rpn_box_reg: 0.0180 (0.0498)  time: 0.3327  data: 0.1397  max mem: 3973\n",
      "Training Epoch: [4]  [1140/1229]  eta: 0:00:29  lr: 0.005000  loss: 0.4021 (0.4865)  loss_classifier: 0.1597 (0.1665)  loss_box_reg: 0.1082 (0.1461)  loss_objectness: 0.1301 (0.1240)  loss_rpn_box_reg: 0.0332 (0.0499)  time: 0.3316  data: 0.1414  max mem: 3973\n",
      "Training Epoch: [4]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.5836 (0.4867)  loss_classifier: 0.1816 (0.1665)  loss_box_reg: 0.1345 (0.1460)  loss_objectness: 0.1565 (0.1243)  loss_rpn_box_reg: 0.0413 (0.0500)  time: 0.3280  data: 0.1425  max mem: 3973\n",
      "Training Epoch: [4]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.4540 (0.4867)  loss_classifier: 0.1756 (0.1665)  loss_box_reg: 0.0999 (0.1460)  loss_objectness: 0.1228 (0.1242)  loss_rpn_box_reg: 0.0396 (0.0500)  time: 0.3262  data: 0.1410  max mem: 3973\n",
      "Training Epoch: [4]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.5188 (0.4888)  loss_classifier: 0.1793 (0.1672)  loss_box_reg: 0.1519 (0.1470)  loss_objectness: 0.1148 (0.1244)  loss_rpn_box_reg: 0.0410 (0.0502)  time: 0.3250  data: 0.1432  max mem: 3973\n",
      "Training Epoch: [4]  [1180/1229]  eta: 0:00:16  lr: 0.005000  loss: 0.5984 (0.4901)  loss_classifier: 0.2186 (0.1677)  loss_box_reg: 0.2024 (0.1475)  loss_objectness: 0.1284 (0.1246)  loss_rpn_box_reg: 0.0591 (0.0503)  time: 0.3244  data: 0.1424  max mem: 3973\n",
      "Training Epoch: [4]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.4919 (0.4892)  loss_classifier: 0.1709 (0.1673)  loss_box_reg: 0.1093 (0.1472)  loss_objectness: 0.1089 (0.1243)  loss_rpn_box_reg: 0.0247 (0.0503)  time: 0.3250  data: 0.1402  max mem: 3973\n",
      "Training Epoch: [4]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.3892 (0.4896)  loss_classifier: 0.1292 (0.1675)  loss_box_reg: 0.1138 (0.1473)  loss_objectness: 0.1043 (0.1245)  loss_rpn_box_reg: 0.0257 (0.0504)  time: 0.3261  data: 0.1417  max mem: 3973\n",
      "Training Epoch: [4]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.3892 (0.4891)  loss_classifier: 0.1357 (0.1673)  loss_box_reg: 0.1198 (0.1470)  loss_objectness: 0.1177 (0.1246)  loss_rpn_box_reg: 0.0275 (0.0503)  time: 0.3275  data: 0.1419  max mem: 3973\n",
      "Training Epoch: [4]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.3771 (0.4894)  loss_classifier: 0.1415 (0.1673)  loss_box_reg: 0.1269 (0.1470)  loss_objectness: 0.1123 (0.1246)  loss_rpn_box_reg: 0.0253 (0.0504)  time: 0.3271  data: 0.1413  max mem: 3973\n",
      "Training Epoch: [4]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4260 (0.4889)  loss_classifier: 0.1591 (0.1672)  loss_box_reg: 0.1269 (0.1469)  loss_objectness: 0.1101 (0.1246)  loss_rpn_box_reg: 0.0253 (0.0502)  time: 0.3274  data: 0.1433  max mem: 3973\n",
      "Training Epoch: [4] Total time: 0:06:42 (0.3273 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:05:59  model_time: 0.3180 (0.3180)  evaluator_time: 0.0020 (0.0020)  time: 1.1680  data: 0.0300  max mem: 3973\n",
      "Test:  [100/308]  eta: 0:00:34  model_time: 0.1050 (0.1114)  evaluator_time: 0.0050 (0.0066)  time: 0.1581  data: 0.0386  max mem: 3973\n",
      "Test:  [200/308]  eta: 0:00:17  model_time: 0.1130 (0.1106)  evaluator_time: 0.0030 (0.0062)  time: 0.1545  data: 0.0334  max mem: 3973\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0970 (0.1095)  evaluator_time: 0.0040 (0.0062)  time: 0.1470  data: 0.0378  max mem: 3973\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0990 (0.1093)  evaluator_time: 0.0030 (0.0062)  time: 0.1498  data: 0.0416  max mem: 3973\n",
      "Test: Total time: 0:00:48 (0.1576 s / it)\n",
      "Averaged stats: model_time: 0.0990 (0.1093)  evaluator_time: 0.0030 (0.0062)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.223\n",
      "Testing Epoch: [4]  [  0/308]  eta: 0:00:51  lr: 0.005000  loss: 0.1939 (0.1939)  loss_classifier: 0.0575 (0.0575)  loss_box_reg: 0.0523 (0.0523)  loss_objectness: 0.0649 (0.0649)  loss_rpn_box_reg: 0.0193 (0.0193)  time: 0.1660  data: 0.0290  max mem: 3973\n",
      "Testing Epoch: [4]  [100/308]  eta: 0:00:36  lr: 0.005000  loss: 0.3424 (0.5085)  loss_classifier: 0.1333 (0.1659)  loss_box_reg: 0.1055 (0.1613)  loss_objectness: 0.0959 (0.1177)  loss_rpn_box_reg: 0.0204 (0.0636)  time: 0.1803  data: 0.0428  max mem: 3973\n",
      "Testing Epoch: [4]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.4329 (0.4842)  loss_classifier: 0.1445 (0.1583)  loss_box_reg: 0.1321 (0.1515)  loss_objectness: 0.1054 (0.1127)  loss_rpn_box_reg: 0.0241 (0.0617)  time: 0.1802  data: 0.0355  max mem: 3973\n",
      "Testing Epoch: [4]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5100 (0.4863)  loss_classifier: 0.1876 (0.1593)  loss_box_reg: 0.1579 (0.1544)  loss_objectness: 0.1119 (0.1117)  loss_rpn_box_reg: 0.0329 (0.0608)  time: 0.1700  data: 0.0411  max mem: 4015\n",
      "Testing Epoch: [4]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.4948 (0.4859)  loss_classifier: 0.1737 (0.1594)  loss_box_reg: 0.1595 (0.1546)  loss_objectness: 0.1100 (0.1117)  loss_rpn_box_reg: 0.0286 (0.0602)  time: 0.1686  data: 0.0398  max mem: 4015\n",
      "Testing Epoch: [4] Total time: 0:00:54 (0.1769 s / it)\n",
      "Training Epoch: [5]  [   0/1229]  eta: 0:06:41  lr: 0.005000  loss: 0.5710 (0.5710)  loss_classifier: 0.1908 (0.1908)  loss_box_reg: 0.1025 (0.1025)  loss_objectness: 0.2275 (0.2275)  loss_rpn_box_reg: 0.0502 (0.0502)  time: 0.3270  data: 0.1400  max mem: 4015\n",
      "Training Epoch: [5]  [  10/1229]  eta: 0:06:43  lr: 0.005000  loss: 0.5710 (0.5762)  loss_classifier: 0.2035 (0.1988)  loss_box_reg: 0.1855 (0.1794)  loss_objectness: 0.0942 (0.1220)  loss_rpn_box_reg: 0.0452 (0.0760)  time: 0.3307  data: 0.1455  max mem: 4015\n",
      "Training Epoch: [5]  [  20/1229]  eta: 0:06:38  lr: 0.005000  loss: 0.4852 (0.5348)  loss_classifier: 0.2006 (0.1928)  loss_box_reg: 0.1339 (0.1687)  loss_objectness: 0.0911 (0.1172)  loss_rpn_box_reg: 0.0335 (0.0562)  time: 0.3301  data: 0.1445  max mem: 4015\n",
      "Training Epoch: [5]  [  30/1229]  eta: 0:06:34  lr: 0.005000  loss: 0.3976 (0.5294)  loss_classifier: 0.1296 (0.1879)  loss_box_reg: 0.1014 (0.1687)  loss_objectness: 0.0977 (0.1193)  loss_rpn_box_reg: 0.0280 (0.0535)  time: 0.3280  data: 0.1439  max mem: 4015\n",
      "Training Epoch: [5]  [  40/1229]  eta: 0:06:28  lr: 0.005000  loss: 0.4338 (0.5359)  loss_classifier: 0.1507 (0.1854)  loss_box_reg: 0.0843 (0.1662)  loss_objectness: 0.1281 (0.1288)  loss_rpn_box_reg: 0.0319 (0.0555)  time: 0.3236  data: 0.1429  max mem: 4015\n",
      "Training Epoch: [5]  [  50/1229]  eta: 0:06:25  lr: 0.005000  loss: 0.5027 (0.5359)  loss_classifier: 0.1861 (0.1884)  loss_box_reg: 0.1559 (0.1689)  loss_objectness: 0.1281 (0.1278)  loss_rpn_box_reg: 0.0319 (0.0509)  time: 0.3238  data: 0.1424  max mem: 4015\n",
      "Training Epoch: [5]  [  60/1229]  eta: 0:06:23  lr: 0.005000  loss: 0.5027 (0.5225)  loss_classifier: 0.1796 (0.1826)  loss_box_reg: 0.1792 (0.1685)  loss_objectness: 0.1091 (0.1221)  loss_rpn_box_reg: 0.0238 (0.0492)  time: 0.3294  data: 0.1413  max mem: 4015\n",
      "Training Epoch: [5]  [  70/1229]  eta: 0:06:19  lr: 0.005000  loss: 0.4449 (0.5180)  loss_classifier: 0.1584 (0.1819)  loss_box_reg: 0.1442 (0.1662)  loss_objectness: 0.0973 (0.1221)  loss_rpn_box_reg: 0.0289 (0.0477)  time: 0.3300  data: 0.1404  max mem: 4015\n",
      "Training Epoch: [5]  [  80/1229]  eta: 0:06:15  lr: 0.005000  loss: 0.5483 (0.5265)  loss_classifier: 0.1867 (0.1846)  loss_box_reg: 0.1442 (0.1676)  loss_objectness: 0.1399 (0.1245)  loss_rpn_box_reg: 0.0336 (0.0499)  time: 0.3245  data: 0.1430  max mem: 4015\n",
      "Training Epoch: [5]  [  90/1229]  eta: 0:06:12  lr: 0.005000  loss: 0.4352 (0.5160)  loss_classifier: 0.1547 (0.1807)  loss_box_reg: 0.1384 (0.1661)  loss_objectness: 0.0973 (0.1211)  loss_rpn_box_reg: 0.0266 (0.0481)  time: 0.3249  data: 0.1420  max mem: 4015\n",
      "Training Epoch: [5]  [ 100/1229]  eta: 0:06:08  lr: 0.005000  loss: 0.4352 (0.5197)  loss_classifier: 0.1231 (0.1801)  loss_box_reg: 0.1079 (0.1641)  loss_objectness: 0.0954 (0.1245)  loss_rpn_box_reg: 0.0267 (0.0510)  time: 0.3260  data: 0.1420  max mem: 4015\n",
      "Training Epoch: [5]  [ 110/1229]  eta: 0:06:05  lr: 0.005000  loss: 0.4978 (0.5111)  loss_classifier: 0.1274 (0.1773)  loss_box_reg: 0.1069 (0.1613)  loss_objectness: 0.1233 (0.1231)  loss_rpn_box_reg: 0.0267 (0.0494)  time: 0.3253  data: 0.1423  max mem: 4015\n",
      "Training Epoch: [5]  [ 120/1229]  eta: 0:06:01  lr: 0.005000  loss: 0.3519 (0.4959)  loss_classifier: 0.1118 (0.1716)  loss_box_reg: 0.1069 (0.1549)  loss_objectness: 0.0921 (0.1217)  loss_rpn_box_reg: 0.0169 (0.0477)  time: 0.3239  data: 0.1405  max mem: 4015\n",
      "Training Epoch: [5]  [ 130/1229]  eta: 0:05:58  lr: 0.005000  loss: 0.3877 (0.4978)  loss_classifier: 0.1233 (0.1722)  loss_box_reg: 0.1126 (0.1558)  loss_objectness: 0.0942 (0.1225)  loss_rpn_box_reg: 0.0242 (0.0472)  time: 0.3225  data: 0.1421  max mem: 4015\n",
      "Training Epoch: [5]  [ 140/1229]  eta: 0:05:55  lr: 0.005000  loss: 0.5426 (0.5041)  loss_classifier: 0.1973 (0.1732)  loss_box_reg: 0.1661 (0.1574)  loss_objectness: 0.1136 (0.1236)  loss_rpn_box_reg: 0.0288 (0.0499)  time: 0.3293  data: 0.1425  max mem: 4015\n",
      "Training Epoch: [5]  [ 150/1229]  eta: 0:05:52  lr: 0.005000  loss: 0.4266 (0.5006)  loss_classifier: 0.1499 (0.1722)  loss_box_reg: 0.1123 (0.1556)  loss_objectness: 0.1037 (0.1223)  loss_rpn_box_reg: 0.0297 (0.0505)  time: 0.3297  data: 0.1450  max mem: 4015\n",
      "Training Epoch: [5]  [ 160/1229]  eta: 0:05:49  lr: 0.005000  loss: 0.4266 (0.4979)  loss_classifier: 0.1431 (0.1712)  loss_box_reg: 0.1009 (0.1541)  loss_objectness: 0.1023 (0.1225)  loss_rpn_box_reg: 0.0297 (0.0501)  time: 0.3273  data: 0.1454  max mem: 4015\n",
      "Training Epoch: [5]  [ 170/1229]  eta: 0:05:46  lr: 0.005000  loss: 0.3725 (0.4881)  loss_classifier: 0.1301 (0.1684)  loss_box_reg: 0.0906 (0.1511)  loss_objectness: 0.0937 (0.1201)  loss_rpn_box_reg: 0.0247 (0.0486)  time: 0.3276  data: 0.1430  max mem: 4015\n",
      "Training Epoch: [5]  [ 180/1229]  eta: 0:05:43  lr: 0.005000  loss: 0.3725 (0.4887)  loss_classifier: 0.1301 (0.1689)  loss_box_reg: 0.1050 (0.1524)  loss_objectness: 0.0898 (0.1198)  loss_rpn_box_reg: 0.0177 (0.0476)  time: 0.3314  data: 0.1431  max mem: 4015\n",
      "Training Epoch: [5]  [ 190/1229]  eta: 0:05:39  lr: 0.005000  loss: 0.3502 (0.4808)  loss_classifier: 0.1208 (0.1667)  loss_box_reg: 0.0884 (0.1507)  loss_objectness: 0.0871 (0.1175)  loss_rpn_box_reg: 0.0162 (0.0459)  time: 0.3310  data: 0.1425  max mem: 4015\n",
      "Training Epoch: [5]  [ 200/1229]  eta: 0:05:36  lr: 0.005000  loss: 0.3166 (0.4764)  loss_classifier: 0.1018 (0.1642)  loss_box_reg: 0.0812 (0.1476)  loss_objectness: 0.0871 (0.1170)  loss_rpn_box_reg: 0.0142 (0.0476)  time: 0.3226  data: 0.1432  max mem: 4015\n",
      "Training Epoch: [5]  [ 210/1229]  eta: 0:05:33  lr: 0.005000  loss: 0.3654 (0.4749)  loss_classifier: 0.1074 (0.1634)  loss_box_reg: 0.0812 (0.1467)  loss_objectness: 0.0948 (0.1174)  loss_rpn_box_reg: 0.0339 (0.0475)  time: 0.3269  data: 0.1451  max mem: 4015\n",
      "Training Epoch: [5]  [ 220/1229]  eta: 0:05:29  lr: 0.005000  loss: 0.3451 (0.4748)  loss_classifier: 0.1388 (0.1635)  loss_box_reg: 0.1024 (0.1463)  loss_objectness: 0.0999 (0.1170)  loss_rpn_box_reg: 0.0333 (0.0481)  time: 0.3262  data: 0.1451  max mem: 4015\n",
      "Training Epoch: [5]  [ 230/1229]  eta: 0:05:26  lr: 0.005000  loss: 0.3393 (0.4702)  loss_classifier: 0.1388 (0.1616)  loss_box_reg: 0.1018 (0.1442)  loss_objectness: 0.0997 (0.1167)  loss_rpn_box_reg: 0.0279 (0.0477)  time: 0.3224  data: 0.1439  max mem: 4015\n",
      "Training Epoch: [5]  [ 240/1229]  eta: 0:05:23  lr: 0.005000  loss: 0.3882 (0.4703)  loss_classifier: 0.1389 (0.1614)  loss_box_reg: 0.0876 (0.1441)  loss_objectness: 0.1061 (0.1167)  loss_rpn_box_reg: 0.0279 (0.0481)  time: 0.3290  data: 0.1439  max mem: 4015\n",
      "Training Epoch: [5]  [ 250/1229]  eta: 0:05:20  lr: 0.005000  loss: 0.4767 (0.4733)  loss_classifier: 0.1575 (0.1624)  loss_box_reg: 0.1283 (0.1462)  loss_objectness: 0.1167 (0.1166)  loss_rpn_box_reg: 0.0255 (0.0481)  time: 0.3295  data: 0.1415  max mem: 4015\n",
      "Training Epoch: [5]  [ 260/1229]  eta: 0:05:16  lr: 0.005000  loss: 0.3768 (0.4695)  loss_classifier: 0.1385 (0.1615)  loss_box_reg: 0.1056 (0.1456)  loss_objectness: 0.0821 (0.1151)  loss_rpn_box_reg: 0.0197 (0.0473)  time: 0.3289  data: 0.1402  max mem: 4015\n",
      "Training Epoch: [5]  [ 270/1229]  eta: 0:05:13  lr: 0.005000  loss: 0.3633 (0.4692)  loss_classifier: 0.1351 (0.1616)  loss_box_reg: 0.1218 (0.1454)  loss_objectness: 0.0758 (0.1153)  loss_rpn_box_reg: 0.0219 (0.0469)  time: 0.3310  data: 0.1415  max mem: 4015\n",
      "Training Epoch: [5]  [ 280/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.3715 (0.4674)  loss_classifier: 0.1238 (0.1608)  loss_box_reg: 0.1188 (0.1442)  loss_objectness: 0.1112 (0.1156)  loss_rpn_box_reg: 0.0289 (0.0468)  time: 0.3264  data: 0.1420  max mem: 4015\n",
      "Training Epoch: [5]  [ 290/1229]  eta: 0:05:06  lr: 0.005000  loss: 0.3259 (0.4638)  loss_classifier: 0.1204 (0.1596)  loss_box_reg: 0.1011 (0.1425)  loss_objectness: 0.0950 (0.1153)  loss_rpn_box_reg: 0.0303 (0.0465)  time: 0.3191  data: 0.1419  max mem: 4015\n",
      "Training Epoch: [5]  [ 300/1229]  eta: 0:05:03  lr: 0.005000  loss: 0.3089 (0.4591)  loss_classifier: 0.1149 (0.1582)  loss_box_reg: 0.0953 (0.1410)  loss_objectness: 0.0767 (0.1141)  loss_rpn_box_reg: 0.0146 (0.0457)  time: 0.3248  data: 0.1411  max mem: 4015\n",
      "Training Epoch: [5]  [ 310/1229]  eta: 0:05:00  lr: 0.005000  loss: 0.3675 (0.4608)  loss_classifier: 0.1188 (0.1586)  loss_box_reg: 0.1110 (0.1424)  loss_objectness: 0.0645 (0.1138)  loss_rpn_box_reg: 0.0283 (0.0460)  time: 0.3227  data: 0.1402  max mem: 4015\n",
      "Training Epoch: [5]  [ 320/1229]  eta: 0:04:56  lr: 0.005000  loss: 0.4298 (0.4609)  loss_classifier: 0.1501 (0.1585)  loss_box_reg: 0.1124 (0.1414)  loss_objectness: 0.0914 (0.1148)  loss_rpn_box_reg: 0.0491 (0.0462)  time: 0.3191  data: 0.1432  max mem: 4015\n",
      "Training Epoch: [5]  [ 330/1229]  eta: 0:04:53  lr: 0.005000  loss: 0.4650 (0.4651)  loss_classifier: 0.1586 (0.1592)  loss_box_reg: 0.1282 (0.1428)  loss_objectness: 0.1295 (0.1156)  loss_rpn_box_reg: 0.0329 (0.0474)  time: 0.3225  data: 0.1463  max mem: 4015\n",
      "Training Epoch: [5]  [ 340/1229]  eta: 0:04:49  lr: 0.005000  loss: 0.4774 (0.4659)  loss_classifier: 0.1546 (0.1593)  loss_box_reg: 0.1356 (0.1430)  loss_objectness: 0.1144 (0.1158)  loss_rpn_box_reg: 0.0329 (0.0477)  time: 0.3199  data: 0.1444  max mem: 4015\n",
      "Training Epoch: [5]  [ 350/1229]  eta: 0:04:46  lr: 0.005000  loss: 0.5014 (0.4675)  loss_classifier: 0.1551 (0.1602)  loss_box_reg: 0.1152 (0.1435)  loss_objectness: 0.1114 (0.1161)  loss_rpn_box_reg: 0.0323 (0.0476)  time: 0.3219  data: 0.1443  max mem: 4015\n",
      "Training Epoch: [5]  [ 360/1229]  eta: 0:04:43  lr: 0.005000  loss: 0.3460 (0.4636)  loss_classifier: 0.1304 (0.1589)  loss_box_reg: 0.0923 (0.1416)  loss_objectness: 0.0991 (0.1160)  loss_rpn_box_reg: 0.0226 (0.0470)  time: 0.3267  data: 0.1435  max mem: 4015\n",
      "Training Epoch: [5]  [ 370/1229]  eta: 0:04:39  lr: 0.005000  loss: 0.3360 (0.4648)  loss_classifier: 0.1263 (0.1594)  loss_box_reg: 0.0923 (0.1416)  loss_objectness: 0.0968 (0.1167)  loss_rpn_box_reg: 0.0235 (0.0471)  time: 0.3252  data: 0.1418  max mem: 4015\n",
      "Training Epoch: [5]  [ 380/1229]  eta: 0:04:36  lr: 0.005000  loss: 0.5145 (0.4687)  loss_classifier: 0.1825 (0.1607)  loss_box_reg: 0.1740 (0.1433)  loss_objectness: 0.1282 (0.1172)  loss_rpn_box_reg: 0.0498 (0.0475)  time: 0.3216  data: 0.1440  max mem: 4015\n",
      "Training Epoch: [5]  [ 390/1229]  eta: 0:04:33  lr: 0.005000  loss: 0.5616 (0.4690)  loss_classifier: 0.1825 (0.1607)  loss_box_reg: 0.1219 (0.1429)  loss_objectness: 0.1370 (0.1176)  loss_rpn_box_reg: 0.0498 (0.0477)  time: 0.3222  data: 0.1441  max mem: 4015\n",
      "Training Epoch: [5]  [ 400/1229]  eta: 0:04:30  lr: 0.005000  loss: 0.4670 (0.4710)  loss_classifier: 0.1664 (0.1616)  loss_box_reg: 0.1219 (0.1437)  loss_objectness: 0.1281 (0.1180)  loss_rpn_box_reg: 0.0454 (0.0478)  time: 0.3276  data: 0.1415  max mem: 4015\n",
      "Training Epoch: [5]  [ 410/1229]  eta: 0:04:26  lr: 0.005000  loss: 0.4467 (0.4687)  loss_classifier: 0.1413 (0.1610)  loss_box_reg: 0.1118 (0.1426)  loss_objectness: 0.1229 (0.1179)  loss_rpn_box_reg: 0.0324 (0.0473)  time: 0.3265  data: 0.1389  max mem: 4015\n",
      "Training Epoch: [5]  [ 420/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.3520 (0.4662)  loss_classifier: 0.1277 (0.1606)  loss_box_reg: 0.0965 (0.1418)  loss_objectness: 0.0786 (0.1171)  loss_rpn_box_reg: 0.0226 (0.0468)  time: 0.3210  data: 0.1378  max mem: 4015\n",
      "Training Epoch: [5]  [ 430/1229]  eta: 0:04:20  lr: 0.005000  loss: 0.3970 (0.4654)  loss_classifier: 0.1345 (0.1604)  loss_box_reg: 0.1240 (0.1422)  loss_objectness: 0.0786 (0.1165)  loss_rpn_box_reg: 0.0226 (0.0464)  time: 0.3211  data: 0.1392  max mem: 4015\n",
      "Training Epoch: [5]  [ 440/1229]  eta: 0:04:16  lr: 0.005000  loss: 0.4210 (0.4663)  loss_classifier: 0.1452 (0.1606)  loss_box_reg: 0.1315 (0.1425)  loss_objectness: 0.1033 (0.1170)  loss_rpn_box_reg: 0.0242 (0.0463)  time: 0.3211  data: 0.1413  max mem: 4015\n",
      "Training Epoch: [5]  [ 450/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.3600 (0.4654)  loss_classifier: 0.1324 (0.1605)  loss_box_reg: 0.1118 (0.1421)  loss_objectness: 0.0958 (0.1168)  loss_rpn_box_reg: 0.0238 (0.0461)  time: 0.3269  data: 0.1428  max mem: 4015\n",
      "Training Epoch: [5]  [ 460/1229]  eta: 0:04:10  lr: 0.005000  loss: 0.3718 (0.4664)  loss_classifier: 0.1373 (0.1608)  loss_box_reg: 0.0906 (0.1421)  loss_objectness: 0.0971 (0.1174)  loss_rpn_box_reg: 0.0238 (0.0462)  time: 0.3358  data: 0.1428  max mem: 4015\n",
      "Training Epoch: [5]  [ 470/1229]  eta: 0:04:07  lr: 0.005000  loss: 0.4571 (0.4686)  loss_classifier: 0.1520 (0.1612)  loss_box_reg: 0.1114 (0.1431)  loss_objectness: 0.1143 (0.1175)  loss_rpn_box_reg: 0.0411 (0.0468)  time: 0.3277  data: 0.1420  max mem: 4015\n",
      "Training Epoch: [5]  [ 480/1229]  eta: 0:04:03  lr: 0.005000  loss: 0.3599 (0.4669)  loss_classifier: 0.1159 (0.1605)  loss_box_reg: 0.1052 (0.1427)  loss_objectness: 0.0928 (0.1173)  loss_rpn_box_reg: 0.0343 (0.0464)  time: 0.3209  data: 0.1427  max mem: 4015\n",
      "Training Epoch: [5]  [ 490/1229]  eta: 0:04:00  lr: 0.005000  loss: 0.3576 (0.4662)  loss_classifier: 0.1159 (0.1602)  loss_box_reg: 0.1040 (0.1431)  loss_objectness: 0.0911 (0.1167)  loss_rpn_box_reg: 0.0240 (0.0462)  time: 0.3274  data: 0.1428  max mem: 4015\n",
      "Training Epoch: [5]  [ 500/1229]  eta: 0:03:57  lr: 0.005000  loss: 0.4777 (0.4693)  loss_classifier: 0.1766 (0.1612)  loss_box_reg: 0.1829 (0.1449)  loss_objectness: 0.0955 (0.1167)  loss_rpn_box_reg: 0.0257 (0.0465)  time: 0.3275  data: 0.1418  max mem: 4015\n",
      "Training Epoch: [5]  [ 510/1229]  eta: 0:03:54  lr: 0.005000  loss: 0.4234 (0.4666)  loss_classifier: 0.1315 (0.1602)  loss_box_reg: 0.0801 (0.1432)  loss_objectness: 0.0987 (0.1169)  loss_rpn_box_reg: 0.0192 (0.0464)  time: 0.3239  data: 0.1385  max mem: 4015\n",
      "Training Epoch: [5]  [ 520/1229]  eta: 0:03:50  lr: 0.005000  loss: 0.3602 (0.4671)  loss_classifier: 0.1315 (0.1604)  loss_box_reg: 0.0855 (0.1432)  loss_objectness: 0.1112 (0.1170)  loss_rpn_box_reg: 0.0185 (0.0464)  time: 0.3248  data: 0.1346  max mem: 4015\n",
      "Training Epoch: [5]  [ 530/1229]  eta: 0:03:47  lr: 0.005000  loss: 0.3602 (0.4654)  loss_classifier: 0.1377 (0.1599)  loss_box_reg: 0.1130 (0.1424)  loss_objectness: 0.1112 (0.1167)  loss_rpn_box_reg: 0.0253 (0.0464)  time: 0.3266  data: 0.1394  max mem: 4015\n",
      "Training Epoch: [5]  [ 540/1229]  eta: 0:03:44  lr: 0.005000  loss: 0.3389 (0.4652)  loss_classifier: 0.1196 (0.1598)  loss_box_reg: 0.0935 (0.1424)  loss_objectness: 0.0998 (0.1166)  loss_rpn_box_reg: 0.0220 (0.0465)  time: 0.3268  data: 0.1449  max mem: 4015\n",
      "Training Epoch: [5]  [ 550/1229]  eta: 0:03:41  lr: 0.005000  loss: 0.4702 (0.4657)  loss_classifier: 0.1335 (0.1597)  loss_box_reg: 0.1224 (0.1425)  loss_objectness: 0.0942 (0.1169)  loss_rpn_box_reg: 0.0231 (0.0466)  time: 0.3270  data: 0.1434  max mem: 4015\n",
      "Training Epoch: [5]  [ 560/1229]  eta: 0:03:37  lr: 0.005000  loss: 0.5549 (0.4671)  loss_classifier: 0.1699 (0.1602)  loss_box_reg: 0.1450 (0.1431)  loss_objectness: 0.1129 (0.1173)  loss_rpn_box_reg: 0.0307 (0.0465)  time: 0.3252  data: 0.1417  max mem: 4015\n",
      "Training Epoch: [5]  [ 570/1229]  eta: 0:03:34  lr: 0.005000  loss: 0.4558 (0.4675)  loss_classifier: 0.1699 (0.1604)  loss_box_reg: 0.1361 (0.1431)  loss_objectness: 0.1129 (0.1173)  loss_rpn_box_reg: 0.0307 (0.0466)  time: 0.3212  data: 0.1404  max mem: 4015\n",
      "Training Epoch: [5]  [ 580/1229]  eta: 0:03:31  lr: 0.005000  loss: 0.4160 (0.4664)  loss_classifier: 0.1500 (0.1599)  loss_box_reg: 0.1170 (0.1425)  loss_objectness: 0.1163 (0.1174)  loss_rpn_box_reg: 0.0303 (0.0465)  time: 0.3230  data: 0.1418  max mem: 4015\n",
      "Training Epoch: [5]  [ 590/1229]  eta: 0:03:28  lr: 0.005000  loss: 0.4057 (0.4656)  loss_classifier: 0.1137 (0.1596)  loss_box_reg: 0.0902 (0.1421)  loss_objectness: 0.1313 (0.1175)  loss_rpn_box_reg: 0.0292 (0.0464)  time: 0.3245  data: 0.1457  max mem: 4015\n",
      "Training Epoch: [5]  [ 600/1229]  eta: 0:03:24  lr: 0.005000  loss: 0.4250 (0.4678)  loss_classifier: 0.1260 (0.1602)  loss_box_reg: 0.1223 (0.1432)  loss_objectness: 0.1128 (0.1175)  loss_rpn_box_reg: 0.0308 (0.0470)  time: 0.3212  data: 0.1427  max mem: 4015\n",
      "Training Epoch: [5]  [ 610/1229]  eta: 0:03:21  lr: 0.005000  loss: 0.4808 (0.4681)  loss_classifier: 0.1519 (0.1602)  loss_box_reg: 0.1347 (0.1433)  loss_objectness: 0.1085 (0.1173)  loss_rpn_box_reg: 0.0308 (0.0473)  time: 0.3281  data: 0.1397  max mem: 4015\n",
      "Training Epoch: [5]  [ 620/1229]  eta: 0:03:18  lr: 0.005000  loss: 0.3787 (0.4682)  loss_classifier: 0.1504 (0.1602)  loss_box_reg: 0.1288 (0.1436)  loss_objectness: 0.0931 (0.1170)  loss_rpn_box_reg: 0.0252 (0.0474)  time: 0.3294  data: 0.1412  max mem: 4015\n",
      "Training Epoch: [5]  [ 630/1229]  eta: 0:03:15  lr: 0.005000  loss: 0.3788 (0.4683)  loss_classifier: 0.1447 (0.1603)  loss_box_reg: 0.1358 (0.1439)  loss_objectness: 0.0939 (0.1169)  loss_rpn_box_reg: 0.0304 (0.0472)  time: 0.3269  data: 0.1422  max mem: 4015\n",
      "Training Epoch: [5]  [ 640/1229]  eta: 0:03:11  lr: 0.005000  loss: 0.3788 (0.4680)  loss_classifier: 0.1342 (0.1601)  loss_box_reg: 0.1112 (0.1436)  loss_objectness: 0.1181 (0.1170)  loss_rpn_box_reg: 0.0308 (0.0474)  time: 0.3243  data: 0.1416  max mem: 4015\n",
      "Training Epoch: [5]  [ 650/1229]  eta: 0:03:08  lr: 0.005000  loss: 0.4363 (0.4692)  loss_classifier: 0.1617 (0.1608)  loss_box_reg: 0.1204 (0.1439)  loss_objectness: 0.1261 (0.1172)  loss_rpn_box_reg: 0.0225 (0.0473)  time: 0.3222  data: 0.1402  max mem: 4015\n",
      "Training Epoch: [5]  [ 660/1229]  eta: 0:03:05  lr: 0.005000  loss: 0.5336 (0.4714)  loss_classifier: 0.1742 (0.1613)  loss_box_reg: 0.1495 (0.1446)  loss_objectness: 0.1310 (0.1178)  loss_rpn_box_reg: 0.0252 (0.0477)  time: 0.3230  data: 0.1414  max mem: 4015\n",
      "Training Epoch: [5]  [ 670/1229]  eta: 0:03:01  lr: 0.005000  loss: 0.5336 (0.4724)  loss_classifier: 0.1585 (0.1614)  loss_box_reg: 0.0951 (0.1447)  loss_objectness: 0.1335 (0.1185)  loss_rpn_box_reg: 0.0390 (0.0478)  time: 0.3223  data: 0.1425  max mem: 4015\n",
      "Training Epoch: [5]  [ 680/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.4000 (0.4713)  loss_classifier: 0.1465 (0.1611)  loss_box_reg: 0.0890 (0.1445)  loss_objectness: 0.0963 (0.1183)  loss_rpn_box_reg: 0.0212 (0.0474)  time: 0.3214  data: 0.1424  max mem: 4015\n",
      "Training Epoch: [5]  [ 690/1229]  eta: 0:02:55  lr: 0.005000  loss: 0.5098 (0.4734)  loss_classifier: 0.1529 (0.1618)  loss_box_reg: 0.1434 (0.1454)  loss_objectness: 0.0963 (0.1184)  loss_rpn_box_reg: 0.0213 (0.0478)  time: 0.3203  data: 0.1433  max mem: 4015\n",
      "Training Epoch: [5]  [ 700/1229]  eta: 0:02:52  lr: 0.005000  loss: 0.5098 (0.4742)  loss_classifier: 0.1732 (0.1620)  loss_box_reg: 0.1565 (0.1460)  loss_objectness: 0.1112 (0.1183)  loss_rpn_box_reg: 0.0296 (0.0479)  time: 0.3211  data: 0.1440  max mem: 4015\n",
      "Training Epoch: [5]  [ 710/1229]  eta: 0:02:48  lr: 0.005000  loss: 0.4268 (0.4748)  loss_classifier: 0.1524 (0.1624)  loss_box_reg: 0.1453 (0.1463)  loss_objectness: 0.0988 (0.1181)  loss_rpn_box_reg: 0.0236 (0.0480)  time: 0.3221  data: 0.1430  max mem: 4015\n",
      "Training Epoch: [5]  [ 720/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.4284 (0.4750)  loss_classifier: 0.1585 (0.1624)  loss_box_reg: 0.1419 (0.1465)  loss_objectness: 0.1016 (0.1182)  loss_rpn_box_reg: 0.0219 (0.0478)  time: 0.3236  data: 0.1406  max mem: 4015\n",
      "Training Epoch: [5]  [ 730/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.3614 (0.4736)  loss_classifier: 0.1479 (0.1622)  loss_box_reg: 0.1359 (0.1462)  loss_objectness: 0.0932 (0.1178)  loss_rpn_box_reg: 0.0206 (0.0474)  time: 0.3263  data: 0.1398  max mem: 4015\n",
      "Training Epoch: [5]  [ 740/1229]  eta: 0:02:39  lr: 0.005000  loss: 0.3328 (0.4740)  loss_classifier: 0.1479 (0.1623)  loss_box_reg: 0.1162 (0.1465)  loss_objectness: 0.0932 (0.1179)  loss_rpn_box_reg: 0.0208 (0.0474)  time: 0.3277  data: 0.1425  max mem: 4015\n",
      "Training Epoch: [5]  [ 750/1229]  eta: 0:02:35  lr: 0.005000  loss: 0.4336 (0.4736)  loss_classifier: 0.1814 (0.1623)  loss_box_reg: 0.1230 (0.1465)  loss_objectness: 0.1062 (0.1177)  loss_rpn_box_reg: 0.0162 (0.0471)  time: 0.3278  data: 0.1431  max mem: 4015\n",
      "Training Epoch: [5]  [ 760/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.4945 (0.4740)  loss_classifier: 0.1630 (0.1626)  loss_box_reg: 0.1435 (0.1467)  loss_objectness: 0.1074 (0.1177)  loss_rpn_box_reg: 0.0382 (0.0471)  time: 0.3229  data: 0.1430  max mem: 4015\n",
      "Training Epoch: [5]  [ 770/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.4945 (0.4741)  loss_classifier: 0.1630 (0.1626)  loss_box_reg: 0.1435 (0.1466)  loss_objectness: 0.1233 (0.1179)  loss_rpn_box_reg: 0.0382 (0.0470)  time: 0.3222  data: 0.1452  max mem: 4015\n",
      "Training Epoch: [5]  [ 780/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.4331 (0.4747)  loss_classifier: 0.1526 (0.1628)  loss_box_reg: 0.1194 (0.1467)  loss_objectness: 0.1292 (0.1181)  loss_rpn_box_reg: 0.0219 (0.0471)  time: 0.3254  data: 0.1448  max mem: 4015\n",
      "Training Epoch: [5]  [ 790/1229]  eta: 0:02:22  lr: 0.005000  loss: 0.4726 (0.4754)  loss_classifier: 0.1698 (0.1629)  loss_box_reg: 0.1164 (0.1467)  loss_objectness: 0.1133 (0.1183)  loss_rpn_box_reg: 0.0613 (0.0474)  time: 0.3263  data: 0.1443  max mem: 4015\n",
      "Training Epoch: [5]  [ 800/1229]  eta: 0:02:19  lr: 0.005000  loss: 0.3605 (0.4733)  loss_classifier: 0.0993 (0.1623)  loss_box_reg: 0.0854 (0.1460)  loss_objectness: 0.1098 (0.1179)  loss_rpn_box_reg: 0.0259 (0.0471)  time: 0.3268  data: 0.1431  max mem: 4015\n",
      "Training Epoch: [5]  [ 810/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.3721 (0.4750)  loss_classifier: 0.1599 (0.1629)  loss_box_reg: 0.1070 (0.1468)  loss_objectness: 0.1107 (0.1181)  loss_rpn_box_reg: 0.0216 (0.0472)  time: 0.3257  data: 0.1409  max mem: 4015\n",
      "Training Epoch: [5]  [ 820/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.4512 (0.4741)  loss_classifier: 0.1650 (0.1627)  loss_box_reg: 0.1490 (0.1468)  loss_objectness: 0.0869 (0.1176)  loss_rpn_box_reg: 0.0219 (0.0470)  time: 0.3257  data: 0.1407  max mem: 4015\n",
      "Training Epoch: [5]  [ 830/1229]  eta: 0:02:09  lr: 0.005000  loss: 0.3458 (0.4731)  loss_classifier: 0.1115 (0.1623)  loss_box_reg: 0.1078 (0.1460)  loss_objectness: 0.0837 (0.1178)  loss_rpn_box_reg: 0.0188 (0.0469)  time: 0.3244  data: 0.1412  max mem: 4015\n",
      "Training Epoch: [5]  [ 840/1229]  eta: 0:02:06  lr: 0.005000  loss: 0.3245 (0.4713)  loss_classifier: 0.1078 (0.1616)  loss_box_reg: 0.0629 (0.1453)  loss_objectness: 0.1047 (0.1177)  loss_rpn_box_reg: 0.0278 (0.0467)  time: 0.3267  data: 0.1405  max mem: 4015\n",
      "Training Epoch: [5]  [ 850/1229]  eta: 0:02:03  lr: 0.005000  loss: 0.3907 (0.4721)  loss_classifier: 0.1249 (0.1619)  loss_box_reg: 0.0971 (0.1455)  loss_objectness: 0.1106 (0.1180)  loss_rpn_box_reg: 0.0279 (0.0467)  time: 0.3292  data: 0.1443  max mem: 4015\n",
      "Training Epoch: [5]  [ 860/1229]  eta: 0:02:00  lr: 0.005000  loss: 0.4549 (0.4720)  loss_classifier: 0.1589 (0.1618)  loss_box_reg: 0.1475 (0.1455)  loss_objectness: 0.1232 (0.1180)  loss_rpn_box_reg: 0.0219 (0.0467)  time: 0.3306  data: 0.1453  max mem: 4015\n",
      "Training Epoch: [5]  [ 870/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.4468 (0.4733)  loss_classifier: 0.1559 (0.1621)  loss_box_reg: 0.1486 (0.1460)  loss_objectness: 0.1203 (0.1184)  loss_rpn_box_reg: 0.0275 (0.0469)  time: 0.3284  data: 0.1449  max mem: 4015\n",
      "Training Epoch: [5]  [ 880/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.4865 (0.4730)  loss_classifier: 0.1523 (0.1619)  loss_box_reg: 0.1105 (0.1456)  loss_objectness: 0.1289 (0.1187)  loss_rpn_box_reg: 0.0341 (0.0468)  time: 0.3223  data: 0.1468  max mem: 4015\n",
      "Training Epoch: [5]  [ 890/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.4669 (0.4731)  loss_classifier: 0.1523 (0.1621)  loss_box_reg: 0.1077 (0.1456)  loss_objectness: 0.1161 (0.1186)  loss_rpn_box_reg: 0.0245 (0.0468)  time: 0.3202  data: 0.1452  max mem: 4015\n",
      "Training Epoch: [5]  [ 900/1229]  eta: 0:01:47  lr: 0.005000  loss: 0.4632 (0.4741)  loss_classifier: 0.1609 (0.1624)  loss_box_reg: 0.1239 (0.1459)  loss_objectness: 0.0978 (0.1186)  loss_rpn_box_reg: 0.0355 (0.0473)  time: 0.3254  data: 0.1438  max mem: 4015\n",
      "Training Epoch: [5]  [ 910/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.4393 (0.4733)  loss_classifier: 0.1492 (0.1621)  loss_box_reg: 0.1368 (0.1456)  loss_objectness: 0.0978 (0.1184)  loss_rpn_box_reg: 0.0355 (0.0471)  time: 0.3294  data: 0.1414  max mem: 4015\n",
      "Training Epoch: [5]  [ 920/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.4439 (0.4747)  loss_classifier: 0.1644 (0.1629)  loss_box_reg: 0.1484 (0.1463)  loss_objectness: 0.1035 (0.1184)  loss_rpn_box_reg: 0.0336 (0.0470)  time: 0.3298  data: 0.1434  max mem: 4015\n",
      "Training Epoch: [5]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.5093 (0.4745)  loss_classifier: 0.1751 (0.1629)  loss_box_reg: 0.1197 (0.1459)  loss_objectness: 0.1134 (0.1187)  loss_rpn_box_reg: 0.0325 (0.0470)  time: 0.3331  data: 0.1466  max mem: 4015\n",
      "Training Epoch: [5]  [ 940/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.3840 (0.4759)  loss_classifier: 0.1733 (0.1636)  loss_box_reg: 0.1197 (0.1466)  loss_objectness: 0.1085 (0.1187)  loss_rpn_box_reg: 0.0301 (0.0469)  time: 0.3305  data: 0.1430  max mem: 4015\n",
      "Training Epoch: [5]  [ 950/1229]  eta: 0:01:30  lr: 0.005000  loss: 0.4126 (0.4756)  loss_classifier: 0.1708 (0.1634)  loss_box_reg: 0.1265 (0.1462)  loss_objectness: 0.1098 (0.1188)  loss_rpn_box_reg: 0.0368 (0.0472)  time: 0.3222  data: 0.1381  max mem: 4015\n",
      "Training Epoch: [5]  [ 960/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.5533 (0.4764)  loss_classifier: 0.1726 (0.1636)  loss_box_reg: 0.0987 (0.1461)  loss_objectness: 0.1098 (0.1190)  loss_rpn_box_reg: 0.0524 (0.0476)  time: 0.3225  data: 0.1387  max mem: 4015\n",
      "Training Epoch: [5]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.5616 (0.4768)  loss_classifier: 0.1726 (0.1636)  loss_box_reg: 0.1007 (0.1461)  loss_objectness: 0.1265 (0.1192)  loss_rpn_box_reg: 0.0413 (0.0480)  time: 0.3271  data: 0.1427  max mem: 4015\n",
      "Training Epoch: [5]  [ 980/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.5255 (0.4783)  loss_classifier: 0.1629 (0.1640)  loss_box_reg: 0.1314 (0.1466)  loss_objectness: 0.1293 (0.1196)  loss_rpn_box_reg: 0.0312 (0.0482)  time: 0.3295  data: 0.1441  max mem: 4015\n",
      "Training Epoch: [5]  [ 990/1229]  eta: 0:01:17  lr: 0.005000  loss: 0.4662 (0.4772)  loss_classifier: 0.1267 (0.1634)  loss_box_reg: 0.1398 (0.1463)  loss_objectness: 0.0992 (0.1193)  loss_rpn_box_reg: 0.0231 (0.0483)  time: 0.3253  data: 0.1425  max mem: 4015\n",
      "Training Epoch: [5]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.3296 (0.4777)  loss_classifier: 0.1145 (0.1634)  loss_box_reg: 0.0969 (0.1467)  loss_objectness: 0.0948 (0.1192)  loss_rpn_box_reg: 0.0231 (0.0485)  time: 0.3216  data: 0.1432  max mem: 4015\n",
      "Training Epoch: [5]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.5532 (0.4786)  loss_classifier: 0.1800 (0.1640)  loss_box_reg: 0.1659 (0.1472)  loss_objectness: 0.1104 (0.1190)  loss_rpn_box_reg: 0.0313 (0.0484)  time: 0.3271  data: 0.1446  max mem: 4015\n",
      "Training Epoch: [5]  [1020/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.5532 (0.4799)  loss_classifier: 0.2020 (0.1644)  loss_box_reg: 0.1865 (0.1478)  loss_objectness: 0.1104 (0.1190)  loss_rpn_box_reg: 0.0383 (0.0487)  time: 0.3232  data: 0.1440  max mem: 4015\n",
      "Training Epoch: [5]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.5171 (0.4810)  loss_classifier: 0.1814 (0.1648)  loss_box_reg: 0.1514 (0.1483)  loss_objectness: 0.1117 (0.1189)  loss_rpn_box_reg: 0.0430 (0.0489)  time: 0.3209  data: 0.1443  max mem: 4015\n",
      "Training Epoch: [5]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.4150 (0.4805)  loss_classifier: 0.1452 (0.1647)  loss_box_reg: 0.1144 (0.1483)  loss_objectness: 0.0897 (0.1188)  loss_rpn_box_reg: 0.0212 (0.0486)  time: 0.3223  data: 0.1428  max mem: 4015\n",
      "Training Epoch: [5]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.4150 (0.4806)  loss_classifier: 0.1401 (0.1647)  loss_box_reg: 0.0985 (0.1481)  loss_objectness: 0.1052 (0.1189)  loss_rpn_box_reg: 0.0225 (0.0488)  time: 0.3178  data: 0.1392  max mem: 4015\n",
      "Training Epoch: [5]  [1060/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.4640 (0.4809)  loss_classifier: 0.1290 (0.1647)  loss_box_reg: 0.0922 (0.1481)  loss_objectness: 0.1267 (0.1192)  loss_rpn_box_reg: 0.0318 (0.0489)  time: 0.3177  data: 0.1385  max mem: 4015\n",
      "Training Epoch: [5]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.3005 (0.4790)  loss_classifier: 0.0886 (0.1639)  loss_box_reg: 0.0719 (0.1473)  loss_objectness: 0.1128 (0.1191)  loss_rpn_box_reg: 0.0216 (0.0487)  time: 0.3176  data: 0.1397  max mem: 4015\n",
      "Training Epoch: [5]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.3267 (0.4798)  loss_classifier: 0.1119 (0.1643)  loss_box_reg: 0.0737 (0.1475)  loss_objectness: 0.1128 (0.1192)  loss_rpn_box_reg: 0.0235 (0.0489)  time: 0.3198  data: 0.1421  max mem: 4015\n",
      "Training Epoch: [5]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.5663 (0.4810)  loss_classifier: 0.2053 (0.1647)  loss_box_reg: 0.1373 (0.1476)  loss_objectness: 0.1163 (0.1194)  loss_rpn_box_reg: 0.0335 (0.0492)  time: 0.3219  data: 0.1438  max mem: 4015\n",
      "Training Epoch: [5]  [1100/1229]  eta: 0:00:41  lr: 0.005000  loss: 0.3975 (0.4803)  loss_classifier: 0.1642 (0.1646)  loss_box_reg: 0.1019 (0.1473)  loss_objectness: 0.1241 (0.1194)  loss_rpn_box_reg: 0.0289 (0.0490)  time: 0.3199  data: 0.1425  max mem: 4015\n",
      "Training Epoch: [5]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.4138 (0.4815)  loss_classifier: 0.1604 (0.1649)  loss_box_reg: 0.1030 (0.1476)  loss_objectness: 0.1319 (0.1196)  loss_rpn_box_reg: 0.0282 (0.0493)  time: 0.3174  data: 0.1399  max mem: 4015\n",
      "Training Epoch: [5]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4872 (0.4807)  loss_classifier: 0.1576 (0.1646)  loss_box_reg: 0.1348 (0.1475)  loss_objectness: 0.0981 (0.1195)  loss_rpn_box_reg: 0.0282 (0.0491)  time: 0.3256  data: 0.1449  max mem: 4015\n",
      "Training Epoch: [5]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.3358 (0.4796)  loss_classifier: 0.1207 (0.1643)  loss_box_reg: 0.1124 (0.1474)  loss_objectness: 0.0831 (0.1191)  loss_rpn_box_reg: 0.0166 (0.0489)  time: 0.3385  data: 0.1484  max mem: 4015\n",
      "Training Epoch: [5]  [1140/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.3412 (0.4796)  loss_classifier: 0.1164 (0.1642)  loss_box_reg: 0.1095 (0.1475)  loss_objectness: 0.0899 (0.1192)  loss_rpn_box_reg: 0.0199 (0.0488)  time: 0.3390  data: 0.1450  max mem: 4015\n",
      "Training Epoch: [5]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.3721 (0.4795)  loss_classifier: 0.1215 (0.1642)  loss_box_reg: 0.1095 (0.1474)  loss_objectness: 0.1127 (0.1191)  loss_rpn_box_reg: 0.0211 (0.0488)  time: 0.3275  data: 0.1446  max mem: 4015\n",
      "Training Epoch: [5]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.3721 (0.4785)  loss_classifier: 0.1231 (0.1637)  loss_box_reg: 0.1096 (0.1471)  loss_objectness: 0.1012 (0.1189)  loss_rpn_box_reg: 0.0217 (0.0488)  time: 0.3205  data: 0.1449  max mem: 4015\n",
      "Training Epoch: [5]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.3476 (0.4779)  loss_classifier: 0.1259 (0.1636)  loss_box_reg: 0.1096 (0.1470)  loss_objectness: 0.0803 (0.1186)  loss_rpn_box_reg: 0.0217 (0.0486)  time: 0.3287  data: 0.1454  max mem: 4015\n",
      "Training Epoch: [5]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.3476 (0.4775)  loss_classifier: 0.1305 (0.1637)  loss_box_reg: 0.1239 (0.1471)  loss_objectness: 0.0803 (0.1183)  loss_rpn_box_reg: 0.0190 (0.0484)  time: 0.3328  data: 0.1445  max mem: 4015\n",
      "Training Epoch: [5]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.3560 (0.4776)  loss_classifier: 0.1318 (0.1637)  loss_box_reg: 0.0967 (0.1469)  loss_objectness: 0.0924 (0.1185)  loss_rpn_box_reg: 0.0179 (0.0484)  time: 0.3359  data: 0.1478  max mem: 4015\n",
      "Training Epoch: [5]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.3546 (0.4765)  loss_classifier: 0.1210 (0.1633)  loss_box_reg: 0.0978 (0.1467)  loss_objectness: 0.0686 (0.1181)  loss_rpn_box_reg: 0.0212 (0.0484)  time: 0.3317  data: 0.1493  max mem: 4015\n",
      "Training Epoch: [5]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.4169 (0.4766)  loss_classifier: 0.1345 (0.1635)  loss_box_reg: 0.1359 (0.1467)  loss_objectness: 0.0768 (0.1182)  loss_rpn_box_reg: 0.0252 (0.0483)  time: 0.3270  data: 0.1498  max mem: 4015\n",
      "Training Epoch: [5]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.4352 (0.4760)  loss_classifier: 0.1540 (0.1633)  loss_box_reg: 0.1188 (0.1463)  loss_objectness: 0.0876 (0.1182)  loss_rpn_box_reg: 0.0252 (0.0482)  time: 0.3273  data: 0.1492  max mem: 4015\n",
      "Training Epoch: [5]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4156 (0.4765)  loss_classifier: 0.1540 (0.1635)  loss_box_reg: 0.1120 (0.1465)  loss_objectness: 0.1197 (0.1183)  loss_rpn_box_reg: 0.0234 (0.0482)  time: 0.3238  data: 0.1459  max mem: 4015\n",
      "Training Epoch: [5] Total time: 0:06:40 (0.3256 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:45  model_time: 0.3040 (0.3040)  evaluator_time: 0.0020 (0.0020)  time: 0.3410  data: 0.0320  max mem: 4015\n",
      "Test:  [100/308]  eta: 0:00:34  model_time: 0.1080 (0.1146)  evaluator_time: 0.0090 (0.0104)  time: 0.1666  data: 0.0399  max mem: 4015\n",
      "Test:  [200/308]  eta: 0:00:17  model_time: 0.1160 (0.1140)  evaluator_time: 0.0040 (0.0094)  time: 0.1607  data: 0.0343  max mem: 4015\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.1050 (0.1131)  evaluator_time: 0.0050 (0.0091)  time: 0.1627  data: 0.0458  max mem: 4015\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.1060 (0.1129)  evaluator_time: 0.0040 (0.0091)  time: 0.1580  data: 0.0434  max mem: 4015\n",
      "Test: Total time: 0:00:50 (0.1625 s / it)\n",
      "Averaged stats: model_time: 0.1060 (0.1129)  evaluator_time: 0.0040 (0.0091)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.051\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.116\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.136\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.098\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.224\n",
      "Testing Epoch: [5]  [  0/308]  eta: 0:00:48  lr: 0.005000  loss: 0.1632 (0.1632)  loss_classifier: 0.0660 (0.0660)  loss_box_reg: 0.0427 (0.0427)  loss_objectness: 0.0445 (0.0445)  loss_rpn_box_reg: 0.0100 (0.0100)  time: 0.1570  data: 0.0330  max mem: 4015\n",
      "Testing Epoch: [5]  [100/308]  eta: 0:00:38  lr: 0.005000  loss: 0.3286 (0.5285)  loss_classifier: 0.1381 (0.1701)  loss_box_reg: 0.1192 (0.1662)  loss_objectness: 0.0830 (0.1179)  loss_rpn_box_reg: 0.0180 (0.0743)  time: 0.1887  data: 0.0501  max mem: 4015\n",
      "Testing Epoch: [5]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.4179 (0.5065)  loss_classifier: 0.1464 (0.1625)  loss_box_reg: 0.1528 (0.1600)  loss_objectness: 0.0934 (0.1121)  loss_rpn_box_reg: 0.0264 (0.0719)  time: 0.1828  data: 0.0383  max mem: 4015\n",
      "Testing Epoch: [5]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5362 (0.5050)  loss_classifier: 0.1852 (0.1625)  loss_box_reg: 0.1492 (0.1626)  loss_objectness: 0.0986 (0.1093)  loss_rpn_box_reg: 0.0336 (0.0706)  time: 0.1760  data: 0.0443  max mem: 4022\n",
      "Testing Epoch: [5]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.5073 (0.5039)  loss_classifier: 0.1620 (0.1623)  loss_box_reg: 0.1525 (0.1627)  loss_objectness: 0.0975 (0.1092)  loss_rpn_box_reg: 0.0292 (0.0697)  time: 0.1751  data: 0.0427  max mem: 4022\n",
      "Testing Epoch: [5] Total time: 0:00:56 (0.1829 s / it)\n",
      "Training Epoch: [6]  [   0/1229]  eta: 0:07:22  lr: 0.005000  loss: 0.8617 (0.8617)  loss_classifier: 0.3264 (0.3264)  loss_box_reg: 0.3158 (0.3158)  loss_objectness: 0.1756 (0.1756)  loss_rpn_box_reg: 0.0439 (0.0439)  time: 0.3600  data: 0.1630  max mem: 4022\n",
      "Training Epoch: [6]  [  10/1229]  eta: 0:06:56  lr: 0.005000  loss: 0.4904 (0.6818)  loss_classifier: 0.1801 (0.2359)  loss_box_reg: 0.1594 (0.1863)  loss_objectness: 0.1461 (0.1594)  loss_rpn_box_reg: 0.0439 (0.1002)  time: 0.3415  data: 0.1484  max mem: 4022\n",
      "Training Epoch: [6]  [  20/1229]  eta: 0:06:53  lr: 0.005000  loss: 0.4161 (0.5743)  loss_classifier: 0.1745 (0.1992)  loss_box_reg: 0.1399 (0.1675)  loss_objectness: 0.1297 (0.1383)  loss_rpn_box_reg: 0.0338 (0.0693)  time: 0.3411  data: 0.1443  max mem: 4022\n",
      "Training Epoch: [6]  [  30/1229]  eta: 0:06:52  lr: 0.005000  loss: 0.4161 (0.5107)  loss_classifier: 0.1441 (0.1745)  loss_box_reg: 0.0903 (0.1412)  loss_objectness: 0.1195 (0.1342)  loss_rpn_box_reg: 0.0281 (0.0608)  time: 0.3451  data: 0.1445  max mem: 4022\n",
      "Training Epoch: [6]  [  40/1229]  eta: 0:06:48  lr: 0.005000  loss: 0.3644 (0.4859)  loss_classifier: 0.1102 (0.1647)  loss_box_reg: 0.1059 (0.1411)  loss_objectness: 0.0941 (0.1251)  loss_rpn_box_reg: 0.0269 (0.0550)  time: 0.3454  data: 0.1538  max mem: 4022\n",
      "Training Epoch: [6]  [  50/1229]  eta: 0:06:40  lr: 0.005000  loss: 0.3870 (0.5002)  loss_classifier: 0.1193 (0.1686)  loss_box_reg: 0.1440 (0.1548)  loss_objectness: 0.0790 (0.1214)  loss_rpn_box_reg: 0.0215 (0.0554)  time: 0.3341  data: 0.1517  max mem: 4022\n",
      "Training Epoch: [6]  [  60/1229]  eta: 0:06:36  lr: 0.005000  loss: 0.4583 (0.4950)  loss_classifier: 0.1635 (0.1694)  loss_box_reg: 0.1440 (0.1559)  loss_objectness: 0.0860 (0.1174)  loss_rpn_box_reg: 0.0268 (0.0524)  time: 0.3305  data: 0.1433  max mem: 4022\n",
      "Training Epoch: [6]  [  70/1229]  eta: 0:06:33  lr: 0.005000  loss: 0.4168 (0.4916)  loss_classifier: 0.1667 (0.1700)  loss_box_reg: 0.1278 (0.1574)  loss_objectness: 0.0928 (0.1150)  loss_rpn_box_reg: 0.0366 (0.0492)  time: 0.3368  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [6]  [  80/1229]  eta: 0:06:26  lr: 0.005000  loss: 0.3390 (0.4739)  loss_classifier: 0.1154 (0.1635)  loss_box_reg: 0.0887 (0.1499)  loss_objectness: 0.0957 (0.1142)  loss_rpn_box_reg: 0.0168 (0.0464)  time: 0.3284  data: 0.1394  max mem: 4022\n",
      "Training Epoch: [6]  [  90/1229]  eta: 0:06:21  lr: 0.005000  loss: 0.3168 (0.4652)  loss_classifier: 0.1058 (0.1614)  loss_box_reg: 0.0823 (0.1472)  loss_objectness: 0.0897 (0.1122)  loss_rpn_box_reg: 0.0202 (0.0444)  time: 0.3190  data: 0.1375  max mem: 4022\n",
      "Training Epoch: [6]  [ 100/1229]  eta: 0:06:16  lr: 0.005000  loss: 0.3281 (0.4609)  loss_classifier: 0.1037 (0.1583)  loss_box_reg: 0.1018 (0.1453)  loss_objectness: 0.0831 (0.1100)  loss_rpn_box_reg: 0.0228 (0.0472)  time: 0.3184  data: 0.1386  max mem: 4022\n",
      "Training Epoch: [6]  [ 110/1229]  eta: 0:06:11  lr: 0.005000  loss: 0.4279 (0.4643)  loss_classifier: 0.1509 (0.1607)  loss_box_reg: 0.1021 (0.1469)  loss_objectness: 0.0934 (0.1106)  loss_rpn_box_reg: 0.0228 (0.0461)  time: 0.3180  data: 0.1381  max mem: 4022\n",
      "Training Epoch: [6]  [ 120/1229]  eta: 0:06:06  lr: 0.005000  loss: 0.4808 (0.4677)  loss_classifier: 0.1667 (0.1619)  loss_box_reg: 0.1449 (0.1480)  loss_objectness: 0.1190 (0.1119)  loss_rpn_box_reg: 0.0233 (0.0459)  time: 0.3152  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [6]  [ 130/1229]  eta: 0:06:02  lr: 0.005000  loss: 0.4899 (0.4705)  loss_classifier: 0.1667 (0.1624)  loss_box_reg: 0.1291 (0.1460)  loss_objectness: 0.1245 (0.1149)  loss_rpn_box_reg: 0.0273 (0.0473)  time: 0.3205  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [6]  [ 140/1229]  eta: 0:05:58  lr: 0.005000  loss: 0.4422 (0.4710)  loss_classifier: 0.1374 (0.1627)  loss_box_reg: 0.1119 (0.1451)  loss_objectness: 0.1267 (0.1160)  loss_rpn_box_reg: 0.0245 (0.0471)  time: 0.3267  data: 0.1365  max mem: 4022\n",
      "Training Epoch: [6]  [ 150/1229]  eta: 0:05:54  lr: 0.005000  loss: 0.4502 (0.4757)  loss_classifier: 0.1571 (0.1643)  loss_box_reg: 0.1305 (0.1459)  loss_objectness: 0.1363 (0.1188)  loss_rpn_box_reg: 0.0273 (0.0466)  time: 0.3223  data: 0.1375  max mem: 4022\n",
      "Training Epoch: [6]  [ 160/1229]  eta: 0:05:51  lr: 0.005000  loss: 0.4419 (0.4750)  loss_classifier: 0.1545 (0.1637)  loss_box_reg: 0.1384 (0.1463)  loss_objectness: 0.1115 (0.1188)  loss_rpn_box_reg: 0.0245 (0.0462)  time: 0.3198  data: 0.1368  max mem: 4022\n",
      "Training Epoch: [6]  [ 170/1229]  eta: 0:05:47  lr: 0.005000  loss: 0.4156 (0.4748)  loss_classifier: 0.1511 (0.1637)  loss_box_reg: 0.1161 (0.1466)  loss_objectness: 0.1234 (0.1196)  loss_rpn_box_reg: 0.0245 (0.0448)  time: 0.3224  data: 0.1373  max mem: 4022\n",
      "Training Epoch: [6]  [ 180/1229]  eta: 0:05:44  lr: 0.005000  loss: 0.5630 (0.4805)  loss_classifier: 0.2186 (0.1654)  loss_box_reg: 0.1727 (0.1485)  loss_objectness: 0.1414 (0.1214)  loss_rpn_box_reg: 0.0285 (0.0451)  time: 0.3248  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [6]  [ 190/1229]  eta: 0:05:40  lr: 0.005000  loss: 0.4693 (0.4780)  loss_classifier: 0.1672 (0.1647)  loss_box_reg: 0.1020 (0.1458)  loss_objectness: 0.1443 (0.1219)  loss_rpn_box_reg: 0.0410 (0.0455)  time: 0.3207  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [6]  [ 200/1229]  eta: 0:05:36  lr: 0.005000  loss: 0.4561 (0.4855)  loss_classifier: 0.1672 (0.1684)  loss_box_reg: 0.0847 (0.1487)  loss_objectness: 0.1103 (0.1226)  loss_rpn_box_reg: 0.0410 (0.0459)  time: 0.3147  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [6]  [ 210/1229]  eta: 0:05:32  lr: 0.005000  loss: 0.4694 (0.4860)  loss_classifier: 0.1693 (0.1693)  loss_box_reg: 0.1584 (0.1488)  loss_objectness: 0.1032 (0.1225)  loss_rpn_box_reg: 0.0391 (0.0454)  time: 0.3132  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [6]  [ 220/1229]  eta: 0:05:28  lr: 0.005000  loss: 0.3884 (0.4857)  loss_classifier: 0.1611 (0.1697)  loss_box_reg: 0.1410 (0.1501)  loss_objectness: 0.0958 (0.1213)  loss_rpn_box_reg: 0.0193 (0.0446)  time: 0.3139  data: 0.1384  max mem: 4022\n",
      "Training Epoch: [6]  [ 230/1229]  eta: 0:05:24  lr: 0.005000  loss: 0.3884 (0.4893)  loss_classifier: 0.1611 (0.1709)  loss_box_reg: 0.1580 (0.1527)  loss_objectness: 0.0905 (0.1211)  loss_rpn_box_reg: 0.0190 (0.0446)  time: 0.3173  data: 0.1391  max mem: 4022\n",
      "Training Epoch: [6]  [ 240/1229]  eta: 0:05:21  lr: 0.005000  loss: 0.4664 (0.4924)  loss_classifier: 0.1886 (0.1714)  loss_box_reg: 0.1803 (0.1539)  loss_objectness: 0.1038 (0.1215)  loss_rpn_box_reg: 0.0394 (0.0455)  time: 0.3176  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [6]  [ 250/1229]  eta: 0:05:18  lr: 0.005000  loss: 0.4634 (0.4891)  loss_classifier: 0.1522 (0.1704)  loss_box_reg: 0.1260 (0.1536)  loss_objectness: 0.0898 (0.1201)  loss_rpn_box_reg: 0.0252 (0.0450)  time: 0.3297  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [6]  [ 260/1229]  eta: 0:05:15  lr: 0.005000  loss: 0.4468 (0.4879)  loss_classifier: 0.1549 (0.1700)  loss_box_reg: 0.1260 (0.1536)  loss_objectness: 0.0971 (0.1197)  loss_rpn_box_reg: 0.0190 (0.0445)  time: 0.3343  data: 0.1397  max mem: 4022\n",
      "Training Epoch: [6]  [ 270/1229]  eta: 0:05:12  lr: 0.005000  loss: 0.4342 (0.4853)  loss_classifier: 0.1399 (0.1692)  loss_box_reg: 0.1085 (0.1528)  loss_objectness: 0.1113 (0.1193)  loss_rpn_box_reg: 0.0224 (0.0440)  time: 0.3214  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [6]  [ 280/1229]  eta: 0:05:08  lr: 0.005000  loss: 0.3122 (0.4810)  loss_classifier: 0.1174 (0.1676)  loss_box_reg: 0.0832 (0.1507)  loss_objectness: 0.0961 (0.1189)  loss_rpn_box_reg: 0.0224 (0.0438)  time: 0.3244  data: 0.1433  max mem: 4022\n",
      "Training Epoch: [6]  [ 290/1229]  eta: 0:05:05  lr: 0.005000  loss: 0.3170 (0.4822)  loss_classifier: 0.1174 (0.1682)  loss_box_reg: 0.0831 (0.1508)  loss_objectness: 0.0961 (0.1190)  loss_rpn_box_reg: 0.0282 (0.0442)  time: 0.3279  data: 0.1428  max mem: 4022\n",
      "Training Epoch: [6]  [ 300/1229]  eta: 0:05:02  lr: 0.005000  loss: 0.4618 (0.4849)  loss_classifier: 0.1335 (0.1689)  loss_box_reg: 0.1162 (0.1522)  loss_objectness: 0.1078 (0.1186)  loss_rpn_box_reg: 0.0369 (0.0451)  time: 0.3231  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [6]  [ 310/1229]  eta: 0:04:59  lr: 0.005000  loss: 0.4636 (0.4877)  loss_classifier: 0.1805 (0.1700)  loss_box_reg: 0.1407 (0.1532)  loss_objectness: 0.1069 (0.1194)  loss_rpn_box_reg: 0.0274 (0.0450)  time: 0.3244  data: 0.1436  max mem: 4022\n",
      "Training Epoch: [6]  [ 320/1229]  eta: 0:04:55  lr: 0.005000  loss: 0.3142 (0.4844)  loss_classifier: 0.1266 (0.1688)  loss_box_reg: 0.0857 (0.1515)  loss_objectness: 0.0986 (0.1191)  loss_rpn_box_reg: 0.0160 (0.0450)  time: 0.3235  data: 0.1443  max mem: 4022\n",
      "Training Epoch: [6]  [ 330/1229]  eta: 0:04:52  lr: 0.005000  loss: 0.3152 (0.4860)  loss_classifier: 0.1266 (0.1690)  loss_box_reg: 0.0791 (0.1516)  loss_objectness: 0.1087 (0.1199)  loss_rpn_box_reg: 0.0174 (0.0456)  time: 0.3200  data: 0.1447  max mem: 4022\n",
      "Training Epoch: [6]  [ 340/1229]  eta: 0:04:49  lr: 0.005000  loss: 0.4160 (0.4859)  loss_classifier: 0.1488 (0.1690)  loss_box_reg: 0.1334 (0.1520)  loss_objectness: 0.1131 (0.1193)  loss_rpn_box_reg: 0.0322 (0.0457)  time: 0.3279  data: 0.1448  max mem: 4022\n",
      "Training Epoch: [6]  [ 350/1229]  eta: 0:04:47  lr: 0.005000  loss: 0.4160 (0.4852)  loss_classifier: 0.1552 (0.1690)  loss_box_reg: 0.1483 (0.1521)  loss_objectness: 0.0900 (0.1189)  loss_rpn_box_reg: 0.0226 (0.0452)  time: 0.3549  data: 0.1433  max mem: 4022\n",
      "Training Epoch: [6]  [ 360/1229]  eta: 0:04:43  lr: 0.005000  loss: 0.4597 (0.4879)  loss_classifier: 0.1759 (0.1701)  loss_box_reg: 0.1758 (0.1536)  loss_objectness: 0.0886 (0.1191)  loss_rpn_box_reg: 0.0271 (0.0451)  time: 0.3480  data: 0.1409  max mem: 4022\n",
      "Training Epoch: [6]  [ 370/1229]  eta: 0:04:40  lr: 0.005000  loss: 0.4839 (0.4873)  loss_classifier: 0.1746 (0.1698)  loss_box_reg: 0.1758 (0.1536)  loss_objectness: 0.0991 (0.1190)  loss_rpn_box_reg: 0.0291 (0.0449)  time: 0.3229  data: 0.1368  max mem: 4022\n",
      "Training Epoch: [6]  [ 380/1229]  eta: 0:04:37  lr: 0.005000  loss: 0.4646 (0.4867)  loss_classifier: 0.1586 (0.1695)  loss_box_reg: 0.1334 (0.1529)  loss_objectness: 0.0994 (0.1192)  loss_rpn_box_reg: 0.0338 (0.0451)  time: 0.3239  data: 0.1383  max mem: 4022\n",
      "Training Epoch: [6]  [ 390/1229]  eta: 0:04:33  lr: 0.005000  loss: 0.4121 (0.4850)  loss_classifier: 0.1570 (0.1690)  loss_box_reg: 0.1270 (0.1525)  loss_objectness: 0.0956 (0.1188)  loss_rpn_box_reg: 0.0304 (0.0447)  time: 0.3227  data: 0.1397  max mem: 4022\n",
      "Training Epoch: [6]  [ 400/1229]  eta: 0:04:30  lr: 0.005000  loss: 0.5073 (0.4882)  loss_classifier: 0.1602 (0.1701)  loss_box_reg: 0.1722 (0.1543)  loss_objectness: 0.0956 (0.1187)  loss_rpn_box_reg: 0.0284 (0.0452)  time: 0.3173  data: 0.1380  max mem: 4022\n",
      "Training Epoch: [6]  [ 410/1229]  eta: 0:04:26  lr: 0.005000  loss: 0.5451 (0.4874)  loss_classifier: 0.1581 (0.1698)  loss_box_reg: 0.1607 (0.1539)  loss_objectness: 0.1008 (0.1184)  loss_rpn_box_reg: 0.0284 (0.0452)  time: 0.3178  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [6]  [ 420/1229]  eta: 0:04:23  lr: 0.005000  loss: 0.3693 (0.4860)  loss_classifier: 0.1408 (0.1693)  loss_box_reg: 0.1004 (0.1529)  loss_objectness: 0.0874 (0.1185)  loss_rpn_box_reg: 0.0214 (0.0453)  time: 0.3193  data: 0.1402  max mem: 4022\n",
      "Training Epoch: [6]  [ 430/1229]  eta: 0:04:20  lr: 0.005000  loss: 0.2832 (0.4811)  loss_classifier: 0.1105 (0.1678)  loss_box_reg: 0.0890 (0.1510)  loss_objectness: 0.0854 (0.1177)  loss_rpn_box_reg: 0.0149 (0.0446)  time: 0.3140  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [6]  [ 440/1229]  eta: 0:04:16  lr: 0.005000  loss: 0.3434 (0.4803)  loss_classifier: 0.1229 (0.1675)  loss_box_reg: 0.0991 (0.1510)  loss_objectness: 0.0779 (0.1173)  loss_rpn_box_reg: 0.0177 (0.0444)  time: 0.3171  data: 0.1361  max mem: 4022\n",
      "Training Epoch: [6]  [ 450/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.4165 (0.4805)  loss_classifier: 0.1662 (0.1677)  loss_box_reg: 0.1274 (0.1510)  loss_objectness: 0.1046 (0.1175)  loss_rpn_box_reg: 0.0183 (0.0442)  time: 0.3219  data: 0.1386  max mem: 4022\n",
      "Training Epoch: [6]  [ 460/1229]  eta: 0:04:09  lr: 0.005000  loss: 0.4199 (0.4797)  loss_classifier: 0.1662 (0.1672)  loss_box_reg: 0.1244 (0.1501)  loss_objectness: 0.0984 (0.1175)  loss_rpn_box_reg: 0.0322 (0.0448)  time: 0.3173  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [6]  [ 470/1229]  eta: 0:04:06  lr: 0.005000  loss: 0.4463 (0.4816)  loss_classifier: 0.1736 (0.1677)  loss_box_reg: 0.0996 (0.1505)  loss_objectness: 0.1061 (0.1181)  loss_rpn_box_reg: 0.0526 (0.0453)  time: 0.3162  data: 0.1401  max mem: 4022\n",
      "Training Epoch: [6]  [ 480/1229]  eta: 0:04:03  lr: 0.005000  loss: 0.3888 (0.4794)  loss_classifier: 0.1454 (0.1669)  loss_box_reg: 0.0996 (0.1496)  loss_objectness: 0.1101 (0.1178)  loss_rpn_box_reg: 0.0348 (0.0451)  time: 0.3186  data: 0.1392  max mem: 4022\n",
      "Training Epoch: [6]  [ 490/1229]  eta: 0:04:00  lr: 0.005000  loss: 0.3328 (0.4789)  loss_classifier: 0.1356 (0.1667)  loss_box_reg: 0.0949 (0.1494)  loss_objectness: 0.1057 (0.1176)  loss_rpn_box_reg: 0.0232 (0.0452)  time: 0.3221  data: 0.1377  max mem: 4022\n",
      "Training Epoch: [6]  [ 500/1229]  eta: 0:03:56  lr: 0.005000  loss: 0.3349 (0.4776)  loss_classifier: 0.1262 (0.1662)  loss_box_reg: 0.0949 (0.1491)  loss_objectness: 0.0993 (0.1173)  loss_rpn_box_reg: 0.0193 (0.0450)  time: 0.3284  data: 0.1371  max mem: 4022\n",
      "Training Epoch: [6]  [ 510/1229]  eta: 0:03:53  lr: 0.005000  loss: 0.3349 (0.4752)  loss_classifier: 0.1202 (0.1652)  loss_box_reg: 0.0947 (0.1482)  loss_objectness: 0.0815 (0.1168)  loss_rpn_box_reg: 0.0184 (0.0449)  time: 0.3222  data: 0.1354  max mem: 4022\n",
      "Training Epoch: [6]  [ 520/1229]  eta: 0:03:50  lr: 0.005000  loss: 0.3373 (0.4749)  loss_classifier: 0.1301 (0.1650)  loss_box_reg: 0.1071 (0.1480)  loss_objectness: 0.0791 (0.1170)  loss_rpn_box_reg: 0.0192 (0.0447)  time: 0.3188  data: 0.1350  max mem: 4022\n",
      "Training Epoch: [6]  [ 530/1229]  eta: 0:03:47  lr: 0.005000  loss: 0.4831 (0.4760)  loss_classifier: 0.1637 (0.1651)  loss_box_reg: 0.1207 (0.1480)  loss_objectness: 0.1069 (0.1173)  loss_rpn_box_reg: 0.0365 (0.0457)  time: 0.3297  data: 0.1363  max mem: 4022\n",
      "Training Epoch: [6]  [ 540/1229]  eta: 0:03:43  lr: 0.005000  loss: 0.4736 (0.4759)  loss_classifier: 0.1564 (0.1649)  loss_box_reg: 0.1299 (0.1480)  loss_objectness: 0.1132 (0.1174)  loss_rpn_box_reg: 0.0453 (0.0456)  time: 0.3328  data: 0.1390  max mem: 4022\n",
      "Training Epoch: [6]  [ 550/1229]  eta: 0:03:40  lr: 0.005000  loss: 0.4119 (0.4772)  loss_classifier: 0.1341 (0.1650)  loss_box_reg: 0.1197 (0.1482)  loss_objectness: 0.1139 (0.1180)  loss_rpn_box_reg: 0.0308 (0.0459)  time: 0.3313  data: 0.1414  max mem: 4022\n",
      "Training Epoch: [6]  [ 560/1229]  eta: 0:03:37  lr: 0.005000  loss: 0.4082 (0.4777)  loss_classifier: 0.1341 (0.1652)  loss_box_reg: 0.1171 (0.1488)  loss_objectness: 0.1072 (0.1180)  loss_rpn_box_reg: 0.0266 (0.0457)  time: 0.3325  data: 0.1401  max mem: 4022\n",
      "Training Epoch: [6]  [ 570/1229]  eta: 0:03:34  lr: 0.005000  loss: 0.5551 (0.4788)  loss_classifier: 0.1814 (0.1655)  loss_box_reg: 0.1551 (0.1490)  loss_objectness: 0.1000 (0.1180)  loss_rpn_box_reg: 0.0325 (0.0463)  time: 0.3316  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [6]  [ 580/1229]  eta: 0:03:30  lr: 0.005000  loss: 0.3864 (0.4789)  loss_classifier: 0.1390 (0.1654)  loss_box_reg: 0.1163 (0.1491)  loss_objectness: 0.0999 (0.1179)  loss_rpn_box_reg: 0.0366 (0.0465)  time: 0.3187  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [6]  [ 590/1229]  eta: 0:03:27  lr: 0.005000  loss: 0.3449 (0.4771)  loss_classifier: 0.1251 (0.1650)  loss_box_reg: 0.1014 (0.1484)  loss_objectness: 0.0800 (0.1174)  loss_rpn_box_reg: 0.0237 (0.0463)  time: 0.3189  data: 0.1380  max mem: 4022\n",
      "Training Epoch: [6]  [ 600/1229]  eta: 0:03:24  lr: 0.005000  loss: 0.3687 (0.4761)  loss_classifier: 0.1258 (0.1644)  loss_box_reg: 0.1116 (0.1478)  loss_objectness: 0.1009 (0.1177)  loss_rpn_box_reg: 0.0295 (0.0462)  time: 0.3227  data: 0.1385  max mem: 4022\n",
      "Training Epoch: [6]  [ 610/1229]  eta: 0:03:21  lr: 0.005000  loss: 0.4970 (0.4784)  loss_classifier: 0.1598 (0.1649)  loss_box_reg: 0.1567 (0.1491)  loss_objectness: 0.0954 (0.1179)  loss_rpn_box_reg: 0.0295 (0.0465)  time: 0.3183  data: 0.1389  max mem: 4022\n",
      "Training Epoch: [6]  [ 620/1229]  eta: 0:03:17  lr: 0.005000  loss: 0.5148 (0.4796)  loss_classifier: 0.1873 (0.1655)  loss_box_reg: 0.1762 (0.1498)  loss_objectness: 0.0912 (0.1178)  loss_rpn_box_reg: 0.0293 (0.0464)  time: 0.3297  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [6]  [ 630/1229]  eta: 0:03:14  lr: 0.005000  loss: 0.4270 (0.4794)  loss_classifier: 0.1591 (0.1654)  loss_box_reg: 0.1277 (0.1498)  loss_objectness: 0.0982 (0.1175)  loss_rpn_box_reg: 0.0218 (0.0466)  time: 0.3285  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [6]  [ 640/1229]  eta: 0:03:11  lr: 0.005000  loss: 0.4270 (0.4796)  loss_classifier: 0.1372 (0.1655)  loss_box_reg: 0.1267 (0.1497)  loss_objectness: 0.0982 (0.1175)  loss_rpn_box_reg: 0.0223 (0.0469)  time: 0.3276  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [6]  [ 650/1229]  eta: 0:03:08  lr: 0.005000  loss: 0.3960 (0.4796)  loss_classifier: 0.1460 (0.1655)  loss_box_reg: 0.1104 (0.1499)  loss_objectness: 0.0819 (0.1176)  loss_rpn_box_reg: 0.0317 (0.0467)  time: 0.3271  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [6]  [ 660/1229]  eta: 0:03:04  lr: 0.005000  loss: 0.3960 (0.4799)  loss_classifier: 0.1519 (0.1655)  loss_box_reg: 0.1612 (0.1502)  loss_objectness: 0.0985 (0.1176)  loss_rpn_box_reg: 0.0221 (0.0466)  time: 0.3212  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [6]  [ 670/1229]  eta: 0:03:01  lr: 0.005000  loss: 0.4430 (0.4797)  loss_classifier: 0.1589 (0.1655)  loss_box_reg: 0.1412 (0.1501)  loss_objectness: 0.1133 (0.1177)  loss_rpn_box_reg: 0.0221 (0.0464)  time: 0.3236  data: 0.1409  max mem: 4022\n",
      "Training Epoch: [6]  [ 680/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.4676 (0.4797)  loss_classifier: 0.1567 (0.1654)  loss_box_reg: 0.1085 (0.1499)  loss_objectness: 0.1185 (0.1181)  loss_rpn_box_reg: 0.0224 (0.0464)  time: 0.3217  data: 0.1401  max mem: 4022\n",
      "Training Epoch: [6]  [ 690/1229]  eta: 0:02:55  lr: 0.005000  loss: 0.3521 (0.4784)  loss_classifier: 0.1186 (0.1647)  loss_box_reg: 0.0927 (0.1492)  loss_objectness: 0.1168 (0.1180)  loss_rpn_box_reg: 0.0249 (0.0465)  time: 0.3202  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [6]  [ 700/1229]  eta: 0:02:51  lr: 0.005000  loss: 0.3521 (0.4769)  loss_classifier: 0.1166 (0.1641)  loss_box_reg: 0.0749 (0.1484)  loss_objectness: 0.1100 (0.1180)  loss_rpn_box_reg: 0.0270 (0.0465)  time: 0.3198  data: 0.1391  max mem: 4022\n",
      "Training Epoch: [6]  [ 710/1229]  eta: 0:02:48  lr: 0.005000  loss: 0.4463 (0.4790)  loss_classifier: 0.1392 (0.1648)  loss_box_reg: 0.1227 (0.1491)  loss_objectness: 0.1395 (0.1184)  loss_rpn_box_reg: 0.0290 (0.0466)  time: 0.3193  data: 0.1406  max mem: 4022\n",
      "Training Epoch: [6]  [ 720/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.4888 (0.4795)  loss_classifier: 0.1829 (0.1652)  loss_box_reg: 0.1501 (0.1495)  loss_objectness: 0.1130 (0.1183)  loss_rpn_box_reg: 0.0315 (0.0465)  time: 0.3218  data: 0.1422  max mem: 4022\n",
      "Training Epoch: [6]  [ 730/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.4153 (0.4789)  loss_classifier: 0.1588 (0.1650)  loss_box_reg: 0.1180 (0.1496)  loss_objectness: 0.0935 (0.1179)  loss_rpn_box_reg: 0.0315 (0.0464)  time: 0.3240  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [6]  [ 740/1229]  eta: 0:02:38  lr: 0.005000  loss: 0.4280 (0.4788)  loss_classifier: 0.1588 (0.1649)  loss_box_reg: 0.1116 (0.1494)  loss_objectness: 0.0935 (0.1181)  loss_rpn_box_reg: 0.0231 (0.0464)  time: 0.3293  data: 0.1403  max mem: 4022\n",
      "Training Epoch: [6]  [ 750/1229]  eta: 0:02:35  lr: 0.005000  loss: 0.4465 (0.4794)  loss_classifier: 0.1588 (0.1650)  loss_box_reg: 0.1234 (0.1499)  loss_objectness: 0.1075 (0.1178)  loss_rpn_box_reg: 0.0266 (0.0467)  time: 0.3271  data: 0.1412  max mem: 4022\n",
      "Training Epoch: [6]  [ 760/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.3689 (0.4779)  loss_classifier: 0.1187 (0.1645)  loss_box_reg: 0.1053 (0.1495)  loss_objectness: 0.0938 (0.1174)  loss_rpn_box_reg: 0.0192 (0.0465)  time: 0.3179  data: 0.1429  max mem: 4022\n",
      "Training Epoch: [6]  [ 770/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.3417 (0.4773)  loss_classifier: 0.1160 (0.1642)  loss_box_reg: 0.1052 (0.1490)  loss_objectness: 0.0777 (0.1174)  loss_rpn_box_reg: 0.0231 (0.0467)  time: 0.3254  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [6]  [ 780/1229]  eta: 0:02:25  lr: 0.005000  loss: 0.3899 (0.4778)  loss_classifier: 0.1415 (0.1643)  loss_box_reg: 0.1266 (0.1491)  loss_objectness: 0.0820 (0.1175)  loss_rpn_box_reg: 0.0336 (0.0469)  time: 0.3304  data: 0.1424  max mem: 4022\n",
      "Training Epoch: [6]  [ 790/1229]  eta: 0:02:22  lr: 0.005000  loss: 0.4515 (0.4780)  loss_classifier: 0.1441 (0.1643)  loss_box_reg: 0.1216 (0.1488)  loss_objectness: 0.1293 (0.1178)  loss_rpn_box_reg: 0.0253 (0.0472)  time: 0.3220  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [6]  [ 800/1229]  eta: 0:02:19  lr: 0.005000  loss: 0.3821 (0.4775)  loss_classifier: 0.1383 (0.1642)  loss_box_reg: 0.1100 (0.1487)  loss_objectness: 0.0863 (0.1175)  loss_rpn_box_reg: 0.0267 (0.0471)  time: 0.3189  data: 0.1391  max mem: 4022\n",
      "Training Epoch: [6]  [ 810/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.3269 (0.4768)  loss_classifier: 0.1198 (0.1642)  loss_box_reg: 0.1013 (0.1485)  loss_objectness: 0.0856 (0.1172)  loss_rpn_box_reg: 0.0267 (0.0468)  time: 0.3204  data: 0.1401  max mem: 4022\n",
      "Training Epoch: [6]  [ 820/1229]  eta: 0:02:12  lr: 0.005000  loss: 0.4255 (0.4769)  loss_classifier: 0.1248 (0.1642)  loss_box_reg: 0.1013 (0.1483)  loss_objectness: 0.0895 (0.1174)  loss_rpn_box_reg: 0.0183 (0.0469)  time: 0.3244  data: 0.1387  max mem: 4022\n",
      "Training Epoch: [6]  [ 830/1229]  eta: 0:02:09  lr: 0.005000  loss: 0.4255 (0.4762)  loss_classifier: 0.1431 (0.1640)  loss_box_reg: 0.1173 (0.1480)  loss_objectness: 0.0895 (0.1173)  loss_rpn_box_reg: 0.0245 (0.0469)  time: 0.3277  data: 0.1380  max mem: 4022\n",
      "Training Epoch: [6]  [ 840/1229]  eta: 0:02:06  lr: 0.005000  loss: 0.4523 (0.4766)  loss_classifier: 0.1490 (0.1640)  loss_box_reg: 0.1386 (0.1484)  loss_objectness: 0.1154 (0.1172)  loss_rpn_box_reg: 0.0401 (0.0470)  time: 0.3257  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [6]  [ 850/1229]  eta: 0:02:03  lr: 0.005000  loss: 0.5020 (0.4771)  loss_classifier: 0.1437 (0.1641)  loss_box_reg: 0.1470 (0.1487)  loss_objectness: 0.1219 (0.1175)  loss_rpn_box_reg: 0.0286 (0.0468)  time: 0.3227  data: 0.1411  max mem: 4022\n",
      "Training Epoch: [6]  [ 860/1229]  eta: 0:01:59  lr: 0.005000  loss: 0.5674 (0.4799)  loss_classifier: 0.1961 (0.1650)  loss_box_reg: 0.1945 (0.1497)  loss_objectness: 0.1606 (0.1181)  loss_rpn_box_reg: 0.0394 (0.0470)  time: 0.3212  data: 0.1432  max mem: 4022\n",
      "Training Epoch: [6]  [ 870/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.5525 (0.4796)  loss_classifier: 0.1946 (0.1651)  loss_box_reg: 0.1929 (0.1498)  loss_objectness: 0.1097 (0.1180)  loss_rpn_box_reg: 0.0289 (0.0468)  time: 0.3225  data: 0.1438  max mem: 4022\n",
      "Training Epoch: [6]  [ 880/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.4189 (0.4795)  loss_classifier: 0.1805 (0.1653)  loss_box_reg: 0.1201 (0.1500)  loss_objectness: 0.0759 (0.1177)  loss_rpn_box_reg: 0.0186 (0.0465)  time: 0.3250  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [6]  [ 890/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.3223 (0.4776)  loss_classifier: 0.1226 (0.1648)  loss_box_reg: 0.0815 (0.1495)  loss_objectness: 0.0705 (0.1172)  loss_rpn_box_reg: 0.0170 (0.0462)  time: 0.3232  data: 0.1412  max mem: 4022\n",
      "Training Epoch: [6]  [ 900/1229]  eta: 0:01:46  lr: 0.005000  loss: 0.3416 (0.4781)  loss_classifier: 0.1226 (0.1648)  loss_box_reg: 0.0857 (0.1494)  loss_objectness: 0.0725 (0.1175)  loss_rpn_box_reg: 0.0180 (0.0464)  time: 0.3218  data: 0.1412  max mem: 4022\n",
      "Training Epoch: [6]  [ 910/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.4327 (0.4780)  loss_classifier: 0.1456 (0.1648)  loss_box_reg: 0.1121 (0.1495)  loss_objectness: 0.0947 (0.1173)  loss_rpn_box_reg: 0.0431 (0.0465)  time: 0.3262  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [6]  [ 920/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.4481 (0.4785)  loss_classifier: 0.1418 (0.1650)  loss_box_reg: 0.1430 (0.1500)  loss_objectness: 0.0972 (0.1172)  loss_rpn_box_reg: 0.0260 (0.0463)  time: 0.3301  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [6]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.4469 (0.4782)  loss_classifier: 0.1418 (0.1648)  loss_box_reg: 0.1379 (0.1499)  loss_objectness: 0.0965 (0.1170)  loss_rpn_box_reg: 0.0281 (0.0465)  time: 0.3323  data: 0.1372  max mem: 4022\n",
      "Training Epoch: [6]  [ 940/1229]  eta: 0:01:33  lr: 0.005000  loss: 0.4110 (0.4779)  loss_classifier: 0.1242 (0.1647)  loss_box_reg: 0.1189 (0.1499)  loss_objectness: 0.0942 (0.1169)  loss_rpn_box_reg: 0.0307 (0.0463)  time: 0.3328  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [6]  [ 950/1229]  eta: 0:01:30  lr: 0.005000  loss: 0.3418 (0.4771)  loss_classifier: 0.1242 (0.1646)  loss_box_reg: 0.1170 (0.1496)  loss_objectness: 0.0915 (0.1167)  loss_rpn_box_reg: 0.0213 (0.0463)  time: 0.3322  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [6]  [ 960/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.3904 (0.4765)  loss_classifier: 0.1258 (0.1644)  loss_box_reg: 0.0985 (0.1491)  loss_objectness: 0.1100 (0.1167)  loss_rpn_box_reg: 0.0327 (0.0463)  time: 0.3294  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [6]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.4085 (0.4760)  loss_classifier: 0.1470 (0.1642)  loss_box_reg: 0.1069 (0.1490)  loss_objectness: 0.0817 (0.1165)  loss_rpn_box_reg: 0.0370 (0.0463)  time: 0.3208  data: 0.1385  max mem: 4022\n",
      "Training Epoch: [6]  [ 980/1229]  eta: 0:01:20  lr: 0.005000  loss: 0.3851 (0.4755)  loss_classifier: 0.1460 (0.1641)  loss_box_reg: 0.1208 (0.1488)  loss_objectness: 0.0817 (0.1165)  loss_rpn_box_reg: 0.0365 (0.0461)  time: 0.3171  data: 0.1412  max mem: 4022\n",
      "Training Epoch: [6]  [ 990/1229]  eta: 0:01:17  lr: 0.005000  loss: 0.3375 (0.4743)  loss_classifier: 0.1186 (0.1637)  loss_box_reg: 0.1198 (0.1484)  loss_objectness: 0.0966 (0.1163)  loss_rpn_box_reg: 0.0200 (0.0459)  time: 0.3201  data: 0.1420  max mem: 4022\n",
      "Training Epoch: [6]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.3351 (0.4735)  loss_classifier: 0.1008 (0.1634)  loss_box_reg: 0.0783 (0.1479)  loss_objectness: 0.0966 (0.1164)  loss_rpn_box_reg: 0.0200 (0.0459)  time: 0.3289  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [6]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.3287 (0.4724)  loss_classifier: 0.1147 (0.1630)  loss_box_reg: 0.0721 (0.1474)  loss_objectness: 0.0910 (0.1162)  loss_rpn_box_reg: 0.0150 (0.0458)  time: 0.3324  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [6]  [1020/1229]  eta: 0:01:07  lr: 0.005000  loss: 0.3292 (0.4723)  loss_classifier: 0.1221 (0.1629)  loss_box_reg: 0.1037 (0.1474)  loss_objectness: 0.0934 (0.1162)  loss_rpn_box_reg: 0.0180 (0.0458)  time: 0.3269  data: 0.1383  max mem: 4022\n",
      "Training Epoch: [6]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.4547 (0.4733)  loss_classifier: 0.1495 (0.1631)  loss_box_reg: 0.1518 (0.1479)  loss_objectness: 0.0934 (0.1163)  loss_rpn_box_reg: 0.0446 (0.0460)  time: 0.3230  data: 0.1392  max mem: 4022\n",
      "Training Epoch: [6]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.4191 (0.4726)  loss_classifier: 0.1463 (0.1630)  loss_box_reg: 0.1463 (0.1479)  loss_objectness: 0.0838 (0.1160)  loss_rpn_box_reg: 0.0446 (0.0458)  time: 0.3224  data: 0.1395  max mem: 4022\n",
      "Training Epoch: [6]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.3524 (0.4725)  loss_classifier: 0.1410 (0.1629)  loss_box_reg: 0.1401 (0.1479)  loss_objectness: 0.0663 (0.1158)  loss_rpn_box_reg: 0.0320 (0.0458)  time: 0.3306  data: 0.1406  max mem: 4022\n",
      "Training Epoch: [6]  [1060/1229]  eta: 0:00:54  lr: 0.005000  loss: 0.3492 (0.4720)  loss_classifier: 0.1355 (0.1628)  loss_box_reg: 0.1175 (0.1479)  loss_objectness: 0.0675 (0.1155)  loss_rpn_box_reg: 0.0320 (0.0458)  time: 0.3257  data: 0.1402  max mem: 4022\n",
      "Training Epoch: [6]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.3204 (0.4714)  loss_classifier: 0.1156 (0.1626)  loss_box_reg: 0.1005 (0.1476)  loss_objectness: 0.0831 (0.1154)  loss_rpn_box_reg: 0.0203 (0.0457)  time: 0.3186  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [6]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.3204 (0.4710)  loss_classifier: 0.1085 (0.1623)  loss_box_reg: 0.0822 (0.1472)  loss_objectness: 0.0917 (0.1156)  loss_rpn_box_reg: 0.0242 (0.0459)  time: 0.3249  data: 0.1420  max mem: 4022\n",
      "Training Epoch: [6]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.5009 (0.4722)  loss_classifier: 0.1759 (0.1627)  loss_box_reg: 0.1593 (0.1478)  loss_objectness: 0.0961 (0.1157)  loss_rpn_box_reg: 0.0242 (0.0460)  time: 0.3313  data: 0.1411  max mem: 4022\n",
      "Training Epoch: [6]  [1100/1229]  eta: 0:00:41  lr: 0.005000  loss: 0.5330 (0.4718)  loss_classifier: 0.1826 (0.1626)  loss_box_reg: 0.1387 (0.1474)  loss_objectness: 0.1018 (0.1159)  loss_rpn_box_reg: 0.0246 (0.0460)  time: 0.3287  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [6]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.4103 (0.4717)  loss_classifier: 0.1307 (0.1624)  loss_box_reg: 0.0874 (0.1471)  loss_objectness: 0.1147 (0.1161)  loss_rpn_box_reg: 0.0259 (0.0460)  time: 0.3228  data: 0.1414  max mem: 4022\n",
      "Training Epoch: [6]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4758 (0.4715)  loss_classifier: 0.1448 (0.1624)  loss_box_reg: 0.1096 (0.1472)  loss_objectness: 0.1131 (0.1160)  loss_rpn_box_reg: 0.0274 (0.0459)  time: 0.3213  data: 0.1403  max mem: 4022\n",
      "Training Epoch: [6]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.4271 (0.4715)  loss_classifier: 0.1568 (0.1624)  loss_box_reg: 0.1242 (0.1470)  loss_objectness: 0.1105 (0.1160)  loss_rpn_box_reg: 0.0224 (0.0460)  time: 0.3257  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [6]  [1140/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.4401 (0.4723)  loss_classifier: 0.1572 (0.1625)  loss_box_reg: 0.1329 (0.1471)  loss_objectness: 0.1175 (0.1164)  loss_rpn_box_reg: 0.0448 (0.0463)  time: 0.3337  data: 0.1457  max mem: 4022\n",
      "Training Epoch: [6]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.4620 (0.4718)  loss_classifier: 0.1583 (0.1623)  loss_box_reg: 0.1288 (0.1469)  loss_objectness: 0.1170 (0.1163)  loss_rpn_box_reg: 0.0411 (0.0462)  time: 0.3310  data: 0.1437  max mem: 4022\n",
      "Training Epoch: [6]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.3945 (0.4718)  loss_classifier: 0.1436 (0.1623)  loss_box_reg: 0.1269 (0.1469)  loss_objectness: 0.1130 (0.1163)  loss_rpn_box_reg: 0.0263 (0.0463)  time: 0.3234  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [6]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.4473 (0.4719)  loss_classifier: 0.1536 (0.1624)  loss_box_reg: 0.1248 (0.1470)  loss_objectness: 0.0988 (0.1163)  loss_rpn_box_reg: 0.0283 (0.0462)  time: 0.3216  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [6]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.4664 (0.4719)  loss_classifier: 0.1475 (0.1622)  loss_box_reg: 0.1247 (0.1468)  loss_objectness: 0.0988 (0.1164)  loss_rpn_box_reg: 0.0283 (0.0464)  time: 0.3232  data: 0.1407  max mem: 4022\n",
      "Training Epoch: [6]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.4303 (0.4715)  loss_classifier: 0.1475 (0.1622)  loss_box_reg: 0.1241 (0.1467)  loss_objectness: 0.1105 (0.1164)  loss_rpn_box_reg: 0.0283 (0.0462)  time: 0.3204  data: 0.1390  max mem: 4022\n",
      "Training Epoch: [6]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.4785 (0.4727)  loss_classifier: 0.1521 (0.1625)  loss_box_reg: 0.1546 (0.1474)  loss_objectness: 0.1105 (0.1164)  loss_rpn_box_reg: 0.0309 (0.0463)  time: 0.3238  data: 0.1384  max mem: 4022\n",
      "Training Epoch: [6]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.5271 (0.4740)  loss_classifier: 0.1996 (0.1630)  loss_box_reg: 0.1768 (0.1482)  loss_objectness: 0.1189 (0.1164)  loss_rpn_box_reg: 0.0366 (0.0464)  time: 0.3288  data: 0.1364  max mem: 4022\n",
      "Training Epoch: [6]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.5271 (0.4744)  loss_classifier: 0.1820 (0.1631)  loss_box_reg: 0.1707 (0.1483)  loss_objectness: 0.1046 (0.1166)  loss_rpn_box_reg: 0.0322 (0.0464)  time: 0.3257  data: 0.1377  max mem: 4022\n",
      "Training Epoch: [6]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.5047 (0.4754)  loss_classifier: 0.1654 (0.1634)  loss_box_reg: 0.1344 (0.1485)  loss_objectness: 0.1046 (0.1169)  loss_rpn_box_reg: 0.0375 (0.0467)  time: 0.3252  data: 0.1382  max mem: 4022\n",
      "Training Epoch: [6] Total time: 0:06:39 (0.3251 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:02:08  model_time: 0.3820 (0.3820)  evaluator_time: 0.0020 (0.0020)  time: 0.4160  data: 0.0300  max mem: 4022\n",
      "Test:  [100/308]  eta: 0:00:32  model_time: 0.1060 (0.1107)  evaluator_time: 0.0040 (0.0068)  time: 0.1568  data: 0.0386  max mem: 4022\n",
      "Test:  [200/308]  eta: 0:00:16  model_time: 0.1110 (0.1096)  evaluator_time: 0.0030 (0.0064)  time: 0.1533  data: 0.0335  max mem: 4022\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0970 (0.1086)  evaluator_time: 0.0040 (0.0063)  time: 0.1476  data: 0.0382  max mem: 4022\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0980 (0.1084)  evaluator_time: 0.0030 (0.0063)  time: 0.1457  data: 0.0374  max mem: 4022\n",
      "Test: Total time: 0:00:47 (0.1536 s / it)\n",
      "Averaged stats: model_time: 0.0980 (0.1084)  evaluator_time: 0.0030 (0.0063)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.17s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.062\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.120\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.083\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
      "Testing Epoch: [6]  [  0/308]  eta: 0:00:50  lr: 0.005000  loss: 0.1650 (0.1650)  loss_classifier: 0.0618 (0.0618)  loss_box_reg: 0.0419 (0.0419)  loss_objectness: 0.0507 (0.0507)  loss_rpn_box_reg: 0.0106 (0.0106)  time: 0.1630  data: 0.0370  max mem: 4022\n",
      "Testing Epoch: [6]  [100/308]  eta: 0:00:38  lr: 0.005000  loss: 0.3440 (0.5204)  loss_classifier: 0.1496 (0.1709)  loss_box_reg: 0.1235 (0.1689)  loss_objectness: 0.0897 (0.1166)  loss_rpn_box_reg: 0.0234 (0.0640)  time: 0.1835  data: 0.0470  max mem: 4022\n",
      "Testing Epoch: [6]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.4584 (0.4935)  loss_classifier: 0.1275 (0.1625)  loss_box_reg: 0.1279 (0.1596)  loss_objectness: 0.0949 (0.1103)  loss_rpn_box_reg: 0.0298 (0.0611)  time: 0.1811  data: 0.0376  max mem: 4022\n",
      "Testing Epoch: [6]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5230 (0.4950)  loss_classifier: 0.1734 (0.1624)  loss_box_reg: 0.1699 (0.1631)  loss_objectness: 0.1086 (0.1090)  loss_rpn_box_reg: 0.0410 (0.0605)  time: 0.1709  data: 0.0437  max mem: 4022\n",
      "Testing Epoch: [6]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.5203 (0.4950)  loss_classifier: 0.1663 (0.1626)  loss_box_reg: 0.1533 (0.1634)  loss_objectness: 0.0994 (0.1089)  loss_rpn_box_reg: 0.0384 (0.0600)  time: 0.1670  data: 0.0400  max mem: 4022\n",
      "Testing Epoch: [6] Total time: 0:00:55 (0.1791 s / it)\n",
      "Training Epoch: [7]  [   0/1229]  eta: 0:07:33  lr: 0.005000  loss: 0.5883 (0.5883)  loss_classifier: 0.2643 (0.2643)  loss_box_reg: 0.1644 (0.1644)  loss_objectness: 0.1448 (0.1448)  loss_rpn_box_reg: 0.0148 (0.0148)  time: 0.3690  data: 0.1810  max mem: 4022\n",
      "Training Epoch: [7]  [  10/1229]  eta: 0:06:33  lr: 0.005000  loss: 0.4369 (0.4671)  loss_classifier: 0.1837 (0.1742)  loss_box_reg: 0.1085 (0.1248)  loss_objectness: 0.1331 (0.1275)  loss_rpn_box_reg: 0.0262 (0.0406)  time: 0.3225  data: 0.1485  max mem: 4022\n",
      "Training Epoch: [7]  [  20/1229]  eta: 0:06:36  lr: 0.005000  loss: 0.3313 (0.3825)  loss_classifier: 0.1154 (0.1409)  loss_box_reg: 0.0900 (0.1083)  loss_objectness: 0.0818 (0.0996)  loss_rpn_box_reg: 0.0216 (0.0337)  time: 0.3258  data: 0.1460  max mem: 4022\n",
      "Training Epoch: [7]  [  30/1229]  eta: 0:06:37  lr: 0.005000  loss: 0.2629 (0.3818)  loss_classifier: 0.0955 (0.1325)  loss_box_reg: 0.0755 (0.1077)  loss_objectness: 0.0772 (0.1047)  loss_rpn_box_reg: 0.0290 (0.0368)  time: 0.3360  data: 0.1439  max mem: 4022\n",
      "Training Epoch: [7]  [  40/1229]  eta: 0:06:30  lr: 0.005000  loss: 0.4411 (0.3946)  loss_classifier: 0.1183 (0.1394)  loss_box_reg: 0.1433 (0.1203)  loss_objectness: 0.0880 (0.1017)  loss_rpn_box_reg: 0.0290 (0.0332)  time: 0.3291  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [7]  [  50/1229]  eta: 0:06:30  lr: 0.005000  loss: 0.3794 (0.4074)  loss_classifier: 0.1483 (0.1424)  loss_box_reg: 0.1433 (0.1231)  loss_objectness: 0.0870 (0.1018)  loss_rpn_box_reg: 0.0219 (0.0401)  time: 0.3302  data: 0.1432  max mem: 4022\n",
      "Training Epoch: [7]  [  60/1229]  eta: 0:06:27  lr: 0.005000  loss: 0.3332 (0.4106)  loss_classifier: 0.1260 (0.1432)  loss_box_reg: 0.1078 (0.1246)  loss_objectness: 0.0870 (0.1026)  loss_rpn_box_reg: 0.0182 (0.0402)  time: 0.3364  data: 0.1428  max mem: 4022\n",
      "Training Epoch: [7]  [  70/1229]  eta: 0:06:21  lr: 0.005000  loss: 0.4536 (0.4171)  loss_classifier: 0.1551 (0.1451)  loss_box_reg: 0.1192 (0.1280)  loss_objectness: 0.1087 (0.1041)  loss_rpn_box_reg: 0.0283 (0.0399)  time: 0.3259  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [7]  [  80/1229]  eta: 0:06:18  lr: 0.005000  loss: 0.4182 (0.4219)  loss_classifier: 0.1578 (0.1460)  loss_box_reg: 0.1192 (0.1252)  loss_objectness: 0.1139 (0.1068)  loss_rpn_box_reg: 0.0230 (0.0441)  time: 0.3246  data: 0.1407  max mem: 4022\n",
      "Training Epoch: [7]  [  90/1229]  eta: 0:06:14  lr: 0.005000  loss: 0.4122 (0.4275)  loss_classifier: 0.1445 (0.1476)  loss_box_reg: 0.1226 (0.1292)  loss_objectness: 0.1013 (0.1077)  loss_rpn_box_reg: 0.0221 (0.0430)  time: 0.3284  data: 0.1397  max mem: 4022\n",
      "Training Epoch: [7]  [ 100/1229]  eta: 0:06:11  lr: 0.005000  loss: 0.4852 (0.4301)  loss_classifier: 0.1613 (0.1489)  loss_box_reg: 0.1357 (0.1294)  loss_objectness: 0.1030 (0.1103)  loss_rpn_box_reg: 0.0282 (0.0415)  time: 0.3285  data: 0.1426  max mem: 4022\n",
      "Training Epoch: [7]  [ 110/1229]  eta: 0:06:08  lr: 0.005000  loss: 0.3889 (0.4296)  loss_classifier: 0.1359 (0.1496)  loss_box_reg: 0.1159 (0.1306)  loss_objectness: 0.0933 (0.1086)  loss_rpn_box_reg: 0.0177 (0.0408)  time: 0.3310  data: 0.1426  max mem: 4022\n",
      "Training Epoch: [7]  [ 120/1229]  eta: 0:06:05  lr: 0.005000  loss: 0.3647 (0.4276)  loss_classifier: 0.1297 (0.1487)  loss_box_reg: 0.1159 (0.1303)  loss_objectness: 0.0863 (0.1088)  loss_rpn_box_reg: 0.0177 (0.0399)  time: 0.3308  data: 0.1425  max mem: 4022\n",
      "Training Epoch: [7]  [ 130/1229]  eta: 0:06:01  lr: 0.005000  loss: 0.3696 (0.4304)  loss_classifier: 0.1431 (0.1491)  loss_box_reg: 0.1136 (0.1309)  loss_objectness: 0.0899 (0.1096)  loss_rpn_box_reg: 0.0307 (0.0409)  time: 0.3248  data: 0.1439  max mem: 4022\n",
      "Training Epoch: [7]  [ 140/1229]  eta: 0:05:58  lr: 0.005000  loss: 0.4159 (0.4314)  loss_classifier: 0.1560 (0.1498)  loss_box_reg: 0.1231 (0.1306)  loss_objectness: 0.0898 (0.1098)  loss_rpn_box_reg: 0.0207 (0.0412)  time: 0.3240  data: 0.1437  max mem: 4022\n",
      "Training Epoch: [7]  [ 150/1229]  eta: 0:05:54  lr: 0.005000  loss: 0.3262 (0.4288)  loss_classifier: 0.1374 (0.1494)  loss_box_reg: 0.0850 (0.1297)  loss_objectness: 0.0898 (0.1091)  loss_rpn_box_reg: 0.0175 (0.0407)  time: 0.3273  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [7]  [ 160/1229]  eta: 0:05:51  lr: 0.005000  loss: 0.4060 (0.4349)  loss_classifier: 0.1685 (0.1519)  loss_box_reg: 0.1419 (0.1325)  loss_objectness: 0.1031 (0.1094)  loss_rpn_box_reg: 0.0207 (0.0411)  time: 0.3283  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [7]  [ 170/1229]  eta: 0:05:48  lr: 0.005000  loss: 0.6278 (0.4469)  loss_classifier: 0.1970 (0.1558)  loss_box_reg: 0.1601 (0.1366)  loss_objectness: 0.1303 (0.1109)  loss_rpn_box_reg: 0.0458 (0.0437)  time: 0.3318  data: 0.1424  max mem: 4022\n",
      "Training Epoch: [7]  [ 180/1229]  eta: 0:05:44  lr: 0.005000  loss: 0.6139 (0.4478)  loss_classifier: 0.1762 (0.1558)  loss_box_reg: 0.1529 (0.1368)  loss_objectness: 0.1018 (0.1117)  loss_rpn_box_reg: 0.0386 (0.0434)  time: 0.3282  data: 0.1403  max mem: 4022\n",
      "Training Epoch: [7]  [ 190/1229]  eta: 0:05:40  lr: 0.005000  loss: 0.4552 (0.4465)  loss_classifier: 0.1474 (0.1560)  loss_box_reg: 0.1175 (0.1370)  loss_objectness: 0.0989 (0.1113)  loss_rpn_box_reg: 0.0239 (0.0422)  time: 0.3214  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [7]  [ 200/1229]  eta: 0:05:37  lr: 0.005000  loss: 0.4552 (0.4501)  loss_classifier: 0.1524 (0.1567)  loss_box_reg: 0.1663 (0.1386)  loss_objectness: 0.0998 (0.1121)  loss_rpn_box_reg: 0.0253 (0.0427)  time: 0.3253  data: 0.1424  max mem: 4022\n",
      "Training Epoch: [7]  [ 210/1229]  eta: 0:05:34  lr: 0.005000  loss: 0.5307 (0.4529)  loss_classifier: 0.1524 (0.1580)  loss_box_reg: 0.1663 (0.1402)  loss_objectness: 0.1040 (0.1123)  loss_rpn_box_reg: 0.0325 (0.0424)  time: 0.3285  data: 0.1441  max mem: 4022\n",
      "Training Epoch: [7]  [ 220/1229]  eta: 0:05:30  lr: 0.005000  loss: 0.3719 (0.4541)  loss_classifier: 0.1474 (0.1588)  loss_box_reg: 0.1098 (0.1411)  loss_objectness: 0.0918 (0.1124)  loss_rpn_box_reg: 0.0157 (0.0418)  time: 0.3251  data: 0.1436  max mem: 4022\n",
      "Training Epoch: [7]  [ 230/1229]  eta: 0:05:27  lr: 0.005000  loss: 0.4707 (0.4548)  loss_classifier: 0.1737 (0.1593)  loss_box_reg: 0.1576 (0.1422)  loss_objectness: 0.0808 (0.1118)  loss_rpn_box_reg: 0.0202 (0.0415)  time: 0.3260  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [7]  [ 240/1229]  eta: 0:05:24  lr: 0.005000  loss: 0.4646 (0.4533)  loss_classifier: 0.1830 (0.1594)  loss_box_reg: 0.1785 (0.1421)  loss_objectness: 0.0888 (0.1111)  loss_rpn_box_reg: 0.0225 (0.0407)  time: 0.3265  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [7]  [ 250/1229]  eta: 0:05:20  lr: 0.005000  loss: 0.4646 (0.4543)  loss_classifier: 0.1830 (0.1599)  loss_box_reg: 0.1644 (0.1438)  loss_objectness: 0.0840 (0.1101)  loss_rpn_box_reg: 0.0230 (0.0404)  time: 0.3218  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [7]  [ 260/1229]  eta: 0:05:17  lr: 0.005000  loss: 0.4261 (0.4522)  loss_classifier: 0.1572 (0.1594)  loss_box_reg: 0.1644 (0.1433)  loss_objectness: 0.0889 (0.1099)  loss_rpn_box_reg: 0.0177 (0.0396)  time: 0.3232  data: 0.1429  max mem: 4022\n",
      "Training Epoch: [7]  [ 270/1229]  eta: 0:05:14  lr: 0.005000  loss: 0.4022 (0.4518)  loss_classifier: 0.1396 (0.1590)  loss_box_reg: 0.0948 (0.1424)  loss_objectness: 0.0984 (0.1105)  loss_rpn_box_reg: 0.0177 (0.0400)  time: 0.3266  data: 0.1404  max mem: 4022\n",
      "Training Epoch: [7]  [ 280/1229]  eta: 0:05:11  lr: 0.005000  loss: 0.3976 (0.4503)  loss_classifier: 0.1370 (0.1588)  loss_box_reg: 0.0961 (0.1412)  loss_objectness: 0.1032 (0.1105)  loss_rpn_box_reg: 0.0210 (0.0398)  time: 0.3305  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [7]  [ 290/1229]  eta: 0:05:07  lr: 0.005000  loss: 0.4076 (0.4494)  loss_classifier: 0.1357 (0.1583)  loss_box_reg: 0.0961 (0.1402)  loss_objectness: 0.0994 (0.1107)  loss_rpn_box_reg: 0.0307 (0.0403)  time: 0.3318  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [7]  [ 300/1229]  eta: 0:05:04  lr: 0.005000  loss: 0.4210 (0.4484)  loss_classifier: 0.1245 (0.1572)  loss_box_reg: 0.0821 (0.1390)  loss_objectness: 0.0889 (0.1107)  loss_rpn_box_reg: 0.0367 (0.0416)  time: 0.3292  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [7]  [ 310/1229]  eta: 0:05:01  lr: 0.005000  loss: 0.4369 (0.4524)  loss_classifier: 0.1355 (0.1584)  loss_box_reg: 0.0997 (0.1399)  loss_objectness: 0.1083 (0.1121)  loss_rpn_box_reg: 0.0366 (0.0420)  time: 0.3248  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [7]  [ 320/1229]  eta: 0:04:57  lr: 0.005000  loss: 0.4144 (0.4517)  loss_classifier: 0.1341 (0.1580)  loss_box_reg: 0.1237 (0.1397)  loss_objectness: 0.1130 (0.1117)  loss_rpn_box_reg: 0.0352 (0.0423)  time: 0.3223  data: 0.1429  max mem: 4022\n",
      "Training Epoch: [7]  [ 330/1229]  eta: 0:04:54  lr: 0.005000  loss: 0.4144 (0.4541)  loss_classifier: 0.1552 (0.1587)  loss_box_reg: 0.1314 (0.1407)  loss_objectness: 0.0867 (0.1123)  loss_rpn_box_reg: 0.0287 (0.0425)  time: 0.3309  data: 0.1433  max mem: 4022\n",
      "Training Epoch: [7]  [ 340/1229]  eta: 0:04:51  lr: 0.005000  loss: 0.4548 (0.4539)  loss_classifier: 0.1648 (0.1584)  loss_box_reg: 0.1305 (0.1405)  loss_objectness: 0.0915 (0.1126)  loss_rpn_box_reg: 0.0261 (0.0425)  time: 0.3370  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [7]  [ 350/1229]  eta: 0:04:48  lr: 0.005000  loss: 0.4867 (0.4591)  loss_classifier: 0.1764 (0.1598)  loss_box_reg: 0.1455 (0.1423)  loss_objectness: 0.1141 (0.1135)  loss_rpn_box_reg: 0.0411 (0.0436)  time: 0.3298  data: 0.1430  max mem: 4022\n",
      "Training Epoch: [7]  [ 360/1229]  eta: 0:04:44  lr: 0.005000  loss: 0.4964 (0.4592)  loss_classifier: 0.1805 (0.1599)  loss_box_reg: 0.1616 (0.1427)  loss_objectness: 0.1079 (0.1135)  loss_rpn_box_reg: 0.0415 (0.0430)  time: 0.3209  data: 0.1442  max mem: 4022\n",
      "Training Epoch: [7]  [ 370/1229]  eta: 0:04:41  lr: 0.005000  loss: 0.3727 (0.4571)  loss_classifier: 0.1070 (0.1591)  loss_box_reg: 0.0966 (0.1420)  loss_objectness: 0.0992 (0.1131)  loss_rpn_box_reg: 0.0129 (0.0429)  time: 0.3255  data: 0.1436  max mem: 4022\n",
      "Training Epoch: [7]  [ 380/1229]  eta: 0:04:38  lr: 0.005000  loss: 0.4453 (0.4613)  loss_classifier: 0.1464 (0.1608)  loss_box_reg: 0.1195 (0.1439)  loss_objectness: 0.1030 (0.1137)  loss_rpn_box_reg: 0.0248 (0.0429)  time: 0.3269  data: 0.1432  max mem: 4022\n",
      "Training Epoch: [7]  [ 390/1229]  eta: 0:04:34  lr: 0.005000  loss: 0.4205 (0.4598)  loss_classifier: 0.1517 (0.1602)  loss_box_reg: 0.1540 (0.1438)  loss_objectness: 0.0915 (0.1132)  loss_rpn_box_reg: 0.0321 (0.0427)  time: 0.3233  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [7]  [ 400/1229]  eta: 0:04:31  lr: 0.005000  loss: 0.3995 (0.4585)  loss_classifier: 0.1430 (0.1599)  loss_box_reg: 0.1432 (0.1435)  loss_objectness: 0.0797 (0.1128)  loss_rpn_box_reg: 0.0207 (0.0422)  time: 0.3202  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [7]  [ 410/1229]  eta: 0:04:27  lr: 0.005000  loss: 0.3995 (0.4562)  loss_classifier: 0.1219 (0.1592)  loss_box_reg: 0.1031 (0.1425)  loss_objectness: 0.0768 (0.1125)  loss_rpn_box_reg: 0.0175 (0.0420)  time: 0.3172  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [7]  [ 420/1229]  eta: 0:04:24  lr: 0.005000  loss: 0.3289 (0.4558)  loss_classifier: 0.1208 (0.1593)  loss_box_reg: 0.0908 (0.1425)  loss_objectness: 0.0933 (0.1122)  loss_rpn_box_reg: 0.0243 (0.0418)  time: 0.3242  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [7]  [ 430/1229]  eta: 0:04:21  lr: 0.005000  loss: 0.4879 (0.4571)  loss_classifier: 0.1749 (0.1599)  loss_box_reg: 0.1424 (0.1432)  loss_objectness: 0.1107 (0.1122)  loss_rpn_box_reg: 0.0332 (0.0418)  time: 0.3334  data: 0.1409  max mem: 4022\n",
      "Training Epoch: [7]  [ 440/1229]  eta: 0:04:18  lr: 0.005000  loss: 0.4879 (0.4585)  loss_classifier: 0.1550 (0.1605)  loss_box_reg: 0.1424 (0.1438)  loss_objectness: 0.1107 (0.1123)  loss_rpn_box_reg: 0.0332 (0.0419)  time: 0.3317  data: 0.1437  max mem: 4022\n",
      "Training Epoch: [7]  [ 450/1229]  eta: 0:04:14  lr: 0.005000  loss: 0.4541 (0.4591)  loss_classifier: 0.1550 (0.1606)  loss_box_reg: 0.1345 (0.1442)  loss_objectness: 0.1015 (0.1120)  loss_rpn_box_reg: 0.0371 (0.0423)  time: 0.3258  data: 0.1425  max mem: 4022\n",
      "Training Epoch: [7]  [ 460/1229]  eta: 0:04:11  lr: 0.005000  loss: 0.4631 (0.4640)  loss_classifier: 0.1717 (0.1618)  loss_box_reg: 0.1563 (0.1460)  loss_objectness: 0.1094 (0.1127)  loss_rpn_box_reg: 0.0517 (0.0436)  time: 0.3160  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [7]  [ 470/1229]  eta: 0:04:07  lr: 0.005000  loss: 0.4631 (0.4652)  loss_classifier: 0.1511 (0.1620)  loss_box_reg: 0.1591 (0.1462)  loss_objectness: 0.1089 (0.1128)  loss_rpn_box_reg: 0.0524 (0.0442)  time: 0.3136  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [7]  [ 480/1229]  eta: 0:04:04  lr: 0.005000  loss: 0.4595 (0.4644)  loss_classifier: 0.1435 (0.1617)  loss_box_reg: 0.1074 (0.1461)  loss_objectness: 0.0947 (0.1124)  loss_rpn_box_reg: 0.0313 (0.0442)  time: 0.3217  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [7]  [ 490/1229]  eta: 0:04:01  lr: 0.005000  loss: 0.4453 (0.4624)  loss_classifier: 0.1171 (0.1609)  loss_box_reg: 0.0939 (0.1453)  loss_objectness: 0.0947 (0.1120)  loss_rpn_box_reg: 0.0222 (0.0442)  time: 0.3230  data: 0.1436  max mem: 4022\n",
      "Training Epoch: [7]  [ 500/1229]  eta: 0:03:58  lr: 0.005000  loss: 0.3135 (0.4615)  loss_classifier: 0.1018 (0.1604)  loss_box_reg: 0.0801 (0.1449)  loss_objectness: 0.0999 (0.1123)  loss_rpn_box_reg: 0.0186 (0.0440)  time: 0.3266  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [7]  [ 510/1229]  eta: 0:03:54  lr: 0.005000  loss: 0.3400 (0.4606)  loss_classifier: 0.1070 (0.1598)  loss_box_reg: 0.0810 (0.1440)  loss_objectness: 0.1085 (0.1127)  loss_rpn_box_reg: 0.0168 (0.0441)  time: 0.3237  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [7]  [ 520/1229]  eta: 0:03:51  lr: 0.005000  loss: 0.3916 (0.4596)  loss_classifier: 0.1324 (0.1596)  loss_box_reg: 0.1112 (0.1436)  loss_objectness: 0.1030 (0.1126)  loss_rpn_box_reg: 0.0319 (0.0438)  time: 0.3178  data: 0.1425  max mem: 4022\n",
      "Training Epoch: [7]  [ 530/1229]  eta: 0:03:48  lr: 0.005000  loss: 0.3916 (0.4603)  loss_classifier: 0.1386 (0.1600)  loss_box_reg: 0.1209 (0.1436)  loss_objectness: 0.1015 (0.1128)  loss_rpn_box_reg: 0.0313 (0.0439)  time: 0.3201  data: 0.1424  max mem: 4022\n",
      "Training Epoch: [7]  [ 540/1229]  eta: 0:03:44  lr: 0.005000  loss: 0.4568 (0.4610)  loss_classifier: 0.1523 (0.1601)  loss_box_reg: 0.1366 (0.1441)  loss_objectness: 0.1016 (0.1127)  loss_rpn_box_reg: 0.0292 (0.0440)  time: 0.3259  data: 0.1438  max mem: 4022\n",
      "Training Epoch: [7]  [ 550/1229]  eta: 0:03:41  lr: 0.005000  loss: 0.3919 (0.4606)  loss_classifier: 0.1523 (0.1601)  loss_box_reg: 0.1162 (0.1439)  loss_objectness: 0.1016 (0.1130)  loss_rpn_box_reg: 0.0186 (0.0437)  time: 0.3263  data: 0.1431  max mem: 4022\n",
      "Training Epoch: [7]  [ 560/1229]  eta: 0:03:38  lr: 0.005000  loss: 0.3583 (0.4606)  loss_classifier: 0.1373 (0.1602)  loss_box_reg: 0.1132 (0.1441)  loss_objectness: 0.0959 (0.1128)  loss_rpn_box_reg: 0.0127 (0.0435)  time: 0.3235  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [7]  [ 570/1229]  eta: 0:03:34  lr: 0.005000  loss: 0.3560 (0.4602)  loss_classifier: 0.1373 (0.1601)  loss_box_reg: 0.1005 (0.1439)  loss_objectness: 0.0760 (0.1126)  loss_rpn_box_reg: 0.0251 (0.0436)  time: 0.3236  data: 0.1441  max mem: 4022\n",
      "Training Epoch: [7]  [ 580/1229]  eta: 0:03:31  lr: 0.005000  loss: 0.4021 (0.4614)  loss_classifier: 0.1293 (0.1606)  loss_box_reg: 0.1120 (0.1444)  loss_objectness: 0.0859 (0.1123)  loss_rpn_box_reg: 0.0387 (0.0440)  time: 0.3300  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [7]  [ 590/1229]  eta: 0:03:28  lr: 0.005000  loss: 0.4021 (0.4609)  loss_classifier: 0.1484 (0.1605)  loss_box_reg: 0.1428 (0.1441)  loss_objectness: 0.0860 (0.1123)  loss_rpn_box_reg: 0.0398 (0.0440)  time: 0.3311  data: 0.1430  max mem: 4022\n",
      "Training Epoch: [7]  [ 600/1229]  eta: 0:03:25  lr: 0.005000  loss: 0.4446 (0.4616)  loss_classifier: 0.1495 (0.1604)  loss_box_reg: 0.1267 (0.1435)  loss_objectness: 0.1199 (0.1136)  loss_rpn_box_reg: 0.0398 (0.0442)  time: 0.3274  data: 0.1440  max mem: 4022\n",
      "Training Epoch: [7]  [ 610/1229]  eta: 0:03:22  lr: 0.005000  loss: 0.3854 (0.4600)  loss_classifier: 0.1231 (0.1598)  loss_box_reg: 0.1043 (0.1426)  loss_objectness: 0.1213 (0.1137)  loss_rpn_box_reg: 0.0292 (0.0439)  time: 0.3296  data: 0.1433  max mem: 4022\n",
      "Training Epoch: [7]  [ 620/1229]  eta: 0:03:18  lr: 0.005000  loss: 0.4300 (0.4614)  loss_classifier: 0.1400 (0.1604)  loss_box_reg: 0.1234 (0.1431)  loss_objectness: 0.1202 (0.1140)  loss_rpn_box_reg: 0.0292 (0.0440)  time: 0.3279  data: 0.1435  max mem: 4022\n",
      "Training Epoch: [7]  [ 630/1229]  eta: 0:03:15  lr: 0.005000  loss: 0.4869 (0.4614)  loss_classifier: 0.1692 (0.1603)  loss_box_reg: 0.1568 (0.1429)  loss_objectness: 0.1247 (0.1142)  loss_rpn_box_reg: 0.0362 (0.0441)  time: 0.3280  data: 0.1426  max mem: 4022\n",
      "Training Epoch: [7]  [ 640/1229]  eta: 0:03:12  lr: 0.005000  loss: 0.4419 (0.4603)  loss_classifier: 0.1287 (0.1598)  loss_box_reg: 0.1216 (0.1423)  loss_objectness: 0.1019 (0.1139)  loss_rpn_box_reg: 0.0328 (0.0444)  time: 0.3361  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [7]  [ 650/1229]  eta: 0:03:09  lr: 0.005000  loss: 0.4109 (0.4608)  loss_classifier: 0.1287 (0.1599)  loss_box_reg: 0.1216 (0.1425)  loss_objectness: 0.0847 (0.1137)  loss_rpn_box_reg: 0.0351 (0.0447)  time: 0.3342  data: 0.1430  max mem: 4022\n",
      "Training Epoch: [7]  [ 660/1229]  eta: 0:03:05  lr: 0.005000  loss: 0.4109 (0.4598)  loss_classifier: 0.1499 (0.1597)  loss_box_reg: 0.1291 (0.1423)  loss_objectness: 0.0935 (0.1134)  loss_rpn_box_reg: 0.0221 (0.0444)  time: 0.3241  data: 0.1432  max mem: 4022\n",
      "Training Epoch: [7]  [ 670/1229]  eta: 0:03:02  lr: 0.005000  loss: 0.3205 (0.4581)  loss_classifier: 0.1130 (0.1592)  loss_box_reg: 0.0837 (0.1416)  loss_objectness: 0.0743 (0.1132)  loss_rpn_box_reg: 0.0184 (0.0442)  time: 0.3272  data: 0.1447  max mem: 4022\n",
      "Training Epoch: [7]  [ 680/1229]  eta: 0:02:59  lr: 0.005000  loss: 0.3593 (0.4582)  loss_classifier: 0.1205 (0.1592)  loss_box_reg: 0.0815 (0.1414)  loss_objectness: 0.0895 (0.1134)  loss_rpn_box_reg: 0.0215 (0.0442)  time: 0.3265  data: 0.1431  max mem: 4022\n",
      "Training Epoch: [7]  [ 690/1229]  eta: 0:02:56  lr: 0.005000  loss: 0.4555 (0.4593)  loss_classifier: 0.1622 (0.1593)  loss_box_reg: 0.1255 (0.1420)  loss_objectness: 0.0981 (0.1136)  loss_rpn_box_reg: 0.0229 (0.0444)  time: 0.3249  data: 0.1420  max mem: 4022\n",
      "Training Epoch: [7]  [ 700/1229]  eta: 0:02:52  lr: 0.005000  loss: 0.3894 (0.4587)  loss_classifier: 0.1444 (0.1591)  loss_box_reg: 0.0805 (0.1414)  loss_objectness: 0.1005 (0.1136)  loss_rpn_box_reg: 0.0229 (0.0446)  time: 0.3339  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [7]  [ 710/1229]  eta: 0:02:49  lr: 0.005000  loss: 0.4255 (0.4594)  loss_classifier: 0.1417 (0.1592)  loss_box_reg: 0.1023 (0.1418)  loss_objectness: 0.0896 (0.1136)  loss_rpn_box_reg: 0.0344 (0.0448)  time: 0.3303  data: 0.1437  max mem: 4022\n",
      "Training Epoch: [7]  [ 720/1229]  eta: 0:02:46  lr: 0.005000  loss: 0.4768 (0.4600)  loss_classifier: 0.1417 (0.1592)  loss_box_reg: 0.1523 (0.1420)  loss_objectness: 0.0923 (0.1137)  loss_rpn_box_reg: 0.0503 (0.0451)  time: 0.3232  data: 0.1444  max mem: 4022\n",
      "Training Epoch: [7]  [ 730/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.5036 (0.4622)  loss_classifier: 0.1732 (0.1599)  loss_box_reg: 0.1575 (0.1428)  loss_objectness: 0.1228 (0.1140)  loss_rpn_box_reg: 0.0494 (0.0454)  time: 0.3233  data: 0.1449  max mem: 4022\n",
      "Training Epoch: [7]  [ 740/1229]  eta: 0:02:39  lr: 0.005000  loss: 0.4999 (0.4616)  loss_classifier: 0.1579 (0.1596)  loss_box_reg: 0.1482 (0.1426)  loss_objectness: 0.1229 (0.1138)  loss_rpn_box_reg: 0.0463 (0.0455)  time: 0.3297  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [7]  [ 750/1229]  eta: 0:02:36  lr: 0.005000  loss: 0.3392 (0.4612)  loss_classifier: 0.1184 (0.1593)  loss_box_reg: 0.0949 (0.1426)  loss_objectness: 0.0838 (0.1136)  loss_rpn_box_reg: 0.0329 (0.0457)  time: 0.3365  data: 0.1422  max mem: 4022\n",
      "Training Epoch: [7]  [ 760/1229]  eta: 0:02:33  lr: 0.005000  loss: 0.4510 (0.4627)  loss_classifier: 0.1454 (0.1598)  loss_box_reg: 0.1204 (0.1428)  loss_objectness: 0.1045 (0.1139)  loss_rpn_box_reg: 0.0425 (0.0462)  time: 0.3329  data: 0.1481  max mem: 4022\n",
      "Training Epoch: [7]  [ 770/1229]  eta: 0:02:30  lr: 0.005000  loss: 0.5344 (0.4630)  loss_classifier: 0.1744 (0.1597)  loss_box_reg: 0.1353 (0.1429)  loss_objectness: 0.1120 (0.1138)  loss_rpn_box_reg: 0.0539 (0.0466)  time: 0.3306  data: 0.1479  max mem: 4022\n",
      "Training Epoch: [7]  [ 780/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.4078 (0.4627)  loss_classifier: 0.1589 (0.1599)  loss_box_reg: 0.1352 (0.1429)  loss_objectness: 0.0852 (0.1136)  loss_rpn_box_reg: 0.0302 (0.0464)  time: 0.3340  data: 0.1456  max mem: 4022\n",
      "Training Epoch: [7]  [ 790/1229]  eta: 0:02:23  lr: 0.005000  loss: 0.4078 (0.4622)  loss_classifier: 0.1442 (0.1596)  loss_box_reg: 0.1196 (0.1427)  loss_objectness: 0.0852 (0.1134)  loss_rpn_box_reg: 0.0223 (0.0465)  time: 0.3314  data: 0.1450  max mem: 4022\n",
      "Training Epoch: [7]  [ 800/1229]  eta: 0:02:20  lr: 0.005000  loss: 0.4100 (0.4625)  loss_classifier: 0.1163 (0.1596)  loss_box_reg: 0.0993 (0.1425)  loss_objectness: 0.0914 (0.1136)  loss_rpn_box_reg: 0.0350 (0.0468)  time: 0.3258  data: 0.1461  max mem: 4022\n",
      "Training Epoch: [7]  [ 810/1229]  eta: 0:02:17  lr: 0.005000  loss: 0.3932 (0.4614)  loss_classifier: 0.1163 (0.1591)  loss_box_reg: 0.0912 (0.1424)  loss_objectness: 0.0998 (0.1134)  loss_rpn_box_reg: 0.0299 (0.0465)  time: 0.3284  data: 0.1448  max mem: 4022\n",
      "Training Epoch: [7]  [ 820/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.3175 (0.4607)  loss_classifier: 0.0941 (0.1588)  loss_box_reg: 0.0687 (0.1418)  loss_objectness: 0.0917 (0.1136)  loss_rpn_box_reg: 0.0261 (0.0465)  time: 0.3342  data: 0.1451  max mem: 4022\n",
      "Training Epoch: [7]  [ 830/1229]  eta: 0:02:10  lr: 0.005000  loss: 0.2706 (0.4594)  loss_classifier: 0.0941 (0.1584)  loss_box_reg: 0.0687 (0.1414)  loss_objectness: 0.0985 (0.1134)  loss_rpn_box_reg: 0.0208 (0.0463)  time: 0.3347  data: 0.1478  max mem: 4022\n",
      "Training Epoch: [7]  [ 840/1229]  eta: 0:02:07  lr: 0.005000  loss: 0.4392 (0.4599)  loss_classifier: 0.1494 (0.1584)  loss_box_reg: 0.1152 (0.1417)  loss_objectness: 0.1044 (0.1136)  loss_rpn_box_reg: 0.0253 (0.0463)  time: 0.3266  data: 0.1456  max mem: 4022\n",
      "Training Epoch: [7]  [ 850/1229]  eta: 0:02:04  lr: 0.005000  loss: 0.4392 (0.4597)  loss_classifier: 0.1363 (0.1583)  loss_box_reg: 0.1152 (0.1416)  loss_objectness: 0.1115 (0.1136)  loss_rpn_box_reg: 0.0297 (0.0462)  time: 0.3271  data: 0.1444  max mem: 4022\n",
      "Training Epoch: [7]  [ 860/1229]  eta: 0:02:00  lr: 0.005000  loss: 0.3368 (0.4590)  loss_classifier: 0.1292 (0.1581)  loss_box_reg: 0.0665 (0.1416)  loss_objectness: 0.0690 (0.1133)  loss_rpn_box_reg: 0.0176 (0.0461)  time: 0.3353  data: 0.1441  max mem: 4022\n",
      "Training Epoch: [7]  [ 870/1229]  eta: 0:01:57  lr: 0.005000  loss: 0.3709 (0.4589)  loss_classifier: 0.1188 (0.1581)  loss_box_reg: 0.0980 (0.1414)  loss_objectness: 0.0791 (0.1133)  loss_rpn_box_reg: 0.0269 (0.0461)  time: 0.3317  data: 0.1449  max mem: 4022\n",
      "Training Epoch: [7]  [ 880/1229]  eta: 0:01:54  lr: 0.005000  loss: 0.3719 (0.4584)  loss_classifier: 0.1188 (0.1579)  loss_box_reg: 0.1077 (0.1412)  loss_objectness: 0.0915 (0.1134)  loss_rpn_box_reg: 0.0204 (0.0459)  time: 0.3273  data: 0.1467  max mem: 4022\n",
      "Training Epoch: [7]  [ 890/1229]  eta: 0:01:51  lr: 0.005000  loss: 0.3694 (0.4571)  loss_classifier: 0.1264 (0.1575)  loss_box_reg: 0.1049 (0.1407)  loss_objectness: 0.0796 (0.1132)  loss_rpn_box_reg: 0.0160 (0.0457)  time: 0.3313  data: 0.1467  max mem: 4022\n",
      "Training Epoch: [7]  [ 900/1229]  eta: 0:01:47  lr: 0.005000  loss: 0.3449 (0.4565)  loss_classifier: 0.1190 (0.1573)  loss_box_reg: 0.0966 (0.1405)  loss_objectness: 0.0871 (0.1132)  loss_rpn_box_reg: 0.0244 (0.0456)  time: 0.3348  data: 0.1481  max mem: 4022\n",
      "Training Epoch: [7]  [ 910/1229]  eta: 0:01:44  lr: 0.005000  loss: 0.4728 (0.4582)  loss_classifier: 0.1467 (0.1577)  loss_box_reg: 0.1247 (0.1411)  loss_objectness: 0.1053 (0.1136)  loss_rpn_box_reg: 0.0294 (0.0458)  time: 0.3323  data: 0.1469  max mem: 4022\n",
      "Training Epoch: [7]  [ 920/1229]  eta: 0:01:41  lr: 0.005000  loss: 0.6090 (0.4604)  loss_classifier: 0.2086 (0.1585)  loss_box_reg: 0.1932 (0.1420)  loss_objectness: 0.1392 (0.1140)  loss_rpn_box_reg: 0.0396 (0.0459)  time: 0.3265  data: 0.1464  max mem: 4022\n",
      "Training Epoch: [7]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.5161 (0.4601)  loss_classifier: 0.1845 (0.1585)  loss_box_reg: 0.1695 (0.1421)  loss_objectness: 0.1074 (0.1137)  loss_rpn_box_reg: 0.0271 (0.0457)  time: 0.3273  data: 0.1483  max mem: 4022\n",
      "Training Epoch: [7]  [ 940/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.3610 (0.4598)  loss_classifier: 0.1314 (0.1584)  loss_box_reg: 0.1069 (0.1419)  loss_objectness: 0.0813 (0.1139)  loss_rpn_box_reg: 0.0150 (0.0456)  time: 0.3318  data: 0.1484  max mem: 4022\n",
      "Training Epoch: [7]  [ 950/1229]  eta: 0:01:31  lr: 0.005000  loss: 0.3017 (0.4584)  loss_classifier: 0.1044 (0.1579)  loss_box_reg: 0.0865 (0.1413)  loss_objectness: 0.0659 (0.1136)  loss_rpn_box_reg: 0.0230 (0.0456)  time: 0.3282  data: 0.1461  max mem: 4022\n",
      "Training Epoch: [7]  [ 960/1229]  eta: 0:01:28  lr: 0.005000  loss: 0.4024 (0.4590)  loss_classifier: 0.1235 (0.1582)  loss_box_reg: 0.1047 (0.1415)  loss_objectness: 0.0759 (0.1137)  loss_rpn_box_reg: 0.0269 (0.0456)  time: 0.3346  data: 0.1462  max mem: 4022\n",
      "Training Epoch: [7]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.4141 (0.4585)  loss_classifier: 0.1703 (0.1581)  loss_box_reg: 0.1090 (0.1412)  loss_objectness: 0.0754 (0.1137)  loss_rpn_box_reg: 0.0233 (0.0455)  time: 0.3399  data: 0.1488  max mem: 4022\n",
      "Training Epoch: [7]  [ 980/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.3202 (0.4575)  loss_classifier: 0.1102 (0.1577)  loss_box_reg: 0.0826 (0.1407)  loss_objectness: 0.0896 (0.1137)  loss_rpn_box_reg: 0.0217 (0.0453)  time: 0.3258  data: 0.1475  max mem: 4022\n",
      "Training Epoch: [7]  [ 990/1229]  eta: 0:01:18  lr: 0.005000  loss: 0.3978 (0.4571)  loss_classifier: 0.1279 (0.1576)  loss_box_reg: 0.0922 (0.1406)  loss_objectness: 0.1032 (0.1136)  loss_rpn_box_reg: 0.0257 (0.0453)  time: 0.3261  data: 0.1476  max mem: 4022\n",
      "Training Epoch: [7]  [1000/1229]  eta: 0:01:15  lr: 0.005000  loss: 0.3998 (0.4570)  loss_classifier: 0.1310 (0.1576)  loss_box_reg: 0.1097 (0.1408)  loss_objectness: 0.0753 (0.1134)  loss_rpn_box_reg: 0.0202 (0.0452)  time: 0.3356  data: 0.1472  max mem: 4022\n",
      "Training Epoch: [7]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.4302 (0.4575)  loss_classifier: 0.1310 (0.1577)  loss_box_reg: 0.1520 (0.1413)  loss_objectness: 0.0855 (0.1133)  loss_rpn_box_reg: 0.0202 (0.0451)  time: 0.3315  data: 0.1454  max mem: 4022\n",
      "Training Epoch: [7]  [1020/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.5300 (0.4591)  loss_classifier: 0.1791 (0.1582)  loss_box_reg: 0.1617 (0.1419)  loss_objectness: 0.1169 (0.1136)  loss_rpn_box_reg: 0.0277 (0.0454)  time: 0.3285  data: 0.1483  max mem: 4022\n",
      "Training Epoch: [7]  [1030/1229]  eta: 0:01:05  lr: 0.005000  loss: 0.4788 (0.4590)  loss_classifier: 0.1534 (0.1581)  loss_box_reg: 0.1460 (0.1419)  loss_objectness: 0.0845 (0.1135)  loss_rpn_box_reg: 0.0506 (0.0454)  time: 0.3337  data: 0.1489  max mem: 4022\n",
      "Training Epoch: [7]  [1040/1229]  eta: 0:01:02  lr: 0.005000  loss: 0.4259 (0.4593)  loss_classifier: 0.1341 (0.1583)  loss_box_reg: 0.1409 (0.1419)  loss_objectness: 0.1088 (0.1137)  loss_rpn_box_reg: 0.0298 (0.0454)  time: 0.3356  data: 0.1477  max mem: 4022\n",
      "Training Epoch: [7]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.4179 (0.4587)  loss_classifier: 0.1266 (0.1580)  loss_box_reg: 0.0945 (0.1418)  loss_objectness: 0.1117 (0.1136)  loss_rpn_box_reg: 0.0271 (0.0454)  time: 0.3348  data: 0.1551  max mem: 4022\n",
      "Training Epoch: [7]  [1060/1229]  eta: 0:00:55  lr: 0.005000  loss: 0.4770 (0.4602)  loss_classifier: 0.1378 (0.1585)  loss_box_reg: 0.1117 (0.1422)  loss_objectness: 0.1121 (0.1139)  loss_rpn_box_reg: 0.0243 (0.0456)  time: 0.3366  data: 0.1578  max mem: 4022\n",
      "Training Epoch: [7]  [1070/1229]  eta: 0:00:52  lr: 0.005000  loss: 0.5307 (0.4595)  loss_classifier: 0.1766 (0.1584)  loss_box_reg: 0.1466 (0.1418)  loss_objectness: 0.1170 (0.1139)  loss_rpn_box_reg: 0.0253 (0.0454)  time: 0.3359  data: 0.1514  max mem: 4022\n",
      "Training Epoch: [7]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.3394 (0.4596)  loss_classifier: 0.1298 (0.1584)  loss_box_reg: 0.0950 (0.1418)  loss_objectness: 0.1125 (0.1140)  loss_rpn_box_reg: 0.0233 (0.0454)  time: 0.3284  data: 0.1492  max mem: 4022\n",
      "Training Epoch: [7]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.3983 (0.4592)  loss_classifier: 0.1499 (0.1583)  loss_box_reg: 0.0950 (0.1417)  loss_objectness: 0.1219 (0.1139)  loss_rpn_box_reg: 0.0220 (0.0453)  time: 0.3320  data: 0.1475  max mem: 4022\n",
      "Training Epoch: [7]  [1100/1229]  eta: 0:00:42  lr: 0.005000  loss: 0.3952 (0.4595)  loss_classifier: 0.1383 (0.1584)  loss_box_reg: 0.0929 (0.1418)  loss_objectness: 0.1167 (0.1140)  loss_rpn_box_reg: 0.0255 (0.0452)  time: 0.3368  data: 0.1463  max mem: 4022\n",
      "Training Epoch: [7]  [1110/1229]  eta: 0:00:39  lr: 0.005000  loss: 0.3952 (0.4592)  loss_classifier: 0.1293 (0.1584)  loss_box_reg: 0.0932 (0.1420)  loss_objectness: 0.0879 (0.1138)  loss_rpn_box_reg: 0.0251 (0.0451)  time: 0.3358  data: 0.1472  max mem: 4022\n",
      "Training Epoch: [7]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.3457 (0.4586)  loss_classifier: 0.1269 (0.1582)  loss_box_reg: 0.1207 (0.1418)  loss_objectness: 0.0802 (0.1136)  loss_rpn_box_reg: 0.0108 (0.0450)  time: 0.3358  data: 0.1475  max mem: 4022\n",
      "Training Epoch: [7]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.3078 (0.4584)  loss_classifier: 0.1269 (0.1582)  loss_box_reg: 0.1207 (0.1421)  loss_objectness: 0.0737 (0.1133)  loss_rpn_box_reg: 0.0140 (0.0448)  time: 0.3366  data: 0.1450  max mem: 4022\n",
      "Training Epoch: [7]  [1140/1229]  eta: 0:00:29  lr: 0.005000  loss: 0.3811 (0.4583)  loss_classifier: 0.1343 (0.1582)  loss_box_reg: 0.1170 (0.1419)  loss_objectness: 0.0709 (0.1135)  loss_rpn_box_reg: 0.0221 (0.0448)  time: 0.3320  data: 0.1452  max mem: 4022\n",
      "Training Epoch: [7]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.3511 (0.4582)  loss_classifier: 0.1552 (0.1582)  loss_box_reg: 0.1149 (0.1420)  loss_objectness: 0.0809 (0.1132)  loss_rpn_box_reg: 0.0287 (0.0448)  time: 0.3361  data: 0.1482  max mem: 4022\n",
      "Training Epoch: [7]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.4320 (0.4594)  loss_classifier: 0.1552 (0.1586)  loss_box_reg: 0.1215 (0.1425)  loss_objectness: 0.0828 (0.1133)  loss_rpn_box_reg: 0.0317 (0.0449)  time: 0.3347  data: 0.1441  max mem: 4022\n",
      "Training Epoch: [7]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.4946 (0.4601)  loss_classifier: 0.1664 (0.1589)  loss_box_reg: 0.1597 (0.1429)  loss_objectness: 0.1006 (0.1134)  loss_rpn_box_reg: 0.0285 (0.0448)  time: 0.3261  data: 0.1420  max mem: 4022\n",
      "Training Epoch: [7]  [1180/1229]  eta: 0:00:16  lr: 0.005000  loss: 0.5409 (0.4607)  loss_classifier: 0.1565 (0.1591)  loss_box_reg: 0.1535 (0.1432)  loss_objectness: 0.1009 (0.1136)  loss_rpn_box_reg: 0.0259 (0.0449)  time: 0.3303  data: 0.1474  max mem: 4022\n",
      "Training Epoch: [7]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.4234 (0.4604)  loss_classifier: 0.1143 (0.1590)  loss_box_reg: 0.1025 (0.1429)  loss_objectness: 0.0984 (0.1137)  loss_rpn_box_reg: 0.0344 (0.0449)  time: 0.3339  data: 0.1477  max mem: 4022\n",
      "Training Epoch: [7]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.3995 (0.4607)  loss_classifier: 0.1106 (0.1591)  loss_box_reg: 0.0996 (0.1429)  loss_objectness: 0.1125 (0.1138)  loss_rpn_box_reg: 0.0304 (0.0449)  time: 0.3323  data: 0.1469  max mem: 4022\n",
      "Training Epoch: [7]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.4026 (0.4605)  loss_classifier: 0.1536 (0.1591)  loss_box_reg: 0.1291 (0.1429)  loss_objectness: 0.1125 (0.1137)  loss_rpn_box_reg: 0.0267 (0.0449)  time: 0.3259  data: 0.1463  max mem: 4022\n",
      "Training Epoch: [7]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.4170 (0.4605)  loss_classifier: 0.1453 (0.1590)  loss_box_reg: 0.1023 (0.1427)  loss_objectness: 0.1032 (0.1138)  loss_rpn_box_reg: 0.0334 (0.0450)  time: 0.3307  data: 0.1456  max mem: 4022\n",
      "Training Epoch: [7]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4026 (0.4604)  loss_classifier: 0.1475 (0.1589)  loss_box_reg: 0.1023 (0.1426)  loss_objectness: 0.1032 (0.1138)  loss_rpn_box_reg: 0.0234 (0.0450)  time: 0.3347  data: 0.1470  max mem: 4022\n",
      "Training Epoch: [7] Total time: 0:06:44 (0.3289 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:02:37  model_time: 0.3600 (0.3600)  evaluator_time: 0.0030 (0.0030)  time: 0.5110  data: 0.1450  max mem: 4022\n",
      "Test:  [100/308]  eta: 0:00:34  model_time: 0.1060 (0.1145)  evaluator_time: 0.0080 (0.0095)  time: 0.1706  data: 0.0459  max mem: 4022\n",
      "Test:  [200/308]  eta: 0:00:17  model_time: 0.1150 (0.1131)  evaluator_time: 0.0040 (0.0084)  time: 0.1644  data: 0.0398  max mem: 4022\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.1020 (0.1119)  evaluator_time: 0.0060 (0.0083)  time: 0.1596  data: 0.0455  max mem: 4022\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.1020 (0.1117)  evaluator_time: 0.0040 (0.0083)  time: 0.1562  data: 0.0437  max mem: 4022\n",
      "Test: Total time: 0:00:49 (0.1606 s / it)\n",
      "Averaged stats: model_time: 0.1020 (0.1117)  evaluator_time: 0.0040 (0.0083)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.080\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.137\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.096\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.252\n",
      "Testing Epoch: [7]  [  0/308]  eta: 0:00:49  lr: 0.005000  loss: 0.2144 (0.2144)  loss_classifier: 0.0931 (0.0931)  loss_box_reg: 0.0655 (0.0655)  loss_objectness: 0.0491 (0.0491)  loss_rpn_box_reg: 0.0067 (0.0067)  time: 0.1600  data: 0.0360  max mem: 4022\n",
      "Testing Epoch: [7]  [100/308]  eta: 0:00:37  lr: 0.005000  loss: 0.3363 (0.5022)  loss_classifier: 0.1256 (0.1644)  loss_box_reg: 0.1293 (0.1629)  loss_objectness: 0.0767 (0.1166)  loss_rpn_box_reg: 0.0233 (0.0582)  time: 0.1861  data: 0.0479  max mem: 4022\n",
      "Testing Epoch: [7]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.3954 (0.4788)  loss_classifier: 0.1392 (0.1583)  loss_box_reg: 0.1395 (0.1556)  loss_objectness: 0.0900 (0.1097)  loss_rpn_box_reg: 0.0270 (0.0551)  time: 0.1813  data: 0.0369  max mem: 4022\n",
      "Testing Epoch: [7]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.5352 (0.4790)  loss_classifier: 0.1700 (0.1594)  loss_box_reg: 0.1508 (0.1585)  loss_objectness: 0.1018 (0.1074)  loss_rpn_box_reg: 0.0283 (0.0537)  time: 0.1784  data: 0.0490  max mem: 4022\n",
      "Testing Epoch: [7]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.4645 (0.4788)  loss_classifier: 0.1526 (0.1595)  loss_box_reg: 0.1450 (0.1587)  loss_objectness: 0.0947 (0.1074)  loss_rpn_box_reg: 0.0247 (0.0532)  time: 0.1760  data: 0.0461  max mem: 4022\n",
      "Testing Epoch: [7] Total time: 0:00:55 (0.1796 s / it)\n",
      "Training Epoch: [8]  [   0/1229]  eta: 0:06:23  lr: 0.005000  loss: 0.3284 (0.3284)  loss_classifier: 0.1267 (0.1267)  loss_box_reg: 0.1099 (0.1099)  loss_objectness: 0.0853 (0.0853)  loss_rpn_box_reg: 0.0065 (0.0065)  time: 0.3120  data: 0.1440  max mem: 4022\n",
      "Training Epoch: [8]  [  10/1229]  eta: 0:06:36  lr: 0.005000  loss: 0.3284 (0.4061)  loss_classifier: 0.1267 (0.1376)  loss_box_reg: 0.1089 (0.1269)  loss_objectness: 0.0717 (0.0967)  loss_rpn_box_reg: 0.0126 (0.0449)  time: 0.3254  data: 0.1380  max mem: 4022\n",
      "Training Epoch: [8]  [  20/1229]  eta: 0:06:27  lr: 0.005000  loss: 0.3685 (0.4006)  loss_classifier: 0.1212 (0.1416)  loss_box_reg: 0.1071 (0.1264)  loss_objectness: 0.0707 (0.0936)  loss_rpn_box_reg: 0.0158 (0.0391)  time: 0.3210  data: 0.1369  max mem: 4022\n",
      "Training Epoch: [8]  [  30/1229]  eta: 0:06:23  lr: 0.005000  loss: 0.3591 (0.3940)  loss_classifier: 0.1025 (0.1370)  loss_box_reg: 0.1005 (0.1172)  loss_objectness: 0.0934 (0.0965)  loss_rpn_box_reg: 0.0212 (0.0433)  time: 0.3168  data: 0.1358  max mem: 4022\n",
      "Training Epoch: [8]  [  40/1229]  eta: 0:06:19  lr: 0.005000  loss: 0.3138 (0.3895)  loss_classifier: 0.1004 (0.1371)  loss_box_reg: 0.0972 (0.1177)  loss_objectness: 0.0934 (0.0957)  loss_rpn_box_reg: 0.0181 (0.0390)  time: 0.3181  data: 0.1372  max mem: 4022\n",
      "Training Epoch: [8]  [  50/1229]  eta: 0:06:17  lr: 0.005000  loss: 0.4305 (0.4245)  loss_classifier: 0.1474 (0.1478)  loss_box_reg: 0.1196 (0.1273)  loss_objectness: 0.1074 (0.1065)  loss_rpn_box_reg: 0.0221 (0.0429)  time: 0.3214  data: 0.1385  max mem: 4022\n",
      "Training Epoch: [8]  [  60/1229]  eta: 0:06:15  lr: 0.005000  loss: 0.5292 (0.4409)  loss_classifier: 0.1824 (0.1535)  loss_box_reg: 0.1484 (0.1353)  loss_objectness: 0.1074 (0.1044)  loss_rpn_box_reg: 0.0195 (0.0477)  time: 0.3261  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [8]  [  70/1229]  eta: 0:06:13  lr: 0.005000  loss: 0.3372 (0.4340)  loss_classifier: 0.1310 (0.1512)  loss_box_reg: 0.1098 (0.1327)  loss_objectness: 0.0827 (0.1015)  loss_rpn_box_reg: 0.0195 (0.0485)  time: 0.3270  data: 0.1375  max mem: 4022\n",
      "Training Epoch: [8]  [  80/1229]  eta: 0:06:10  lr: 0.005000  loss: 0.3222 (0.4259)  loss_classifier: 0.1112 (0.1480)  loss_box_reg: 0.0782 (0.1305)  loss_objectness: 0.0768 (0.0998)  loss_rpn_box_reg: 0.0310 (0.0476)  time: 0.3241  data: 0.1371  max mem: 4022\n",
      "Training Epoch: [8]  [  90/1229]  eta: 0:06:07  lr: 0.005000  loss: 0.3690 (0.4321)  loss_classifier: 0.1209 (0.1512)  loss_box_reg: 0.1107 (0.1336)  loss_objectness: 0.0824 (0.1001)  loss_rpn_box_reg: 0.0263 (0.0472)  time: 0.3248  data: 0.1387  max mem: 4022\n",
      "Training Epoch: [8]  [ 100/1229]  eta: 0:06:04  lr: 0.005000  loss: 0.4506 (0.4353)  loss_classifier: 0.1594 (0.1523)  loss_box_reg: 0.1052 (0.1333)  loss_objectness: 0.0924 (0.1017)  loss_rpn_box_reg: 0.0301 (0.0480)  time: 0.3233  data: 0.1391  max mem: 4022\n",
      "Training Epoch: [8]  [ 110/1229]  eta: 0:06:00  lr: 0.005000  loss: 0.4125 (0.4342)  loss_classifier: 0.1410 (0.1520)  loss_box_reg: 0.0942 (0.1339)  loss_objectness: 0.0981 (0.1013)  loss_rpn_box_reg: 0.0301 (0.0470)  time: 0.3197  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [8]  [ 120/1229]  eta: 0:05:58  lr: 0.005000  loss: 0.3745 (0.4337)  loss_classifier: 0.1160 (0.1506)  loss_box_reg: 0.0923 (0.1343)  loss_objectness: 0.0978 (0.1023)  loss_rpn_box_reg: 0.0387 (0.0465)  time: 0.3266  data: 0.1425  max mem: 4022\n",
      "Training Epoch: [8]  [ 130/1229]  eta: 0:05:55  lr: 0.005000  loss: 0.3745 (0.4338)  loss_classifier: 0.1105 (0.1499)  loss_box_reg: 0.0906 (0.1325)  loss_objectness: 0.0916 (0.1022)  loss_rpn_box_reg: 0.0410 (0.0492)  time: 0.3321  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [8]  [ 140/1229]  eta: 0:05:52  lr: 0.005000  loss: 0.2917 (0.4270)  loss_classifier: 0.1044 (0.1482)  loss_box_reg: 0.0927 (0.1309)  loss_objectness: 0.0855 (0.1010)  loss_rpn_box_reg: 0.0181 (0.0468)  time: 0.3264  data: 0.1400  max mem: 4022\n",
      "Training Epoch: [8]  [ 150/1229]  eta: 0:05:49  lr: 0.005000  loss: 0.3124 (0.4247)  loss_classifier: 0.1101 (0.1486)  loss_box_reg: 0.0927 (0.1297)  loss_objectness: 0.0845 (0.1007)  loss_rpn_box_reg: 0.0178 (0.0457)  time: 0.3244  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [8]  [ 160/1229]  eta: 0:05:46  lr: 0.005000  loss: 0.3124 (0.4169)  loss_classifier: 0.1055 (0.1459)  loss_box_reg: 0.0702 (0.1260)  loss_objectness: 0.0728 (0.0994)  loss_rpn_box_reg: 0.0225 (0.0456)  time: 0.3289  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [8]  [ 170/1229]  eta: 0:05:42  lr: 0.005000  loss: 0.3488 (0.4213)  loss_classifier: 0.1071 (0.1464)  loss_box_reg: 0.0935 (0.1276)  loss_objectness: 0.0690 (0.1001)  loss_rpn_box_reg: 0.0301 (0.0473)  time: 0.3222  data: 0.1383  max mem: 4022\n",
      "Training Epoch: [8]  [ 180/1229]  eta: 0:05:39  lr: 0.005000  loss: 0.3913 (0.4196)  loss_classifier: 0.1291 (0.1460)  loss_box_reg: 0.0996 (0.1270)  loss_objectness: 0.0969 (0.1000)  loss_rpn_box_reg: 0.0306 (0.0465)  time: 0.3173  data: 0.1381  max mem: 4022\n",
      "Training Epoch: [8]  [ 190/1229]  eta: 0:05:36  lr: 0.005000  loss: 0.4714 (0.4279)  loss_classifier: 0.1795 (0.1496)  loss_box_reg: 0.1166 (0.1299)  loss_objectness: 0.1057 (0.1012)  loss_rpn_box_reg: 0.0367 (0.0472)  time: 0.3259  data: 0.1378  max mem: 4022\n",
      "Training Epoch: [8]  [ 200/1229]  eta: 0:05:33  lr: 0.005000  loss: 0.4970 (0.4271)  loss_classifier: 0.1844 (0.1500)  loss_box_reg: 0.1349 (0.1300)  loss_objectness: 0.1057 (0.1010)  loss_rpn_box_reg: 0.0345 (0.0461)  time: 0.3253  data: 0.1381  max mem: 4022\n",
      "Training Epoch: [8]  [ 210/1229]  eta: 0:05:30  lr: 0.005000  loss: 0.4373 (0.4264)  loss_classifier: 0.1465 (0.1496)  loss_box_reg: 0.1349 (0.1310)  loss_objectness: 0.0869 (0.1008)  loss_rpn_box_reg: 0.0274 (0.0450)  time: 0.3257  data: 0.1373  max mem: 4022\n",
      "Training Epoch: [8]  [ 220/1229]  eta: 0:05:26  lr: 0.005000  loss: 0.4353 (0.4264)  loss_classifier: 0.1524 (0.1497)  loss_box_reg: 0.1444 (0.1320)  loss_objectness: 0.0754 (0.1004)  loss_rpn_box_reg: 0.0245 (0.0443)  time: 0.3266  data: 0.1380  max mem: 4022\n",
      "Training Epoch: [8]  [ 230/1229]  eta: 0:05:23  lr: 0.005000  loss: 0.4619 (0.4340)  loss_classifier: 0.1598 (0.1516)  loss_box_reg: 0.1625 (0.1354)  loss_objectness: 0.1024 (0.1022)  loss_rpn_box_reg: 0.0320 (0.0449)  time: 0.3218  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [8]  [ 240/1229]  eta: 0:05:20  lr: 0.005000  loss: 0.4481 (0.4333)  loss_classifier: 0.1439 (0.1517)  loss_box_reg: 0.1426 (0.1356)  loss_objectness: 0.1038 (0.1020)  loss_rpn_box_reg: 0.0275 (0.0441)  time: 0.3226  data: 0.1381  max mem: 4022\n",
      "Training Epoch: [8]  [ 250/1229]  eta: 0:05:17  lr: 0.005000  loss: 0.3891 (0.4319)  loss_classifier: 0.1590 (0.1519)  loss_box_reg: 0.1073 (0.1345)  loss_objectness: 0.1038 (0.1020)  loss_rpn_box_reg: 0.0259 (0.0435)  time: 0.3272  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [8]  [ 260/1229]  eta: 0:05:14  lr: 0.005000  loss: 0.3634 (0.4335)  loss_classifier: 0.1497 (0.1526)  loss_box_reg: 0.0996 (0.1344)  loss_objectness: 0.1002 (0.1028)  loss_rpn_box_reg: 0.0277 (0.0437)  time: 0.3300  data: 0.1402  max mem: 4022\n",
      "Training Epoch: [8]  [ 270/1229]  eta: 0:05:11  lr: 0.005000  loss: 0.3599 (0.4311)  loss_classifier: 0.1392 (0.1518)  loss_box_reg: 0.0996 (0.1338)  loss_objectness: 0.0868 (0.1021)  loss_rpn_box_reg: 0.0200 (0.0434)  time: 0.3272  data: 0.1376  max mem: 4022\n",
      "Training Epoch: [8]  [ 280/1229]  eta: 0:05:07  lr: 0.005000  loss: 0.3750 (0.4358)  loss_classifier: 0.1485 (0.1530)  loss_box_reg: 0.0983 (0.1346)  loss_objectness: 0.0961 (0.1043)  loss_rpn_box_reg: 0.0204 (0.0440)  time: 0.3225  data: 0.1377  max mem: 4022\n",
      "Training Epoch: [8]  [ 290/1229]  eta: 0:05:04  lr: 0.005000  loss: 0.3927 (0.4352)  loss_classifier: 0.1485 (0.1525)  loss_box_reg: 0.1016 (0.1345)  loss_objectness: 0.1123 (0.1043)  loss_rpn_box_reg: 0.0360 (0.0439)  time: 0.3163  data: 0.1395  max mem: 4022\n",
      "Training Epoch: [8]  [ 300/1229]  eta: 0:05:01  lr: 0.005000  loss: 0.3942 (0.4356)  loss_classifier: 0.1384 (0.1531)  loss_box_reg: 0.1109 (0.1346)  loss_objectness: 0.1108 (0.1044)  loss_rpn_box_reg: 0.0305 (0.0434)  time: 0.3237  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [8]  [ 310/1229]  eta: 0:04:57  lr: 0.005000  loss: 0.4537 (0.4388)  loss_classifier: 0.1660 (0.1542)  loss_box_reg: 0.1288 (0.1363)  loss_objectness: 0.1022 (0.1048)  loss_rpn_box_reg: 0.0222 (0.0434)  time: 0.3295  data: 0.1403  max mem: 4022\n",
      "Training Epoch: [8]  [ 320/1229]  eta: 0:04:54  lr: 0.005000  loss: 0.4737 (0.4414)  loss_classifier: 0.1691 (0.1553)  loss_box_reg: 0.1345 (0.1377)  loss_objectness: 0.0942 (0.1050)  loss_rpn_box_reg: 0.0251 (0.0433)  time: 0.3226  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [8]  [ 330/1229]  eta: 0:04:51  lr: 0.005000  loss: 0.5273 (0.4460)  loss_classifier: 0.1856 (0.1570)  loss_box_reg: 0.1437 (0.1396)  loss_objectness: 0.1220 (0.1058)  loss_rpn_box_reg: 0.0361 (0.0436)  time: 0.3257  data: 0.1422  max mem: 4022\n",
      "Training Epoch: [8]  [ 340/1229]  eta: 0:04:47  lr: 0.005000  loss: 0.4532 (0.4479)  loss_classifier: 0.1711 (0.1577)  loss_box_reg: 0.1059 (0.1402)  loss_objectness: 0.1261 (0.1066)  loss_rpn_box_reg: 0.0310 (0.0434)  time: 0.3226  data: 0.1404  max mem: 4022\n",
      "Training Epoch: [8]  [ 350/1229]  eta: 0:04:44  lr: 0.005000  loss: 0.4532 (0.4484)  loss_classifier: 0.1402 (0.1577)  loss_box_reg: 0.1058 (0.1406)  loss_objectness: 0.1151 (0.1066)  loss_rpn_box_reg: 0.0267 (0.0435)  time: 0.3182  data: 0.1387  max mem: 4022\n",
      "Training Epoch: [8]  [ 360/1229]  eta: 0:04:41  lr: 0.005000  loss: 0.4351 (0.4489)  loss_classifier: 0.1402 (0.1577)  loss_box_reg: 0.1773 (0.1411)  loss_objectness: 0.0810 (0.1067)  loss_rpn_box_reg: 0.0267 (0.0433)  time: 0.3209  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [8]  [ 370/1229]  eta: 0:04:38  lr: 0.005000  loss: 0.4184 (0.4470)  loss_classifier: 0.1640 (0.1576)  loss_box_reg: 0.1641 (0.1406)  loss_objectness: 0.0737 (0.1062)  loss_rpn_box_reg: 0.0156 (0.0426)  time: 0.3197  data: 0.1383  max mem: 4022\n",
      "Training Epoch: [8]  [ 380/1229]  eta: 0:04:34  lr: 0.005000  loss: 0.4348 (0.4501)  loss_classifier: 0.1711 (0.1587)  loss_box_reg: 0.1106 (0.1410)  loss_objectness: 0.1111 (0.1071)  loss_rpn_box_reg: 0.0187 (0.0433)  time: 0.3214  data: 0.1406  max mem: 4022\n",
      "Training Epoch: [8]  [ 390/1229]  eta: 0:04:31  lr: 0.005000  loss: 0.5855 (0.4524)  loss_classifier: 0.2004 (0.1598)  loss_box_reg: 0.1569 (0.1422)  loss_objectness: 0.1169 (0.1072)  loss_rpn_box_reg: 0.0407 (0.0432)  time: 0.3286  data: 0.1449  max mem: 4022\n",
      "Training Epoch: [8]  [ 400/1229]  eta: 0:04:28  lr: 0.005000  loss: 0.4509 (0.4524)  loss_classifier: 0.1788 (0.1596)  loss_box_reg: 0.1569 (0.1425)  loss_objectness: 0.0831 (0.1070)  loss_rpn_box_reg: 0.0345 (0.0433)  time: 0.3273  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [8]  [ 410/1229]  eta: 0:04:25  lr: 0.005000  loss: 0.3737 (0.4521)  loss_classifier: 0.1307 (0.1595)  loss_box_reg: 0.1148 (0.1422)  loss_objectness: 0.0935 (0.1068)  loss_rpn_box_reg: 0.0339 (0.0436)  time: 0.3258  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [8]  [ 420/1229]  eta: 0:04:22  lr: 0.005000  loss: 0.5051 (0.4530)  loss_classifier: 0.1594 (0.1597)  loss_box_reg: 0.1383 (0.1426)  loss_objectness: 0.0940 (0.1070)  loss_rpn_box_reg: 0.0440 (0.0438)  time: 0.3261  data: 0.1448  max mem: 4022\n",
      "Training Epoch: [8]  [ 430/1229]  eta: 0:04:18  lr: 0.005000  loss: 0.5051 (0.4540)  loss_classifier: 0.1526 (0.1599)  loss_box_reg: 0.1411 (0.1427)  loss_objectness: 0.1187 (0.1077)  loss_rpn_box_reg: 0.0432 (0.0437)  time: 0.3245  data: 0.1446  max mem: 4022\n",
      "Training Epoch: [8]  [ 440/1229]  eta: 0:04:15  lr: 0.005000  loss: 0.4373 (0.4537)  loss_classifier: 0.1457 (0.1597)  loss_box_reg: 0.1268 (0.1422)  loss_objectness: 0.1203 (0.1083)  loss_rpn_box_reg: 0.0360 (0.0435)  time: 0.3257  data: 0.1425  max mem: 4022\n",
      "Training Epoch: [8]  [ 450/1229]  eta: 0:04:12  lr: 0.005000  loss: 0.4598 (0.4574)  loss_classifier: 0.1561 (0.1610)  loss_box_reg: 0.1318 (0.1433)  loss_objectness: 0.1415 (0.1095)  loss_rpn_box_reg: 0.0324 (0.0436)  time: 0.3216  data: 0.1428  max mem: 4022\n",
      "Training Epoch: [8]  [ 460/1229]  eta: 0:04:09  lr: 0.005000  loss: 0.4280 (0.4564)  loss_classifier: 0.1688 (0.1610)  loss_box_reg: 0.1285 (0.1427)  loss_objectness: 0.1134 (0.1091)  loss_rpn_box_reg: 0.0256 (0.0436)  time: 0.3198  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [8]  [ 470/1229]  eta: 0:04:05  lr: 0.005000  loss: 0.4191 (0.4590)  loss_classifier: 0.1680 (0.1619)  loss_box_reg: 0.1113 (0.1437)  loss_objectness: 0.0899 (0.1092)  loss_rpn_box_reg: 0.0256 (0.0442)  time: 0.3195  data: 0.1397  max mem: 4022\n",
      "Training Epoch: [8]  [ 480/1229]  eta: 0:04:02  lr: 0.005000  loss: 0.5632 (0.4598)  loss_classifier: 0.1802 (0.1618)  loss_box_reg: 0.1534 (0.1438)  loss_objectness: 0.1124 (0.1094)  loss_rpn_box_reg: 0.0441 (0.0447)  time: 0.3181  data: 0.1404  max mem: 4022\n",
      "Training Epoch: [8]  [ 490/1229]  eta: 0:03:59  lr: 0.005000  loss: 0.5916 (0.4633)  loss_classifier: 0.1908 (0.1629)  loss_box_reg: 0.1694 (0.1449)  loss_objectness: 0.1264 (0.1104)  loss_rpn_box_reg: 0.0497 (0.0452)  time: 0.3158  data: 0.1408  max mem: 4022\n",
      "Training Epoch: [8]  [ 500/1229]  eta: 0:03:55  lr: 0.005000  loss: 0.5008 (0.4644)  loss_classifier: 0.1603 (0.1631)  loss_box_reg: 0.1557 (0.1452)  loss_objectness: 0.1313 (0.1109)  loss_rpn_box_reg: 0.0286 (0.0452)  time: 0.3212  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [8]  [ 510/1229]  eta: 0:03:52  lr: 0.005000  loss: 0.4047 (0.4639)  loss_classifier: 0.1512 (0.1632)  loss_box_reg: 0.1177 (0.1453)  loss_objectness: 0.1048 (0.1107)  loss_rpn_box_reg: 0.0189 (0.0448)  time: 0.3325  data: 0.1462  max mem: 4022\n",
      "Training Epoch: [8]  [ 520/1229]  eta: 0:03:49  lr: 0.005000  loss: 0.3534 (0.4638)  loss_classifier: 0.1453 (0.1631)  loss_box_reg: 0.1197 (0.1450)  loss_objectness: 0.0784 (0.1112)  loss_rpn_box_reg: 0.0152 (0.0446)  time: 0.3340  data: 0.1493  max mem: 4022\n",
      "Training Epoch: [8]  [ 530/1229]  eta: 0:03:46  lr: 0.005000  loss: 0.3880 (0.4653)  loss_classifier: 0.1593 (0.1635)  loss_box_reg: 0.1416 (0.1456)  loss_objectness: 0.0784 (0.1114)  loss_rpn_box_reg: 0.0170 (0.0447)  time: 0.3332  data: 0.1488  max mem: 4022\n",
      "Training Epoch: [8]  [ 540/1229]  eta: 0:03:43  lr: 0.005000  loss: 0.4722 (0.4662)  loss_classifier: 0.1595 (0.1639)  loss_box_reg: 0.1425 (0.1457)  loss_objectness: 0.1083 (0.1121)  loss_rpn_box_reg: 0.0292 (0.0446)  time: 0.3318  data: 0.1452  max mem: 4022\n",
      "Training Epoch: [8]  [ 550/1229]  eta: 0:03:40  lr: 0.005000  loss: 0.5086 (0.4662)  loss_classifier: 0.1539 (0.1638)  loss_box_reg: 0.1641 (0.1460)  loss_objectness: 0.1081 (0.1120)  loss_rpn_box_reg: 0.0312 (0.0444)  time: 0.3304  data: 0.1404  max mem: 4022\n",
      "Training Epoch: [8]  [ 560/1229]  eta: 0:03:37  lr: 0.005000  loss: 0.5086 (0.4666)  loss_classifier: 0.1544 (0.1640)  loss_box_reg: 0.1600 (0.1462)  loss_objectness: 0.1081 (0.1121)  loss_rpn_box_reg: 0.0251 (0.0443)  time: 0.3309  data: 0.1404  max mem: 4022\n",
      "Training Epoch: [8]  [ 570/1229]  eta: 0:03:33  lr: 0.005000  loss: 0.4555 (0.4672)  loss_classifier: 0.1647 (0.1640)  loss_box_reg: 0.1253 (0.1463)  loss_objectness: 0.1210 (0.1122)  loss_rpn_box_reg: 0.0184 (0.0447)  time: 0.3215  data: 0.1400  max mem: 4022\n",
      "Training Epoch: [8]  [ 580/1229]  eta: 0:03:30  lr: 0.005000  loss: 0.4555 (0.4680)  loss_classifier: 0.1647 (0.1643)  loss_box_reg: 0.1393 (0.1465)  loss_objectness: 0.1123 (0.1124)  loss_rpn_box_reg: 0.0224 (0.0448)  time: 0.3182  data: 0.1384  max mem: 4022\n",
      "Training Epoch: [8]  [ 590/1229]  eta: 0:03:27  lr: 0.005000  loss: 0.5098 (0.4674)  loss_classifier: 0.1772 (0.1640)  loss_box_reg: 0.1393 (0.1460)  loss_objectness: 0.1327 (0.1126)  loss_rpn_box_reg: 0.0224 (0.0447)  time: 0.3187  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [8]  [ 600/1229]  eta: 0:03:23  lr: 0.005000  loss: 0.3821 (0.4672)  loss_classifier: 0.1307 (0.1640)  loss_box_reg: 0.1191 (0.1464)  loss_objectness: 0.0835 (0.1122)  loss_rpn_box_reg: 0.0269 (0.0446)  time: 0.3157  data: 0.1385  max mem: 4022\n",
      "Training Epoch: [8]  [ 610/1229]  eta: 0:03:20  lr: 0.005000  loss: 0.3486 (0.4655)  loss_classifier: 0.1238 (0.1634)  loss_box_reg: 0.0887 (0.1455)  loss_objectness: 0.0847 (0.1122)  loss_rpn_box_reg: 0.0280 (0.0444)  time: 0.3153  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [8]  [ 620/1229]  eta: 0:03:17  lr: 0.005000  loss: 0.3369 (0.4638)  loss_classifier: 0.1229 (0.1629)  loss_box_reg: 0.0887 (0.1452)  loss_objectness: 0.0847 (0.1117)  loss_rpn_box_reg: 0.0218 (0.0440)  time: 0.3213  data: 0.1385  max mem: 4022\n",
      "Training Epoch: [8]  [ 630/1229]  eta: 0:03:13  lr: 0.005000  loss: 0.3324 (0.4627)  loss_classifier: 0.1323 (0.1625)  loss_box_reg: 0.1216 (0.1448)  loss_objectness: 0.0839 (0.1117)  loss_rpn_box_reg: 0.0182 (0.0438)  time: 0.3239  data: 0.1375  max mem: 4022\n",
      "Training Epoch: [8]  [ 640/1229]  eta: 0:03:10  lr: 0.005000  loss: 0.4317 (0.4630)  loss_classifier: 0.1474 (0.1623)  loss_box_reg: 0.1334 (0.1452)  loss_objectness: 0.0865 (0.1115)  loss_rpn_box_reg: 0.0199 (0.0440)  time: 0.3183  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [8]  [ 650/1229]  eta: 0:03:07  lr: 0.005000  loss: 0.4846 (0.4632)  loss_classifier: 0.1703 (0.1624)  loss_box_reg: 0.1560 (0.1454)  loss_objectness: 0.0865 (0.1115)  loss_rpn_box_reg: 0.0225 (0.0439)  time: 0.3225  data: 0.1436  max mem: 4022\n",
      "Training Epoch: [8]  [ 660/1229]  eta: 0:03:04  lr: 0.005000  loss: 0.3998 (0.4622)  loss_classifier: 0.1670 (0.1622)  loss_box_reg: 0.1184 (0.1450)  loss_objectness: 0.0778 (0.1113)  loss_rpn_box_reg: 0.0215 (0.0438)  time: 0.3321  data: 0.1446  max mem: 4022\n",
      "Training Epoch: [8]  [ 670/1229]  eta: 0:03:01  lr: 0.005000  loss: 0.4485 (0.4634)  loss_classifier: 0.1477 (0.1626)  loss_box_reg: 0.1245 (0.1457)  loss_objectness: 0.0942 (0.1114)  loss_rpn_box_reg: 0.0253 (0.0438)  time: 0.3291  data: 0.1439  max mem: 4022\n",
      "Training Epoch: [8]  [ 680/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.4754 (0.4641)  loss_classifier: 0.1545 (0.1627)  loss_box_reg: 0.1385 (0.1458)  loss_objectness: 0.1115 (0.1117)  loss_rpn_box_reg: 0.0323 (0.0439)  time: 0.3431  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [8]  [ 690/1229]  eta: 0:02:54  lr: 0.005000  loss: 0.4693 (0.4657)  loss_classifier: 0.1350 (0.1632)  loss_box_reg: 0.1116 (0.1467)  loss_objectness: 0.1101 (0.1118)  loss_rpn_box_reg: 0.0290 (0.0441)  time: 0.3452  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [8]  [ 700/1229]  eta: 0:02:51  lr: 0.005000  loss: 0.3344 (0.4641)  loss_classifier: 0.1190 (0.1627)  loss_box_reg: 0.1058 (0.1463)  loss_objectness: 0.0683 (0.1112)  loss_rpn_box_reg: 0.0266 (0.0440)  time: 0.3352  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [8]  [ 710/1229]  eta: 0:02:48  lr: 0.005000  loss: 0.3543 (0.4643)  loss_classifier: 0.1300 (0.1628)  loss_box_reg: 0.1197 (0.1465)  loss_objectness: 0.0861 (0.1112)  loss_rpn_box_reg: 0.0270 (0.0438)  time: 0.3331  data: 0.1427  max mem: 4022\n",
      "Training Epoch: [8]  [ 720/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.4249 (0.4642)  loss_classifier: 0.1542 (0.1627)  loss_box_reg: 0.1207 (0.1465)  loss_objectness: 0.1022 (0.1110)  loss_rpn_box_reg: 0.0274 (0.0440)  time: 0.3238  data: 0.1392  max mem: 4022\n",
      "Training Epoch: [8]  [ 730/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.3835 (0.4635)  loss_classifier: 0.1349 (0.1625)  loss_box_reg: 0.1048 (0.1464)  loss_objectness: 0.0892 (0.1109)  loss_rpn_box_reg: 0.0226 (0.0437)  time: 0.3332  data: 0.1429  max mem: 4022\n",
      "Training Epoch: [8]  [ 740/1229]  eta: 0:02:39  lr: 0.005000  loss: 0.3875 (0.4626)  loss_classifier: 0.1359 (0.1621)  loss_box_reg: 0.1158 (0.1461)  loss_objectness: 0.0730 (0.1107)  loss_rpn_box_reg: 0.0214 (0.0437)  time: 0.3397  data: 0.1481  max mem: 4022\n",
      "Training Epoch: [8]  [ 750/1229]  eta: 0:02:35  lr: 0.005000  loss: 0.3915 (0.4634)  loss_classifier: 0.1365 (0.1624)  loss_box_reg: 0.1158 (0.1464)  loss_objectness: 0.0989 (0.1108)  loss_rpn_box_reg: 0.0252 (0.0438)  time: 0.3314  data: 0.1477  max mem: 4022\n",
      "Training Epoch: [8]  [ 760/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.4349 (0.4637)  loss_classifier: 0.1736 (0.1625)  loss_box_reg: 0.1450 (0.1467)  loss_objectness: 0.1094 (0.1109)  loss_rpn_box_reg: 0.0358 (0.0437)  time: 0.3312  data: 0.1459  max mem: 4022\n",
      "Training Epoch: [8]  [ 770/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.3115 (0.4607)  loss_classifier: 0.1246 (0.1615)  loss_box_reg: 0.0877 (0.1456)  loss_objectness: 0.0822 (0.1104)  loss_rpn_box_reg: 0.0136 (0.0433)  time: 0.3455  data: 0.1514  max mem: 4022\n",
      "Training Epoch: [8]  [ 780/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.2600 (0.4610)  loss_classifier: 0.0995 (0.1614)  loss_box_reg: 0.0877 (0.1459)  loss_objectness: 0.0770 (0.1104)  loss_rpn_box_reg: 0.0139 (0.0434)  time: 0.3435  data: 0.1485  max mem: 4022\n",
      "Training Epoch: [8]  [ 790/1229]  eta: 0:02:23  lr: 0.005000  loss: 0.3755 (0.4600)  loss_classifier: 0.1145 (0.1611)  loss_box_reg: 0.1149 (0.1455)  loss_objectness: 0.0935 (0.1102)  loss_rpn_box_reg: 0.0313 (0.0431)  time: 0.3274  data: 0.1378  max mem: 4022\n",
      "Training Epoch: [8]  [ 800/1229]  eta: 0:02:19  lr: 0.005000  loss: 0.3853 (0.4599)  loss_classifier: 0.1232 (0.1610)  loss_box_reg: 0.1101 (0.1452)  loss_objectness: 0.0952 (0.1103)  loss_rpn_box_reg: 0.0228 (0.0433)  time: 0.3238  data: 0.1357  max mem: 4022\n",
      "Training Epoch: [8]  [ 810/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.4183 (0.4606)  loss_classifier: 0.1614 (0.1612)  loss_box_reg: 0.1160 (0.1453)  loss_objectness: 0.1142 (0.1107)  loss_rpn_box_reg: 0.0273 (0.0434)  time: 0.3225  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [8]  [ 820/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.3851 (0.4599)  loss_classifier: 0.1341 (0.1611)  loss_box_reg: 0.1121 (0.1451)  loss_objectness: 0.0796 (0.1104)  loss_rpn_box_reg: 0.0224 (0.0432)  time: 0.3253  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [8]  [ 830/1229]  eta: 0:02:09  lr: 0.005000  loss: 0.3851 (0.4589)  loss_classifier: 0.1304 (0.1607)  loss_box_reg: 0.0925 (0.1447)  loss_objectness: 0.0781 (0.1102)  loss_rpn_box_reg: 0.0157 (0.0432)  time: 0.3293  data: 0.1353  max mem: 4022\n",
      "Training Epoch: [8]  [ 840/1229]  eta: 0:02:06  lr: 0.005000  loss: 0.3984 (0.4585)  loss_classifier: 0.1257 (0.1605)  loss_box_reg: 0.0948 (0.1447)  loss_objectness: 0.0824 (0.1102)  loss_rpn_box_reg: 0.0195 (0.0431)  time: 0.3256  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [8]  [ 850/1229]  eta: 0:02:03  lr: 0.005000  loss: 0.3975 (0.4581)  loss_classifier: 0.1257 (0.1602)  loss_box_reg: 0.1062 (0.1442)  loss_objectness: 0.0880 (0.1102)  loss_rpn_box_reg: 0.0258 (0.0436)  time: 0.3327  data: 0.1412  max mem: 4022\n",
      "Training Epoch: [8]  [ 860/1229]  eta: 0:02:00  lr: 0.005000  loss: 0.3975 (0.4591)  loss_classifier: 0.1176 (0.1605)  loss_box_reg: 0.1059 (0.1448)  loss_objectness: 0.0880 (0.1101)  loss_rpn_box_reg: 0.0263 (0.0437)  time: 0.3313  data: 0.1390  max mem: 4022\n",
      "Training Epoch: [8]  [ 870/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.4347 (0.4592)  loss_classifier: 0.1601 (0.1607)  loss_box_reg: 0.1443 (0.1451)  loss_objectness: 0.0992 (0.1099)  loss_rpn_box_reg: 0.0216 (0.0435)  time: 0.3217  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [8]  [ 880/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.3794 (0.4585)  loss_classifier: 0.1354 (0.1603)  loss_box_reg: 0.1155 (0.1448)  loss_objectness: 0.0915 (0.1096)  loss_rpn_box_reg: 0.0216 (0.0437)  time: 0.3284  data: 0.1397  max mem: 4022\n",
      "Training Epoch: [8]  [ 890/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.3995 (0.4583)  loss_classifier: 0.1354 (0.1604)  loss_box_reg: 0.1042 (0.1447)  loss_objectness: 0.0894 (0.1095)  loss_rpn_box_reg: 0.0239 (0.0437)  time: 0.3330  data: 0.1409  max mem: 4022\n",
      "Training Epoch: [8]  [ 900/1229]  eta: 0:01:47  lr: 0.005000  loss: 0.4157 (0.4579)  loss_classifier: 0.1249 (0.1601)  loss_box_reg: 0.1094 (0.1447)  loss_objectness: 0.1000 (0.1093)  loss_rpn_box_reg: 0.0339 (0.0438)  time: 0.3295  data: 0.1418  max mem: 4022\n",
      "Training Epoch: [8]  [ 910/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.3739 (0.4576)  loss_classifier: 0.1142 (0.1600)  loss_box_reg: 0.1094 (0.1446)  loss_objectness: 0.0797 (0.1094)  loss_rpn_box_reg: 0.0228 (0.0436)  time: 0.3233  data: 0.1407  max mem: 4022\n",
      "Training Epoch: [8]  [ 920/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.3056 (0.4566)  loss_classifier: 0.1106 (0.1597)  loss_box_reg: 0.0977 (0.1444)  loss_objectness: 0.0791 (0.1092)  loss_rpn_box_reg: 0.0172 (0.0434)  time: 0.3211  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [8]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.3133 (0.4562)  loss_classifier: 0.1154 (0.1595)  loss_box_reg: 0.0939 (0.1444)  loss_objectness: 0.0791 (0.1091)  loss_rpn_box_reg: 0.0210 (0.0432)  time: 0.3256  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [8]  [ 940/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.3133 (0.4553)  loss_classifier: 0.1274 (0.1592)  loss_box_reg: 0.0939 (0.1441)  loss_objectness: 0.0780 (0.1090)  loss_rpn_box_reg: 0.0194 (0.0430)  time: 0.3294  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [8]  [ 950/1229]  eta: 0:01:30  lr: 0.005000  loss: 0.3423 (0.4563)  loss_classifier: 0.1274 (0.1595)  loss_box_reg: 0.1147 (0.1448)  loss_objectness: 0.0804 (0.1090)  loss_rpn_box_reg: 0.0194 (0.0430)  time: 0.3284  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [8]  [ 960/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.3599 (0.4558)  loss_classifier: 0.1277 (0.1593)  loss_box_reg: 0.1246 (0.1447)  loss_objectness: 0.0830 (0.1088)  loss_rpn_box_reg: 0.0255 (0.0430)  time: 0.3330  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [8]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.3738 (0.4555)  loss_classifier: 0.1413 (0.1592)  loss_box_reg: 0.1205 (0.1446)  loss_objectness: 0.0830 (0.1085)  loss_rpn_box_reg: 0.0255 (0.0431)  time: 0.3292  data: 0.1402  max mem: 4022\n",
      "Training Epoch: [8]  [ 980/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.5773 (0.4580)  loss_classifier: 0.1952 (0.1602)  loss_box_reg: 0.2007 (0.1455)  loss_objectness: 0.1119 (0.1091)  loss_rpn_box_reg: 0.0389 (0.0432)  time: 0.3212  data: 0.1427  max mem: 4022\n",
      "Training Epoch: [8]  [ 990/1229]  eta: 0:01:17  lr: 0.005000  loss: 0.4867 (0.4583)  loss_classifier: 0.1892 (0.1603)  loss_box_reg: 0.1554 (0.1456)  loss_objectness: 0.1119 (0.1090)  loss_rpn_box_reg: 0.0282 (0.0434)  time: 0.3228  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [8]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.4318 (0.4588)  loss_classifier: 0.1253 (0.1605)  loss_box_reg: 0.1235 (0.1457)  loss_objectness: 0.0993 (0.1091)  loss_rpn_box_reg: 0.0273 (0.0434)  time: 0.3254  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [8]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.4921 (0.4591)  loss_classifier: 0.1742 (0.1607)  loss_box_reg: 0.1265 (0.1456)  loss_objectness: 0.1084 (0.1092)  loss_rpn_box_reg: 0.0278 (0.0436)  time: 0.3269  data: 0.1436  max mem: 4022\n",
      "Training Epoch: [8]  [1020/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.4204 (0.4587)  loss_classifier: 0.1514 (0.1605)  loss_box_reg: 0.0908 (0.1454)  loss_objectness: 0.1021 (0.1091)  loss_rpn_box_reg: 0.0278 (0.0437)  time: 0.3254  data: 0.1441  max mem: 4022\n",
      "Training Epoch: [8]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.3922 (0.4581)  loss_classifier: 0.1083 (0.1602)  loss_box_reg: 0.0968 (0.1452)  loss_objectness: 0.0837 (0.1089)  loss_rpn_box_reg: 0.0273 (0.0438)  time: 0.3281  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [8]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.4086 (0.4583)  loss_classifier: 0.1532 (0.1602)  loss_box_reg: 0.1069 (0.1453)  loss_objectness: 0.0895 (0.1089)  loss_rpn_box_reg: 0.0218 (0.0439)  time: 0.3286  data: 0.1420  max mem: 4022\n",
      "Training Epoch: [8]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.3622 (0.4581)  loss_classifier: 0.1499 (0.1602)  loss_box_reg: 0.1127 (0.1453)  loss_objectness: 0.0818 (0.1088)  loss_rpn_box_reg: 0.0218 (0.0438)  time: 0.3254  data: 0.1401  max mem: 4022\n",
      "Training Epoch: [8]  [1060/1229]  eta: 0:00:55  lr: 0.005000  loss: 0.3381 (0.4577)  loss_classifier: 0.1226 (0.1601)  loss_box_reg: 0.1060 (0.1452)  loss_objectness: 0.0713 (0.1086)  loss_rpn_box_reg: 0.0164 (0.0438)  time: 0.3252  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [8]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.3578 (0.4568)  loss_classifier: 0.1225 (0.1597)  loss_box_reg: 0.1016 (0.1448)  loss_objectness: 0.0785 (0.1086)  loss_rpn_box_reg: 0.0200 (0.0436)  time: 0.3238  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [8]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.3265 (0.4556)  loss_classifier: 0.1134 (0.1593)  loss_box_reg: 0.0839 (0.1444)  loss_objectness: 0.1036 (0.1084)  loss_rpn_box_reg: 0.0200 (0.0435)  time: 0.3188  data: 0.1400  max mem: 4022\n",
      "Training Epoch: [8]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.3063 (0.4555)  loss_classifier: 0.1156 (0.1593)  loss_box_reg: 0.1001 (0.1446)  loss_objectness: 0.0995 (0.1083)  loss_rpn_box_reg: 0.0203 (0.0433)  time: 0.3172  data: 0.1402  max mem: 4022\n",
      "Training Epoch: [8]  [1100/1229]  eta: 0:00:42  lr: 0.005000  loss: 0.3994 (0.4556)  loss_classifier: 0.1453 (0.1592)  loss_box_reg: 0.1187 (0.1447)  loss_objectness: 0.0995 (0.1082)  loss_rpn_box_reg: 0.0246 (0.0434)  time: 0.3228  data: 0.1414  max mem: 4022\n",
      "Training Epoch: [8]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.4061 (0.4564)  loss_classifier: 0.1580 (0.1594)  loss_box_reg: 0.1258 (0.1450)  loss_objectness: 0.1061 (0.1084)  loss_rpn_box_reg: 0.0434 (0.0435)  time: 0.3251  data: 0.1411  max mem: 4022\n",
      "Training Epoch: [8]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4560 (0.4563)  loss_classifier: 0.1520 (0.1593)  loss_box_reg: 0.1281 (0.1450)  loss_objectness: 0.1149 (0.1083)  loss_rpn_box_reg: 0.0330 (0.0437)  time: 0.3246  data: 0.1440  max mem: 4022\n",
      "Training Epoch: [8]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.3854 (0.4555)  loss_classifier: 0.1135 (0.1590)  loss_box_reg: 0.1049 (0.1448)  loss_objectness: 0.0983 (0.1082)  loss_rpn_box_reg: 0.0319 (0.0436)  time: 0.3269  data: 0.1447  max mem: 4022\n",
      "Training Epoch: [8]  [1140/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.3332 (0.4550)  loss_classifier: 0.1060 (0.1588)  loss_box_reg: 0.1163 (0.1447)  loss_objectness: 0.0906 (0.1080)  loss_rpn_box_reg: 0.0166 (0.0435)  time: 0.3248  data: 0.1422  max mem: 4022\n",
      "Training Epoch: [8]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.3332 (0.4547)  loss_classifier: 0.1288 (0.1588)  loss_box_reg: 0.1203 (0.1447)  loss_objectness: 0.0900 (0.1079)  loss_rpn_box_reg: 0.0166 (0.0433)  time: 0.3264  data: 0.1407  max mem: 4022\n",
      "Training Epoch: [8]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.3459 (0.4544)  loss_classifier: 0.1397 (0.1587)  loss_box_reg: 0.1010 (0.1446)  loss_objectness: 0.0900 (0.1078)  loss_rpn_box_reg: 0.0156 (0.0432)  time: 0.3275  data: 0.1409  max mem: 4022\n",
      "Training Epoch: [8]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.3905 (0.4539)  loss_classifier: 0.1500 (0.1587)  loss_box_reg: 0.0940 (0.1443)  loss_objectness: 0.0955 (0.1078)  loss_rpn_box_reg: 0.0212 (0.0431)  time: 0.3310  data: 0.1427  max mem: 4022\n",
      "Training Epoch: [8]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.4531 (0.4547)  loss_classifier: 0.1539 (0.1589)  loss_box_reg: 0.0940 (0.1446)  loss_objectness: 0.1040 (0.1080)  loss_rpn_box_reg: 0.0215 (0.0432)  time: 0.3342  data: 0.1441  max mem: 4022\n",
      "Training Epoch: [8]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.5212 (0.4552)  loss_classifier: 0.1859 (0.1591)  loss_box_reg: 0.1363 (0.1447)  loss_objectness: 0.1273 (0.1082)  loss_rpn_box_reg: 0.0313 (0.0431)  time: 0.3309  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [8]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.4968 (0.4548)  loss_classifier: 0.1524 (0.1591)  loss_box_reg: 0.1109 (0.1445)  loss_objectness: 0.0886 (0.1081)  loss_rpn_box_reg: 0.0313 (0.0432)  time: 0.3362  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [8]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.4876 (0.4555)  loss_classifier: 0.1544 (0.1592)  loss_box_reg: 0.1171 (0.1448)  loss_objectness: 0.1069 (0.1081)  loss_rpn_box_reg: 0.0284 (0.0433)  time: 0.3320  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [8]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.4411 (0.4551)  loss_classifier: 0.1544 (0.1591)  loss_box_reg: 0.1795 (0.1448)  loss_objectness: 0.0995 (0.1080)  loss_rpn_box_reg: 0.0266 (0.0432)  time: 0.3220  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [8]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4127 (0.4552)  loss_classifier: 0.1461 (0.1591)  loss_box_reg: 0.1273 (0.1449)  loss_objectness: 0.0872 (0.1080)  loss_rpn_box_reg: 0.0264 (0.0432)  time: 0.3222  data: 0.1391  max mem: 4022\n",
      "Training Epoch: [8] Total time: 0:06:40 (0.3261 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:01:42  model_time: 0.2960 (0.2960)  evaluator_time: 0.0010 (0.0010)  time: 0.3320  data: 0.0330  max mem: 4022\n",
      "Test:  [100/308]  eta: 0:00:33  model_time: 0.1090 (0.1136)  evaluator_time: 0.0020 (0.0053)  time: 0.1609  data: 0.0402  max mem: 4022\n",
      "Test:  [200/308]  eta: 0:00:17  model_time: 0.1170 (0.1128)  evaluator_time: 0.0020 (0.0049)  time: 0.1572  data: 0.0350  max mem: 4022\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.1020 (0.1119)  evaluator_time: 0.0020 (0.0049)  time: 0.1563  data: 0.0453  max mem: 4022\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.1030 (0.1116)  evaluator_time: 0.0020 (0.0049)  time: 0.1475  data: 0.0378  max mem: 4022\n",
      "Test: Total time: 0:00:48 (0.1569 s / it)\n",
      "Averaged stats: model_time: 0.1030 (0.1116)  evaluator_time: 0.0020 (0.0049)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.124\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.072\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.246\n",
      "Testing Epoch: [8]  [  0/308]  eta: 0:00:47  lr: 0.005000  loss: 0.1616 (0.1616)  loss_classifier: 0.0715 (0.0715)  loss_box_reg: 0.0538 (0.0538)  loss_objectness: 0.0290 (0.0290)  loss_rpn_box_reg: 0.0073 (0.0073)  time: 0.1540  data: 0.0310  max mem: 4022\n",
      "Testing Epoch: [8]  [100/308]  eta: 0:00:37  lr: 0.005000  loss: 0.3469 (0.5198)  loss_classifier: 0.1545 (0.1770)  loss_box_reg: 0.1258 (0.1661)  loss_objectness: 0.0616 (0.1170)  loss_rpn_box_reg: 0.0170 (0.0597)  time: 0.1870  data: 0.0486  max mem: 4022\n",
      "Testing Epoch: [8]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.4230 (0.4931)  loss_classifier: 0.1532 (0.1687)  loss_box_reg: 0.1408 (0.1583)  loss_objectness: 0.0849 (0.1102)  loss_rpn_box_reg: 0.0266 (0.0559)  time: 0.1838  data: 0.0379  max mem: 4022\n",
      "Testing Epoch: [8]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.4638 (0.4905)  loss_classifier: 0.1959 (0.1693)  loss_box_reg: 0.1495 (0.1602)  loss_objectness: 0.0878 (0.1070)  loss_rpn_box_reg: 0.0338 (0.0540)  time: 0.1763  data: 0.0462  max mem: 4022\n",
      "Testing Epoch: [8]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.4453 (0.4904)  loss_classifier: 0.1739 (0.1694)  loss_box_reg: 0.1239 (0.1605)  loss_objectness: 0.0858 (0.1070)  loss_rpn_box_reg: 0.0338 (0.0535)  time: 0.1734  data: 0.0436  max mem: 4022\n",
      "Testing Epoch: [8] Total time: 0:00:55 (0.1807 s / it)\n",
      "Training Epoch: [9]  [   0/1229]  eta: 0:06:25  lr: 0.005000  loss: 0.2232 (0.2232)  loss_classifier: 0.0973 (0.0973)  loss_box_reg: 0.0656 (0.0656)  loss_objectness: 0.0450 (0.0450)  loss_rpn_box_reg: 0.0153 (0.0153)  time: 0.3140  data: 0.1450  max mem: 4022\n",
      "Training Epoch: [9]  [  10/1229]  eta: 0:06:43  lr: 0.005000  loss: 0.3461 (0.4221)  loss_classifier: 0.1079 (0.1448)  loss_box_reg: 0.0824 (0.1407)  loss_objectness: 0.0741 (0.0908)  loss_rpn_box_reg: 0.0215 (0.0458)  time: 0.3312  data: 0.1499  max mem: 4022\n",
      "Training Epoch: [9]  [  20/1229]  eta: 0:06:43  lr: 0.005000  loss: 0.4322 (0.4754)  loss_classifier: 0.1244 (0.1537)  loss_box_reg: 0.1181 (0.1602)  loss_objectness: 0.1074 (0.1130)  loss_rpn_box_reg: 0.0215 (0.0485)  time: 0.3346  data: 0.1509  max mem: 4022\n",
      "Training Epoch: [9]  [  30/1229]  eta: 0:06:40  lr: 0.005000  loss: 0.4322 (0.4799)  loss_classifier: 0.1495 (0.1623)  loss_box_reg: 0.1230 (0.1503)  loss_objectness: 0.1167 (0.1224)  loss_rpn_box_reg: 0.0274 (0.0448)  time: 0.3357  data: 0.1539  max mem: 4022\n",
      "Training Epoch: [9]  [  40/1229]  eta: 0:06:37  lr: 0.005000  loss: 0.3335 (0.4525)  loss_classifier: 0.1322 (0.1522)  loss_box_reg: 0.0913 (0.1404)  loss_objectness: 0.1049 (0.1133)  loss_rpn_box_reg: 0.0156 (0.0467)  time: 0.3355  data: 0.1522  max mem: 4022\n",
      "Training Epoch: [9]  [  50/1229]  eta: 0:06:30  lr: 0.005000  loss: 0.2826 (0.4365)  loss_classifier: 0.1023 (0.1467)  loss_box_reg: 0.0709 (0.1375)  loss_objectness: 0.0813 (0.1095)  loss_rpn_box_reg: 0.0126 (0.0428)  time: 0.3275  data: 0.1457  max mem: 4022\n",
      "Training Epoch: [9]  [  60/1229]  eta: 0:06:26  lr: 0.005000  loss: 0.3163 (0.4343)  loss_classifier: 0.1070 (0.1459)  loss_box_reg: 0.0968 (0.1368)  loss_objectness: 0.0830 (0.1077)  loss_rpn_box_reg: 0.0200 (0.0438)  time: 0.3227  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [9]  [  70/1229]  eta: 0:06:23  lr: 0.005000  loss: 0.4144 (0.4524)  loss_classifier: 0.1325 (0.1519)  loss_box_reg: 0.1138 (0.1435)  loss_objectness: 0.1011 (0.1135)  loss_rpn_box_reg: 0.0274 (0.0435)  time: 0.3295  data: 0.1455  max mem: 4022\n",
      "Training Epoch: [9]  [  80/1229]  eta: 0:06:19  lr: 0.005000  loss: 0.4144 (0.4468)  loss_classifier: 0.1325 (0.1510)  loss_box_reg: 0.1100 (0.1407)  loss_objectness: 0.1133 (0.1129)  loss_rpn_box_reg: 0.0251 (0.0421)  time: 0.3295  data: 0.1420  max mem: 4022\n",
      "Training Epoch: [9]  [  90/1229]  eta: 0:06:15  lr: 0.005000  loss: 0.3401 (0.4541)  loss_classifier: 0.1243 (0.1526)  loss_box_reg: 0.0942 (0.1432)  loss_objectness: 0.1083 (0.1145)  loss_rpn_box_reg: 0.0305 (0.0437)  time: 0.3261  data: 0.1377  max mem: 4022\n",
      "Training Epoch: [9]  [ 100/1229]  eta: 0:06:12  lr: 0.005000  loss: 0.3539 (0.4551)  loss_classifier: 0.1200 (0.1537)  loss_box_reg: 0.1054 (0.1450)  loss_objectness: 0.0842 (0.1131)  loss_rpn_box_reg: 0.0334 (0.0433)  time: 0.3287  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [9]  [ 110/1229]  eta: 0:06:09  lr: 0.005000  loss: 0.4985 (0.4655)  loss_classifier: 0.1651 (0.1572)  loss_box_reg: 0.1397 (0.1519)  loss_objectness: 0.0810 (0.1119)  loss_rpn_box_reg: 0.0231 (0.0446)  time: 0.3335  data: 0.1426  max mem: 4022\n",
      "Training Epoch: [9]  [ 120/1229]  eta: 0:06:06  lr: 0.005000  loss: 0.5080 (0.4627)  loss_classifier: 0.1775 (0.1573)  loss_box_reg: 0.1375 (0.1518)  loss_objectness: 0.0930 (0.1106)  loss_rpn_box_reg: 0.0209 (0.0431)  time: 0.3334  data: 0.1429  max mem: 4022\n",
      "Training Epoch: [9]  [ 130/1229]  eta: 0:06:02  lr: 0.005000  loss: 0.3451 (0.4608)  loss_classifier: 0.1395 (0.1568)  loss_box_reg: 0.1242 (0.1506)  loss_objectness: 0.0954 (0.1100)  loss_rpn_box_reg: 0.0209 (0.0433)  time: 0.3253  data: 0.1390  max mem: 4022\n",
      "Training Epoch: [9]  [ 140/1229]  eta: 0:05:58  lr: 0.005000  loss: 0.5144 (0.4662)  loss_classifier: 0.1723 (0.1596)  loss_box_reg: 0.1401 (0.1527)  loss_objectness: 0.0970 (0.1098)  loss_rpn_box_reg: 0.0319 (0.0440)  time: 0.3215  data: 0.1365  max mem: 4022\n",
      "Training Epoch: [9]  [ 150/1229]  eta: 0:05:55  lr: 0.005000  loss: 0.3784 (0.4575)  loss_classifier: 0.1435 (0.1568)  loss_box_reg: 0.1375 (0.1484)  loss_objectness: 0.0970 (0.1088)  loss_rpn_box_reg: 0.0226 (0.0435)  time: 0.3266  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [9]  [ 160/1229]  eta: 0:05:52  lr: 0.005000  loss: 0.3484 (0.4568)  loss_classifier: 0.1269 (0.1565)  loss_box_reg: 0.0899 (0.1478)  loss_objectness: 0.0990 (0.1078)  loss_rpn_box_reg: 0.0199 (0.0447)  time: 0.3298  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [9]  [ 170/1229]  eta: 0:05:48  lr: 0.005000  loss: 0.4335 (0.4575)  loss_classifier: 0.1425 (0.1571)  loss_box_reg: 0.1297 (0.1492)  loss_objectness: 0.0809 (0.1070)  loss_rpn_box_reg: 0.0203 (0.0442)  time: 0.3261  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [9]  [ 180/1229]  eta: 0:05:44  lr: 0.005000  loss: 0.3876 (0.4536)  loss_classifier: 0.1166 (0.1560)  loss_box_reg: 0.0942 (0.1478)  loss_objectness: 0.0809 (0.1070)  loss_rpn_box_reg: 0.0182 (0.0429)  time: 0.3208  data: 0.1429  max mem: 4022\n",
      "Training Epoch: [9]  [ 190/1229]  eta: 0:05:40  lr: 0.005000  loss: 0.3626 (0.4514)  loss_classifier: 0.1054 (0.1544)  loss_box_reg: 0.0951 (0.1459)  loss_objectness: 0.1008 (0.1077)  loss_rpn_box_reg: 0.0178 (0.0433)  time: 0.3166  data: 0.1401  max mem: 4022\n",
      "Training Epoch: [9]  [ 200/1229]  eta: 0:05:37  lr: 0.005000  loss: 0.4029 (0.4520)  loss_classifier: 0.1180 (0.1540)  loss_box_reg: 0.1137 (0.1460)  loss_objectness: 0.1027 (0.1079)  loss_rpn_box_reg: 0.0295 (0.0441)  time: 0.3201  data: 0.1409  max mem: 4022\n",
      "Training Epoch: [9]  [ 210/1229]  eta: 0:05:33  lr: 0.005000  loss: 0.4686 (0.4544)  loss_classifier: 0.1604 (0.1554)  loss_box_reg: 0.1549 (0.1472)  loss_objectness: 0.1019 (0.1074)  loss_rpn_box_reg: 0.0321 (0.0444)  time: 0.3254  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [9]  [ 220/1229]  eta: 0:05:30  lr: 0.005000  loss: 0.3837 (0.4494)  loss_classifier: 0.1436 (0.1537)  loss_box_reg: 0.1318 (0.1453)  loss_objectness: 0.0860 (0.1070)  loss_rpn_box_reg: 0.0244 (0.0434)  time: 0.3237  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [9]  [ 230/1229]  eta: 0:05:27  lr: 0.005000  loss: 0.3837 (0.4512)  loss_classifier: 0.1348 (0.1548)  loss_box_reg: 0.0992 (0.1455)  loss_objectness: 0.1141 (0.1083)  loss_rpn_box_reg: 0.0152 (0.0427)  time: 0.3275  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [9]  [ 240/1229]  eta: 0:05:23  lr: 0.005000  loss: 0.4239 (0.4494)  loss_classifier: 0.1498 (0.1543)  loss_box_reg: 0.1362 (0.1447)  loss_objectness: 0.1056 (0.1076)  loss_rpn_box_reg: 0.0158 (0.0428)  time: 0.3265  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [9]  [ 250/1229]  eta: 0:05:20  lr: 0.005000  loss: 0.3665 (0.4504)  loss_classifier: 0.1369 (0.1550)  loss_box_reg: 0.1412 (0.1453)  loss_objectness: 0.0927 (0.1077)  loss_rpn_box_reg: 0.0178 (0.0424)  time: 0.3211  data: 0.1443  max mem: 4022\n",
      "Training Epoch: [9]  [ 260/1229]  eta: 0:05:16  lr: 0.005000  loss: 0.4001 (0.4503)  loss_classifier: 0.1412 (0.1549)  loss_box_reg: 0.1265 (0.1445)  loss_objectness: 0.1117 (0.1085)  loss_rpn_box_reg: 0.0280 (0.0424)  time: 0.3260  data: 0.1442  max mem: 4022\n",
      "Training Epoch: [9]  [ 270/1229]  eta: 0:05:13  lr: 0.005000  loss: 0.3513 (0.4486)  loss_classifier: 0.1391 (0.1546)  loss_box_reg: 0.1084 (0.1448)  loss_objectness: 0.0792 (0.1074)  loss_rpn_box_reg: 0.0286 (0.0418)  time: 0.3280  data: 0.1427  max mem: 4022\n",
      "Training Epoch: [9]  [ 280/1229]  eta: 0:05:10  lr: 0.005000  loss: 0.3513 (0.4463)  loss_classifier: 0.1285 (0.1538)  loss_box_reg: 0.0977 (0.1434)  loss_objectness: 0.0767 (0.1074)  loss_rpn_box_reg: 0.0243 (0.0417)  time: 0.3226  data: 0.1427  max mem: 4022\n",
      "Training Epoch: [9]  [ 290/1229]  eta: 0:05:06  lr: 0.005000  loss: 0.3365 (0.4454)  loss_classifier: 0.1027 (0.1527)  loss_box_reg: 0.0827 (0.1421)  loss_objectness: 0.1028 (0.1075)  loss_rpn_box_reg: 0.0312 (0.0430)  time: 0.3232  data: 0.1409  max mem: 4022\n",
      "Training Epoch: [9]  [ 300/1229]  eta: 0:05:03  lr: 0.005000  loss: 0.3274 (0.4423)  loss_classifier: 0.1009 (0.1517)  loss_box_reg: 0.0827 (0.1409)  loss_objectness: 0.1035 (0.1071)  loss_rpn_box_reg: 0.0201 (0.0426)  time: 0.3233  data: 0.1401  max mem: 4022\n",
      "Training Epoch: [9]  [ 310/1229]  eta: 0:04:59  lr: 0.005000  loss: 0.4559 (0.4464)  loss_classifier: 0.1441 (0.1533)  loss_box_reg: 0.1276 (0.1429)  loss_objectness: 0.0967 (0.1076)  loss_rpn_box_reg: 0.0202 (0.0426)  time: 0.3216  data: 0.1420  max mem: 4022\n",
      "Training Epoch: [9]  [ 320/1229]  eta: 0:04:56  lr: 0.005000  loss: 0.4155 (0.4448)  loss_classifier: 0.1464 (0.1528)  loss_box_reg: 0.1276 (0.1424)  loss_objectness: 0.0967 (0.1070)  loss_rpn_box_reg: 0.0250 (0.0426)  time: 0.3218  data: 0.1433  max mem: 4022\n",
      "Training Epoch: [9]  [ 330/1229]  eta: 0:04:53  lr: 0.005000  loss: 0.3421 (0.4407)  loss_classifier: 0.1066 (0.1514)  loss_box_reg: 0.0935 (0.1407)  loss_objectness: 0.0930 (0.1064)  loss_rpn_box_reg: 0.0145 (0.0421)  time: 0.3285  data: 0.1476  max mem: 4022\n",
      "Training Epoch: [9]  [ 340/1229]  eta: 0:04:50  lr: 0.005000  loss: 0.2860 (0.4391)  loss_classifier: 0.0969 (0.1509)  loss_box_reg: 0.0709 (0.1394)  loss_objectness: 0.0807 (0.1067)  loss_rpn_box_reg: 0.0125 (0.0422)  time: 0.3410  data: 0.1521  max mem: 4022\n",
      "Training Epoch: [9]  [ 350/1229]  eta: 0:04:47  lr: 0.005000  loss: 0.3599 (0.4377)  loss_classifier: 0.1455 (0.1505)  loss_box_reg: 0.1034 (0.1392)  loss_objectness: 0.0778 (0.1063)  loss_rpn_box_reg: 0.0151 (0.0417)  time: 0.3393  data: 0.1511  max mem: 4022\n",
      "Training Epoch: [9]  [ 360/1229]  eta: 0:04:44  lr: 0.005000  loss: 0.4748 (0.4409)  loss_classifier: 0.1496 (0.1515)  loss_box_reg: 0.1302 (0.1397)  loss_objectness: 0.1057 (0.1075)  loss_rpn_box_reg: 0.0219 (0.0421)  time: 0.3270  data: 0.1472  max mem: 4022\n",
      "Training Epoch: [9]  [ 370/1229]  eta: 0:04:40  lr: 0.005000  loss: 0.3724 (0.4385)  loss_classifier: 0.1380 (0.1507)  loss_box_reg: 0.1041 (0.1391)  loss_objectness: 0.0995 (0.1069)  loss_rpn_box_reg: 0.0231 (0.0418)  time: 0.3187  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [9]  [ 380/1229]  eta: 0:04:37  lr: 0.005000  loss: 0.4604 (0.4440)  loss_classifier: 0.1637 (0.1528)  loss_box_reg: 0.1553 (0.1425)  loss_objectness: 0.0949 (0.1071)  loss_rpn_box_reg: 0.0231 (0.0417)  time: 0.3197  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [9]  [ 390/1229]  eta: 0:04:34  lr: 0.005000  loss: 0.5440 (0.4456)  loss_classifier: 0.1765 (0.1530)  loss_box_reg: 0.1553 (0.1425)  loss_objectness: 0.1172 (0.1081)  loss_rpn_box_reg: 0.0280 (0.0420)  time: 0.3232  data: 0.1424  max mem: 4022\n",
      "Training Epoch: [9]  [ 400/1229]  eta: 0:04:30  lr: 0.005000  loss: 0.3835 (0.4427)  loss_classifier: 0.1261 (0.1520)  loss_box_reg: 0.1147 (0.1417)  loss_objectness: 0.0989 (0.1074)  loss_rpn_box_reg: 0.0190 (0.0416)  time: 0.3218  data: 0.1422  max mem: 4022\n",
      "Training Epoch: [9]  [ 410/1229]  eta: 0:04:27  lr: 0.005000  loss: 0.3516 (0.4435)  loss_classifier: 0.1173 (0.1522)  loss_box_reg: 0.1142 (0.1418)  loss_objectness: 0.1077 (0.1077)  loss_rpn_box_reg: 0.0196 (0.0418)  time: 0.3251  data: 0.1414  max mem: 4022\n",
      "Training Epoch: [9]  [ 420/1229]  eta: 0:04:24  lr: 0.005000  loss: 0.3899 (0.4421)  loss_classifier: 0.1252 (0.1518)  loss_box_reg: 0.1179 (0.1415)  loss_objectness: 0.1096 (0.1073)  loss_rpn_box_reg: 0.0270 (0.0415)  time: 0.3237  data: 0.1428  max mem: 4022\n",
      "Training Epoch: [9]  [ 430/1229]  eta: 0:04:20  lr: 0.005000  loss: 0.4029 (0.4414)  loss_classifier: 0.1321 (0.1520)  loss_box_reg: 0.1309 (0.1416)  loss_objectness: 0.0832 (0.1068)  loss_rpn_box_reg: 0.0208 (0.0411)  time: 0.3215  data: 0.1424  max mem: 4022\n",
      "Training Epoch: [9]  [ 440/1229]  eta: 0:04:17  lr: 0.005000  loss: 0.4535 (0.4441)  loss_classifier: 0.1657 (0.1529)  loss_box_reg: 0.1691 (0.1431)  loss_objectness: 0.0855 (0.1070)  loss_rpn_box_reg: 0.0208 (0.0412)  time: 0.3219  data: 0.1433  max mem: 4022\n",
      "Training Epoch: [9]  [ 450/1229]  eta: 0:04:13  lr: 0.005000  loss: 0.5078 (0.4460)  loss_classifier: 0.1738 (0.1537)  loss_box_reg: 0.1768 (0.1439)  loss_objectness: 0.0882 (0.1072)  loss_rpn_box_reg: 0.0246 (0.0412)  time: 0.3175  data: 0.1423  max mem: 4022\n",
      "Training Epoch: [9]  [ 460/1229]  eta: 0:04:10  lr: 0.005000  loss: 0.4144 (0.4439)  loss_classifier: 0.1554 (0.1531)  loss_box_reg: 0.1493 (0.1430)  loss_objectness: 0.0851 (0.1068)  loss_rpn_box_reg: 0.0231 (0.0409)  time: 0.3203  data: 0.1374  max mem: 4022\n",
      "Training Epoch: [9]  [ 470/1229]  eta: 0:04:07  lr: 0.005000  loss: 0.3828 (0.4426)  loss_classifier: 0.1195 (0.1529)  loss_box_reg: 0.1120 (0.1428)  loss_objectness: 0.0845 (0.1066)  loss_rpn_box_reg: 0.0157 (0.0405)  time: 0.3192  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [9]  [ 480/1229]  eta: 0:04:03  lr: 0.005000  loss: 0.4143 (0.4446)  loss_classifier: 0.1682 (0.1539)  loss_box_reg: 0.1494 (0.1439)  loss_objectness: 0.0837 (0.1065)  loss_rpn_box_reg: 0.0289 (0.0402)  time: 0.3221  data: 0.1440  max mem: 4022\n",
      "Training Epoch: [9]  [ 490/1229]  eta: 0:04:00  lr: 0.005000  loss: 0.5133 (0.4459)  loss_classifier: 0.1706 (0.1541)  loss_box_reg: 0.1513 (0.1443)  loss_objectness: 0.1063 (0.1072)  loss_rpn_box_reg: 0.0354 (0.0403)  time: 0.3238  data: 0.1434  max mem: 4022\n",
      "Training Epoch: [9]  [ 500/1229]  eta: 0:03:57  lr: 0.005000  loss: 0.3312 (0.4437)  loss_classifier: 0.1296 (0.1534)  loss_box_reg: 0.1062 (0.1434)  loss_objectness: 0.0997 (0.1069)  loss_rpn_box_reg: 0.0262 (0.0401)  time: 0.3256  data: 0.1439  max mem: 4022\n",
      "Training Epoch: [9]  [ 510/1229]  eta: 0:03:54  lr: 0.005000  loss: 0.2854 (0.4422)  loss_classifier: 0.1113 (0.1530)  loss_box_reg: 0.0760 (0.1423)  loss_objectness: 0.0867 (0.1068)  loss_rpn_box_reg: 0.0170 (0.0401)  time: 0.3296  data: 0.1431  max mem: 4022\n",
      "Training Epoch: [9]  [ 520/1229]  eta: 0:03:50  lr: 0.005000  loss: 0.3816 (0.4423)  loss_classifier: 0.1207 (0.1532)  loss_box_reg: 0.0964 (0.1422)  loss_objectness: 0.0994 (0.1065)  loss_rpn_box_reg: 0.0224 (0.0403)  time: 0.3224  data: 0.1412  max mem: 4022\n",
      "Training Epoch: [9]  [ 530/1229]  eta: 0:03:47  lr: 0.005000  loss: 0.3886 (0.4417)  loss_classifier: 0.1532 (0.1532)  loss_box_reg: 0.1275 (0.1423)  loss_objectness: 0.0775 (0.1061)  loss_rpn_box_reg: 0.0224 (0.0401)  time: 0.3215  data: 0.1425  max mem: 4022\n",
      "Training Epoch: [9]  [ 540/1229]  eta: 0:03:44  lr: 0.005000  loss: 0.5033 (0.4416)  loss_classifier: 0.1786 (0.1530)  loss_box_reg: 0.1387 (0.1425)  loss_objectness: 0.0775 (0.1059)  loss_rpn_box_reg: 0.0274 (0.0402)  time: 0.3235  data: 0.1431  max mem: 4022\n",
      "Training Epoch: [9]  [ 550/1229]  eta: 0:03:40  lr: 0.005000  loss: 0.4173 (0.4428)  loss_classifier: 0.1422 (0.1536)  loss_box_reg: 0.1224 (0.1427)  loss_objectness: 0.0830 (0.1060)  loss_rpn_box_reg: 0.0274 (0.0406)  time: 0.3218  data: 0.1432  max mem: 4022\n",
      "Training Epoch: [9]  [ 560/1229]  eta: 0:03:37  lr: 0.005000  loss: 0.5051 (0.4466)  loss_classifier: 0.1627 (0.1547)  loss_box_reg: 0.1608 (0.1442)  loss_objectness: 0.0839 (0.1063)  loss_rpn_box_reg: 0.0272 (0.0414)  time: 0.3246  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [9]  [ 570/1229]  eta: 0:03:34  lr: 0.005000  loss: 0.5169 (0.4471)  loss_classifier: 0.1627 (0.1548)  loss_box_reg: 0.1449 (0.1441)  loss_objectness: 0.1211 (0.1066)  loss_rpn_box_reg: 0.0227 (0.0416)  time: 0.3276  data: 0.1413  max mem: 4022\n",
      "Training Epoch: [9]  [ 580/1229]  eta: 0:03:31  lr: 0.005000  loss: 0.3547 (0.4467)  loss_classifier: 0.1123 (0.1544)  loss_box_reg: 0.1036 (0.1435)  loss_objectness: 0.1199 (0.1067)  loss_rpn_box_reg: 0.0317 (0.0421)  time: 0.3237  data: 0.1424  max mem: 4022\n",
      "Training Epoch: [9]  [ 590/1229]  eta: 0:03:27  lr: 0.005000  loss: 0.3547 (0.4459)  loss_classifier: 0.1123 (0.1540)  loss_box_reg: 0.1036 (0.1430)  loss_objectness: 0.0947 (0.1069)  loss_rpn_box_reg: 0.0211 (0.0420)  time: 0.3159  data: 0.1418  max mem: 4022\n",
      "Training Epoch: [9]  [ 600/1229]  eta: 0:03:24  lr: 0.005000  loss: 0.4151 (0.4469)  loss_classifier: 0.1390 (0.1543)  loss_box_reg: 0.0898 (0.1427)  loss_objectness: 0.1200 (0.1075)  loss_rpn_box_reg: 0.0211 (0.0424)  time: 0.3217  data: 0.1421  max mem: 4022\n",
      "Training Epoch: [9]  [ 610/1229]  eta: 0:03:21  lr: 0.005000  loss: 0.4151 (0.4455)  loss_classifier: 0.1363 (0.1537)  loss_box_reg: 0.0867 (0.1418)  loss_objectness: 0.1200 (0.1075)  loss_rpn_box_reg: 0.0241 (0.0425)  time: 0.3364  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [9]  [ 620/1229]  eta: 0:03:18  lr: 0.005000  loss: 0.4103 (0.4456)  loss_classifier: 0.1144 (0.1537)  loss_box_reg: 0.1069 (0.1418)  loss_objectness: 0.0929 (0.1075)  loss_rpn_box_reg: 0.0256 (0.0426)  time: 0.3318  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [9]  [ 630/1229]  eta: 0:03:15  lr: 0.005000  loss: 0.4103 (0.4443)  loss_classifier: 0.1394 (0.1532)  loss_box_reg: 0.1196 (0.1414)  loss_objectness: 0.0897 (0.1073)  loss_rpn_box_reg: 0.0263 (0.0424)  time: 0.3276  data: 0.1417  max mem: 4022\n",
      "Training Epoch: [9]  [ 640/1229]  eta: 0:03:11  lr: 0.005000  loss: 0.2822 (0.4422)  loss_classifier: 0.0995 (0.1526)  loss_box_reg: 0.0866 (0.1407)  loss_objectness: 0.0764 (0.1068)  loss_rpn_box_reg: 0.0171 (0.0421)  time: 0.3310  data: 0.1399  max mem: 4022\n",
      "Training Epoch: [9]  [ 650/1229]  eta: 0:03:08  lr: 0.005000  loss: 0.2822 (0.4429)  loss_classifier: 0.1161 (0.1529)  loss_box_reg: 0.1027 (0.1407)  loss_objectness: 0.0920 (0.1070)  loss_rpn_box_reg: 0.0200 (0.0423)  time: 0.3312  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [9]  [ 660/1229]  eta: 0:03:05  lr: 0.005000  loss: 0.5095 (0.4422)  loss_classifier: 0.1368 (0.1526)  loss_box_reg: 0.1535 (0.1407)  loss_objectness: 0.0913 (0.1066)  loss_rpn_box_reg: 0.0224 (0.0423)  time: 0.3251  data: 0.1430  max mem: 4022\n",
      "Training Epoch: [9]  [ 670/1229]  eta: 0:03:02  lr: 0.005000  loss: 0.5131 (0.4429)  loss_classifier: 0.1368 (0.1527)  loss_box_reg: 0.1582 (0.1411)  loss_objectness: 0.0897 (0.1068)  loss_rpn_box_reg: 0.0248 (0.0424)  time: 0.3227  data: 0.1425  max mem: 4022\n",
      "Training Epoch: [9]  [ 680/1229]  eta: 0:02:58  lr: 0.005000  loss: 0.5296 (0.4441)  loss_classifier: 0.1666 (0.1529)  loss_box_reg: 0.1849 (0.1418)  loss_objectness: 0.1144 (0.1067)  loss_rpn_box_reg: 0.0318 (0.0426)  time: 0.3273  data: 0.1387  max mem: 4022\n",
      "Training Epoch: [9]  [ 690/1229]  eta: 0:02:55  lr: 0.005000  loss: 0.5470 (0.4458)  loss_classifier: 0.1827 (0.1539)  loss_box_reg: 0.1770 (0.1425)  loss_objectness: 0.1018 (0.1069)  loss_rpn_box_reg: 0.0344 (0.0425)  time: 0.3264  data: 0.1385  max mem: 4022\n",
      "Training Epoch: [9]  [ 700/1229]  eta: 0:02:52  lr: 0.005000  loss: 0.5470 (0.4461)  loss_classifier: 0.1775 (0.1541)  loss_box_reg: 0.1627 (0.1428)  loss_objectness: 0.1018 (0.1068)  loss_rpn_box_reg: 0.0250 (0.0425)  time: 0.3250  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [9]  [ 710/1229]  eta: 0:02:49  lr: 0.005000  loss: 0.4096 (0.4462)  loss_classifier: 0.1472 (0.1543)  loss_box_reg: 0.1239 (0.1429)  loss_objectness: 0.0995 (0.1067)  loss_rpn_box_reg: 0.0243 (0.0423)  time: 0.3285  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [9]  [ 720/1229]  eta: 0:02:45  lr: 0.005000  loss: 0.4208 (0.4481)  loss_classifier: 0.1548 (0.1551)  loss_box_reg: 0.1239 (0.1437)  loss_objectness: 0.1024 (0.1071)  loss_rpn_box_reg: 0.0243 (0.0422)  time: 0.3262  data: 0.1407  max mem: 4022\n",
      "Training Epoch: [9]  [ 730/1229]  eta: 0:02:42  lr: 0.005000  loss: 0.5973 (0.4492)  loss_classifier: 0.2042 (0.1555)  loss_box_reg: 0.1557 (0.1440)  loss_objectness: 0.1160 (0.1073)  loss_rpn_box_reg: 0.0327 (0.0425)  time: 0.3208  data: 0.1416  max mem: 4022\n",
      "Training Epoch: [9]  [ 740/1229]  eta: 0:02:39  lr: 0.005000  loss: 0.5190 (0.4499)  loss_classifier: 0.1762 (0.1556)  loss_box_reg: 0.1897 (0.1446)  loss_objectness: 0.1159 (0.1073)  loss_rpn_box_reg: 0.0352 (0.0424)  time: 0.3215  data: 0.1382  max mem: 4022\n",
      "Training Epoch: [9]  [ 750/1229]  eta: 0:02:35  lr: 0.005000  loss: 0.4726 (0.4496)  loss_classifier: 0.1634 (0.1556)  loss_box_reg: 0.1405 (0.1443)  loss_objectness: 0.0933 (0.1073)  loss_rpn_box_reg: 0.0238 (0.0424)  time: 0.3242  data: 0.1366  max mem: 4022\n",
      "Training Epoch: [9]  [ 760/1229]  eta: 0:02:32  lr: 0.005000  loss: 0.4004 (0.4497)  loss_classifier: 0.1413 (0.1555)  loss_box_reg: 0.0991 (0.1444)  loss_objectness: 0.0807 (0.1072)  loss_rpn_box_reg: 0.0300 (0.0425)  time: 0.3299  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [9]  [ 770/1229]  eta: 0:02:29  lr: 0.005000  loss: 0.4004 (0.4500)  loss_classifier: 0.1196 (0.1554)  loss_box_reg: 0.1134 (0.1444)  loss_objectness: 0.0749 (0.1072)  loss_rpn_box_reg: 0.0258 (0.0430)  time: 0.3298  data: 0.1366  max mem: 4022\n",
      "Training Epoch: [9]  [ 780/1229]  eta: 0:02:26  lr: 0.005000  loss: 0.4036 (0.4502)  loss_classifier: 0.1196 (0.1555)  loss_box_reg: 0.1130 (0.1444)  loss_objectness: 0.0870 (0.1073)  loss_rpn_box_reg: 0.0269 (0.0430)  time: 0.3239  data: 0.1368  max mem: 4022\n",
      "Training Epoch: [9]  [ 790/1229]  eta: 0:02:22  lr: 0.005000  loss: 0.4036 (0.4500)  loss_classifier: 0.1566 (0.1555)  loss_box_reg: 0.1092 (0.1441)  loss_objectness: 0.1120 (0.1073)  loss_rpn_box_reg: 0.0349 (0.0430)  time: 0.3246  data: 0.1376  max mem: 4022\n",
      "Training Epoch: [9]  [ 800/1229]  eta: 0:02:19  lr: 0.005000  loss: 0.3700 (0.4494)  loss_classifier: 0.1533 (0.1555)  loss_box_reg: 0.1050 (0.1440)  loss_objectness: 0.0884 (0.1070)  loss_rpn_box_reg: 0.0219 (0.0429)  time: 0.3251  data: 0.1379  max mem: 4022\n",
      "Training Epoch: [9]  [ 810/1229]  eta: 0:02:16  lr: 0.005000  loss: 0.4571 (0.4501)  loss_classifier: 0.1636 (0.1560)  loss_box_reg: 0.1275 (0.1442)  loss_objectness: 0.0899 (0.1071)  loss_rpn_box_reg: 0.0232 (0.0428)  time: 0.3282  data: 0.1382  max mem: 4022\n",
      "Training Epoch: [9]  [ 820/1229]  eta: 0:02:13  lr: 0.005000  loss: 0.4126 (0.4493)  loss_classifier: 0.1705 (0.1557)  loss_box_reg: 0.1297 (0.1440)  loss_objectness: 0.0888 (0.1069)  loss_rpn_box_reg: 0.0248 (0.0428)  time: 0.3332  data: 0.1380  max mem: 4022\n",
      "Training Epoch: [9]  [ 830/1229]  eta: 0:02:09  lr: 0.005000  loss: 0.2824 (0.4479)  loss_classifier: 0.1021 (0.1552)  loss_box_reg: 0.0962 (0.1436)  loss_objectness: 0.0750 (0.1065)  loss_rpn_box_reg: 0.0183 (0.0426)  time: 0.3265  data: 0.1393  max mem: 4022\n",
      "Training Epoch: [9]  [ 840/1229]  eta: 0:02:06  lr: 0.005000  loss: 0.4288 (0.4495)  loss_classifier: 0.1550 (0.1558)  loss_box_reg: 0.1094 (0.1443)  loss_objectness: 0.0819 (0.1068)  loss_rpn_box_reg: 0.0281 (0.0426)  time: 0.3225  data: 0.1408  max mem: 4022\n",
      "Training Epoch: [9]  [ 850/1229]  eta: 0:02:03  lr: 0.005000  loss: 0.4822 (0.4490)  loss_classifier: 0.1681 (0.1556)  loss_box_reg: 0.1586 (0.1441)  loss_objectness: 0.1063 (0.1068)  loss_rpn_box_reg: 0.0312 (0.0425)  time: 0.3231  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [9]  [ 860/1229]  eta: 0:02:00  lr: 0.005000  loss: 0.4310 (0.4493)  loss_classifier: 0.1468 (0.1558)  loss_box_reg: 0.1552 (0.1443)  loss_objectness: 0.0868 (0.1067)  loss_rpn_box_reg: 0.0234 (0.0424)  time: 0.3241  data: 0.1366  max mem: 4022\n",
      "Training Epoch: [9]  [ 870/1229]  eta: 0:01:56  lr: 0.005000  loss: 0.3911 (0.4493)  loss_classifier: 0.1502 (0.1559)  loss_box_reg: 0.1252 (0.1442)  loss_objectness: 0.0819 (0.1067)  loss_rpn_box_reg: 0.0188 (0.0424)  time: 0.3272  data: 0.1373  max mem: 4022\n",
      "Training Epoch: [9]  [ 880/1229]  eta: 0:01:53  lr: 0.005000  loss: 0.3911 (0.4489)  loss_classifier: 0.1391 (0.1558)  loss_box_reg: 0.1168 (0.1440)  loss_objectness: 0.0808 (0.1065)  loss_rpn_box_reg: 0.0272 (0.0425)  time: 0.3299  data: 0.1384  max mem: 4022\n",
      "Training Epoch: [9]  [ 890/1229]  eta: 0:01:50  lr: 0.005000  loss: 0.4592 (0.4493)  loss_classifier: 0.1374 (0.1558)  loss_box_reg: 0.1294 (0.1440)  loss_objectness: 0.1061 (0.1067)  loss_rpn_box_reg: 0.0392 (0.0428)  time: 0.3296  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [9]  [ 900/1229]  eta: 0:01:47  lr: 0.005000  loss: 0.4287 (0.4488)  loss_classifier: 0.1385 (0.1556)  loss_box_reg: 0.1185 (0.1439)  loss_objectness: 0.0933 (0.1066)  loss_rpn_box_reg: 0.0231 (0.0427)  time: 0.3232  data: 0.1391  max mem: 4022\n",
      "Training Epoch: [9]  [ 910/1229]  eta: 0:01:43  lr: 0.005000  loss: 0.3070 (0.4486)  loss_classifier: 0.1056 (0.1555)  loss_box_reg: 0.1055 (0.1441)  loss_objectness: 0.0718 (0.1063)  loss_rpn_box_reg: 0.0124 (0.0426)  time: 0.3206  data: 0.1390  max mem: 4022\n",
      "Training Epoch: [9]  [ 920/1229]  eta: 0:01:40  lr: 0.005000  loss: 0.3087 (0.4482)  loss_classifier: 0.0998 (0.1555)  loss_box_reg: 0.0967 (0.1439)  loss_objectness: 0.0743 (0.1062)  loss_rpn_box_reg: 0.0252 (0.0426)  time: 0.3248  data: 0.1398  max mem: 4022\n",
      "Training Epoch: [9]  [ 930/1229]  eta: 0:01:37  lr: 0.005000  loss: 0.3582 (0.4482)  loss_classifier: 0.1625 (0.1556)  loss_box_reg: 0.1470 (0.1441)  loss_objectness: 0.0774 (0.1060)  loss_rpn_box_reg: 0.0272 (0.0426)  time: 0.3276  data: 0.1378  max mem: 4022\n",
      "Training Epoch: [9]  [ 940/1229]  eta: 0:01:34  lr: 0.005000  loss: 0.3582 (0.4475)  loss_classifier: 0.1312 (0.1554)  loss_box_reg: 0.1200 (0.1436)  loss_objectness: 0.0774 (0.1060)  loss_rpn_box_reg: 0.0238 (0.0425)  time: 0.3279  data: 0.1358  max mem: 4022\n",
      "Training Epoch: [9]  [ 950/1229]  eta: 0:01:30  lr: 0.005000  loss: 0.3199 (0.4466)  loss_classifier: 0.1003 (0.1551)  loss_box_reg: 0.0760 (0.1431)  loss_objectness: 0.0880 (0.1058)  loss_rpn_box_reg: 0.0225 (0.0425)  time: 0.3215  data: 0.1367  max mem: 4022\n",
      "Training Epoch: [9]  [ 960/1229]  eta: 0:01:27  lr: 0.005000  loss: 0.3398 (0.4460)  loss_classifier: 0.1310 (0.1550)  loss_box_reg: 0.0943 (0.1426)  loss_objectness: 0.0890 (0.1060)  loss_rpn_box_reg: 0.0221 (0.0423)  time: 0.3231  data: 0.1394  max mem: 4022\n",
      "Training Epoch: [9]  [ 970/1229]  eta: 0:01:24  lr: 0.005000  loss: 0.3398 (0.4454)  loss_classifier: 0.1353 (0.1548)  loss_box_reg: 0.1001 (0.1424)  loss_objectness: 0.0890 (0.1060)  loss_rpn_box_reg: 0.0164 (0.0422)  time: 0.3300  data: 0.1404  max mem: 4022\n",
      "Training Epoch: [9]  [ 980/1229]  eta: 0:01:21  lr: 0.005000  loss: 0.3887 (0.4464)  loss_classifier: 0.1462 (0.1551)  loss_box_reg: 0.1117 (0.1428)  loss_objectness: 0.0938 (0.1062)  loss_rpn_box_reg: 0.0331 (0.0424)  time: 0.3251  data: 0.1384  max mem: 4022\n",
      "Training Epoch: [9]  [ 990/1229]  eta: 0:01:17  lr: 0.005000  loss: 0.3415 (0.4459)  loss_classifier: 0.1166 (0.1548)  loss_box_reg: 0.0958 (0.1426)  loss_objectness: 0.0928 (0.1059)  loss_rpn_box_reg: 0.0271 (0.0425)  time: 0.3249  data: 0.1395  max mem: 4022\n",
      "Training Epoch: [9]  [1000/1229]  eta: 0:01:14  lr: 0.005000  loss: 0.2953 (0.4458)  loss_classifier: 0.1192 (0.1548)  loss_box_reg: 0.0933 (0.1425)  loss_objectness: 0.0886 (0.1060)  loss_rpn_box_reg: 0.0192 (0.0424)  time: 0.3347  data: 0.1410  max mem: 4022\n",
      "Training Epoch: [9]  [1010/1229]  eta: 0:01:11  lr: 0.005000  loss: 0.3691 (0.4457)  loss_classifier: 0.1283 (0.1549)  loss_box_reg: 0.0967 (0.1424)  loss_objectness: 0.0894 (0.1060)  loss_rpn_box_reg: 0.0238 (0.0424)  time: 0.3286  data: 0.1394  max mem: 4022\n",
      "Training Epoch: [9]  [1020/1229]  eta: 0:01:08  lr: 0.005000  loss: 0.3832 (0.4462)  loss_classifier: 0.1304 (0.1552)  loss_box_reg: 0.1306 (0.1426)  loss_objectness: 0.0959 (0.1059)  loss_rpn_box_reg: 0.0268 (0.0424)  time: 0.3217  data: 0.1388  max mem: 4022\n",
      "Training Epoch: [9]  [1030/1229]  eta: 0:01:04  lr: 0.005000  loss: 0.4040 (0.4457)  loss_classifier: 0.1303 (0.1549)  loss_box_reg: 0.1225 (0.1424)  loss_objectness: 0.0967 (0.1060)  loss_rpn_box_reg: 0.0231 (0.0423)  time: 0.3177  data: 0.1374  max mem: 4022\n",
      "Training Epoch: [9]  [1040/1229]  eta: 0:01:01  lr: 0.005000  loss: 0.4291 (0.4462)  loss_classifier: 0.1310 (0.1550)  loss_box_reg: 0.1155 (0.1423)  loss_objectness: 0.1094 (0.1064)  loss_rpn_box_reg: 0.0231 (0.0425)  time: 0.3149  data: 0.1392  max mem: 4022\n",
      "Training Epoch: [9]  [1050/1229]  eta: 0:00:58  lr: 0.005000  loss: 0.4474 (0.4460)  loss_classifier: 0.1364 (0.1549)  loss_box_reg: 0.1059 (0.1421)  loss_objectness: 0.1054 (0.1065)  loss_rpn_box_reg: 0.0301 (0.0426)  time: 0.3220  data: 0.1403  max mem: 4022\n",
      "Training Epoch: [9]  [1060/1229]  eta: 0:00:55  lr: 0.005000  loss: 0.3290 (0.4453)  loss_classifier: 0.1148 (0.1546)  loss_box_reg: 0.0910 (0.1418)  loss_objectness: 0.0782 (0.1063)  loss_rpn_box_reg: 0.0291 (0.0426)  time: 0.3255  data: 0.1406  max mem: 4022\n",
      "Training Epoch: [9]  [1070/1229]  eta: 0:00:51  lr: 0.005000  loss: 0.3320 (0.4453)  loss_classifier: 0.1152 (0.1546)  loss_box_reg: 0.0928 (0.1418)  loss_objectness: 0.0708 (0.1062)  loss_rpn_box_reg: 0.0218 (0.0428)  time: 0.3280  data: 0.1445  max mem: 4022\n",
      "Training Epoch: [9]  [1080/1229]  eta: 0:00:48  lr: 0.005000  loss: 0.3736 (0.4454)  loss_classifier: 0.1237 (0.1546)  loss_box_reg: 0.0972 (0.1418)  loss_objectness: 0.0913 (0.1063)  loss_rpn_box_reg: 0.0200 (0.0427)  time: 0.3316  data: 0.1478  max mem: 4022\n",
      "Training Epoch: [9]  [1090/1229]  eta: 0:00:45  lr: 0.005000  loss: 0.3353 (0.4451)  loss_classifier: 0.1189 (0.1544)  loss_box_reg: 0.1108 (0.1419)  loss_objectness: 0.1012 (0.1062)  loss_rpn_box_reg: 0.0174 (0.0426)  time: 0.3306  data: 0.1464  max mem: 4022\n",
      "Training Epoch: [9]  [1100/1229]  eta: 0:00:42  lr: 0.005000  loss: 0.3353 (0.4445)  loss_classifier: 0.1105 (0.1542)  loss_box_reg: 0.1108 (0.1416)  loss_objectness: 0.0781 (0.1061)  loss_rpn_box_reg: 0.0232 (0.0426)  time: 0.3284  data: 0.1405  max mem: 4022\n",
      "Training Epoch: [9]  [1110/1229]  eta: 0:00:38  lr: 0.005000  loss: 0.4084 (0.4449)  loss_classifier: 0.1438 (0.1542)  loss_box_reg: 0.0975 (0.1416)  loss_objectness: 0.0970 (0.1062)  loss_rpn_box_reg: 0.0283 (0.0428)  time: 0.3247  data: 0.1369  max mem: 4022\n",
      "Training Epoch: [9]  [1120/1229]  eta: 0:00:35  lr: 0.005000  loss: 0.4449 (0.4457)  loss_classifier: 0.1645 (0.1546)  loss_box_reg: 0.1500 (0.1421)  loss_objectness: 0.1067 (0.1063)  loss_rpn_box_reg: 0.0267 (0.0428)  time: 0.3209  data: 0.1385  max mem: 4022\n",
      "Training Epoch: [9]  [1130/1229]  eta: 0:00:32  lr: 0.005000  loss: 0.4210 (0.4463)  loss_classifier: 0.1503 (0.1545)  loss_box_reg: 0.1427 (0.1420)  loss_objectness: 0.1234 (0.1067)  loss_rpn_box_reg: 0.0269 (0.0430)  time: 0.3247  data: 0.1415  max mem: 4022\n",
      "Training Epoch: [9]  [1140/1229]  eta: 0:00:28  lr: 0.005000  loss: 0.3809 (0.4468)  loss_classifier: 0.1366 (0.1547)  loss_box_reg: 0.1233 (0.1420)  loss_objectness: 0.1246 (0.1069)  loss_rpn_box_reg: 0.0382 (0.0431)  time: 0.3253  data: 0.1397  max mem: 4022\n",
      "Training Epoch: [9]  [1150/1229]  eta: 0:00:25  lr: 0.005000  loss: 0.4403 (0.4474)  loss_classifier: 0.1497 (0.1548)  loss_box_reg: 0.1586 (0.1423)  loss_objectness: 0.1190 (0.1071)  loss_rpn_box_reg: 0.0430 (0.0432)  time: 0.3263  data: 0.1384  max mem: 4022\n",
      "Training Epoch: [9]  [1160/1229]  eta: 0:00:22  lr: 0.005000  loss: 0.3592 (0.4470)  loss_classifier: 0.1078 (0.1546)  loss_box_reg: 0.1157 (0.1423)  loss_objectness: 0.0848 (0.1069)  loss_rpn_box_reg: 0.0309 (0.0431)  time: 0.3266  data: 0.1400  max mem: 4022\n",
      "Training Epoch: [9]  [1170/1229]  eta: 0:00:19  lr: 0.005000  loss: 0.3150 (0.4470)  loss_classifier: 0.1096 (0.1547)  loss_box_reg: 0.1104 (0.1423)  loss_objectness: 0.0725 (0.1070)  loss_rpn_box_reg: 0.0265 (0.0430)  time: 0.3228  data: 0.1396  max mem: 4022\n",
      "Training Epoch: [9]  [1180/1229]  eta: 0:00:15  lr: 0.005000  loss: 0.3150 (0.4467)  loss_classifier: 0.1227 (0.1547)  loss_box_reg: 0.1091 (0.1423)  loss_objectness: 0.0695 (0.1068)  loss_rpn_box_reg: 0.0207 (0.0429)  time: 0.3206  data: 0.1368  max mem: 4022\n",
      "Training Epoch: [9]  [1190/1229]  eta: 0:00:12  lr: 0.005000  loss: 0.3113 (0.4461)  loss_classifier: 0.1188 (0.1545)  loss_box_reg: 0.1081 (0.1422)  loss_objectness: 0.0672 (0.1067)  loss_rpn_box_reg: 0.0170 (0.0428)  time: 0.3238  data: 0.1391  max mem: 4022\n",
      "Training Epoch: [9]  [1200/1229]  eta: 0:00:09  lr: 0.005000  loss: 0.3398 (0.4456)  loss_classifier: 0.1188 (0.1543)  loss_box_reg: 0.1178 (0.1421)  loss_objectness: 0.0726 (0.1066)  loss_rpn_box_reg: 0.0246 (0.0426)  time: 0.3272  data: 0.1402  max mem: 4022\n",
      "Training Epoch: [9]  [1210/1229]  eta: 0:00:06  lr: 0.005000  loss: 0.3474 (0.4454)  loss_classifier: 0.1236 (0.1543)  loss_box_reg: 0.1265 (0.1422)  loss_objectness: 0.0826 (0.1064)  loss_rpn_box_reg: 0.0250 (0.0425)  time: 0.3277  data: 0.1371  max mem: 4022\n",
      "Training Epoch: [9]  [1220/1229]  eta: 0:00:02  lr: 0.005000  loss: 0.4558 (0.4464)  loss_classifier: 0.1613 (0.1546)  loss_box_reg: 0.1587 (0.1425)  loss_objectness: 0.1018 (0.1067)  loss_rpn_box_reg: 0.0249 (0.0426)  time: 0.3241  data: 0.1377  max mem: 4022\n",
      "Training Epoch: [9]  [1228/1229]  eta: 0:00:00  lr: 0.005000  loss: 0.4443 (0.4463)  loss_classifier: 0.1613 (0.1545)  loss_box_reg: 0.1587 (0.1424)  loss_objectness: 0.1027 (0.1067)  loss_rpn_box_reg: 0.0249 (0.0426)  time: 0.3239  data: 0.1400  max mem: 4022\n",
      "Training Epoch: [9] Total time: 0:06:40 (0.3257 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/308]  eta: 0:02:05  model_time: 0.3710 (0.3710)  evaluator_time: 0.0030 (0.0030)  time: 0.4060  data: 0.0300  max mem: 4022\n",
      "Test:  [100/308]  eta: 0:00:33  model_time: 0.1070 (0.1124)  evaluator_time: 0.0030 (0.0070)  time: 0.1581  data: 0.0383  max mem: 4022\n",
      "Test:  [200/308]  eta: 0:00:16  model_time: 0.1160 (0.1117)  evaluator_time: 0.0030 (0.0064)  time: 0.1536  data: 0.0321  max mem: 4022\n",
      "Test:  [300/308]  eta: 0:00:01  model_time: 0.0990 (0.1104)  evaluator_time: 0.0040 (0.0062)  time: 0.1482  data: 0.0378  max mem: 4022\n",
      "Test:  [307/308]  eta: 0:00:00  model_time: 0.0990 (0.1101)  evaluator_time: 0.0030 (0.0062)  time: 0.1501  data: 0.0417  max mem: 4022\n",
      "Test: Total time: 0:00:47 (0.1552 s / it)\n",
      "Averaged stats: model_time: 0.0990 (0.1101)  evaluator_time: 0.0030 (0.0062)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.038\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.083\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.274\n",
      "Testing Epoch: [9]  [  0/308]  eta: 0:00:46  lr: 0.005000  loss: 0.2042 (0.2042)  loss_classifier: 0.0727 (0.0727)  loss_box_reg: 0.0752 (0.0752)  loss_objectness: 0.0444 (0.0444)  loss_rpn_box_reg: 0.0119 (0.0119)  time: 0.1510  data: 0.0300  max mem: 4022\n",
      "Testing Epoch: [9]  [100/308]  eta: 0:00:36  lr: 0.005000  loss: 0.3174 (0.5183)  loss_classifier: 0.1245 (0.1771)  loss_box_reg: 0.1294 (0.1768)  loss_objectness: 0.0739 (0.1084)  loss_rpn_box_reg: 0.0179 (0.0561)  time: 0.1782  data: 0.0420  max mem: 4022\n",
      "Testing Epoch: [9]  [200/308]  eta: 0:00:19  lr: 0.005000  loss: 0.4543 (0.4931)  loss_classifier: 0.1338 (0.1691)  loss_box_reg: 0.1636 (0.1670)  loss_objectness: 0.0845 (0.1043)  loss_rpn_box_reg: 0.0274 (0.0527)  time: 0.1785  data: 0.0354  max mem: 4022\n",
      "Testing Epoch: [9]  [300/308]  eta: 0:00:01  lr: 0.005000  loss: 0.4778 (0.4951)  loss_classifier: 0.1793 (0.1714)  loss_box_reg: 0.1777 (0.1703)  loss_objectness: 0.0973 (0.1020)  loss_rpn_box_reg: 0.0343 (0.0514)  time: 0.1694  data: 0.0421  max mem: 4022\n",
      "Testing Epoch: [9]  [307/308]  eta: 0:00:00  lr: 0.005000  loss: 0.4743 (0.4950)  loss_classifier: 0.1612 (0.1717)  loss_box_reg: 0.1702 (0.1705)  loss_objectness: 0.0888 (0.1019)  loss_rpn_box_reg: 0.0293 (0.0509)  time: 0.1729  data: 0.0454  max mem: 4022\n",
      "Testing Epoch: [9] Total time: 0:00:54 (0.1766 s / it)\n"
     ]
    }
   ],
   "source": [
    "#train a custom vanilla model so that we can compare and make sure the CLIP FRCNN is comparable\n",
    "# Fully-Custom-Vanilla is most appropriate as it generates the model in a similar fashion\n",
    "MODEL_TYPE = 'Fully-Custom-Vanilla'\n",
    "\n",
    "vanilla_model = create_model(MODEL_TYPE, num_classes=(len(item_list)+1))\n",
    "train_model(vanilla_model, train_dataset, evaluation_dataset, num_epochs=10, MODEL_TYPE=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj3vLT1eXFnk"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkzG1i3AW1O7",
    "outputId": "ec7971c3-66ef-4a57-e710-248cb53dee8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      " 100% || 615/615 [45.2s elapsed, 0s remaining, 13.6 samples/s]      \n",
      "Evaluating detections...\n",
      " 100% || 615/615 [11.0s elapsed, 0s remaining, 59.3 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% || 615/615 [14.2s elapsed, 0s remaining, 47.1 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "add_detections(model, evaluation_dataset, fo_dataset, field_name=\"predictions\")\n",
    "\n",
    "results = fo.evaluate_detections(\n",
    "    test_view,\n",
    "    \"predictions\",\n",
    "    classes=item_list,\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uYdXrhgYdJ_",
    "outputId": "2eb792e9-342f-4dc8-f6c0-e1503d8bf193"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.12274161085786321"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcJBOM76aJPR",
    "outputId": "ac452527-7608-4e8d-f57e-18a0470acd30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.10      0.59      0.17       508\n",
      "         dog       0.15      0.80      0.25        41\n",
      "         bus       0.13      0.70      0.22        90\n",
      "        fork       0.09      0.18      0.12        44\n",
      "         tie       0.11      0.10      0.11        29\n",
      "      person       0.31      0.86      0.45      4349\n",
      "\n",
      "   micro avg       0.26      0.82      0.39      5061\n",
      "   macro avg       0.15      0.54      0.22      5061\n",
      "weighted avg       0.28      0.82      0.41      5061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nddFfGSnXo7i"
   },
   "source": [
    "By default, objects are only matched with other objects of the same class. In order to get an interesting confusion matrix, we need to match interclass objects by setting `classwise=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_53aCMna2Vt",
    "outputId": "4db71f31-73e3-4036-f623-efd8e2ac85bf"
   },
   "outputs": [],
   "source": [
    "results_interclass = fo.evaluate_detections(\n",
    "    test_view, \n",
    "    \"predictions\", \n",
    "    classes=item_list,\n",
    "    compute_mAP=True, \n",
    "    classwise=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot = results.plot_pr_curves(classes=item_list)\n",
    "plot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "Nbqf-NuAZ7Ps",
    "outputId": "571cd947-c94a-4b9a-ed93-2330fbddea7e"
   },
   "outputs": [],
   "source": [
    "results_interclass.plot_confusion_matrix(classes=item_list, include_other=False, include_missing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElSV7tTbYKLr"
   },
   "source": [
    "The [detection evaluation](https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#detections) also added the attributes `eval_fp`, `eval_tp`, and `eval_fn` to every predicted detection indicating if it is a false positive, true positive, or false negative. \n",
    "Let's create a view to find the worst samples by sorting by `eval_fp` using the [FiftyOne App](https://voxel51.com/docs/fiftyone/user_guide/app.html) to visualize the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786,
     "resources": {
      "https://localhost:5151/polling?sessionId=de0b710e-15f8-4c57-ba46-ae7955f716b1": {
       "data": "eyJtZXNzYWdlcyI6IFtdfQ==",
       "headers": [
        [
         "access-control-allow-headers",
         "x-requested-with"
        ],
        [
         "content-type",
         "text/html; charset=UTF-8"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "Pm4Z52rd8AC1",
    "outputId": "62d39076-7ef3-4fe3-95ae-500d0f8f8a3f"
   },
   "outputs": [],
   "source": [
    "session.view = test_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786,
     "resources": {
      "https://localhost:5151/polling?sessionId=ebbc318d-3578-4fb1-9ae7-68596117572b": {
       "data": "eyJtZXNzYWdlcyI6IFtdfQ==",
       "headers": [
        [
         "access-control-allow-headers",
         "x-requested-with"
        ],
        [
         "content-type",
         "text/html; charset=UTF-8"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "njLG0l5K-ucV",
    "outputId": "bda6f02d-d8fe-49be-d212-31e0e70779e3"
   },
   "outputs": [],
   "source": [
    "session.view = test_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReXDVFgLZLtf"
   },
   "source": [
    "It would be best to get this [data reannotated to fix these mistakes](https://towardsdatascience.com/managing-annotation-mistakes-with-fiftyone-and-labelbox-fc6e87b51102), but in the meantime, we can easily remedy this by simply creating a new view that remaps the labels `car`, `truck`, and `bus` all to `vehicle` and then retraining the model with that. This is only possible because we are backing our data in FiftyOne and loading views into PyTorch as needed. Without FiftyOne, the PyTorch dataset class or the underlying data would need to be changed to remap these classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# map labels to single vehicle class\n",
    "vehicle_list = ['car', 'bus', 'truck']\n",
    "vehicles_map = {c: \"vehicle\" for c in vehicle_list}\n",
    "\n",
    "train_map_view = train_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "test_map_view = test_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "torch_map_dataset = FiftyOneTorchDataset(train_map_view, train_transforms)\n",
    "torch_map_dataset_test = FiftyOneTorchDataset(test_map_view, test_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ynRCHQv8XB_v"
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'model' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19068/3484283395.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Only 2 classes (background and vehicle)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mMODEL_TYPE\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'Vanilla-FRCNN'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mvehicle_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mMODEL_TYPE\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_classes\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvehicles_map\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mtrain_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtorch_map_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtorch_map_dataset_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mMODEL_TYPE\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mMODEL_TYPE\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Git\\Torch_CLIP_FRCNN\\model.py\u001B[0m in \u001B[0;36mcreate_model\u001B[1;34m(model_type, num_classes)\u001B[0m\n\u001B[0;32m    116\u001B[0m                            \u001B[0mimage_std\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSTD\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    117\u001B[0m                            ).half().to(config.DEVICE)\n\u001B[1;32m--> 118\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    119\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    120\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mtest_backbone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mUnboundLocalError\u001B[0m: local variable 'model' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Only 2 classes (background and vehicle)\n",
    "MODEL_TYPE = 'Vanilla-FRCNN'\n",
    "vehicle_model = create_model(MODEL_TYPE, num_classes=(len(vehicles_map)+1))\n",
    "train_model(vehicle_model, torch_map_dataset, torch_map_dataset_test, num_epochs=2, MODEL_TYPE=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-mrVOl4XFbp",
    "outputId": "6d8bec76-ebe8-4a36-959a-52bb1aab8498"
   },
   "outputs": [],
   "source": [
    "add_detections(vehicle_model, torch_map_dataset_test, test_map_view, field_name=\"vehicle_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfd3xvhaXhl_",
    "outputId": "d9c4a2fe-538a-4979-c3f8-f5ede0c98aa1"
   },
   "outputs": [],
   "source": [
    "vehicle_results = fo.evaluate_detections(\n",
    "    test_map_view, \n",
    "    \"vehicle_predictions\", \n",
    "    classes=[\"vehicle\"], \n",
    "    eval_key=\"vehicle_eval\", \n",
    "    compute_mAP=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFvddH3rk0NR",
    "outputId": "59572ba2-f9ad-4dd2-e9ac-90877190ff99"
   },
   "outputs": [],
   "source": [
    "vehicle_results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwbhq18sk1PL",
    "outputId": "d6985867-5049-4678-cc88-d5041a0079ed"
   },
   "outputs": [],
   "source": [
    "vehicle_results.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJMAkJbWZ_u1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Due to our ability to easily visualize and manage our dataset with FiftyOne, we were able to spot and take action on a dataset issue that would otherwise have gone unnoticed if we only concerned ourselves with dataset-wide evaluation metrics and fixed dataset representations. Through these efforts, we managed to increase the mAP of the model to 43%.\n",
    "\n",
    "Even though this example workflow may not work in all situations, this kind of class-merging strategy can be effective in cases where more fine-grained discrimination is not called for."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "fiftyone_pytorch_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "32b6ec3046e64d04b4134553dc434fe0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     },
     "model_module_version": "1.2.0"
    },
    "4a4788a4fd6841788b20cfbf54a3d10b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     },
     "model_module_version": "1.5.0"
    },
    "5d836b94d13e459d82429606496e4d4f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     },
     "model_module_version": "1.2.0"
    },
    "a1645bdfb02b42fba268f7000f183639": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c063e7d90f6a4027b53d1b70c8c07742",
      "placeholder": "",
      "style": "IPY_MODEL_a410071b34034a91aeda7ef1114969c2",
      "value": " 160M/160M [01:05&lt;00:00, 2.55MB/s]"
     },
     "model_module_version": "1.5.0"
    },
    "a410071b34034a91aeda7ef1114969c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     },
     "model_module_version": "1.5.0"
    },
    "acbb3df601244291b8b2fb9ea1137573": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8c6a316609d4ca5bfee139b93177ef5",
       "IPY_MODEL_a1645bdfb02b42fba268f7000f183639"
      ],
      "layout": "IPY_MODEL_32b6ec3046e64d04b4134553dc434fe0"
     },
     "model_module_version": "1.5.0"
    },
    "c063e7d90f6a4027b53d1b70c8c07742": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     },
     "model_module_version": "1.2.0"
    },
    "d8c6a316609d4ca5bfee139b93177ef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d836b94d13e459d82429606496e4d4f",
      "max": 167502836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a4788a4fd6841788b20cfbf54a3d10b",
      "value": 167502836
     },
     "model_module_version": "1.5.0"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}