{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Code for using FiftyOne to train a Faster RCNN on COCO data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x25db96bc8d0>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import torchvision.models.detection.roi_heads\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "from dataset import FiftyOneTorchDataset, get_transforms\n",
    "from model import create_model\n",
    "from utils import add_detections\n",
    "\n",
    "from engine import train_model\n",
    "import config\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load full dataset from model zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5crNDNsRWdPT",
    "outputId": "4f3ff734-ca0a-4312-a811-7f84db514fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to 'C:\\Users\\blain\\fiftyone\\coco-2017\\validation' if necessary\n",
      "Found annotations at 'C:\\Users\\blain\\fiftyone\\coco-2017\\raw\\instances_val2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading 'coco-2017' split 'validation'\n",
      " 100% |███████████████| 5000/5000 [14.7s elapsed, 0s remaining, 359.9 samples/s]      \n",
      "Dataset 'coco-2017-validation' created\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x25df3e0d910>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"800\"\n            src=\"http://localhost:5151/?notebook=true&handleId=c4c4b35e-3a58-4b87-bf4d-b81ac5a02801\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lodad in the dataset from the FiftyOne model Zoo\n",
    "fo_dataset = foz.load_zoo_dataset(\"coco-2017\", \"validation\")\n",
    "\n",
    "#needed to calculate image height and width\n",
    "fo_dataset.compute_metadata()\n",
    "\n",
    "session = fo.launch_app(fo_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqU6Ckq4WKHK"
   },
   "source": [
    "For example, cluttered images make it difficult for models to localize objects. We can use FiftyOne to create a view containing only samples with more than, say, 10 objects. You can perform the same operations on views as datasets, so we can create an instance of our PyTorch dataset from this view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kLACOukJFUxd"
   },
   "outputs": [],
   "source": [
    "#if we want to see images with more than 10 items, we can\n",
    "# busy_view = fo_dataset.match(F(\"ground_truth.detections\").length() > 10)\n",
    "# busy_torch_dataset = FiftyOneTorchDataset(busy_view)\n",
    "# session.view = busy_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKsE_7TOWXBE"
   },
   "source": [
    "### Create training and testing views (and corresponding PyTorch datasets) that only contain some items from the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TELK0NWmWrMT",
    "outputId": "8bf582cf-e483-4643-8f6b-7c664a2d6c5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning on 4000 samples\n",
      "Testing on 1000 samples\n"
     ]
    }
   ],
   "source": [
    "subset = False\n",
    "\n",
    "train_transforms, test_transforms = get_transforms()\n",
    "\n",
    "if subset:\n",
    "    # to filter certain items from the dataset we can\n",
    "    item_list = [\"car\", \"dog\", \"bus\", 'fork', 'tie', 'person']\n",
    "    item_list = ['bus', 'dog']\n",
    "    item_view = fo_dataset.filter_labels(\"ground_truth\",\n",
    "            F(\"label\").is_in(item_list))\n",
    "\n",
    "    #session.view = item_view\n",
    "\n",
    "    # split the dataset in train and test set\n",
    "    train_view = item_view.take((len(item_view) * config.TRAIN_TEST_SPLIT), seed=51)\n",
    "    test_view = item_view.exclude([s.id for s in train_view])\n",
    "\n",
    "else:\n",
    "    train_view = fo_dataset.take(len(fo_dataset) * config.TRAIN_TEST_SPLIT)\n",
    "    test_view = fo_dataset.exclude([s.id for s in train_view])\n",
    "    item_list = fo_dataset.distinct(\"ground_truth.detections.label\")\n",
    "\n",
    "print(f'Traning on {len(train_view)} samples')\n",
    "print(f'Testing on {len(test_view)} samples')\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "train_dataset = FiftyOneTorchDataset(train_view, train_transforms,\n",
    "        classes=item_list)\n",
    "evaluation_dataset = FiftyOneTorchDataset(test_view, test_transforms,\n",
    "        classes=item_list)\n",
    "\n",
    "#this is needed for later use, but not for creating the dataset\n",
    "if item_list[0] != 'background':\n",
    "     item_list.insert(0,'background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# # map labels to single vehicle class\n",
    "# vehicle_list = ['car', 'bus', 'truck']\n",
    "# vehicles_map = {c: \"vehicle\" for c in vehicle_list}\n",
    "#\n",
    "# train_map_view = train_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "# test_map_view = test_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "#\n",
    "# # use our dataset and defined transformations\n",
    "# torch_map_dataset = FiftyOneTorchDataset(train_map_view, train_transforms)\n",
    "# torch_map_dataset_test = FiftyOneTorchDataset(test_map_view, test_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5je6lVBWz5r"
   },
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# #to change the loss function, create a new function and implement like below\n",
    "# import torchvision\n",
    "# torchvision.models.detection.roi_heads.fastrcnn_loss = cliprcnn_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blain\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: [0]  [  0/500]  eta: 0:10:26  lr: 0.000015  loss: 6.6419 (6.6419)  loss_classifier: 5.5420 (5.5420)  loss_box_reg: 0.1103 (0.1103)  loss_objectness: 0.7270 (0.7270)  loss_rpn_box_reg: 0.2627 (0.2627)  time: 1.2525  data: 0.2511  max mem: 8559\n",
      "Training Epoch: [0]  [ 10/500]  eta: 0:05:50  lr: 0.000115  loss: 6.7500 (6.7155)  loss_classifier: 5.6925 (5.7246)  loss_box_reg: 0.0784 (0.0866)  loss_objectness: 0.7258 (0.7247)  loss_rpn_box_reg: 0.1557 (0.1795)  time: 0.7155  data: 0.1595  max mem: 8897\n",
      "Training Epoch: [0]  [ 20/500]  eta: 0:05:30  lr: 0.000215  loss: 6.6348 (6.6396)  loss_classifier: 5.6925 (5.6808)  loss_box_reg: 0.0887 (0.0940)  loss_objectness: 0.7094 (0.7033)  loss_rpn_box_reg: 0.1451 (0.1616)  time: 0.6605  data: 0.1459  max mem: 8897\n",
      "Training Epoch: [0]  [ 30/500]  eta: 0:05:20  lr: 0.000315  loss: 6.5092 (6.5836)  loss_classifier: 5.6345 (5.6711)  loss_box_reg: 0.0983 (0.0972)  loss_objectness: 0.6154 (0.6597)  loss_rpn_box_reg: 0.1132 (0.1556)  time: 0.6623  data: 0.1395  max mem: 8898\n",
      "Training Epoch: [0]  [ 40/500]  eta: 0:05:09  lr: 0.000415  loss: 6.3266 (6.5191)  loss_classifier: 5.5561 (5.6477)  loss_box_reg: 0.1239 (0.1047)  loss_objectness: 0.5080 (0.6114)  loss_rpn_box_reg: 0.1353 (0.1552)  time: 0.6546  data: 0.1388  max mem: 8898\n",
      "Training Epoch: [0]  [ 50/500]  eta: 0:04:56  lr: 0.000516  loss: 6.2073 (6.4673)  loss_classifier: 5.5267 (5.6341)  loss_box_reg: 0.1324 (0.1114)  loss_objectness: 0.4096 (0.5650)  loss_rpn_box_reg: 0.1369 (0.1568)  time: 0.6237  data: 0.1394  max mem: 8898\n",
      "Training Epoch: [0]  [ 60/500]  eta: 0:04:44  lr: 0.000616  loss: 6.1857 (6.4139)  loss_classifier: 5.4517 (5.6104)  loss_box_reg: 0.1469 (0.1210)  loss_objectness: 0.3452 (0.5265)  loss_rpn_box_reg: 0.1362 (0.1560)  time: 0.5915  data: 0.1398  max mem: 8898\n",
      "Training Epoch: [0]  [ 70/500]  eta: 0:04:33  lr: 0.000716  loss: 6.0468 (6.3637)  loss_classifier: 5.3941 (5.5821)  loss_box_reg: 0.1707 (0.1300)  loss_objectness: 0.3152 (0.4956)  loss_rpn_box_reg: 0.1356 (0.1559)  time: 0.5778  data: 0.1399  max mem: 8898\n",
      "Training Epoch: [0]  [ 80/500]  eta: 0:04:24  lr: 0.000816  loss: 5.9983 (6.3385)  loss_classifier: 5.3984 (5.5779)  loss_box_reg: 0.1759 (0.1382)  loss_objectness: 0.2864 (0.4695)  loss_rpn_box_reg: 0.1302 (0.1529)  time: 0.5844  data: 0.1390  max mem: 8898\n",
      "Training Epoch: [0]  [ 90/500]  eta: 0:04:15  lr: 0.000916  loss: 6.0467 (6.3093)  loss_classifier: 5.3984 (5.5631)  loss_box_reg: 0.2072 (0.1477)  loss_objectness: 0.2696 (0.4481)  loss_rpn_box_reg: 0.1199 (0.1504)  time: 0.5735  data: 0.1382  max mem: 8898\n",
      "Training Epoch: [0]  [100/500]  eta: 0:04:06  lr: 0.001016  loss: 6.0133 (6.2761)  loss_classifier: 5.3722 (5.5429)  loss_box_reg: 0.2072 (0.1543)  loss_objectness: 0.2644 (0.4290)  loss_rpn_box_reg: 0.1306 (0.1499)  time: 0.5599  data: 0.1391  max mem: 8898\n",
      "Training Epoch: [0]  [110/500]  eta: 0:03:59  lr: 0.001116  loss: 6.0133 (6.2577)  loss_classifier: 5.4230 (5.5305)  loss_box_reg: 0.2123 (0.1607)  loss_objectness: 0.2620 (0.4156)  loss_rpn_box_reg: 0.1395 (0.1508)  time: 0.5717  data: 0.1395  max mem: 8898\n",
      "Training Epoch: [0]  [120/500]  eta: 0:03:51  lr: 0.001216  loss: 6.1239 (6.2552)  loss_classifier: 5.6086 (5.5401)  loss_box_reg: 0.2066 (0.1638)  loss_objectness: 0.2628 (0.4032)  loss_rpn_box_reg: 0.1300 (0.1481)  time: 0.5743  data: 0.1384  max mem: 8898\n",
      "Training Epoch: [0]  [130/500]  eta: 0:03:45  lr: 0.001316  loss: 6.1222 (6.2406)  loss_classifier: 5.6677 (5.5420)  loss_box_reg: 0.1863 (0.1628)  loss_objectness: 0.2545 (0.3909)  loss_rpn_box_reg: 0.1073 (0.1450)  time: 0.5977  data: 0.1392  max mem: 8898\n",
      "Training Epoch: [0]  [140/500]  eta: 0:03:41  lr: 0.001416  loss: 5.9246 (6.2236)  loss_classifier: 5.2764 (5.5313)  loss_box_reg: 0.1864 (0.1656)  loss_objectness: 0.2419 (0.3817)  loss_rpn_box_reg: 0.1297 (0.1449)  time: 0.6488  data: 0.1386  max mem: 8898\n",
      "Training Epoch: [0]  [150/500]  eta: 0:03:35  lr: 0.001517  loss: 6.0125 (6.2198)  loss_classifier: 5.3803 (5.5365)  loss_box_reg: 0.1907 (0.1678)  loss_objectness: 0.2377 (0.3720)  loss_rpn_box_reg: 0.1232 (0.1435)  time: 0.6390  data: 0.1374  max mem: 8898\n",
      "Training Epoch: [0]  [160/500]  eta: 0:03:29  lr: 0.001617  loss: 6.1313 (6.2111)  loss_classifier: 5.5367 (5.5342)  loss_box_reg: 0.1809 (0.1683)  loss_objectness: 0.2335 (0.3646)  loss_rpn_box_reg: 0.1141 (0.1440)  time: 0.6295  data: 0.1400  max mem: 8898\n",
      "Training Epoch: [0]  [170/500]  eta: 0:03:24  lr: 0.001717  loss: 6.1111 (6.2107)  loss_classifier: 5.3974 (5.5423)  loss_box_reg: 0.1796 (0.1686)  loss_objectness: 0.2335 (0.3566)  loss_rpn_box_reg: 0.1404 (0.1433)  time: 0.6579  data: 0.1392  max mem: 8898\n",
      "Training Epoch: [0]  [180/500]  eta: 0:03:18  lr: 0.001817  loss: 5.9969 (6.1992)  loss_classifier: 5.5012 (5.5402)  loss_box_reg: 0.1750 (0.1688)  loss_objectness: 0.2090 (0.3488)  loss_rpn_box_reg: 0.1119 (0.1413)  time: 0.6575  data: 0.1369  max mem: 8898\n",
      "Training Epoch: [0]  [190/500]  eta: 0:03:13  lr: 0.001917  loss: 5.9136 (6.1837)  loss_classifier: 5.3358 (5.5322)  loss_box_reg: 0.1738 (0.1691)  loss_objectness: 0.2090 (0.3429)  loss_rpn_box_reg: 0.1008 (0.1396)  time: 0.6543  data: 0.1410  max mem: 8898\n",
      "Training Epoch: [0]  [200/500]  eta: 0:03:07  lr: 0.002017  loss: 5.9472 (6.1862)  loss_classifier: 5.4277 (5.5398)  loss_box_reg: 0.1738 (0.1699)  loss_objectness: 0.2213 (0.3379)  loss_rpn_box_reg: 0.1105 (0.1386)  time: 0.6657  data: 0.1433  max mem: 8898\n",
      "Training Epoch: [0]  [210/500]  eta: 0:03:01  lr: 0.002117  loss: 6.0450 (6.1690)  loss_classifier: 5.4892 (5.5281)  loss_box_reg: 0.1875 (0.1708)  loss_objectness: 0.2288 (0.3324)  loss_rpn_box_reg: 0.1078 (0.1376)  time: 0.6581  data: 0.1417  max mem: 8898\n",
      "Training Epoch: [0]  [220/500]  eta: 0:02:55  lr: 0.002217  loss: 5.8998 (6.1592)  loss_classifier: 5.3397 (5.5235)  loss_box_reg: 0.1853 (0.1705)  loss_objectness: 0.2288 (0.3280)  loss_rpn_box_reg: 0.1078 (0.1373)  time: 0.6456  data: 0.1391  max mem: 8898\n",
      "Training Epoch: [0]  [230/500]  eta: 0:02:49  lr: 0.002317  loss: 5.9752 (6.1586)  loss_classifier: 5.3596 (5.5251)  loss_box_reg: 0.1666 (0.1710)  loss_objectness: 0.2332 (0.3242)  loss_rpn_box_reg: 0.1285 (0.1382)  time: 0.6620  data: 0.1378  max mem: 8898\n",
      "Training Epoch: [0]  [240/500]  eta: 0:02:44  lr: 0.002417  loss: 5.8807 (6.1496)  loss_classifier: 5.3596 (5.5194)  loss_box_reg: 0.1666 (0.1715)  loss_objectness: 0.2266 (0.3205)  loss_rpn_box_reg: 0.1295 (0.1382)  time: 0.6697  data: 0.1391  max mem: 8898\n",
      "Training Epoch: [0]  [250/500]  eta: 0:02:37  lr: 0.002518  loss: 5.8418 (6.1412)  loss_classifier: 5.3960 (5.5142)  loss_box_reg: 0.1733 (0.1721)  loss_objectness: 0.2153 (0.3165)  loss_rpn_box_reg: 0.1309 (0.1384)  time: 0.6535  data: 0.1381  max mem: 8898\n",
      "Training Epoch: [0]  [260/500]  eta: 0:02:31  lr: 0.002618  loss: 5.9616 (6.1405)  loss_classifier: 5.4448 (5.5181)  loss_box_reg: 0.1709 (0.1722)  loss_objectness: 0.2060 (0.3122)  loss_rpn_box_reg: 0.1282 (0.1380)  time: 0.6373  data: 0.1361  max mem: 8898\n",
      "Training Epoch: [0]  [270/500]  eta: 0:02:25  lr: 0.002718  loss: 5.9661 (6.1315)  loss_classifier: 5.4448 (5.5158)  loss_box_reg: 0.1398 (0.1706)  loss_objectness: 0.2017 (0.3075)  loss_rpn_box_reg: 0.1148 (0.1375)  time: 0.6568  data: 0.1353  max mem: 8916\n",
      "Training Epoch: [0]  [280/500]  eta: 0:02:19  lr: 0.002818  loss: 5.8430 (6.1268)  loss_classifier: 5.2878 (5.5126)  loss_box_reg: 0.1511 (0.1709)  loss_objectness: 0.2043 (0.3047)  loss_rpn_box_reg: 0.1470 (0.1387)  time: 0.6866  data: 0.1375  max mem: 8916\n",
      "Training Epoch: [0]  [290/500]  eta: 0:02:13  lr: 0.002918  loss: 6.0457 (6.1231)  loss_classifier: 5.4188 (5.5114)  loss_box_reg: 0.1883 (0.1717)  loss_objectness: 0.2046 (0.3013)  loss_rpn_box_reg: 0.1459 (0.1387)  time: 0.6576  data: 0.1389  max mem: 8916\n",
      "Training Epoch: [0]  [300/500]  eta: 0:02:07  lr: 0.003018  loss: 6.0514 (6.1205)  loss_classifier: 5.4632 (5.5103)  loss_box_reg: 0.1869 (0.1726)  loss_objectness: 0.2182 (0.2987)  loss_rpn_box_reg: 0.1103 (0.1389)  time: 0.6412  data: 0.1402  max mem: 8916\n",
      "Training Epoch: [0]  [310/500]  eta: 0:02:00  lr: 0.003118  loss: 6.1489 (6.1225)  loss_classifier: 5.5102 (5.5136)  loss_box_reg: 0.1879 (0.1737)  loss_objectness: 0.2243 (0.2965)  loss_rpn_box_reg: 0.1103 (0.1386)  time: 0.6348  data: 0.1403  max mem: 8916\n",
      "Training Epoch: [0]  [320/500]  eta: 0:01:54  lr: 0.003218  loss: 6.0335 (6.1105)  loss_classifier: 5.6239 (5.5046)  loss_box_reg: 0.2035 (0.1743)  loss_objectness: 0.2003 (0.2931)  loss_rpn_box_reg: 0.1167 (0.1385)  time: 0.6245  data: 0.1366  max mem: 8916\n",
      "Training Epoch: [0]  [330/500]  eta: 0:01:47  lr: 0.003318  loss: 5.9883 (6.1094)  loss_classifier: 5.4106 (5.5073)  loss_box_reg: 0.1652 (0.1740)  loss_objectness: 0.1898 (0.2902)  loss_rpn_box_reg: 0.1028 (0.1378)  time: 0.6376  data: 0.1362  max mem: 8916\n",
      "Training Epoch: [0]  [340/500]  eta: 0:01:41  lr: 0.003418  loss: 5.9763 (6.1038)  loss_classifier: 5.4414 (5.5062)  loss_box_reg: 0.1543 (0.1735)  loss_objectness: 0.1898 (0.2871)  loss_rpn_box_reg: 0.0998 (0.1371)  time: 0.6370  data: 0.1358  max mem: 8916\n",
      "Training Epoch: [0]  [350/500]  eta: 0:01:35  lr: 0.003519  loss: 5.9893 (6.1111)  loss_classifier: 5.4581 (5.5155)  loss_box_reg: 0.1543 (0.1731)  loss_objectness: 0.1876 (0.2846)  loss_rpn_box_reg: 0.1311 (0.1380)  time: 0.6440  data: 0.1334  max mem: 8916\n",
      "Training Epoch: [0]  [360/500]  eta: 0:01:29  lr: 0.003619  loss: 6.2598 (6.1140)  loss_classifier: 5.7492 (5.5206)  loss_box_reg: 0.1755 (0.1736)  loss_objectness: 0.1885 (0.2821)  loss_rpn_box_reg: 0.1311 (0.1378)  time: 0.6472  data: 0.1347  max mem: 8916\n",
      "Training Epoch: [0]  [370/500]  eta: 0:01:22  lr: 0.003719  loss: 6.0494 (6.1142)  loss_classifier: 5.4705 (5.5222)  loss_box_reg: 0.1878 (0.1740)  loss_objectness: 0.1925 (0.2799)  loss_rpn_box_reg: 0.1297 (0.1381)  time: 0.6475  data: 0.1371  max mem: 8916\n",
      "Training Epoch: [0]  [380/500]  eta: 0:01:16  lr: 0.003819  loss: 6.0494 (6.1110)  loss_classifier: 5.4645 (5.5193)  loss_box_reg: 0.1895 (0.1749)  loss_objectness: 0.2159 (0.2789)  loss_rpn_box_reg: 0.1297 (0.1379)  time: 0.6440  data: 0.1388  max mem: 8916\n",
      "Training Epoch: [0]  [390/500]  eta: 0:01:09  lr: 0.003919  loss: 6.2812 (6.1125)  loss_classifier: 5.5043 (5.5209)  loss_box_reg: 0.2216 (0.1764)  loss_objectness: 0.2151 (0.2770)  loss_rpn_box_reg: 0.1237 (0.1382)  time: 0.6361  data: 0.1392  max mem: 8916\n",
      "Training Epoch: [0]  [400/500]  eta: 0:01:03  lr: 0.004019  loss: 6.0397 (6.1066)  loss_classifier: 5.4863 (5.5180)  loss_box_reg: 0.2038 (0.1768)  loss_objectness: 0.1949 (0.2747)  loss_rpn_box_reg: 0.1028 (0.1371)  time: 0.6410  data: 0.1372  max mem: 8916\n",
      "Training Epoch: [0]  [410/500]  eta: 0:00:57  lr: 0.004119  loss: 6.0457 (6.1121)  loss_classifier: 5.5471 (5.5250)  loss_box_reg: 0.1868 (0.1775)  loss_objectness: 0.2027 (0.2729)  loss_rpn_box_reg: 0.1004 (0.1367)  time: 0.6430  data: 0.1354  max mem: 8916\n",
      "Training Epoch: [0]  [420/500]  eta: 0:00:50  lr: 0.004219  loss: 6.2380 (6.1174)  loss_classifier: 5.6571 (5.5314)  loss_box_reg: 0.2049 (0.1785)  loss_objectness: 0.2027 (0.2714)  loss_rpn_box_reg: 0.1036 (0.1361)  time: 0.6429  data: 0.1358  max mem: 8916\n",
      "Training Epoch: [0]  [430/500]  eta: 0:00:44  lr: 0.004319  loss: 6.1339 (6.1140)  loss_classifier: 5.5425 (5.5284)  loss_box_reg: 0.2330 (0.1802)  loss_objectness: 0.1993 (0.2695)  loss_rpn_box_reg: 0.1092 (0.1359)  time: 0.6409  data: 0.1373  max mem: 8916\n",
      "Training Epoch: [0]  [440/500]  eta: 0:00:38  lr: 0.004419  loss: 6.0663 (6.1134)  loss_classifier: 5.5425 (5.5288)  loss_box_reg: 0.2286 (0.1808)  loss_objectness: 0.1984 (0.2682)  loss_rpn_box_reg: 0.1128 (0.1356)  time: 0.6335  data: 0.1378  max mem: 8916\n",
      "Training Epoch: [0]  [450/500]  eta: 0:00:31  lr: 0.004520  loss: 5.9857 (6.1088)  loss_classifier: 5.5027 (5.5247)  loss_box_reg: 0.2252 (0.1821)  loss_objectness: 0.2036 (0.2669)  loss_rpn_box_reg: 0.1105 (0.1351)  time: 0.6157  data: 0.1371  max mem: 8916\n",
      "Training Epoch: [0]  [460/500]  eta: 0:00:25  lr: 0.004620  loss: 5.8971 (6.1045)  loss_classifier: 5.3664 (5.5229)  loss_box_reg: 0.1962 (0.1820)  loss_objectness: 0.1894 (0.2652)  loss_rpn_box_reg: 0.1072 (0.1344)  time: 0.6136  data: 0.1350  max mem: 8916\n",
      "Training Epoch: [0]  [470/500]  eta: 0:00:19  lr: 0.004720  loss: 5.8971 (6.1012)  loss_classifier: 5.5736 (5.5215)  loss_box_reg: 0.1674 (0.1820)  loss_objectness: 0.1882 (0.2637)  loss_rpn_box_reg: 0.0934 (0.1339)  time: 0.6257  data: 0.1350  max mem: 8916\n",
      "Training Epoch: [0]  [480/500]  eta: 0:00:12  lr: 0.004820  loss: 6.2455 (6.1064)  loss_classifier: 5.6430 (5.5281)  loss_box_reg: 0.1766 (0.1821)  loss_objectness: 0.1869 (0.2626)  loss_rpn_box_reg: 0.1073 (0.1336)  time: 0.6276  data: 0.1371  max mem: 8916\n",
      "Training Epoch: [0]  [490/500]  eta: 0:00:06  lr: 0.004920  loss: 5.9245 (6.1033)  loss_classifier: 5.4977 (5.5267)  loss_box_reg: 0.1851 (0.1825)  loss_objectness: 0.1860 (0.2608)  loss_rpn_box_reg: 0.1073 (0.1333)  time: 0.6439  data: 0.1369  max mem: 8916\n",
      "Training Epoch: [0]  [499/500]  eta: 0:00:00  lr: 0.005000  loss: 6.0113 (6.1031)  loss_classifier: 5.4977 (5.5285)  loss_box_reg: 0.1851 (0.1824)  loss_objectness: 0.1813 (0.2595)  loss_rpn_box_reg: 0.1058 (0.1327)  time: 0.6395  data: 0.1361  max mem: 8916\n",
      "Training Epoch: [0] Total time: 0:05:17 (0.6357 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:37  model_time: 0.5991 (0.5991)  evaluator_time: 0.0320 (0.0320)  time: 0.7832  data: 0.1420  max mem: 8916\n",
      "Test:  [100/125]  eta: 0:00:14  model_time: 0.3891 (0.3953)  evaluator_time: 0.0310 (0.0319)  time: 0.5740  data: 0.1502  max mem: 8916\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.3981 (0.3958)  evaluator_time: 0.0330 (0.0324)  time: 0.5881  data: 0.1510  max mem: 8916\n",
      "Test: Total time: 0:01:13 (0.5844 s / it)\n",
      "Averaged stats: model_time: 0.3981 (0.3958)  evaluator_time: 0.0330 (0.0324)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.29s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.071\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.129\n",
      "Testing Epoch: [0]  [  0/125]  eta: 0:01:22  lr: 0.005000  loss: 6.0960 (6.0960)  loss_classifier: 5.5084 (5.5084)  loss_box_reg: 0.2137 (0.2137)  loss_objectness: 0.1658 (0.1658)  loss_rpn_box_reg: 0.2081 (0.2081)  time: 0.6611  data: 0.1410  max mem: 8916\n",
      "Testing Epoch: [0]  [100/125]  eta: 0:00:15  lr: 0.005000  loss: 5.8183 (6.0145)  loss_classifier: 5.2493 (5.4933)  loss_box_reg: 0.2073 (0.2280)  loss_objectness: 0.1730 (0.1753)  loss_rpn_box_reg: 0.0989 (0.1178)  time: 0.6034  data: 0.1549  max mem: 9296\n",
      "Testing Epoch: [0]  [124/125]  eta: 0:00:00  lr: 0.005000  loss: 5.9626 (6.0437)  loss_classifier: 5.5031 (5.5252)  loss_box_reg: 0.1925 (0.2256)  loss_objectness: 0.1649 (0.1756)  loss_rpn_box_reg: 0.0837 (0.1173)  time: 0.5975  data: 0.1470  max mem: 9296\n",
      "Testing Epoch: [0] Total time: 0:01:16 (0.6086 s / it)\n",
      "Training Epoch: [1]  [  0/500]  eta: 0:06:29  lr: 0.005000  loss: 5.7350 (5.7350)  loss_classifier: 5.1440 (5.1440)  loss_box_reg: 0.2564 (0.2564)  loss_objectness: 0.2209 (0.2209)  loss_rpn_box_reg: 0.1138 (0.1138)  time: 0.7782  data: 0.1550  max mem: 9296\n",
      "Training Epoch: [1]  [ 10/500]  eta: 0:05:17  lr: 0.005000  loss: 5.9316 (6.0379)  loss_classifier: 5.3347 (5.4687)  loss_box_reg: 0.2564 (0.2548)  loss_objectness: 0.1855 (0.1994)  loss_rpn_box_reg: 0.1180 (0.1151)  time: 0.6485  data: 0.1470  max mem: 9296\n",
      "Training Epoch: [1]  [ 20/500]  eta: 0:05:02  lr: 0.005000  loss: 5.9316 (6.0716)  loss_classifier: 5.4410 (5.5272)  loss_box_reg: 0.2104 (0.2301)  loss_objectness: 0.1855 (0.2047)  loss_rpn_box_reg: 0.1055 (0.1096)  time: 0.6238  data: 0.1429  max mem: 9296\n",
      "Training Epoch: [1]  [ 30/500]  eta: 0:04:54  lr: 0.005000  loss: 6.1378 (6.1653)  loss_classifier: 5.6603 (5.6417)  loss_box_reg: 0.1847 (0.2135)  loss_objectness: 0.1843 (0.1976)  loss_rpn_box_reg: 0.0901 (0.1125)  time: 0.6156  data: 0.1384  max mem: 9296\n",
      "Training Epoch: [1]  [ 40/500]  eta: 0:04:51  lr: 0.005000  loss: 6.0957 (6.0969)  loss_classifier: 5.6552 (5.5847)  loss_box_reg: 0.1850 (0.2076)  loss_objectness: 0.1810 (0.1944)  loss_rpn_box_reg: 0.0919 (0.1102)  time: 0.6351  data: 0.1426  max mem: 9296\n",
      "Training Epoch: [1]  [ 50/500]  eta: 0:04:47  lr: 0.005000  loss: 5.6754 (6.0931)  loss_classifier: 5.1477 (5.5799)  loss_box_reg: 0.1951 (0.2073)  loss_objectness: 0.1842 (0.1948)  loss_rpn_box_reg: 0.1038 (0.1112)  time: 0.6545  data: 0.1434  max mem: 9296\n",
      "Training Epoch: [1]  [ 60/500]  eta: 0:04:39  lr: 0.005000  loss: 6.1369 (6.1009)  loss_classifier: 5.5710 (5.5833)  loss_box_reg: 0.2079 (0.2067)  loss_objectness: 0.1963 (0.1969)  loss_rpn_box_reg: 0.1241 (0.1139)  time: 0.6377  data: 0.1399  max mem: 9296\n",
      "Training Epoch: [1]  [ 70/500]  eta: 0:04:33  lr: 0.005000  loss: 6.1369 (6.1382)  loss_classifier: 5.5780 (5.6281)  loss_box_reg: 0.1861 (0.2048)  loss_objectness: 0.1940 (0.1929)  loss_rpn_box_reg: 0.1144 (0.1124)  time: 0.6340  data: 0.1385  max mem: 9296\n",
      "Training Epoch: [1]  [ 80/500]  eta: 0:04:25  lr: 0.005000  loss: 6.0842 (6.1410)  loss_classifier: 5.5823 (5.6282)  loss_box_reg: 0.1987 (0.2083)  loss_objectness: 0.1630 (0.1923)  loss_rpn_box_reg: 0.1021 (0.1123)  time: 0.6286  data: 0.1350  max mem: 9296\n",
      "Training Epoch: [1]  [ 90/500]  eta: 0:04:17  lr: 0.005000  loss: 5.8870 (6.1301)  loss_classifier: 5.3859 (5.6149)  loss_box_reg: 0.2168 (0.2086)  loss_objectness: 0.1891 (0.1942)  loss_rpn_box_reg: 0.0876 (0.1124)  time: 0.6006  data: 0.1365  max mem: 9296\n",
      "Training Epoch: [1]  [100/500]  eta: 0:04:11  lr: 0.005000  loss: 6.0041 (6.1309)  loss_classifier: 5.3859 (5.6122)  loss_box_reg: 0.1959 (0.2090)  loss_objectness: 0.2022 (0.1966)  loss_rpn_box_reg: 0.0916 (0.1130)  time: 0.6109  data: 0.1406  max mem: 9296\n",
      "Training Epoch: [1]  [110/500]  eta: 0:04:05  lr: 0.005000  loss: 6.2267 (6.1371)  loss_classifier: 5.5980 (5.6234)  loss_box_reg: 0.1959 (0.2078)  loss_objectness: 0.1889 (0.1950)  loss_rpn_box_reg: 0.0916 (0.1109)  time: 0.6346  data: 0.1388  max mem: 9296\n",
      "Training Epoch: [1]  [120/500]  eta: 0:03:59  lr: 0.005000  loss: 6.1870 (6.1323)  loss_classifier: 5.6180 (5.6143)  loss_box_reg: 0.2010 (0.2117)  loss_objectness: 0.1824 (0.1961)  loss_rpn_box_reg: 0.0902 (0.1103)  time: 0.6321  data: 0.1381  max mem: 9296\n",
      "Training Epoch: [1]  [130/500]  eta: 0:03:52  lr: 0.005000  loss: 6.0833 (6.1303)  loss_classifier: 5.5765 (5.6161)  loss_box_reg: 0.2006 (0.2096)  loss_objectness: 0.1794 (0.1936)  loss_rpn_box_reg: 0.1080 (0.1110)  time: 0.6230  data: 0.1389  max mem: 9296\n",
      "Training Epoch: [1]  [140/500]  eta: 0:03:46  lr: 0.005000  loss: 5.9914 (6.1349)  loss_classifier: 5.5367 (5.6219)  loss_box_reg: 0.1824 (0.2099)  loss_objectness: 0.1742 (0.1935)  loss_rpn_box_reg: 0.0967 (0.1097)  time: 0.6242  data: 0.1398  max mem: 9296\n",
      "Training Epoch: [1]  [150/500]  eta: 0:03:41  lr: 0.005000  loss: 5.9990 (6.1295)  loss_classifier: 5.5934 (5.6166)  loss_box_reg: 0.2073 (0.2105)  loss_objectness: 0.1869 (0.1930)  loss_rpn_box_reg: 0.0967 (0.1093)  time: 0.6494  data: 0.1435  max mem: 9296\n",
      "Training Epoch: [1]  [160/500]  eta: 0:03:34  lr: 0.005000  loss: 6.0588 (6.1226)  loss_classifier: 5.6067 (5.6159)  loss_box_reg: 0.1798 (0.2078)  loss_objectness: 0.1727 (0.1905)  loss_rpn_box_reg: 0.0887 (0.1084)  time: 0.6573  data: 0.1392  max mem: 9296\n",
      "Training Epoch: [1]  [170/500]  eta: 0:03:28  lr: 0.005000  loss: 6.0731 (6.1333)  loss_classifier: 5.6287 (5.6273)  loss_box_reg: 0.1698 (0.2070)  loss_objectness: 0.1657 (0.1901)  loss_rpn_box_reg: 0.1042 (0.1089)  time: 0.6422  data: 0.1362  max mem: 9296\n",
      "Training Epoch: [1]  [180/500]  eta: 0:03:23  lr: 0.005000  loss: 6.1635 (6.1364)  loss_classifier: 5.6687 (5.6307)  loss_box_reg: 0.2078 (0.2077)  loss_objectness: 0.1847 (0.1895)  loss_rpn_box_reg: 0.1067 (0.1085)  time: 0.6543  data: 0.1403  max mem: 9296\n",
      "Training Epoch: [1]  [190/500]  eta: 0:03:17  lr: 0.005000  loss: 5.9161 (6.1221)  loss_classifier: 5.3931 (5.6162)  loss_box_reg: 0.2225 (0.2078)  loss_objectness: 0.1847 (0.1895)  loss_rpn_box_reg: 0.0943 (0.1085)  time: 0.6650  data: 0.1410  max mem: 9296\n",
      "Training Epoch: [1]  [200/500]  eta: 0:03:10  lr: 0.005000  loss: 5.9424 (6.1301)  loss_classifier: 5.4444 (5.6243)  loss_box_reg: 0.2025 (0.2082)  loss_objectness: 0.1853 (0.1898)  loss_rpn_box_reg: 0.0942 (0.1077)  time: 0.6451  data: 0.1403  max mem: 9296\n",
      "Training Epoch: [1]  [210/500]  eta: 0:03:04  lr: 0.005000  loss: 6.1545 (6.1302)  loss_classifier: 5.6163 (5.6254)  loss_box_reg: 0.2025 (0.2084)  loss_objectness: 0.1911 (0.1896)  loss_rpn_box_reg: 0.1008 (0.1069)  time: 0.6354  data: 0.1407  max mem: 9296\n",
      "Training Epoch: [1]  [220/500]  eta: 0:02:57  lr: 0.005000  loss: 6.1820 (6.1373)  loss_classifier: 5.6698 (5.6322)  loss_box_reg: 0.2316 (0.2094)  loss_objectness: 0.1771 (0.1892)  loss_rpn_box_reg: 0.1014 (0.1065)  time: 0.6283  data: 0.1399  max mem: 9296\n",
      "Training Epoch: [1]  [230/500]  eta: 0:02:51  lr: 0.005000  loss: 6.0215 (6.1327)  loss_classifier: 5.6031 (5.6303)  loss_box_reg: 0.2266 (0.2085)  loss_objectness: 0.1670 (0.1883)  loss_rpn_box_reg: 0.0740 (0.1056)  time: 0.6288  data: 0.1381  max mem: 9296\n",
      "Training Epoch: [1]  [240/500]  eta: 0:02:45  lr: 0.005000  loss: 6.0177 (6.1385)  loss_classifier: 5.6031 (5.6369)  loss_box_reg: 0.1856 (0.2079)  loss_objectness: 0.1703 (0.1883)  loss_rpn_box_reg: 0.0781 (0.1054)  time: 0.6367  data: 0.1370  max mem: 9296\n",
      "Training Epoch: [1]  [250/500]  eta: 0:02:38  lr: 0.005000  loss: 6.3139 (6.1469)  loss_classifier: 5.8833 (5.6449)  loss_box_reg: 0.2007 (0.2083)  loss_objectness: 0.1799 (0.1881)  loss_rpn_box_reg: 0.1023 (0.1055)  time: 0.6195  data: 0.1368  max mem: 9296\n",
      "Training Epoch: [1]  [260/500]  eta: 0:02:31  lr: 0.005000  loss: 6.2677 (6.1488)  loss_classifier: 5.6637 (5.6457)  loss_box_reg: 0.2008 (0.2092)  loss_objectness: 0.1843 (0.1887)  loss_rpn_box_reg: 0.1023 (0.1052)  time: 0.6117  data: 0.1369  max mem: 9296\n",
      "Training Epoch: [1]  [270/500]  eta: 0:02:25  lr: 0.005000  loss: 5.9907 (6.1473)  loss_classifier: 5.4681 (5.6444)  loss_box_reg: 0.2008 (0.2089)  loss_objectness: 0.1864 (0.1886)  loss_rpn_box_reg: 0.0903 (0.1055)  time: 0.6298  data: 0.1389  max mem: 9296\n",
      "Training Epoch: [1]  [280/500]  eta: 0:02:19  lr: 0.005000  loss: 6.0362 (6.1547)  loss_classifier: 5.4681 (5.6529)  loss_box_reg: 0.1969 (0.2087)  loss_objectness: 0.1757 (0.1882)  loss_rpn_box_reg: 0.0931 (0.1050)  time: 0.6276  data: 0.1397  max mem: 9296\n",
      "Training Epoch: [1]  [290/500]  eta: 0:02:13  lr: 0.005000  loss: 6.5127 (6.1713)  loss_classifier: 6.0010 (5.6709)  loss_box_reg: 0.1832 (0.2071)  loss_objectness: 0.1670 (0.1881)  loss_rpn_box_reg: 0.0994 (0.1053)  time: 0.6372  data: 0.1410  max mem: 9296\n",
      "Training Epoch: [1]  [300/500]  eta: 0:02:06  lr: 0.005000  loss: 6.3169 (6.1651)  loss_classifier: 5.9344 (5.6648)  loss_box_reg: 0.1782 (0.2074)  loss_objectness: 0.1790 (0.1881)  loss_rpn_box_reg: 0.0822 (0.1048)  time: 0.6454  data: 0.1413  max mem: 9296\n",
      "Training Epoch: [1]  [310/500]  eta: 0:02:00  lr: 0.005000  loss: 5.9444 (6.1575)  loss_classifier: 5.3796 (5.6580)  loss_box_reg: 0.1975 (0.2078)  loss_objectness: 0.1708 (0.1874)  loss_rpn_box_reg: 0.0715 (0.1043)  time: 0.6244  data: 0.1379  max mem: 9296\n",
      "Training Epoch: [1]  [320/500]  eta: 0:01:53  lr: 0.005000  loss: 5.9769 (6.1572)  loss_classifier: 5.4409 (5.6573)  loss_box_reg: 0.2107 (0.2081)  loss_objectness: 0.1708 (0.1874)  loss_rpn_box_reg: 0.1023 (0.1044)  time: 0.6159  data: 0.1369  max mem: 9296\n",
      "Training Epoch: [1]  [330/500]  eta: 0:01:47  lr: 0.005000  loss: 5.9769 (6.1570)  loss_classifier: 5.4409 (5.6581)  loss_box_reg: 0.2099 (0.2083)  loss_objectness: 0.1671 (0.1867)  loss_rpn_box_reg: 0.0870 (0.1038)  time: 0.6221  data: 0.1391  max mem: 9296\n",
      "Training Epoch: [1]  [340/500]  eta: 0:01:41  lr: 0.005000  loss: 6.1861 (6.1568)  loss_classifier: 5.6992 (5.6570)  loss_box_reg: 0.2096 (0.2086)  loss_objectness: 0.1587 (0.1872)  loss_rpn_box_reg: 0.0907 (0.1040)  time: 0.6239  data: 0.1399  max mem: 9296\n",
      "Training Epoch: [1]  [350/500]  eta: 0:01:34  lr: 0.005000  loss: 6.1026 (6.1501)  loss_classifier: 5.4900 (5.6496)  loss_box_reg: 0.2242 (0.2091)  loss_objectness: 0.1705 (0.1872)  loss_rpn_box_reg: 0.1120 (0.1042)  time: 0.6108  data: 0.1377  max mem: 9296\n",
      "Training Epoch: [1]  [360/500]  eta: 0:01:28  lr: 0.005000  loss: 6.1026 (6.1498)  loss_classifier: 5.6030 (5.6514)  loss_box_reg: 0.1961 (0.2082)  loss_objectness: 0.1685 (0.1867)  loss_rpn_box_reg: 0.0800 (0.1034)  time: 0.6265  data: 0.1377  max mem: 9296\n",
      "Training Epoch: [1]  [370/500]  eta: 0:01:22  lr: 0.005000  loss: 6.2388 (6.1546)  loss_classifier: 5.7781 (5.6568)  loss_box_reg: 0.2067 (0.2086)  loss_objectness: 0.1719 (0.1864)  loss_rpn_box_reg: 0.0696 (0.1029)  time: 0.6437  data: 0.1401  max mem: 9296\n",
      "Training Epoch: [1]  [380/500]  eta: 0:01:15  lr: 0.005000  loss: 6.1114 (6.1503)  loss_classifier: 5.6568 (5.6531)  loss_box_reg: 0.2106 (0.2084)  loss_objectness: 0.1772 (0.1864)  loss_rpn_box_reg: 0.0792 (0.1023)  time: 0.6461  data: 0.1401  max mem: 9296\n",
      "Training Epoch: [1]  [390/500]  eta: 0:01:09  lr: 0.005000  loss: 6.1029 (6.1564)  loss_classifier: 5.6446 (5.6604)  loss_box_reg: 0.1824 (0.2079)  loss_objectness: 0.1789 (0.1862)  loss_rpn_box_reg: 0.0792 (0.1019)  time: 0.6351  data: 0.1378  max mem: 9296\n",
      "Training Epoch: [1]  [400/500]  eta: 0:01:03  lr: 0.005000  loss: 6.0236 (6.1533)  loss_classifier: 5.5715 (5.6578)  loss_box_reg: 0.1824 (0.2076)  loss_objectness: 0.1673 (0.1859)  loss_rpn_box_reg: 0.0925 (0.1019)  time: 0.6163  data: 0.1384  max mem: 9296\n",
      "Training Epoch: [1]  [410/500]  eta: 0:00:56  lr: 0.005000  loss: 5.9052 (6.1538)  loss_classifier: 5.5503 (5.6597)  loss_box_reg: 0.1897 (0.2069)  loss_objectness: 0.1679 (0.1859)  loss_rpn_box_reg: 0.0925 (0.1014)  time: 0.6239  data: 0.1419  max mem: 9296\n",
      "Training Epoch: [1]  [420/500]  eta: 0:00:50  lr: 0.005000  loss: 6.0883 (6.1528)  loss_classifier: 5.6340 (5.6586)  loss_box_reg: 0.2079 (0.2076)  loss_objectness: 0.1679 (0.1856)  loss_rpn_box_reg: 0.0739 (0.1010)  time: 0.6450  data: 0.1418  max mem: 9296\n",
      "Training Epoch: [1]  [430/500]  eta: 0:00:44  lr: 0.005000  loss: 6.1864 (6.1578)  loss_classifier: 5.7202 (5.6635)  loss_box_reg: 0.2131 (0.2080)  loss_objectness: 0.1725 (0.1856)  loss_rpn_box_reg: 0.0726 (0.1007)  time: 0.6328  data: 0.1405  max mem: 9296\n",
      "Training Epoch: [1]  [440/500]  eta: 0:00:37  lr: 0.005000  loss: 6.1864 (6.1592)  loss_classifier: 5.6901 (5.6636)  loss_box_reg: 0.2235 (0.2094)  loss_objectness: 0.1732 (0.1854)  loss_rpn_box_reg: 0.0809 (0.1009)  time: 0.6205  data: 0.1417  max mem: 9296\n",
      "Training Epoch: [1]  [450/500]  eta: 0:00:31  lr: 0.005000  loss: 6.0371 (6.1616)  loss_classifier: 5.5116 (5.6663)  loss_box_reg: 0.2255 (0.2095)  loss_objectness: 0.1681 (0.1850)  loss_rpn_box_reg: 0.0969 (0.1008)  time: 0.6305  data: 0.1399  max mem: 9296\n",
      "Training Epoch: [1]  [460/500]  eta: 0:00:25  lr: 0.005000  loss: 6.0121 (6.1594)  loss_classifier: 5.4852 (5.6645)  loss_box_reg: 0.1983 (0.2092)  loss_objectness: 0.1684 (0.1847)  loss_rpn_box_reg: 0.0996 (0.1011)  time: 0.6300  data: 0.1381  max mem: 9296\n",
      "Training Epoch: [1]  [470/500]  eta: 0:00:18  lr: 0.005000  loss: 5.8973 (6.1593)  loss_classifier: 5.5281 (5.6657)  loss_box_reg: 0.1928 (0.2088)  loss_objectness: 0.1461 (0.1838)  loss_rpn_box_reg: 0.0930 (0.1010)  time: 0.6303  data: 0.1378  max mem: 9296\n",
      "Training Epoch: [1]  [480/500]  eta: 0:00:12  lr: 0.005000  loss: 6.0258 (6.1582)  loss_classifier: 5.5535 (5.6650)  loss_box_reg: 0.1939 (0.2088)  loss_objectness: 0.1511 (0.1834)  loss_rpn_box_reg: 0.0939 (0.1010)  time: 0.6206  data: 0.1369  max mem: 9296\n",
      "Training Epoch: [1]  [490/500]  eta: 0:00:06  lr: 0.005000  loss: 6.0258 (6.1562)  loss_classifier: 5.5168 (5.6642)  loss_box_reg: 0.1936 (0.2085)  loss_objectness: 0.1605 (0.1828)  loss_rpn_box_reg: 0.0889 (0.1007)  time: 0.6290  data: 0.1372  max mem: 9296\n",
      "Training Epoch: [1]  [499/500]  eta: 0:00:00  lr: 0.005000  loss: 5.9271 (6.1565)  loss_classifier: 5.4775 (5.6652)  loss_box_reg: 0.1884 (0.2084)  loss_objectness: 0.1564 (0.1824)  loss_rpn_box_reg: 0.0855 (0.1005)  time: 0.6524  data: 0.1376  max mem: 9296\n",
      "Training Epoch: [1] Total time: 0:05:16 (0.6322 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:56  model_time: 0.6531 (0.6531)  evaluator_time: 0.0330 (0.0330)  time: 0.9312  data: 0.2341  max mem: 9296\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4061 (0.4138)  evaluator_time: 0.0330 (0.0343)  time: 0.6079  data: 0.1571  max mem: 9318\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4191 (0.4145)  evaluator_time: 0.0340 (0.0356)  time: 0.6087  data: 0.1439  max mem: 9318\n",
      "Test: Total time: 0:01:15 (0.6048 s / it)\n",
      "Averaged stats: model_time: 0.4191 (0.4145)  evaluator_time: 0.0340 (0.0356)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.28s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.047\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.080\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.152\n",
      "Testing Epoch: [1]  [  0/125]  eta: 0:01:21  lr: 0.005000  loss: 6.1694 (6.1694)  loss_classifier: 5.6365 (5.6365)  loss_box_reg: 0.2300 (0.2300)  loss_objectness: 0.1515 (0.1515)  loss_rpn_box_reg: 0.1514 (0.1514)  time: 0.6541  data: 0.1450  max mem: 9318\n",
      "Testing Epoch: [1]  [100/125]  eta: 0:00:14  lr: 0.005000  loss: 5.8960 (6.0836)  loss_classifier: 5.4039 (5.5878)  loss_box_reg: 0.2248 (0.2440)  loss_objectness: 0.1483 (0.1527)  loss_rpn_box_reg: 0.0842 (0.0991)  time: 0.5862  data: 0.1482  max mem: 9318\n",
      "Testing Epoch: [1]  [124/125]  eta: 0:00:00  lr: 0.005000  loss: 6.0863 (6.1147)  loss_classifier: 5.6199 (5.6226)  loss_box_reg: 0.2002 (0.2399)  loss_objectness: 0.1426 (0.1528)  loss_rpn_box_reg: 0.0844 (0.0994)  time: 0.6036  data: 0.1486  max mem: 9356\n",
      "Testing Epoch: [1] Total time: 0:01:15 (0.6001 s / it)\n",
      "Training Epoch: [2]  [  0/500]  eta: 0:05:21  lr: 0.005000  loss: 7.1242 (7.1242)  loss_classifier: 6.6485 (6.6485)  loss_box_reg: 0.1832 (0.1832)  loss_objectness: 0.1814 (0.1814)  loss_rpn_box_reg: 0.1111 (0.1111)  time: 0.6431  data: 0.1360  max mem: 9356\n",
      "Training Epoch: [2]  [ 10/500]  eta: 0:05:17  lr: 0.005000  loss: 6.2778 (6.1688)  loss_classifier: 5.8229 (5.7027)  loss_box_reg: 0.1737 (0.2019)  loss_objectness: 0.1814 (0.1741)  loss_rpn_box_reg: 0.0917 (0.0900)  time: 0.6479  data: 0.1383  max mem: 9356\n",
      "Training Epoch: [2]  [ 20/500]  eta: 0:05:09  lr: 0.005000  loss: 6.0710 (6.2003)  loss_classifier: 5.6425 (5.7177)  loss_box_reg: 0.1972 (0.2100)  loss_objectness: 0.1771 (0.1758)  loss_rpn_box_reg: 0.0926 (0.0968)  time: 0.6450  data: 0.1396  max mem: 9356\n",
      "Training Epoch: [2]  [ 30/500]  eta: 0:05:02  lr: 0.005000  loss: 6.0529 (6.1734)  loss_classifier: 5.5803 (5.6920)  loss_box_reg: 0.2071 (0.2127)  loss_objectness: 0.1736 (0.1757)  loss_rpn_box_reg: 0.0908 (0.0930)  time: 0.6411  data: 0.1401  max mem: 9356\n",
      "Training Epoch: [2]  [ 40/500]  eta: 0:04:54  lr: 0.005000  loss: 6.1349 (6.1775)  loss_classifier: 5.6938 (5.6899)  loss_box_reg: 0.2191 (0.2209)  loss_objectness: 0.1621 (0.1726)  loss_rpn_box_reg: 0.0867 (0.0942)  time: 0.6363  data: 0.1412  max mem: 9356\n",
      "Training Epoch: [2]  [ 50/500]  eta: 0:04:49  lr: 0.005000  loss: 6.1349 (6.2047)  loss_classifier: 5.6938 (5.7182)  loss_box_reg: 0.2145 (0.2190)  loss_objectness: 0.1621 (0.1732)  loss_rpn_box_reg: 0.0867 (0.0943)  time: 0.6404  data: 0.1450  max mem: 9356\n",
      "Training Epoch: [2]  [ 60/500]  eta: 0:04:44  lr: 0.005000  loss: 5.8857 (6.1385)  loss_classifier: 5.4322 (5.6592)  loss_box_reg: 0.2145 (0.2183)  loss_objectness: 0.1579 (0.1704)  loss_rpn_box_reg: 0.0809 (0.0906)  time: 0.6568  data: 0.1477  max mem: 9356\n",
      "Training Epoch: [2]  [ 70/500]  eta: 0:04:37  lr: 0.005000  loss: 5.8614 (6.1167)  loss_classifier: 5.3898 (5.6392)  loss_box_reg: 0.2177 (0.2180)  loss_objectness: 0.1476 (0.1697)  loss_rpn_box_reg: 0.0628 (0.0898)  time: 0.6571  data: 0.1463  max mem: 9356\n",
      "Training Epoch: [2]  [ 80/500]  eta: 0:04:31  lr: 0.005000  loss: 6.0758 (6.1224)  loss_classifier: 5.6251 (5.6502)  loss_box_reg: 0.2063 (0.2180)  loss_objectness: 0.1476 (0.1674)  loss_rpn_box_reg: 0.0624 (0.0868)  time: 0.6430  data: 0.1435  max mem: 9356\n",
      "Training Epoch: [2]  [ 90/500]  eta: 0:04:25  lr: 0.005000  loss: 6.0054 (6.0979)  loss_classifier: 5.5959 (5.6249)  loss_box_reg: 0.2019 (0.2170)  loss_objectness: 0.1504 (0.1677)  loss_rpn_box_reg: 0.0669 (0.0884)  time: 0.6558  data: 0.1416  max mem: 9356\n",
      "Training Epoch: [2]  [100/500]  eta: 0:04:18  lr: 0.005000  loss: 6.1195 (6.1146)  loss_classifier: 5.7020 (5.6459)  loss_box_reg: 0.1891 (0.2139)  loss_objectness: 0.1610 (0.1669)  loss_rpn_box_reg: 0.0798 (0.0880)  time: 0.6508  data: 0.1386  max mem: 9356\n",
      "Training Epoch: [2]  [110/500]  eta: 0:04:10  lr: 0.005000  loss: 6.2393 (6.1164)  loss_classifier: 5.7747 (5.6422)  loss_box_reg: 0.1844 (0.2146)  loss_objectness: 0.1610 (0.1674)  loss_rpn_box_reg: 0.0945 (0.0922)  time: 0.6191  data: 0.1399  max mem: 9356\n",
      "Training Epoch: [2]  [120/500]  eta: 0:04:04  lr: 0.005000  loss: 5.9934 (6.1188)  loss_classifier: 5.5028 (5.6459)  loss_box_reg: 0.1938 (0.2110)  loss_objectness: 0.1742 (0.1686)  loss_rpn_box_reg: 0.1070 (0.0933)  time: 0.6247  data: 0.1422  max mem: 9356\n",
      "Training Epoch: [2]  [130/500]  eta: 0:03:56  lr: 0.005000  loss: 6.0051 (6.1318)  loss_classifier: 5.5818 (5.6572)  loss_box_reg: 0.1879 (0.2113)  loss_objectness: 0.1759 (0.1694)  loss_rpn_box_reg: 0.0899 (0.0939)  time: 0.6223  data: 0.1416  max mem: 9356\n",
      "Training Epoch: [2]  [140/500]  eta: 0:03:49  lr: 0.005000  loss: 6.0051 (6.1247)  loss_classifier: 5.5532 (5.6490)  loss_box_reg: 0.2279 (0.2126)  loss_objectness: 0.1816 (0.1703)  loss_rpn_box_reg: 0.0790 (0.0928)  time: 0.6148  data: 0.1439  max mem: 9356\n",
      "Training Epoch: [2]  [150/500]  eta: 0:03:43  lr: 0.005000  loss: 6.0682 (6.1283)  loss_classifier: 5.4994 (5.6530)  loss_box_reg: 0.2279 (0.2124)  loss_objectness: 0.1837 (0.1709)  loss_rpn_box_reg: 0.0776 (0.0920)  time: 0.6370  data: 0.1463  max mem: 9356\n",
      "Training Epoch: [2]  [160/500]  eta: 0:03:36  lr: 0.005000  loss: 6.1947 (6.1320)  loss_classifier: 5.6627 (5.6554)  loss_box_reg: 0.2194 (0.2126)  loss_objectness: 0.1690 (0.1713)  loss_rpn_box_reg: 0.0809 (0.0927)  time: 0.6288  data: 0.1434  max mem: 9356\n",
      "Training Epoch: [2]  [170/500]  eta: 0:03:29  lr: 0.005000  loss: 6.3664 (6.1501)  loss_classifier: 5.7433 (5.6727)  loss_box_reg: 0.2056 (0.2133)  loss_objectness: 0.1695 (0.1710)  loss_rpn_box_reg: 0.0959 (0.0932)  time: 0.6092  data: 0.1397  max mem: 9356\n",
      "Training Epoch: [2]  [180/500]  eta: 0:03:24  lr: 0.005000  loss: 6.2224 (6.1487)  loss_classifier: 5.7433 (5.6723)  loss_box_reg: 0.2014 (0.2126)  loss_objectness: 0.1674 (0.1704)  loss_rpn_box_reg: 0.0803 (0.0933)  time: 0.6383  data: 0.1476  max mem: 9356\n",
      "Training Epoch: [2]  [190/500]  eta: 0:03:18  lr: 0.005000  loss: 5.9859 (6.1489)  loss_classifier: 5.4650 (5.6722)  loss_box_reg: 0.2014 (0.2123)  loss_objectness: 0.1608 (0.1702)  loss_rpn_box_reg: 0.0874 (0.0943)  time: 0.6658  data: 0.1470  max mem: 9356\n",
      "Training Epoch: [2]  [200/500]  eta: 0:03:11  lr: 0.005000  loss: 6.0559 (6.1492)  loss_classifier: 5.5354 (5.6738)  loss_box_reg: 0.2068 (0.2119)  loss_objectness: 0.1608 (0.1701)  loss_rpn_box_reg: 0.0818 (0.0934)  time: 0.6458  data: 0.1407  max mem: 9356\n",
      "Training Epoch: [2]  [210/500]  eta: 0:03:05  lr: 0.005000  loss: 6.0699 (6.1415)  loss_classifier: 5.5697 (5.6654)  loss_box_reg: 0.2139 (0.2122)  loss_objectness: 0.1652 (0.1701)  loss_rpn_box_reg: 0.0796 (0.0938)  time: 0.6342  data: 0.1479  max mem: 9356\n",
      "Training Epoch: [2]  [220/500]  eta: 0:02:58  lr: 0.005000  loss: 6.0831 (6.1399)  loss_classifier: 5.5927 (5.6649)  loss_box_reg: 0.2225 (0.2121)  loss_objectness: 0.1710 (0.1699)  loss_rpn_box_reg: 0.0780 (0.0931)  time: 0.6440  data: 0.1454  max mem: 9356\n",
      "Training Epoch: [2]  [230/500]  eta: 0:02:52  lr: 0.005000  loss: 6.0831 (6.1379)  loss_classifier: 5.5608 (5.6618)  loss_box_reg: 0.2197 (0.2129)  loss_objectness: 0.1656 (0.1698)  loss_rpn_box_reg: 0.0753 (0.0933)  time: 0.6354  data: 0.1382  max mem: 9356\n",
      "Training Epoch: [2]  [240/500]  eta: 0:02:46  lr: 0.005000  loss: 6.0996 (6.1415)  loss_classifier: 5.5608 (5.6668)  loss_box_reg: 0.2197 (0.2125)  loss_objectness: 0.1656 (0.1695)  loss_rpn_box_reg: 0.0865 (0.0927)  time: 0.6354  data: 0.1405  max mem: 9356\n",
      "Training Epoch: [2]  [250/500]  eta: 0:02:39  lr: 0.005000  loss: 6.2699 (6.1477)  loss_classifier: 5.7727 (5.6738)  loss_box_reg: 0.2147 (0.2128)  loss_objectness: 0.1582 (0.1694)  loss_rpn_box_reg: 0.0736 (0.0917)  time: 0.6443  data: 0.1447  max mem: 9356\n",
      "Training Epoch: [2]  [260/500]  eta: 0:02:33  lr: 0.005000  loss: 6.1912 (6.1500)  loss_classifier: 5.7132 (5.6737)  loss_box_reg: 0.2366 (0.2142)  loss_objectness: 0.1680 (0.1694)  loss_rpn_box_reg: 0.0879 (0.0927)  time: 0.6413  data: 0.1475  max mem: 9356\n",
      "Training Epoch: [2]  [270/500]  eta: 0:02:27  lr: 0.005000  loss: 6.1064 (6.1477)  loss_classifier: 5.5815 (5.6710)  loss_box_reg: 0.2271 (0.2147)  loss_objectness: 0.1680 (0.1693)  loss_rpn_box_reg: 0.0973 (0.0927)  time: 0.6430  data: 0.1473  max mem: 9356\n",
      "Training Epoch: [2]  [280/500]  eta: 0:02:20  lr: 0.005000  loss: 6.0614 (6.1424)  loss_classifier: 5.5481 (5.6641)  loss_box_reg: 0.2347 (0.2162)  loss_objectness: 0.1752 (0.1696)  loss_rpn_box_reg: 0.0793 (0.0925)  time: 0.6350  data: 0.1448  max mem: 9356\n",
      "Training Epoch: [2]  [290/500]  eta: 0:02:14  lr: 0.005000  loss: 6.1170 (6.1537)  loss_classifier: 5.5612 (5.6735)  loss_box_reg: 0.2514 (0.2174)  loss_objectness: 0.1740 (0.1700)  loss_rpn_box_reg: 0.0867 (0.0928)  time: 0.6239  data: 0.1432  max mem: 9356\n",
      "Training Epoch: [2]  [300/500]  eta: 0:02:07  lr: 0.005000  loss: 6.4500 (6.1639)  loss_classifier: 5.9333 (5.6855)  loss_box_reg: 0.1994 (0.2163)  loss_objectness: 0.1614 (0.1698)  loss_rpn_box_reg: 0.0741 (0.0924)  time: 0.6353  data: 0.1405  max mem: 9356\n",
      "Training Epoch: [2]  [310/500]  eta: 0:02:01  lr: 0.005000  loss: 6.2269 (6.1664)  loss_classifier: 5.7755 (5.6882)  loss_box_reg: 0.1699 (0.2162)  loss_objectness: 0.1518 (0.1693)  loss_rpn_box_reg: 0.0741 (0.0927)  time: 0.6382  data: 0.1372  max mem: 9356\n",
      "Training Epoch: [2]  [320/500]  eta: 0:01:54  lr: 0.005000  loss: 6.1074 (6.1682)  loss_classifier: 5.5470 (5.6890)  loss_box_reg: 0.2097 (0.2166)  loss_objectness: 0.1635 (0.1694)  loss_rpn_box_reg: 0.0996 (0.0932)  time: 0.6303  data: 0.1410  max mem: 9356\n",
      "Training Epoch: [2]  [330/500]  eta: 0:01:48  lr: 0.005000  loss: 6.0866 (6.1708)  loss_classifier: 5.6532 (5.6918)  loss_box_reg: 0.2035 (0.2161)  loss_objectness: 0.1686 (0.1695)  loss_rpn_box_reg: 0.0904 (0.0933)  time: 0.6261  data: 0.1429  max mem: 9356\n",
      "Training Epoch: [2]  [340/500]  eta: 0:01:42  lr: 0.005000  loss: 6.2818 (6.1744)  loss_classifier: 5.7906 (5.6973)  loss_box_reg: 0.1957 (0.2155)  loss_objectness: 0.1625 (0.1690)  loss_rpn_box_reg: 0.0714 (0.0926)  time: 0.6391  data: 0.1411  max mem: 9356\n",
      "Training Epoch: [2]  [350/500]  eta: 0:01:35  lr: 0.005000  loss: 6.2749 (6.1757)  loss_classifier: 5.8166 (5.6989)  loss_box_reg: 0.1957 (0.2152)  loss_objectness: 0.1501 (0.1689)  loss_rpn_box_reg: 0.0769 (0.0927)  time: 0.6476  data: 0.1430  max mem: 9356\n",
      "Training Epoch: [2]  [360/500]  eta: 0:01:29  lr: 0.005000  loss: 6.2268 (6.1748)  loss_classifier: 5.8166 (5.6976)  loss_box_reg: 0.2252 (0.2155)  loss_objectness: 0.1547 (0.1686)  loss_rpn_box_reg: 0.0962 (0.0931)  time: 0.6318  data: 0.1446  max mem: 9356\n",
      "Training Epoch: [2]  [370/500]  eta: 0:01:22  lr: 0.005000  loss: 6.0005 (6.1721)  loss_classifier: 5.5087 (5.6952)  loss_box_reg: 0.2168 (0.2151)  loss_objectness: 0.1616 (0.1684)  loss_rpn_box_reg: 0.0930 (0.0934)  time: 0.6448  data: 0.1468  max mem: 9356\n",
      "Training Epoch: [2]  [380/500]  eta: 0:01:16  lr: 0.005000  loss: 6.1491 (6.1800)  loss_classifier: 5.7320 (5.7030)  loss_box_reg: 0.2168 (0.2153)  loss_objectness: 0.1751 (0.1684)  loss_rpn_box_reg: 0.0828 (0.0933)  time: 0.6630  data: 0.1471  max mem: 9356\n",
      "Training Epoch: [2]  [390/500]  eta: 0:01:10  lr: 0.005000  loss: 6.3262 (6.1791)  loss_classifier: 5.8408 (5.7029)  loss_box_reg: 0.1906 (0.2147)  loss_objectness: 0.1751 (0.1683)  loss_rpn_box_reg: 0.0828 (0.0932)  time: 0.6653  data: 0.1468  max mem: 9356\n",
      "Training Epoch: [2]  [400/500]  eta: 0:01:03  lr: 0.005000  loss: 6.3262 (6.1869)  loss_classifier: 5.8408 (5.7105)  loss_box_reg: 0.1906 (0.2146)  loss_objectness: 0.1601 (0.1687)  loss_rpn_box_reg: 0.0791 (0.0931)  time: 0.6575  data: 0.1461  max mem: 9356\n",
      "Training Epoch: [2]  [410/500]  eta: 0:00:57  lr: 0.005000  loss: 6.2506 (6.1863)  loss_classifier: 5.8397 (5.7096)  loss_box_reg: 0.2074 (0.2144)  loss_objectness: 0.1739 (0.1692)  loss_rpn_box_reg: 0.0781 (0.0931)  time: 0.6386  data: 0.1442  max mem: 9356\n",
      "Training Epoch: [2]  [420/500]  eta: 0:00:51  lr: 0.005000  loss: 6.0564 (6.1850)  loss_classifier: 5.6003 (5.7086)  loss_box_reg: 0.2226 (0.2145)  loss_objectness: 0.1755 (0.1689)  loss_rpn_box_reg: 0.0781 (0.0931)  time: 0.6370  data: 0.1449  max mem: 9356\n",
      "Training Epoch: [2]  [430/500]  eta: 0:00:44  lr: 0.005000  loss: 5.9718 (6.1788)  loss_classifier: 5.5379 (5.7032)  loss_box_reg: 0.1976 (0.2140)  loss_objectness: 0.1539 (0.1687)  loss_rpn_box_reg: 0.0835 (0.0929)  time: 0.6568  data: 0.1449  max mem: 9356\n",
      "Training Epoch: [2]  [440/500]  eta: 0:00:38  lr: 0.005000  loss: 5.9106 (6.1767)  loss_classifier: 5.4957 (5.7007)  loss_box_reg: 0.1909 (0.2141)  loss_objectness: 0.1539 (0.1686)  loss_rpn_box_reg: 0.0969 (0.0933)  time: 0.6480  data: 0.1426  max mem: 9356\n",
      "Training Epoch: [2]  [450/500]  eta: 0:00:32  lr: 0.005000  loss: 6.1936 (6.1796)  loss_classifier: 5.7238 (5.7029)  loss_box_reg: 0.2284 (0.2147)  loss_objectness: 0.1663 (0.1686)  loss_rpn_box_reg: 0.1015 (0.0934)  time: 0.6298  data: 0.1436  max mem: 9356\n",
      "Training Epoch: [2]  [460/500]  eta: 0:00:25  lr: 0.005000  loss: 6.5093 (6.1920)  loss_classifier: 6.0875 (5.7156)  loss_box_reg: 0.2284 (0.2146)  loss_objectness: 0.1612 (0.1684)  loss_rpn_box_reg: 0.0802 (0.0933)  time: 0.6218  data: 0.1429  max mem: 9356\n",
      "Training Epoch: [2]  [470/500]  eta: 0:00:19  lr: 0.005000  loss: 6.5216 (6.1967)  loss_classifier: 6.0007 (5.7195)  loss_box_reg: 0.2209 (0.2149)  loss_objectness: 0.1712 (0.1689)  loss_rpn_box_reg: 0.0792 (0.0934)  time: 0.6458  data: 0.1424  max mem: 9356\n",
      "Training Epoch: [2]  [480/500]  eta: 0:00:12  lr: 0.005000  loss: 6.2215 (6.1960)  loss_classifier: 5.7880 (5.7190)  loss_box_reg: 0.2091 (0.2146)  loss_objectness: 0.1867 (0.1690)  loss_rpn_box_reg: 0.0817 (0.0934)  time: 0.6649  data: 0.1451  max mem: 9356\n",
      "Training Epoch: [2]  [490/500]  eta: 0:00:06  lr: 0.005000  loss: 6.0531 (6.1930)  loss_classifier: 5.5595 (5.7143)  loss_box_reg: 0.2023 (0.2152)  loss_objectness: 0.1836 (0.1697)  loss_rpn_box_reg: 0.0982 (0.0938)  time: 0.6456  data: 0.1464  max mem: 9356\n",
      "Training Epoch: [2]  [499/500]  eta: 0:00:00  lr: 0.005000  loss: 6.0513 (6.1913)  loss_classifier: 5.6515 (5.7120)  loss_box_reg: 0.2431 (0.2153)  loss_objectness: 0.1858 (0.1699)  loss_rpn_box_reg: 0.1128 (0.0940)  time: 0.6472  data: 0.1445  max mem: 9356\n",
      "Training Epoch: [2] Total time: 0:05:20 (0.6406 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:07  model_time: 0.8182 (0.8182)  evaluator_time: 0.0330 (0.0330)  time: 1.0162  data: 0.1560  max mem: 9356\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4691 (0.4797)  evaluator_time: 0.0340 (0.0362)  time: 0.6640  data: 0.1556  max mem: 10017\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4721 (0.4786)  evaluator_time: 0.0350 (0.0377)  time: 0.6679  data: 0.1503  max mem: 10017\n",
      "Test: Total time: 0:01:24 (0.6750 s / it)\n",
      "Averaged stats: model_time: 0.4721 (0.4786)  evaluator_time: 0.0350 (0.0377)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.24s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.043\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.083\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.043\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.150\n",
      "Testing Epoch: [2]  [  0/125]  eta: 0:01:25  lr: 0.005000  loss: 6.1563 (6.1563)  loss_classifier: 5.6403 (5.6403)  loss_box_reg: 0.2173 (0.2173)  loss_objectness: 0.1424 (0.1424)  loss_rpn_box_reg: 0.1562 (0.1562)  time: 0.6842  data: 0.1510  max mem: 10017\n",
      "Testing Epoch: [2]  [100/125]  eta: 0:00:15  lr: 0.005000  loss: 5.9440 (6.0688)  loss_classifier: 5.3779 (5.5796)  loss_box_reg: 0.2290 (0.2416)  loss_objectness: 0.1454 (0.1484)  loss_rpn_box_reg: 0.0800 (0.0992)  time: 0.6011  data: 0.1457  max mem: 10017\n",
      "Testing Epoch: [2]  [124/125]  eta: 0:00:00  lr: 0.005000  loss: 6.0567 (6.1007)  loss_classifier: 5.6225 (5.6147)  loss_box_reg: 0.2118 (0.2392)  loss_objectness: 0.1360 (0.1483)  loss_rpn_box_reg: 0.0761 (0.0984)  time: 0.6118  data: 0.1477  max mem: 10017\n",
      "Testing Epoch: [2] Total time: 0:01:16 (0.6146 s / it)\n",
      "Training Epoch: [3]  [  0/500]  eta: 0:05:11  lr: 0.005000  loss: 6.0528 (6.0528)  loss_classifier: 5.6962 (5.6962)  loss_box_reg: 0.1789 (0.1789)  loss_objectness: 0.1268 (0.1268)  loss_rpn_box_reg: 0.0510 (0.0510)  time: 0.6221  data: 0.1390  max mem: 10017\n",
      "Training Epoch: [3]  [ 10/500]  eta: 0:05:13  lr: 0.005000  loss: 6.1397 (6.3333)  loss_classifier: 5.7483 (5.9109)  loss_box_reg: 0.1789 (0.1777)  loss_objectness: 0.1475 (0.1570)  loss_rpn_box_reg: 0.0821 (0.0878)  time: 0.6401  data: 0.1363  max mem: 10017\n",
      "Training Epoch: [3]  [ 20/500]  eta: 0:04:59  lr: 0.005000  loss: 6.4016 (6.3815)  loss_classifier: 5.8346 (5.9143)  loss_box_reg: 0.2061 (0.2044)  loss_objectness: 0.1632 (0.1659)  loss_rpn_box_reg: 0.0821 (0.0969)  time: 0.6238  data: 0.1378  max mem: 10017\n",
      "Training Epoch: [3]  [ 30/500]  eta: 0:04:54  lr: 0.005000  loss: 6.3515 (6.3646)  loss_classifier: 5.8611 (5.8952)  loss_box_reg: 0.2333 (0.2084)  loss_objectness: 0.1812 (0.1680)  loss_rpn_box_reg: 0.0750 (0.0929)  time: 0.6191  data: 0.1413  max mem: 10017\n",
      "Training Epoch: [3]  [ 40/500]  eta: 0:04:49  lr: 0.005000  loss: 6.3515 (6.3696)  loss_classifier: 5.7122 (5.8892)  loss_box_reg: 0.2142 (0.2099)  loss_objectness: 0.1778 (0.1724)  loss_rpn_box_reg: 0.0896 (0.0981)  time: 0.6352  data: 0.1447  max mem: 10017\n",
      "Training Epoch: [3]  [ 50/500]  eta: 0:04:43  lr: 0.005000  loss: 6.0131 (6.2891)  loss_classifier: 5.4720 (5.8026)  loss_box_reg: 0.2206 (0.2166)  loss_objectness: 0.1699 (0.1696)  loss_rpn_box_reg: 0.0993 (0.1002)  time: 0.6370  data: 0.1423  max mem: 10017\n",
      "Training Epoch: [3]  [ 60/500]  eta: 0:04:37  lr: 0.005000  loss: 6.0344 (6.2848)  loss_classifier: 5.4720 (5.7908)  loss_box_reg: 0.2561 (0.2213)  loss_objectness: 0.1666 (0.1715)  loss_rpn_box_reg: 0.1007 (0.1014)  time: 0.6303  data: 0.1388  max mem: 10017\n",
      "Training Epoch: [3]  [ 70/500]  eta: 0:04:30  lr: 0.005000  loss: 6.1789 (6.2738)  loss_classifier: 5.7636 (5.7842)  loss_box_reg: 0.2418 (0.2226)  loss_objectness: 0.1501 (0.1670)  loss_rpn_box_reg: 0.0902 (0.0999)  time: 0.6250  data: 0.1378  max mem: 10017\n",
      "Training Epoch: [3]  [ 80/500]  eta: 0:04:25  lr: 0.005000  loss: 6.1529 (6.2800)  loss_classifier: 5.6541 (5.7906)  loss_box_reg: 0.2193 (0.2231)  loss_objectness: 0.1503 (0.1668)  loss_rpn_box_reg: 0.0886 (0.0995)  time: 0.6361  data: 0.1393  max mem: 10017\n",
      "Training Epoch: [3]  [ 90/500]  eta: 0:04:21  lr: 0.005000  loss: 6.1605 (6.2732)  loss_classifier: 5.6392 (5.7912)  loss_box_reg: 0.2028 (0.2204)  loss_objectness: 0.1586 (0.1653)  loss_rpn_box_reg: 0.0726 (0.0964)  time: 0.6695  data: 0.1446  max mem: 10017\n",
      "Training Epoch: [3]  [100/500]  eta: 0:04:17  lr: 0.005000  loss: 6.0477 (6.2459)  loss_classifier: 5.7276 (5.7689)  loss_box_reg: 0.2023 (0.2178)  loss_objectness: 0.1439 (0.1640)  loss_rpn_box_reg: 0.0714 (0.0951)  time: 0.6892  data: 0.1492  max mem: 10017\n",
      "Training Epoch: [3]  [110/500]  eta: 0:04:11  lr: 0.005000  loss: 6.1367 (6.2464)  loss_classifier: 5.7380 (5.7725)  loss_box_reg: 0.1862 (0.2154)  loss_objectness: 0.1439 (0.1643)  loss_rpn_box_reg: 0.0792 (0.0943)  time: 0.6730  data: 0.1494  max mem: 10017\n",
      "Training Epoch: [3]  [120/500]  eta: 0:04:05  lr: 0.005000  loss: 6.1376 (6.2374)  loss_classifier: 5.7482 (5.7631)  loss_box_reg: 0.2066 (0.2171)  loss_objectness: 0.1446 (0.1632)  loss_rpn_box_reg: 0.0824 (0.0939)  time: 0.6577  data: 0.1483  max mem: 10017\n",
      "Training Epoch: [3]  [130/500]  eta: 0:03:58  lr: 0.005000  loss: 6.0868 (6.2440)  loss_classifier: 5.5934 (5.7700)  loss_box_reg: 0.2111 (0.2168)  loss_objectness: 0.1534 (0.1639)  loss_rpn_box_reg: 0.0779 (0.0934)  time: 0.6482  data: 0.1486  max mem: 10017\n",
      "Training Epoch: [3]  [140/500]  eta: 0:03:51  lr: 0.005000  loss: 6.2723 (6.2566)  loss_classifier: 5.7930 (5.7795)  loss_box_reg: 0.2262 (0.2182)  loss_objectness: 0.1704 (0.1652)  loss_rpn_box_reg: 0.0780 (0.0936)  time: 0.6324  data: 0.1453  max mem: 10017\n",
      "Training Epoch: [3]  [150/500]  eta: 0:03:44  lr: 0.005000  loss: 6.2052 (6.2485)  loss_classifier: 5.6239 (5.7683)  loss_box_reg: 0.2525 (0.2199)  loss_objectness: 0.1731 (0.1665)  loss_rpn_box_reg: 0.0842 (0.0939)  time: 0.6241  data: 0.1450  max mem: 10017\n",
      "Training Epoch: [3]  [160/500]  eta: 0:03:38  lr: 0.005000  loss: 6.1958 (6.2460)  loss_classifier: 5.6239 (5.7669)  loss_box_reg: 0.2178 (0.2193)  loss_objectness: 0.1688 (0.1667)  loss_rpn_box_reg: 0.0857 (0.0930)  time: 0.6285  data: 0.1524  max mem: 10017\n",
      "Training Epoch: [3]  [170/500]  eta: 0:03:32  lr: 0.005000  loss: 6.2394 (6.2489)  loss_classifier: 5.7895 (5.7687)  loss_box_reg: 0.2173 (0.2196)  loss_objectness: 0.1560 (0.1666)  loss_rpn_box_reg: 0.0865 (0.0940)  time: 0.6493  data: 0.1536  max mem: 10017\n",
      "Training Epoch: [3]  [180/500]  eta: 0:03:25  lr: 0.005000  loss: 6.1799 (6.2402)  loss_classifier: 5.6229 (5.7611)  loss_box_reg: 0.2026 (0.2195)  loss_objectness: 0.1576 (0.1661)  loss_rpn_box_reg: 0.0818 (0.0934)  time: 0.6612  data: 0.1497  max mem: 10017\n",
      "Training Epoch: [3]  [190/500]  eta: 0:03:19  lr: 0.005000  loss: 6.0557 (6.2259)  loss_classifier: 5.5048 (5.7503)  loss_box_reg: 0.1794 (0.2181)  loss_objectness: 0.1501 (0.1649)  loss_rpn_box_reg: 0.0733 (0.0926)  time: 0.6561  data: 0.1451  max mem: 10017\n",
      "Training Epoch: [3]  [200/500]  eta: 0:03:13  lr: 0.005000  loss: 6.0557 (6.2174)  loss_classifier: 5.6162 (5.7433)  loss_box_reg: 0.1885 (0.2165)  loss_objectness: 0.1445 (0.1654)  loss_rpn_box_reg: 0.0728 (0.0923)  time: 0.6545  data: 0.1404  max mem: 10017\n",
      "Training Epoch: [3]  [210/500]  eta: 0:03:07  lr: 0.005000  loss: 6.1305 (6.2138)  loss_classifier: 5.6927 (5.7424)  loss_box_reg: 0.2051 (0.2160)  loss_objectness: 0.1605 (0.1645)  loss_rpn_box_reg: 0.0639 (0.0909)  time: 0.6678  data: 0.1417  max mem: 10017\n",
      "Training Epoch: [3]  [220/500]  eta: 0:03:00  lr: 0.005000  loss: 6.1459 (6.2024)  loss_classifier: 5.6842 (5.7305)  loss_box_reg: 0.2163 (0.2170)  loss_objectness: 0.1544 (0.1644)  loss_rpn_box_reg: 0.0652 (0.0905)  time: 0.6561  data: 0.1434  max mem: 10017\n",
      "Training Epoch: [3]  [230/500]  eta: 0:02:54  lr: 0.005000  loss: 5.9950 (6.2022)  loss_classifier: 5.4528 (5.7313)  loss_box_reg: 0.2281 (0.2167)  loss_objectness: 0.1539 (0.1640)  loss_rpn_box_reg: 0.0711 (0.0902)  time: 0.6444  data: 0.1459  max mem: 10017\n",
      "Training Epoch: [3]  [240/500]  eta: 0:02:47  lr: 0.005000  loss: 6.3903 (6.2145)  loss_classifier: 5.8391 (5.7415)  loss_box_reg: 0.1991 (0.2175)  loss_objectness: 0.1679 (0.1649)  loss_rpn_box_reg: 0.0764 (0.0906)  time: 0.6402  data: 0.1491  max mem: 10017\n",
      "Training Epoch: [3]  [250/500]  eta: 0:02:41  lr: 0.005000  loss: 6.3069 (6.2072)  loss_classifier: 5.7405 (5.7335)  loss_box_reg: 0.2332 (0.2183)  loss_objectness: 0.1786 (0.1650)  loss_rpn_box_reg: 0.0864 (0.0904)  time: 0.6167  data: 0.1496  max mem: 10017\n",
      "Training Epoch: [3]  [260/500]  eta: 0:02:34  lr: 0.005000  loss: 6.0251 (6.2049)  loss_classifier: 5.5705 (5.7328)  loss_box_reg: 0.2183 (0.2177)  loss_objectness: 0.1453 (0.1643)  loss_rpn_box_reg: 0.0823 (0.0902)  time: 0.6426  data: 0.1489  max mem: 10017\n",
      "Training Epoch: [3]  [270/500]  eta: 0:02:28  lr: 0.005000  loss: 6.3239 (6.2082)  loss_classifier: 5.8502 (5.7358)  loss_box_reg: 0.2048 (0.2180)  loss_objectness: 0.1452 (0.1639)  loss_rpn_box_reg: 0.0823 (0.0906)  time: 0.6624  data: 0.1491  max mem: 10017\n",
      "Training Epoch: [3]  [280/500]  eta: 0:02:22  lr: 0.005000  loss: 6.2509 (6.2065)  loss_classifier: 5.8021 (5.7337)  loss_box_reg: 0.2078 (0.2184)  loss_objectness: 0.1624 (0.1643)  loss_rpn_box_reg: 0.0775 (0.0901)  time: 0.6541  data: 0.1499  max mem: 10017\n",
      "Training Epoch: [3]  [290/500]  eta: 0:02:15  lr: 0.005000  loss: 6.2282 (6.2083)  loss_classifier: 5.7944 (5.7361)  loss_box_reg: 0.2149 (0.2182)  loss_objectness: 0.1642 (0.1642)  loss_rpn_box_reg: 0.0638 (0.0898)  time: 0.6542  data: 0.1503  max mem: 10017\n",
      "Training Epoch: [3]  [300/500]  eta: 0:02:09  lr: 0.005000  loss: 6.3018 (6.2110)  loss_classifier: 5.8490 (5.7399)  loss_box_reg: 0.2089 (0.2181)  loss_objectness: 0.1462 (0.1635)  loss_rpn_box_reg: 0.0657 (0.0896)  time: 0.6674  data: 0.1481  max mem: 10017\n",
      "Training Epoch: [3]  [310/500]  eta: 0:02:02  lr: 0.005000  loss: 6.1789 (6.2079)  loss_classifier: 5.7496 (5.7355)  loss_box_reg: 0.2189 (0.2194)  loss_objectness: 0.1631 (0.1636)  loss_rpn_box_reg: 0.0657 (0.0894)  time: 0.6658  data: 0.1528  max mem: 10017\n",
      "Training Epoch: [3]  [320/500]  eta: 0:01:56  lr: 0.005000  loss: 6.1059 (6.2089)  loss_classifier: 5.6515 (5.7369)  loss_box_reg: 0.2233 (0.2186)  loss_objectness: 0.1700 (0.1636)  loss_rpn_box_reg: 0.0800 (0.0897)  time: 0.6545  data: 0.1536  max mem: 10017\n",
      "Training Epoch: [3]  [330/500]  eta: 0:01:50  lr: 0.005000  loss: 6.1255 (6.2002)  loss_classifier: 5.6515 (5.7278)  loss_box_reg: 0.1978 (0.2189)  loss_objectness: 0.1483 (0.1636)  loss_rpn_box_reg: 0.0927 (0.0899)  time: 0.6499  data: 0.1462  max mem: 10017\n",
      "Training Epoch: [3]  [340/500]  eta: 0:01:43  lr: 0.005000  loss: 5.9318 (6.1968)  loss_classifier: 5.5384 (5.7246)  loss_box_reg: 0.2351 (0.2195)  loss_objectness: 0.1382 (0.1628)  loss_rpn_box_reg: 0.0793 (0.0898)  time: 0.6474  data: 0.1424  max mem: 10017\n",
      "Training Epoch: [3]  [350/500]  eta: 0:01:37  lr: 0.005000  loss: 5.9501 (6.1974)  loss_classifier: 5.5532 (5.7251)  loss_box_reg: 0.2231 (0.2191)  loss_objectness: 0.1494 (0.1630)  loss_rpn_box_reg: 0.0808 (0.0902)  time: 0.6358  data: 0.1407  max mem: 10017\n",
      "Training Epoch: [3]  [360/500]  eta: 0:01:30  lr: 0.005000  loss: 6.1212 (6.1993)  loss_classifier: 5.6343 (5.7263)  loss_box_reg: 0.2068 (0.2193)  loss_objectness: 0.1720 (0.1636)  loss_rpn_box_reg: 0.0835 (0.0902)  time: 0.6117  data: 0.1403  max mem: 10017\n",
      "Training Epoch: [3]  [370/500]  eta: 0:01:23  lr: 0.005000  loss: 6.1964 (6.1974)  loss_classifier: 5.7049 (5.7236)  loss_box_reg: 0.2068 (0.2195)  loss_objectness: 0.1729 (0.1640)  loss_rpn_box_reg: 0.0842 (0.0903)  time: 0.6297  data: 0.1450  max mem: 10017\n",
      "Training Epoch: [3]  [380/500]  eta: 0:01:17  lr: 0.005000  loss: 6.0661 (6.1942)  loss_classifier: 5.7049 (5.7213)  loss_box_reg: 0.2130 (0.2192)  loss_objectness: 0.1655 (0.1641)  loss_rpn_box_reg: 0.0725 (0.0896)  time: 0.6522  data: 0.1485  max mem: 10017\n",
      "Training Epoch: [3]  [390/500]  eta: 0:01:11  lr: 0.005000  loss: 6.1108 (6.1934)  loss_classifier: 5.6659 (5.7191)  loss_box_reg: 0.2414 (0.2201)  loss_objectness: 0.1599 (0.1641)  loss_rpn_box_reg: 0.0737 (0.0901)  time: 0.6452  data: 0.1444  max mem: 10017\n",
      "Training Epoch: [3]  [400/500]  eta: 0:01:04  lr: 0.005000  loss: 6.2142 (6.1929)  loss_classifier: 5.7007 (5.7193)  loss_box_reg: 0.2433 (0.2203)  loss_objectness: 0.1592 (0.1638)  loss_rpn_box_reg: 0.0767 (0.0895)  time: 0.6256  data: 0.1416  max mem: 10017\n",
      "Training Epoch: [3]  [410/500]  eta: 0:00:58  lr: 0.005000  loss: 6.2142 (6.1972)  loss_classifier: 5.7479 (5.7235)  loss_box_reg: 0.2297 (0.2203)  loss_objectness: 0.1419 (0.1637)  loss_rpn_box_reg: 0.0767 (0.0898)  time: 0.6279  data: 0.1401  max mem: 10017\n",
      "Training Epoch: [3]  [420/500]  eta: 0:00:51  lr: 0.005000  loss: 6.4068 (6.2019)  loss_classifier: 5.8810 (5.7271)  loss_box_reg: 0.2297 (0.2202)  loss_objectness: 0.1773 (0.1644)  loss_rpn_box_reg: 0.0980 (0.0901)  time: 0.6446  data: 0.1419  max mem: 10017\n",
      "Training Epoch: [3]  [430/500]  eta: 0:00:45  lr: 0.005000  loss: 6.2571 (6.2018)  loss_classifier: 5.6315 (5.7260)  loss_box_reg: 0.2314 (0.2208)  loss_objectness: 0.1773 (0.1648)  loss_rpn_box_reg: 0.0784 (0.0901)  time: 0.6371  data: 0.1416  max mem: 10017\n",
      "Training Epoch: [3]  [440/500]  eta: 0:00:38  lr: 0.005000  loss: 6.1306 (6.2025)  loss_classifier: 5.5435 (5.7270)  loss_box_reg: 0.2090 (0.2203)  loss_objectness: 0.1684 (0.1650)  loss_rpn_box_reg: 0.0784 (0.0902)  time: 0.6271  data: 0.1389  max mem: 10017\n",
      "Training Epoch: [3]  [450/500]  eta: 0:00:32  lr: 0.005000  loss: 6.1460 (6.2058)  loss_classifier: 5.6466 (5.7298)  loss_box_reg: 0.2160 (0.2207)  loss_objectness: 0.1684 (0.1654)  loss_rpn_box_reg: 0.0881 (0.0900)  time: 0.6222  data: 0.1393  max mem: 10017\n",
      "Training Epoch: [3]  [460/500]  eta: 0:00:25  lr: 0.005000  loss: 6.1867 (6.2031)  loss_classifier: 5.7610 (5.7285)  loss_box_reg: 0.2294 (0.2203)  loss_objectness: 0.1566 (0.1648)  loss_rpn_box_reg: 0.0724 (0.0895)  time: 0.6453  data: 0.1439  max mem: 10017\n",
      "Training Epoch: [3]  [470/500]  eta: 0:00:19  lr: 0.005000  loss: 6.1866 (6.2044)  loss_classifier: 5.7610 (5.7305)  loss_box_reg: 0.1889 (0.2204)  loss_objectness: 0.1377 (0.1644)  loss_rpn_box_reg: 0.0542 (0.0890)  time: 0.6513  data: 0.1416  max mem: 10017\n",
      "Training Epoch: [3]  [480/500]  eta: 0:00:12  lr: 0.005000  loss: 6.1926 (6.2054)  loss_classifier: 5.7846 (5.7308)  loss_box_reg: 0.2278 (0.2209)  loss_objectness: 0.1601 (0.1647)  loss_rpn_box_reg: 0.0769 (0.0889)  time: 0.6162  data: 0.1367  max mem: 10017\n",
      "Training Epoch: [3]  [490/500]  eta: 0:00:06  lr: 0.005000  loss: 6.3976 (6.2101)  loss_classifier: 5.8953 (5.7349)  loss_box_reg: 0.2273 (0.2212)  loss_objectness: 0.1780 (0.1649)  loss_rpn_box_reg: 0.0848 (0.0891)  time: 0.6152  data: 0.1388  max mem: 10017\n",
      "Training Epoch: [3]  [499/500]  eta: 0:00:00  lr: 0.005000  loss: 6.2508 (6.2089)  loss_classifier: 5.8180 (5.7333)  loss_box_reg: 0.2273 (0.2215)  loss_objectness: 0.1582 (0.1649)  loss_rpn_box_reg: 0.0925 (0.0893)  time: 0.6326  data: 0.1393  max mem: 10017\n",
      "Training Epoch: [3] Total time: 0:05:21 (0.6428 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:06  model_time: 0.8242 (0.8242)  evaluator_time: 0.0340 (0.0340)  time: 1.0142  data: 0.1470  max mem: 10017\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4581 (0.4749)  evaluator_time: 0.0340 (0.0356)  time: 0.6547  data: 0.1522  max mem: 10029\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4861 (0.4758)  evaluator_time: 0.0350 (0.0362)  time: 0.6750  data: 0.1498  max mem: 10029\n",
      "Test: Total time: 0:01:23 (0.6703 s / it)\n",
      "Averaged stats: model_time: 0.4861 (0.4758)  evaluator_time: 0.0350 (0.0362)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.29s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.160\n",
      "Testing Epoch: [3]  [  0/125]  eta: 0:01:22  lr: 0.005000  loss: 6.1978 (6.1978)  loss_classifier: 5.6747 (5.6747)  loss_box_reg: 0.2426 (0.2426)  loss_objectness: 0.1366 (0.1366)  loss_rpn_box_reg: 0.1439 (0.1439)  time: 0.6581  data: 0.1450  max mem: 10029\n",
      "Testing Epoch: [3]  [100/125]  eta: 0:00:15  lr: 0.005000  loss: 5.9800 (6.0841)  loss_classifier: 5.4284 (5.5888)  loss_box_reg: 0.2464 (0.2584)  loss_objectness: 0.1437 (0.1422)  loss_rpn_box_reg: 0.0716 (0.0948)  time: 0.6041  data: 0.1526  max mem: 10029\n",
      "Testing Epoch: [3]  [124/125]  eta: 0:00:00  lr: 0.005000  loss: 6.1364 (6.1181)  loss_classifier: 5.6310 (5.6261)  loss_box_reg: 0.2163 (0.2544)  loss_objectness: 0.1374 (0.1428)  loss_rpn_box_reg: 0.0780 (0.0949)  time: 0.6107  data: 0.1481  max mem: 10029\n",
      "Testing Epoch: [3] Total time: 0:01:16 (0.6112 s / it)\n",
      "Training Epoch: [4]  [  0/500]  eta: 0:05:14  lr: 0.005000  loss: 6.8154 (6.8154)  loss_classifier: 6.2716 (6.2716)  loss_box_reg: 0.2715 (0.2715)  loss_objectness: 0.1757 (0.1757)  loss_rpn_box_reg: 0.0967 (0.0967)  time: 0.6291  data: 0.1420  max mem: 10029\n",
      "Training Epoch: [4]  [ 10/500]  eta: 0:05:16  lr: 0.005000  loss: 6.1631 (6.1465)  loss_classifier: 5.7586 (5.6928)  loss_box_reg: 0.2225 (0.2166)  loss_objectness: 0.1656 (0.1585)  loss_rpn_box_reg: 0.0817 (0.0785)  time: 0.6465  data: 0.1430  max mem: 10029\n",
      "Training Epoch: [4]  [ 20/500]  eta: 0:05:07  lr: 0.005000  loss: 6.0689 (6.0791)  loss_classifier: 5.5565 (5.6235)  loss_box_reg: 0.2139 (0.2105)  loss_objectness: 0.1514 (0.1614)  loss_rpn_box_reg: 0.0817 (0.0837)  time: 0.6405  data: 0.1398  max mem: 10029\n",
      "Training Epoch: [4]  [ 30/500]  eta: 0:04:56  lr: 0.005000  loss: 6.1663 (6.1488)  loss_classifier: 5.5565 (5.6702)  loss_box_reg: 0.2280 (0.2257)  loss_objectness: 0.1473 (0.1628)  loss_rpn_box_reg: 0.0956 (0.0901)  time: 0.6227  data: 0.1385  max mem: 10029\n",
      "Training Epoch: [4]  [ 40/500]  eta: 0:04:48  lr: 0.005000  loss: 6.1722 (6.1505)  loss_classifier: 5.6705 (5.6700)  loss_box_reg: 0.2339 (0.2253)  loss_objectness: 0.1440 (0.1621)  loss_rpn_box_reg: 0.0887 (0.0931)  time: 0.6152  data: 0.1437  max mem: 10029\n",
      "Training Epoch: [4]  [ 50/500]  eta: 0:04:44  lr: 0.005000  loss: 5.9928 (6.1083)  loss_classifier: 5.5199 (5.6390)  loss_box_reg: 0.1961 (0.2211)  loss_objectness: 0.1431 (0.1607)  loss_rpn_box_reg: 0.0638 (0.0875)  time: 0.6358  data: 0.1488  max mem: 10029\n",
      "Training Epoch: [4]  [ 60/500]  eta: 0:04:41  lr: 0.005000  loss: 6.0194 (6.1212)  loss_classifier: 5.5199 (5.6561)  loss_box_reg: 0.1909 (0.2194)  loss_objectness: 0.1496 (0.1599)  loss_rpn_box_reg: 0.0630 (0.0857)  time: 0.6626  data: 0.1494  max mem: 10029\n",
      "Training Epoch: [4]  [ 70/500]  eta: 0:04:35  lr: 0.005000  loss: 6.0194 (6.1093)  loss_classifier: 5.5119 (5.6460)  loss_box_reg: 0.2004 (0.2209)  loss_objectness: 0.1496 (0.1593)  loss_rpn_box_reg: 0.0650 (0.0831)  time: 0.6603  data: 0.1483  max mem: 10029\n",
      "Training Epoch: [4]  [ 80/500]  eta: 0:04:30  lr: 0.005000  loss: 5.9627 (6.1306)  loss_classifier: 5.5020 (5.6666)  loss_box_reg: 0.2277 (0.2215)  loss_objectness: 0.1522 (0.1589)  loss_rpn_box_reg: 0.0749 (0.0835)  time: 0.6541  data: 0.1473  max mem: 10029\n",
      "Training Epoch: [4]  [ 90/500]  eta: 0:04:22  lr: 0.005000  loss: 6.1570 (6.1407)  loss_classifier: 5.7867 (5.6736)  loss_box_reg: 0.2387 (0.2263)  loss_objectness: 0.1522 (0.1573)  loss_rpn_box_reg: 0.0884 (0.0836)  time: 0.6352  data: 0.1460  max mem: 10029\n",
      "Training Epoch: [4]  [100/500]  eta: 0:04:15  lr: 0.005000  loss: 6.3753 (6.1859)  loss_classifier: 6.0238 (5.7195)  loss_box_reg: 0.2427 (0.2257)  loss_objectness: 0.1474 (0.1579)  loss_rpn_box_reg: 0.0804 (0.0828)  time: 0.6228  data: 0.1441  max mem: 10029\n",
      "Training Epoch: [4]  [110/500]  eta: 0:04:09  lr: 0.005000  loss: 6.3753 (6.1874)  loss_classifier: 5.9040 (5.7174)  loss_box_reg: 0.2370 (0.2273)  loss_objectness: 0.1622 (0.1596)  loss_rpn_box_reg: 0.0804 (0.0831)  time: 0.6345  data: 0.1412  max mem: 10029\n",
      "Training Epoch: [4]  [120/500]  eta: 0:04:02  lr: 0.005000  loss: 6.1391 (6.2028)  loss_classifier: 5.7684 (5.7399)  loss_box_reg: 0.1942 (0.2233)  loss_objectness: 0.1372 (0.1577)  loss_rpn_box_reg: 0.0707 (0.0819)  time: 0.6334  data: 0.1395  max mem: 10029\n",
      "Training Epoch: [4]  [130/500]  eta: 0:03:56  lr: 0.005000  loss: 6.2347 (6.2073)  loss_classifier: 5.7684 (5.7430)  loss_box_reg: 0.1865 (0.2232)  loss_objectness: 0.1351 (0.1581)  loss_rpn_box_reg: 0.0617 (0.0830)  time: 0.6344  data: 0.1397  max mem: 10029\n",
      "Training Epoch: [4]  [140/500]  eta: 0:03:49  lr: 0.005000  loss: 6.1415 (6.2008)  loss_classifier: 5.6695 (5.7336)  loss_box_reg: 0.2091 (0.2245)  loss_objectness: 0.1516 (0.1589)  loss_rpn_box_reg: 0.0874 (0.0839)  time: 0.6305  data: 0.1405  max mem: 10029\n",
      "Training Epoch: [4]  [150/500]  eta: 0:03:42  lr: 0.005000  loss: 6.1065 (6.1908)  loss_classifier: 5.6506 (5.7234)  loss_box_reg: 0.2163 (0.2244)  loss_objectness: 0.1560 (0.1597)  loss_rpn_box_reg: 0.0716 (0.0832)  time: 0.6281  data: 0.1389  max mem: 10029\n",
      "Training Epoch: [4]  [160/500]  eta: 0:03:36  lr: 0.005000  loss: 6.1095 (6.1923)  loss_classifier: 5.6506 (5.7234)  loss_box_reg: 0.2169 (0.2244)  loss_objectness: 0.1744 (0.1606)  loss_rpn_box_reg: 0.0720 (0.0839)  time: 0.6312  data: 0.1396  max mem: 10029\n",
      "Training Epoch: [4]  [170/500]  eta: 0:03:29  lr: 0.005000  loss: 6.1718 (6.1902)  loss_classifier: 5.6492 (5.7209)  loss_box_reg: 0.2320 (0.2253)  loss_objectness: 0.1721 (0.1600)  loss_rpn_box_reg: 0.0836 (0.0839)  time: 0.6156  data: 0.1386  max mem: 10029\n",
      "Training Epoch: [4]  [180/500]  eta: 0:03:22  lr: 0.005000  loss: 6.1264 (6.1942)  loss_classifier: 5.5717 (5.7221)  loss_box_reg: 0.2667 (0.2277)  loss_objectness: 0.1511 (0.1599)  loss_rpn_box_reg: 0.0886 (0.0845)  time: 0.6082  data: 0.1379  max mem: 10029\n",
      "Training Epoch: [4]  [190/500]  eta: 0:03:16  lr: 0.005000  loss: 6.1497 (6.2094)  loss_classifier: 5.6819 (5.7372)  loss_box_reg: 0.2366 (0.2278)  loss_objectness: 0.1516 (0.1597)  loss_rpn_box_reg: 0.0943 (0.0847)  time: 0.6211  data: 0.1395  max mem: 10029\n",
      "Training Epoch: [4]  [200/500]  eta: 0:03:09  lr: 0.005000  loss: 6.4141 (6.2134)  loss_classifier: 6.0263 (5.7417)  loss_box_reg: 0.2215 (0.2274)  loss_objectness: 0.1520 (0.1594)  loss_rpn_box_reg: 0.0911 (0.0848)  time: 0.6289  data: 0.1396  max mem: 10029\n",
      "Training Epoch: [4]  [210/500]  eta: 0:03:03  lr: 0.005000  loss: 6.1706 (6.2143)  loss_classifier: 5.5828 (5.7445)  loss_box_reg: 0.2092 (0.2263)  loss_objectness: 0.1473 (0.1590)  loss_rpn_box_reg: 0.0697 (0.0845)  time: 0.6320  data: 0.1388  max mem: 10029\n",
      "Training Epoch: [4]  [220/500]  eta: 0:02:57  lr: 0.005000  loss: 6.0772 (6.2135)  loss_classifier: 5.5624 (5.7417)  loss_box_reg: 0.2092 (0.2280)  loss_objectness: 0.1473 (0.1590)  loss_rpn_box_reg: 0.0672 (0.0847)  time: 0.6270  data: 0.1382  max mem: 10029\n",
      "Training Epoch: [4]  [230/500]  eta: 0:02:50  lr: 0.005000  loss: 6.1480 (6.2103)  loss_classifier: 5.5624 (5.7389)  loss_box_reg: 0.2218 (0.2271)  loss_objectness: 0.1601 (0.1594)  loss_rpn_box_reg: 0.0849 (0.0849)  time: 0.6113  data: 0.1395  max mem: 10029\n",
      "Training Epoch: [4]  [240/500]  eta: 0:02:44  lr: 0.005000  loss: 6.1573 (6.2129)  loss_classifier: 5.6348 (5.7425)  loss_box_reg: 0.2104 (0.2263)  loss_objectness: 0.1534 (0.1590)  loss_rpn_box_reg: 0.0849 (0.0852)  time: 0.6209  data: 0.1399  max mem: 10029\n",
      "Training Epoch: [4]  [250/500]  eta: 0:02:37  lr: 0.005000  loss: 6.1679 (6.2158)  loss_classifier: 5.6526 (5.7438)  loss_box_reg: 0.2129 (0.2271)  loss_objectness: 0.1479 (0.1591)  loss_rpn_box_reg: 0.0808 (0.0858)  time: 0.6314  data: 0.1391  max mem: 10029\n",
      "Training Epoch: [4]  [260/500]  eta: 0:02:31  lr: 0.005000  loss: 6.0073 (6.2066)  loss_classifier: 5.5400 (5.7334)  loss_box_reg: 0.2231 (0.2267)  loss_objectness: 0.1589 (0.1592)  loss_rpn_box_reg: 0.1082 (0.0873)  time: 0.6182  data: 0.1387  max mem: 10029\n",
      "Training Epoch: [4]  [270/500]  eta: 0:02:25  lr: 0.005000  loss: 5.9834 (6.1980)  loss_classifier: 5.5142 (5.7265)  loss_box_reg: 0.2162 (0.2259)  loss_objectness: 0.1537 (0.1590)  loss_rpn_box_reg: 0.0953 (0.0866)  time: 0.6298  data: 0.1388  max mem: 10029\n",
      "Training Epoch: [4]  [280/500]  eta: 0:02:18  lr: 0.005000  loss: 6.2399 (6.2046)  loss_classifier: 5.7843 (5.7321)  loss_box_reg: 0.2162 (0.2260)  loss_objectness: 0.1555 (0.1592)  loss_rpn_box_reg: 0.0839 (0.0873)  time: 0.6296  data: 0.1388  max mem: 10029\n",
      "Training Epoch: [4]  [290/500]  eta: 0:02:12  lr: 0.005000  loss: 6.2512 (6.2051)  loss_classifier: 5.7459 (5.7305)  loss_box_reg: 0.2386 (0.2272)  loss_objectness: 0.1574 (0.1593)  loss_rpn_box_reg: 0.1032 (0.0881)  time: 0.6241  data: 0.1382  max mem: 10029\n",
      "Training Epoch: [4]  [300/500]  eta: 0:02:06  lr: 0.005000  loss: 6.2257 (6.2076)  loss_classifier: 5.7459 (5.7335)  loss_box_reg: 0.2555 (0.2270)  loss_objectness: 0.1452 (0.1591)  loss_rpn_box_reg: 0.0885 (0.0880)  time: 0.6371  data: 0.1357  max mem: 10029\n",
      "Training Epoch: [4]  [310/500]  eta: 0:01:59  lr: 0.005000  loss: 6.3814 (6.2183)  loss_classifier: 5.8685 (5.7443)  loss_box_reg: 0.2037 (0.2269)  loss_objectness: 0.1529 (0.1596)  loss_rpn_box_reg: 0.0769 (0.0875)  time: 0.6323  data: 0.1366  max mem: 10029\n",
      "Training Epoch: [4]  [320/500]  eta: 0:01:53  lr: 0.005000  loss: 6.3814 (6.2173)  loss_classifier: 5.8685 (5.7422)  loss_box_reg: 0.2223 (0.2277)  loss_objectness: 0.1585 (0.1600)  loss_rpn_box_reg: 0.0644 (0.0875)  time: 0.6219  data: 0.1385  max mem: 10029\n",
      "Training Epoch: [4]  [330/500]  eta: 0:01:47  lr: 0.005000  loss: 6.2430 (6.2220)  loss_classifier: 5.8169 (5.7479)  loss_box_reg: 0.2163 (0.2269)  loss_objectness: 0.1563 (0.1596)  loss_rpn_box_reg: 0.0792 (0.0875)  time: 0.6346  data: 0.1387  max mem: 10029\n",
      "Training Epoch: [4]  [340/500]  eta: 0:01:40  lr: 0.005000  loss: 6.1903 (6.2219)  loss_classifier: 5.7800 (5.7474)  loss_box_reg: 0.1937 (0.2271)  loss_objectness: 0.1565 (0.1600)  loss_rpn_box_reg: 0.0792 (0.0873)  time: 0.6443  data: 0.1383  max mem: 10029\n",
      "Training Epoch: [4]  [350/500]  eta: 0:01:34  lr: 0.005000  loss: 6.1521 (6.2201)  loss_classifier: 5.6535 (5.7467)  loss_box_reg: 0.2092 (0.2268)  loss_objectness: 0.1467 (0.1595)  loss_rpn_box_reg: 0.0723 (0.0871)  time: 0.6209  data: 0.1367  max mem: 10029\n",
      "Training Epoch: [4]  [360/500]  eta: 0:01:28  lr: 0.005000  loss: 6.2081 (6.2189)  loss_classifier: 5.7040 (5.7451)  loss_box_reg: 0.2274 (0.2272)  loss_objectness: 0.1427 (0.1596)  loss_rpn_box_reg: 0.0780 (0.0871)  time: 0.6356  data: 0.1383  max mem: 10029\n",
      "Training Epoch: [4]  [370/500]  eta: 0:01:22  lr: 0.005000  loss: 6.1257 (6.2180)  loss_classifier: 5.6790 (5.7438)  loss_box_reg: 0.2343 (0.2272)  loss_objectness: 0.1459 (0.1598)  loss_rpn_box_reg: 0.0851 (0.0872)  time: 0.6516  data: 0.1394  max mem: 10029\n",
      "Training Epoch: [4]  [380/500]  eta: 0:01:15  lr: 0.005000  loss: 6.1508 (6.2201)  loss_classifier: 5.6790 (5.7438)  loss_box_reg: 0.2408 (0.2284)  loss_objectness: 0.1706 (0.1604)  loss_rpn_box_reg: 0.0935 (0.0876)  time: 0.6304  data: 0.1372  max mem: 10029\n",
      "Training Epoch: [4]  [390/500]  eta: 0:01:09  lr: 0.005000  loss: 6.1508 (6.2144)  loss_classifier: 5.6441 (5.7365)  loss_box_reg: 0.2792 (0.2291)  loss_objectness: 0.1700 (0.1609)  loss_rpn_box_reg: 0.1042 (0.0878)  time: 0.6432  data: 0.1401  max mem: 10029\n",
      "Training Epoch: [4]  [400/500]  eta: 0:01:03  lr: 0.005000  loss: 6.2622 (6.2193)  loss_classifier: 5.7302 (5.7408)  loss_box_reg: 0.2643 (0.2295)  loss_objectness: 0.1645 (0.1608)  loss_rpn_box_reg: 0.0968 (0.0881)  time: 0.6311  data: 0.1409  max mem: 10029\n",
      "Training Epoch: [4]  [410/500]  eta: 0:00:56  lr: 0.005000  loss: 6.2661 (6.2216)  loss_classifier: 5.8547 (5.7438)  loss_box_reg: 0.2086 (0.2291)  loss_objectness: 0.1631 (0.1609)  loss_rpn_box_reg: 0.0779 (0.0877)  time: 0.6150  data: 0.1376  max mem: 10029\n",
      "Training Epoch: [4]  [420/500]  eta: 0:00:50  lr: 0.005000  loss: 6.2198 (6.2211)  loss_classifier: 5.7101 (5.7437)  loss_box_reg: 0.2086 (0.2295)  loss_objectness: 0.1434 (0.1606)  loss_rpn_box_reg: 0.0778 (0.0874)  time: 0.6410  data: 0.1369  max mem: 10029\n",
      "Training Epoch: [4]  [430/500]  eta: 0:00:44  lr: 0.005000  loss: 6.1641 (6.2190)  loss_classifier: 5.7101 (5.7408)  loss_box_reg: 0.2576 (0.2303)  loss_objectness: 0.1364 (0.1605)  loss_rpn_box_reg: 0.0805 (0.0874)  time: 0.6216  data: 0.1369  max mem: 10029\n",
      "Training Epoch: [4]  [440/500]  eta: 0:00:37  lr: 0.005000  loss: 6.2455 (6.2206)  loss_classifier: 5.7485 (5.7423)  loss_box_reg: 0.2415 (0.2305)  loss_objectness: 0.1412 (0.1605)  loss_rpn_box_reg: 0.0771 (0.0874)  time: 0.6073  data: 0.1385  max mem: 10029\n",
      "Training Epoch: [4]  [450/500]  eta: 0:00:31  lr: 0.005000  loss: 6.1234 (6.2164)  loss_classifier: 5.4968 (5.7381)  loss_box_reg: 0.2338 (0.2303)  loss_objectness: 0.1654 (0.1609)  loss_rpn_box_reg: 0.0753 (0.0872)  time: 0.6304  data: 0.1398  max mem: 10029\n",
      "Training Epoch: [4]  [460/500]  eta: 0:00:25  lr: 0.005000  loss: 6.1564 (6.2172)  loss_classifier: 5.5981 (5.7400)  loss_box_reg: 0.1942 (0.2299)  loss_objectness: 0.1455 (0.1605)  loss_rpn_box_reg: 0.0753 (0.0868)  time: 0.6372  data: 0.1400  max mem: 10029\n",
      "Training Epoch: [4]  [470/500]  eta: 0:00:18  lr: 0.005000  loss: 6.1564 (6.2133)  loss_classifier: 5.6634 (5.7368)  loss_box_reg: 0.2031 (0.2297)  loss_objectness: 0.1369 (0.1602)  loss_rpn_box_reg: 0.0758 (0.0866)  time: 0.6224  data: 0.1389  max mem: 10029\n",
      "Training Epoch: [4]  [480/500]  eta: 0:00:12  lr: 0.005000  loss: 6.0717 (6.2107)  loss_classifier: 5.6069 (5.7347)  loss_box_reg: 0.2031 (0.2292)  loss_objectness: 0.1384 (0.1601)  loss_rpn_box_reg: 0.0805 (0.0867)  time: 0.6200  data: 0.1385  max mem: 10029\n",
      "Training Epoch: [4]  [490/500]  eta: 0:00:06  lr: 0.005000  loss: 5.9870 (6.2080)  loss_classifier: 5.5589 (5.7325)  loss_box_reg: 0.1980 (0.2289)  loss_objectness: 0.1406 (0.1600)  loss_rpn_box_reg: 0.0768 (0.0866)  time: 0.6221  data: 0.1400  max mem: 10029\n",
      "Training Epoch: [4]  [499/500]  eta: 0:00:00  lr: 0.005000  loss: 5.9819 (6.2090)  loss_classifier: 5.5554 (5.7341)  loss_box_reg: 0.2117 (0.2287)  loss_objectness: 0.1406 (0.1599)  loss_rpn_box_reg: 0.0645 (0.0863)  time: 0.6171  data: 0.1401  max mem: 10029\n",
      "Training Epoch: [4] Total time: 0:05:14 (0.6299 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:57  model_time: 0.7472 (0.7472)  evaluator_time: 0.0340 (0.0340)  time: 0.9422  data: 0.1520  max mem: 10029\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4351 (0.4473)  evaluator_time: 0.0340 (0.0352)  time: 0.6262  data: 0.1500  max mem: 10593\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4601 (0.4487)  evaluator_time: 0.0350 (0.0359)  time: 0.6507  data: 0.1510  max mem: 10593\n",
      "Test: Total time: 0:01:19 (0.6397 s / it)\n",
      "Averaged stats: model_time: 0.4601 (0.4487)  evaluator_time: 0.0350 (0.0359)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.099\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.171\n",
      "Testing Epoch: [4]  [  0/125]  eta: 0:01:21  lr: 0.005000  loss: 6.1647 (6.1647)  loss_classifier: 5.6482 (5.6482)  loss_box_reg: 0.2555 (0.2555)  loss_objectness: 0.1255 (0.1255)  loss_rpn_box_reg: 0.1355 (0.1355)  time: 0.6531  data: 0.1520  max mem: 10593\n",
      "Testing Epoch: [4]  [100/125]  eta: 0:00:14  lr: 0.005000  loss: 5.9586 (6.1135)  loss_classifier: 5.4020 (5.6075)  loss_box_reg: 0.2492 (0.2750)  loss_objectness: 0.1281 (0.1365)  loss_rpn_box_reg: 0.0777 (0.0945)  time: 0.5881  data: 0.1483  max mem: 10593\n",
      "Testing Epoch: [4]  [124/125]  eta: 0:00:00  lr: 0.005000  loss: 6.1358 (6.1457)  loss_classifier: 5.6510 (5.6445)  loss_box_reg: 0.2294 (0.2710)  loss_objectness: 0.1284 (0.1361)  loss_rpn_box_reg: 0.0747 (0.0940)  time: 0.5992  data: 0.1466  max mem: 10593\n",
      "Testing Epoch: [4] Total time: 0:01:14 (0.5984 s / it)\n",
      "Training Epoch: [5]  [  0/500]  eta: 0:06:05  lr: 0.000500  loss: 6.1312 (6.1312)  loss_classifier: 5.5713 (5.5713)  loss_box_reg: 0.2403 (0.2403)  loss_objectness: 0.1664 (0.1664)  loss_rpn_box_reg: 0.1532 (0.1532)  time: 0.7302  data: 0.1430  max mem: 10593\n",
      "Training Epoch: [5]  [ 10/500]  eta: 0:05:09  lr: 0.000500  loss: 6.1304 (6.2811)  loss_classifier: 5.7055 (5.8152)  loss_box_reg: 0.2105 (0.2230)  loss_objectness: 0.1664 (0.1629)  loss_rpn_box_reg: 0.0678 (0.0800)  time: 0.6324  data: 0.1364  max mem: 10593\n",
      "Training Epoch: [5]  [ 20/500]  eta: 0:05:02  lr: 0.000500  loss: 6.0598 (6.2163)  loss_classifier: 5.7055 (5.7554)  loss_box_reg: 0.2058 (0.2209)  loss_objectness: 0.1604 (0.1592)  loss_rpn_box_reg: 0.0587 (0.0807)  time: 0.6242  data: 0.1355  max mem: 10593\n",
      "Training Epoch: [5]  [ 30/500]  eta: 0:04:53  lr: 0.000500  loss: 6.2183 (6.2006)  loss_classifier: 5.7212 (5.7426)  loss_box_reg: 0.2058 (0.2215)  loss_objectness: 0.1421 (0.1570)  loss_rpn_box_reg: 0.0700 (0.0794)  time: 0.6207  data: 0.1353  max mem: 10593\n",
      "Training Epoch: [5]  [ 40/500]  eta: 0:04:46  lr: 0.000500  loss: 6.2480 (6.1823)  loss_classifier: 5.7554 (5.7302)  loss_box_reg: 0.2051 (0.2183)  loss_objectness: 0.1528 (0.1568)  loss_rpn_box_reg: 0.0700 (0.0772)  time: 0.6172  data: 0.1365  max mem: 10593\n",
      "Training Epoch: [5]  [ 50/500]  eta: 0:04:40  lr: 0.000500  loss: 6.2636 (6.2196)  loss_classifier: 5.8133 (5.7803)  loss_box_reg: 0.1789 (0.2156)  loss_objectness: 0.1368 (0.1512)  loss_rpn_box_reg: 0.0550 (0.0725)  time: 0.6195  data: 0.1357  max mem: 10593\n",
      "Training Epoch: [5]  [ 60/500]  eta: 0:04:34  lr: 0.000500  loss: 6.3186 (6.2275)  loss_classifier: 5.8133 (5.7791)  loss_box_reg: 0.2097 (0.2189)  loss_objectness: 0.1353 (0.1547)  loss_rpn_box_reg: 0.0639 (0.0748)  time: 0.6265  data: 0.1362  max mem: 10593\n",
      "Training Epoch: [5]  [ 70/500]  eta: 0:04:28  lr: 0.000500  loss: 6.1883 (6.2155)  loss_classifier: 5.6656 (5.7617)  loss_box_reg: 0.2335 (0.2224)  loss_objectness: 0.1678 (0.1548)  loss_rpn_box_reg: 0.0827 (0.0766)  time: 0.6249  data: 0.1364  max mem: 10593\n",
      "Training Epoch: [5]  [ 80/500]  eta: 0:04:21  lr: 0.000500  loss: 6.2018 (6.2271)  loss_classifier: 5.7038 (5.7718)  loss_box_reg: 0.2436 (0.2233)  loss_objectness: 0.1590 (0.1549)  loss_rpn_box_reg: 0.0827 (0.0770)  time: 0.6174  data: 0.1357  max mem: 10593\n",
      "Training Epoch: [5]  [ 90/500]  eta: 0:04:15  lr: 0.000500  loss: 6.2018 (6.1990)  loss_classifier: 5.7038 (5.7410)  loss_box_reg: 0.2365 (0.2251)  loss_objectness: 0.1433 (0.1541)  loss_rpn_box_reg: 0.0745 (0.0788)  time: 0.6188  data: 0.1363  max mem: 10593\n",
      "Training Epoch: [5]  [100/500]  eta: 0:04:09  lr: 0.000500  loss: 6.1803 (6.2014)  loss_classifier: 5.6002 (5.7386)  loss_box_reg: 0.2309 (0.2265)  loss_objectness: 0.1729 (0.1573)  loss_rpn_box_reg: 0.0818 (0.0791)  time: 0.6275  data: 0.1360  max mem: 10593\n",
      "Training Epoch: [5]  [110/500]  eta: 0:04:03  lr: 0.000500  loss: 6.1803 (6.1990)  loss_classifier: 5.6691 (5.7356)  loss_box_reg: 0.2255 (0.2270)  loss_objectness: 0.1744 (0.1583)  loss_rpn_box_reg: 0.0800 (0.0781)  time: 0.6311  data: 0.1369  max mem: 10593\n",
      "Training Epoch: [5]  [120/500]  eta: 0:03:56  lr: 0.000500  loss: 5.8240 (6.1705)  loss_classifier: 5.4721 (5.7085)  loss_box_reg: 0.2151 (0.2251)  loss_objectness: 0.1678 (0.1590)  loss_rpn_box_reg: 0.0704 (0.0780)  time: 0.6232  data: 0.1369  max mem: 10593\n",
      "Training Epoch: [5]  [130/500]  eta: 0:03:50  lr: 0.000500  loss: 5.9189 (6.1646)  loss_classifier: 5.5003 (5.7023)  loss_box_reg: 0.2183 (0.2260)  loss_objectness: 0.1527 (0.1583)  loss_rpn_box_reg: 0.0697 (0.0781)  time: 0.6199  data: 0.1358  max mem: 10593\n",
      "Training Epoch: [5]  [140/500]  eta: 0:03:44  lr: 0.000500  loss: 6.2296 (6.1881)  loss_classifier: 5.6917 (5.7269)  loss_box_reg: 0.2207 (0.2271)  loss_objectness: 0.1441 (0.1562)  loss_rpn_box_reg: 0.0659 (0.0779)  time: 0.6272  data: 0.1353  max mem: 10593\n",
      "Training Epoch: [5]  [150/500]  eta: 0:03:38  lr: 0.000500  loss: 6.2944 (6.1945)  loss_classifier: 5.8000 (5.7303)  loss_box_reg: 0.2743 (0.2303)  loss_objectness: 0.1441 (0.1563)  loss_rpn_box_reg: 0.0673 (0.0776)  time: 0.6254  data: 0.1380  max mem: 10593\n",
      "Training Epoch: [5]  [160/500]  eta: 0:03:31  lr: 0.000500  loss: 6.1827 (6.2075)  loss_classifier: 5.7145 (5.7435)  loss_box_reg: 0.2743 (0.2307)  loss_objectness: 0.1522 (0.1558)  loss_rpn_box_reg: 0.0673 (0.0776)  time: 0.6066  data: 0.1369  max mem: 10593\n",
      "Training Epoch: [5]  [170/500]  eta: 0:03:25  lr: 0.000500  loss: 6.5833 (6.2254)  loss_classifier: 6.0260 (5.7576)  loss_box_reg: 0.2520 (0.2331)  loss_objectness: 0.1564 (0.1570)  loss_rpn_box_reg: 0.0683 (0.0777)  time: 0.6159  data: 0.1363  max mem: 10593\n",
      "Training Epoch: [5]  [180/500]  eta: 0:03:19  lr: 0.000500  loss: 6.3211 (6.2152)  loss_classifier: 5.8931 (5.7472)  loss_box_reg: 0.2390 (0.2339)  loss_objectness: 0.1568 (0.1567)  loss_rpn_box_reg: 0.0613 (0.0773)  time: 0.6339  data: 0.1368  max mem: 10593\n",
      "Training Epoch: [5]  [190/500]  eta: 0:03:13  lr: 0.000500  loss: 6.0170 (6.2071)  loss_classifier: 5.5860 (5.7402)  loss_box_reg: 0.2359 (0.2339)  loss_objectness: 0.1426 (0.1559)  loss_rpn_box_reg: 0.0610 (0.0771)  time: 0.6313  data: 0.1338  max mem: 10593\n",
      "Training Epoch: [5]  [200/500]  eta: 0:03:07  lr: 0.000500  loss: 6.0090 (6.2004)  loss_classifier: 5.6204 (5.7341)  loss_box_reg: 0.2085 (0.2334)  loss_objectness: 0.1406 (0.1556)  loss_rpn_box_reg: 0.0707 (0.0774)  time: 0.6365  data: 0.1346  max mem: 10593\n",
      "Training Epoch: [5]  [210/500]  eta: 0:03:00  lr: 0.000500  loss: 6.1007 (6.2046)  loss_classifier: 5.7610 (5.7407)  loss_box_reg: 0.2047 (0.2321)  loss_objectness: 0.1406 (0.1553)  loss_rpn_box_reg: 0.0599 (0.0765)  time: 0.6268  data: 0.1372  max mem: 10593\n",
      "Training Epoch: [5]  [220/500]  eta: 0:02:54  lr: 0.000500  loss: 6.0887 (6.1986)  loss_classifier: 5.7175 (5.7331)  loss_box_reg: 0.2215 (0.2326)  loss_objectness: 0.1489 (0.1555)  loss_rpn_box_reg: 0.0748 (0.0774)  time: 0.6178  data: 0.1379  max mem: 10593\n",
      "Training Epoch: [5]  [230/500]  eta: 0:02:48  lr: 0.000500  loss: 6.1325 (6.2014)  loss_classifier: 5.6891 (5.7366)  loss_box_reg: 0.2359 (0.2320)  loss_objectness: 0.1530 (0.1552)  loss_rpn_box_reg: 0.0843 (0.0775)  time: 0.6207  data: 0.1380  max mem: 10593\n",
      "Training Epoch: [5]  [240/500]  eta: 0:02:41  lr: 0.000500  loss: 6.2268 (6.2071)  loss_classifier: 5.7271 (5.7430)  loss_box_reg: 0.2285 (0.2315)  loss_objectness: 0.1488 (0.1548)  loss_rpn_box_reg: 0.0788 (0.0778)  time: 0.6100  data: 0.1359  max mem: 10593\n",
      "Training Epoch: [5]  [250/500]  eta: 0:02:35  lr: 0.000500  loss: 6.1926 (6.2011)  loss_classifier: 5.7703 (5.7365)  loss_box_reg: 0.2285 (0.2311)  loss_objectness: 0.1444 (0.1554)  loss_rpn_box_reg: 0.0801 (0.0781)  time: 0.6025  data: 0.1340  max mem: 10593\n",
      "Training Epoch: [5]  [260/500]  eta: 0:02:29  lr: 0.000500  loss: 6.2714 (6.2098)  loss_classifier: 5.8379 (5.7452)  loss_box_reg: 0.2126 (0.2310)  loss_objectness: 0.1489 (0.1552)  loss_rpn_box_reg: 0.0801 (0.0784)  time: 0.6105  data: 0.1353  max mem: 10593\n",
      "Training Epoch: [5]  [270/500]  eta: 0:02:22  lr: 0.000500  loss: 6.2714 (6.2110)  loss_classifier: 5.7759 (5.7447)  loss_box_reg: 0.2268 (0.2321)  loss_objectness: 0.1515 (0.1555)  loss_rpn_box_reg: 0.0840 (0.0787)  time: 0.6051  data: 0.1354  max mem: 10593\n",
      "Training Epoch: [5]  [280/500]  eta: 0:02:16  lr: 0.000500  loss: 5.9786 (6.2002)  loss_classifier: 5.4785 (5.7325)  loss_box_reg: 0.2431 (0.2332)  loss_objectness: 0.1558 (0.1559)  loss_rpn_box_reg: 0.0792 (0.0786)  time: 0.6321  data: 0.1412  max mem: 10593\n",
      "Training Epoch: [5]  [290/500]  eta: 0:02:10  lr: 0.000500  loss: 5.9786 (6.2026)  loss_classifier: 5.5275 (5.7360)  loss_box_reg: 0.2254 (0.2330)  loss_objectness: 0.1670 (0.1556)  loss_rpn_box_reg: 0.0682 (0.0779)  time: 0.6594  data: 0.1435  max mem: 10593\n",
      "Training Epoch: [5]  [300/500]  eta: 0:02:04  lr: 0.000500  loss: 6.4506 (6.2175)  loss_classifier: 5.9827 (5.7507)  loss_box_reg: 0.2223 (0.2333)  loss_objectness: 0.1496 (0.1558)  loss_rpn_box_reg: 0.0661 (0.0778)  time: 0.6407  data: 0.1408  max mem: 10593\n",
      "Training Epoch: [5]  [310/500]  eta: 0:01:58  lr: 0.000500  loss: 6.2607 (6.2102)  loss_classifier: 5.8756 (5.7443)  loss_box_reg: 0.2332 (0.2333)  loss_objectness: 0.1396 (0.1550)  loss_rpn_box_reg: 0.0661 (0.0775)  time: 0.6442  data: 0.1404  max mem: 10593\n",
      "Training Epoch: [5]  [320/500]  eta: 0:01:52  lr: 0.000500  loss: 6.0362 (6.2099)  loss_classifier: 5.7084 (5.7458)  loss_box_reg: 0.2123 (0.2322)  loss_objectness: 0.1394 (0.1548)  loss_rpn_box_reg: 0.0588 (0.0771)  time: 0.6363  data: 0.1375  max mem: 10593\n",
      "Training Epoch: [5]  [330/500]  eta: 0:01:46  lr: 0.000500  loss: 6.2269 (6.2091)  loss_classifier: 5.7639 (5.7445)  loss_box_reg: 0.1903 (0.2322)  loss_objectness: 0.1559 (0.1550)  loss_rpn_box_reg: 0.0744 (0.0774)  time: 0.6330  data: 0.1361  max mem: 10593\n",
      "Training Epoch: [5]  [340/500]  eta: 0:01:40  lr: 0.000500  loss: 6.0039 (6.2073)  loss_classifier: 5.5816 (5.7436)  loss_box_reg: 0.2212 (0.2316)  loss_objectness: 0.1571 (0.1550)  loss_rpn_box_reg: 0.0744 (0.0771)  time: 0.6437  data: 0.1378  max mem: 10593\n",
      "Training Epoch: [5]  [350/500]  eta: 0:01:33  lr: 0.000500  loss: 6.0490 (6.2039)  loss_classifier: 5.5800 (5.7381)  loss_box_reg: 0.2392 (0.2326)  loss_objectness: 0.1533 (0.1553)  loss_rpn_box_reg: 0.0740 (0.0778)  time: 0.6464  data: 0.1410  max mem: 10593\n",
      "Training Epoch: [5]  [360/500]  eta: 0:01:27  lr: 0.000500  loss: 6.0490 (6.2039)  loss_classifier: 5.5698 (5.7379)  loss_box_reg: 0.2409 (0.2323)  loss_objectness: 0.1675 (0.1559)  loss_rpn_box_reg: 0.0829 (0.0777)  time: 0.6389  data: 0.1446  max mem: 10593\n",
      "Training Epoch: [5]  [370/500]  eta: 0:01:21  lr: 0.000500  loss: 6.1109 (6.2022)  loss_classifier: 5.5698 (5.7346)  loss_box_reg: 0.2348 (0.2332)  loss_objectness: 0.1677 (0.1565)  loss_rpn_box_reg: 0.0776 (0.0779)  time: 0.6309  data: 0.1439  max mem: 10593\n",
      "Training Epoch: [5]  [380/500]  eta: 0:01:15  lr: 0.000500  loss: 6.2310 (6.2072)  loss_classifier: 5.6985 (5.7387)  loss_box_reg: 0.2411 (0.2331)  loss_objectness: 0.1696 (0.1569)  loss_rpn_box_reg: 0.0899 (0.0784)  time: 0.6305  data: 0.1397  max mem: 10593\n",
      "Training Epoch: [5]  [390/500]  eta: 0:01:08  lr: 0.000500  loss: 6.3310 (6.2091)  loss_classifier: 5.7584 (5.7415)  loss_box_reg: 0.2100 (0.2329)  loss_objectness: 0.1417 (0.1564)  loss_rpn_box_reg: 0.0775 (0.0782)  time: 0.6222  data: 0.1370  max mem: 10593\n",
      "Training Epoch: [5]  [400/500]  eta: 0:01:02  lr: 0.000500  loss: 6.0801 (6.2046)  loss_classifier: 5.6530 (5.7375)  loss_box_reg: 0.2074 (0.2329)  loss_objectness: 0.1337 (0.1561)  loss_rpn_box_reg: 0.0731 (0.0781)  time: 0.6088  data: 0.1347  max mem: 10593\n",
      "Training Epoch: [5]  [410/500]  eta: 0:00:56  lr: 0.000500  loss: 6.1512 (6.2070)  loss_classifier: 5.6571 (5.7408)  loss_box_reg: 0.2031 (0.2319)  loss_objectness: 0.1415 (0.1561)  loss_rpn_box_reg: 0.0607 (0.0781)  time: 0.6197  data: 0.1353  max mem: 10593\n",
      "Training Epoch: [5]  [420/500]  eta: 0:00:50  lr: 0.000500  loss: 6.2484 (6.2047)  loss_classifier: 5.6856 (5.7381)  loss_box_reg: 0.2238 (0.2320)  loss_objectness: 0.1585 (0.1563)  loss_rpn_box_reg: 0.0769 (0.0783)  time: 0.6238  data: 0.1385  max mem: 10593\n",
      "Training Epoch: [5]  [430/500]  eta: 0:00:43  lr: 0.000500  loss: 6.0847 (6.2027)  loss_classifier: 5.6742 (5.7353)  loss_box_reg: 0.2417 (0.2327)  loss_objectness: 0.1640 (0.1564)  loss_rpn_box_reg: 0.0784 (0.0783)  time: 0.6100  data: 0.1394  max mem: 10593\n",
      "Training Epoch: [5]  [440/500]  eta: 0:00:37  lr: 0.000500  loss: 6.1402 (6.2077)  loss_classifier: 5.6968 (5.7391)  loss_box_reg: 0.2531 (0.2333)  loss_objectness: 0.1640 (0.1568)  loss_rpn_box_reg: 0.0871 (0.0785)  time: 0.6159  data: 0.1400  max mem: 10593\n",
      "Training Epoch: [5]  [450/500]  eta: 0:00:31  lr: 0.000500  loss: 6.3002 (6.2113)  loss_classifier: 5.8554 (5.7423)  loss_box_reg: 0.2499 (0.2334)  loss_objectness: 0.1479 (0.1569)  loss_rpn_box_reg: 0.0911 (0.0787)  time: 0.6225  data: 0.1395  max mem: 10593\n",
      "Training Epoch: [5]  [460/500]  eta: 0:00:25  lr: 0.000500  loss: 6.2718 (6.2117)  loss_classifier: 5.8339 (5.7442)  loss_box_reg: 0.2099 (0.2326)  loss_objectness: 0.1410 (0.1565)  loss_rpn_box_reg: 0.0559 (0.0785)  time: 0.6286  data: 0.1378  max mem: 10593\n",
      "Training Epoch: [5]  [470/500]  eta: 0:00:18  lr: 0.000500  loss: 6.0944 (6.2096)  loss_classifier: 5.6992 (5.7419)  loss_box_reg: 0.2018 (0.2323)  loss_objectness: 0.1381 (0.1565)  loss_rpn_box_reg: 0.0650 (0.0789)  time: 0.6359  data: 0.1382  max mem: 10593\n",
      "Training Epoch: [5]  [480/500]  eta: 0:00:12  lr: 0.000500  loss: 6.2767 (6.2125)  loss_classifier: 5.7502 (5.7452)  loss_box_reg: 0.2150 (0.2323)  loss_objectness: 0.1404 (0.1562)  loss_rpn_box_reg: 0.0774 (0.0787)  time: 0.6337  data: 0.1367  max mem: 10593\n",
      "Training Epoch: [5]  [490/500]  eta: 0:00:06  lr: 0.000500  loss: 6.3288 (6.2139)  loss_classifier: 5.8974 (5.7463)  loss_box_reg: 0.2232 (0.2328)  loss_objectness: 0.1412 (0.1562)  loss_rpn_box_reg: 0.0726 (0.0787)  time: 0.6157  data: 0.1353  max mem: 10593\n",
      "Training Epoch: [5]  [499/500]  eta: 0:00:00  lr: 0.000500  loss: 6.0940 (6.2111)  loss_classifier: 5.5844 (5.7430)  loss_box_reg: 0.2562 (0.2334)  loss_objectness: 0.1490 (0.1559)  loss_rpn_box_reg: 0.0726 (0.0788)  time: 0.6287  data: 0.1381  max mem: 10593\n",
      "Training Epoch: [5] Total time: 0:05:12 (0.6257 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:00  model_time: 0.7782 (0.7782)  evaluator_time: 0.0340 (0.0340)  time: 0.9672  data: 0.1460  max mem: 10593\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4161 (0.4361)  evaluator_time: 0.0340 (0.0370)  time: 0.6117  data: 0.1434  max mem: 10593\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4521 (0.4375)  evaluator_time: 0.0350 (0.0373)  time: 0.6377  data: 0.1506  max mem: 10593\n",
      "Test: Total time: 0:01:18 (0.6284 s / it)\n",
      "Averaged stats: model_time: 0.4521 (0.4375)  evaluator_time: 0.0350 (0.0373)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.101\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.173\n",
      "Testing Epoch: [5]  [  0/125]  eta: 0:01:20  lr: 0.000500  loss: 6.1942 (6.1942)  loss_classifier: 5.6690 (5.6690)  loss_box_reg: 0.2695 (0.2695)  loss_objectness: 0.1250 (0.1250)  loss_rpn_box_reg: 0.1308 (0.1308)  time: 0.6441  data: 0.1470  max mem: 10593\n",
      "Testing Epoch: [5]  [100/125]  eta: 0:00:14  lr: 0.000500  loss: 5.9761 (6.1242)  loss_classifier: 5.4186 (5.6170)  loss_box_reg: 0.2604 (0.2844)  loss_objectness: 0.1269 (0.1333)  loss_rpn_box_reg: 0.0715 (0.0895)  time: 0.5909  data: 0.1482  max mem: 10593\n",
      "Testing Epoch: [5]  [124/125]  eta: 0:00:00  lr: 0.000500  loss: 6.1655 (6.1578)  loss_classifier: 5.7064 (5.6551)  loss_box_reg: 0.2304 (0.2798)  loss_objectness: 0.1187 (0.1331)  loss_rpn_box_reg: 0.0742 (0.0897)  time: 0.5974  data: 0.1495  max mem: 10593\n",
      "Testing Epoch: [5] Total time: 0:01:14 (0.5986 s / it)\n",
      "Training Epoch: [6]  [  0/500]  eta: 0:05:13  lr: 0.000500  loss: 5.9679 (5.9679)  loss_classifier: 5.6070 (5.6070)  loss_box_reg: 0.2135 (0.2135)  loss_objectness: 0.1028 (0.1028)  loss_rpn_box_reg: 0.0446 (0.0446)  time: 0.6271  data: 0.1370  max mem: 10593\n",
      "Training Epoch: [6]  [ 10/500]  eta: 0:05:04  lr: 0.000500  loss: 6.0421 (6.1649)  loss_classifier: 5.6070 (5.7330)  loss_box_reg: 0.2381 (0.2409)  loss_objectness: 0.1235 (0.1216)  loss_rpn_box_reg: 0.0695 (0.0693)  time: 0.6208  data: 0.1323  max mem: 10593\n",
      "Training Epoch: [6]  [ 20/500]  eta: 0:04:55  lr: 0.000500  loss: 6.1354 (6.1276)  loss_classifier: 5.6225 (5.6776)  loss_box_reg: 0.2381 (0.2419)  loss_objectness: 0.1253 (0.1372)  loss_rpn_box_reg: 0.0696 (0.0709)  time: 0.6161  data: 0.1327  max mem: 10593\n",
      "Training Epoch: [6]  [ 30/500]  eta: 0:04:51  lr: 0.000500  loss: 6.3079 (6.2186)  loss_classifier: 5.6605 (5.7605)  loss_box_reg: 0.2289 (0.2423)  loss_objectness: 0.1419 (0.1397)  loss_rpn_box_reg: 0.0715 (0.0761)  time: 0.6204  data: 0.1354  max mem: 10593\n",
      "Training Epoch: [6]  [ 40/500]  eta: 0:04:44  lr: 0.000500  loss: 6.3920 (6.2881)  loss_classifier: 5.8559 (5.8251)  loss_box_reg: 0.2289 (0.2376)  loss_objectness: 0.1482 (0.1502)  loss_rpn_box_reg: 0.0695 (0.0752)  time: 0.6209  data: 0.1366  max mem: 10593\n",
      "Training Epoch: [6]  [ 50/500]  eta: 0:04:37  lr: 0.000500  loss: 5.9181 (6.2415)  loss_classifier: 5.4865 (5.7687)  loss_box_reg: 0.2400 (0.2448)  loss_objectness: 0.1602 (0.1488)  loss_rpn_box_reg: 0.0712 (0.0791)  time: 0.6123  data: 0.1341  max mem: 10593\n",
      "Training Epoch: [6]  [ 60/500]  eta: 0:04:31  lr: 0.000500  loss: 6.0196 (6.2572)  loss_classifier: 5.6230 (5.7870)  loss_box_reg: 0.2461 (0.2430)  loss_objectness: 0.1287 (0.1478)  loss_rpn_box_reg: 0.0758 (0.0794)  time: 0.6144  data: 0.1318  max mem: 10593\n",
      "Training Epoch: [6]  [ 70/500]  eta: 0:04:25  lr: 0.000500  loss: 6.3759 (6.2870)  loss_classifier: 5.9013 (5.8176)  loss_box_reg: 0.2350 (0.2399)  loss_objectness: 0.1480 (0.1513)  loss_rpn_box_reg: 0.0629 (0.0781)  time: 0.6193  data: 0.1357  max mem: 10593\n",
      "Training Epoch: [6]  [ 80/500]  eta: 0:04:19  lr: 0.000500  loss: 6.3017 (6.2500)  loss_classifier: 5.8404 (5.7796)  loss_box_reg: 0.2299 (0.2388)  loss_objectness: 0.1684 (0.1517)  loss_rpn_box_reg: 0.0804 (0.0799)  time: 0.6162  data: 0.1382  max mem: 10593\n",
      "Training Epoch: [6]  [ 90/500]  eta: 0:04:13  lr: 0.000500  loss: 6.0241 (6.2352)  loss_classifier: 5.5011 (5.7591)  loss_box_reg: 0.2563 (0.2414)  loss_objectness: 0.1585 (0.1527)  loss_rpn_box_reg: 0.0832 (0.0819)  time: 0.6177  data: 0.1381  max mem: 10593\n",
      "Training Epoch: [6]  [100/500]  eta: 0:04:07  lr: 0.000500  loss: 5.9772 (6.2175)  loss_classifier: 5.5011 (5.7407)  loss_box_reg: 0.2608 (0.2413)  loss_objectness: 0.1589 (0.1540)  loss_rpn_box_reg: 0.0843 (0.0815)  time: 0.6245  data: 0.1363  max mem: 10593\n",
      "Training Epoch: [6]  [110/500]  eta: 0:04:00  lr: 0.000500  loss: 6.1858 (6.2254)  loss_classifier: 5.7563 (5.7498)  loss_box_reg: 0.2388 (0.2401)  loss_objectness: 0.1579 (0.1538)  loss_rpn_box_reg: 0.0718 (0.0817)  time: 0.6163  data: 0.1334  max mem: 10593\n",
      "Training Epoch: [6]  [120/500]  eta: 0:03:55  lr: 0.000500  loss: 6.2170 (6.2116)  loss_classifier: 5.7611 (5.7364)  loss_box_reg: 0.2388 (0.2426)  loss_objectness: 0.1350 (0.1522)  loss_rpn_box_reg: 0.0631 (0.0804)  time: 0.6280  data: 0.1332  max mem: 10593\n",
      "Training Epoch: [6]  [130/500]  eta: 0:03:49  lr: 0.000500  loss: 5.9608 (6.1956)  loss_classifier: 5.4892 (5.7200)  loss_box_reg: 0.2368 (0.2427)  loss_objectness: 0.1442 (0.1524)  loss_rpn_box_reg: 0.0679 (0.0805)  time: 0.6322  data: 0.1349  max mem: 10593\n",
      "Training Epoch: [6]  [140/500]  eta: 0:03:42  lr: 0.000500  loss: 5.9885 (6.1969)  loss_classifier: 5.5491 (5.7216)  loss_box_reg: 0.2297 (0.2421)  loss_objectness: 0.1605 (0.1526)  loss_rpn_box_reg: 0.0684 (0.0806)  time: 0.6135  data: 0.1357  max mem: 10593\n",
      "Training Epoch: [6]  [150/500]  eta: 0:03:36  lr: 0.000500  loss: 6.0249 (6.1937)  loss_classifier: 5.5913 (5.7205)  loss_box_reg: 0.2206 (0.2405)  loss_objectness: 0.1503 (0.1529)  loss_rpn_box_reg: 0.0606 (0.0798)  time: 0.6165  data: 0.1334  max mem: 10593\n",
      "Training Epoch: [6]  [160/500]  eta: 0:03:30  lr: 0.000500  loss: 6.1936 (6.1984)  loss_classifier: 5.7542 (5.7231)  loss_box_reg: 0.2211 (0.2420)  loss_objectness: 0.1488 (0.1532)  loss_rpn_box_reg: 0.0708 (0.0801)  time: 0.6221  data: 0.1337  max mem: 10593\n",
      "Training Epoch: [6]  [170/500]  eta: 0:03:24  lr: 0.000500  loss: 6.1936 (6.1970)  loss_classifier: 5.7542 (5.7247)  loss_box_reg: 0.2239 (0.2398)  loss_objectness: 0.1488 (0.1529)  loss_rpn_box_reg: 0.0708 (0.0795)  time: 0.6292  data: 0.1361  max mem: 10593\n",
      "Training Epoch: [6]  [180/500]  eta: 0:03:18  lr: 0.000500  loss: 5.9957 (6.1918)  loss_classifier: 5.5711 (5.7182)  loss_box_reg: 0.2239 (0.2399)  loss_objectness: 0.1553 (0.1534)  loss_rpn_box_reg: 0.0785 (0.0803)  time: 0.6392  data: 0.1379  max mem: 10593\n",
      "Training Epoch: [6]  [190/500]  eta: 0:03:12  lr: 0.000500  loss: 6.1127 (6.1915)  loss_classifier: 5.6387 (5.7192)  loss_box_reg: 0.2282 (0.2388)  loss_objectness: 0.1531 (0.1536)  loss_rpn_box_reg: 0.0691 (0.0799)  time: 0.6217  data: 0.1361  max mem: 10593\n",
      "Training Epoch: [6]  [200/500]  eta: 0:03:06  lr: 0.000500  loss: 5.8510 (6.1757)  loss_classifier: 5.3956 (5.7037)  loss_box_reg: 0.2171 (0.2394)  loss_objectness: 0.1445 (0.1538)  loss_rpn_box_reg: 0.0502 (0.0788)  time: 0.6078  data: 0.1350  max mem: 10593\n",
      "Training Epoch: [6]  [210/500]  eta: 0:02:59  lr: 0.000500  loss: 6.0575 (6.1856)  loss_classifier: 5.4987 (5.7126)  loss_box_reg: 0.2213 (0.2398)  loss_objectness: 0.1445 (0.1541)  loss_rpn_box_reg: 0.0567 (0.0791)  time: 0.6107  data: 0.1358  max mem: 10593\n",
      "Training Epoch: [6]  [220/500]  eta: 0:02:53  lr: 0.000500  loss: 6.3431 (6.1959)  loss_classifier: 5.8334 (5.7212)  loss_box_reg: 0.2594 (0.2404)  loss_objectness: 0.1566 (0.1551)  loss_rpn_box_reg: 0.0850 (0.0792)  time: 0.6167  data: 0.1371  max mem: 10593\n",
      "Training Epoch: [6]  [230/500]  eta: 0:02:47  lr: 0.000500  loss: 6.3638 (6.2060)  loss_classifier: 5.8450 (5.7318)  loss_box_reg: 0.2431 (0.2404)  loss_objectness: 0.1566 (0.1545)  loss_rpn_box_reg: 0.0704 (0.0793)  time: 0.6241  data: 0.1373  max mem: 10593\n",
      "Training Epoch: [6]  [240/500]  eta: 0:02:41  lr: 0.000500  loss: 6.3228 (6.2089)  loss_classifier: 5.8869 (5.7363)  loss_box_reg: 0.2151 (0.2395)  loss_objectness: 0.1422 (0.1545)  loss_rpn_box_reg: 0.0645 (0.0786)  time: 0.6209  data: 0.1359  max mem: 10593\n",
      "Training Epoch: [6]  [250/500]  eta: 0:02:35  lr: 0.000500  loss: 6.2073 (6.2084)  loss_classifier: 5.7466 (5.7346)  loss_box_reg: 0.2279 (0.2402)  loss_objectness: 0.1467 (0.1544)  loss_rpn_box_reg: 0.0765 (0.0792)  time: 0.6265  data: 0.1354  max mem: 10593\n",
      "Training Epoch: [6]  [260/500]  eta: 0:02:28  lr: 0.000500  loss: 6.2073 (6.2099)  loss_classifier: 5.7466 (5.7384)  loss_box_reg: 0.2244 (0.2383)  loss_objectness: 0.1478 (0.1542)  loss_rpn_box_reg: 0.0804 (0.0791)  time: 0.6254  data: 0.1337  max mem: 10593\n",
      "Training Epoch: [6]  [270/500]  eta: 0:02:22  lr: 0.000500  loss: 6.1797 (6.2032)  loss_classifier: 5.7545 (5.7326)  loss_box_reg: 0.2085 (0.2379)  loss_objectness: 0.1437 (0.1537)  loss_rpn_box_reg: 0.0666 (0.0791)  time: 0.6257  data: 0.1338  max mem: 10593\n",
      "Training Epoch: [6]  [280/500]  eta: 0:02:16  lr: 0.000500  loss: 6.2161 (6.2024)  loss_classifier: 5.7545 (5.7325)  loss_box_reg: 0.2027 (0.2368)  loss_objectness: 0.1522 (0.1539)  loss_rpn_box_reg: 0.0756 (0.0792)  time: 0.6218  data: 0.1354  max mem: 10593\n",
      "Training Epoch: [6]  [290/500]  eta: 0:02:10  lr: 0.000500  loss: 6.3106 (6.2022)  loss_classifier: 5.7797 (5.7320)  loss_box_reg: 0.2214 (0.2373)  loss_objectness: 0.1603 (0.1540)  loss_rpn_box_reg: 0.0821 (0.0790)  time: 0.6072  data: 0.1349  max mem: 10593\n",
      "Training Epoch: [6]  [300/500]  eta: 0:02:04  lr: 0.000500  loss: 6.3074 (6.2005)  loss_classifier: 5.7163 (5.7303)  loss_box_reg: 0.2340 (0.2375)  loss_objectness: 0.1550 (0.1540)  loss_rpn_box_reg: 0.0579 (0.0787)  time: 0.6199  data: 0.1357  max mem: 10593\n",
      "Training Epoch: [6]  [310/500]  eta: 0:01:57  lr: 0.000500  loss: 6.2022 (6.2055)  loss_classifier: 5.7470 (5.7345)  loss_box_reg: 0.2379 (0.2376)  loss_objectness: 0.1556 (0.1545)  loss_rpn_box_reg: 0.0700 (0.0788)  time: 0.6239  data: 0.1362  max mem: 10593\n",
      "Training Epoch: [6]  [320/500]  eta: 0:01:51  lr: 0.000500  loss: 6.2022 (6.2073)  loss_classifier: 5.7470 (5.7360)  loss_box_reg: 0.2457 (0.2385)  loss_objectness: 0.1610 (0.1542)  loss_rpn_box_reg: 0.0700 (0.0786)  time: 0.6208  data: 0.1355  max mem: 10593\n",
      "Training Epoch: [6]  [330/500]  eta: 0:01:45  lr: 0.000500  loss: 6.2122 (6.2054)  loss_classifier: 5.6989 (5.7350)  loss_box_reg: 0.2184 (0.2377)  loss_objectness: 0.1521 (0.1545)  loss_rpn_box_reg: 0.0622 (0.0782)  time: 0.6311  data: 0.1363  max mem: 10593\n",
      "Training Epoch: [6]  [340/500]  eta: 0:01:39  lr: 0.000500  loss: 6.2315 (6.2103)  loss_classifier: 5.8126 (5.7408)  loss_box_reg: 0.1994 (0.2369)  loss_objectness: 0.1506 (0.1545)  loss_rpn_box_reg: 0.0686 (0.0782)  time: 0.6271  data: 0.1370  max mem: 10593\n",
      "Training Epoch: [6]  [350/500]  eta: 0:01:33  lr: 0.000500  loss: 6.2106 (6.2079)  loss_classifier: 5.8102 (5.7387)  loss_box_reg: 0.1980 (0.2360)  loss_objectness: 0.1402 (0.1550)  loss_rpn_box_reg: 0.0727 (0.0781)  time: 0.6194  data: 0.1363  max mem: 10593\n",
      "Training Epoch: [6]  [360/500]  eta: 0:01:26  lr: 0.000500  loss: 6.2343 (6.2160)  loss_classifier: 5.8102 (5.7463)  loss_box_reg: 0.2446 (0.2365)  loss_objectness: 0.1402 (0.1548)  loss_rpn_box_reg: 0.0693 (0.0784)  time: 0.6270  data: 0.1371  max mem: 10593\n",
      "Training Epoch: [6]  [370/500]  eta: 0:01:20  lr: 0.000500  loss: 6.3891 (6.2185)  loss_classifier: 5.9196 (5.7485)  loss_box_reg: 0.2652 (0.2373)  loss_objectness: 0.1260 (0.1542)  loss_rpn_box_reg: 0.0749 (0.0785)  time: 0.6302  data: 0.1381  max mem: 10593\n",
      "Training Epoch: [6]  [380/500]  eta: 0:01:14  lr: 0.000500  loss: 6.3292 (6.2230)  loss_classifier: 5.8394 (5.7522)  loss_box_reg: 0.2692 (0.2373)  loss_objectness: 0.1440 (0.1550)  loss_rpn_box_reg: 0.0790 (0.0785)  time: 0.6321  data: 0.1389  max mem: 10593\n",
      "Training Epoch: [6]  [390/500]  eta: 0:01:08  lr: 0.000500  loss: 6.1636 (6.2208)  loss_classifier: 5.6466 (5.7503)  loss_box_reg: 0.2297 (0.2373)  loss_objectness: 0.1757 (0.1549)  loss_rpn_box_reg: 0.0674 (0.0783)  time: 0.6400  data: 0.1391  max mem: 10593\n",
      "Training Epoch: [6]  [400/500]  eta: 0:01:02  lr: 0.000500  loss: 6.1012 (6.2176)  loss_classifier: 5.6466 (5.7471)  loss_box_reg: 0.2295 (0.2370)  loss_objectness: 0.1494 (0.1551)  loss_rpn_box_reg: 0.0649 (0.0784)  time: 0.6340  data: 0.1364  max mem: 10593\n",
      "Training Epoch: [6]  [410/500]  eta: 0:00:56  lr: 0.000500  loss: 6.0824 (6.2144)  loss_classifier: 5.6170 (5.7439)  loss_box_reg: 0.2277 (0.2371)  loss_objectness: 0.1467 (0.1548)  loss_rpn_box_reg: 0.0746 (0.0786)  time: 0.6268  data: 0.1345  max mem: 10593\n",
      "Training Epoch: [6]  [420/500]  eta: 0:00:49  lr: 0.000500  loss: 5.8799 (6.2059)  loss_classifier: 5.5309 (5.7368)  loss_box_reg: 0.2243 (0.2367)  loss_objectness: 0.1356 (0.1544)  loss_rpn_box_reg: 0.0621 (0.0781)  time: 0.6267  data: 0.1338  max mem: 10593\n",
      "Training Epoch: [6]  [430/500]  eta: 0:00:43  lr: 0.000500  loss: 5.9595 (6.2083)  loss_classifier: 5.5309 (5.7396)  loss_box_reg: 0.2075 (0.2363)  loss_objectness: 0.1371 (0.1545)  loss_rpn_box_reg: 0.0583 (0.0779)  time: 0.6115  data: 0.1361  max mem: 10593\n",
      "Training Epoch: [6]  [440/500]  eta: 0:00:37  lr: 0.000500  loss: 6.2866 (6.2111)  loss_classifier: 5.8494 (5.7422)  loss_box_reg: 0.2292 (0.2370)  loss_objectness: 0.1524 (0.1542)  loss_rpn_box_reg: 0.0729 (0.0777)  time: 0.6093  data: 0.1373  max mem: 10593\n",
      "Training Epoch: [6]  [450/500]  eta: 0:00:31  lr: 0.000500  loss: 6.2866 (6.2158)  loss_classifier: 5.7345 (5.7470)  loss_box_reg: 0.2392 (0.2369)  loss_objectness: 0.1385 (0.1541)  loss_rpn_box_reg: 0.0742 (0.0778)  time: 0.6235  data: 0.1344  max mem: 10593\n",
      "Training Epoch: [6]  [460/500]  eta: 0:00:24  lr: 0.000500  loss: 6.3000 (6.2184)  loss_classifier: 5.7777 (5.7496)  loss_box_reg: 0.2358 (0.2366)  loss_objectness: 0.1530 (0.1543)  loss_rpn_box_reg: 0.0714 (0.0779)  time: 0.6168  data: 0.1327  max mem: 10593\n",
      "Training Epoch: [6]  [470/500]  eta: 0:00:18  lr: 0.000500  loss: 6.2534 (6.2152)  loss_classifier: 5.7758 (5.7450)  loss_box_reg: 0.2591 (0.2373)  loss_objectness: 0.1658 (0.1546)  loss_rpn_box_reg: 0.0832 (0.0784)  time: 0.6203  data: 0.1352  max mem: 10593\n",
      "Training Epoch: [6]  [480/500]  eta: 0:00:12  lr: 0.000500  loss: 6.2101 (6.2146)  loss_classifier: 5.7266 (5.7451)  loss_box_reg: 0.2616 (0.2370)  loss_objectness: 0.1536 (0.1542)  loss_rpn_box_reg: 0.0797 (0.0784)  time: 0.6328  data: 0.1350  max mem: 10593\n",
      "Training Epoch: [6]  [490/500]  eta: 0:00:06  lr: 0.000500  loss: 6.3657 (6.2189)  loss_classifier: 5.8943 (5.7501)  loss_box_reg: 0.2006 (0.2366)  loss_objectness: 0.1427 (0.1542)  loss_rpn_box_reg: 0.0646 (0.0780)  time: 0.6346  data: 0.1348  max mem: 10593\n",
      "Training Epoch: [6]  [499/500]  eta: 0:00:00  lr: 0.000500  loss: 6.1526 (6.2157)  loss_classifier: 5.7266 (5.7466)  loss_box_reg: 0.2162 (0.2366)  loss_objectness: 0.1536 (0.1543)  loss_rpn_box_reg: 0.0709 (0.0783)  time: 0.6234  data: 0.1356  max mem: 10593\n",
      "Training Epoch: [6] Total time: 0:05:11 (0.6223 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:51  model_time: 0.7082 (0.7082)  evaluator_time: 0.0340 (0.0340)  time: 0.8926  data: 0.1414  max mem: 10593\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4311 (0.4401)  evaluator_time: 0.0340 (0.0349)  time: 0.6250  data: 0.1481  max mem: 10593\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4551 (0.4415)  evaluator_time: 0.0350 (0.0356)  time: 0.6402  data: 0.1486  max mem: 10593\n",
      "Test: Total time: 0:01:18 (0.6308 s / it)\n",
      "Averaged stats: model_time: 0.4551 (0.4415)  evaluator_time: 0.0350 (0.0356)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n",
      "Testing Epoch: [6]  [  0/125]  eta: 0:01:20  lr: 0.000500  loss: 6.2038 (6.2038)  loss_classifier: 5.6559 (5.6559)  loss_box_reg: 0.2926 (0.2926)  loss_objectness: 0.1215 (0.1215)  loss_rpn_box_reg: 0.1339 (0.1339)  time: 0.6411  data: 0.1440  max mem: 10593\n",
      "Testing Epoch: [6]  [100/125]  eta: 0:00:14  lr: 0.000500  loss: 5.9848 (6.1218)  loss_classifier: 5.4082 (5.6109)  loss_box_reg: 0.2624 (0.2883)  loss_objectness: 0.1292 (0.1333)  loss_rpn_box_reg: 0.0737 (0.0894)  time: 0.5833  data: 0.1470  max mem: 10593\n",
      "Testing Epoch: [6]  [124/125]  eta: 0:00:00  lr: 0.000500  loss: 6.1588 (6.1554)  loss_classifier: 5.6963 (5.6490)  loss_box_reg: 0.2392 (0.2837)  loss_objectness: 0.1218 (0.1331)  loss_rpn_box_reg: 0.0734 (0.0896)  time: 0.5953  data: 0.1462  max mem: 10593\n",
      "Testing Epoch: [6] Total time: 0:01:14 (0.5937 s / it)\n",
      "Training Epoch: [7]  [  0/500]  eta: 0:04:52  lr: 0.000500  loss: 6.6654 (6.6654)  loss_classifier: 6.2489 (6.2489)  loss_box_reg: 0.1716 (0.1716)  loss_objectness: 0.1405 (0.1405)  loss_rpn_box_reg: 0.1045 (0.1045)  time: 0.5851  data: 0.1360  max mem: 10593\n",
      "Training Epoch: [7]  [ 10/500]  eta: 0:05:02  lr: 0.000500  loss: 6.2747 (6.2018)  loss_classifier: 5.9393 (5.6968)  loss_box_reg: 0.2853 (0.2756)  loss_objectness: 0.1354 (0.1434)  loss_rpn_box_reg: 0.0938 (0.0860)  time: 0.6179  data: 0.1308  max mem: 10593\n",
      "Training Epoch: [7]  [ 20/500]  eta: 0:04:58  lr: 0.000500  loss: 6.0528 (6.1272)  loss_classifier: 5.4556 (5.6203)  loss_box_reg: 0.2763 (0.2674)  loss_objectness: 0.1437 (0.1533)  loss_rpn_box_reg: 0.0858 (0.0863)  time: 0.6241  data: 0.1334  max mem: 10593\n",
      "Training Epoch: [7]  [ 30/500]  eta: 0:04:50  lr: 0.000500  loss: 6.0556 (6.1612)  loss_classifier: 5.5216 (5.6779)  loss_box_reg: 0.2397 (0.2520)  loss_objectness: 0.1548 (0.1494)  loss_rpn_box_reg: 0.0839 (0.0819)  time: 0.6189  data: 0.1344  max mem: 10593\n",
      "Training Epoch: [7]  [ 40/500]  eta: 0:04:45  lr: 0.000500  loss: 6.1540 (6.1637)  loss_classifier: 5.7892 (5.6963)  loss_box_reg: 0.1941 (0.2392)  loss_objectness: 0.1322 (0.1475)  loss_rpn_box_reg: 0.0644 (0.0807)  time: 0.6172  data: 0.1318  max mem: 10593\n",
      "Training Epoch: [7]  [ 50/500]  eta: 0:04:38  lr: 0.000500  loss: 6.1743 (6.1584)  loss_classifier: 5.7892 (5.6963)  loss_box_reg: 0.1885 (0.2324)  loss_objectness: 0.1322 (0.1481)  loss_rpn_box_reg: 0.0644 (0.0816)  time: 0.6214  data: 0.1319  max mem: 10593\n",
      "Training Epoch: [7]  [ 60/500]  eta: 0:04:34  lr: 0.000500  loss: 6.1877 (6.1839)  loss_classifier: 5.7684 (5.7217)  loss_box_reg: 0.2148 (0.2354)  loss_objectness: 0.1459 (0.1480)  loss_rpn_box_reg: 0.0618 (0.0788)  time: 0.6343  data: 0.1326  max mem: 10593\n",
      "Training Epoch: [7]  [ 70/500]  eta: 0:04:29  lr: 0.000500  loss: 6.1113 (6.1711)  loss_classifier: 5.6189 (5.7038)  loss_box_reg: 0.2230 (0.2347)  loss_objectness: 0.1577 (0.1510)  loss_rpn_box_reg: 0.0641 (0.0816)  time: 0.6435  data: 0.1330  max mem: 10593\n",
      "Training Epoch: [7]  [ 80/500]  eta: 0:04:22  lr: 0.000500  loss: 6.0453 (6.2011)  loss_classifier: 5.5828 (5.7338)  loss_box_reg: 0.2325 (0.2346)  loss_objectness: 0.1577 (0.1517)  loss_rpn_box_reg: 0.0746 (0.0810)  time: 0.6254  data: 0.1325  max mem: 10593\n",
      "Training Epoch: [7]  [ 90/500]  eta: 0:04:15  lr: 0.000500  loss: 6.1807 (6.2041)  loss_classifier: 5.7552 (5.7383)  loss_box_reg: 0.2363 (0.2339)  loss_objectness: 0.1487 (0.1527)  loss_rpn_box_reg: 0.0693 (0.0792)  time: 0.6156  data: 0.1319  max mem: 10593\n",
      "Training Epoch: [7]  [100/500]  eta: 0:04:08  lr: 0.000500  loss: 6.1471 (6.2021)  loss_classifier: 5.6617 (5.7364)  loss_box_reg: 0.2396 (0.2341)  loss_objectness: 0.1477 (0.1531)  loss_rpn_box_reg: 0.0693 (0.0784)  time: 0.6095  data: 0.1342  max mem: 10593\n",
      "Training Epoch: [7]  [110/500]  eta: 0:04:02  lr: 0.000500  loss: 5.9947 (6.1792)  loss_classifier: 5.5582 (5.7058)  loss_box_reg: 0.2722 (0.2405)  loss_objectness: 0.1567 (0.1535)  loss_rpn_box_reg: 0.0790 (0.0794)  time: 0.6090  data: 0.1342  max mem: 10593\n",
      "Training Epoch: [7]  [120/500]  eta: 0:03:56  lr: 0.000500  loss: 5.9488 (6.1751)  loss_classifier: 5.5620 (5.7001)  loss_box_reg: 0.2722 (0.2408)  loss_objectness: 0.1638 (0.1539)  loss_rpn_box_reg: 0.0795 (0.0802)  time: 0.6235  data: 0.1331  max mem: 10593\n",
      "Training Epoch: [7]  [130/500]  eta: 0:03:49  lr: 0.000500  loss: 6.1904 (6.1695)  loss_classifier: 5.6672 (5.6959)  loss_box_reg: 0.2213 (0.2398)  loss_objectness: 0.1437 (0.1537)  loss_rpn_box_reg: 0.0707 (0.0801)  time: 0.6224  data: 0.1339  max mem: 10593\n",
      "Training Epoch: [7]  [140/500]  eta: 0:03:43  lr: 0.000500  loss: 6.2068 (6.1816)  loss_classifier: 5.6745 (5.7064)  loss_box_reg: 0.2213 (0.2403)  loss_objectness: 0.1565 (0.1546)  loss_rpn_box_reg: 0.0688 (0.0804)  time: 0.6117  data: 0.1330  max mem: 10593\n",
      "Training Epoch: [7]  [150/500]  eta: 0:03:37  lr: 0.000500  loss: 6.1313 (6.1716)  loss_classifier: 5.6745 (5.6975)  loss_box_reg: 0.2376 (0.2400)  loss_objectness: 0.1541 (0.1541)  loss_rpn_box_reg: 0.0610 (0.0800)  time: 0.6172  data: 0.1330  max mem: 10593\n",
      "Training Epoch: [7]  [160/500]  eta: 0:03:31  lr: 0.000500  loss: 6.0269 (6.1699)  loss_classifier: 5.5276 (5.6963)  loss_box_reg: 0.2165 (0.2394)  loss_objectness: 0.1430 (0.1543)  loss_rpn_box_reg: 0.0645 (0.0798)  time: 0.6351  data: 0.1337  max mem: 10593\n",
      "Training Epoch: [7]  [170/500]  eta: 0:03:25  lr: 0.000500  loss: 6.0998 (6.1838)  loss_classifier: 5.5957 (5.7113)  loss_box_reg: 0.2170 (0.2396)  loss_objectness: 0.1455 (0.1542)  loss_rpn_box_reg: 0.0636 (0.0788)  time: 0.6334  data: 0.1344  max mem: 10593\n",
      "Training Epoch: [7]  [180/500]  eta: 0:03:19  lr: 0.000500  loss: 6.4382 (6.1868)  loss_classifier: 5.9827 (5.7159)  loss_box_reg: 0.2200 (0.2383)  loss_objectness: 0.1477 (0.1541)  loss_rpn_box_reg: 0.0636 (0.0785)  time: 0.6282  data: 0.1348  max mem: 10593\n",
      "Training Epoch: [7]  [190/500]  eta: 0:03:13  lr: 0.000500  loss: 6.2256 (6.1856)  loss_classifier: 5.7599 (5.7155)  loss_box_reg: 0.2200 (0.2368)  loss_objectness: 0.1525 (0.1547)  loss_rpn_box_reg: 0.0719 (0.0786)  time: 0.6340  data: 0.1352  max mem: 10593\n",
      "Training Epoch: [7]  [200/500]  eta: 0:03:06  lr: 0.000500  loss: 6.1187 (6.1820)  loss_classifier: 5.6060 (5.7131)  loss_box_reg: 0.2294 (0.2363)  loss_objectness: 0.1466 (0.1539)  loss_rpn_box_reg: 0.0719 (0.0787)  time: 0.6218  data: 0.1353  max mem: 10593\n",
      "Training Epoch: [7]  [210/500]  eta: 0:03:00  lr: 0.000500  loss: 6.1187 (6.1871)  loss_classifier: 5.6388 (5.7184)  loss_box_reg: 0.2353 (0.2368)  loss_objectness: 0.1462 (0.1540)  loss_rpn_box_reg: 0.0632 (0.0779)  time: 0.6170  data: 0.1334  max mem: 10593\n",
      "Training Epoch: [7]  [220/500]  eta: 0:02:54  lr: 0.000500  loss: 6.2350 (6.1945)  loss_classifier: 5.7596 (5.7251)  loss_box_reg: 0.2383 (0.2376)  loss_objectness: 0.1521 (0.1537)  loss_rpn_box_reg: 0.0632 (0.0780)  time: 0.6281  data: 0.1351  max mem: 10593\n",
      "Training Epoch: [7]  [230/500]  eta: 0:02:48  lr: 0.000500  loss: 6.2055 (6.1932)  loss_classifier: 5.7239 (5.7230)  loss_box_reg: 0.2609 (0.2387)  loss_objectness: 0.1465 (0.1538)  loss_rpn_box_reg: 0.0652 (0.0777)  time: 0.6202  data: 0.1374  max mem: 10593\n",
      "Training Epoch: [7]  [240/500]  eta: 0:02:41  lr: 0.000500  loss: 6.1530 (6.1966)  loss_classifier: 5.5678 (5.7257)  loss_box_reg: 0.2656 (0.2392)  loss_objectness: 0.1613 (0.1547)  loss_rpn_box_reg: 0.0652 (0.0770)  time: 0.6036  data: 0.1357  max mem: 10593\n",
      "Training Epoch: [7]  [250/500]  eta: 0:02:35  lr: 0.000500  loss: 6.1862 (6.2025)  loss_classifier: 5.6870 (5.7303)  loss_box_reg: 0.2543 (0.2398)  loss_objectness: 0.1710 (0.1549)  loss_rpn_box_reg: 0.0708 (0.0775)  time: 0.6160  data: 0.1349  max mem: 10593\n",
      "Training Epoch: [7]  [260/500]  eta: 0:02:29  lr: 0.000500  loss: 6.0851 (6.2029)  loss_classifier: 5.5709 (5.7295)  loss_box_reg: 0.2364 (0.2402)  loss_objectness: 0.1625 (0.1557)  loss_rpn_box_reg: 0.0759 (0.0774)  time: 0.6158  data: 0.1343  max mem: 10593\n",
      "Training Epoch: [7]  [270/500]  eta: 0:02:22  lr: 0.000500  loss: 6.0851 (6.2012)  loss_classifier: 5.5709 (5.7266)  loss_box_reg: 0.2385 (0.2410)  loss_objectness: 0.1728 (0.1565)  loss_rpn_box_reg: 0.0710 (0.0772)  time: 0.6037  data: 0.1354  max mem: 10593\n",
      "Training Epoch: [7]  [280/500]  eta: 0:02:16  lr: 0.000500  loss: 6.0996 (6.1960)  loss_classifier: 5.5822 (5.7211)  loss_box_reg: 0.2475 (0.2412)  loss_objectness: 0.1609 (0.1562)  loss_rpn_box_reg: 0.0688 (0.0775)  time: 0.6138  data: 0.1340  max mem: 10593\n",
      "Training Epoch: [7]  [290/500]  eta: 0:02:10  lr: 0.000500  loss: 6.0179 (6.1880)  loss_classifier: 5.4688 (5.7130)  loss_box_reg: 0.2398 (0.2412)  loss_objectness: 0.1526 (0.1564)  loss_rpn_box_reg: 0.0699 (0.0774)  time: 0.6122  data: 0.1323  max mem: 10593\n",
      "Training Epoch: [7]  [300/500]  eta: 0:02:04  lr: 0.000500  loss: 5.9574 (6.1791)  loss_classifier: 5.4733 (5.7054)  loss_box_reg: 0.2328 (0.2406)  loss_objectness: 0.1453 (0.1557)  loss_rpn_box_reg: 0.0699 (0.0774)  time: 0.6166  data: 0.1330  max mem: 10593\n",
      "Training Epoch: [7]  [310/500]  eta: 0:01:57  lr: 0.000500  loss: 5.9880 (6.1780)  loss_classifier: 5.5312 (5.7052)  loss_box_reg: 0.2109 (0.2397)  loss_objectness: 0.1427 (0.1555)  loss_rpn_box_reg: 0.0731 (0.0775)  time: 0.6249  data: 0.1330  max mem: 10593\n",
      "Training Epoch: [7]  [320/500]  eta: 0:01:51  lr: 0.000500  loss: 6.1147 (6.1765)  loss_classifier: 5.6754 (5.7036)  loss_box_reg: 0.2152 (0.2393)  loss_objectness: 0.1548 (0.1559)  loss_rpn_box_reg: 0.0852 (0.0777)  time: 0.6261  data: 0.1374  max mem: 10593\n",
      "Training Epoch: [7]  [330/500]  eta: 0:01:45  lr: 0.000500  loss: 6.1673 (6.1803)  loss_classifier: 5.6421 (5.7066)  loss_box_reg: 0.2335 (0.2398)  loss_objectness: 0.1646 (0.1562)  loss_rpn_box_reg: 0.0720 (0.0777)  time: 0.6284  data: 0.1396  max mem: 10593\n",
      "Training Epoch: [7]  [340/500]  eta: 0:01:39  lr: 0.000500  loss: 6.1455 (6.1819)  loss_classifier: 5.6421 (5.7086)  loss_box_reg: 0.2621 (0.2399)  loss_objectness: 0.1549 (0.1561)  loss_rpn_box_reg: 0.0657 (0.0773)  time: 0.6165  data: 0.1362  max mem: 10593\n",
      "Training Epoch: [7]  [350/500]  eta: 0:01:33  lr: 0.000500  loss: 6.2977 (6.1870)  loss_classifier: 5.8849 (5.7148)  loss_box_reg: 0.2274 (0.2391)  loss_objectness: 0.1429 (0.1560)  loss_rpn_box_reg: 0.0607 (0.0772)  time: 0.6180  data: 0.1338  max mem: 10593\n",
      "Training Epoch: [7]  [360/500]  eta: 0:01:26  lr: 0.000500  loss: 6.3345 (6.1889)  loss_classifier: 5.9358 (5.7177)  loss_box_reg: 0.2102 (0.2382)  loss_objectness: 0.1390 (0.1559)  loss_rpn_box_reg: 0.0674 (0.0771)  time: 0.6289  data: 0.1328  max mem: 10593\n",
      "Training Epoch: [7]  [370/500]  eta: 0:01:20  lr: 0.000500  loss: 6.3947 (6.1935)  loss_classifier: 5.9065 (5.7224)  loss_box_reg: 0.2350 (0.2386)  loss_objectness: 0.1380 (0.1555)  loss_rpn_box_reg: 0.0690 (0.0770)  time: 0.6269  data: 0.1338  max mem: 10593\n",
      "Training Epoch: [7]  [380/500]  eta: 0:01:14  lr: 0.000500  loss: 6.2364 (6.1931)  loss_classifier: 5.7151 (5.7221)  loss_box_reg: 0.2404 (0.2385)  loss_objectness: 0.1380 (0.1553)  loss_rpn_box_reg: 0.0764 (0.0772)  time: 0.6320  data: 0.1352  max mem: 10593\n",
      "Training Epoch: [7]  [390/500]  eta: 0:01:08  lr: 0.000500  loss: 6.2002 (6.2001)  loss_classifier: 5.7383 (5.7311)  loss_box_reg: 0.2175 (0.2378)  loss_objectness: 0.1276 (0.1544)  loss_rpn_box_reg: 0.0534 (0.0767)  time: 0.6360  data: 0.1331  max mem: 10593\n",
      "Training Epoch: [7]  [400/500]  eta: 0:01:02  lr: 0.000500  loss: 6.4293 (6.2064)  loss_classifier: 5.9534 (5.7380)  loss_box_reg: 0.2144 (0.2375)  loss_objectness: 0.1202 (0.1540)  loss_rpn_box_reg: 0.0636 (0.0769)  time: 0.6280  data: 0.1319  max mem: 10593\n",
      "Training Epoch: [7]  [410/500]  eta: 0:00:55  lr: 0.000500  loss: 6.3901 (6.2055)  loss_classifier: 5.9137 (5.7376)  loss_box_reg: 0.2160 (0.2375)  loss_objectness: 0.1365 (0.1537)  loss_rpn_box_reg: 0.0748 (0.0767)  time: 0.6248  data: 0.1325  max mem: 10593\n",
      "Training Epoch: [7]  [420/500]  eta: 0:00:49  lr: 0.000500  loss: 6.2174 (6.2087)  loss_classifier: 5.6615 (5.7413)  loss_box_reg: 0.2407 (0.2374)  loss_objectness: 0.1352 (0.1533)  loss_rpn_box_reg: 0.0557 (0.0767)  time: 0.6342  data: 0.1335  max mem: 10593\n",
      "Training Epoch: [7]  [430/500]  eta: 0:00:43  lr: 0.000500  loss: 6.3581 (6.2121)  loss_classifier: 5.6615 (5.7438)  loss_box_reg: 0.2444 (0.2378)  loss_objectness: 0.1319 (0.1534)  loss_rpn_box_reg: 0.0826 (0.0771)  time: 0.6287  data: 0.1348  max mem: 10593\n",
      "Training Epoch: [7]  [440/500]  eta: 0:00:37  lr: 0.000500  loss: 6.0899 (6.2156)  loss_classifier: 5.6612 (5.7476)  loss_box_reg: 0.2429 (0.2380)  loss_objectness: 0.1462 (0.1532)  loss_rpn_box_reg: 0.0812 (0.0768)  time: 0.6369  data: 0.1347  max mem: 10593\n",
      "Training Epoch: [7]  [450/500]  eta: 0:00:31  lr: 0.000500  loss: 6.0599 (6.2125)  loss_classifier: 5.6293 (5.7438)  loss_box_reg: 0.2368 (0.2380)  loss_objectness: 0.1462 (0.1535)  loss_rpn_box_reg: 0.0710 (0.0772)  time: 0.6313  data: 0.1346  max mem: 10593\n",
      "Training Epoch: [7]  [460/500]  eta: 0:00:24  lr: 0.000500  loss: 6.1321 (6.2121)  loss_classifier: 5.6472 (5.7435)  loss_box_reg: 0.2349 (0.2377)  loss_objectness: 0.1636 (0.1535)  loss_rpn_box_reg: 0.0767 (0.0773)  time: 0.6030  data: 0.1343  max mem: 10593\n",
      "Training Epoch: [7]  [470/500]  eta: 0:00:18  lr: 0.000500  loss: 6.1649 (6.2125)  loss_classifier: 5.7722 (5.7431)  loss_box_reg: 0.2389 (0.2383)  loss_objectness: 0.1636 (0.1539)  loss_rpn_box_reg: 0.0713 (0.0772)  time: 0.6001  data: 0.1347  max mem: 10593\n",
      "Training Epoch: [7]  [480/500]  eta: 0:00:12  lr: 0.000500  loss: 6.2320 (6.2127)  loss_classifier: 5.7726 (5.7433)  loss_box_reg: 0.2500 (0.2383)  loss_objectness: 0.1529 (0.1538)  loss_rpn_box_reg: 0.0712 (0.0773)  time: 0.6179  data: 0.1355  max mem: 10593\n",
      "Training Epoch: [7]  [490/500]  eta: 0:00:06  lr: 0.000500  loss: 6.3072 (6.2170)  loss_classifier: 5.7984 (5.7476)  loss_box_reg: 0.2340 (0.2384)  loss_objectness: 0.1435 (0.1537)  loss_rpn_box_reg: 0.0823 (0.0773)  time: 0.6281  data: 0.1336  max mem: 10593\n",
      "Training Epoch: [7]  [499/500]  eta: 0:00:00  lr: 0.000500  loss: 6.2347 (6.2152)  loss_classifier: 5.7133 (5.7454)  loss_box_reg: 0.2136 (0.2385)  loss_objectness: 0.1638 (0.1540)  loss_rpn_box_reg: 0.0823 (0.0774)  time: 0.6124  data: 0.1331  max mem: 10593\n",
      "Training Epoch: [7] Total time: 0:05:10 (0.6218 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:50  model_time: 0.6972 (0.6972)  evaluator_time: 0.0340 (0.0340)  time: 0.8802  data: 0.1400  max mem: 10593\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4311 (0.4380)  evaluator_time: 0.0340 (0.0364)  time: 0.6186  data: 0.1531  max mem: 10593\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4581 (0.4395)  evaluator_time: 0.0360 (0.0368)  time: 0.6380  data: 0.1474  max mem: 10593\n",
      "Test: Total time: 0:01:18 (0.6257 s / it)\n",
      "Averaged stats: model_time: 0.4581 (0.4395)  evaluator_time: 0.0360 (0.0368)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [7]  [  0/125]  eta: 0:01:20  lr: 0.000500  loss: 6.2005 (6.2005)  loss_classifier: 5.6481 (5.6481)  loss_box_reg: 0.2993 (0.2993)  loss_objectness: 0.1191 (0.1191)  loss_rpn_box_reg: 0.1340 (0.1340)  time: 0.6441  data: 0.1400  max mem: 10593\n",
      "Testing Epoch: [7]  [100/125]  eta: 0:00:14  lr: 0.000500  loss: 5.9966 (6.1269)  loss_classifier: 5.4302 (5.6131)  loss_box_reg: 0.2632 (0.2908)  loss_objectness: 0.1347 (0.1324)  loss_rpn_box_reg: 0.0733 (0.0905)  time: 0.5770  data: 0.1447  max mem: 10593\n",
      "Testing Epoch: [7]  [124/125]  eta: 0:00:00  lr: 0.000500  loss: 6.1624 (6.1604)  loss_classifier: 5.6719 (5.6513)  loss_box_reg: 0.2461 (0.2863)  loss_objectness: 0.1207 (0.1324)  loss_rpn_box_reg: 0.0743 (0.0905)  time: 0.5902  data: 0.1434  max mem: 10593\n",
      "Testing Epoch: [7] Total time: 0:01:13 (0.5883 s / it)\n",
      "Training Epoch: [8]  [  0/500]  eta: 0:05:20  lr: 0.000500  loss: 5.9117 (5.9117)  loss_classifier: 5.3019 (5.3019)  loss_box_reg: 0.3117 (0.3117)  loss_objectness: 0.2091 (0.2091)  loss_rpn_box_reg: 0.0889 (0.0889)  time: 0.6401  data: 0.1310  max mem: 10593\n",
      "Training Epoch: [8]  [ 10/500]  eta: 0:05:08  lr: 0.000500  loss: 5.9117 (6.0731)  loss_classifier: 5.4336 (5.5781)  loss_box_reg: 0.2708 (0.2690)  loss_objectness: 0.1451 (0.1480)  loss_rpn_box_reg: 0.0763 (0.0781)  time: 0.6299  data: 0.1338  max mem: 10593\n",
      "Training Epoch: [8]  [ 20/500]  eta: 0:04:55  lr: 0.000500  loss: 5.8945 (6.0682)  loss_classifier: 5.4545 (5.5836)  loss_box_reg: 0.2562 (0.2641)  loss_objectness: 0.1457 (0.1477)  loss_rpn_box_reg: 0.0674 (0.0728)  time: 0.6149  data: 0.1312  max mem: 10593\n",
      "Training Epoch: [8]  [ 30/500]  eta: 0:04:46  lr: 0.000500  loss: 6.0407 (6.1006)  loss_classifier: 5.4545 (5.6090)  loss_box_reg: 0.2514 (0.2594)  loss_objectness: 0.1569 (0.1536)  loss_rpn_box_reg: 0.0674 (0.0785)  time: 0.5999  data: 0.1312  max mem: 10593\n",
      "Training Epoch: [8]  [ 40/500]  eta: 0:04:41  lr: 0.000500  loss: 6.2613 (6.1251)  loss_classifier: 5.6992 (5.6345)  loss_box_reg: 0.2411 (0.2580)  loss_objectness: 0.1591 (0.1531)  loss_rpn_box_reg: 0.0751 (0.0795)  time: 0.6097  data: 0.1327  max mem: 10593\n",
      "Training Epoch: [8]  [ 50/500]  eta: 0:04:36  lr: 0.000500  loss: 6.3382 (6.1668)  loss_classifier: 5.7852 (5.6831)  loss_box_reg: 0.2314 (0.2523)  loss_objectness: 0.1420 (0.1525)  loss_rpn_box_reg: 0.0729 (0.0789)  time: 0.6184  data: 0.1322  max mem: 10593\n",
      "Training Epoch: [8]  [ 60/500]  eta: 0:04:32  lr: 0.000500  loss: 6.2787 (6.1740)  loss_classifier: 5.7714 (5.7036)  loss_box_reg: 0.1863 (0.2448)  loss_objectness: 0.1348 (0.1494)  loss_rpn_box_reg: 0.0596 (0.0762)  time: 0.6313  data: 0.1309  max mem: 10593\n",
      "Training Epoch: [8]  [ 70/500]  eta: 0:04:25  lr: 0.000500  loss: 6.2668 (6.1997)  loss_classifier: 5.7714 (5.7318)  loss_box_reg: 0.1877 (0.2422)  loss_objectness: 0.1387 (0.1499)  loss_rpn_box_reg: 0.0579 (0.0759)  time: 0.6308  data: 0.1323  max mem: 10593\n",
      "Training Epoch: [8]  [ 80/500]  eta: 0:04:18  lr: 0.000500  loss: 5.9466 (6.1554)  loss_classifier: 5.3946 (5.6922)  loss_box_reg: 0.2143 (0.2404)  loss_objectness: 0.1447 (0.1481)  loss_rpn_box_reg: 0.0584 (0.0746)  time: 0.6094  data: 0.1343  max mem: 10593\n",
      "Training Epoch: [8]  [ 90/500]  eta: 0:04:13  lr: 0.000500  loss: 5.7336 (6.1489)  loss_classifier: 5.3272 (5.6834)  loss_box_reg: 0.2177 (0.2407)  loss_objectness: 0.1421 (0.1489)  loss_rpn_box_reg: 0.0662 (0.0760)  time: 0.6163  data: 0.1347  max mem: 10593\n",
      "Training Epoch: [8]  [100/500]  eta: 0:04:06  lr: 0.000500  loss: 6.1201 (6.1421)  loss_classifier: 5.6986 (5.6743)  loss_box_reg: 0.2238 (0.2403)  loss_objectness: 0.1482 (0.1503)  loss_rpn_box_reg: 0.0727 (0.0771)  time: 0.6173  data: 0.1349  max mem: 10593\n",
      "Training Epoch: [8]  [110/500]  eta: 0:04:01  lr: 0.000500  loss: 6.2224 (6.1534)  loss_classifier: 5.8080 (5.6871)  loss_box_reg: 0.2113 (0.2396)  loss_objectness: 0.1442 (0.1495)  loss_rpn_box_reg: 0.0720 (0.0773)  time: 0.6185  data: 0.1326  max mem: 10593\n",
      "Training Epoch: [8]  [120/500]  eta: 0:03:55  lr: 0.000500  loss: 6.2224 (6.1526)  loss_classifier: 5.6635 (5.6820)  loss_box_reg: 0.2350 (0.2429)  loss_objectness: 0.1507 (0.1499)  loss_rpn_box_reg: 0.0801 (0.0778)  time: 0.6295  data: 0.1332  max mem: 10593\n",
      "Training Epoch: [8]  [130/500]  eta: 0:03:49  lr: 0.000500  loss: 6.0043 (6.1504)  loss_classifier: 5.6635 (5.6819)  loss_box_reg: 0.2582 (0.2423)  loss_objectness: 0.1507 (0.1498)  loss_rpn_box_reg: 0.0695 (0.0764)  time: 0.6249  data: 0.1341  max mem: 10593\n",
      "Training Epoch: [8]  [140/500]  eta: 0:03:42  lr: 0.000500  loss: 6.2003 (6.1637)  loss_classifier: 5.7413 (5.6944)  loss_box_reg: 0.2385 (0.2427)  loss_objectness: 0.1446 (0.1499)  loss_rpn_box_reg: 0.0534 (0.0766)  time: 0.6200  data: 0.1331  max mem: 10593\n",
      "Training Epoch: [8]  [150/500]  eta: 0:03:36  lr: 0.000500  loss: 6.2117 (6.1742)  loss_classifier: 5.7665 (5.7054)  loss_box_reg: 0.2191 (0.2413)  loss_objectness: 0.1446 (0.1512)  loss_rpn_box_reg: 0.0574 (0.0762)  time: 0.6156  data: 0.1327  max mem: 10593\n",
      "Training Epoch: [8]  [160/500]  eta: 0:03:29  lr: 0.000500  loss: 6.1414 (6.1723)  loss_classifier: 5.6511 (5.7044)  loss_box_reg: 0.2274 (0.2403)  loss_objectness: 0.1479 (0.1513)  loss_rpn_box_reg: 0.0719 (0.0762)  time: 0.6054  data: 0.1340  max mem: 10593\n",
      "Training Epoch: [8]  [170/500]  eta: 0:03:23  lr: 0.000500  loss: 6.1966 (6.1817)  loss_classifier: 5.7717 (5.7116)  loss_box_reg: 0.2521 (0.2429)  loss_objectness: 0.1508 (0.1515)  loss_rpn_box_reg: 0.0710 (0.0757)  time: 0.6057  data: 0.1353  max mem: 10593\n",
      "Training Epoch: [8]  [180/500]  eta: 0:03:17  lr: 0.000500  loss: 6.1452 (6.1728)  loss_classifier: 5.6824 (5.7045)  loss_box_reg: 0.2449 (0.2410)  loss_objectness: 0.1508 (0.1514)  loss_rpn_box_reg: 0.0704 (0.0759)  time: 0.6159  data: 0.1331  max mem: 10593\n",
      "Training Epoch: [8]  [190/500]  eta: 0:03:11  lr: 0.000500  loss: 6.0886 (6.1852)  loss_classifier: 5.6824 (5.7180)  loss_box_reg: 0.2058 (0.2405)  loss_objectness: 0.1378 (0.1512)  loss_rpn_box_reg: 0.0636 (0.0755)  time: 0.6268  data: 0.1320  max mem: 10593\n",
      "Training Epoch: [8]  [200/500]  eta: 0:03:05  lr: 0.000500  loss: 6.4643 (6.1973)  loss_classifier: 5.9611 (5.7275)  loss_box_reg: 0.2220 (0.2413)  loss_objectness: 0.1531 (0.1526)  loss_rpn_box_reg: 0.0652 (0.0759)  time: 0.6276  data: 0.1329  max mem: 10593\n",
      "Training Epoch: [8]  [210/500]  eta: 0:02:59  lr: 0.000500  loss: 6.3337 (6.2021)  loss_classifier: 5.8467 (5.7323)  loss_box_reg: 0.2298 (0.2415)  loss_objectness: 0.1476 (0.1519)  loss_rpn_box_reg: 0.0770 (0.0764)  time: 0.6137  data: 0.1342  max mem: 10593\n",
      "Training Epoch: [8]  [220/500]  eta: 0:02:52  lr: 0.000500  loss: 6.3337 (6.2101)  loss_classifier: 5.8467 (5.7405)  loss_box_reg: 0.2298 (0.2415)  loss_objectness: 0.1417 (0.1518)  loss_rpn_box_reg: 0.0770 (0.0763)  time: 0.6139  data: 0.1341  max mem: 10593\n",
      "Training Epoch: [8]  [230/500]  eta: 0:02:46  lr: 0.000500  loss: 6.1339 (6.2071)  loss_classifier: 5.6546 (5.7354)  loss_box_reg: 0.2423 (0.2425)  loss_objectness: 0.1647 (0.1530)  loss_rpn_box_reg: 0.0658 (0.0762)  time: 0.6052  data: 0.1348  max mem: 10593\n",
      "Training Epoch: [8]  [240/500]  eta: 0:02:40  lr: 0.000500  loss: 6.0354 (6.2012)  loss_classifier: 5.5292 (5.7296)  loss_box_reg: 0.2541 (0.2428)  loss_objectness: 0.1595 (0.1527)  loss_rpn_box_reg: 0.0695 (0.0760)  time: 0.6137  data: 0.1352  max mem: 10593\n",
      "Training Epoch: [8]  [250/500]  eta: 0:02:34  lr: 0.000500  loss: 5.9819 (6.1998)  loss_classifier: 5.5889 (5.7301)  loss_box_reg: 0.2250 (0.2414)  loss_objectness: 0.1349 (0.1525)  loss_rpn_box_reg: 0.0691 (0.0758)  time: 0.6365  data: 0.1334  max mem: 10593\n",
      "Training Epoch: [8]  [260/500]  eta: 0:02:28  lr: 0.000500  loss: 6.0003 (6.1945)  loss_classifier: 5.5669 (5.7236)  loss_box_reg: 0.2270 (0.2423)  loss_objectness: 0.1443 (0.1526)  loss_rpn_box_reg: 0.0691 (0.0760)  time: 0.6275  data: 0.1326  max mem: 10593\n",
      "Training Epoch: [8]  [270/500]  eta: 0:02:22  lr: 0.000500  loss: 6.0612 (6.1947)  loss_classifier: 5.5809 (5.7241)  loss_box_reg: 0.2319 (0.2424)  loss_objectness: 0.1471 (0.1523)  loss_rpn_box_reg: 0.0754 (0.0760)  time: 0.6182  data: 0.1327  max mem: 10593\n",
      "Training Epoch: [8]  [280/500]  eta: 0:02:16  lr: 0.000500  loss: 6.1100 (6.1875)  loss_classifier: 5.5937 (5.7176)  loss_box_reg: 0.2319 (0.2427)  loss_objectness: 0.1431 (0.1520)  loss_rpn_box_reg: 0.0551 (0.0752)  time: 0.6189  data: 0.1334  max mem: 10593\n",
      "Training Epoch: [8]  [290/500]  eta: 0:02:10  lr: 0.000500  loss: 6.1289 (6.1875)  loss_classifier: 5.6321 (5.7193)  loss_box_reg: 0.2241 (0.2416)  loss_objectness: 0.1402 (0.1514)  loss_rpn_box_reg: 0.0591 (0.0752)  time: 0.6316  data: 0.1348  max mem: 10593\n",
      "Training Epoch: [8]  [300/500]  eta: 0:02:03  lr: 0.000500  loss: 6.1289 (6.1885)  loss_classifier: 5.6321 (5.7189)  loss_box_reg: 0.2249 (0.2423)  loss_objectness: 0.1572 (0.1520)  loss_rpn_box_reg: 0.0609 (0.0754)  time: 0.6412  data: 0.1391  max mem: 10593\n",
      "Training Epoch: [8]  [310/500]  eta: 0:01:57  lr: 0.000500  loss: 6.1039 (6.1837)  loss_classifier: 5.6545 (5.7145)  loss_box_reg: 0.2271 (0.2419)  loss_objectness: 0.1572 (0.1518)  loss_rpn_box_reg: 0.0724 (0.0755)  time: 0.6318  data: 0.1376  max mem: 10593\n",
      "Training Epoch: [8]  [320/500]  eta: 0:01:51  lr: 0.000500  loss: 6.1272 (6.1874)  loss_classifier: 5.7179 (5.7176)  loss_box_reg: 0.2242 (0.2420)  loss_objectness: 0.1560 (0.1521)  loss_rpn_box_reg: 0.0751 (0.0757)  time: 0.6242  data: 0.1342  max mem: 10593\n",
      "Training Epoch: [8]  [330/500]  eta: 0:01:45  lr: 0.000500  loss: 6.1272 (6.1880)  loss_classifier: 5.6820 (5.7173)  loss_box_reg: 0.2251 (0.2417)  loss_objectness: 0.1732 (0.1526)  loss_rpn_box_reg: 0.0818 (0.0764)  time: 0.6180  data: 0.1346  max mem: 10593\n",
      "Training Epoch: [8]  [340/500]  eta: 0:01:39  lr: 0.000500  loss: 6.1655 (6.1964)  loss_classifier: 5.7194 (5.7260)  loss_box_reg: 0.2396 (0.2413)  loss_objectness: 0.1727 (0.1527)  loss_rpn_box_reg: 0.0739 (0.0765)  time: 0.6224  data: 0.1345  max mem: 10593\n",
      "Training Epoch: [8]  [350/500]  eta: 0:01:33  lr: 0.000500  loss: 6.4453 (6.2028)  loss_classifier: 6.0492 (5.7340)  loss_box_reg: 0.2274 (0.2404)  loss_objectness: 0.1376 (0.1520)  loss_rpn_box_reg: 0.0665 (0.0763)  time: 0.6250  data: 0.1324  max mem: 10593\n",
      "Training Epoch: [8]  [360/500]  eta: 0:01:26  lr: 0.000500  loss: 6.3699 (6.2057)  loss_classifier: 5.8895 (5.7365)  loss_box_reg: 0.2109 (0.2404)  loss_objectness: 0.1376 (0.1520)  loss_rpn_box_reg: 0.0757 (0.0767)  time: 0.6106  data: 0.1303  max mem: 10593\n",
      "Training Epoch: [8]  [370/500]  eta: 0:01:20  lr: 0.000500  loss: 6.2017 (6.2085)  loss_classifier: 5.7755 (5.7381)  loss_box_reg: 0.2249 (0.2406)  loss_objectness: 0.1498 (0.1524)  loss_rpn_box_reg: 0.0950 (0.0774)  time: 0.6149  data: 0.1339  max mem: 10593\n",
      "Training Epoch: [8]  [380/500]  eta: 0:01:14  lr: 0.000500  loss: 6.3470 (6.2123)  loss_classifier: 5.7879 (5.7399)  loss_box_reg: 0.2358 (0.2417)  loss_objectness: 0.1717 (0.1529)  loss_rpn_box_reg: 0.0950 (0.0779)  time: 0.6208  data: 0.1362  max mem: 10593\n",
      "Training Epoch: [8]  [390/500]  eta: 0:01:08  lr: 0.000500  loss: 6.1858 (6.2099)  loss_classifier: 5.7058 (5.7377)  loss_box_reg: 0.2580 (0.2417)  loss_objectness: 0.1473 (0.1526)  loss_rpn_box_reg: 0.0873 (0.0779)  time: 0.6203  data: 0.1345  max mem: 10593\n",
      "Training Epoch: [8]  [400/500]  eta: 0:01:02  lr: 0.000500  loss: 5.9737 (6.2056)  loss_classifier: 5.5557 (5.7336)  loss_box_reg: 0.2218 (0.2415)  loss_objectness: 0.1439 (0.1527)  loss_rpn_box_reg: 0.0684 (0.0777)  time: 0.6259  data: 0.1333  max mem: 10593\n",
      "Training Epoch: [8]  [410/500]  eta: 0:00:55  lr: 0.000500  loss: 6.0503 (6.2102)  loss_classifier: 5.6088 (5.7388)  loss_box_reg: 0.2087 (0.2412)  loss_objectness: 0.1466 (0.1528)  loss_rpn_box_reg: 0.0614 (0.0774)  time: 0.6181  data: 0.1333  max mem: 10593\n",
      "Training Epoch: [8]  [420/500]  eta: 0:00:49  lr: 0.000500  loss: 6.2244 (6.2092)  loss_classifier: 5.7264 (5.7390)  loss_box_reg: 0.2031 (0.2404)  loss_objectness: 0.1413 (0.1524)  loss_rpn_box_reg: 0.0736 (0.0775)  time: 0.6150  data: 0.1314  max mem: 10593\n",
      "Training Epoch: [8]  [430/500]  eta: 0:00:43  lr: 0.000500  loss: 6.2320 (6.2115)  loss_classifier: 5.7264 (5.7410)  loss_box_reg: 0.1997 (0.2405)  loss_objectness: 0.1413 (0.1527)  loss_rpn_box_reg: 0.0727 (0.0774)  time: 0.6248  data: 0.1321  max mem: 10593\n",
      "Training Epoch: [8]  [440/500]  eta: 0:00:37  lr: 0.000500  loss: 6.2747 (6.2125)  loss_classifier: 5.8118 (5.7430)  loss_box_reg: 0.2119 (0.2397)  loss_objectness: 0.1524 (0.1527)  loss_rpn_box_reg: 0.0660 (0.0771)  time: 0.6251  data: 0.1335  max mem: 10593\n",
      "Training Epoch: [8]  [450/500]  eta: 0:00:31  lr: 0.000500  loss: 6.2755 (6.2126)  loss_classifier: 5.8212 (5.7429)  loss_box_reg: 0.2280 (0.2397)  loss_objectness: 0.1448 (0.1529)  loss_rpn_box_reg: 0.0660 (0.0771)  time: 0.6246  data: 0.1329  max mem: 10593\n",
      "Training Epoch: [8]  [460/500]  eta: 0:00:24  lr: 0.000500  loss: 6.3255 (6.2148)  loss_classifier: 5.8438 (5.7450)  loss_box_reg: 0.2376 (0.2398)  loss_objectness: 0.1420 (0.1528)  loss_rpn_box_reg: 0.0680 (0.0773)  time: 0.6231  data: 0.1333  max mem: 10593\n",
      "Training Epoch: [8]  [470/500]  eta: 0:00:18  lr: 0.000500  loss: 6.3664 (6.2228)  loss_classifier: 5.9558 (5.7531)  loss_box_reg: 0.2453 (0.2396)  loss_objectness: 0.1455 (0.1530)  loss_rpn_box_reg: 0.0680 (0.0772)  time: 0.6145  data: 0.1330  max mem: 10593\n",
      "Training Epoch: [8]  [480/500]  eta: 0:00:12  lr: 0.000500  loss: 6.3664 (6.2242)  loss_classifier: 5.9500 (5.7549)  loss_box_reg: 0.2066 (0.2389)  loss_objectness: 0.1607 (0.1533)  loss_rpn_box_reg: 0.0644 (0.0771)  time: 0.6276  data: 0.1343  max mem: 10593\n",
      "Training Epoch: [8]  [490/500]  eta: 0:00:06  lr: 0.000500  loss: 6.1439 (6.2188)  loss_classifier: 5.6484 (5.7500)  loss_box_reg: 0.2066 (0.2385)  loss_objectness: 0.1569 (0.1532)  loss_rpn_box_reg: 0.0728 (0.0771)  time: 0.6342  data: 0.1356  max mem: 10593\n",
      "Training Epoch: [8]  [499/500]  eta: 0:00:00  lr: 0.000500  loss: 5.8525 (6.2155)  loss_classifier: 5.5225 (5.7470)  loss_box_reg: 0.2173 (0.2382)  loss_objectness: 0.1495 (0.1532)  loss_rpn_box_reg: 0.0728 (0.0771)  time: 0.6268  data: 0.1349  max mem: 10593\n",
      "Training Epoch: [8] Total time: 0:05:10 (0.6209 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:48  model_time: 0.6792 (0.6792)  evaluator_time: 0.0350 (0.0350)  time: 0.8642  data: 0.1400  max mem: 10593\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4481 (0.4582)  evaluator_time: 0.0340 (0.0371)  time: 0.6375  data: 0.1473  max mem: 10593\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4821 (0.4608)  evaluator_time: 0.0360 (0.0375)  time: 0.6643  data: 0.1470  max mem: 10593\n",
      "Test: Total time: 0:01:21 (0.6484 s / it)\n",
      "Averaged stats: model_time: 0.4821 (0.4608)  evaluator_time: 0.0360 (0.0375)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.072\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.173\n",
      "Testing Epoch: [8]  [  0/125]  eta: 0:01:21  lr: 0.000500  loss: 6.2013 (6.2013)  loss_classifier: 5.6400 (5.6400)  loss_box_reg: 0.2947 (0.2947)  loss_objectness: 0.1349 (0.1349)  loss_rpn_box_reg: 0.1317 (0.1317)  time: 0.6491  data: 0.1470  max mem: 10593\n",
      "Testing Epoch: [8]  [100/125]  eta: 0:00:14  lr: 0.000500  loss: 6.0362 (6.1210)  loss_classifier: 5.4222 (5.6113)  loss_box_reg: 0.2687 (0.2865)  loss_objectness: 0.1275 (0.1333)  loss_rpn_box_reg: 0.0704 (0.0900)  time: 0.5880  data: 0.1454  max mem: 10593\n",
      "Testing Epoch: [8]  [124/125]  eta: 0:00:00  lr: 0.000500  loss: 6.1578 (6.1551)  loss_classifier: 5.6558 (5.6504)  loss_box_reg: 0.2418 (0.2820)  loss_objectness: 0.1203 (0.1327)  loss_rpn_box_reg: 0.0747 (0.0899)  time: 0.5988  data: 0.1453  max mem: 10593\n",
      "Testing Epoch: [8] Total time: 0:01:14 (0.5972 s / it)\n",
      "Training Epoch: [9]  [  0/500]  eta: 0:05:48  lr: 0.000050  loss: 6.4128 (6.4128)  loss_classifier: 5.9071 (5.9071)  loss_box_reg: 0.2236 (0.2236)  loss_objectness: 0.1553 (0.1553)  loss_rpn_box_reg: 0.1269 (0.1269)  time: 0.6972  data: 0.1500  max mem: 10593\n",
      "Training Epoch: [9]  [ 10/500]  eta: 0:05:04  lr: 0.000050  loss: 5.8163 (5.8287)  loss_classifier: 5.4033 (5.4065)  loss_box_reg: 0.2300 (0.2235)  loss_objectness: 0.1330 (0.1319)  loss_rpn_box_reg: 0.0558 (0.0668)  time: 0.6220  data: 0.1303  max mem: 10593\n",
      "Training Epoch: [9]  [ 20/500]  eta: 0:04:57  lr: 0.000050  loss: 5.8369 (5.8732)  loss_classifier: 5.3657 (5.4307)  loss_box_reg: 0.2300 (0.2264)  loss_objectness: 0.1330 (0.1402)  loss_rpn_box_reg: 0.0660 (0.0758)  time: 0.6161  data: 0.1322  max mem: 10593\n",
      "Training Epoch: [9]  [ 30/500]  eta: 0:04:53  lr: 0.000050  loss: 6.0047 (6.0366)  loss_classifier: 5.5676 (5.5752)  loss_box_reg: 0.2436 (0.2439)  loss_objectness: 0.1501 (0.1442)  loss_rpn_box_reg: 0.0692 (0.0733)  time: 0.6258  data: 0.1363  max mem: 10593\n",
      "Training Epoch: [9]  [ 40/500]  eta: 0:04:47  lr: 0.000050  loss: 6.0454 (6.0060)  loss_classifier: 5.6265 (5.5576)  loss_box_reg: 0.2320 (0.2323)  loss_objectness: 0.1525 (0.1463)  loss_rpn_box_reg: 0.0549 (0.0698)  time: 0.6300  data: 0.1361  max mem: 10593\n",
      "Training Epoch: [9]  [ 50/500]  eta: 0:04:41  lr: 0.000050  loss: 6.0454 (6.0746)  loss_classifier: 5.5332 (5.6205)  loss_box_reg: 0.2320 (0.2374)  loss_objectness: 0.1525 (0.1474)  loss_rpn_box_reg: 0.0581 (0.0693)  time: 0.6280  data: 0.1347  max mem: 10593\n",
      "Training Epoch: [9]  [ 60/500]  eta: 0:04:36  lr: 0.000050  loss: 6.0230 (6.0558)  loss_classifier: 5.4941 (5.5997)  loss_box_reg: 0.2353 (0.2394)  loss_objectness: 0.1522 (0.1471)  loss_rpn_box_reg: 0.0630 (0.0695)  time: 0.6325  data: 0.1327  max mem: 10593\n",
      "Training Epoch: [9]  [ 70/500]  eta: 0:04:29  lr: 0.000050  loss: 6.0464 (6.1010)  loss_classifier: 5.5577 (5.6473)  loss_box_reg: 0.2164 (0.2352)  loss_objectness: 0.1444 (0.1478)  loss_rpn_box_reg: 0.0754 (0.0708)  time: 0.6264  data: 0.1338  max mem: 10593\n",
      "Training Epoch: [9]  [ 80/500]  eta: 0:04:23  lr: 0.000050  loss: 6.2689 (6.0781)  loss_classifier: 5.8633 (5.6249)  loss_box_reg: 0.2223 (0.2339)  loss_objectness: 0.1275 (0.1474)  loss_rpn_box_reg: 0.0893 (0.0719)  time: 0.6254  data: 0.1341  max mem: 10593\n",
      "Training Epoch: [9]  [ 90/500]  eta: 0:04:16  lr: 0.000050  loss: 6.1323 (6.0872)  loss_classifier: 5.6502 (5.6302)  loss_box_reg: 0.2311 (0.2352)  loss_objectness: 0.1346 (0.1486)  loss_rpn_box_reg: 0.0793 (0.0732)  time: 0.6257  data: 0.1337  max mem: 10593\n",
      "Training Epoch: [9]  [100/500]  eta: 0:04:10  lr: 0.000050  loss: 6.3841 (6.1318)  loss_classifier: 5.8364 (5.6739)  loss_box_reg: 0.2311 (0.2355)  loss_objectness: 0.1563 (0.1490)  loss_rpn_box_reg: 0.0602 (0.0734)  time: 0.6207  data: 0.1356  max mem: 10593\n",
      "Training Epoch: [9]  [110/500]  eta: 0:04:03  lr: 0.000050  loss: 6.3956 (6.1322)  loss_classifier: 5.8364 (5.6748)  loss_box_reg: 0.2197 (0.2355)  loss_objectness: 0.1466 (0.1498)  loss_rpn_box_reg: 0.0538 (0.0722)  time: 0.6136  data: 0.1337  max mem: 10593\n",
      "Training Epoch: [9]  [120/500]  eta: 0:03:56  lr: 0.000050  loss: 6.2578 (6.1694)  loss_classifier: 5.8139 (5.7113)  loss_box_reg: 0.2176 (0.2339)  loss_objectness: 0.1499 (0.1508)  loss_rpn_box_reg: 0.0678 (0.0733)  time: 0.6109  data: 0.1332  max mem: 10593\n",
      "Training Epoch: [9]  [130/500]  eta: 0:03:50  lr: 0.000050  loss: 6.1599 (6.1658)  loss_classifier: 5.7246 (5.7081)  loss_box_reg: 0.2213 (0.2335)  loss_objectness: 0.1570 (0.1501)  loss_rpn_box_reg: 0.0811 (0.0740)  time: 0.6232  data: 0.1340  max mem: 10593\n",
      "Training Epoch: [9]  [140/500]  eta: 0:03:45  lr: 0.000050  loss: 6.0742 (6.1624)  loss_classifier: 5.6674 (5.7078)  loss_box_reg: 0.2183 (0.2318)  loss_objectness: 0.1289 (0.1496)  loss_rpn_box_reg: 0.0617 (0.0733)  time: 0.6374  data: 0.1312  max mem: 10593\n",
      "Training Epoch: [9]  [150/500]  eta: 0:03:39  lr: 0.000050  loss: 6.1559 (6.1618)  loss_classifier: 5.7496 (5.7051)  loss_box_reg: 0.2183 (0.2319)  loss_objectness: 0.1521 (0.1506)  loss_rpn_box_reg: 0.0681 (0.0742)  time: 0.6444  data: 0.1330  max mem: 10593\n",
      "Training Epoch: [9]  [160/500]  eta: 0:03:32  lr: 0.000050  loss: 6.1320 (6.1497)  loss_classifier: 5.6420 (5.6945)  loss_box_reg: 0.2283 (0.2315)  loss_objectness: 0.1582 (0.1501)  loss_rpn_box_reg: 0.0651 (0.0736)  time: 0.6234  data: 0.1332  max mem: 10593\n",
      "Training Epoch: [9]  [170/500]  eta: 0:03:26  lr: 0.000050  loss: 6.1157 (6.1602)  loss_classifier: 5.6420 (5.7027)  loss_box_reg: 0.2357 (0.2327)  loss_objectness: 0.1552 (0.1507)  loss_rpn_box_reg: 0.0608 (0.0741)  time: 0.6239  data: 0.1323  max mem: 10593\n",
      "Training Epoch: [9]  [180/500]  eta: 0:03:20  lr: 0.000050  loss: 6.1240 (6.1559)  loss_classifier: 5.7278 (5.7000)  loss_box_reg: 0.2291 (0.2312)  loss_objectness: 0.1466 (0.1500)  loss_rpn_box_reg: 0.0707 (0.0747)  time: 0.6353  data: 0.1338  max mem: 10593\n",
      "Training Epoch: [9]  [190/500]  eta: 0:03:13  lr: 0.000050  loss: 6.0442 (6.1504)  loss_classifier: 5.5528 (5.6945)  loss_box_reg: 0.2202 (0.2320)  loss_objectness: 0.1378 (0.1489)  loss_rpn_box_reg: 0.0806 (0.0751)  time: 0.6187  data: 0.1326  max mem: 10593\n",
      "Training Epoch: [9]  [200/500]  eta: 0:03:07  lr: 0.000050  loss: 6.0153 (6.1512)  loss_classifier: 5.5528 (5.6933)  loss_box_reg: 0.2349 (0.2331)  loss_objectness: 0.1351 (0.1490)  loss_rpn_box_reg: 0.0928 (0.0757)  time: 0.6157  data: 0.1329  max mem: 10593\n",
      "Training Epoch: [9]  [210/500]  eta: 0:03:01  lr: 0.000050  loss: 6.0402 (6.1451)  loss_classifier: 5.6109 (5.6855)  loss_box_reg: 0.2407 (0.2343)  loss_objectness: 0.1463 (0.1491)  loss_rpn_box_reg: 0.0798 (0.0762)  time: 0.6225  data: 0.1334  max mem: 10593\n",
      "Training Epoch: [9]  [220/500]  eta: 0:02:54  lr: 0.000050  loss: 6.2718 (6.1663)  loss_classifier: 5.7440 (5.7039)  loss_box_reg: 0.2421 (0.2352)  loss_objectness: 0.1537 (0.1507)  loss_rpn_box_reg: 0.0733 (0.0765)  time: 0.6208  data: 0.1344  max mem: 10593\n",
      "Training Epoch: [9]  [230/500]  eta: 0:02:48  lr: 0.000050  loss: 6.1797 (6.1679)  loss_classifier: 5.7654 (5.7074)  loss_box_reg: 0.2394 (0.2343)  loss_objectness: 0.1498 (0.1500)  loss_rpn_box_reg: 0.0733 (0.0761)  time: 0.6231  data: 0.1326  max mem: 10593\n",
      "Training Epoch: [9]  [240/500]  eta: 0:02:42  lr: 0.000050  loss: 6.1309 (6.1704)  loss_classifier: 5.6591 (5.7110)  loss_box_reg: 0.1934 (0.2336)  loss_objectness: 0.1321 (0.1499)  loss_rpn_box_reg: 0.0577 (0.0759)  time: 0.6371  data: 0.1310  max mem: 10593\n",
      "Training Epoch: [9]  [250/500]  eta: 0:02:36  lr: 0.000050  loss: 6.1442 (6.1709)  loss_classifier: 5.5840 (5.7117)  loss_box_reg: 0.2245 (0.2337)  loss_objectness: 0.1391 (0.1501)  loss_rpn_box_reg: 0.0551 (0.0754)  time: 0.6333  data: 0.1332  max mem: 10593\n",
      "Training Epoch: [9]  [260/500]  eta: 0:02:29  lr: 0.000050  loss: 6.1659 (6.1781)  loss_classifier: 5.6467 (5.7181)  loss_box_reg: 0.2358 (0.2344)  loss_objectness: 0.1532 (0.1501)  loss_rpn_box_reg: 0.0695 (0.0756)  time: 0.6135  data: 0.1349  max mem: 10593\n",
      "Training Epoch: [9]  [270/500]  eta: 0:02:23  lr: 0.000050  loss: 6.2414 (6.1857)  loss_classifier: 5.8055 (5.7247)  loss_box_reg: 0.2471 (0.2352)  loss_objectness: 0.1496 (0.1501)  loss_rpn_box_reg: 0.0700 (0.0756)  time: 0.6099  data: 0.1335  max mem: 10593\n",
      "Training Epoch: [9]  [280/500]  eta: 0:02:17  lr: 0.000050  loss: 6.2820 (6.1863)  loss_classifier: 5.7043 (5.7230)  loss_box_reg: 0.2769 (0.2361)  loss_objectness: 0.1482 (0.1506)  loss_rpn_box_reg: 0.0824 (0.0765)  time: 0.6222  data: 0.1332  max mem: 10593\n",
      "Training Epoch: [9]  [290/500]  eta: 0:02:11  lr: 0.000050  loss: 6.1368 (6.1812)  loss_classifier: 5.6744 (5.7196)  loss_box_reg: 0.2271 (0.2349)  loss_objectness: 0.1418 (0.1503)  loss_rpn_box_reg: 0.0801 (0.0764)  time: 0.6313  data: 0.1333  max mem: 10593\n",
      "Training Epoch: [9]  [300/500]  eta: 0:02:04  lr: 0.000050  loss: 6.2020 (6.1837)  loss_classifier: 5.8010 (5.7211)  loss_box_reg: 0.2214 (0.2349)  loss_objectness: 0.1549 (0.1512)  loss_rpn_box_reg: 0.0719 (0.0766)  time: 0.6230  data: 0.1357  max mem: 10593\n",
      "Training Epoch: [9]  [310/500]  eta: 0:01:58  lr: 0.000050  loss: 6.2983 (6.1894)  loss_classifier: 5.6744 (5.7261)  loss_box_reg: 0.2302 (0.2354)  loss_objectness: 0.1563 (0.1513)  loss_rpn_box_reg: 0.0719 (0.0766)  time: 0.6226  data: 0.1389  max mem: 10593\n",
      "Training Epoch: [9]  [320/500]  eta: 0:01:52  lr: 0.000050  loss: 6.2185 (6.1853)  loss_classifier: 5.6744 (5.7202)  loss_box_reg: 0.2427 (0.2366)  loss_objectness: 0.1504 (0.1516)  loss_rpn_box_reg: 0.0768 (0.0769)  time: 0.6356  data: 0.1372  max mem: 10593\n",
      "Training Epoch: [9]  [330/500]  eta: 0:01:46  lr: 0.000050  loss: 6.2185 (6.1878)  loss_classifier: 5.7487 (5.7217)  loss_box_reg: 0.2495 (0.2370)  loss_objectness: 0.1583 (0.1519)  loss_rpn_box_reg: 0.0816 (0.0772)  time: 0.6350  data: 0.1370  max mem: 10593\n",
      "Training Epoch: [9]  [340/500]  eta: 0:01:39  lr: 0.000050  loss: 6.1906 (6.1860)  loss_classifier: 5.7511 (5.7213)  loss_box_reg: 0.2143 (0.2362)  loss_objectness: 0.1451 (0.1515)  loss_rpn_box_reg: 0.0729 (0.0769)  time: 0.6166  data: 0.1347  max mem: 10593\n",
      "Training Epoch: [9]  [350/500]  eta: 0:01:33  lr: 0.000050  loss: 6.1906 (6.1875)  loss_classifier: 5.6901 (5.7229)  loss_box_reg: 0.2050 (0.2359)  loss_objectness: 0.1492 (0.1520)  loss_rpn_box_reg: 0.0566 (0.0767)  time: 0.6221  data: 0.1336  max mem: 10593\n",
      "Training Epoch: [9]  [360/500]  eta: 0:01:27  lr: 0.000050  loss: 6.0507 (6.1891)  loss_classifier: 5.5974 (5.7245)  loss_box_reg: 0.2245 (0.2358)  loss_objectness: 0.1537 (0.1520)  loss_rpn_box_reg: 0.0696 (0.0767)  time: 0.6357  data: 0.1342  max mem: 10593\n",
      "Training Epoch: [9]  [370/500]  eta: 0:01:21  lr: 0.000050  loss: 6.0720 (6.1937)  loss_classifier: 5.5974 (5.7298)  loss_box_reg: 0.2383 (0.2356)  loss_objectness: 0.1498 (0.1518)  loss_rpn_box_reg: 0.0730 (0.0764)  time: 0.6281  data: 0.1324  max mem: 10593\n",
      "Training Epoch: [9]  [380/500]  eta: 0:01:15  lr: 0.000050  loss: 6.1384 (6.1966)  loss_classifier: 5.7660 (5.7317)  loss_box_reg: 0.2348 (0.2365)  loss_objectness: 0.1509 (0.1521)  loss_rpn_box_reg: 0.0610 (0.0763)  time: 0.6284  data: 0.1332  max mem: 10593\n",
      "Training Epoch: [9]  [390/500]  eta: 0:01:08  lr: 0.000050  loss: 6.3427 (6.2080)  loss_classifier: 5.9886 (5.7442)  loss_box_reg: 0.2348 (0.2362)  loss_objectness: 0.1466 (0.1519)  loss_rpn_box_reg: 0.0560 (0.0757)  time: 0.6262  data: 0.1355  max mem: 10593\n",
      "Training Epoch: [9]  [400/500]  eta: 0:01:02  lr: 0.000050  loss: 6.3427 (6.2090)  loss_classifier: 5.9886 (5.7461)  loss_box_reg: 0.2422 (0.2362)  loss_objectness: 0.1292 (0.1513)  loss_rpn_box_reg: 0.0516 (0.0754)  time: 0.6177  data: 0.1335  max mem: 10593\n",
      "Training Epoch: [9]  [410/500]  eta: 0:00:56  lr: 0.000050  loss: 6.0767 (6.2051)  loss_classifier: 5.5239 (5.7423)  loss_box_reg: 0.2469 (0.2364)  loss_objectness: 0.1351 (0.1512)  loss_rpn_box_reg: 0.0603 (0.0752)  time: 0.6151  data: 0.1312  max mem: 10593\n",
      "Training Epoch: [9]  [420/500]  eta: 0:00:50  lr: 0.000050  loss: 6.0145 (6.2013)  loss_classifier: 5.5202 (5.7379)  loss_box_reg: 0.2313 (0.2365)  loss_objectness: 0.1542 (0.1518)  loss_rpn_box_reg: 0.0700 (0.0751)  time: 0.6242  data: 0.1340  max mem: 10593\n",
      "Training Epoch: [9]  [430/500]  eta: 0:00:43  lr: 0.000050  loss: 6.0751 (6.2004)  loss_classifier: 5.6328 (5.7369)  loss_box_reg: 0.2206 (0.2363)  loss_objectness: 0.1668 (0.1521)  loss_rpn_box_reg: 0.0684 (0.0750)  time: 0.6251  data: 0.1347  max mem: 10593\n",
      "Training Epoch: [9]  [440/500]  eta: 0:00:37  lr: 0.000050  loss: 6.1786 (6.2015)  loss_classifier: 5.7165 (5.7383)  loss_box_reg: 0.2137 (0.2357)  loss_objectness: 0.1599 (0.1523)  loss_rpn_box_reg: 0.0649 (0.0751)  time: 0.6220  data: 0.1332  max mem: 10593\n",
      "Training Epoch: [9]  [450/500]  eta: 0:00:31  lr: 0.000050  loss: 5.9705 (6.1967)  loss_classifier: 5.5404 (5.7340)  loss_box_reg: 0.2168 (0.2356)  loss_objectness: 0.1371 (0.1519)  loss_rpn_box_reg: 0.0711 (0.0752)  time: 0.6278  data: 0.1321  max mem: 10593\n",
      "Training Epoch: [9]  [460/500]  eta: 0:00:25  lr: 0.000050  loss: 6.3533 (6.2032)  loss_classifier: 5.8364 (5.7410)  loss_box_reg: 0.2256 (0.2353)  loss_objectness: 0.1412 (0.1520)  loss_rpn_box_reg: 0.0682 (0.0749)  time: 0.6369  data: 0.1327  max mem: 10593\n",
      "Training Epoch: [9]  [470/500]  eta: 0:00:18  lr: 0.000050  loss: 6.3584 (6.2007)  loss_classifier: 5.8364 (5.7375)  loss_box_reg: 0.2272 (0.2360)  loss_objectness: 0.1548 (0.1520)  loss_rpn_box_reg: 0.0674 (0.0752)  time: 0.6171  data: 0.1342  max mem: 10593\n",
      "Training Epoch: [9]  [480/500]  eta: 0:00:12  lr: 0.000050  loss: 6.1949 (6.2026)  loss_classifier: 5.5389 (5.7388)  loss_box_reg: 0.2351 (0.2362)  loss_objectness: 0.1557 (0.1521)  loss_rpn_box_reg: 0.0751 (0.0755)  time: 0.6112  data: 0.1338  max mem: 10593\n",
      "Training Epoch: [9]  [490/500]  eta: 0:00:06  lr: 0.000050  loss: 6.3122 (6.2057)  loss_classifier: 5.7552 (5.7413)  loss_box_reg: 0.2340 (0.2364)  loss_objectness: 0.1578 (0.1523)  loss_rpn_box_reg: 0.0867 (0.0757)  time: 0.6202  data: 0.1342  max mem: 10593\n",
      "Training Epoch: [9]  [499/500]  eta: 0:00:00  lr: 0.000050  loss: 6.3063 (6.2104)  loss_classifier: 5.7819 (5.7450)  loss_box_reg: 0.2414 (0.2367)  loss_objectness: 0.1570 (0.1523)  loss_rpn_box_reg: 0.0867 (0.0763)  time: 0.6124  data: 0.1351  max mem: 10593\n",
      "Training Epoch: [9] Total time: 0:05:12 (0.6244 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:02  model_time: 0.7052 (0.7052)  evaluator_time: 0.0340 (0.0340)  time: 0.9768  data: 0.2287  max mem: 10593\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4411 (0.4517)  evaluator_time: 0.0340 (0.0348)  time: 0.6289  data: 0.1474  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4701 (0.4535)  evaluator_time: 0.0360 (0.0356)  time: 0.6556  data: 0.1486  max mem: 10714\n",
      "Test: Total time: 0:01:20 (0.6417 s / it)\n",
      "Averaged stats: model_time: 0.4701 (0.4535)  evaluator_time: 0.0360 (0.0356)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.071\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [9]  [  0/125]  eta: 0:01:19  lr: 0.000050  loss: 6.1933 (6.1933)  loss_classifier: 5.6396 (5.6396)  loss_box_reg: 0.2992 (0.2992)  loss_objectness: 0.1247 (0.1247)  loss_rpn_box_reg: 0.1299 (0.1299)  time: 0.6381  data: 0.1410  max mem: 10714\n",
      "Testing Epoch: [9]  [100/125]  eta: 0:00:14  lr: 0.000050  loss: 6.0150 (6.1393)  loss_classifier: 5.4305 (5.6277)  loss_box_reg: 0.2658 (0.2892)  loss_objectness: 0.1286 (0.1323)  loss_rpn_box_reg: 0.0722 (0.0901)  time: 0.5898  data: 0.1488  max mem: 10714\n",
      "Testing Epoch: [9]  [124/125]  eta: 0:00:00  lr: 0.000050  loss: 6.1566 (6.1713)  loss_classifier: 5.7006 (5.6644)  loss_box_reg: 0.2432 (0.2846)  loss_objectness: 0.1188 (0.1322)  loss_rpn_box_reg: 0.0742 (0.0901)  time: 0.5991  data: 0.1474  max mem: 10714\n",
      "Testing Epoch: [9] Total time: 0:01:14 (0.5958 s / it)\n",
      "Training Epoch: [10]  [  0/500]  eta: 0:04:58  lr: 0.000050  loss: 5.8241 (5.8241)  loss_classifier: 5.3097 (5.3097)  loss_box_reg: 0.2572 (0.2572)  loss_objectness: 0.1666 (0.1666)  loss_rpn_box_reg: 0.0906 (0.0906)  time: 0.5961  data: 0.1510  max mem: 10714\n",
      "Training Epoch: [10]  [ 10/500]  eta: 0:05:14  lr: 0.000050  loss: 6.4242 (6.3821)  loss_classifier: 5.9328 (5.9506)  loss_box_reg: 0.2090 (0.1994)  loss_objectness: 0.1578 (0.1509)  loss_rpn_box_reg: 0.0856 (0.0813)  time: 0.6409  data: 0.1356  max mem: 10714\n",
      "Training Epoch: [10]  [ 20/500]  eta: 0:04:59  lr: 0.000050  loss: 6.3070 (6.3363)  loss_classifier: 5.7356 (5.9013)  loss_box_reg: 0.2071 (0.2086)  loss_objectness: 0.1455 (0.1519)  loss_rpn_box_reg: 0.0674 (0.0745)  time: 0.6255  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [10]  [ 30/500]  eta: 0:04:53  lr: 0.000050  loss: 6.1463 (6.2792)  loss_classifier: 5.6917 (5.8458)  loss_box_reg: 0.2225 (0.2126)  loss_objectness: 0.1455 (0.1492)  loss_rpn_box_reg: 0.0517 (0.0716)  time: 0.6158  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [10]  [ 40/500]  eta: 0:04:47  lr: 0.000050  loss: 6.3333 (6.2628)  loss_classifier: 5.8080 (5.8285)  loss_box_reg: 0.2211 (0.2132)  loss_objectness: 0.1468 (0.1507)  loss_rpn_box_reg: 0.0596 (0.0704)  time: 0.6252  data: 0.1334  max mem: 10714\n",
      "Training Epoch: [10]  [ 50/500]  eta: 0:04:42  lr: 0.000050  loss: 6.3333 (6.2658)  loss_classifier: 5.7980 (5.8331)  loss_box_reg: 0.2068 (0.2159)  loss_objectness: 0.1386 (0.1493)  loss_rpn_box_reg: 0.0596 (0.0674)  time: 0.6339  data: 0.1309  max mem: 10714\n",
      "Training Epoch: [10]  [ 60/500]  eta: 0:04:35  lr: 0.000050  loss: 6.1814 (6.2396)  loss_classifier: 5.7107 (5.8004)  loss_box_reg: 0.2119 (0.2195)  loss_objectness: 0.1552 (0.1514)  loss_rpn_box_reg: 0.0547 (0.0683)  time: 0.6309  data: 0.1304  max mem: 10714\n",
      "Training Epoch: [10]  [ 70/500]  eta: 0:04:29  lr: 0.000050  loss: 6.0599 (6.2143)  loss_classifier: 5.5636 (5.7679)  loss_box_reg: 0.2336 (0.2235)  loss_objectness: 0.1568 (0.1515)  loss_rpn_box_reg: 0.0765 (0.0714)  time: 0.6226  data: 0.1331  max mem: 10714\n",
      "Training Epoch: [10]  [ 80/500]  eta: 0:04:23  lr: 0.000050  loss: 6.0289 (6.2049)  loss_classifier: 5.4749 (5.7536)  loss_box_reg: 0.2341 (0.2284)  loss_objectness: 0.1455 (0.1500)  loss_rpn_box_reg: 0.0836 (0.0730)  time: 0.6278  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [10]  [ 90/500]  eta: 0:04:16  lr: 0.000050  loss: 6.0286 (6.2028)  loss_classifier: 5.6057 (5.7519)  loss_box_reg: 0.2207 (0.2272)  loss_objectness: 0.1455 (0.1503)  loss_rpn_box_reg: 0.0847 (0.0733)  time: 0.6230  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [10]  [100/500]  eta: 0:04:10  lr: 0.000050  loss: 6.1403 (6.2051)  loss_classifier: 5.6900 (5.7538)  loss_box_reg: 0.2054 (0.2259)  loss_objectness: 0.1494 (0.1517)  loss_rpn_box_reg: 0.0703 (0.0736)  time: 0.6261  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [10]  [110/500]  eta: 0:04:04  lr: 0.000050  loss: 6.1331 (6.2021)  loss_classifier: 5.6768 (5.7491)  loss_box_reg: 0.2286 (0.2282)  loss_objectness: 0.1501 (0.1521)  loss_rpn_box_reg: 0.0636 (0.0728)  time: 0.6348  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [10]  [120/500]  eta: 0:03:57  lr: 0.000050  loss: 6.0464 (6.1935)  loss_classifier: 5.5860 (5.7361)  loss_box_reg: 0.2506 (0.2309)  loss_objectness: 0.1608 (0.1531)  loss_rpn_box_reg: 0.0636 (0.0734)  time: 0.6233  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [10]  [130/500]  eta: 0:03:52  lr: 0.000050  loss: 5.9899 (6.1925)  loss_classifier: 5.5623 (5.7355)  loss_box_reg: 0.2473 (0.2321)  loss_objectness: 0.1472 (0.1514)  loss_rpn_box_reg: 0.0737 (0.0735)  time: 0.6290  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [10]  [140/500]  eta: 0:03:45  lr: 0.000050  loss: 5.9954 (6.1741)  loss_classifier: 5.5434 (5.7179)  loss_box_reg: 0.2128 (0.2303)  loss_objectness: 0.1301 (0.1523)  loss_rpn_box_reg: 0.0737 (0.0736)  time: 0.6320  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [10]  [150/500]  eta: 0:03:39  lr: 0.000050  loss: 6.0734 (6.1921)  loss_classifier: 5.6396 (5.7351)  loss_box_reg: 0.2128 (0.2302)  loss_objectness: 0.1684 (0.1532)  loss_rpn_box_reg: 0.0663 (0.0736)  time: 0.6201  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [10]  [160/500]  eta: 0:03:33  lr: 0.000050  loss: 6.3017 (6.1973)  loss_classifier: 5.8452 (5.7403)  loss_box_reg: 0.2343 (0.2311)  loss_objectness: 0.1488 (0.1524)  loss_rpn_box_reg: 0.0663 (0.0736)  time: 0.6242  data: 0.1324  max mem: 10714\n",
      "Training Epoch: [10]  [170/500]  eta: 0:03:26  lr: 0.000050  loss: 6.2586 (6.2058)  loss_classifier: 5.7166 (5.7452)  loss_box_reg: 0.2639 (0.2342)  loss_objectness: 0.1488 (0.1527)  loss_rpn_box_reg: 0.0712 (0.0737)  time: 0.6260  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [10]  [180/500]  eta: 0:03:20  lr: 0.000050  loss: 6.3887 (6.2160)  loss_classifier: 5.8939 (5.7553)  loss_box_reg: 0.2631 (0.2339)  loss_objectness: 0.1521 (0.1524)  loss_rpn_box_reg: 0.0802 (0.0743)  time: 0.6350  data: 0.1370  max mem: 10714\n",
      "Training Epoch: [10]  [190/500]  eta: 0:03:14  lr: 0.000050  loss: 6.3796 (6.2152)  loss_classifier: 5.8860 (5.7516)  loss_box_reg: 0.2407 (0.2362)  loss_objectness: 0.1455 (0.1529)  loss_rpn_box_reg: 0.0848 (0.0745)  time: 0.6313  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [10]  [200/500]  eta: 0:03:07  lr: 0.000050  loss: 6.3796 (6.2240)  loss_classifier: 5.8839 (5.7593)  loss_box_reg: 0.2774 (0.2371)  loss_objectness: 0.1506 (0.1528)  loss_rpn_box_reg: 0.0837 (0.0748)  time: 0.6154  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [10]  [210/500]  eta: 0:03:01  lr: 0.000050  loss: 6.1687 (6.2152)  loss_classifier: 5.5722 (5.7482)  loss_box_reg: 0.2441 (0.2376)  loss_objectness: 0.1622 (0.1539)  loss_rpn_box_reg: 0.0764 (0.0755)  time: 0.6052  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [10]  [220/500]  eta: 0:02:55  lr: 0.000050  loss: 5.9897 (6.2103)  loss_classifier: 5.5094 (5.7434)  loss_box_reg: 0.2368 (0.2373)  loss_objectness: 0.1634 (0.1538)  loss_rpn_box_reg: 0.0780 (0.0758)  time: 0.6173  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [10]  [230/500]  eta: 0:02:48  lr: 0.000050  loss: 6.2092 (6.2096)  loss_classifier: 5.6812 (5.7434)  loss_box_reg: 0.2216 (0.2372)  loss_objectness: 0.1321 (0.1533)  loss_rpn_box_reg: 0.0689 (0.0757)  time: 0.6256  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [10]  [240/500]  eta: 0:02:42  lr: 0.000050  loss: 6.2089 (6.2076)  loss_classifier: 5.6554 (5.7394)  loss_box_reg: 0.2126 (0.2381)  loss_objectness: 0.1366 (0.1538)  loss_rpn_box_reg: 0.0721 (0.0762)  time: 0.6185  data: 0.1333  max mem: 10714\n",
      "Training Epoch: [10]  [250/500]  eta: 0:02:36  lr: 0.000050  loss: 6.1492 (6.2141)  loss_classifier: 5.6641 (5.7459)  loss_box_reg: 0.2211 (0.2381)  loss_objectness: 0.1531 (0.1538)  loss_rpn_box_reg: 0.0876 (0.0763)  time: 0.6208  data: 0.1335  max mem: 10714\n",
      "Training Epoch: [10]  [260/500]  eta: 0:02:29  lr: 0.000050  loss: 6.0947 (6.2069)  loss_classifier: 5.6641 (5.7404)  loss_box_reg: 0.2211 (0.2376)  loss_objectness: 0.1393 (0.1532)  loss_rpn_box_reg: 0.0633 (0.0757)  time: 0.6209  data: 0.1330  max mem: 10714\n",
      "Training Epoch: [10]  [270/500]  eta: 0:02:23  lr: 0.000050  loss: 6.0853 (6.2001)  loss_classifier: 5.5396 (5.7331)  loss_box_reg: 0.2372 (0.2381)  loss_objectness: 0.1320 (0.1532)  loss_rpn_box_reg: 0.0633 (0.0757)  time: 0.6281  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [10]  [280/500]  eta: 0:02:17  lr: 0.000050  loss: 6.2673 (6.2057)  loss_classifier: 5.6474 (5.7382)  loss_box_reg: 0.2372 (0.2382)  loss_objectness: 0.1492 (0.1536)  loss_rpn_box_reg: 0.0759 (0.0757)  time: 0.6230  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [10]  [290/500]  eta: 0:02:11  lr: 0.000050  loss: 6.3999 (6.2143)  loss_classifier: 6.0050 (5.7460)  loss_box_reg: 0.2455 (0.2393)  loss_objectness: 0.1315 (0.1530)  loss_rpn_box_reg: 0.0657 (0.0759)  time: 0.6152  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [10]  [300/500]  eta: 0:02:04  lr: 0.000050  loss: 6.4462 (6.2172)  loss_classifier: 6.0050 (5.7494)  loss_box_reg: 0.2455 (0.2393)  loss_objectness: 0.1286 (0.1528)  loss_rpn_box_reg: 0.0657 (0.0757)  time: 0.6112  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [10]  [310/500]  eta: 0:01:58  lr: 0.000050  loss: 6.3710 (6.2195)  loss_classifier: 5.8732 (5.7512)  loss_box_reg: 0.2264 (0.2390)  loss_objectness: 0.1503 (0.1532)  loss_rpn_box_reg: 0.0736 (0.0761)  time: 0.6113  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [10]  [320/500]  eta: 0:01:52  lr: 0.000050  loss: 6.2241 (6.2187)  loss_classifier: 5.8253 (5.7505)  loss_box_reg: 0.2252 (0.2390)  loss_objectness: 0.1322 (0.1532)  loss_rpn_box_reg: 0.0799 (0.0760)  time: 0.6216  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [10]  [330/500]  eta: 0:01:46  lr: 0.000050  loss: 6.0145 (6.2160)  loss_classifier: 5.5808 (5.7490)  loss_box_reg: 0.2351 (0.2387)  loss_objectness: 0.1376 (0.1528)  loss_rpn_box_reg: 0.0639 (0.0756)  time: 0.6254  data: 0.1335  max mem: 10714\n",
      "Training Epoch: [10]  [340/500]  eta: 0:01:39  lr: 0.000050  loss: 6.1214 (6.2210)  loss_classifier: 5.7486 (5.7539)  loss_box_reg: 0.2339 (0.2385)  loss_objectness: 0.1440 (0.1530)  loss_rpn_box_reg: 0.0676 (0.0757)  time: 0.6244  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [10]  [350/500]  eta: 0:01:33  lr: 0.000050  loss: 6.3604 (6.2211)  loss_classifier: 5.8857 (5.7538)  loss_box_reg: 0.2240 (0.2383)  loss_objectness: 0.1600 (0.1529)  loss_rpn_box_reg: 0.0763 (0.0761)  time: 0.6164  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [10]  [360/500]  eta: 0:01:27  lr: 0.000050  loss: 6.0293 (6.2120)  loss_classifier: 5.4614 (5.7453)  loss_box_reg: 0.2218 (0.2381)  loss_objectness: 0.1398 (0.1526)  loss_rpn_box_reg: 0.0722 (0.0760)  time: 0.6088  data: 0.1334  max mem: 10714\n",
      "Training Epoch: [10]  [370/500]  eta: 0:01:20  lr: 0.000050  loss: 5.9547 (6.2073)  loss_classifier: 5.4423 (5.7400)  loss_box_reg: 0.2361 (0.2385)  loss_objectness: 0.1351 (0.1524)  loss_rpn_box_reg: 0.0645 (0.0764)  time: 0.6120  data: 0.1329  max mem: 10714\n",
      "Training Epoch: [10]  [380/500]  eta: 0:01:14  lr: 0.000050  loss: 6.1814 (6.2187)  loss_classifier: 5.7490 (5.7506)  loss_box_reg: 0.2462 (0.2386)  loss_objectness: 0.1389 (0.1530)  loss_rpn_box_reg: 0.0738 (0.0764)  time: 0.6147  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [10]  [390/500]  eta: 0:01:08  lr: 0.000050  loss: 6.3606 (6.2193)  loss_classifier: 5.8511 (5.7513)  loss_box_reg: 0.2281 (0.2387)  loss_objectness: 0.1502 (0.1527)  loss_rpn_box_reg: 0.0788 (0.0767)  time: 0.6171  data: 0.1356  max mem: 10714\n",
      "Training Epoch: [10]  [400/500]  eta: 0:01:02  lr: 0.000050  loss: 6.3025 (6.2194)  loss_classifier: 5.7756 (5.7513)  loss_box_reg: 0.2097 (0.2382)  loss_objectness: 0.1502 (0.1529)  loss_rpn_box_reg: 0.0752 (0.0770)  time: 0.6138  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [10]  [410/500]  eta: 0:00:55  lr: 0.000050  loss: 6.2204 (6.2184)  loss_classifier: 5.7869 (5.7513)  loss_box_reg: 0.2143 (0.2382)  loss_objectness: 0.1492 (0.1524)  loss_rpn_box_reg: 0.0667 (0.0766)  time: 0.6162  data: 0.1321  max mem: 10714\n",
      "Training Epoch: [10]  [420/500]  eta: 0:00:49  lr: 0.000050  loss: 6.1537 (6.2153)  loss_classifier: 5.7869 (5.7476)  loss_box_reg: 0.2388 (0.2385)  loss_objectness: 0.1426 (0.1526)  loss_rpn_box_reg: 0.0623 (0.0766)  time: 0.6184  data: 0.1310  max mem: 10714\n",
      "Training Epoch: [10]  [430/500]  eta: 0:00:43  lr: 0.000050  loss: 5.9546 (6.2133)  loss_classifier: 5.5140 (5.7458)  loss_box_reg: 0.2388 (0.2386)  loss_objectness: 0.1561 (0.1527)  loss_rpn_box_reg: 0.0623 (0.0762)  time: 0.6162  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [10]  [440/500]  eta: 0:00:37  lr: 0.000050  loss: 5.9546 (6.2137)  loss_classifier: 5.5140 (5.7456)  loss_box_reg: 0.2375 (0.2388)  loss_objectness: 0.1603 (0.1531)  loss_rpn_box_reg: 0.0592 (0.0763)  time: 0.6288  data: 0.1396  max mem: 10714\n",
      "Training Epoch: [10]  [450/500]  eta: 0:00:31  lr: 0.000050  loss: 6.0963 (6.2117)  loss_classifier: 5.6277 (5.7440)  loss_box_reg: 0.2280 (0.2384)  loss_objectness: 0.1497 (0.1530)  loss_rpn_box_reg: 0.0711 (0.0764)  time: 0.6246  data: 0.1372  max mem: 10714\n",
      "Training Epoch: [10]  [460/500]  eta: 0:00:24  lr: 0.000050  loss: 6.0607 (6.2097)  loss_classifier: 5.6201 (5.7417)  loss_box_reg: 0.2310 (0.2386)  loss_objectness: 0.1341 (0.1529)  loss_rpn_box_reg: 0.0744 (0.0764)  time: 0.6104  data: 0.1327  max mem: 10714\n",
      "Training Epoch: [10]  [470/500]  eta: 0:00:18  lr: 0.000050  loss: 5.9933 (6.2077)  loss_classifier: 5.5339 (5.7396)  loss_box_reg: 0.2208 (0.2387)  loss_objectness: 0.1500 (0.1530)  loss_rpn_box_reg: 0.0736 (0.0763)  time: 0.6146  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [10]  [480/500]  eta: 0:00:12  lr: 0.000050  loss: 6.1802 (6.2114)  loss_classifier: 5.6385 (5.7428)  loss_box_reg: 0.2208 (0.2394)  loss_objectness: 0.1500 (0.1529)  loss_rpn_box_reg: 0.0736 (0.0764)  time: 0.6154  data: 0.1357  max mem: 10714\n",
      "Training Epoch: [10]  [490/500]  eta: 0:00:06  lr: 0.000050  loss: 6.3066 (6.2126)  loss_classifier: 5.9265 (5.7449)  loss_box_reg: 0.2402 (0.2389)  loss_objectness: 0.1398 (0.1526)  loss_rpn_box_reg: 0.0704 (0.0762)  time: 0.6146  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [10]  [499/500]  eta: 0:00:00  lr: 0.000050  loss: 6.1039 (6.2117)  loss_classifier: 5.7072 (5.7441)  loss_box_reg: 0.2267 (0.2389)  loss_objectness: 0.1398 (0.1524)  loss_rpn_box_reg: 0.0704 (0.0763)  time: 0.6198  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [10] Total time: 0:05:10 (0.6213 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:53  model_time: 0.7202 (0.7202)  evaluator_time: 0.0340 (0.0340)  time: 0.9052  data: 0.1420  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4321 (0.4445)  evaluator_time: 0.0340 (0.0338)  time: 0.6293  data: 0.1542  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4681 (0.4466)  evaluator_time: 0.0360 (0.0347)  time: 0.6489  data: 0.1481  max mem: 10714\n",
      "Test: Total time: 0:01:19 (0.6345 s / it)\n",
      "Averaged stats: model_time: 0.4681 (0.4466)  evaluator_time: 0.0360 (0.0347)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.177\n",
      "Testing Epoch: [10]  [  0/125]  eta: 0:01:29  lr: 0.000050  loss: 6.2056 (6.2056)  loss_classifier: 5.6549 (5.6549)  loss_box_reg: 0.2890 (0.2890)  loss_objectness: 0.1307 (0.1307)  loss_rpn_box_reg: 0.1310 (0.1310)  time: 0.7182  data: 0.2201  max mem: 10714\n",
      "Testing Epoch: [10]  [100/125]  eta: 0:00:14  lr: 0.000050  loss: 6.0046 (6.1209)  loss_classifier: 5.4357 (5.6109)  loss_box_reg: 0.2683 (0.2893)  loss_objectness: 0.1303 (0.1309)  loss_rpn_box_reg: 0.0702 (0.0898)  time: 0.5803  data: 0.1447  max mem: 10714\n",
      "Testing Epoch: [10]  [124/125]  eta: 0:00:00  lr: 0.000050  loss: 6.1479 (6.1554)  loss_classifier: 5.7009 (5.6497)  loss_box_reg: 0.2442 (0.2847)  loss_objectness: 0.1181 (0.1310)  loss_rpn_box_reg: 0.0745 (0.0899)  time: 0.5959  data: 0.1440  max mem: 10714\n",
      "Testing Epoch: [10] Total time: 0:01:14 (0.5934 s / it)\n",
      "Training Epoch: [11]  [  0/500]  eta: 0:04:28  lr: 0.000050  loss: 5.6853 (5.6853)  loss_classifier: 5.1833 (5.1833)  loss_box_reg: 0.2618 (0.2618)  loss_objectness: 0.1341 (0.1341)  loss_rpn_box_reg: 0.1061 (0.1061)  time: 0.5361  data: 0.1280  max mem: 10714\n",
      "Training Epoch: [11]  [ 10/500]  eta: 0:04:58  lr: 0.000050  loss: 5.7426 (5.8385)  loss_classifier: 5.1833 (5.3474)  loss_box_reg: 0.2618 (0.2605)  loss_objectness: 0.1315 (0.1404)  loss_rpn_box_reg: 0.0807 (0.0902)  time: 0.6100  data: 0.1326  max mem: 10714\n",
      "Training Epoch: [11]  [ 20/500]  eta: 0:04:57  lr: 0.000050  loss: 5.7433 (5.9066)  loss_classifier: 5.2584 (5.4293)  loss_box_reg: 0.2462 (0.2506)  loss_objectness: 0.1415 (0.1424)  loss_rpn_box_reg: 0.0716 (0.0844)  time: 0.6248  data: 0.1329  max mem: 10714\n",
      "Training Epoch: [11]  [ 30/500]  eta: 0:04:53  lr: 0.000050  loss: 6.1461 (5.9917)  loss_classifier: 5.6017 (5.5304)  loss_box_reg: 0.2187 (0.2387)  loss_objectness: 0.1512 (0.1419)  loss_rpn_box_reg: 0.0639 (0.0807)  time: 0.6313  data: 0.1335  max mem: 10714\n",
      "Training Epoch: [11]  [ 40/500]  eta: 0:04:46  lr: 0.000050  loss: 6.3133 (6.1127)  loss_classifier: 5.8225 (5.6455)  loss_box_reg: 0.2114 (0.2367)  loss_objectness: 0.1567 (0.1507)  loss_rpn_box_reg: 0.0665 (0.0798)  time: 0.6230  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [11]  [ 50/500]  eta: 0:04:40  lr: 0.000050  loss: 6.2526 (6.1205)  loss_classifier: 5.8311 (5.6546)  loss_box_reg: 0.2104 (0.2365)  loss_objectness: 0.1567 (0.1511)  loss_rpn_box_reg: 0.0665 (0.0784)  time: 0.6213  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [11]  [ 60/500]  eta: 0:04:33  lr: 0.000050  loss: 6.1846 (6.1142)  loss_classifier: 5.6933 (5.6551)  loss_box_reg: 0.2104 (0.2340)  loss_objectness: 0.1442 (0.1489)  loss_rpn_box_reg: 0.0636 (0.0761)  time: 0.6239  data: 0.1336  max mem: 10714\n",
      "Training Epoch: [11]  [ 70/500]  eta: 0:04:27  lr: 0.000050  loss: 6.2370 (6.1647)  loss_classifier: 5.8211 (5.7062)  loss_box_reg: 0.2074 (0.2343)  loss_objectness: 0.1369 (0.1485)  loss_rpn_box_reg: 0.0691 (0.0757)  time: 0.6203  data: 0.1318  max mem: 10714\n",
      "Training Epoch: [11]  [ 80/500]  eta: 0:04:21  lr: 0.000050  loss: 6.6150 (6.2292)  loss_classifier: 6.1568 (5.7739)  loss_box_reg: 0.1964 (0.2292)  loss_objectness: 0.1517 (0.1499)  loss_rpn_box_reg: 0.0716 (0.0762)  time: 0.6234  data: 0.1320  max mem: 10714\n",
      "Training Epoch: [11]  [ 90/500]  eta: 0:04:16  lr: 0.000050  loss: 6.2804 (6.2230)  loss_classifier: 5.8763 (5.7693)  loss_box_reg: 0.2044 (0.2294)  loss_objectness: 0.1403 (0.1486)  loss_rpn_box_reg: 0.0678 (0.0757)  time: 0.6377  data: 0.1324  max mem: 10714\n",
      "Training Epoch: [11]  [100/500]  eta: 0:04:10  lr: 0.000050  loss: 6.2477 (6.2442)  loss_classifier: 5.8121 (5.7855)  loss_box_reg: 0.2114 (0.2321)  loss_objectness: 0.1449 (0.1506)  loss_rpn_box_reg: 0.0714 (0.0761)  time: 0.6403  data: 0.1368  max mem: 10714\n",
      "Training Epoch: [11]  [110/500]  eta: 0:04:04  lr: 0.000050  loss: 6.2696 (6.2333)  loss_classifier: 5.7829 (5.7752)  loss_box_reg: 0.2309 (0.2324)  loss_objectness: 0.1532 (0.1498)  loss_rpn_box_reg: 0.0726 (0.0758)  time: 0.6262  data: 0.1363  max mem: 10714\n",
      "Training Epoch: [11]  [120/500]  eta: 0:03:57  lr: 0.000050  loss: 6.1630 (6.2536)  loss_classifier: 5.7056 (5.7948)  loss_box_reg: 0.2494 (0.2331)  loss_objectness: 0.1342 (0.1500)  loss_rpn_box_reg: 0.0654 (0.0758)  time: 0.6216  data: 0.1326  max mem: 10714\n",
      "Training Epoch: [11]  [130/500]  eta: 0:03:51  lr: 0.000050  loss: 6.3703 (6.2572)  loss_classifier: 5.7664 (5.7977)  loss_box_reg: 0.2472 (0.2334)  loss_objectness: 0.1436 (0.1504)  loss_rpn_box_reg: 0.0690 (0.0756)  time: 0.6194  data: 0.1315  max mem: 10714\n",
      "Training Epoch: [11]  [140/500]  eta: 0:03:44  lr: 0.000050  loss: 6.1268 (6.2503)  loss_classifier: 5.6280 (5.7882)  loss_box_reg: 0.2382 (0.2351)  loss_objectness: 0.1559 (0.1508)  loss_rpn_box_reg: 0.0690 (0.0762)  time: 0.6205  data: 0.1317  max mem: 10714\n",
      "Training Epoch: [11]  [150/500]  eta: 0:03:38  lr: 0.000050  loss: 6.1268 (6.2492)  loss_classifier: 5.5630 (5.7838)  loss_box_reg: 0.2499 (0.2366)  loss_objectness: 0.1477 (0.1512)  loss_rpn_box_reg: 0.0810 (0.0776)  time: 0.6219  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [11]  [160/500]  eta: 0:03:32  lr: 0.000050  loss: 6.0815 (6.2406)  loss_classifier: 5.5630 (5.7762)  loss_box_reg: 0.2476 (0.2365)  loss_objectness: 0.1431 (0.1508)  loss_rpn_box_reg: 0.0781 (0.0771)  time: 0.6228  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [11]  [170/500]  eta: 0:03:25  lr: 0.000050  loss: 6.0940 (6.2368)  loss_classifier: 5.6241 (5.7733)  loss_box_reg: 0.2401 (0.2364)  loss_objectness: 0.1431 (0.1510)  loss_rpn_box_reg: 0.0690 (0.0761)  time: 0.6189  data: 0.1317  max mem: 10714\n",
      "Training Epoch: [11]  [180/500]  eta: 0:03:19  lr: 0.000050  loss: 6.3475 (6.2352)  loss_classifier: 5.8507 (5.7722)  loss_box_reg: 0.2468 (0.2366)  loss_objectness: 0.1502 (0.1511)  loss_rpn_box_reg: 0.0575 (0.0753)  time: 0.6186  data: 0.1326  max mem: 10714\n",
      "Training Epoch: [11]  [190/500]  eta: 0:03:13  lr: 0.000050  loss: 6.1883 (6.2323)  loss_classifier: 5.7346 (5.7671)  loss_box_reg: 0.2601 (0.2383)  loss_objectness: 0.1522 (0.1517)  loss_rpn_box_reg: 0.0594 (0.0751)  time: 0.6268  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [11]  [200/500]  eta: 0:03:07  lr: 0.000050  loss: 6.0843 (6.2241)  loss_classifier: 5.6225 (5.7597)  loss_box_reg: 0.2321 (0.2375)  loss_objectness: 0.1522 (0.1516)  loss_rpn_box_reg: 0.0604 (0.0753)  time: 0.6240  data: 0.1356  max mem: 10714\n",
      "Training Epoch: [11]  [210/500]  eta: 0:03:01  lr: 0.000050  loss: 6.0843 (6.2139)  loss_classifier: 5.6225 (5.7501)  loss_box_reg: 0.2367 (0.2382)  loss_objectness: 0.1459 (0.1507)  loss_rpn_box_reg: 0.0589 (0.0748)  time: 0.6260  data: 0.1329  max mem: 10714\n",
      "Training Epoch: [11]  [220/500]  eta: 0:02:54  lr: 0.000050  loss: 5.9520 (6.2017)  loss_classifier: 5.4949 (5.7387)  loss_box_reg: 0.2395 (0.2379)  loss_objectness: 0.1466 (0.1506)  loss_rpn_box_reg: 0.0570 (0.0744)  time: 0.6204  data: 0.1324  max mem: 10714\n",
      "Training Epoch: [11]  [230/500]  eta: 0:02:48  lr: 0.000050  loss: 6.0605 (6.2020)  loss_classifier: 5.6043 (5.7370)  loss_box_reg: 0.2620 (0.2393)  loss_objectness: 0.1520 (0.1509)  loss_rpn_box_reg: 0.0691 (0.0749)  time: 0.6143  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [11]  [240/500]  eta: 0:02:41  lr: 0.000050  loss: 6.0631 (6.1926)  loss_classifier: 5.6043 (5.7290)  loss_box_reg: 0.2330 (0.2383)  loss_objectness: 0.1520 (0.1509)  loss_rpn_box_reg: 0.0691 (0.0745)  time: 0.6114  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [11]  [250/500]  eta: 0:02:35  lr: 0.000050  loss: 6.1400 (6.2014)  loss_classifier: 5.6607 (5.7365)  loss_box_reg: 0.2035 (0.2383)  loss_objectness: 0.1568 (0.1520)  loss_rpn_box_reg: 0.0646 (0.0746)  time: 0.5954  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [11]  [260/500]  eta: 0:02:29  lr: 0.000050  loss: 6.3845 (6.2068)  loss_classifier: 5.9087 (5.7442)  loss_box_reg: 0.1995 (0.2370)  loss_objectness: 0.1427 (0.1515)  loss_rpn_box_reg: 0.0584 (0.0742)  time: 0.6036  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [11]  [270/500]  eta: 0:02:22  lr: 0.000050  loss: 6.0681 (6.1979)  loss_classifier: 5.6653 (5.7359)  loss_box_reg: 0.1954 (0.2368)  loss_objectness: 0.1398 (0.1513)  loss_rpn_box_reg: 0.0635 (0.0739)  time: 0.6218  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [11]  [280/500]  eta: 0:02:16  lr: 0.000050  loss: 6.0219 (6.2070)  loss_classifier: 5.5158 (5.7453)  loss_box_reg: 0.2060 (0.2366)  loss_objectness: 0.1443 (0.1512)  loss_rpn_box_reg: 0.0662 (0.0739)  time: 0.6223  data: 0.1357  max mem: 10714\n",
      "Training Epoch: [11]  [290/500]  eta: 0:02:10  lr: 0.000050  loss: 6.3088 (6.2168)  loss_classifier: 5.9065 (5.7539)  loss_box_reg: 0.2110 (0.2373)  loss_objectness: 0.1586 (0.1511)  loss_rpn_box_reg: 0.0662 (0.0744)  time: 0.6163  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [11]  [300/500]  eta: 0:02:04  lr: 0.000050  loss: 6.2955 (6.2253)  loss_classifier: 5.8390 (5.7611)  loss_box_reg: 0.2374 (0.2378)  loss_objectness: 0.1599 (0.1514)  loss_rpn_box_reg: 0.0933 (0.0750)  time: 0.6230  data: 0.1336  max mem: 10714\n",
      "Training Epoch: [11]  [310/500]  eta: 0:01:58  lr: 0.000050  loss: 6.1847 (6.2218)  loss_classifier: 5.7520 (5.7574)  loss_box_reg: 0.2449 (0.2380)  loss_objectness: 0.1405 (0.1511)  loss_rpn_box_reg: 0.0761 (0.0754)  time: 0.6306  data: 0.1345  max mem: 10714\n",
      "Training Epoch: [11]  [320/500]  eta: 0:01:51  lr: 0.000050  loss: 6.2514 (6.2219)  loss_classifier: 5.7372 (5.7565)  loss_box_reg: 0.2421 (0.2387)  loss_objectness: 0.1448 (0.1511)  loss_rpn_box_reg: 0.0748 (0.0756)  time: 0.6291  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [11]  [330/500]  eta: 0:01:45  lr: 0.000050  loss: 6.0043 (6.2200)  loss_classifier: 5.6246 (5.7535)  loss_box_reg: 0.2744 (0.2403)  loss_objectness: 0.1446 (0.1508)  loss_rpn_box_reg: 0.0651 (0.0754)  time: 0.6379  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [11]  [340/500]  eta: 0:01:39  lr: 0.000050  loss: 6.2911 (6.2286)  loss_classifier: 5.6339 (5.7598)  loss_box_reg: 0.2631 (0.2406)  loss_objectness: 0.1453 (0.1518)  loss_rpn_box_reg: 0.0745 (0.0764)  time: 0.6303  data: 0.1364  max mem: 10714\n",
      "Training Epoch: [11]  [350/500]  eta: 0:01:33  lr: 0.000050  loss: 6.4403 (6.2323)  loss_classifier: 5.7728 (5.7620)  loss_box_reg: 0.2616 (0.2413)  loss_objectness: 0.1761 (0.1524)  loss_rpn_box_reg: 0.0940 (0.0767)  time: 0.6191  data: 0.1353  max mem: 10714\n",
      "Training Epoch: [11]  [360/500]  eta: 0:01:27  lr: 0.000050  loss: 6.1325 (6.2279)  loss_classifier: 5.5684 (5.7577)  loss_box_reg: 0.2303 (0.2412)  loss_objectness: 0.1536 (0.1523)  loss_rpn_box_reg: 0.0821 (0.0767)  time: 0.6228  data: 0.1323  max mem: 10714\n",
      "Training Epoch: [11]  [370/500]  eta: 0:01:20  lr: 0.000050  loss: 6.0884 (6.2322)  loss_classifier: 5.7028 (5.7629)  loss_box_reg: 0.2174 (0.2404)  loss_objectness: 0.1442 (0.1523)  loss_rpn_box_reg: 0.0687 (0.0766)  time: 0.6310  data: 0.1330  max mem: 10714\n",
      "Training Epoch: [11]  [380/500]  eta: 0:01:14  lr: 0.000050  loss: 6.1949 (6.2315)  loss_classifier: 5.7622 (5.7618)  loss_box_reg: 0.2317 (0.2416)  loss_objectness: 0.1378 (0.1519)  loss_rpn_box_reg: 0.0603 (0.0761)  time: 0.6322  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [11]  [390/500]  eta: 0:01:08  lr: 0.000050  loss: 6.1949 (6.2344)  loss_classifier: 5.6907 (5.7644)  loss_box_reg: 0.2464 (0.2415)  loss_objectness: 0.1388 (0.1522)  loss_rpn_box_reg: 0.0610 (0.0762)  time: 0.6209  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [11]  [400/500]  eta: 0:01:02  lr: 0.000050  loss: 6.2645 (6.2295)  loss_classifier: 5.8095 (5.7598)  loss_box_reg: 0.2464 (0.2417)  loss_objectness: 0.1408 (0.1519)  loss_rpn_box_reg: 0.0735 (0.0761)  time: 0.6171  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [11]  [410/500]  eta: 0:00:56  lr: 0.000050  loss: 6.2288 (6.2295)  loss_classifier: 5.7557 (5.7592)  loss_box_reg: 0.2638 (0.2421)  loss_objectness: 0.1522 (0.1523)  loss_rpn_box_reg: 0.0684 (0.0760)  time: 0.6230  data: 0.1331  max mem: 10714\n",
      "Training Epoch: [11]  [420/500]  eta: 0:00:49  lr: 0.000050  loss: 6.0839 (6.2253)  loss_classifier: 5.6839 (5.7548)  loss_box_reg: 0.2173 (0.2421)  loss_objectness: 0.1522 (0.1521)  loss_rpn_box_reg: 0.0729 (0.0763)  time: 0.6097  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [11]  [430/500]  eta: 0:00:43  lr: 0.000050  loss: 6.0018 (6.2227)  loss_classifier: 5.4761 (5.7513)  loss_box_reg: 0.2441 (0.2428)  loss_objectness: 0.1473 (0.1522)  loss_rpn_box_reg: 0.0747 (0.0765)  time: 0.6054  data: 0.1364  max mem: 10714\n",
      "Training Epoch: [11]  [440/500]  eta: 0:00:37  lr: 0.000050  loss: 6.1571 (6.2230)  loss_classifier: 5.6524 (5.7517)  loss_box_reg: 0.2441 (0.2428)  loss_objectness: 0.1457 (0.1521)  loss_rpn_box_reg: 0.0732 (0.0765)  time: 0.6158  data: 0.1357  max mem: 10714\n",
      "Training Epoch: [11]  [450/500]  eta: 0:00:31  lr: 0.000050  loss: 6.1571 (6.2197)  loss_classifier: 5.7896 (5.7488)  loss_box_reg: 0.2240 (0.2429)  loss_objectness: 0.1373 (0.1518)  loss_rpn_box_reg: 0.0560 (0.0761)  time: 0.6310  data: 0.1326  max mem: 10714\n",
      "Training Epoch: [11]  [460/500]  eta: 0:00:24  lr: 0.000050  loss: 5.9996 (6.2171)  loss_classifier: 5.5392 (5.7466)  loss_box_reg: 0.2361 (0.2428)  loss_objectness: 0.1267 (0.1515)  loss_rpn_box_reg: 0.0664 (0.0762)  time: 0.6329  data: 0.1328  max mem: 10714\n",
      "Training Epoch: [11]  [470/500]  eta: 0:00:18  lr: 0.000050  loss: 5.9996 (6.2136)  loss_classifier: 5.5265 (5.7435)  loss_box_reg: 0.2056 (0.2421)  loss_objectness: 0.1472 (0.1516)  loss_rpn_box_reg: 0.0762 (0.0763)  time: 0.6246  data: 0.1340  max mem: 10714\n",
      "Training Epoch: [11]  [480/500]  eta: 0:00:12  lr: 0.000050  loss: 6.0576 (6.2134)  loss_classifier: 5.5526 (5.7437)  loss_box_reg: 0.2056 (0.2417)  loss_objectness: 0.1488 (0.1517)  loss_rpn_box_reg: 0.0759 (0.0763)  time: 0.6339  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [11]  [490/500]  eta: 0:00:06  lr: 0.000050  loss: 6.1186 (6.2121)  loss_classifier: 5.6654 (5.7426)  loss_box_reg: 0.2186 (0.2413)  loss_objectness: 0.1409 (0.1519)  loss_rpn_box_reg: 0.0726 (0.0763)  time: 0.6302  data: 0.1371  max mem: 10714\n",
      "Training Epoch: [11]  [499/500]  eta: 0:00:00  lr: 0.000050  loss: 6.1847 (6.2150)  loss_classifier: 5.7945 (5.7460)  loss_box_reg: 0.2201 (0.2410)  loss_objectness: 0.1434 (0.1520)  loss_rpn_box_reg: 0.0602 (0.0760)  time: 0.6255  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [11] Total time: 0:05:11 (0.6228 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:55  model_time: 0.7362 (0.7362)  evaluator_time: 0.0340 (0.0340)  time: 0.9212  data: 0.1420  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4461 (0.4491)  evaluator_time: 0.0340 (0.0358)  time: 0.6287  data: 0.1478  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4661 (0.4505)  evaluator_time: 0.0360 (0.0364)  time: 0.6580  data: 0.1554  max mem: 10714\n",
      "Test: Total time: 0:01:19 (0.6385 s / it)\n",
      "Averaged stats: model_time: 0.4661 (0.4505)  evaluator_time: 0.0360 (0.0364)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.180\n",
      "Testing Epoch: [11]  [  0/125]  eta: 0:01:20  lr: 0.000050  loss: 6.1974 (6.1974)  loss_classifier: 5.6373 (5.6373)  loss_box_reg: 0.2961 (0.2961)  loss_objectness: 0.1317 (0.1317)  loss_rpn_box_reg: 0.1323 (0.1323)  time: 0.6401  data: 0.1420  max mem: 10714\n",
      "Testing Epoch: [11]  [100/125]  eta: 0:00:14  lr: 0.000050  loss: 5.9782 (6.1295)  loss_classifier: 5.4496 (5.6212)  loss_box_reg: 0.2622 (0.2881)  loss_objectness: 0.1289 (0.1313)  loss_rpn_box_reg: 0.0695 (0.0889)  time: 0.5872  data: 0.1475  max mem: 10714\n",
      "Testing Epoch: [11]  [124/125]  eta: 0:00:00  lr: 0.000050  loss: 6.1587 (6.1617)  loss_classifier: 5.6830 (5.6574)  loss_box_reg: 0.2498 (0.2839)  loss_objectness: 0.1201 (0.1313)  loss_rpn_box_reg: 0.0744 (0.0891)  time: 0.5980  data: 0.1461  max mem: 10714\n",
      "Testing Epoch: [11] Total time: 0:01:14 (0.5947 s / it)\n",
      "Training Epoch: [12]  [  0/500]  eta: 0:04:55  lr: 0.000050  loss: 6.0172 (6.0172)  loss_classifier: 5.5555 (5.5555)  loss_box_reg: 0.2173 (0.2173)  loss_objectness: 0.1445 (0.1445)  loss_rpn_box_reg: 0.0999 (0.0999)  time: 0.5911  data: 0.1370  max mem: 10714\n",
      "Training Epoch: [12]  [ 10/500]  eta: 0:05:04  lr: 0.000050  loss: 6.3485 (6.3010)  loss_classifier: 5.9369 (5.8236)  loss_box_reg: 0.2516 (0.2495)  loss_objectness: 0.1463 (0.1551)  loss_rpn_box_reg: 0.0676 (0.0728)  time: 0.6218  data: 0.1333  max mem: 10714\n",
      "Training Epoch: [12]  [ 20/500]  eta: 0:05:01  lr: 0.000050  loss: 6.1837 (6.2719)  loss_classifier: 5.6828 (5.8031)  loss_box_reg: 0.2507 (0.2463)  loss_objectness: 0.1488 (0.1509)  loss_rpn_box_reg: 0.0676 (0.0716)  time: 0.6304  data: 0.1329  max mem: 10714\n",
      "Training Epoch: [12]  [ 30/500]  eta: 0:04:51  lr: 0.000050  loss: 6.1203 (6.2682)  loss_classifier: 5.6683 (5.7997)  loss_box_reg: 0.2306 (0.2397)  loss_objectness: 0.1562 (0.1558)  loss_rpn_box_reg: 0.0716 (0.0732)  time: 0.6201  data: 0.1334  max mem: 10714\n",
      "Training Epoch: [12]  [ 40/500]  eta: 0:04:44  lr: 0.000050  loss: 6.1203 (6.2534)  loss_classifier: 5.6683 (5.7814)  loss_box_reg: 0.2252 (0.2439)  loss_objectness: 0.1566 (0.1553)  loss_rpn_box_reg: 0.0716 (0.0728)  time: 0.6059  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [12]  [ 50/500]  eta: 0:04:38  lr: 0.000050  loss: 6.0322 (6.1882)  loss_classifier: 5.5325 (5.7260)  loss_box_reg: 0.2313 (0.2405)  loss_objectness: 0.1356 (0.1512)  loss_rpn_box_reg: 0.0599 (0.0704)  time: 0.6133  data: 0.1320  max mem: 10714\n",
      "Training Epoch: [12]  [ 60/500]  eta: 0:04:31  lr: 0.000050  loss: 6.1199 (6.2097)  loss_classifier: 5.6104 (5.7494)  loss_box_reg: 0.2313 (0.2406)  loss_objectness: 0.1330 (0.1498)  loss_rpn_box_reg: 0.0653 (0.0699)  time: 0.6192  data: 0.1314  max mem: 10714\n",
      "Training Epoch: [12]  [ 70/500]  eta: 0:04:25  lr: 0.000050  loss: 6.2732 (6.2089)  loss_classifier: 5.7572 (5.7419)  loss_box_reg: 0.2395 (0.2420)  loss_objectness: 0.1460 (0.1528)  loss_rpn_box_reg: 0.0723 (0.0722)  time: 0.6141  data: 0.1359  max mem: 10714\n",
      "Training Epoch: [12]  [ 80/500]  eta: 0:04:19  lr: 0.000050  loss: 6.2732 (6.1971)  loss_classifier: 5.7307 (5.7273)  loss_box_reg: 0.2300 (0.2427)  loss_objectness: 0.1527 (0.1532)  loss_rpn_box_reg: 0.0808 (0.0740)  time: 0.6167  data: 0.1357  max mem: 10714\n",
      "Training Epoch: [12]  [ 90/500]  eta: 0:04:13  lr: 0.000050  loss: 6.0848 (6.2046)  loss_classifier: 5.6675 (5.7430)  loss_box_reg: 0.1988 (0.2380)  loss_objectness: 0.1423 (0.1505)  loss_rpn_box_reg: 0.0716 (0.0731)  time: 0.6266  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [12]  [100/500]  eta: 0:04:07  lr: 0.000050  loss: 6.1520 (6.2219)  loss_classifier: 5.7263 (5.7577)  loss_box_reg: 0.2095 (0.2404)  loss_objectness: 0.1423 (0.1516)  loss_rpn_box_reg: 0.0616 (0.0722)  time: 0.6261  data: 0.1362  max mem: 10714\n",
      "Training Epoch: [12]  [110/500]  eta: 0:04:01  lr: 0.000050  loss: 6.3780 (6.2219)  loss_classifier: 5.9255 (5.7555)  loss_box_reg: 0.2664 (0.2421)  loss_objectness: 0.1558 (0.1511)  loss_rpn_box_reg: 0.0664 (0.0732)  time: 0.6255  data: 0.1359  max mem: 10714\n",
      "Training Epoch: [12]  [120/500]  eta: 0:03:56  lr: 0.000050  loss: 6.2812 (6.2414)  loss_classifier: 5.8266 (5.7758)  loss_box_reg: 0.2286 (0.2413)  loss_objectness: 0.1441 (0.1507)  loss_rpn_box_reg: 0.0757 (0.0736)  time: 0.6350  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [12]  [130/500]  eta: 0:03:50  lr: 0.000050  loss: 6.1703 (6.2364)  loss_classifier: 5.6865 (5.7696)  loss_box_reg: 0.2286 (0.2410)  loss_objectness: 0.1534 (0.1507)  loss_rpn_box_reg: 0.0811 (0.0751)  time: 0.6411  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [12]  [140/500]  eta: 0:03:44  lr: 0.000050  loss: 6.0968 (6.2415)  loss_classifier: 5.6627 (5.7762)  loss_box_reg: 0.2209 (0.2391)  loss_objectness: 0.1262 (0.1503)  loss_rpn_box_reg: 0.0789 (0.0759)  time: 0.6354  data: 0.1331  max mem: 10714\n",
      "Training Epoch: [12]  [150/500]  eta: 0:03:38  lr: 0.000050  loss: 6.0574 (6.2208)  loss_classifier: 5.6194 (5.7531)  loss_box_reg: 0.2209 (0.2410)  loss_objectness: 0.1250 (0.1501)  loss_rpn_box_reg: 0.0757 (0.0766)  time: 0.6247  data: 0.1336  max mem: 10714\n",
      "Training Epoch: [12]  [160/500]  eta: 0:03:32  lr: 0.000050  loss: 6.0393 (6.2117)  loss_classifier: 5.5271 (5.7475)  loss_box_reg: 0.2158 (0.2394)  loss_objectness: 0.1398 (0.1494)  loss_rpn_box_reg: 0.0633 (0.0755)  time: 0.6275  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [12]  [170/500]  eta: 0:03:26  lr: 0.000050  loss: 6.0933 (6.2233)  loss_classifier: 5.7080 (5.7584)  loss_box_reg: 0.2100 (0.2393)  loss_objectness: 0.1459 (0.1501)  loss_rpn_box_reg: 0.0575 (0.0756)  time: 0.6417  data: 0.1352  max mem: 10714\n",
      "Training Epoch: [12]  [180/500]  eta: 0:03:20  lr: 0.000050  loss: 6.3273 (6.2289)  loss_classifier: 5.8787 (5.7637)  loss_box_reg: 0.2192 (0.2395)  loss_objectness: 0.1562 (0.1505)  loss_rpn_box_reg: 0.0621 (0.0752)  time: 0.6436  data: 0.1352  max mem: 10714\n",
      "Training Epoch: [12]  [190/500]  eta: 0:03:14  lr: 0.000050  loss: 6.1108 (6.2335)  loss_classifier: 5.8075 (5.7690)  loss_box_reg: 0.2238 (0.2388)  loss_objectness: 0.1538 (0.1509)  loss_rpn_box_reg: 0.0589 (0.0748)  time: 0.6412  data: 0.1336  max mem: 10714\n",
      "Training Epoch: [12]  [200/500]  eta: 0:03:08  lr: 0.000050  loss: 6.0220 (6.2247)  loss_classifier: 5.5970 (5.7582)  loss_box_reg: 0.2240 (0.2403)  loss_objectness: 0.1538 (0.1508)  loss_rpn_box_reg: 0.0689 (0.0753)  time: 0.6317  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [12]  [210/500]  eta: 0:03:01  lr: 0.000050  loss: 6.0100 (6.2239)  loss_classifier: 5.5959 (5.7580)  loss_box_reg: 0.2202 (0.2395)  loss_objectness: 0.1557 (0.1513)  loss_rpn_box_reg: 0.0689 (0.0752)  time: 0.6146  data: 0.1325  max mem: 10714\n",
      "Training Epoch: [12]  [220/500]  eta: 0:02:55  lr: 0.000050  loss: 6.0403 (6.2136)  loss_classifier: 5.5227 (5.7466)  loss_box_reg: 0.2202 (0.2394)  loss_objectness: 0.1635 (0.1523)  loss_rpn_box_reg: 0.0701 (0.0753)  time: 0.6142  data: 0.1329  max mem: 10714\n",
      "Training Epoch: [12]  [230/500]  eta: 0:02:49  lr: 0.000050  loss: 6.0403 (6.2056)  loss_classifier: 5.5227 (5.7402)  loss_box_reg: 0.2210 (0.2387)  loss_objectness: 0.1428 (0.1518)  loss_rpn_box_reg: 0.0781 (0.0750)  time: 0.6312  data: 0.1340  max mem: 10714\n",
      "Training Epoch: [12]  [240/500]  eta: 0:02:42  lr: 0.000050  loss: 6.0817 (6.2057)  loss_classifier: 5.5771 (5.7395)  loss_box_reg: 0.2239 (0.2385)  loss_objectness: 0.1446 (0.1522)  loss_rpn_box_reg: 0.0701 (0.0756)  time: 0.6348  data: 0.1360  max mem: 10714\n",
      "Training Epoch: [12]  [250/500]  eta: 0:02:36  lr: 0.000050  loss: 6.2278 (6.2076)  loss_classifier: 5.7533 (5.7407)  loss_box_reg: 0.2264 (0.2392)  loss_objectness: 0.1426 (0.1520)  loss_rpn_box_reg: 0.0698 (0.0756)  time: 0.6263  data: 0.1365  max mem: 10714\n",
      "Training Epoch: [12]  [260/500]  eta: 0:02:30  lr: 0.000050  loss: 6.2981 (6.2175)  loss_classifier: 5.8455 (5.7510)  loss_box_reg: 0.2473 (0.2388)  loss_objectness: 0.1310 (0.1516)  loss_rpn_box_reg: 0.0747 (0.0762)  time: 0.6270  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [12]  [270/500]  eta: 0:02:23  lr: 0.000050  loss: 6.4606 (6.2206)  loss_classifier: 5.9070 (5.7531)  loss_box_reg: 0.2411 (0.2391)  loss_objectness: 0.1488 (0.1521)  loss_rpn_box_reg: 0.0920 (0.0762)  time: 0.6162  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [12]  [280/500]  eta: 0:02:17  lr: 0.000050  loss: 6.2038 (6.2202)  loss_classifier: 5.6905 (5.7535)  loss_box_reg: 0.2448 (0.2392)  loss_objectness: 0.1573 (0.1519)  loss_rpn_box_reg: 0.0690 (0.0757)  time: 0.6113  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [12]  [290/500]  eta: 0:02:11  lr: 0.000050  loss: 6.1777 (6.2258)  loss_classifier: 5.6628 (5.7594)  loss_box_reg: 0.2355 (0.2391)  loss_objectness: 0.1355 (0.1518)  loss_rpn_box_reg: 0.0652 (0.0755)  time: 0.6188  data: 0.1328  max mem: 10714\n",
      "Training Epoch: [12]  [300/500]  eta: 0:02:05  lr: 0.000050  loss: 6.1837 (6.2288)  loss_classifier: 5.7144 (5.7615)  loss_box_reg: 0.2355 (0.2395)  loss_objectness: 0.1574 (0.1521)  loss_rpn_box_reg: 0.0747 (0.0758)  time: 0.6206  data: 0.1323  max mem: 10714\n",
      "Training Epoch: [12]  [310/500]  eta: 0:01:58  lr: 0.000050  loss: 6.1771 (6.2284)  loss_classifier: 5.6744 (5.7613)  loss_box_reg: 0.2315 (0.2396)  loss_objectness: 0.1427 (0.1518)  loss_rpn_box_reg: 0.0792 (0.0757)  time: 0.6228  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [12]  [320/500]  eta: 0:01:52  lr: 0.000050  loss: 6.2094 (6.2288)  loss_classifier: 5.7032 (5.7621)  loss_box_reg: 0.2297 (0.2399)  loss_objectness: 0.1321 (0.1512)  loss_rpn_box_reg: 0.0675 (0.0755)  time: 0.6311  data: 0.1345  max mem: 10714\n",
      "Training Epoch: [12]  [330/500]  eta: 0:01:46  lr: 0.000050  loss: 6.2200 (6.2269)  loss_classifier: 5.6590 (5.7608)  loss_box_reg: 0.2234 (0.2392)  loss_objectness: 0.1422 (0.1515)  loss_rpn_box_reg: 0.0696 (0.0754)  time: 0.6299  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [12]  [340/500]  eta: 0:01:39  lr: 0.000050  loss: 6.2309 (6.2259)  loss_classifier: 5.6590 (5.7592)  loss_box_reg: 0.2234 (0.2392)  loss_objectness: 0.1482 (0.1516)  loss_rpn_box_reg: 0.0700 (0.0759)  time: 0.6087  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [12]  [350/500]  eta: 0:01:33  lr: 0.000050  loss: 5.9511 (6.2200)  loss_classifier: 5.5188 (5.7543)  loss_box_reg: 0.2121 (0.2386)  loss_objectness: 0.1474 (0.1515)  loss_rpn_box_reg: 0.0592 (0.0756)  time: 0.6124  data: 0.1334  max mem: 10714\n",
      "Training Epoch: [12]  [360/500]  eta: 0:01:27  lr: 0.000050  loss: 5.9511 (6.2201)  loss_classifier: 5.5122 (5.7536)  loss_box_reg: 0.2399 (0.2391)  loss_objectness: 0.1427 (0.1517)  loss_rpn_box_reg: 0.0605 (0.0757)  time: 0.6248  data: 0.1326  max mem: 10714\n",
      "Training Epoch: [12]  [370/500]  eta: 0:01:21  lr: 0.000050  loss: 6.1293 (6.2157)  loss_classifier: 5.6296 (5.7497)  loss_box_reg: 0.2531 (0.2390)  loss_objectness: 0.1432 (0.1516)  loss_rpn_box_reg: 0.0611 (0.0755)  time: 0.6249  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [12]  [380/500]  eta: 0:01:14  lr: 0.000050  loss: 5.9956 (6.2123)  loss_classifier: 5.6461 (5.7466)  loss_box_reg: 0.2261 (0.2386)  loss_objectness: 0.1488 (0.1515)  loss_rpn_box_reg: 0.0717 (0.0756)  time: 0.6257  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [12]  [390/500]  eta: 0:01:08  lr: 0.000050  loss: 6.0429 (6.2142)  loss_classifier: 5.6941 (5.7495)  loss_box_reg: 0.2101 (0.2379)  loss_objectness: 0.1449 (0.1513)  loss_rpn_box_reg: 0.0773 (0.0755)  time: 0.6111  data: 0.1316  max mem: 10714\n",
      "Training Epoch: [12]  [400/500]  eta: 0:01:02  lr: 0.000050  loss: 6.1991 (6.2120)  loss_classifier: 5.8060 (5.7469)  loss_box_reg: 0.2210 (0.2383)  loss_objectness: 0.1346 (0.1513)  loss_rpn_box_reg: 0.0597 (0.0754)  time: 0.6056  data: 0.1324  max mem: 10714\n",
      "Training Epoch: [12]  [410/500]  eta: 0:00:56  lr: 0.000050  loss: 6.3966 (6.2151)  loss_classifier: 5.8159 (5.7487)  loss_box_reg: 0.2613 (0.2390)  loss_objectness: 0.1434 (0.1517)  loss_rpn_box_reg: 0.0761 (0.0758)  time: 0.6226  data: 0.1376  max mem: 10714\n",
      "Training Epoch: [12]  [420/500]  eta: 0:00:49  lr: 0.000050  loss: 6.1851 (6.2142)  loss_classifier: 5.7079 (5.7467)  loss_box_reg: 0.2470 (0.2395)  loss_objectness: 0.1703 (0.1521)  loss_rpn_box_reg: 0.0761 (0.0759)  time: 0.6239  data: 0.1374  max mem: 10714\n",
      "Training Epoch: [12]  [430/500]  eta: 0:00:43  lr: 0.000050  loss: 6.0782 (6.2095)  loss_classifier: 5.5857 (5.7420)  loss_box_reg: 0.2465 (0.2396)  loss_objectness: 0.1367 (0.1517)  loss_rpn_box_reg: 0.0740 (0.0763)  time: 0.6127  data: 0.1326  max mem: 10714\n",
      "Training Epoch: [12]  [440/500]  eta: 0:00:37  lr: 0.000050  loss: 6.1429 (6.2111)  loss_classifier: 5.7050 (5.7437)  loss_box_reg: 0.2118 (0.2394)  loss_objectness: 0.1381 (0.1518)  loss_rpn_box_reg: 0.0746 (0.0762)  time: 0.6085  data: 0.1319  max mem: 10714\n",
      "Training Epoch: [12]  [450/500]  eta: 0:00:31  lr: 0.000050  loss: 6.1586 (6.2090)  loss_classifier: 5.7090 (5.7409)  loss_box_reg: 0.2331 (0.2401)  loss_objectness: 0.1511 (0.1520)  loss_rpn_box_reg: 0.0649 (0.0761)  time: 0.6013  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [12]  [460/500]  eta: 0:00:24  lr: 0.000050  loss: 6.1586 (6.2154)  loss_classifier: 5.6579 (5.7477)  loss_box_reg: 0.2167 (0.2397)  loss_objectness: 0.1526 (0.1522)  loss_rpn_box_reg: 0.0588 (0.0759)  time: 0.6192  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [12]  [470/500]  eta: 0:00:18  lr: 0.000050  loss: 6.1384 (6.2106)  loss_classifier: 5.6579 (5.7415)  loss_box_reg: 0.2374 (0.2403)  loss_objectness: 0.1515 (0.1525)  loss_rpn_box_reg: 0.0773 (0.0764)  time: 0.6256  data: 0.1336  max mem: 10714\n",
      "Training Epoch: [12]  [480/500]  eta: 0:00:12  lr: 0.000050  loss: 6.2622 (6.2146)  loss_classifier: 5.7222 (5.7459)  loss_box_reg: 0.2475 (0.2402)  loss_objectness: 0.1414 (0.1521)  loss_rpn_box_reg: 0.0823 (0.0764)  time: 0.6253  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [12]  [490/500]  eta: 0:00:06  lr: 0.000050  loss: 6.3004 (6.2143)  loss_classifier: 5.8402 (5.7467)  loss_box_reg: 0.2298 (0.2396)  loss_objectness: 0.1322 (0.1519)  loss_rpn_box_reg: 0.0641 (0.0761)  time: 0.6336  data: 0.1326  max mem: 10714\n",
      "Training Epoch: [12]  [499/500]  eta: 0:00:00  lr: 0.000050  loss: 6.1302 (6.2121)  loss_classifier: 5.6570 (5.7447)  loss_box_reg: 0.2086 (0.2394)  loss_objectness: 0.1351 (0.1519)  loss_rpn_box_reg: 0.0635 (0.0761)  time: 0.6208  data: 0.1330  max mem: 10714\n",
      "Training Epoch: [12] Total time: 0:05:11 (0.6230 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:51  model_time: 0.7072 (0.7072)  evaluator_time: 0.0350 (0.0350)  time: 0.8932  data: 0.1420  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4461 (0.4514)  evaluator_time: 0.0340 (0.0353)  time: 0.6321  data: 0.1416  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4711 (0.4534)  evaluator_time: 0.0360 (0.0370)  time: 0.6569  data: 0.1419  max mem: 10714\n",
      "Test: Total time: 0:01:20 (0.6410 s / it)\n",
      "Averaged stats: model_time: 0.4711 (0.4534)  evaluator_time: 0.0360 (0.0370)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.180\n",
      "Testing Epoch: [12]  [  0/125]  eta: 0:01:21  lr: 0.000050  loss: 6.1912 (6.1912)  loss_classifier: 5.6436 (5.6436)  loss_box_reg: 0.2947 (0.2947)  loss_objectness: 0.1202 (0.1202)  loss_rpn_box_reg: 0.1327 (0.1327)  time: 0.6501  data: 0.1490  max mem: 10714\n",
      "Testing Epoch: [12]  [100/125]  eta: 0:00:14  lr: 0.000050  loss: 6.0125 (6.1327)  loss_classifier: 5.4177 (5.6224)  loss_box_reg: 0.2636 (0.2886)  loss_objectness: 0.1269 (0.1323)  loss_rpn_box_reg: 0.0700 (0.0895)  time: 0.5882  data: 0.1473  max mem: 10714\n",
      "Testing Epoch: [12]  [124/125]  eta: 0:00:00  lr: 0.000050  loss: 6.1762 (6.1650)  loss_classifier: 5.6760 (5.6586)  loss_box_reg: 0.2475 (0.2841)  loss_objectness: 0.1200 (0.1325)  loss_rpn_box_reg: 0.0747 (0.0896)  time: 0.5989  data: 0.1452  max mem: 10714\n",
      "Testing Epoch: [12] Total time: 0:01:14 (0.5968 s / it)\n",
      "Training Epoch: [13]  [  0/500]  eta: 0:07:02  lr: 0.000005  loss: 6.5965 (6.5965)  loss_classifier: 6.0997 (6.0997)  loss_box_reg: 0.1862 (0.1862)  loss_objectness: 0.2455 (0.2455)  loss_rpn_box_reg: 0.0650 (0.0650)  time: 0.8452  data: 0.1440  max mem: 10714\n",
      "Training Epoch: [13]  [ 10/500]  eta: 0:05:16  lr: 0.000005  loss: 5.7171 (5.9389)  loss_classifier: 5.3299 (5.4842)  loss_box_reg: 0.2135 (0.2260)  loss_objectness: 0.1546 (0.1605)  loss_rpn_box_reg: 0.0650 (0.0682)  time: 0.6457  data: 0.1335  max mem: 10714\n",
      "Training Epoch: [13]  [ 20/500]  eta: 0:05:01  lr: 0.000005  loss: 5.9281 (6.0780)  loss_classifier: 5.3996 (5.5957)  loss_box_reg: 0.2217 (0.2408)  loss_objectness: 0.1546 (0.1636)  loss_rpn_box_reg: 0.0678 (0.0779)  time: 0.6175  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [13]  [ 30/500]  eta: 0:04:52  lr: 0.000005  loss: 6.1285 (6.1245)  loss_classifier: 5.6774 (5.6396)  loss_box_reg: 0.2193 (0.2396)  loss_objectness: 0.1531 (0.1634)  loss_rpn_box_reg: 0.0789 (0.0820)  time: 0.6102  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [13]  [ 40/500]  eta: 0:04:46  lr: 0.000005  loss: 6.0033 (6.0800)  loss_classifier: 5.5836 (5.6074)  loss_box_reg: 0.2289 (0.2332)  loss_objectness: 0.1465 (0.1610)  loss_rpn_box_reg: 0.0733 (0.0784)  time: 0.6156  data: 0.1333  max mem: 10714\n",
      "Training Epoch: [13]  [ 50/500]  eta: 0:04:39  lr: 0.000005  loss: 5.9674 (6.1235)  loss_classifier: 5.5868 (5.6622)  loss_box_reg: 0.2289 (0.2299)  loss_objectness: 0.1138 (0.1541)  loss_rpn_box_reg: 0.0699 (0.0772)  time: 0.6195  data: 0.1333  max mem: 10714\n",
      "Training Epoch: [13]  [ 60/500]  eta: 0:04:32  lr: 0.000005  loss: 6.1582 (6.1246)  loss_classifier: 5.6630 (5.6636)  loss_box_reg: 0.2231 (0.2307)  loss_objectness: 0.1288 (0.1534)  loss_rpn_box_reg: 0.0643 (0.0768)  time: 0.6151  data: 0.1326  max mem: 10714\n",
      "Training Epoch: [13]  [ 70/500]  eta: 0:04:25  lr: 0.000005  loss: 6.3670 (6.1500)  loss_classifier: 5.8490 (5.6844)  loss_box_reg: 0.2400 (0.2365)  loss_objectness: 0.1416 (0.1535)  loss_rpn_box_reg: 0.0631 (0.0755)  time: 0.6109  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [13]  [ 80/500]  eta: 0:04:20  lr: 0.000005  loss: 6.3957 (6.1926)  loss_classifier: 5.9387 (5.7338)  loss_box_reg: 0.1992 (0.2302)  loss_objectness: 0.1541 (0.1536)  loss_rpn_box_reg: 0.0577 (0.0749)  time: 0.6197  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [13]  [ 90/500]  eta: 0:04:14  lr: 0.000005  loss: 6.2898 (6.1816)  loss_classifier: 5.8248 (5.7196)  loss_box_reg: 0.1992 (0.2339)  loss_objectness: 0.1585 (0.1537)  loss_rpn_box_reg: 0.0597 (0.0745)  time: 0.6310  data: 0.1353  max mem: 10714\n",
      "Training Epoch: [13]  [100/500]  eta: 0:04:08  lr: 0.000005  loss: 6.0074 (6.1822)  loss_classifier: 5.5293 (5.7202)  loss_box_reg: 0.2312 (0.2334)  loss_objectness: 0.1585 (0.1545)  loss_rpn_box_reg: 0.0597 (0.0741)  time: 0.6291  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [13]  [110/500]  eta: 0:04:02  lr: 0.000005  loss: 6.1849 (6.1861)  loss_classifier: 5.7783 (5.7248)  loss_box_reg: 0.2265 (0.2341)  loss_objectness: 0.1492 (0.1536)  loss_rpn_box_reg: 0.0590 (0.0736)  time: 0.6180  data: 0.1327  max mem: 10714\n",
      "Training Epoch: [13]  [120/500]  eta: 0:03:55  lr: 0.000005  loss: 6.2156 (6.2005)  loss_classifier: 5.8076 (5.7418)  loss_box_reg: 0.2023 (0.2326)  loss_objectness: 0.1378 (0.1524)  loss_rpn_box_reg: 0.0739 (0.0737)  time: 0.6181  data: 0.1317  max mem: 10714\n",
      "Training Epoch: [13]  [130/500]  eta: 0:03:49  lr: 0.000005  loss: 6.3694 (6.2181)  loss_classifier: 5.8154 (5.7553)  loss_box_reg: 0.2367 (0.2367)  loss_objectness: 0.1354 (0.1516)  loss_rpn_box_reg: 0.0667 (0.0744)  time: 0.6247  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [13]  [140/500]  eta: 0:03:43  lr: 0.000005  loss: 6.0780 (6.2005)  loss_classifier: 5.5099 (5.7357)  loss_box_reg: 0.2501 (0.2377)  loss_objectness: 0.1390 (0.1525)  loss_rpn_box_reg: 0.0635 (0.0746)  time: 0.6147  data: 0.1362  max mem: 10714\n",
      "Training Epoch: [13]  [150/500]  eta: 0:03:36  lr: 0.000005  loss: 5.9189 (6.1889)  loss_classifier: 5.4364 (5.7207)  loss_box_reg: 0.2501 (0.2411)  loss_objectness: 0.1390 (0.1515)  loss_rpn_box_reg: 0.0777 (0.0757)  time: 0.6056  data: 0.1332  max mem: 10714\n",
      "Training Epoch: [13]  [160/500]  eta: 0:03:31  lr: 0.000005  loss: 5.8855 (6.1830)  loss_classifier: 5.5520 (5.7171)  loss_box_reg: 0.2462 (0.2398)  loss_objectness: 0.1238 (0.1507)  loss_rpn_box_reg: 0.0777 (0.0754)  time: 0.6250  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [13]  [170/500]  eta: 0:03:24  lr: 0.000005  loss: 6.1623 (6.1993)  loss_classifier: 5.6149 (5.7322)  loss_box_reg: 0.2159 (0.2405)  loss_objectness: 0.1419 (0.1510)  loss_rpn_box_reg: 0.0750 (0.0757)  time: 0.6339  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [13]  [180/500]  eta: 0:03:18  lr: 0.000005  loss: 6.3632 (6.1981)  loss_classifier: 5.8415 (5.7321)  loss_box_reg: 0.2120 (0.2384)  loss_objectness: 0.1540 (0.1519)  loss_rpn_box_reg: 0.0751 (0.0755)  time: 0.6277  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [13]  [190/500]  eta: 0:03:12  lr: 0.000005  loss: 6.0255 (6.1918)  loss_classifier: 5.6349 (5.7269)  loss_box_reg: 0.1890 (0.2377)  loss_objectness: 0.1540 (0.1521)  loss_rpn_box_reg: 0.0605 (0.0752)  time: 0.6257  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [13]  [200/500]  eta: 0:03:06  lr: 0.000005  loss: 6.1053 (6.2028)  loss_classifier: 5.6454 (5.7390)  loss_box_reg: 0.1964 (0.2363)  loss_objectness: 0.1590 (0.1521)  loss_rpn_box_reg: 0.0794 (0.0754)  time: 0.6225  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [13]  [210/500]  eta: 0:02:59  lr: 0.000005  loss: 6.1053 (6.1938)  loss_classifier: 5.6454 (5.7294)  loss_box_reg: 0.2083 (0.2355)  loss_objectness: 0.1544 (0.1522)  loss_rpn_box_reg: 0.0882 (0.0767)  time: 0.6117  data: 0.1324  max mem: 10714\n",
      "Training Epoch: [13]  [220/500]  eta: 0:02:53  lr: 0.000005  loss: 6.3209 (6.2080)  loss_classifier: 5.7808 (5.7435)  loss_box_reg: 0.2341 (0.2360)  loss_objectness: 0.1405 (0.1521)  loss_rpn_box_reg: 0.0794 (0.0763)  time: 0.6187  data: 0.1333  max mem: 10714\n",
      "Training Epoch: [13]  [230/500]  eta: 0:02:48  lr: 0.000005  loss: 6.4214 (6.2037)  loss_classifier: 5.8788 (5.7397)  loss_box_reg: 0.2294 (0.2365)  loss_objectness: 0.1369 (0.1512)  loss_rpn_box_reg: 0.0666 (0.0763)  time: 0.6409  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [13]  [240/500]  eta: 0:02:41  lr: 0.000005  loss: 6.1188 (6.1989)  loss_classifier: 5.7124 (5.7344)  loss_box_reg: 0.2163 (0.2365)  loss_objectness: 0.1369 (0.1513)  loss_rpn_box_reg: 0.0730 (0.0767)  time: 0.6226  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [13]  [250/500]  eta: 0:02:35  lr: 0.000005  loss: 6.1072 (6.1980)  loss_classifier: 5.7075 (5.7332)  loss_box_reg: 0.2254 (0.2363)  loss_objectness: 0.1485 (0.1517)  loss_rpn_box_reg: 0.0730 (0.0768)  time: 0.6202  data: 0.1345  max mem: 10714\n",
      "Training Epoch: [13]  [260/500]  eta: 0:02:29  lr: 0.000005  loss: 6.1157 (6.1875)  loss_classifier: 5.6515 (5.7231)  loss_box_reg: 0.2284 (0.2364)  loss_objectness: 0.1427 (0.1517)  loss_rpn_box_reg: 0.0643 (0.0763)  time: 0.6339  data: 0.1340  max mem: 10714\n",
      "Training Epoch: [13]  [270/500]  eta: 0:02:23  lr: 0.000005  loss: 6.1043 (6.1874)  loss_classifier: 5.6516 (5.7252)  loss_box_reg: 0.2284 (0.2358)  loss_objectness: 0.1345 (0.1510)  loss_rpn_box_reg: 0.0567 (0.0755)  time: 0.6392  data: 0.1345  max mem: 10714\n",
      "Training Epoch: [13]  [280/500]  eta: 0:02:17  lr: 0.000005  loss: 6.2292 (6.2001)  loss_classifier: 5.7288 (5.7382)  loss_box_reg: 0.2111 (0.2357)  loss_objectness: 0.1457 (0.1509)  loss_rpn_box_reg: 0.0646 (0.0753)  time: 0.6503  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [13]  [290/500]  eta: 0:02:11  lr: 0.000005  loss: 6.0966 (6.1959)  loss_classifier: 5.6830 (5.7330)  loss_box_reg: 0.2372 (0.2364)  loss_objectness: 0.1507 (0.1512)  loss_rpn_box_reg: 0.0711 (0.0752)  time: 0.6378  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [13]  [300/500]  eta: 0:02:04  lr: 0.000005  loss: 6.0966 (6.1970)  loss_classifier: 5.6547 (5.7346)  loss_box_reg: 0.2429 (0.2361)  loss_objectness: 0.1551 (0.1514)  loss_rpn_box_reg: 0.0682 (0.0749)  time: 0.6254  data: 0.1363  max mem: 10714\n",
      "Training Epoch: [13]  [310/500]  eta: 0:01:58  lr: 0.000005  loss: 6.3049 (6.1983)  loss_classifier: 5.8346 (5.7347)  loss_box_reg: 0.2543 (0.2368)  loss_objectness: 0.1683 (0.1518)  loss_rpn_box_reg: 0.0648 (0.0749)  time: 0.6221  data: 0.1370  max mem: 10714\n",
      "Training Epoch: [13]  [320/500]  eta: 0:01:52  lr: 0.000005  loss: 5.9361 (6.1867)  loss_classifier: 5.6385 (5.7234)  loss_box_reg: 0.2557 (0.2370)  loss_objectness: 0.1628 (0.1517)  loss_rpn_box_reg: 0.0660 (0.0746)  time: 0.6271  data: 0.1356  max mem: 10714\n",
      "Training Epoch: [13]  [330/500]  eta: 0:01:46  lr: 0.000005  loss: 5.9082 (6.1852)  loss_classifier: 5.4265 (5.7208)  loss_box_reg: 0.2215 (0.2376)  loss_objectness: 0.1604 (0.1521)  loss_rpn_box_reg: 0.0776 (0.0748)  time: 0.6304  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [13]  [340/500]  eta: 0:01:39  lr: 0.000005  loss: 6.0987 (6.1893)  loss_classifier: 5.4914 (5.7234)  loss_box_reg: 0.2271 (0.2383)  loss_objectness: 0.1686 (0.1528)  loss_rpn_box_reg: 0.0813 (0.0748)  time: 0.6130  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [13]  [350/500]  eta: 0:01:33  lr: 0.000005  loss: 6.2530 (6.1961)  loss_classifier: 5.8467 (5.7301)  loss_box_reg: 0.2306 (0.2385)  loss_objectness: 0.1649 (0.1527)  loss_rpn_box_reg: 0.0733 (0.0749)  time: 0.6027  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [13]  [360/500]  eta: 0:01:27  lr: 0.000005  loss: 6.3079 (6.1980)  loss_classifier: 5.8520 (5.7319)  loss_box_reg: 0.2306 (0.2386)  loss_objectness: 0.1529 (0.1526)  loss_rpn_box_reg: 0.0733 (0.0749)  time: 0.6077  data: 0.1325  max mem: 10714\n",
      "Training Epoch: [13]  [370/500]  eta: 0:01:20  lr: 0.000005  loss: 6.3343 (6.2048)  loss_classifier: 5.8636 (5.7387)  loss_box_reg: 0.2532 (0.2387)  loss_objectness: 0.1586 (0.1528)  loss_rpn_box_reg: 0.0661 (0.0747)  time: 0.6138  data: 0.1329  max mem: 10714\n",
      "Training Epoch: [13]  [380/500]  eta: 0:01:14  lr: 0.000005  loss: 6.2883 (6.2063)  loss_classifier: 5.8581 (5.7406)  loss_box_reg: 0.2120 (0.2385)  loss_objectness: 0.1586 (0.1527)  loss_rpn_box_reg: 0.0598 (0.0744)  time: 0.6174  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [13]  [390/500]  eta: 0:01:08  lr: 0.000005  loss: 6.2830 (6.2113)  loss_classifier: 5.7875 (5.7459)  loss_box_reg: 0.2209 (0.2383)  loss_objectness: 0.1559 (0.1528)  loss_rpn_box_reg: 0.0598 (0.0743)  time: 0.6280  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [13]  [400/500]  eta: 0:01:02  lr: 0.000005  loss: 6.2962 (6.2098)  loss_classifier: 5.6964 (5.7433)  loss_box_reg: 0.2298 (0.2390)  loss_objectness: 0.1618 (0.1531)  loss_rpn_box_reg: 0.0578 (0.0743)  time: 0.6226  data: 0.1332  max mem: 10714\n",
      "Training Epoch: [13]  [410/500]  eta: 0:00:56  lr: 0.000005  loss: 6.0678 (6.2040)  loss_classifier: 5.6770 (5.7383)  loss_box_reg: 0.2344 (0.2389)  loss_objectness: 0.1523 (0.1527)  loss_rpn_box_reg: 0.0599 (0.0741)  time: 0.6147  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [13]  [420/500]  eta: 0:00:49  lr: 0.000005  loss: 6.0059 (6.2033)  loss_classifier: 5.5349 (5.7362)  loss_box_reg: 0.2413 (0.2394)  loss_objectness: 0.1382 (0.1528)  loss_rpn_box_reg: 0.0695 (0.0749)  time: 0.6290  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [13]  [430/500]  eta: 0:00:43  lr: 0.000005  loss: 6.1361 (6.2044)  loss_classifier: 5.5434 (5.7367)  loss_box_reg: 0.2602 (0.2397)  loss_objectness: 0.1540 (0.1532)  loss_rpn_box_reg: 0.0796 (0.0749)  time: 0.6290  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [13]  [440/500]  eta: 0:00:37  lr: 0.000005  loss: 6.1361 (6.2028)  loss_classifier: 5.5780 (5.7342)  loss_box_reg: 0.2500 (0.2401)  loss_objectness: 0.1461 (0.1530)  loss_rpn_box_reg: 0.0796 (0.0755)  time: 0.6208  data: 0.1377  max mem: 10714\n",
      "Training Epoch: [13]  [450/500]  eta: 0:00:31  lr: 0.000005  loss: 6.0727 (6.2015)  loss_classifier: 5.6658 (5.7330)  loss_box_reg: 0.2246 (0.2398)  loss_objectness: 0.1474 (0.1532)  loss_rpn_box_reg: 0.0801 (0.0755)  time: 0.6307  data: 0.1363  max mem: 10714\n",
      "Training Epoch: [13]  [460/500]  eta: 0:00:24  lr: 0.000005  loss: 6.1576 (6.1999)  loss_classifier: 5.7232 (5.7316)  loss_box_reg: 0.2246 (0.2399)  loss_objectness: 0.1490 (0.1532)  loss_rpn_box_reg: 0.0620 (0.0751)  time: 0.6415  data: 0.1330  max mem: 10714\n",
      "Training Epoch: [13]  [470/500]  eta: 0:00:18  lr: 0.000005  loss: 6.1576 (6.2035)  loss_classifier: 5.7232 (5.7346)  loss_box_reg: 0.2299 (0.2403)  loss_objectness: 0.1463 (0.1532)  loss_rpn_box_reg: 0.0663 (0.0754)  time: 0.6232  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [13]  [480/500]  eta: 0:00:12  lr: 0.000005  loss: 6.1931 (6.2057)  loss_classifier: 5.7358 (5.7366)  loss_box_reg: 0.2255 (0.2404)  loss_objectness: 0.1542 (0.1532)  loss_rpn_box_reg: 0.0728 (0.0754)  time: 0.6118  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [13]  [490/500]  eta: 0:00:06  lr: 0.000005  loss: 6.2590 (6.2083)  loss_classifier: 5.7911 (5.7394)  loss_box_reg: 0.2359 (0.2404)  loss_objectness: 0.1521 (0.1531)  loss_rpn_box_reg: 0.0716 (0.0754)  time: 0.6355  data: 0.1326  max mem: 10714\n",
      "Training Epoch: [13]  [499/500]  eta: 0:00:00  lr: 0.000005  loss: 6.1366 (6.2067)  loss_classifier: 5.6551 (5.7384)  loss_box_reg: 0.2183 (0.2398)  loss_objectness: 0.1487 (0.1528)  loss_rpn_box_reg: 0.0795 (0.0757)  time: 0.6353  data: 0.1313  max mem: 10714\n",
      "Training Epoch: [13] Total time: 0:05:11 (0.6238 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:52  model_time: 0.7152 (0.7152)  evaluator_time: 0.0340 (0.0340)  time: 0.9012  data: 0.1430  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4401 (0.4505)  evaluator_time: 0.0340 (0.0359)  time: 0.6341  data: 0.1539  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4681 (0.4529)  evaluator_time: 0.0360 (0.0364)  time: 0.6579  data: 0.1482  max mem: 10714\n",
      "Test: Total time: 0:01:20 (0.6407 s / it)\n",
      "Averaged stats: model_time: 0.4681 (0.4529)  evaluator_time: 0.0360 (0.0364)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.179\n",
      "Testing Epoch: [13]  [  0/125]  eta: 0:01:30  lr: 0.000005  loss: 6.1873 (6.1873)  loss_classifier: 5.6406 (5.6406)  loss_box_reg: 0.2953 (0.2953)  loss_objectness: 0.1198 (0.1198)  loss_rpn_box_reg: 0.1315 (0.1315)  time: 0.7212  data: 0.2230  max mem: 10714\n",
      "Testing Epoch: [13]  [100/125]  eta: 0:00:14  lr: 0.000005  loss: 5.9752 (6.1293)  loss_classifier: 5.4289 (5.6194)  loss_box_reg: 0.2644 (0.2886)  loss_objectness: 0.1303 (0.1317)  loss_rpn_box_reg: 0.0739 (0.0896)  time: 0.5865  data: 0.1458  max mem: 10714\n",
      "Testing Epoch: [13]  [124/125]  eta: 0:00:00  lr: 0.000005  loss: 6.1504 (6.1616)  loss_classifier: 5.6879 (5.6559)  loss_box_reg: 0.2512 (0.2841)  loss_objectness: 0.1207 (0.1320)  loss_rpn_box_reg: 0.0746 (0.0897)  time: 0.5992  data: 0.1453  max mem: 10714\n",
      "Testing Epoch: [13] Total time: 0:01:14 (0.5973 s / it)\n",
      "Training Epoch: [14]  [  0/500]  eta: 0:05:57  lr: 0.000005  loss: 5.5111 (5.5111)  loss_classifier: 5.0845 (5.0845)  loss_box_reg: 0.2298 (0.2298)  loss_objectness: 0.0958 (0.0958)  loss_rpn_box_reg: 0.1009 (0.1009)  time: 0.7142  data: 0.1190  max mem: 10714\n",
      "Training Epoch: [14]  [ 10/500]  eta: 0:05:16  lr: 0.000005  loss: 5.8596 (5.9288)  loss_classifier: 5.3410 (5.4533)  loss_box_reg: 0.2824 (0.2539)  loss_objectness: 0.1428 (0.1344)  loss_rpn_box_reg: 0.0963 (0.0872)  time: 0.6469  data: 0.1320  max mem: 10714\n",
      "Training Epoch: [14]  [ 20/500]  eta: 0:05:02  lr: 0.000005  loss: 6.0718 (6.1781)  loss_classifier: 5.5690 (5.7142)  loss_box_reg: 0.2475 (0.2451)  loss_objectness: 0.1427 (0.1410)  loss_rpn_box_reg: 0.0736 (0.0778)  time: 0.6269  data: 0.1322  max mem: 10714\n",
      "Training Epoch: [14]  [ 30/500]  eta: 0:04:55  lr: 0.000005  loss: 6.2978 (6.1974)  loss_classifier: 5.8247 (5.7481)  loss_box_reg: 0.2250 (0.2345)  loss_objectness: 0.1383 (0.1412)  loss_rpn_box_reg: 0.0608 (0.0735)  time: 0.6189  data: 0.1328  max mem: 10714\n",
      "Training Epoch: [14]  [ 40/500]  eta: 0:04:51  lr: 0.000005  loss: 6.3007 (6.2610)  loss_classifier: 5.8247 (5.8021)  loss_box_reg: 0.2200 (0.2397)  loss_objectness: 0.1407 (0.1437)  loss_rpn_box_reg: 0.0668 (0.0755)  time: 0.6378  data: 0.1352  max mem: 10714\n",
      "Training Epoch: [14]  [ 50/500]  eta: 0:04:45  lr: 0.000005  loss: 6.4911 (6.2816)  loss_classifier: 6.0660 (5.8217)  loss_box_reg: 0.2364 (0.2379)  loss_objectness: 0.1374 (0.1442)  loss_rpn_box_reg: 0.0784 (0.0778)  time: 0.6410  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [14]  [ 60/500]  eta: 0:04:39  lr: 0.000005  loss: 6.3672 (6.2572)  loss_classifier: 5.8203 (5.7954)  loss_box_reg: 0.2337 (0.2400)  loss_objectness: 0.1419 (0.1450)  loss_rpn_box_reg: 0.0673 (0.0767)  time: 0.6348  data: 0.1325  max mem: 10714\n",
      "Training Epoch: [14]  [ 70/500]  eta: 0:04:31  lr: 0.000005  loss: 6.3672 (6.2657)  loss_classifier: 5.8203 (5.8030)  loss_box_reg: 0.2337 (0.2396)  loss_objectness: 0.1429 (0.1444)  loss_rpn_box_reg: 0.0702 (0.0786)  time: 0.6228  data: 0.1323  max mem: 10714\n",
      "Training Epoch: [14]  [ 80/500]  eta: 0:04:24  lr: 0.000005  loss: 6.4585 (6.2986)  loss_classifier: 5.8633 (5.8304)  loss_box_reg: 0.2450 (0.2439)  loss_objectness: 0.1391 (0.1454)  loss_rpn_box_reg: 0.0779 (0.0788)  time: 0.6140  data: 0.1330  max mem: 10714\n",
      "Training Epoch: [14]  [ 90/500]  eta: 0:04:18  lr: 0.000005  loss: 6.3104 (6.2752)  loss_classifier: 5.7861 (5.8145)  loss_box_reg: 0.2202 (0.2397)  loss_objectness: 0.1246 (0.1430)  loss_rpn_box_reg: 0.0734 (0.0780)  time: 0.6294  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [14]  [100/500]  eta: 0:04:11  lr: 0.000005  loss: 6.2567 (6.2686)  loss_classifier: 5.7861 (5.8138)  loss_box_reg: 0.1902 (0.2357)  loss_objectness: 0.1178 (0.1426)  loss_rpn_box_reg: 0.0606 (0.0765)  time: 0.6292  data: 0.1332  max mem: 10714\n",
      "Training Epoch: [14]  [110/500]  eta: 0:04:04  lr: 0.000005  loss: 6.1816 (6.2510)  loss_classifier: 5.6791 (5.7929)  loss_box_reg: 0.2166 (0.2371)  loss_objectness: 0.1493 (0.1443)  loss_rpn_box_reg: 0.0755 (0.0768)  time: 0.6107  data: 0.1309  max mem: 10714\n",
      "Training Epoch: [14]  [120/500]  eta: 0:03:57  lr: 0.000005  loss: 6.1816 (6.2420)  loss_classifier: 5.6502 (5.7828)  loss_box_reg: 0.2285 (0.2374)  loss_objectness: 0.1497 (0.1446)  loss_rpn_box_reg: 0.0755 (0.0770)  time: 0.6103  data: 0.1325  max mem: 10714\n",
      "Training Epoch: [14]  [130/500]  eta: 0:03:51  lr: 0.000005  loss: 5.9894 (6.2374)  loss_classifier: 5.5303 (5.7769)  loss_box_reg: 0.2296 (0.2384)  loss_objectness: 0.1495 (0.1453)  loss_rpn_box_reg: 0.0696 (0.0767)  time: 0.6148  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [14]  [140/500]  eta: 0:03:44  lr: 0.000005  loss: 6.0622 (6.2208)  loss_classifier: 5.5303 (5.7635)  loss_box_reg: 0.2281 (0.2368)  loss_objectness: 0.1473 (0.1446)  loss_rpn_box_reg: 0.0513 (0.0758)  time: 0.6162  data: 0.1320  max mem: 10714\n",
      "Training Epoch: [14]  [150/500]  eta: 0:03:38  lr: 0.000005  loss: 6.1221 (6.2196)  loss_classifier: 5.7042 (5.7622)  loss_box_reg: 0.2134 (0.2367)  loss_objectness: 0.1404 (0.1445)  loss_rpn_box_reg: 0.0513 (0.0761)  time: 0.6284  data: 0.1316  max mem: 10714\n",
      "Training Epoch: [14]  [160/500]  eta: 0:03:32  lr: 0.000005  loss: 6.2064 (6.2117)  loss_classifier: 5.7247 (5.7547)  loss_box_reg: 0.2015 (0.2361)  loss_objectness: 0.1461 (0.1453)  loss_rpn_box_reg: 0.0567 (0.0756)  time: 0.6256  data: 0.1317  max mem: 10714\n",
      "Training Epoch: [14]  [170/500]  eta: 0:03:26  lr: 0.000005  loss: 6.2074 (6.2200)  loss_classifier: 5.8174 (5.7635)  loss_box_reg: 0.2106 (0.2367)  loss_objectness: 0.1438 (0.1447)  loss_rpn_box_reg: 0.0521 (0.0750)  time: 0.6163  data: 0.1327  max mem: 10714\n",
      "Training Epoch: [14]  [180/500]  eta: 0:03:19  lr: 0.000005  loss: 6.3474 (6.2351)  loss_classifier: 5.8907 (5.7778)  loss_box_reg: 0.2245 (0.2363)  loss_objectness: 0.1464 (0.1457)  loss_rpn_box_reg: 0.0705 (0.0752)  time: 0.6251  data: 0.1356  max mem: 10714\n",
      "Training Epoch: [14]  [190/500]  eta: 0:03:14  lr: 0.000005  loss: 6.3106 (6.2489)  loss_classifier: 5.9251 (5.7908)  loss_box_reg: 0.2252 (0.2367)  loss_objectness: 0.1502 (0.1460)  loss_rpn_box_reg: 0.0705 (0.0754)  time: 0.6406  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [14]  [200/500]  eta: 0:03:07  lr: 0.000005  loss: 6.2301 (6.2374)  loss_classifier: 5.7709 (5.7790)  loss_box_reg: 0.2393 (0.2369)  loss_objectness: 0.1429 (0.1461)  loss_rpn_box_reg: 0.0594 (0.0754)  time: 0.6298  data: 0.1326  max mem: 10714\n",
      "Training Epoch: [14]  [210/500]  eta: 0:03:01  lr: 0.000005  loss: 6.0589 (6.2333)  loss_classifier: 5.5783 (5.7738)  loss_box_reg: 0.2393 (0.2378)  loss_objectness: 0.1473 (0.1464)  loss_rpn_box_reg: 0.0643 (0.0752)  time: 0.6180  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [14]  [220/500]  eta: 0:02:55  lr: 0.000005  loss: 6.0918 (6.2231)  loss_classifier: 5.6359 (5.7639)  loss_box_reg: 0.2305 (0.2369)  loss_objectness: 0.1536 (0.1471)  loss_rpn_box_reg: 0.0734 (0.0752)  time: 0.6234  data: 0.1352  max mem: 10714\n",
      "Training Epoch: [14]  [230/500]  eta: 0:02:48  lr: 0.000005  loss: 6.0918 (6.2266)  loss_classifier: 5.6359 (5.7683)  loss_box_reg: 0.2147 (0.2358)  loss_objectness: 0.1598 (0.1474)  loss_rpn_box_reg: 0.0680 (0.0750)  time: 0.6182  data: 0.1340  max mem: 10714\n",
      "Training Epoch: [14]  [240/500]  eta: 0:02:42  lr: 0.000005  loss: 6.1124 (6.2221)  loss_classifier: 5.6887 (5.7626)  loss_box_reg: 0.2205 (0.2363)  loss_objectness: 0.1598 (0.1479)  loss_rpn_box_reg: 0.0602 (0.0752)  time: 0.6156  data: 0.1331  max mem: 10714\n",
      "Training Epoch: [14]  [250/500]  eta: 0:02:36  lr: 0.000005  loss: 6.1210 (6.2263)  loss_classifier: 5.6887 (5.7665)  loss_box_reg: 0.2421 (0.2365)  loss_objectness: 0.1553 (0.1483)  loss_rpn_box_reg: 0.0594 (0.0750)  time: 0.6198  data: 0.1334  max mem: 10714\n",
      "Training Epoch: [14]  [260/500]  eta: 0:02:29  lr: 0.000005  loss: 6.1210 (6.2255)  loss_classifier: 5.5974 (5.7647)  loss_box_reg: 0.2528 (0.2373)  loss_objectness: 0.1493 (0.1482)  loss_rpn_box_reg: 0.0680 (0.0752)  time: 0.6145  data: 0.1359  max mem: 10714\n",
      "Training Epoch: [14]  [270/500]  eta: 0:02:23  lr: 0.000005  loss: 5.9891 (6.2207)  loss_classifier: 5.5182 (5.7583)  loss_box_reg: 0.2646 (0.2388)  loss_objectness: 0.1380 (0.1483)  loss_rpn_box_reg: 0.0699 (0.0753)  time: 0.6033  data: 0.1366  max mem: 10714\n",
      "Training Epoch: [14]  [280/500]  eta: 0:02:17  lr: 0.000005  loss: 6.2373 (6.2286)  loss_classifier: 5.7929 (5.7668)  loss_box_reg: 0.2464 (0.2389)  loss_objectness: 0.1380 (0.1479)  loss_rpn_box_reg: 0.0652 (0.0750)  time: 0.6110  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [14]  [290/500]  eta: 0:02:10  lr: 0.000005  loss: 6.2373 (6.2257)  loss_classifier: 5.7929 (5.7633)  loss_box_reg: 0.2415 (0.2389)  loss_objectness: 0.1338 (0.1481)  loss_rpn_box_reg: 0.0711 (0.0754)  time: 0.6201  data: 0.1356  max mem: 10714\n",
      "Training Epoch: [14]  [300/500]  eta: 0:02:04  lr: 0.000005  loss: 6.1277 (6.2196)  loss_classifier: 5.6205 (5.7593)  loss_box_reg: 0.2154 (0.2375)  loss_objectness: 0.1577 (0.1483)  loss_rpn_box_reg: 0.0589 (0.0746)  time: 0.6296  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [14]  [310/500]  eta: 0:01:58  lr: 0.000005  loss: 6.1364 (6.2224)  loss_classifier: 5.7302 (5.7622)  loss_box_reg: 0.2154 (0.2375)  loss_objectness: 0.1449 (0.1483)  loss_rpn_box_reg: 0.0551 (0.0744)  time: 0.6375  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [14]  [320/500]  eta: 0:01:52  lr: 0.000005  loss: 6.4458 (6.2339)  loss_classifier: 5.9707 (5.7739)  loss_box_reg: 0.2195 (0.2374)  loss_objectness: 0.1449 (0.1484)  loss_rpn_box_reg: 0.0613 (0.0742)  time: 0.6365  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [14]  [330/500]  eta: 0:01:45  lr: 0.000005  loss: 6.4458 (6.2360)  loss_classifier: 5.9341 (5.7742)  loss_box_reg: 0.2488 (0.2382)  loss_objectness: 0.1504 (0.1490)  loss_rpn_box_reg: 0.0750 (0.0747)  time: 0.6147  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [14]  [340/500]  eta: 0:01:39  lr: 0.000005  loss: 6.2329 (6.2348)  loss_classifier: 5.7262 (5.7733)  loss_box_reg: 0.2276 (0.2379)  loss_objectness: 0.1564 (0.1491)  loss_rpn_box_reg: 0.0767 (0.0746)  time: 0.6079  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [14]  [350/500]  eta: 0:01:33  lr: 0.000005  loss: 6.1569 (6.2283)  loss_classifier: 5.6667 (5.7661)  loss_box_reg: 0.2278 (0.2381)  loss_objectness: 0.1564 (0.1494)  loss_rpn_box_reg: 0.0638 (0.0747)  time: 0.6354  data: 0.1359  max mem: 10714\n",
      "Training Epoch: [14]  [360/500]  eta: 0:01:27  lr: 0.000005  loss: 6.1628 (6.2296)  loss_classifier: 5.7191 (5.7669)  loss_box_reg: 0.2184 (0.2376)  loss_objectness: 0.1590 (0.1501)  loss_rpn_box_reg: 0.0690 (0.0750)  time: 0.6313  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [14]  [370/500]  eta: 0:01:21  lr: 0.000005  loss: 6.1729 (6.2286)  loss_classifier: 5.7250 (5.7641)  loss_box_reg: 0.2184 (0.2386)  loss_objectness: 0.1584 (0.1503)  loss_rpn_box_reg: 0.0998 (0.0756)  time: 0.6262  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [14]  [380/500]  eta: 0:01:14  lr: 0.000005  loss: 6.1974 (6.2291)  loss_classifier: 5.7197 (5.7651)  loss_box_reg: 0.2382 (0.2386)  loss_objectness: 0.1355 (0.1500)  loss_rpn_box_reg: 0.0758 (0.0753)  time: 0.6296  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [14]  [390/500]  eta: 0:01:08  lr: 0.000005  loss: 6.2658 (6.2315)  loss_classifier: 5.7197 (5.7671)  loss_box_reg: 0.2199 (0.2383)  loss_objectness: 0.1485 (0.1506)  loss_rpn_box_reg: 0.0715 (0.0755)  time: 0.6301  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [14]  [400/500]  eta: 0:01:02  lr: 0.000005  loss: 6.1111 (6.2248)  loss_classifier: 5.5911 (5.7593)  loss_box_reg: 0.2334 (0.2386)  loss_objectness: 0.1631 (0.1512)  loss_rpn_box_reg: 0.0775 (0.0758)  time: 0.6323  data: 0.1361  max mem: 10714\n",
      "Training Epoch: [14]  [410/500]  eta: 0:00:56  lr: 0.000005  loss: 6.0569 (6.2235)  loss_classifier: 5.5318 (5.7578)  loss_box_reg: 0.2533 (0.2389)  loss_objectness: 0.1394 (0.1508)  loss_rpn_box_reg: 0.0765 (0.0759)  time: 0.6185  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [14]  [420/500]  eta: 0:00:49  lr: 0.000005  loss: 6.0550 (6.2232)  loss_classifier: 5.5644 (5.7570)  loss_box_reg: 0.2257 (0.2392)  loss_objectness: 0.1434 (0.1510)  loss_rpn_box_reg: 0.0733 (0.0760)  time: 0.6063  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [14]  [430/500]  eta: 0:00:43  lr: 0.000005  loss: 6.0550 (6.2216)  loss_classifier: 5.5677 (5.7562)  loss_box_reg: 0.2096 (0.2386)  loss_objectness: 0.1570 (0.1511)  loss_rpn_box_reg: 0.0651 (0.0758)  time: 0.6239  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [14]  [440/500]  eta: 0:00:37  lr: 0.000005  loss: 6.1031 (6.2182)  loss_classifier: 5.7159 (5.7518)  loss_box_reg: 0.2095 (0.2389)  loss_objectness: 0.1599 (0.1516)  loss_rpn_box_reg: 0.0707 (0.0759)  time: 0.6289  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [14]  [450/500]  eta: 0:00:31  lr: 0.000005  loss: 6.1031 (6.2204)  loss_classifier: 5.6857 (5.7543)  loss_box_reg: 0.2247 (0.2381)  loss_objectness: 0.1751 (0.1520)  loss_rpn_box_reg: 0.0759 (0.0761)  time: 0.6293  data: 0.1353  max mem: 10714\n",
      "Training Epoch: [14]  [460/500]  eta: 0:00:24  lr: 0.000005  loss: 6.0736 (6.2166)  loss_classifier: 5.6262 (5.7495)  loss_box_reg: 0.2247 (0.2386)  loss_objectness: 0.1734 (0.1525)  loss_rpn_box_reg: 0.0729 (0.0760)  time: 0.6342  data: 0.1370  max mem: 10714\n",
      "Training Epoch: [14]  [470/500]  eta: 0:00:18  lr: 0.000005  loss: 6.2374 (6.2184)  loss_classifier: 5.7146 (5.7515)  loss_box_reg: 0.2290 (0.2387)  loss_objectness: 0.1499 (0.1524)  loss_rpn_box_reg: 0.0614 (0.0760)  time: 0.6315  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [14]  [480/500]  eta: 0:00:12  lr: 0.000005  loss: 5.9768 (6.2104)  loss_classifier: 5.5476 (5.7434)  loss_box_reg: 0.2236 (0.2385)  loss_objectness: 0.1496 (0.1524)  loss_rpn_box_reg: 0.0664 (0.0761)  time: 0.6362  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [14]  [490/500]  eta: 0:00:06  lr: 0.000005  loss: 5.9768 (6.2102)  loss_classifier: 5.5476 (5.7438)  loss_box_reg: 0.2100 (0.2379)  loss_objectness: 0.1496 (0.1525)  loss_rpn_box_reg: 0.0718 (0.0759)  time: 0.6341  data: 0.1367  max mem: 10714\n",
      "Training Epoch: [14]  [499/500]  eta: 0:00:00  lr: 0.000005  loss: 6.1759 (6.2137)  loss_classifier: 5.6532 (5.7468)  loss_box_reg: 0.2259 (0.2382)  loss_objectness: 0.1453 (0.1528)  loss_rpn_box_reg: 0.0592 (0.0758)  time: 0.6301  data: 0.1368  max mem: 10714\n",
      "Training Epoch: [14] Total time: 0:05:12 (0.6250 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:55  model_time: 0.7372 (0.7372)  evaluator_time: 0.0340 (0.0340)  time: 0.9232  data: 0.1420  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4381 (0.4510)  evaluator_time: 0.0340 (0.0340)  time: 0.6274  data: 0.1477  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4761 (0.4529)  evaluator_time: 0.0360 (0.0349)  time: 0.6556  data: 0.1483  max mem: 10714\n",
      "Test: Total time: 0:01:20 (0.6422 s / it)\n",
      "Averaged stats: model_time: 0.4761 (0.4529)  evaluator_time: 0.0360 (0.0349)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [14]  [  0/125]  eta: 0:01:20  lr: 0.000005  loss: 6.1850 (6.1850)  loss_classifier: 5.6351 (5.6351)  loss_box_reg: 0.2964 (0.2964)  loss_objectness: 0.1216 (0.1216)  loss_rpn_box_reg: 0.1319 (0.1319)  time: 0.6421  data: 0.1410  max mem: 10714\n",
      "Testing Epoch: [14]  [100/125]  eta: 0:00:14  lr: 0.000005  loss: 6.0164 (6.1290)  loss_classifier: 5.4325 (5.6209)  loss_box_reg: 0.2642 (0.2881)  loss_objectness: 0.1288 (0.1307)  loss_rpn_box_reg: 0.0716 (0.0892)  time: 0.5834  data: 0.1452  max mem: 10714\n",
      "Testing Epoch: [14]  [124/125]  eta: 0:00:00  lr: 0.000005  loss: 6.1647 (6.1610)  loss_classifier: 5.6910 (5.6571)  loss_box_reg: 0.2503 (0.2837)  loss_objectness: 0.1146 (0.1308)  loss_rpn_box_reg: 0.0746 (0.0894)  time: 0.5986  data: 0.1452  max mem: 10714\n",
      "Testing Epoch: [14] Total time: 0:01:14 (0.5950 s / it)\n",
      "Training Epoch: [15]  [  0/500]  eta: 0:06:40  lr: 0.000005  loss: 5.5130 (5.5130)  loss_classifier: 5.1573 (5.1573)  loss_box_reg: 0.2299 (0.2299)  loss_objectness: 0.0769 (0.0769)  loss_rpn_box_reg: 0.0488 (0.0488)  time: 0.8012  data: 0.1280  max mem: 10714\n",
      "Training Epoch: [15]  [ 10/500]  eta: 0:05:19  lr: 0.000005  loss: 6.1958 (6.1855)  loss_classifier: 5.6581 (5.7026)  loss_box_reg: 0.2459 (0.2559)  loss_objectness: 0.1408 (0.1435)  loss_rpn_box_reg: 0.0858 (0.0835)  time: 0.6514  data: 0.1368  max mem: 10714\n",
      "Training Epoch: [15]  [ 20/500]  eta: 0:05:04  lr: 0.000005  loss: 6.1958 (6.1857)  loss_classifier: 5.7057 (5.7260)  loss_box_reg: 0.2208 (0.2378)  loss_objectness: 0.1414 (0.1488)  loss_rpn_box_reg: 0.0674 (0.0732)  time: 0.6254  data: 0.1363  max mem: 10714\n",
      "Training Epoch: [15]  [ 30/500]  eta: 0:04:53  lr: 0.000005  loss: 6.1007 (6.1420)  loss_classifier: 5.7887 (5.6837)  loss_box_reg: 0.2076 (0.2342)  loss_objectness: 0.1433 (0.1467)  loss_rpn_box_reg: 0.0574 (0.0774)  time: 0.6105  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [15]  [ 40/500]  eta: 0:04:48  lr: 0.000005  loss: 6.1474 (6.1640)  loss_classifier: 5.6173 (5.7011)  loss_box_reg: 0.2248 (0.2371)  loss_objectness: 0.1496 (0.1493)  loss_rpn_box_reg: 0.0636 (0.0766)  time: 0.6190  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [15]  [ 50/500]  eta: 0:04:42  lr: 0.000005  loss: 6.2679 (6.2390)  loss_classifier: 5.8948 (5.7791)  loss_box_reg: 0.2308 (0.2342)  loss_objectness: 0.1625 (0.1509)  loss_rpn_box_reg: 0.0561 (0.0747)  time: 0.6316  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [15]  [ 60/500]  eta: 0:04:37  lr: 0.000005  loss: 6.4015 (6.2467)  loss_classifier: 5.9773 (5.7921)  loss_box_reg: 0.2036 (0.2312)  loss_objectness: 0.1468 (0.1494)  loss_rpn_box_reg: 0.0561 (0.0740)  time: 0.6360  data: 0.1340  max mem: 10714\n",
      "Training Epoch: [15]  [ 70/500]  eta: 0:04:30  lr: 0.000005  loss: 6.1173 (6.2562)  loss_classifier: 5.7338 (5.7985)  loss_box_reg: 0.1992 (0.2335)  loss_objectness: 0.1435 (0.1495)  loss_rpn_box_reg: 0.0648 (0.0748)  time: 0.6310  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [15]  [ 80/500]  eta: 0:04:23  lr: 0.000005  loss: 6.2481 (6.2646)  loss_classifier: 5.8307 (5.8079)  loss_box_reg: 0.2028 (0.2309)  loss_objectness: 0.1482 (0.1504)  loss_rpn_box_reg: 0.0752 (0.0754)  time: 0.6179  data: 0.1332  max mem: 10714\n",
      "Training Epoch: [15]  [ 90/500]  eta: 0:04:17  lr: 0.000005  loss: 6.2481 (6.2636)  loss_classifier: 5.8307 (5.8090)  loss_box_reg: 0.2026 (0.2299)  loss_objectness: 0.1430 (0.1497)  loss_rpn_box_reg: 0.0784 (0.0750)  time: 0.6275  data: 0.1327  max mem: 10714\n",
      "Training Epoch: [15]  [100/500]  eta: 0:04:10  lr: 0.000005  loss: 6.0615 (6.2459)  loss_classifier: 5.5873 (5.7913)  loss_box_reg: 0.2190 (0.2304)  loss_objectness: 0.1361 (0.1495)  loss_rpn_box_reg: 0.0787 (0.0747)  time: 0.6276  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [15]  [110/500]  eta: 0:04:04  lr: 0.000005  loss: 6.0329 (6.2405)  loss_classifier: 5.5448 (5.7837)  loss_box_reg: 0.2285 (0.2321)  loss_objectness: 0.1531 (0.1499)  loss_rpn_box_reg: 0.0737 (0.0748)  time: 0.6247  data: 0.1336  max mem: 10714\n",
      "Training Epoch: [15]  [120/500]  eta: 0:03:57  lr: 0.000005  loss: 6.0329 (6.2272)  loss_classifier: 5.5448 (5.7701)  loss_box_reg: 0.2274 (0.2327)  loss_objectness: 0.1523 (0.1494)  loss_rpn_box_reg: 0.0715 (0.0750)  time: 0.6223  data: 0.1309  max mem: 10714\n",
      "Training Epoch: [15]  [130/500]  eta: 0:03:51  lr: 0.000005  loss: 6.1056 (6.2409)  loss_classifier: 5.6367 (5.7814)  loss_box_reg: 0.2303 (0.2349)  loss_objectness: 0.1409 (0.1490)  loss_rpn_box_reg: 0.0715 (0.0756)  time: 0.6180  data: 0.1319  max mem: 10714\n",
      "Training Epoch: [15]  [140/500]  eta: 0:03:45  lr: 0.000005  loss: 5.9605 (6.2203)  loss_classifier: 5.3930 (5.7582)  loss_box_reg: 0.2408 (0.2359)  loss_objectness: 0.1368 (0.1496)  loss_rpn_box_reg: 0.0796 (0.0766)  time: 0.6257  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [15]  [150/500]  eta: 0:03:39  lr: 0.000005  loss: 5.9878 (6.2204)  loss_classifier: 5.3703 (5.7565)  loss_box_reg: 0.2476 (0.2377)  loss_objectness: 0.1529 (0.1503)  loss_rpn_box_reg: 0.0648 (0.0759)  time: 0.6264  data: 0.1353  max mem: 10714\n",
      "Training Epoch: [15]  [160/500]  eta: 0:03:33  lr: 0.000005  loss: 6.1366 (6.2067)  loss_classifier: 5.6257 (5.7444)  loss_box_reg: 0.2476 (0.2373)  loss_objectness: 0.1293 (0.1497)  loss_rpn_box_reg: 0.0648 (0.0752)  time: 0.6316  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [15]  [170/500]  eta: 0:03:26  lr: 0.000005  loss: 6.0217 (6.1960)  loss_classifier: 5.5602 (5.7325)  loss_box_reg: 0.2228 (0.2376)  loss_objectness: 0.1305 (0.1503)  loss_rpn_box_reg: 0.0662 (0.0756)  time: 0.6227  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [15]  [180/500]  eta: 0:03:20  lr: 0.000005  loss: 6.0319 (6.1926)  loss_classifier: 5.5999 (5.7300)  loss_box_reg: 0.2228 (0.2370)  loss_objectness: 0.1519 (0.1500)  loss_rpn_box_reg: 0.0852 (0.0756)  time: 0.6249  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [15]  [190/500]  eta: 0:03:14  lr: 0.000005  loss: 6.1986 (6.1944)  loss_classifier: 5.7452 (5.7312)  loss_box_reg: 0.2512 (0.2377)  loss_objectness: 0.1485 (0.1507)  loss_rpn_box_reg: 0.0571 (0.0747)  time: 0.6384  data: 0.1326  max mem: 10714\n",
      "Training Epoch: [15]  [200/500]  eta: 0:03:08  lr: 0.000005  loss: 6.3367 (6.2060)  loss_classifier: 5.8056 (5.7388)  loss_box_reg: 0.2801 (0.2398)  loss_objectness: 0.1700 (0.1516)  loss_rpn_box_reg: 0.0762 (0.0758)  time: 0.6313  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [15]  [210/500]  eta: 0:03:01  lr: 0.000005  loss: 6.3472 (6.2076)  loss_classifier: 5.8954 (5.7391)  loss_box_reg: 0.2467 (0.2393)  loss_objectness: 0.1737 (0.1527)  loss_rpn_box_reg: 0.0957 (0.0764)  time: 0.6047  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [15]  [220/500]  eta: 0:02:55  lr: 0.000005  loss: 6.3418 (6.2103)  loss_classifier: 5.8954 (5.7430)  loss_box_reg: 0.2316 (0.2392)  loss_objectness: 0.1641 (0.1522)  loss_rpn_box_reg: 0.0790 (0.0760)  time: 0.6204  data: 0.1330  max mem: 10714\n",
      "Training Epoch: [15]  [230/500]  eta: 0:02:49  lr: 0.000005  loss: 6.0836 (6.2050)  loss_classifier: 5.7054 (5.7383)  loss_box_reg: 0.2316 (0.2386)  loss_objectness: 0.1351 (0.1523)  loss_rpn_box_reg: 0.0630 (0.0758)  time: 0.6409  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [15]  [240/500]  eta: 0:02:42  lr: 0.000005  loss: 6.0700 (6.2074)  loss_classifier: 5.6424 (5.7414)  loss_box_reg: 0.2220 (0.2382)  loss_objectness: 0.1351 (0.1521)  loss_rpn_box_reg: 0.0666 (0.0757)  time: 0.6188  data: 0.1332  max mem: 10714\n",
      "Training Epoch: [15]  [250/500]  eta: 0:02:36  lr: 0.000005  loss: 6.1965 (6.2095)  loss_classifier: 5.6991 (5.7426)  loss_box_reg: 0.2335 (0.2386)  loss_objectness: 0.1599 (0.1525)  loss_rpn_box_reg: 0.0735 (0.0758)  time: 0.6272  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [15]  [260/500]  eta: 0:02:30  lr: 0.000005  loss: 6.1582 (6.2085)  loss_classifier: 5.6581 (5.7406)  loss_box_reg: 0.2405 (0.2390)  loss_objectness: 0.1695 (0.1530)  loss_rpn_box_reg: 0.0777 (0.0758)  time: 0.6384  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [15]  [270/500]  eta: 0:02:24  lr: 0.000005  loss: 6.0085 (6.1950)  loss_classifier: 5.5256 (5.7252)  loss_box_reg: 0.2520 (0.2401)  loss_objectness: 0.1702 (0.1539)  loss_rpn_box_reg: 0.0777 (0.0758)  time: 0.6214  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [15]  [280/500]  eta: 0:02:17  lr: 0.000005  loss: 5.9412 (6.1913)  loss_classifier: 5.3889 (5.7215)  loss_box_reg: 0.2543 (0.2404)  loss_objectness: 0.1569 (0.1536)  loss_rpn_box_reg: 0.0796 (0.0758)  time: 0.6163  data: 0.1336  max mem: 10714\n",
      "Training Epoch: [15]  [290/500]  eta: 0:02:11  lr: 0.000005  loss: 6.2219 (6.1930)  loss_classifier: 5.8995 (5.7250)  loss_box_reg: 0.2250 (0.2393)  loss_objectness: 0.1636 (0.1535)  loss_rpn_box_reg: 0.0573 (0.0753)  time: 0.6205  data: 0.1327  max mem: 10714\n",
      "Training Epoch: [15]  [300/500]  eta: 0:02:05  lr: 0.000005  loss: 6.1525 (6.1881)  loss_classifier: 5.8502 (5.7222)  loss_box_reg: 0.1970 (0.2379)  loss_objectness: 0.1337 (0.1527)  loss_rpn_box_reg: 0.0592 (0.0753)  time: 0.6260  data: 0.1310  max mem: 10714\n",
      "Training Epoch: [15]  [310/500]  eta: 0:01:59  lr: 0.000005  loss: 6.0394 (6.1875)  loss_classifier: 5.6966 (5.7221)  loss_box_reg: 0.1967 (0.2384)  loss_objectness: 0.1194 (0.1520)  loss_rpn_box_reg: 0.0604 (0.0751)  time: 0.6364  data: 0.1309  max mem: 10714\n",
      "Training Epoch: [15]  [320/500]  eta: 0:01:52  lr: 0.000005  loss: 6.2969 (6.2009)  loss_classifier: 5.8229 (5.7346)  loss_box_reg: 0.2305 (0.2384)  loss_objectness: 0.1458 (0.1523)  loss_rpn_box_reg: 0.0667 (0.0757)  time: 0.6335  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [15]  [330/500]  eta: 0:01:46  lr: 0.000005  loss: 6.2392 (6.1994)  loss_classifier: 5.8081 (5.7333)  loss_box_reg: 0.2305 (0.2387)  loss_objectness: 0.1458 (0.1520)  loss_rpn_box_reg: 0.0667 (0.0755)  time: 0.6207  data: 0.1328  max mem: 10714\n",
      "Training Epoch: [15]  [340/500]  eta: 0:01:40  lr: 0.000005  loss: 6.1228 (6.1985)  loss_classifier: 5.7546 (5.7325)  loss_box_reg: 0.2327 (0.2382)  loss_objectness: 0.1457 (0.1525)  loss_rpn_box_reg: 0.0638 (0.0753)  time: 0.6138  data: 0.1325  max mem: 10714\n",
      "Training Epoch: [15]  [350/500]  eta: 0:01:33  lr: 0.000005  loss: 6.2787 (6.2038)  loss_classifier: 5.8239 (5.7375)  loss_box_reg: 0.2216 (0.2378)  loss_objectness: 0.1607 (0.1531)  loss_rpn_box_reg: 0.0638 (0.0754)  time: 0.5980  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [15]  [360/500]  eta: 0:01:27  lr: 0.000005  loss: 6.2661 (6.2050)  loss_classifier: 5.8884 (5.7382)  loss_box_reg: 0.2216 (0.2382)  loss_objectness: 0.1607 (0.1531)  loss_rpn_box_reg: 0.0653 (0.0755)  time: 0.6065  data: 0.1369  max mem: 10714\n",
      "Training Epoch: [15]  [370/500]  eta: 0:01:21  lr: 0.000005  loss: 6.4065 (6.2149)  loss_classifier: 6.0282 (5.7483)  loss_box_reg: 0.2053 (0.2374)  loss_objectness: 0.1454 (0.1535)  loss_rpn_box_reg: 0.0800 (0.0758)  time: 0.6326  data: 0.1366  max mem: 10714\n",
      "Training Epoch: [15]  [380/500]  eta: 0:01:15  lr: 0.000005  loss: 6.3434 (6.2179)  loss_classifier: 5.9928 (5.7512)  loss_box_reg: 0.2053 (0.2377)  loss_objectness: 0.1425 (0.1533)  loss_rpn_box_reg: 0.0786 (0.0758)  time: 0.6314  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [15]  [390/500]  eta: 0:01:08  lr: 0.000005  loss: 6.3344 (6.2231)  loss_classifier: 5.8513 (5.7552)  loss_box_reg: 0.2514 (0.2380)  loss_objectness: 0.1471 (0.1537)  loss_rpn_box_reg: 0.0786 (0.0761)  time: 0.6222  data: 0.1353  max mem: 10714\n",
      "Training Epoch: [15]  [400/500]  eta: 0:01:02  lr: 0.000005  loss: 6.3062 (6.2190)  loss_classifier: 5.8513 (5.7508)  loss_box_reg: 0.2557 (0.2383)  loss_objectness: 0.1604 (0.1537)  loss_rpn_box_reg: 0.0746 (0.0763)  time: 0.6107  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [15]  [410/500]  eta: 0:00:56  lr: 0.000005  loss: 6.0872 (6.2170)  loss_classifier: 5.5503 (5.7494)  loss_box_reg: 0.2378 (0.2381)  loss_objectness: 0.1530 (0.1535)  loss_rpn_box_reg: 0.0746 (0.0760)  time: 0.6155  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [15]  [420/500]  eta: 0:00:49  lr: 0.000005  loss: 6.0905 (6.2175)  loss_classifier: 5.6083 (5.7500)  loss_box_reg: 0.2296 (0.2381)  loss_objectness: 0.1449 (0.1534)  loss_rpn_box_reg: 0.0680 (0.0760)  time: 0.6321  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [15]  [430/500]  eta: 0:00:43  lr: 0.000005  loss: 6.1350 (6.2156)  loss_classifier: 5.6831 (5.7490)  loss_box_reg: 0.2232 (0.2378)  loss_objectness: 0.1434 (0.1529)  loss_rpn_box_reg: 0.0664 (0.0759)  time: 0.6435  data: 0.1319  max mem: 10714\n",
      "Training Epoch: [15]  [440/500]  eta: 0:00:37  lr: 0.000005  loss: 6.1350 (6.2168)  loss_classifier: 5.6831 (5.7502)  loss_box_reg: 0.2299 (0.2379)  loss_objectness: 0.1419 (0.1531)  loss_rpn_box_reg: 0.0650 (0.0757)  time: 0.6478  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [15]  [450/500]  eta: 0:00:31  lr: 0.000005  loss: 6.0913 (6.2160)  loss_classifier: 5.6036 (5.7491)  loss_box_reg: 0.2326 (0.2377)  loss_objectness: 0.1574 (0.1532)  loss_rpn_box_reg: 0.0759 (0.0760)  time: 0.6268  data: 0.1368  max mem: 10714\n",
      "Training Epoch: [15]  [460/500]  eta: 0:00:25  lr: 0.000005  loss: 6.1520 (6.2165)  loss_classifier: 5.6612 (5.7498)  loss_box_reg: 0.2370 (0.2375)  loss_objectness: 0.1588 (0.1533)  loss_rpn_box_reg: 0.0655 (0.0759)  time: 0.6142  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [15]  [470/500]  eta: 0:00:18  lr: 0.000005  loss: 6.2327 (6.2180)  loss_classifier: 5.7518 (5.7503)  loss_box_reg: 0.2425 (0.2382)  loss_objectness: 0.1544 (0.1535)  loss_rpn_box_reg: 0.0653 (0.0761)  time: 0.6125  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [15]  [480/500]  eta: 0:00:12  lr: 0.000005  loss: 6.2327 (6.2161)  loss_classifier: 5.7646 (5.7482)  loss_box_reg: 0.2672 (0.2385)  loss_objectness: 0.1495 (0.1533)  loss_rpn_box_reg: 0.0811 (0.0761)  time: 0.6014  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [15]  [490/500]  eta: 0:00:06  lr: 0.000005  loss: 6.2605 (6.2206)  loss_classifier: 5.7929 (5.7527)  loss_box_reg: 0.2371 (0.2386)  loss_objectness: 0.1442 (0.1533)  loss_rpn_box_reg: 0.0682 (0.0760)  time: 0.6154  data: 0.1326  max mem: 10714\n",
      "Training Epoch: [15]  [499/500]  eta: 0:00:00  lr: 0.000005  loss: 6.2787 (6.2196)  loss_classifier: 5.7929 (5.7525)  loss_box_reg: 0.2145 (0.2382)  loss_objectness: 0.1467 (0.1533)  loss_rpn_box_reg: 0.0593 (0.0757)  time: 0.6259  data: 0.1321  max mem: 10714\n",
      "Training Epoch: [15] Total time: 0:05:12 (0.6244 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:50  model_time: 0.6992 (0.6992)  evaluator_time: 0.0350 (0.0350)  time: 0.8832  data: 0.1390  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4361 (0.4491)  evaluator_time: 0.0330 (0.0361)  time: 0.6262  data: 0.1482  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4701 (0.4514)  evaluator_time: 0.0360 (0.0377)  time: 0.6561  data: 0.1415  max mem: 10714\n",
      "Test: Total time: 0:01:20 (0.6402 s / it)\n",
      "Averaged stats: model_time: 0.4701 (0.4514)  evaluator_time: 0.0360 (0.0377)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.177\n",
      "Testing Epoch: [15]  [  0/125]  eta: 0:01:20  lr: 0.000005  loss: 6.2048 (6.2048)  loss_classifier: 5.6559 (5.6559)  loss_box_reg: 0.2943 (0.2943)  loss_objectness: 0.1224 (0.1224)  loss_rpn_box_reg: 0.1323 (0.1323)  time: 0.6451  data: 0.1480  max mem: 10714\n",
      "Testing Epoch: [15]  [100/125]  eta: 0:00:14  lr: 0.000005  loss: 5.9989 (6.1374)  loss_classifier: 5.4221 (5.6274)  loss_box_reg: 0.2637 (0.2889)  loss_objectness: 0.1297 (0.1321)  loss_rpn_box_reg: 0.0695 (0.0890)  time: 0.5837  data: 0.1459  max mem: 10714\n",
      "Testing Epoch: [15]  [124/125]  eta: 0:00:00  lr: 0.000005  loss: 6.1805 (6.1688)  loss_classifier: 5.6827 (5.6627)  loss_box_reg: 0.2502 (0.2844)  loss_objectness: 0.1170 (0.1324)  loss_rpn_box_reg: 0.0745 (0.0892)  time: 0.5976  data: 0.1439  max mem: 10714\n",
      "Testing Epoch: [15] Total time: 0:01:14 (0.5940 s / it)\n",
      "Training Epoch: [16]  [  0/500]  eta: 0:06:21  lr: 0.000005  loss: 6.7677 (6.7677)  loss_classifier: 6.2836 (6.2836)  loss_box_reg: 0.2526 (0.2526)  loss_objectness: 0.1675 (0.1675)  loss_rpn_box_reg: 0.0640 (0.0640)  time: 0.7632  data: 0.1390  max mem: 10714\n",
      "Training Epoch: [16]  [ 10/500]  eta: 0:05:04  lr: 0.000005  loss: 6.0666 (6.1373)  loss_classifier: 5.5572 (5.6624)  loss_box_reg: 0.2451 (0.2468)  loss_objectness: 0.1608 (0.1582)  loss_rpn_box_reg: 0.0583 (0.0700)  time: 0.6220  data: 0.1371  max mem: 10714\n",
      "Training Epoch: [16]  [ 20/500]  eta: 0:04:56  lr: 0.000005  loss: 6.0666 (6.1935)  loss_classifier: 5.5572 (5.7307)  loss_box_reg: 0.2413 (0.2384)  loss_objectness: 0.1575 (0.1529)  loss_rpn_box_reg: 0.0583 (0.0715)  time: 0.6114  data: 0.1329  max mem: 10714\n",
      "Training Epoch: [16]  [ 30/500]  eta: 0:04:49  lr: 0.000005  loss: 6.1489 (6.1576)  loss_classifier: 5.6307 (5.6902)  loss_box_reg: 0.2306 (0.2432)  loss_objectness: 0.1495 (0.1509)  loss_rpn_box_reg: 0.0734 (0.0733)  time: 0.6135  data: 0.1294  max mem: 10714\n",
      "Training Epoch: [16]  [ 40/500]  eta: 0:04:45  lr: 0.000005  loss: 6.1511 (6.2333)  loss_classifier: 5.6987 (5.7537)  loss_box_reg: 0.2304 (0.2405)  loss_objectness: 0.1643 (0.1596)  loss_rpn_box_reg: 0.0859 (0.0795)  time: 0.6247  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [16]  [ 50/500]  eta: 0:04:41  lr: 0.000005  loss: 6.2870 (6.2528)  loss_classifier: 5.7774 (5.7760)  loss_box_reg: 0.2262 (0.2415)  loss_objectness: 0.1779 (0.1572)  loss_rpn_box_reg: 0.0852 (0.0781)  time: 0.6374  data: 0.1383  max mem: 10714\n",
      "Training Epoch: [16]  [ 60/500]  eta: 0:04:34  lr: 0.000005  loss: 6.0884 (6.2359)  loss_classifier: 5.7682 (5.7727)  loss_box_reg: 0.2258 (0.2327)  loss_objectness: 0.1490 (0.1554)  loss_rpn_box_reg: 0.0604 (0.0751)  time: 0.6307  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [16]  [ 70/500]  eta: 0:04:29  lr: 0.000005  loss: 6.0800 (6.2223)  loss_classifier: 5.6272 (5.7526)  loss_box_reg: 0.2277 (0.2359)  loss_objectness: 0.1595 (0.1572)  loss_rpn_box_reg: 0.0703 (0.0765)  time: 0.6356  data: 0.1352  max mem: 10714\n",
      "Training Epoch: [16]  [ 80/500]  eta: 0:04:24  lr: 0.000005  loss: 6.0896 (6.2268)  loss_classifier: 5.6029 (5.7570)  loss_box_reg: 0.2443 (0.2382)  loss_objectness: 0.1567 (0.1558)  loss_rpn_box_reg: 0.0690 (0.0759)  time: 0.6444  data: 0.1364  max mem: 10714\n",
      "Training Epoch: [16]  [ 90/500]  eta: 0:04:18  lr: 0.000005  loss: 6.1709 (6.2380)  loss_classifier: 5.7807 (5.7733)  loss_box_reg: 0.2449 (0.2364)  loss_objectness: 0.1403 (0.1545)  loss_rpn_box_reg: 0.0593 (0.0737)  time: 0.6366  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [16]  [100/500]  eta: 0:04:11  lr: 0.000005  loss: 6.2768 (6.2453)  loss_classifier: 5.8288 (5.7830)  loss_box_reg: 0.1991 (0.2354)  loss_objectness: 0.1416 (0.1536)  loss_rpn_box_reg: 0.0593 (0.0733)  time: 0.6305  data: 0.1334  max mem: 10714\n",
      "Training Epoch: [16]  [110/500]  eta: 0:04:04  lr: 0.000005  loss: 6.2882 (6.2422)  loss_classifier: 5.8707 (5.7778)  loss_box_reg: 0.2057 (0.2368)  loss_objectness: 0.1363 (0.1541)  loss_rpn_box_reg: 0.0634 (0.0735)  time: 0.6210  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [16]  [120/500]  eta: 0:03:58  lr: 0.000005  loss: 6.1522 (6.2304)  loss_classifier: 5.7210 (5.7617)  loss_box_reg: 0.2540 (0.2393)  loss_objectness: 0.1366 (0.1538)  loss_rpn_box_reg: 0.0715 (0.0756)  time: 0.6178  data: 0.1334  max mem: 10714\n",
      "Training Epoch: [16]  [130/500]  eta: 0:03:52  lr: 0.000005  loss: 6.2775 (6.2352)  loss_classifier: 5.8098 (5.7661)  loss_box_reg: 0.2543 (0.2407)  loss_objectness: 0.1426 (0.1532)  loss_rpn_box_reg: 0.0698 (0.0753)  time: 0.6275  data: 0.1329  max mem: 10714\n",
      "Training Epoch: [16]  [140/500]  eta: 0:03:45  lr: 0.000005  loss: 6.3867 (6.2472)  loss_classifier: 5.8666 (5.7731)  loss_box_reg: 0.2640 (0.2432)  loss_objectness: 0.1513 (0.1548)  loss_rpn_box_reg: 0.0673 (0.0761)  time: 0.6245  data: 0.1359  max mem: 10714\n",
      "Training Epoch: [16]  [150/500]  eta: 0:03:39  lr: 0.000005  loss: 6.3250 (6.2492)  loss_classifier: 5.7243 (5.7766)  loss_box_reg: 0.2567 (0.2427)  loss_objectness: 0.1419 (0.1532)  loss_rpn_box_reg: 0.0681 (0.0768)  time: 0.6138  data: 0.1345  max mem: 10714\n",
      "Training Epoch: [16]  [160/500]  eta: 0:03:33  lr: 0.000005  loss: 6.1365 (6.2294)  loss_classifier: 5.6139 (5.7596)  loss_box_reg: 0.2463 (0.2420)  loss_objectness: 0.1328 (0.1521)  loss_rpn_box_reg: 0.0647 (0.0757)  time: 0.6222  data: 0.1325  max mem: 10714\n",
      "Training Epoch: [16]  [170/500]  eta: 0:03:26  lr: 0.000005  loss: 5.9954 (6.2231)  loss_classifier: 5.6139 (5.7539)  loss_box_reg: 0.2407 (0.2417)  loss_objectness: 0.1482 (0.1519)  loss_rpn_box_reg: 0.0647 (0.0756)  time: 0.6267  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [16]  [180/500]  eta: 0:03:20  lr: 0.000005  loss: 6.2545 (6.2272)  loss_classifier: 5.7215 (5.7590)  loss_box_reg: 0.2286 (0.2412)  loss_objectness: 0.1486 (0.1517)  loss_rpn_box_reg: 0.0608 (0.0754)  time: 0.6211  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [16]  [190/500]  eta: 0:03:14  lr: 0.000005  loss: 6.2568 (6.2281)  loss_classifier: 5.7658 (5.7593)  loss_box_reg: 0.2286 (0.2414)  loss_objectness: 0.1378 (0.1519)  loss_rpn_box_reg: 0.0595 (0.0755)  time: 0.6246  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [16]  [200/500]  eta: 0:03:07  lr: 0.000005  loss: 6.2789 (6.2363)  loss_classifier: 5.8674 (5.7701)  loss_box_reg: 0.2304 (0.2402)  loss_objectness: 0.1431 (0.1512)  loss_rpn_box_reg: 0.0599 (0.0747)  time: 0.6215  data: 0.1359  max mem: 10714\n",
      "Training Epoch: [16]  [210/500]  eta: 0:03:01  lr: 0.000005  loss: 6.4753 (6.2380)  loss_classifier: 5.9014 (5.7726)  loss_box_reg: 0.2175 (0.2392)  loss_objectness: 0.1475 (0.1516)  loss_rpn_box_reg: 0.0616 (0.0746)  time: 0.6219  data: 0.1334  max mem: 10714\n",
      "Training Epoch: [16]  [220/500]  eta: 0:02:55  lr: 0.000005  loss: 6.4753 (6.2449)  loss_classifier: 5.9014 (5.7789)  loss_box_reg: 0.2198 (0.2384)  loss_objectness: 0.1626 (0.1524)  loss_rpn_box_reg: 0.0819 (0.0752)  time: 0.6195  data: 0.1329  max mem: 10714\n",
      "Training Epoch: [16]  [230/500]  eta: 0:02:48  lr: 0.000005  loss: 6.0434 (6.2370)  loss_classifier: 5.6554 (5.7709)  loss_box_reg: 0.2194 (0.2369)  loss_objectness: 0.1651 (0.1528)  loss_rpn_box_reg: 0.0827 (0.0764)  time: 0.6104  data: 0.1330  max mem: 10714\n",
      "Training Epoch: [16]  [240/500]  eta: 0:02:42  lr: 0.000005  loss: 5.9300 (6.2281)  loss_classifier: 5.5017 (5.7616)  loss_box_reg: 0.2123 (0.2368)  loss_objectness: 0.1654 (0.1533)  loss_rpn_box_reg: 0.0776 (0.0764)  time: 0.6211  data: 0.1334  max mem: 10714\n",
      "Training Epoch: [16]  [250/500]  eta: 0:02:36  lr: 0.000005  loss: 6.1065 (6.2254)  loss_classifier: 5.5639 (5.7599)  loss_box_reg: 0.2193 (0.2361)  loss_objectness: 0.1624 (0.1534)  loss_rpn_box_reg: 0.0644 (0.0760)  time: 0.6224  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [16]  [260/500]  eta: 0:02:29  lr: 0.000005  loss: 6.1828 (6.2245)  loss_classifier: 5.7200 (5.7604)  loss_box_reg: 0.2349 (0.2356)  loss_objectness: 0.1565 (0.1534)  loss_rpn_box_reg: 0.0519 (0.0750)  time: 0.6165  data: 0.1329  max mem: 10714\n",
      "Training Epoch: [16]  [270/500]  eta: 0:02:23  lr: 0.000005  loss: 6.0912 (6.2212)  loss_classifier: 5.5177 (5.7574)  loss_box_reg: 0.2283 (0.2350)  loss_objectness: 0.1398 (0.1531)  loss_rpn_box_reg: 0.0596 (0.0756)  time: 0.6233  data: 0.1335  max mem: 10714\n",
      "Training Epoch: [16]  [280/500]  eta: 0:02:17  lr: 0.000005  loss: 6.1295 (6.2198)  loss_classifier: 5.7539 (5.7557)  loss_box_reg: 0.2283 (0.2355)  loss_objectness: 0.1363 (0.1529)  loss_rpn_box_reg: 0.0798 (0.0758)  time: 0.6308  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [16]  [290/500]  eta: 0:02:11  lr: 0.000005  loss: 6.2343 (6.2232)  loss_classifier: 5.7539 (5.7591)  loss_box_reg: 0.2314 (0.2355)  loss_objectness: 0.1386 (0.1526)  loss_rpn_box_reg: 0.0699 (0.0760)  time: 0.6316  data: 0.1320  max mem: 10714\n",
      "Training Epoch: [16]  [300/500]  eta: 0:02:05  lr: 0.000005  loss: 6.2343 (6.2222)  loss_classifier: 5.7347 (5.7577)  loss_box_reg: 0.2279 (0.2353)  loss_objectness: 0.1484 (0.1529)  loss_rpn_box_reg: 0.0737 (0.0763)  time: 0.6319  data: 0.1323  max mem: 10714\n",
      "Training Epoch: [16]  [310/500]  eta: 0:01:58  lr: 0.000005  loss: 6.1662 (6.2166)  loss_classifier: 5.6078 (5.7512)  loss_box_reg: 0.2526 (0.2365)  loss_objectness: 0.1505 (0.1529)  loss_rpn_box_reg: 0.0682 (0.0760)  time: 0.6330  data: 0.1366  max mem: 10714\n",
      "Training Epoch: [16]  [320/500]  eta: 0:01:52  lr: 0.000005  loss: 6.2179 (6.2161)  loss_classifier: 5.6812 (5.7519)  loss_box_reg: 0.2353 (0.2357)  loss_objectness: 0.1505 (0.1526)  loss_rpn_box_reg: 0.0682 (0.0758)  time: 0.6259  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [16]  [330/500]  eta: 0:01:46  lr: 0.000005  loss: 6.1876 (6.2138)  loss_classifier: 5.6725 (5.7483)  loss_box_reg: 0.2353 (0.2363)  loss_objectness: 0.1561 (0.1531)  loss_rpn_box_reg: 0.0713 (0.0761)  time: 0.6272  data: 0.1329  max mem: 10714\n",
      "Training Epoch: [16]  [340/500]  eta: 0:01:39  lr: 0.000005  loss: 6.0928 (6.2126)  loss_classifier: 5.6146 (5.7461)  loss_box_reg: 0.2478 (0.2371)  loss_objectness: 0.1512 (0.1529)  loss_rpn_box_reg: 0.0859 (0.0764)  time: 0.6218  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [16]  [350/500]  eta: 0:01:33  lr: 0.000005  loss: 6.1352 (6.2138)  loss_classifier: 5.7124 (5.7462)  loss_box_reg: 0.2686 (0.2382)  loss_objectness: 0.1489 (0.1529)  loss_rpn_box_reg: 0.0758 (0.0765)  time: 0.6225  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [16]  [360/500]  eta: 0:01:27  lr: 0.000005  loss: 6.1742 (6.2166)  loss_classifier: 5.7333 (5.7487)  loss_box_reg: 0.2649 (0.2383)  loss_objectness: 0.1430 (0.1528)  loss_rpn_box_reg: 0.0755 (0.0768)  time: 0.6256  data: 0.1334  max mem: 10714\n",
      "Training Epoch: [16]  [370/500]  eta: 0:01:21  lr: 0.000005  loss: 6.3743 (6.2225)  loss_classifier: 5.7839 (5.7545)  loss_box_reg: 0.2280 (0.2384)  loss_objectness: 0.1363 (0.1526)  loss_rpn_box_reg: 0.0801 (0.0770)  time: 0.6136  data: 0.1318  max mem: 10714\n",
      "Training Epoch: [16]  [380/500]  eta: 0:01:14  lr: 0.000005  loss: 6.2880 (6.2197)  loss_classifier: 5.7559 (5.7527)  loss_box_reg: 0.2248 (0.2377)  loss_objectness: 0.1363 (0.1523)  loss_rpn_box_reg: 0.0750 (0.0769)  time: 0.6247  data: 0.1317  max mem: 10714\n",
      "Training Epoch: [16]  [390/500]  eta: 0:01:08  lr: 0.000005  loss: 6.1283 (6.2195)  loss_classifier: 5.6973 (5.7524)  loss_box_reg: 0.2318 (0.2384)  loss_objectness: 0.1327 (0.1521)  loss_rpn_box_reg: 0.0730 (0.0767)  time: 0.6459  data: 0.1328  max mem: 10714\n",
      "Training Epoch: [16]  [400/500]  eta: 0:01:02  lr: 0.000005  loss: 6.0075 (6.2160)  loss_classifier: 5.5512 (5.7476)  loss_box_reg: 0.2836 (0.2394)  loss_objectness: 0.1429 (0.1524)  loss_rpn_box_reg: 0.0693 (0.0766)  time: 0.6353  data: 0.1362  max mem: 10714\n",
      "Training Epoch: [16]  [410/500]  eta: 0:00:56  lr: 0.000005  loss: 5.9251 (6.2124)  loss_classifier: 5.5151 (5.7422)  loss_box_reg: 0.2515 (0.2406)  loss_objectness: 0.1618 (0.1527)  loss_rpn_box_reg: 0.0731 (0.0768)  time: 0.6213  data: 0.1364  max mem: 10714\n",
      "Training Epoch: [16]  [420/500]  eta: 0:00:50  lr: 0.000005  loss: 6.0105 (6.2078)  loss_classifier: 5.5555 (5.7380)  loss_box_reg: 0.2411 (0.2402)  loss_objectness: 0.1538 (0.1529)  loss_rpn_box_reg: 0.0791 (0.0766)  time: 0.6225  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [16]  [430/500]  eta: 0:00:43  lr: 0.000005  loss: 6.0749 (6.2091)  loss_classifier: 5.5888 (5.7392)  loss_box_reg: 0.2323 (0.2401)  loss_objectness: 0.1593 (0.1531)  loss_rpn_box_reg: 0.0668 (0.0767)  time: 0.6056  data: 0.1323  max mem: 10714\n",
      "Training Epoch: [16]  [440/500]  eta: 0:00:37  lr: 0.000005  loss: 6.2131 (6.2132)  loss_classifier: 5.8178 (5.7437)  loss_box_reg: 0.2343 (0.2398)  loss_objectness: 0.1575 (0.1530)  loss_rpn_box_reg: 0.0714 (0.0766)  time: 0.6052  data: 0.1329  max mem: 10714\n",
      "Training Epoch: [16]  [450/500]  eta: 0:00:31  lr: 0.000005  loss: 6.0582 (6.2122)  loss_classifier: 5.5709 (5.7433)  loss_box_reg: 0.2299 (0.2395)  loss_objectness: 0.1492 (0.1530)  loss_rpn_box_reg: 0.0528 (0.0765)  time: 0.6272  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [16]  [460/500]  eta: 0:00:24  lr: 0.000005  loss: 6.1252 (6.2147)  loss_classifier: 5.6561 (5.7450)  loss_box_reg: 0.2254 (0.2403)  loss_objectness: 0.1434 (0.1530)  loss_rpn_box_reg: 0.0528 (0.0764)  time: 0.6310  data: 0.1333  max mem: 10714\n",
      "Training Epoch: [16]  [470/500]  eta: 0:00:18  lr: 0.000005  loss: 6.2757 (6.2152)  loss_classifier: 5.7993 (5.7463)  loss_box_reg: 0.2130 (0.2395)  loss_objectness: 0.1567 (0.1532)  loss_rpn_box_reg: 0.0653 (0.0762)  time: 0.6346  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [16]  [480/500]  eta: 0:00:12  lr: 0.000005  loss: 6.1778 (6.2149)  loss_classifier: 5.7416 (5.7459)  loss_box_reg: 0.2141 (0.2399)  loss_objectness: 0.1532 (0.1531)  loss_rpn_box_reg: 0.0585 (0.0760)  time: 0.6258  data: 0.1331  max mem: 10714\n",
      "Training Epoch: [16]  [490/500]  eta: 0:00:06  lr: 0.000005  loss: 6.0844 (6.2158)  loss_classifier: 5.5942 (5.7468)  loss_box_reg: 0.2229 (0.2396)  loss_objectness: 0.1532 (0.1532)  loss_rpn_box_reg: 0.0692 (0.0761)  time: 0.6176  data: 0.1335  max mem: 10714\n",
      "Training Epoch: [16]  [499/500]  eta: 0:00:00  lr: 0.000005  loss: 6.0594 (6.2131)  loss_classifier: 5.5401 (5.7453)  loss_box_reg: 0.2108 (0.2387)  loss_objectness: 0.1599 (0.1531)  loss_rpn_box_reg: 0.0717 (0.0760)  time: 0.6196  data: 0.1329  max mem: 10714\n",
      "Training Epoch: [16] Total time: 0:05:12 (0.6247 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:45  model_time: 0.6581 (0.6581)  evaluator_time: 0.0350 (0.0350)  time: 0.8412  data: 0.1390  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4391 (0.4492)  evaluator_time: 0.0330 (0.0369)  time: 0.6332  data: 0.1546  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4661 (0.4512)  evaluator_time: 0.0360 (0.0382)  time: 0.6530  data: 0.1422  max mem: 10714\n",
      "Test: Total time: 0:01:19 (0.6389 s / it)\n",
      "Averaged stats: model_time: 0.4661 (0.4512)  evaluator_time: 0.0360 (0.0382)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [16]  [  0/125]  eta: 0:01:20  lr: 0.000005  loss: 6.2115 (6.2115)  loss_classifier: 5.6632 (5.6632)  loss_box_reg: 0.2923 (0.2923)  loss_objectness: 0.1243 (0.1243)  loss_rpn_box_reg: 0.1318 (0.1318)  time: 0.6411  data: 0.1410  max mem: 10714\n",
      "Testing Epoch: [16]  [100/125]  eta: 0:00:14  lr: 0.000005  loss: 5.9909 (6.1352)  loss_classifier: 5.4197 (5.6250)  loss_box_reg: 0.2600 (0.2884)  loss_objectness: 0.1314 (0.1321)  loss_rpn_box_reg: 0.0694 (0.0898)  time: 0.5834  data: 0.1453  max mem: 10714\n",
      "Testing Epoch: [16]  [124/125]  eta: 0:00:00  lr: 0.000005  loss: 6.1776 (6.1668)  loss_classifier: 5.6791 (5.6610)  loss_box_reg: 0.2502 (0.2840)  loss_objectness: 0.1197 (0.1319)  loss_rpn_box_reg: 0.0745 (0.0898)  time: 0.5998  data: 0.1463  max mem: 10714\n",
      "Testing Epoch: [16] Total time: 0:01:14 (0.5965 s / it)\n",
      "Training Epoch: [17]  [  0/500]  eta: 0:05:52  lr: 0.000000  loss: 5.5626 (5.5626)  loss_classifier: 5.0815 (5.0815)  loss_box_reg: 0.2160 (0.2160)  loss_objectness: 0.1717 (0.1717)  loss_rpn_box_reg: 0.0933 (0.0933)  time: 0.7042  data: 0.1340  max mem: 10714\n",
      "Training Epoch: [17]  [ 10/500]  eta: 0:05:13  lr: 0.000000  loss: 6.2080 (6.1494)  loss_classifier: 5.7876 (5.6991)  loss_box_reg: 0.2185 (0.2301)  loss_objectness: 0.1329 (0.1429)  loss_rpn_box_reg: 0.0933 (0.0774)  time: 0.6401  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [17]  [ 20/500]  eta: 0:05:01  lr: 0.000000  loss: 6.1842 (6.1198)  loss_classifier: 5.7304 (5.6624)  loss_box_reg: 0.2236 (0.2391)  loss_objectness: 0.1386 (0.1471)  loss_rpn_box_reg: 0.0669 (0.0712)  time: 0.6250  data: 0.1353  max mem: 10714\n",
      "Training Epoch: [17]  [ 30/500]  eta: 0:04:54  lr: 0.000000  loss: 6.1842 (6.1563)  loss_classifier: 5.7304 (5.7101)  loss_box_reg: 0.2229 (0.2339)  loss_objectness: 0.1429 (0.1447)  loss_rpn_box_reg: 0.0627 (0.0677)  time: 0.6182  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [17]  [ 40/500]  eta: 0:04:46  lr: 0.000000  loss: 6.2674 (6.1689)  loss_classifier: 5.7427 (5.7212)  loss_box_reg: 0.1932 (0.2289)  loss_objectness: 0.1526 (0.1483)  loss_rpn_box_reg: 0.0625 (0.0704)  time: 0.6171  data: 0.1323  max mem: 10714\n",
      "Training Epoch: [17]  [ 50/500]  eta: 0:04:40  lr: 0.000000  loss: 6.1985 (6.2092)  loss_classifier: 5.7283 (5.7560)  loss_box_reg: 0.2085 (0.2311)  loss_objectness: 0.1566 (0.1489)  loss_rpn_box_reg: 0.0753 (0.0732)  time: 0.6200  data: 0.1325  max mem: 10714\n",
      "Training Epoch: [17]  [ 60/500]  eta: 0:04:33  lr: 0.000000  loss: 6.1932 (6.2229)  loss_classifier: 5.6518 (5.7639)  loss_box_reg: 0.2195 (0.2317)  loss_objectness: 0.1688 (0.1534)  loss_rpn_box_reg: 0.0786 (0.0739)  time: 0.6191  data: 0.1360  max mem: 10714\n",
      "Training Epoch: [17]  [ 70/500]  eta: 0:04:27  lr: 0.000000  loss: 6.0784 (6.2106)  loss_classifier: 5.5954 (5.7426)  loss_box_reg: 0.2367 (0.2374)  loss_objectness: 0.1755 (0.1540)  loss_rpn_box_reg: 0.0842 (0.0766)  time: 0.6158  data: 0.1382  max mem: 10714\n",
      "Training Epoch: [17]  [ 80/500]  eta: 0:04:20  lr: 0.000000  loss: 6.0151 (6.1832)  loss_classifier: 5.5679 (5.7112)  loss_box_reg: 0.2604 (0.2385)  loss_objectness: 0.1631 (0.1560)  loss_rpn_box_reg: 0.0842 (0.0775)  time: 0.6143  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [17]  [ 90/500]  eta: 0:04:13  lr: 0.000000  loss: 5.9887 (6.1770)  loss_classifier: 5.4432 (5.7014)  loss_box_reg: 0.2621 (0.2387)  loss_objectness: 0.1688 (0.1576)  loss_rpn_box_reg: 0.0808 (0.0792)  time: 0.6125  data: 0.1335  max mem: 10714\n",
      "Training Epoch: [17]  [100/500]  eta: 0:04:08  lr: 0.000000  loss: 6.2753 (6.1837)  loss_classifier: 5.7882 (5.7096)  loss_box_reg: 0.2110 (0.2372)  loss_objectness: 0.1529 (0.1569)  loss_rpn_box_reg: 0.0798 (0.0800)  time: 0.6259  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [17]  [110/500]  eta: 0:04:02  lr: 0.000000  loss: 6.2744 (6.1677)  loss_classifier: 5.7819 (5.6997)  loss_box_reg: 0.2054 (0.2352)  loss_objectness: 0.1379 (0.1546)  loss_rpn_box_reg: 0.0618 (0.0781)  time: 0.6325  data: 0.1331  max mem: 10714\n",
      "Training Epoch: [17]  [120/500]  eta: 0:03:56  lr: 0.000000  loss: 6.2049 (6.1749)  loss_classifier: 5.6691 (5.7042)  loss_box_reg: 0.2235 (0.2368)  loss_objectness: 0.1319 (0.1544)  loss_rpn_box_reg: 0.0526 (0.0794)  time: 0.6223  data: 0.1317  max mem: 10714\n",
      "Training Epoch: [17]  [130/500]  eta: 0:03:50  lr: 0.000000  loss: 6.2931 (6.1916)  loss_classifier: 5.7094 (5.7192)  loss_box_reg: 0.2484 (0.2380)  loss_objectness: 0.1561 (0.1553)  loss_rpn_box_reg: 0.0631 (0.0790)  time: 0.6206  data: 0.1328  max mem: 10714\n",
      "Training Epoch: [17]  [140/500]  eta: 0:03:43  lr: 0.000000  loss: 6.2128 (6.1843)  loss_classifier: 5.8492 (5.7113)  loss_box_reg: 0.2633 (0.2388)  loss_objectness: 0.1550 (0.1553)  loss_rpn_box_reg: 0.0662 (0.0789)  time: 0.6106  data: 0.1332  max mem: 10714\n",
      "Training Epoch: [17]  [150/500]  eta: 0:03:37  lr: 0.000000  loss: 6.3448 (6.1970)  loss_classifier: 5.8492 (5.7236)  loss_box_reg: 0.2429 (0.2380)  loss_objectness: 0.1550 (0.1557)  loss_rpn_box_reg: 0.0744 (0.0798)  time: 0.6167  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [17]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.2049 (6.1871)  loss_classifier: 5.6071 (5.7149)  loss_box_reg: 0.2303 (0.2373)  loss_objectness: 0.1528 (0.1552)  loss_rpn_box_reg: 0.0744 (0.0798)  time: 0.6638  data: 0.1467  max mem: 10714\n",
      "Training Epoch: [17]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.1049 (6.1813)  loss_classifier: 5.4959 (5.7087)  loss_box_reg: 0.2404 (0.2373)  loss_objectness: 0.1373 (0.1556)  loss_rpn_box_reg: 0.0720 (0.0797)  time: 0.6575  data: 0.1507  max mem: 10714\n",
      "Training Epoch: [17]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.1518 (6.1959)  loss_classifier: 5.6728 (5.7270)  loss_box_reg: 0.2403 (0.2354)  loss_objectness: 0.1333 (0.1540)  loss_rpn_box_reg: 0.0730 (0.0794)  time: 0.6456  data: 0.1421  max mem: 10714\n",
      "Training Epoch: [17]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.4075 (6.2126)  loss_classifier: 6.0401 (5.7419)  loss_box_reg: 0.2403 (0.2368)  loss_objectness: 0.1438 (0.1554)  loss_rpn_box_reg: 0.0644 (0.0785)  time: 0.6472  data: 0.1421  max mem: 10714\n",
      "Training Epoch: [17]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.2867 (6.2126)  loss_classifier: 5.7887 (5.7407)  loss_box_reg: 0.2570 (0.2380)  loss_objectness: 0.1657 (0.1557)  loss_rpn_box_reg: 0.0606 (0.0782)  time: 0.6295  data: 0.1439  max mem: 10714\n",
      "Training Epoch: [17]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.1480 (6.2177)  loss_classifier: 5.7127 (5.7461)  loss_box_reg: 0.2540 (0.2384)  loss_objectness: 0.1396 (0.1556)  loss_rpn_box_reg: 0.0673 (0.0775)  time: 0.6247  data: 0.1416  max mem: 10714\n",
      "Training Epoch: [17]  [220/500]  eta: 0:02:56  lr: 0.000000  loss: 6.1480 (6.2200)  loss_classifier: 5.6921 (5.7489)  loss_box_reg: 0.2540 (0.2388)  loss_objectness: 0.1376 (0.1551)  loss_rpn_box_reg: 0.0675 (0.0773)  time: 0.6438  data: 0.1408  max mem: 10714\n",
      "Training Epoch: [17]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.1088 (6.2217)  loss_classifier: 5.5787 (5.7497)  loss_box_reg: 0.2669 (0.2399)  loss_objectness: 0.1546 (0.1552)  loss_rpn_box_reg: 0.0666 (0.0769)  time: 0.6476  data: 0.1474  max mem: 10714\n",
      "Training Epoch: [17]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.0294 (6.2120)  loss_classifier: 5.5329 (5.7388)  loss_box_reg: 0.2697 (0.2412)  loss_objectness: 0.1639 (0.1555)  loss_rpn_box_reg: 0.0660 (0.0765)  time: 0.6477  data: 0.1502  max mem: 10714\n",
      "Training Epoch: [17]  [250/500]  eta: 0:02:38  lr: 0.000000  loss: 6.0198 (6.2085)  loss_classifier: 5.5633 (5.7349)  loss_box_reg: 0.2487 (0.2411)  loss_objectness: 0.1502 (0.1554)  loss_rpn_box_reg: 0.0646 (0.0771)  time: 0.6781  data: 0.1498  max mem: 10714\n",
      "Training Epoch: [17]  [260/500]  eta: 0:02:32  lr: 0.000000  loss: 6.1145 (6.2066)  loss_classifier: 5.5944 (5.7307)  loss_box_reg: 0.2338 (0.2417)  loss_objectness: 0.1578 (0.1563)  loss_rpn_box_reg: 0.0921 (0.0779)  time: 0.6662  data: 0.1519  max mem: 10714\n",
      "Training Epoch: [17]  [270/500]  eta: 0:02:25  lr: 0.000000  loss: 6.1709 (6.2116)  loss_classifier: 5.6135 (5.7378)  loss_box_reg: 0.2292 (0.2407)  loss_objectness: 0.1578 (0.1556)  loss_rpn_box_reg: 0.0744 (0.0776)  time: 0.6532  data: 0.1469  max mem: 10714\n",
      "Training Epoch: [17]  [280/500]  eta: 0:02:19  lr: 0.000000  loss: 6.3004 (6.2142)  loss_classifier: 5.7190 (5.7400)  loss_box_reg: 0.2264 (0.2413)  loss_objectness: 0.1558 (0.1555)  loss_rpn_box_reg: 0.0621 (0.0774)  time: 0.6467  data: 0.1401  max mem: 10714\n",
      "Training Epoch: [17]  [290/500]  eta: 0:02:13  lr: 0.000000  loss: 6.0869 (6.2128)  loss_classifier: 5.6707 (5.7388)  loss_box_reg: 0.2364 (0.2414)  loss_objectness: 0.1558 (0.1555)  loss_rpn_box_reg: 0.0646 (0.0770)  time: 0.6413  data: 0.1397  max mem: 10714\n",
      "Training Epoch: [17]  [300/500]  eta: 0:02:06  lr: 0.000000  loss: 6.1972 (6.2123)  loss_classifier: 5.6453 (5.7385)  loss_box_reg: 0.2180 (0.2414)  loss_objectness: 0.1486 (0.1555)  loss_rpn_box_reg: 0.0655 (0.0769)  time: 0.6409  data: 0.1380  max mem: 10714\n",
      "Training Epoch: [17]  [310/500]  eta: 0:02:00  lr: 0.000000  loss: 6.2223 (6.2220)  loss_classifier: 5.7210 (5.7496)  loss_box_reg: 0.2157 (0.2408)  loss_objectness: 0.1350 (0.1550)  loss_rpn_box_reg: 0.0663 (0.0766)  time: 0.6355  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [17]  [320/500]  eta: 0:01:54  lr: 0.000000  loss: 6.1406 (6.2180)  loss_classifier: 5.6647 (5.7470)  loss_box_reg: 0.2112 (0.2403)  loss_objectness: 0.1281 (0.1544)  loss_rpn_box_reg: 0.0629 (0.0763)  time: 0.6392  data: 0.1327  max mem: 10714\n",
      "Training Epoch: [17]  [330/500]  eta: 0:01:48  lr: 0.000000  loss: 6.0934 (6.2220)  loss_classifier: 5.6519 (5.7521)  loss_box_reg: 0.2247 (0.2405)  loss_objectness: 0.1336 (0.1538)  loss_rpn_box_reg: 0.0566 (0.0757)  time: 0.6436  data: 0.1367  max mem: 10714\n",
      "Training Epoch: [17]  [340/500]  eta: 0:01:41  lr: 0.000000  loss: 6.0934 (6.2191)  loss_classifier: 5.6712 (5.7500)  loss_box_reg: 0.2247 (0.2398)  loss_objectness: 0.1346 (0.1538)  loss_rpn_box_reg: 0.0545 (0.0754)  time: 0.6293  data: 0.1391  max mem: 10714\n",
      "Training Epoch: [17]  [350/500]  eta: 0:01:35  lr: 0.000000  loss: 6.0729 (6.2210)  loss_classifier: 5.6817 (5.7523)  loss_box_reg: 0.1993 (0.2399)  loss_objectness: 0.1579 (0.1536)  loss_rpn_box_reg: 0.0586 (0.0753)  time: 0.6165  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [17]  [360/500]  eta: 0:01:28  lr: 0.000000  loss: 6.3548 (6.2300)  loss_classifier: 5.9119 (5.7619)  loss_box_reg: 0.2278 (0.2393)  loss_objectness: 0.1401 (0.1532)  loss_rpn_box_reg: 0.0787 (0.0755)  time: 0.6350  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [17]  [370/500]  eta: 0:01:22  lr: 0.000000  loss: 6.4161 (6.2327)  loss_classifier: 5.9124 (5.7630)  loss_box_reg: 0.2258 (0.2408)  loss_objectness: 0.1374 (0.1527)  loss_rpn_box_reg: 0.0839 (0.0762)  time: 0.6328  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [17]  [380/500]  eta: 0:01:16  lr: 0.000000  loss: 6.1165 (6.2295)  loss_classifier: 5.6013 (5.7596)  loss_box_reg: 0.2505 (0.2410)  loss_objectness: 0.1379 (0.1527)  loss_rpn_box_reg: 0.0825 (0.0762)  time: 0.6303  data: 0.1364  max mem: 10714\n",
      "Training Epoch: [17]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 5.9859 (6.2212)  loss_classifier: 5.4901 (5.7521)  loss_box_reg: 0.2279 (0.2407)  loss_objectness: 0.1379 (0.1524)  loss_rpn_box_reg: 0.0663 (0.0760)  time: 0.6336  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [17]  [400/500]  eta: 0:01:03  lr: 0.000000  loss: 5.9371 (6.2198)  loss_classifier: 5.4395 (5.7508)  loss_box_reg: 0.2232 (0.2403)  loss_objectness: 0.1334 (0.1524)  loss_rpn_box_reg: 0.0699 (0.0764)  time: 0.6334  data: 0.1362  max mem: 10714\n",
      "Training Epoch: [17]  [410/500]  eta: 0:00:57  lr: 0.000000  loss: 5.9420 (6.2175)  loss_classifier: 5.5682 (5.7485)  loss_box_reg: 0.2254 (0.2401)  loss_objectness: 0.1334 (0.1522)  loss_rpn_box_reg: 0.0810 (0.0767)  time: 0.6401  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [17]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.1690 (6.2176)  loss_classifier: 5.6981 (5.7483)  loss_box_reg: 0.2458 (0.2404)  loss_objectness: 0.1420 (0.1524)  loss_rpn_box_reg: 0.0800 (0.0765)  time: 0.6294  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [17]  [430/500]  eta: 0:00:44  lr: 0.000000  loss: 6.1690 (6.2170)  loss_classifier: 5.6380 (5.7461)  loss_box_reg: 0.2654 (0.2415)  loss_objectness: 0.1585 (0.1526)  loss_rpn_box_reg: 0.0757 (0.0768)  time: 0.6186  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [17]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.0362 (6.2140)  loss_classifier: 5.4946 (5.7435)  loss_box_reg: 0.2654 (0.2413)  loss_objectness: 0.1589 (0.1526)  loss_rpn_box_reg: 0.0715 (0.0765)  time: 0.6127  data: 0.1364  max mem: 10714\n",
      "Training Epoch: [17]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0926 (6.2158)  loss_classifier: 5.6507 (5.7446)  loss_box_reg: 0.2647 (0.2419)  loss_objectness: 0.1505 (0.1528)  loss_rpn_box_reg: 0.0637 (0.0764)  time: 0.6204  data: 0.1379  max mem: 10714\n",
      "Training Epoch: [17]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.2532 (6.2166)  loss_classifier: 5.8166 (5.7456)  loss_box_reg: 0.2472 (0.2419)  loss_objectness: 0.1501 (0.1526)  loss_rpn_box_reg: 0.0741 (0.0765)  time: 0.6335  data: 0.1366  max mem: 10714\n",
      "Training Epoch: [17]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0146 (6.2130)  loss_classifier: 5.6579 (5.7424)  loss_box_reg: 0.2284 (0.2417)  loss_objectness: 0.1429 (0.1525)  loss_rpn_box_reg: 0.0642 (0.0764)  time: 0.6276  data: 0.1336  max mem: 10714\n",
      "Training Epoch: [17]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1448 (6.2124)  loss_classifier: 5.6061 (5.7427)  loss_box_reg: 0.2143 (0.2411)  loss_objectness: 0.1429 (0.1523)  loss_rpn_box_reg: 0.0612 (0.0762)  time: 0.6294  data: 0.1330  max mem: 10714\n",
      "Training Epoch: [17]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1871 (6.2113)  loss_classifier: 5.8262 (5.7421)  loss_box_reg: 0.2054 (0.2406)  loss_objectness: 0.1527 (0.1524)  loss_rpn_box_reg: 0.0650 (0.0762)  time: 0.6336  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [17]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1448 (6.2107)  loss_classifier: 5.6439 (5.7414)  loss_box_reg: 0.2331 (0.2408)  loss_objectness: 0.1572 (0.1524)  loss_rpn_box_reg: 0.0746 (0.0761)  time: 0.6410  data: 0.1352  max mem: 10714\n",
      "Training Epoch: [17] Total time: 0:05:16 (0.6333 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:55  model_time: 0.7392 (0.7392)  evaluator_time: 0.0350 (0.0350)  time: 0.9272  data: 0.1440  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4401 (0.4529)  evaluator_time: 0.0340 (0.0342)  time: 0.6394  data: 0.1558  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4751 (0.4543)  evaluator_time: 0.0360 (0.0351)  time: 0.6545  data: 0.1486  max mem: 10714\n",
      "Test: Total time: 0:01:20 (0.6445 s / it)\n",
      "Averaged stats: model_time: 0.4751 (0.4543)  evaluator_time: 0.0360 (0.0351)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.28s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [17]  [  0/125]  eta: 0:01:22  lr: 0.000000  loss: 6.2001 (6.2001)  loss_classifier: 5.6625 (5.6625)  loss_box_reg: 0.2923 (0.2923)  loss_objectness: 0.1141 (0.1141)  loss_rpn_box_reg: 0.1312 (0.1312)  time: 0.6621  data: 0.1500  max mem: 10714\n",
      "Testing Epoch: [17]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0238 (6.1324)  loss_classifier: 5.4237 (5.6225)  loss_box_reg: 0.2600 (0.2892)  loss_objectness: 0.1289 (0.1314)  loss_rpn_box_reg: 0.0716 (0.0893)  time: 0.5919  data: 0.1454  max mem: 10714\n",
      "Testing Epoch: [17]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1693 (6.1641)  loss_classifier: 5.6908 (5.6583)  loss_box_reg: 0.2501 (0.2847)  loss_objectness: 0.1212 (0.1318)  loss_rpn_box_reg: 0.0745 (0.0894)  time: 0.5986  data: 0.1454  max mem: 10714\n",
      "Testing Epoch: [17] Total time: 0:01:14 (0.5984 s / it)\n",
      "Training Epoch: [18]  [  0/500]  eta: 0:07:29  lr: 0.000000  loss: 6.5624 (6.5624)  loss_classifier: 6.0806 (6.0806)  loss_box_reg: 0.2801 (0.2801)  loss_objectness: 0.1242 (0.1242)  loss_rpn_box_reg: 0.0775 (0.0775)  time: 0.8992  data: 0.1420  max mem: 10714\n",
      "Training Epoch: [18]  [ 10/500]  eta: 0:05:24  lr: 0.000000  loss: 6.2940 (6.3122)  loss_classifier: 5.8096 (5.8389)  loss_box_reg: 0.2801 (0.2412)  loss_objectness: 0.1496 (0.1511)  loss_rpn_box_reg: 0.0738 (0.0810)  time: 0.6623  data: 0.1356  max mem: 10714\n",
      "Training Epoch: [18]  [ 20/500]  eta: 0:05:08  lr: 0.000000  loss: 6.3088 (6.3730)  loss_classifier: 5.8886 (5.8943)  loss_box_reg: 0.2290 (0.2415)  loss_objectness: 0.1467 (0.1527)  loss_rpn_box_reg: 0.0698 (0.0845)  time: 0.6289  data: 0.1352  max mem: 10714\n",
      "Training Epoch: [18]  [ 30/500]  eta: 0:04:55  lr: 0.000000  loss: 6.3088 (6.2909)  loss_classifier: 5.8668 (5.8076)  loss_box_reg: 0.2517 (0.2528)  loss_objectness: 0.1385 (0.1480)  loss_rpn_box_reg: 0.0730 (0.0825)  time: 0.6108  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [18]  [ 40/500]  eta: 0:04:47  lr: 0.000000  loss: 6.1813 (6.3178)  loss_classifier: 5.7055 (5.8457)  loss_box_reg: 0.2351 (0.2471)  loss_objectness: 0.1322 (0.1462)  loss_rpn_box_reg: 0.0768 (0.0789)  time: 0.6073  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [18]  [ 50/500]  eta: 0:04:44  lr: 0.000000  loss: 6.1082 (6.2839)  loss_classifier: 5.6717 (5.8030)  loss_box_reg: 0.2283 (0.2531)  loss_objectness: 0.1365 (0.1493)  loss_rpn_box_reg: 0.0677 (0.0785)  time: 0.6345  data: 0.1357  max mem: 10714\n",
      "Training Epoch: [18]  [ 60/500]  eta: 0:04:38  lr: 0.000000  loss: 6.1082 (6.3046)  loss_classifier: 5.6021 (5.8260)  loss_box_reg: 0.2529 (0.2508)  loss_objectness: 0.1476 (0.1502)  loss_rpn_box_reg: 0.0759 (0.0776)  time: 0.6465  data: 0.1377  max mem: 10714\n",
      "Training Epoch: [18]  [ 70/500]  eta: 0:04:31  lr: 0.000000  loss: 6.1391 (6.2745)  loss_classifier: 5.5150 (5.7955)  loss_box_reg: 0.2357 (0.2511)  loss_objectness: 0.1443 (0.1497)  loss_rpn_box_reg: 0.0759 (0.0782)  time: 0.6341  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [18]  [ 80/500]  eta: 0:04:24  lr: 0.000000  loss: 6.1391 (6.2488)  loss_classifier: 5.5150 (5.7732)  loss_box_reg: 0.2357 (0.2498)  loss_objectness: 0.1395 (0.1491)  loss_rpn_box_reg: 0.0639 (0.0767)  time: 0.6204  data: 0.1332  max mem: 10714\n",
      "Training Epoch: [18]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 6.1421 (6.2450)  loss_classifier: 5.6306 (5.7686)  loss_box_reg: 0.2304 (0.2499)  loss_objectness: 0.1536 (0.1517)  loss_rpn_box_reg: 0.0596 (0.0749)  time: 0.6151  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [18]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 6.0738 (6.2214)  loss_classifier: 5.6347 (5.7493)  loss_box_reg: 0.2221 (0.2463)  loss_objectness: 0.1536 (0.1516)  loss_rpn_box_reg: 0.0595 (0.0742)  time: 0.6160  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [18]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.2192 (6.2380)  loss_classifier: 5.7404 (5.7673)  loss_box_reg: 0.2304 (0.2474)  loss_objectness: 0.1356 (0.1512)  loss_rpn_box_reg: 0.0438 (0.0721)  time: 0.6145  data: 0.1331  max mem: 10714\n",
      "Training Epoch: [18]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.3037 (6.2392)  loss_classifier: 5.8409 (5.7673)  loss_box_reg: 0.2699 (0.2493)  loss_objectness: 0.1356 (0.1500)  loss_rpn_box_reg: 0.0471 (0.0725)  time: 0.6202  data: 0.1327  max mem: 10714\n",
      "Training Epoch: [18]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.2809 (6.2359)  loss_classifier: 5.8152 (5.7636)  loss_box_reg: 0.2385 (0.2496)  loss_objectness: 0.1402 (0.1499)  loss_rpn_box_reg: 0.0742 (0.0729)  time: 0.6268  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [18]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.2418 (6.2415)  loss_classifier: 5.7518 (5.7703)  loss_box_reg: 0.2347 (0.2479)  loss_objectness: 0.1427 (0.1501)  loss_rpn_box_reg: 0.0719 (0.0731)  time: 0.6488  data: 0.1340  max mem: 10714\n",
      "Training Epoch: [18]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.2217 (6.2379)  loss_classifier: 5.7144 (5.7647)  loss_box_reg: 0.2347 (0.2480)  loss_objectness: 0.1497 (0.1505)  loss_rpn_box_reg: 0.0731 (0.0747)  time: 0.6375  data: 0.1331  max mem: 10714\n",
      "Training Epoch: [18]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.0389 (6.2277)  loss_classifier: 5.4932 (5.7551)  loss_box_reg: 0.2373 (0.2472)  loss_objectness: 0.1504 (0.1511)  loss_rpn_box_reg: 0.0711 (0.0744)  time: 0.6114  data: 0.1336  max mem: 10714\n",
      "Training Epoch: [18]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.0799 (6.2390)  loss_classifier: 5.6814 (5.7635)  loss_box_reg: 0.2297 (0.2479)  loss_objectness: 0.1519 (0.1519)  loss_rpn_box_reg: 0.0711 (0.0756)  time: 0.6222  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [18]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.3989 (6.2451)  loss_classifier: 5.8372 (5.7708)  loss_box_reg: 0.2083 (0.2459)  loss_objectness: 0.1531 (0.1528)  loss_rpn_box_reg: 0.0796 (0.0756)  time: 0.6192  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [18]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.2105 (6.2349)  loss_classifier: 5.6892 (5.7628)  loss_box_reg: 0.1879 (0.2446)  loss_objectness: 0.1413 (0.1525)  loss_rpn_box_reg: 0.0613 (0.0750)  time: 0.6158  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [18]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.1540 (6.2350)  loss_classifier: 5.6892 (5.7637)  loss_box_reg: 0.2022 (0.2436)  loss_objectness: 0.1373 (0.1520)  loss_rpn_box_reg: 0.0819 (0.0757)  time: 0.6288  data: 0.1336  max mem: 10714\n",
      "Training Epoch: [18]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.1384 (6.2334)  loss_classifier: 5.6917 (5.7628)  loss_box_reg: 0.2180 (0.2438)  loss_objectness: 0.1369 (0.1518)  loss_rpn_box_reg: 0.0668 (0.0750)  time: 0.6309  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [18]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.1958 (6.2334)  loss_classifier: 5.8725 (5.7646)  loss_box_reg: 0.2201 (0.2432)  loss_objectness: 0.1417 (0.1514)  loss_rpn_box_reg: 0.0535 (0.0741)  time: 0.6323  data: 0.1359  max mem: 10714\n",
      "Training Epoch: [18]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.2693 (6.2341)  loss_classifier: 5.7963 (5.7657)  loss_box_reg: 0.2271 (0.2425)  loss_objectness: 0.1445 (0.1521)  loss_rpn_box_reg: 0.0532 (0.0738)  time: 0.6255  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [18]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.2469 (6.2325)  loss_classifier: 5.7384 (5.7636)  loss_box_reg: 0.2286 (0.2420)  loss_objectness: 0.1562 (0.1528)  loss_rpn_box_reg: 0.0624 (0.0741)  time: 0.6162  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [18]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.1963 (6.2366)  loss_classifier: 5.7430 (5.7673)  loss_box_reg: 0.2534 (0.2425)  loss_objectness: 0.1546 (0.1528)  loss_rpn_box_reg: 0.0624 (0.0741)  time: 0.6233  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [18]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.2936 (6.2406)  loss_classifier: 5.7624 (5.7738)  loss_box_reg: 0.2225 (0.2408)  loss_objectness: 0.1378 (0.1526)  loss_rpn_box_reg: 0.0572 (0.0734)  time: 0.6243  data: 0.1325  max mem: 10714\n",
      "Training Epoch: [18]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.4132 (6.2486)  loss_classifier: 5.9218 (5.7816)  loss_box_reg: 0.1755 (0.2399)  loss_objectness: 0.1501 (0.1532)  loss_rpn_box_reg: 0.0643 (0.0738)  time: 0.6255  data: 0.1366  max mem: 10714\n",
      "Training Epoch: [18]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.4132 (6.2546)  loss_classifier: 5.9218 (5.7902)  loss_box_reg: 0.1802 (0.2380)  loss_objectness: 0.1501 (0.1531)  loss_rpn_box_reg: 0.0574 (0.0733)  time: 0.6307  data: 0.1382  max mem: 10714\n",
      "Training Epoch: [18]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.2638 (6.2483)  loss_classifier: 5.7451 (5.7830)  loss_box_reg: 0.1900 (0.2388)  loss_objectness: 0.1405 (0.1528)  loss_rpn_box_reg: 0.0585 (0.0736)  time: 0.6346  data: 0.1361  max mem: 10714\n",
      "Training Epoch: [18]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 5.9821 (6.2465)  loss_classifier: 5.6310 (5.7796)  loss_box_reg: 0.2555 (0.2392)  loss_objectness: 0.1458 (0.1532)  loss_rpn_box_reg: 0.0793 (0.0745)  time: 0.6289  data: 0.1360  max mem: 10714\n",
      "Training Epoch: [18]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.2099 (6.2473)  loss_classifier: 5.6820 (5.7785)  loss_box_reg: 0.2508 (0.2403)  loss_objectness: 0.1632 (0.1538)  loss_rpn_box_reg: 0.0757 (0.0748)  time: 0.6171  data: 0.1353  max mem: 10714\n",
      "Training Epoch: [18]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.0628 (6.2402)  loss_classifier: 5.5780 (5.7713)  loss_box_reg: 0.2672 (0.2406)  loss_objectness: 0.1579 (0.1534)  loss_rpn_box_reg: 0.0703 (0.0749)  time: 0.6284  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [18]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 5.8672 (6.2311)  loss_classifier: 5.4406 (5.7639)  loss_box_reg: 0.2323 (0.2401)  loss_objectness: 0.1333 (0.1525)  loss_rpn_box_reg: 0.0589 (0.0746)  time: 0.6418  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [18]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 5.9599 (6.2325)  loss_classifier: 5.4656 (5.7655)  loss_box_reg: 0.2303 (0.2398)  loss_objectness: 0.1333 (0.1522)  loss_rpn_box_reg: 0.0659 (0.0751)  time: 0.6297  data: 0.1322  max mem: 10714\n",
      "Training Epoch: [18]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.1265 (6.2344)  loss_classifier: 5.6474 (5.7670)  loss_box_reg: 0.2332 (0.2401)  loss_objectness: 0.1407 (0.1520)  loss_rpn_box_reg: 0.0739 (0.0753)  time: 0.6233  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [18]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.2852 (6.2377)  loss_classifier: 5.8489 (5.7700)  loss_box_reg: 0.2332 (0.2401)  loss_objectness: 0.1448 (0.1521)  loss_rpn_box_reg: 0.0721 (0.0754)  time: 0.6304  data: 0.1340  max mem: 10714\n",
      "Training Epoch: [18]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.2422 (6.2353)  loss_classifier: 5.7651 (5.7676)  loss_box_reg: 0.2191 (0.2402)  loss_objectness: 0.1377 (0.1522)  loss_rpn_box_reg: 0.0712 (0.0753)  time: 0.6438  data: 0.1352  max mem: 10714\n",
      "Training Epoch: [18]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.0710 (6.2221)  loss_classifier: 5.5276 (5.7538)  loss_box_reg: 0.2454 (0.2412)  loss_objectness: 0.1318 (0.1518)  loss_rpn_box_reg: 0.0728 (0.0755)  time: 0.6470  data: 0.1374  max mem: 10714\n",
      "Training Epoch: [18]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 5.6655 (6.2163)  loss_classifier: 5.2211 (5.7473)  loss_box_reg: 0.2680 (0.2416)  loss_objectness: 0.1345 (0.1518)  loss_rpn_box_reg: 0.0790 (0.0756)  time: 0.6399  data: 0.1356  max mem: 10714\n",
      "Training Epoch: [18]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.0341 (6.2198)  loss_classifier: 5.6344 (5.7504)  loss_box_reg: 0.2641 (0.2416)  loss_objectness: 0.1593 (0.1521)  loss_rpn_box_reg: 0.0719 (0.0756)  time: 0.6233  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [18]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.3593 (6.2259)  loss_classifier: 5.8679 (5.7566)  loss_box_reg: 0.2236 (0.2414)  loss_objectness: 0.1523 (0.1522)  loss_rpn_box_reg: 0.0688 (0.0757)  time: 0.6095  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [18]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.4221 (6.2290)  loss_classifier: 5.8184 (5.7597)  loss_box_reg: 0.2129 (0.2411)  loss_objectness: 0.1523 (0.1525)  loss_rpn_box_reg: 0.0734 (0.0758)  time: 0.6258  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [18]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1765 (6.2244)  loss_classifier: 5.6842 (5.7543)  loss_box_reg: 0.2317 (0.2412)  loss_objectness: 0.1525 (0.1525)  loss_rpn_box_reg: 0.0786 (0.0764)  time: 0.6397  data: 0.1370  max mem: 10714\n",
      "Training Epoch: [18]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1765 (6.2263)  loss_classifier: 5.6842 (5.7559)  loss_box_reg: 0.2317 (0.2412)  loss_objectness: 0.1506 (0.1527)  loss_rpn_box_reg: 0.0870 (0.0766)  time: 0.6367  data: 0.1386  max mem: 10714\n",
      "Training Epoch: [18]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1108 (6.2261)  loss_classifier: 5.6806 (5.7565)  loss_box_reg: 0.2117 (0.2404)  loss_objectness: 0.1432 (0.1526)  loss_rpn_box_reg: 0.0639 (0.0765)  time: 0.6257  data: 0.1368  max mem: 10714\n",
      "Training Epoch: [18]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0233 (6.2212)  loss_classifier: 5.6158 (5.7517)  loss_box_reg: 0.2091 (0.2402)  loss_objectness: 0.1432 (0.1529)  loss_rpn_box_reg: 0.0665 (0.0765)  time: 0.6267  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [18]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1389 (6.2227)  loss_classifier: 5.6719 (5.7528)  loss_box_reg: 0.2319 (0.2407)  loss_objectness: 0.1405 (0.1526)  loss_rpn_box_reg: 0.0747 (0.0766)  time: 0.6246  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [18]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2209 (6.2217)  loss_classifier: 5.7891 (5.7522)  loss_box_reg: 0.2350 (0.2402)  loss_objectness: 0.1438 (0.1526)  loss_rpn_box_reg: 0.0762 (0.0768)  time: 0.6177  data: 0.1335  max mem: 10714\n",
      "Training Epoch: [18]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0592 (6.2185)  loss_classifier: 5.6659 (5.7498)  loss_box_reg: 0.2072 (0.2398)  loss_objectness: 0.1442 (0.1524)  loss_rpn_box_reg: 0.0692 (0.0765)  time: 0.6281  data: 0.1340  max mem: 10714\n",
      "Training Epoch: [18]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 5.9818 (6.2150)  loss_classifier: 5.5649 (5.7468)  loss_box_reg: 0.2072 (0.2393)  loss_objectness: 0.1519 (0.1525)  loss_rpn_box_reg: 0.0626 (0.0763)  time: 0.6419  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [18] Total time: 0:05:14 (0.6282 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:00  model_time: 0.7732 (0.7732)  evaluator_time: 0.0350 (0.0350)  time: 0.9602  data: 0.1420  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4491 (0.4538)  evaluator_time: 0.0340 (0.0350)  time: 0.6421  data: 0.1556  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4711 (0.4549)  evaluator_time: 0.0360 (0.0358)  time: 0.6610  data: 0.1560  max mem: 10714\n",
      "Test: Total time: 0:01:20 (0.6460 s / it)\n",
      "Averaged stats: model_time: 0.4711 (0.4549)  evaluator_time: 0.0360 (0.0358)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.28s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [18]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.1948 (6.1948)  loss_classifier: 5.6467 (5.6467)  loss_box_reg: 0.2937 (0.2937)  loss_objectness: 0.1222 (0.1222)  loss_rpn_box_reg: 0.1322 (0.1322)  time: 0.6481  data: 0.1440  max mem: 10714\n",
      "Testing Epoch: [18]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0035 (6.1303)  loss_classifier: 5.4145 (5.6192)  loss_box_reg: 0.2603 (0.2890)  loss_objectness: 0.1323 (0.1322)  loss_rpn_box_reg: 0.0714 (0.0899)  time: 0.5874  data: 0.1448  max mem: 10714\n",
      "Testing Epoch: [18]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1677 (6.1622)  loss_classifier: 5.6826 (5.6557)  loss_box_reg: 0.2500 (0.2845)  loss_objectness: 0.1211 (0.1320)  loss_rpn_box_reg: 0.0745 (0.0900)  time: 0.6007  data: 0.1464  max mem: 10714\n",
      "Testing Epoch: [18] Total time: 0:01:14 (0.5980 s / it)\n",
      "Training Epoch: [19]  [  0/500]  eta: 0:06:37  lr: 0.000000  loss: 6.2761 (6.2761)  loss_classifier: 5.7040 (5.7040)  loss_box_reg: 0.2629 (0.2629)  loss_objectness: 0.2487 (0.2487)  loss_rpn_box_reg: 0.0605 (0.0605)  time: 0.7952  data: 0.1320  max mem: 10714\n",
      "Training Epoch: [19]  [ 10/500]  eta: 0:05:06  lr: 0.000000  loss: 6.2761 (6.1863)  loss_classifier: 5.7040 (5.6990)  loss_box_reg: 0.2591 (0.2523)  loss_objectness: 0.1551 (0.1510)  loss_rpn_box_reg: 0.0769 (0.0840)  time: 0.6252  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [19]  [ 20/500]  eta: 0:05:01  lr: 0.000000  loss: 6.0191 (6.1417)  loss_classifier: 5.4463 (5.6629)  loss_box_reg: 0.2530 (0.2517)  loss_objectness: 0.1527 (0.1513)  loss_rpn_box_reg: 0.0763 (0.0758)  time: 0.6203  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [19]  [ 30/500]  eta: 0:04:56  lr: 0.000000  loss: 6.1863 (6.1760)  loss_classifier: 5.6422 (5.6833)  loss_box_reg: 0.2359 (0.2601)  loss_objectness: 0.1527 (0.1553)  loss_rpn_box_reg: 0.0628 (0.0773)  time: 0.6340  data: 0.1370  max mem: 10714\n",
      "Training Epoch: [19]  [ 40/500]  eta: 0:04:50  lr: 0.000000  loss: 6.2029 (6.1523)  loss_classifier: 5.6842 (5.6749)  loss_box_reg: 0.2359 (0.2510)  loss_objectness: 0.1439 (0.1556)  loss_rpn_box_reg: 0.0534 (0.0709)  time: 0.6351  data: 0.1363  max mem: 10714\n",
      "Training Epoch: [19]  [ 50/500]  eta: 0:04:43  lr: 0.000000  loss: 6.2529 (6.1939)  loss_classifier: 5.7326 (5.7184)  loss_box_reg: 0.2243 (0.2463)  loss_objectness: 0.1513 (0.1568)  loss_rpn_box_reg: 0.0608 (0.0724)  time: 0.6281  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [19]  [ 60/500]  eta: 0:04:38  lr: 0.000000  loss: 6.1772 (6.1733)  loss_classifier: 5.7098 (5.7035)  loss_box_reg: 0.2243 (0.2423)  loss_objectness: 0.1494 (0.1531)  loss_rpn_box_reg: 0.0863 (0.0744)  time: 0.6327  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [19]  [ 70/500]  eta: 0:04:31  lr: 0.000000  loss: 6.0200 (6.1548)  loss_classifier: 5.5996 (5.6872)  loss_box_reg: 0.2262 (0.2428)  loss_objectness: 0.1395 (0.1521)  loss_rpn_box_reg: 0.0632 (0.0728)  time: 0.6355  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [19]  [ 80/500]  eta: 0:04:24  lr: 0.000000  loss: 6.1782 (6.1755)  loss_classifier: 5.7349 (5.7080)  loss_box_reg: 0.2316 (0.2416)  loss_objectness: 0.1461 (0.1527)  loss_rpn_box_reg: 0.0599 (0.0732)  time: 0.6265  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [19]  [ 90/500]  eta: 0:04:18  lr: 0.000000  loss: 6.0661 (6.1624)  loss_classifier: 5.6613 (5.6976)  loss_box_reg: 0.2166 (0.2406)  loss_objectness: 0.1500 (0.1516)  loss_rpn_box_reg: 0.0636 (0.0726)  time: 0.6317  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [19]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 5.9762 (6.1590)  loss_classifier: 5.4695 (5.6871)  loss_box_reg: 0.2729 (0.2455)  loss_objectness: 0.1470 (0.1518)  loss_rpn_box_reg: 0.0748 (0.0747)  time: 0.6219  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [19]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.0209 (6.1675)  loss_classifier: 5.5304 (5.6917)  loss_box_reg: 0.2771 (0.2472)  loss_objectness: 0.1470 (0.1528)  loss_rpn_box_reg: 0.0842 (0.0757)  time: 0.6113  data: 0.1364  max mem: 10714\n",
      "Training Epoch: [19]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.2328 (6.1818)  loss_classifier: 5.7293 (5.7077)  loss_box_reg: 0.2457 (0.2457)  loss_objectness: 0.1416 (0.1534)  loss_rpn_box_reg: 0.0709 (0.0750)  time: 0.6248  data: 0.1357  max mem: 10714\n",
      "Training Epoch: [19]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 6.1777 (6.1787)  loss_classifier: 5.6669 (5.7014)  loss_box_reg: 0.2491 (0.2491)  loss_objectness: 0.1487 (0.1535)  loss_rpn_box_reg: 0.0634 (0.0747)  time: 0.6303  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [19]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.1516 (6.1723)  loss_classifier: 5.5882 (5.6943)  loss_box_reg: 0.2553 (0.2488)  loss_objectness: 0.1502 (0.1536)  loss_rpn_box_reg: 0.0639 (0.0756)  time: 0.6278  data: 0.1359  max mem: 10714\n",
      "Training Epoch: [19]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 5.9920 (6.1645)  loss_classifier: 5.6165 (5.6878)  loss_box_reg: 0.2374 (0.2486)  loss_objectness: 0.1415 (0.1525)  loss_rpn_box_reg: 0.0687 (0.0755)  time: 0.6271  data: 0.1353  max mem: 10714\n",
      "Training Epoch: [19]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 5.9920 (6.1587)  loss_classifier: 5.5099 (5.6828)  loss_box_reg: 0.2424 (0.2476)  loss_objectness: 0.1450 (0.1529)  loss_rpn_box_reg: 0.0687 (0.0754)  time: 0.6275  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [19]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.1136 (6.1698)  loss_classifier: 5.5966 (5.6956)  loss_box_reg: 0.2295 (0.2459)  loss_objectness: 0.1543 (0.1526)  loss_rpn_box_reg: 0.0701 (0.0757)  time: 0.6268  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [19]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.1168 (6.1728)  loss_classifier: 5.6580 (5.6983)  loss_box_reg: 0.2364 (0.2463)  loss_objectness: 0.1403 (0.1527)  loss_rpn_box_reg: 0.0693 (0.0754)  time: 0.6270  data: 0.1319  max mem: 10714\n",
      "Training Epoch: [19]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.1369 (6.1828)  loss_classifier: 5.6580 (5.7099)  loss_box_reg: 0.2381 (0.2463)  loss_objectness: 0.1342 (0.1519)  loss_rpn_box_reg: 0.0681 (0.0747)  time: 0.6341  data: 0.1321  max mem: 10714\n",
      "Training Epoch: [19]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.2250 (6.1832)  loss_classifier: 5.7436 (5.7105)  loss_box_reg: 0.2221 (0.2460)  loss_objectness: 0.1440 (0.1517)  loss_rpn_box_reg: 0.0715 (0.0751)  time: 0.6236  data: 0.1319  max mem: 10714\n",
      "Training Epoch: [19]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.2123 (6.1873)  loss_classifier: 5.7615 (5.7184)  loss_box_reg: 0.2214 (0.2444)  loss_objectness: 0.1301 (0.1502)  loss_rpn_box_reg: 0.0701 (0.0743)  time: 0.6197  data: 0.1306  max mem: 10714\n",
      "Training Epoch: [19]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.2123 (6.1882)  loss_classifier: 5.8776 (5.7194)  loss_box_reg: 0.2069 (0.2440)  loss_objectness: 0.1240 (0.1502)  loss_rpn_box_reg: 0.0684 (0.0746)  time: 0.6158  data: 0.1316  max mem: 10714\n",
      "Training Epoch: [19]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 5.9693 (6.1833)  loss_classifier: 5.5490 (5.7152)  loss_box_reg: 0.2120 (0.2428)  loss_objectness: 0.1572 (0.1507)  loss_rpn_box_reg: 0.0716 (0.0747)  time: 0.6188  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [19]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 5.9693 (6.1804)  loss_classifier: 5.5020 (5.7133)  loss_box_reg: 0.2141 (0.2423)  loss_objectness: 0.1424 (0.1501)  loss_rpn_box_reg: 0.0707 (0.0747)  time: 0.6294  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [19]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 5.9522 (6.1787)  loss_classifier: 5.4794 (5.7102)  loss_box_reg: 0.2279 (0.2426)  loss_objectness: 0.1430 (0.1505)  loss_rpn_box_reg: 0.0842 (0.0753)  time: 0.6086  data: 0.1321  max mem: 10714\n",
      "Training Epoch: [19]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.1123 (6.1813)  loss_classifier: 5.5489 (5.7106)  loss_box_reg: 0.2438 (0.2432)  loss_objectness: 0.1585 (0.1514)  loss_rpn_box_reg: 0.0874 (0.0761)  time: 0.6025  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [19]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.0593 (6.1717)  loss_classifier: 5.5489 (5.7027)  loss_box_reg: 0.2328 (0.2425)  loss_objectness: 0.1493 (0.1509)  loss_rpn_box_reg: 0.0572 (0.0756)  time: 0.6189  data: 0.1360  max mem: 10714\n",
      "Training Epoch: [19]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.0563 (6.1787)  loss_classifier: 5.5926 (5.7095)  loss_box_reg: 0.2215 (0.2426)  loss_objectness: 0.1380 (0.1510)  loss_rpn_box_reg: 0.0602 (0.0756)  time: 0.6267  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [19]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.2302 (6.1804)  loss_classifier: 5.7330 (5.7103)  loss_box_reg: 0.2490 (0.2432)  loss_objectness: 0.1386 (0.1508)  loss_rpn_box_reg: 0.0733 (0.0760)  time: 0.6291  data: 0.1359  max mem: 10714\n",
      "Training Epoch: [19]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.0947 (6.1790)  loss_classifier: 5.6350 (5.7092)  loss_box_reg: 0.2490 (0.2433)  loss_objectness: 0.1397 (0.1506)  loss_rpn_box_reg: 0.0719 (0.0760)  time: 0.6230  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [19]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.2325 (6.1865)  loss_classifier: 5.6693 (5.7170)  loss_box_reg: 0.2279 (0.2425)  loss_objectness: 0.1476 (0.1511)  loss_rpn_box_reg: 0.0719 (0.0759)  time: 0.6226  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [19]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2880 (6.1846)  loss_classifier: 5.7808 (5.7149)  loss_box_reg: 0.2311 (0.2423)  loss_objectness: 0.1476 (0.1513)  loss_rpn_box_reg: 0.0784 (0.0761)  time: 0.6451  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [19]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.1020 (6.1801)  loss_classifier: 5.6270 (5.7107)  loss_box_reg: 0.2339 (0.2423)  loss_objectness: 0.1405 (0.1511)  loss_rpn_box_reg: 0.0777 (0.0760)  time: 0.6320  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [19]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.1004 (6.1791)  loss_classifier: 5.5549 (5.7111)  loss_box_reg: 0.2062 (0.2412)  loss_objectness: 0.1405 (0.1510)  loss_rpn_box_reg: 0.0654 (0.0758)  time: 0.6209  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [19]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.3261 (6.1880)  loss_classifier: 5.9113 (5.7202)  loss_box_reg: 0.2170 (0.2413)  loss_objectness: 0.1409 (0.1512)  loss_rpn_box_reg: 0.0552 (0.0754)  time: 0.6367  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [19]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.4038 (6.1987)  loss_classifier: 5.9489 (5.7309)  loss_box_reg: 0.2295 (0.2408)  loss_objectness: 0.1530 (0.1514)  loss_rpn_box_reg: 0.0552 (0.0756)  time: 0.6303  data: 0.1353  max mem: 10714\n",
      "Training Epoch: [19]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.2975 (6.2009)  loss_classifier: 5.8294 (5.7327)  loss_box_reg: 0.2196 (0.2404)  loss_objectness: 0.1536 (0.1520)  loss_rpn_box_reg: 0.0808 (0.0758)  time: 0.6111  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [19]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1304 (6.1965)  loss_classifier: 5.6922 (5.7284)  loss_box_reg: 0.2363 (0.2404)  loss_objectness: 0.1536 (0.1519)  loss_rpn_box_reg: 0.0808 (0.0758)  time: 0.6081  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [19]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1287 (6.1947)  loss_classifier: 5.6001 (5.7255)  loss_box_reg: 0.2405 (0.2409)  loss_objectness: 0.1605 (0.1521)  loss_rpn_box_reg: 0.0720 (0.0761)  time: 0.6132  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [19]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.0945 (6.1898)  loss_classifier: 5.5069 (5.7194)  loss_box_reg: 0.2383 (0.2416)  loss_objectness: 0.1704 (0.1525)  loss_rpn_box_reg: 0.0694 (0.0763)  time: 0.6229  data: 0.1362  max mem: 10714\n",
      "Training Epoch: [19]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2702 (6.1965)  loss_classifier: 5.8009 (5.7266)  loss_box_reg: 0.2267 (0.2412)  loss_objectness: 0.1704 (0.1526)  loss_rpn_box_reg: 0.0694 (0.0761)  time: 0.6329  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [19]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.3298 (6.1963)  loss_classifier: 5.9081 (5.7281)  loss_box_reg: 0.2017 (0.2404)  loss_objectness: 0.1368 (0.1523)  loss_rpn_box_reg: 0.0634 (0.0756)  time: 0.6331  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [19]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1323 (6.1937)  loss_classifier: 5.6196 (5.7253)  loss_box_reg: 0.2262 (0.2402)  loss_objectness: 0.1342 (0.1523)  loss_rpn_box_reg: 0.0627 (0.0759)  time: 0.6225  data: 0.1333  max mem: 10714\n",
      "Training Epoch: [19]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1420 (6.1963)  loss_classifier: 5.7099 (5.7285)  loss_box_reg: 0.2192 (0.2399)  loss_objectness: 0.1434 (0.1523)  loss_rpn_box_reg: 0.0620 (0.0756)  time: 0.6075  data: 0.1329  max mem: 10714\n",
      "Training Epoch: [19]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.3060 (6.2027)  loss_classifier: 5.8300 (5.7354)  loss_box_reg: 0.2192 (0.2395)  loss_objectness: 0.1447 (0.1522)  loss_rpn_box_reg: 0.0620 (0.0755)  time: 0.6183  data: 0.1357  max mem: 10714\n",
      "Training Epoch: [19]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.2749 (6.2045)  loss_classifier: 5.8190 (5.7369)  loss_box_reg: 0.2318 (0.2396)  loss_objectness: 0.1475 (0.1523)  loss_rpn_box_reg: 0.0723 (0.0757)  time: 0.6230  data: 0.1368  max mem: 10714\n",
      "Training Epoch: [19]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1875 (6.2062)  loss_classifier: 5.7309 (5.7378)  loss_box_reg: 0.2559 (0.2398)  loss_objectness: 0.1544 (0.1525)  loss_rpn_box_reg: 0.0824 (0.0760)  time: 0.6147  data: 0.1366  max mem: 10714\n",
      "Training Epoch: [19]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.3698 (6.2124)  loss_classifier: 5.8731 (5.7443)  loss_box_reg: 0.2559 (0.2398)  loss_objectness: 0.1514 (0.1524)  loss_rpn_box_reg: 0.0761 (0.0759)  time: 0.6329  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [19]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.3469 (6.2120)  loss_classifier: 5.8959 (5.7451)  loss_box_reg: 0.2081 (0.2389)  loss_objectness: 0.1378 (0.1522)  loss_rpn_box_reg: 0.0637 (0.0757)  time: 0.6386  data: 0.1324  max mem: 10714\n",
      "Training Epoch: [19]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2184 (6.2146)  loss_classifier: 5.7825 (5.7465)  loss_box_reg: 0.2201 (0.2395)  loss_objectness: 0.1527 (0.1523)  loss_rpn_box_reg: 0.0814 (0.0762)  time: 0.6227  data: 0.1313  max mem: 10714\n",
      "Training Epoch: [19] Total time: 0:05:12 (0.6248 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:52  model_time: 0.7102 (0.7102)  evaluator_time: 0.0340 (0.0340)  time: 0.8972  data: 0.1430  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4411 (0.4528)  evaluator_time: 0.0350 (0.0375)  time: 0.6420  data: 0.1585  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4791 (0.4546)  evaluator_time: 0.0360 (0.0379)  time: 0.6677  data: 0.1586  max mem: 10714\n",
      "Test: Total time: 0:01:21 (0.6503 s / it)\n",
      "Averaged stats: model_time: 0.4791 (0.4546)  evaluator_time: 0.0360 (0.0379)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.31s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [19]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.2075 (6.2075)  loss_classifier: 5.6568 (5.6568)  loss_box_reg: 0.2937 (0.2937)  loss_objectness: 0.1240 (0.1240)  loss_rpn_box_reg: 0.1331 (0.1331)  time: 0.6551  data: 0.1520  max mem: 10714\n",
      "Testing Epoch: [19]  [100/125]  eta: 0:00:15  lr: 0.000000  loss: 6.0000 (6.1241)  loss_classifier: 5.4301 (5.6133)  loss_box_reg: 0.2618 (0.2893)  loss_objectness: 0.1299 (0.1323)  loss_rpn_box_reg: 0.0706 (0.0892)  time: 0.5872  data: 0.1476  max mem: 10714\n",
      "Testing Epoch: [19]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1672 (6.1575)  loss_classifier: 5.6995 (5.6513)  loss_box_reg: 0.2500 (0.2847)  loss_objectness: 0.1179 (0.1321)  loss_rpn_box_reg: 0.0745 (0.0894)  time: 0.6008  data: 0.1472  max mem: 10714\n",
      "Testing Epoch: [19] Total time: 0:01:15 (0.6027 s / it)\n",
      "Training Epoch: [20]  [  0/500]  eta: 0:08:01  lr: 0.000000  loss: 7.2079 (7.2079)  loss_classifier: 6.8550 (6.8550)  loss_box_reg: 0.1793 (0.1793)  loss_objectness: 0.1193 (0.1193)  loss_rpn_box_reg: 0.0542 (0.0542)  time: 0.9632  data: 0.1430  max mem: 10714\n",
      "Training Epoch: [20]  [ 10/500]  eta: 0:05:17  lr: 0.000000  loss: 6.4577 (6.2905)  loss_classifier: 5.7680 (5.8178)  loss_box_reg: 0.2276 (0.2485)  loss_objectness: 0.1323 (0.1480)  loss_rpn_box_reg: 0.0670 (0.0762)  time: 0.6470  data: 0.1331  max mem: 10714\n",
      "Training Epoch: [20]  [ 20/500]  eta: 0:04:58  lr: 0.000000  loss: 6.2038 (6.1939)  loss_classifier: 5.6286 (5.7241)  loss_box_reg: 0.2394 (0.2497)  loss_objectness: 0.1333 (0.1464)  loss_rpn_box_reg: 0.0744 (0.0737)  time: 0.6045  data: 0.1322  max mem: 10714\n",
      "Training Epoch: [20]  [ 30/500]  eta: 0:04:51  lr: 0.000000  loss: 6.2038 (6.1963)  loss_classifier: 5.6374 (5.7161)  loss_box_reg: 0.2483 (0.2522)  loss_objectness: 0.1473 (0.1494)  loss_rpn_box_reg: 0.0853 (0.0786)  time: 0.6067  data: 0.1384  max mem: 10714\n",
      "Training Epoch: [20]  [ 40/500]  eta: 0:04:46  lr: 0.000000  loss: 6.1136 (6.1409)  loss_classifier: 5.6374 (5.6642)  loss_box_reg: 0.2420 (0.2531)  loss_objectness: 0.1505 (0.1481)  loss_rpn_box_reg: 0.0681 (0.0755)  time: 0.6262  data: 0.1381  max mem: 10714\n",
      "Training Epoch: [20]  [ 50/500]  eta: 0:04:41  lr: 0.000000  loss: 6.0269 (6.0977)  loss_classifier: 5.5838 (5.6223)  loss_box_reg: 0.2441 (0.2514)  loss_objectness: 0.1390 (0.1476)  loss_rpn_box_reg: 0.0644 (0.0763)  time: 0.6314  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [20]  [ 60/500]  eta: 0:04:33  lr: 0.000000  loss: 6.1514 (6.1136)  loss_classifier: 5.6334 (5.6388)  loss_box_reg: 0.2441 (0.2499)  loss_objectness: 0.1464 (0.1488)  loss_rpn_box_reg: 0.0737 (0.0761)  time: 0.6187  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [20]  [ 70/500]  eta: 0:04:27  lr: 0.000000  loss: 6.2534 (6.1227)  loss_classifier: 5.6997 (5.6461)  loss_box_reg: 0.2255 (0.2520)  loss_objectness: 0.1596 (0.1493)  loss_rpn_box_reg: 0.0716 (0.0754)  time: 0.6140  data: 0.1345  max mem: 10714\n",
      "Training Epoch: [20]  [ 80/500]  eta: 0:04:21  lr: 0.000000  loss: 6.1004 (6.1205)  loss_classifier: 5.6697 (5.6408)  loss_box_reg: 0.2348 (0.2516)  loss_objectness: 0.1596 (0.1514)  loss_rpn_box_reg: 0.0718 (0.0766)  time: 0.6240  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [20]  [ 90/500]  eta: 0:04:15  lr: 0.000000  loss: 6.0928 (6.1258)  loss_classifier: 5.6092 (5.6514)  loss_box_reg: 0.2169 (0.2479)  loss_objectness: 0.1388 (0.1509)  loss_rpn_box_reg: 0.0676 (0.0756)  time: 0.6223  data: 0.1353  max mem: 10714\n",
      "Training Epoch: [20]  [100/500]  eta: 0:04:08  lr: 0.000000  loss: 6.0905 (6.1268)  loss_classifier: 5.6092 (5.6536)  loss_box_reg: 0.2131 (0.2475)  loss_objectness: 0.1388 (0.1516)  loss_rpn_box_reg: 0.0594 (0.0741)  time: 0.6200  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [20]  [110/500]  eta: 0:04:02  lr: 0.000000  loss: 6.1001 (6.1337)  loss_classifier: 5.6272 (5.6635)  loss_box_reg: 0.2230 (0.2449)  loss_objectness: 0.1470 (0.1517)  loss_rpn_box_reg: 0.0674 (0.0736)  time: 0.6244  data: 0.1335  max mem: 10714\n",
      "Training Epoch: [20]  [120/500]  eta: 0:03:56  lr: 0.000000  loss: 6.1001 (6.1311)  loss_classifier: 5.6860 (5.6616)  loss_box_reg: 0.2251 (0.2444)  loss_objectness: 0.1406 (0.1508)  loss_rpn_box_reg: 0.0735 (0.0743)  time: 0.6286  data: 0.1356  max mem: 10714\n",
      "Training Epoch: [20]  [130/500]  eta: 0:03:50  lr: 0.000000  loss: 6.1270 (6.1494)  loss_classifier: 5.7587 (5.6826)  loss_box_reg: 0.2274 (0.2426)  loss_objectness: 0.1380 (0.1504)  loss_rpn_box_reg: 0.0712 (0.0738)  time: 0.6280  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [20]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 6.1778 (6.1535)  loss_classifier: 5.7178 (5.6866)  loss_box_reg: 0.2272 (0.2424)  loss_objectness: 0.1380 (0.1503)  loss_rpn_box_reg: 0.0643 (0.0741)  time: 0.6275  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [20]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.1778 (6.1752)  loss_classifier: 5.7178 (5.7063)  loss_box_reg: 0.2485 (0.2437)  loss_objectness: 0.1394 (0.1507)  loss_rpn_box_reg: 0.0643 (0.0745)  time: 0.6296  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [20]  [160/500]  eta: 0:03:31  lr: 0.000000  loss: 6.2503 (6.1754)  loss_classifier: 5.6074 (5.7040)  loss_box_reg: 0.2485 (0.2448)  loss_objectness: 0.1606 (0.1515)  loss_rpn_box_reg: 0.0635 (0.0750)  time: 0.6171  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [20]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 6.2503 (6.1848)  loss_classifier: 5.7413 (5.7159)  loss_box_reg: 0.2129 (0.2425)  loss_objectness: 0.1584 (0.1515)  loss_rpn_box_reg: 0.0635 (0.0749)  time: 0.6202  data: 0.1332  max mem: 10714\n",
      "Training Epoch: [20]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.3541 (6.1993)  loss_classifier: 5.9224 (5.7311)  loss_box_reg: 0.1910 (0.2427)  loss_objectness: 0.1436 (0.1512)  loss_rpn_box_reg: 0.0629 (0.0744)  time: 0.6285  data: 0.1331  max mem: 10714\n",
      "Training Epoch: [20]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.3614 (6.2041)  loss_classifier: 5.9298 (5.7386)  loss_box_reg: 0.1993 (0.2405)  loss_objectness: 0.1267 (0.1507)  loss_rpn_box_reg: 0.0588 (0.0744)  time: 0.6309  data: 0.1311  max mem: 10714\n",
      "Training Epoch: [20]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.1951 (6.1978)  loss_classifier: 5.8352 (5.7307)  loss_box_reg: 0.2195 (0.2419)  loss_objectness: 0.1273 (0.1508)  loss_rpn_box_reg: 0.0663 (0.0744)  time: 0.6271  data: 0.1326  max mem: 10714\n",
      "Training Epoch: [20]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.0245 (6.1897)  loss_classifier: 5.5204 (5.7229)  loss_box_reg: 0.2251 (0.2407)  loss_objectness: 0.1606 (0.1515)  loss_rpn_box_reg: 0.0694 (0.0746)  time: 0.6152  data: 0.1353  max mem: 10714\n",
      "Training Epoch: [20]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.0481 (6.1897)  loss_classifier: 5.6149 (5.7264)  loss_box_reg: 0.1995 (0.2393)  loss_objectness: 0.1363 (0.1502)  loss_rpn_box_reg: 0.0628 (0.0738)  time: 0.6186  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [20]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.2133 (6.1961)  loss_classifier: 5.8338 (5.7335)  loss_box_reg: 0.1955 (0.2385)  loss_objectness: 0.1328 (0.1504)  loss_rpn_box_reg: 0.0563 (0.0736)  time: 0.6299  data: 0.1334  max mem: 10714\n",
      "Training Epoch: [20]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.2133 (6.2034)  loss_classifier: 5.7913 (5.7394)  loss_box_reg: 0.2372 (0.2394)  loss_objectness: 0.1561 (0.1510)  loss_rpn_box_reg: 0.0614 (0.0736)  time: 0.6275  data: 0.1365  max mem: 10714\n",
      "Training Epoch: [20]  [250/500]  eta: 0:02:35  lr: 0.000000  loss: 6.0621 (6.2153)  loss_classifier: 5.7407 (5.7530)  loss_box_reg: 0.2313 (0.2381)  loss_objectness: 0.1514 (0.1504)  loss_rpn_box_reg: 0.0642 (0.0738)  time: 0.6207  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [20]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.1918 (6.2151)  loss_classifier: 5.7267 (5.7491)  loss_box_reg: 0.2438 (0.2393)  loss_objectness: 0.1390 (0.1517)  loss_rpn_box_reg: 0.0756 (0.0749)  time: 0.6152  data: 0.1353  max mem: 10714\n",
      "Training Epoch: [20]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.1918 (6.2148)  loss_classifier: 5.6587 (5.7499)  loss_box_reg: 0.2438 (0.2391)  loss_objectness: 0.1388 (0.1511)  loss_rpn_box_reg: 0.0785 (0.0746)  time: 0.6171  data: 0.1363  max mem: 10714\n",
      "Training Epoch: [20]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.3004 (6.2175)  loss_classifier: 5.7296 (5.7521)  loss_box_reg: 0.2224 (0.2388)  loss_objectness: 0.1388 (0.1516)  loss_rpn_box_reg: 0.0695 (0.0750)  time: 0.6325  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [20]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.3525 (6.2208)  loss_classifier: 5.7800 (5.7554)  loss_box_reg: 0.2298 (0.2391)  loss_objectness: 0.1506 (0.1517)  loss_rpn_box_reg: 0.0667 (0.0746)  time: 0.6326  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [20]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.1300 (6.2174)  loss_classifier: 5.6315 (5.7515)  loss_box_reg: 0.2420 (0.2396)  loss_objectness: 0.1569 (0.1520)  loss_rpn_box_reg: 0.0526 (0.0742)  time: 0.6280  data: 0.1333  max mem: 10714\n",
      "Training Epoch: [20]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 5.9651 (6.2168)  loss_classifier: 5.5209 (5.7512)  loss_box_reg: 0.2227 (0.2392)  loss_objectness: 0.1531 (0.1522)  loss_rpn_box_reg: 0.0668 (0.0742)  time: 0.6355  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [20]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1954 (6.2152)  loss_classifier: 5.7690 (5.7508)  loss_box_reg: 0.2121 (0.2379)  loss_objectness: 0.1444 (0.1529)  loss_rpn_box_reg: 0.0655 (0.0737)  time: 0.6292  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [20]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.1954 (6.2159)  loss_classifier: 5.7690 (5.7502)  loss_box_reg: 0.2062 (0.2383)  loss_objectness: 0.1575 (0.1536)  loss_rpn_box_reg: 0.0609 (0.0738)  time: 0.6108  data: 0.1335  max mem: 10714\n",
      "Training Epoch: [20]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.3394 (6.2213)  loss_classifier: 5.8628 (5.7562)  loss_box_reg: 0.2161 (0.2379)  loss_objectness: 0.1407 (0.1533)  loss_rpn_box_reg: 0.0650 (0.0740)  time: 0.6095  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [20]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.4154 (6.2200)  loss_classifier: 5.7993 (5.7540)  loss_box_reg: 0.2296 (0.2381)  loss_objectness: 0.1498 (0.1535)  loss_rpn_box_reg: 0.0714 (0.0743)  time: 0.6247  data: 0.1353  max mem: 10714\n",
      "Training Epoch: [20]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.4103 (6.2254)  loss_classifier: 5.7993 (5.7600)  loss_box_reg: 0.2460 (0.2377)  loss_objectness: 0.1588 (0.1535)  loss_rpn_box_reg: 0.0726 (0.0742)  time: 0.6339  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [20]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.4103 (6.2264)  loss_classifier: 5.8921 (5.7600)  loss_box_reg: 0.2432 (0.2381)  loss_objectness: 0.1408 (0.1535)  loss_rpn_box_reg: 0.0820 (0.0747)  time: 0.6687  data: 0.1714  max mem: 10714\n",
      "Training Epoch: [20]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.0872 (6.2212)  loss_classifier: 5.6213 (5.7540)  loss_box_reg: 0.2393 (0.2384)  loss_objectness: 0.1603 (0.1538)  loss_rpn_box_reg: 0.0799 (0.0750)  time: 0.6543  data: 0.1707  max mem: 10714\n",
      "Training Epoch: [20]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.0945 (6.2263)  loss_classifier: 5.6257 (5.7602)  loss_box_reg: 0.2052 (0.2373)  loss_objectness: 0.1544 (0.1537)  loss_rpn_box_reg: 0.0749 (0.0751)  time: 0.6161  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [20]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2966 (6.2267)  loss_classifier: 5.8848 (5.7607)  loss_box_reg: 0.1877 (0.2372)  loss_objectness: 0.1434 (0.1537)  loss_rpn_box_reg: 0.0750 (0.0751)  time: 0.6304  data: 0.1340  max mem: 10714\n",
      "Training Epoch: [20]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.0794 (6.2217)  loss_classifier: 5.6997 (5.7552)  loss_box_reg: 0.2098 (0.2367)  loss_objectness: 0.1515 (0.1538)  loss_rpn_box_reg: 0.0797 (0.0759)  time: 0.6346  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [20]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 5.9861 (6.2179)  loss_classifier: 5.5593 (5.7526)  loss_box_reg: 0.2063 (0.2359)  loss_objectness: 0.1337 (0.1535)  loss_rpn_box_reg: 0.0653 (0.0759)  time: 0.6279  data: 0.1323  max mem: 10714\n",
      "Training Epoch: [20]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2509 (6.2196)  loss_classifier: 5.7011 (5.7543)  loss_box_reg: 0.2063 (0.2360)  loss_objectness: 0.1507 (0.1535)  loss_rpn_box_reg: 0.0548 (0.0757)  time: 0.6216  data: 0.1303  max mem: 10714\n",
      "Training Epoch: [20]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2509 (6.2192)  loss_classifier: 5.7724 (5.7525)  loss_box_reg: 0.2558 (0.2368)  loss_objectness: 0.1672 (0.1538)  loss_rpn_box_reg: 0.0767 (0.0761)  time: 0.6300  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [20]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1072 (6.2172)  loss_classifier: 5.6315 (5.7506)  loss_box_reg: 0.2558 (0.2371)  loss_objectness: 0.1577 (0.1536)  loss_rpn_box_reg: 0.0760 (0.0758)  time: 0.6294  data: 0.1369  max mem: 10714\n",
      "Training Epoch: [20]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0190 (6.2163)  loss_classifier: 5.5271 (5.7489)  loss_box_reg: 0.2373 (0.2378)  loss_objectness: 0.1407 (0.1536)  loss_rpn_box_reg: 0.0575 (0.0760)  time: 0.6227  data: 0.1374  max mem: 10714\n",
      "Training Epoch: [20]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1221 (6.2185)  loss_classifier: 5.6277 (5.7502)  loss_box_reg: 0.2373 (0.2385)  loss_objectness: 0.1521 (0.1538)  loss_rpn_box_reg: 0.0674 (0.0760)  time: 0.6282  data: 0.1394  max mem: 10714\n",
      "Training Epoch: [20]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1798 (6.2188)  loss_classifier: 5.7749 (5.7501)  loss_box_reg: 0.2402 (0.2389)  loss_objectness: 0.1521 (0.1537)  loss_rpn_box_reg: 0.0662 (0.0761)  time: 0.6218  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [20]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1620 (6.2200)  loss_classifier: 5.7100 (5.7520)  loss_box_reg: 0.2269 (0.2383)  loss_objectness: 0.1459 (0.1536)  loss_rpn_box_reg: 0.0774 (0.0762)  time: 0.6214  data: 0.1320  max mem: 10714\n",
      "Training Epoch: [20]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1457 (6.2189)  loss_classifier: 5.6358 (5.7511)  loss_box_reg: 0.2269 (0.2383)  loss_objectness: 0.1463 (0.1533)  loss_rpn_box_reg: 0.0821 (0.0763)  time: 0.6272  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [20] Total time: 0:05:12 (0.6259 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:53  model_time: 0.7172 (0.7172)  evaluator_time: 0.0350 (0.0350)  time: 0.9072  data: 0.1450  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4391 (0.4488)  evaluator_time: 0.0340 (0.0385)  time: 0.6291  data: 0.1413  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4701 (0.4510)  evaluator_time: 0.0350 (0.0385)  time: 0.6541  data: 0.1483  max mem: 10714\n",
      "Test: Total time: 0:01:19 (0.6384 s / it)\n",
      "Averaged stats: model_time: 0.4701 (0.4510)  evaluator_time: 0.0350 (0.0385)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [20]  [  0/125]  eta: 0:01:19  lr: 0.000000  loss: 6.2004 (6.2004)  loss_classifier: 5.6492 (5.6492)  loss_box_reg: 0.2937 (0.2937)  loss_objectness: 0.1245 (0.1245)  loss_rpn_box_reg: 0.1331 (0.1331)  time: 0.6371  data: 0.1360  max mem: 10714\n",
      "Testing Epoch: [20]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9903 (6.1260)  loss_classifier: 5.4250 (5.6181)  loss_box_reg: 0.2609 (0.2883)  loss_objectness: 0.1284 (0.1307)  loss_rpn_box_reg: 0.0704 (0.0890)  time: 0.5876  data: 0.1478  max mem: 10714\n",
      "Testing Epoch: [20]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1647 (6.1593)  loss_classifier: 5.6840 (5.6553)  loss_box_reg: 0.2489 (0.2839)  loss_objectness: 0.1178 (0.1309)  loss_rpn_box_reg: 0.0745 (0.0892)  time: 0.5999  data: 0.1460  max mem: 10714\n",
      "Testing Epoch: [20] Total time: 0:01:14 (0.5955 s / it)\n",
      "Training Epoch: [21]  [  0/500]  eta: 0:07:11  lr: 0.000000  loss: 6.1826 (6.1826)  loss_classifier: 5.6312 (5.6312)  loss_box_reg: 0.3161 (0.3161)  loss_objectness: 0.1579 (0.1579)  loss_rpn_box_reg: 0.0774 (0.0774)  time: 0.8622  data: 0.1330  max mem: 10714\n",
      "Training Epoch: [21]  [ 10/500]  eta: 0:05:06  lr: 0.000000  loss: 6.1826 (6.3270)  loss_classifier: 5.6312 (5.8054)  loss_box_reg: 0.2662 (0.2726)  loss_objectness: 0.1579 (0.1559)  loss_rpn_box_reg: 0.0774 (0.0931)  time: 0.6245  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [21]  [ 20/500]  eta: 0:04:57  lr: 0.000000  loss: 6.0292 (6.1805)  loss_classifier: 5.5664 (5.6858)  loss_box_reg: 0.2543 (0.2588)  loss_objectness: 0.1389 (0.1522)  loss_rpn_box_reg: 0.0739 (0.0838)  time: 0.6069  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [21]  [ 30/500]  eta: 0:04:51  lr: 0.000000  loss: 5.9147 (6.1453)  loss_classifier: 5.4130 (5.6476)  loss_box_reg: 0.2659 (0.2642)  loss_objectness: 0.1352 (0.1495)  loss_rpn_box_reg: 0.0838 (0.0840)  time: 0.6168  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [21]  [ 40/500]  eta: 0:04:45  lr: 0.000000  loss: 6.0409 (6.1535)  loss_classifier: 5.4051 (5.6559)  loss_box_reg: 0.2627 (0.2614)  loss_objectness: 0.1470 (0.1512)  loss_rpn_box_reg: 0.0910 (0.0850)  time: 0.6227  data: 0.1357  max mem: 10714\n",
      "Training Epoch: [21]  [ 50/500]  eta: 0:04:39  lr: 0.000000  loss: 6.2999 (6.1754)  loss_classifier: 5.8313 (5.6822)  loss_box_reg: 0.2208 (0.2565)  loss_objectness: 0.1578 (0.1542)  loss_rpn_box_reg: 0.0717 (0.0826)  time: 0.6222  data: 0.1360  max mem: 10714\n",
      "Training Epoch: [21]  [ 60/500]  eta: 0:04:33  lr: 0.000000  loss: 6.1952 (6.1808)  loss_classifier: 5.8035 (5.6934)  loss_box_reg: 0.2274 (0.2519)  loss_objectness: 0.1560 (0.1516)  loss_rpn_box_reg: 0.0717 (0.0839)  time: 0.6223  data: 0.1352  max mem: 10714\n",
      "Training Epoch: [21]  [ 70/500]  eta: 0:04:27  lr: 0.000000  loss: 6.0882 (6.1890)  loss_classifier: 5.5815 (5.7046)  loss_box_reg: 0.2363 (0.2514)  loss_objectness: 0.1382 (0.1516)  loss_rpn_box_reg: 0.0652 (0.0814)  time: 0.6251  data: 0.1336  max mem: 10714\n",
      "Training Epoch: [21]  [ 80/500]  eta: 0:04:21  lr: 0.000000  loss: 6.2032 (6.1959)  loss_classifier: 5.6968 (5.7121)  loss_box_reg: 0.2401 (0.2501)  loss_objectness: 0.1497 (0.1527)  loss_rpn_box_reg: 0.0652 (0.0811)  time: 0.6266  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [21]  [ 90/500]  eta: 0:04:16  lr: 0.000000  loss: 6.2265 (6.2115)  loss_classifier: 5.7891 (5.7325)  loss_box_reg: 0.2275 (0.2472)  loss_objectness: 0.1509 (0.1520)  loss_rpn_box_reg: 0.0693 (0.0798)  time: 0.6368  data: 0.1333  max mem: 10714\n",
      "Training Epoch: [21]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 6.3642 (6.2248)  loss_classifier: 5.8837 (5.7475)  loss_box_reg: 0.2255 (0.2442)  loss_objectness: 0.1462 (0.1524)  loss_rpn_box_reg: 0.0693 (0.0807)  time: 0.6413  data: 0.1361  max mem: 10714\n",
      "Training Epoch: [21]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 6.1591 (6.2316)  loss_classifier: 5.7013 (5.7529)  loss_box_reg: 0.2235 (0.2427)  loss_objectness: 0.1734 (0.1557)  loss_rpn_box_reg: 0.0711 (0.0803)  time: 0.6236  data: 0.1382  max mem: 10714\n",
      "Training Epoch: [21]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.1199 (6.2215)  loss_classifier: 5.7013 (5.7468)  loss_box_reg: 0.2235 (0.2404)  loss_objectness: 0.1642 (0.1551)  loss_rpn_box_reg: 0.0688 (0.0792)  time: 0.6292  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [21]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.3337 (6.2241)  loss_classifier: 5.7312 (5.7491)  loss_box_reg: 0.2462 (0.2418)  loss_objectness: 0.1445 (0.1541)  loss_rpn_box_reg: 0.0679 (0.0791)  time: 0.6320  data: 0.1333  max mem: 10714\n",
      "Training Epoch: [21]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 6.3477 (6.2254)  loss_classifier: 5.7797 (5.7514)  loss_box_reg: 0.2517 (0.2415)  loss_objectness: 0.1371 (0.1533)  loss_rpn_box_reg: 0.0657 (0.0791)  time: 0.6128  data: 0.1325  max mem: 10714\n",
      "Training Epoch: [21]  [150/500]  eta: 0:03:37  lr: 0.000000  loss: 6.3477 (6.2180)  loss_classifier: 5.9494 (5.7464)  loss_box_reg: 0.2517 (0.2401)  loss_objectness: 0.1487 (0.1532)  loss_rpn_box_reg: 0.0628 (0.0783)  time: 0.6000  data: 0.1322  max mem: 10714\n",
      "Training Epoch: [21]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.3924 (6.2350)  loss_classifier: 5.9773 (5.7661)  loss_box_reg: 0.2041 (0.2392)  loss_objectness: 0.1456 (0.1524)  loss_rpn_box_reg: 0.0628 (0.0773)  time: 0.6181  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [21]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.5311 (6.2464)  loss_classifier: 6.0169 (5.7786)  loss_box_reg: 0.1985 (0.2375)  loss_objectness: 0.1374 (0.1527)  loss_rpn_box_reg: 0.0730 (0.0776)  time: 0.6439  data: 0.1356  max mem: 10714\n",
      "Training Epoch: [21]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.4571 (6.2525)  loss_classifier: 5.9567 (5.7839)  loss_box_reg: 0.2182 (0.2386)  loss_objectness: 0.1509 (0.1531)  loss_rpn_box_reg: 0.0730 (0.0770)  time: 0.6444  data: 0.1371  max mem: 10714\n",
      "Training Epoch: [21]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.1371 (6.2389)  loss_classifier: 5.5600 (5.7690)  loss_box_reg: 0.2413 (0.2388)  loss_objectness: 0.1660 (0.1539)  loss_rpn_box_reg: 0.0696 (0.0772)  time: 0.6353  data: 0.1375  max mem: 10714\n",
      "Training Epoch: [21]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.1143 (6.2427)  loss_classifier: 5.5850 (5.7717)  loss_box_reg: 0.2450 (0.2399)  loss_objectness: 0.1630 (0.1542)  loss_rpn_box_reg: 0.0748 (0.0768)  time: 0.6214  data: 0.1357  max mem: 10714\n",
      "Training Epoch: [21]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.2174 (6.2501)  loss_classifier: 5.7031 (5.7806)  loss_box_reg: 0.2190 (0.2389)  loss_objectness: 0.1623 (0.1549)  loss_rpn_box_reg: 0.0494 (0.0757)  time: 0.6241  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [21]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.2174 (6.2472)  loss_classifier: 5.7031 (5.7767)  loss_box_reg: 0.2297 (0.2407)  loss_objectness: 0.1286 (0.1535)  loss_rpn_box_reg: 0.0586 (0.0763)  time: 0.6153  data: 0.1353  max mem: 10714\n",
      "Training Epoch: [21]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.2933 (6.2478)  loss_classifier: 5.8591 (5.7790)  loss_box_reg: 0.2297 (0.2396)  loss_objectness: 0.1286 (0.1532)  loss_rpn_box_reg: 0.0631 (0.0759)  time: 0.6137  data: 0.1332  max mem: 10714\n",
      "Training Epoch: [21]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.1244 (6.2374)  loss_classifier: 5.6461 (5.7652)  loss_box_reg: 0.2272 (0.2411)  loss_objectness: 0.1577 (0.1546)  loss_rpn_box_reg: 0.0737 (0.0766)  time: 0.6161  data: 0.1372  max mem: 10714\n",
      "Training Epoch: [21]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.0249 (6.2305)  loss_classifier: 5.5226 (5.7607)  loss_box_reg: 0.2224 (0.2401)  loss_objectness: 0.1518 (0.1538)  loss_rpn_box_reg: 0.0589 (0.0758)  time: 0.6161  data: 0.1392  max mem: 10714\n",
      "Training Epoch: [21]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.0726 (6.2299)  loss_classifier: 5.6176 (5.7609)  loss_box_reg: 0.2155 (0.2402)  loss_objectness: 0.1392 (0.1533)  loss_rpn_box_reg: 0.0557 (0.0754)  time: 0.6268  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [21]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.1134 (6.2292)  loss_classifier: 5.6076 (5.7590)  loss_box_reg: 0.2194 (0.2404)  loss_objectness: 0.1490 (0.1538)  loss_rpn_box_reg: 0.0711 (0.0760)  time: 0.6204  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [21]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.1427 (6.2282)  loss_classifier: 5.6054 (5.7578)  loss_box_reg: 0.2194 (0.2407)  loss_objectness: 0.1440 (0.1534)  loss_rpn_box_reg: 0.0769 (0.0764)  time: 0.6171  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [21]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.1174 (6.2216)  loss_classifier: 5.5726 (5.7511)  loss_box_reg: 0.2364 (0.2417)  loss_objectness: 0.1360 (0.1530)  loss_rpn_box_reg: 0.0620 (0.0759)  time: 0.6311  data: 0.1369  max mem: 10714\n",
      "Training Epoch: [21]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.0138 (6.2193)  loss_classifier: 5.5615 (5.7484)  loss_box_reg: 0.2376 (0.2418)  loss_objectness: 0.1397 (0.1531)  loss_rpn_box_reg: 0.0639 (0.0759)  time: 0.6367  data: 0.1385  max mem: 10714\n",
      "Training Epoch: [21]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.2677 (6.2190)  loss_classifier: 5.5849 (5.7494)  loss_box_reg: 0.2151 (0.2407)  loss_objectness: 0.1437 (0.1531)  loss_rpn_box_reg: 0.0661 (0.0759)  time: 0.6297  data: 0.1362  max mem: 10714\n",
      "Training Epoch: [21]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2394 (6.2184)  loss_classifier: 5.7316 (5.7481)  loss_box_reg: 0.1997 (0.2412)  loss_objectness: 0.1437 (0.1531)  loss_rpn_box_reg: 0.0696 (0.0760)  time: 0.6235  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [21]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.0905 (6.2088)  loss_classifier: 5.5483 (5.7387)  loss_box_reg: 0.2323 (0.2414)  loss_objectness: 0.1460 (0.1526)  loss_rpn_box_reg: 0.0678 (0.0761)  time: 0.6235  data: 0.1326  max mem: 10714\n",
      "Training Epoch: [21]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 5.9267 (6.2082)  loss_classifier: 5.4427 (5.7390)  loss_box_reg: 0.2261 (0.2411)  loss_objectness: 0.1427 (0.1523)  loss_rpn_box_reg: 0.0676 (0.0758)  time: 0.6281  data: 0.1336  max mem: 10714\n",
      "Training Epoch: [21]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.1179 (6.2046)  loss_classifier: 5.7077 (5.7364)  loss_box_reg: 0.2006 (0.2408)  loss_objectness: 0.1427 (0.1520)  loss_rpn_box_reg: 0.0566 (0.0754)  time: 0.6357  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [21]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1179 (6.2039)  loss_classifier: 5.6559 (5.7367)  loss_box_reg: 0.2304 (0.2403)  loss_objectness: 0.1425 (0.1519)  loss_rpn_box_reg: 0.0571 (0.0749)  time: 0.6397  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [21]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.0897 (6.2049)  loss_classifier: 5.6031 (5.7393)  loss_box_reg: 0.2249 (0.2395)  loss_objectness: 0.1397 (0.1514)  loss_rpn_box_reg: 0.0597 (0.0747)  time: 0.6370  data: 0.1330  max mem: 10714\n",
      "Training Epoch: [21]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1333 (6.2026)  loss_classifier: 5.6016 (5.7364)  loss_box_reg: 0.2249 (0.2396)  loss_objectness: 0.1397 (0.1516)  loss_rpn_box_reg: 0.0660 (0.0750)  time: 0.6380  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [21]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.0046 (6.1988)  loss_classifier: 5.5973 (5.7326)  loss_box_reg: 0.2280 (0.2396)  loss_objectness: 0.1466 (0.1515)  loss_rpn_box_reg: 0.0704 (0.0751)  time: 0.6283  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [21]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.0789 (6.2033)  loss_classifier: 5.5909 (5.7360)  loss_box_reg: 0.2417 (0.2399)  loss_objectness: 0.1603 (0.1519)  loss_rpn_box_reg: 0.0756 (0.0755)  time: 0.6191  data: 0.1328  max mem: 10714\n",
      "Training Epoch: [21]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1354 (6.2011)  loss_classifier: 5.6085 (5.7320)  loss_box_reg: 0.2641 (0.2410)  loss_objectness: 0.1618 (0.1521)  loss_rpn_box_reg: 0.0810 (0.0760)  time: 0.6192  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [21]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 5.8103 (6.1973)  loss_classifier: 5.3770 (5.7288)  loss_box_reg: 0.2546 (0.2408)  loss_objectness: 0.1509 (0.1519)  loss_rpn_box_reg: 0.0747 (0.0757)  time: 0.6199  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [21]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.3652 (6.2063)  loss_classifier: 5.9102 (5.7372)  loss_box_reg: 0.2393 (0.2410)  loss_objectness: 0.1403 (0.1520)  loss_rpn_box_reg: 0.0772 (0.0761)  time: 0.6238  data: 0.1331  max mem: 10714\n",
      "Training Epoch: [21]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.5395 (6.2111)  loss_classifier: 6.0984 (5.7429)  loss_box_reg: 0.2452 (0.2406)  loss_objectness: 0.1419 (0.1519)  loss_rpn_box_reg: 0.0687 (0.0757)  time: 0.6220  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [21]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.3151 (6.2125)  loss_classifier: 5.9564 (5.7443)  loss_box_reg: 0.2356 (0.2409)  loss_objectness: 0.1390 (0.1516)  loss_rpn_box_reg: 0.0563 (0.0756)  time: 0.6339  data: 0.1357  max mem: 10714\n",
      "Training Epoch: [21]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.3147 (6.2133)  loss_classifier: 5.8100 (5.7450)  loss_box_reg: 0.2356 (0.2411)  loss_objectness: 0.1413 (0.1517)  loss_rpn_box_reg: 0.0587 (0.0755)  time: 0.6374  data: 0.1352  max mem: 10714\n",
      "Training Epoch: [21]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.3147 (6.2157)  loss_classifier: 5.8100 (5.7476)  loss_box_reg: 0.2367 (0.2410)  loss_objectness: 0.1402 (0.1514)  loss_rpn_box_reg: 0.0748 (0.0757)  time: 0.6289  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [21]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1579 (6.2114)  loss_classifier: 5.6325 (5.7438)  loss_box_reg: 0.1979 (0.2405)  loss_objectness: 0.1357 (0.1514)  loss_rpn_box_reg: 0.0751 (0.0757)  time: 0.6318  data: 0.1357  max mem: 10714\n",
      "Training Epoch: [21]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 5.9984 (6.2074)  loss_classifier: 5.5672 (5.7382)  loss_box_reg: 0.2295 (0.2417)  loss_objectness: 0.1495 (0.1517)  loss_rpn_box_reg: 0.0775 (0.0758)  time: 0.6221  data: 0.1362  max mem: 10714\n",
      "Training Epoch: [21]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.3104 (6.2105)  loss_classifier: 5.6848 (5.7412)  loss_box_reg: 0.2769 (0.2415)  loss_objectness: 0.1558 (0.1518)  loss_rpn_box_reg: 0.0809 (0.0759)  time: 0.6061  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [21] Total time: 0:05:12 (0.6254 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:41  model_time: 0.6221 (0.6221)  evaluator_time: 0.0352 (0.0352)  time: 0.8103  data: 0.1430  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4431 (0.4507)  evaluator_time: 0.0350 (0.0363)  time: 0.6342  data: 0.1423  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4671 (0.4520)  evaluator_time: 0.0360 (0.0368)  time: 0.6512  data: 0.1480  max mem: 10714\n",
      "Test: Total time: 0:01:20 (0.6414 s / it)\n",
      "Averaged stats: model_time: 0.4671 (0.4520)  evaluator_time: 0.0360 (0.0368)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [21]  [  0/125]  eta: 0:01:22  lr: 0.000000  loss: 6.1961 (6.1961)  loss_classifier: 5.6437 (5.6437)  loss_box_reg: 0.2937 (0.2937)  loss_objectness: 0.1260 (0.1260)  loss_rpn_box_reg: 0.1328 (0.1328)  time: 0.6561  data: 0.1480  max mem: 10714\n",
      "Testing Epoch: [21]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0021 (6.1333)  loss_classifier: 5.4280 (5.6230)  loss_box_reg: 0.2609 (0.2891)  loss_objectness: 0.1273 (0.1314)  loss_rpn_box_reg: 0.0732 (0.0898)  time: 0.5847  data: 0.1456  max mem: 10714\n",
      "Testing Epoch: [21]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1488 (6.1640)  loss_classifier: 5.6957 (5.6583)  loss_box_reg: 0.2500 (0.2846)  loss_objectness: 0.1158 (0.1312)  loss_rpn_box_reg: 0.0745 (0.0899)  time: 0.5997  data: 0.1473  max mem: 10714\n",
      "Testing Epoch: [21] Total time: 0:01:14 (0.5959 s / it)\n",
      "Training Epoch: [22]  [  0/500]  eta: 0:07:26  lr: 0.000000  loss: 6.8279 (6.8279)  loss_classifier: 6.3416 (6.3416)  loss_box_reg: 0.1754 (0.1754)  loss_objectness: 0.1676 (0.1676)  loss_rpn_box_reg: 0.1433 (0.1433)  time: 0.8922  data: 0.1290  max mem: 10714\n",
      "Training Epoch: [22]  [ 10/500]  eta: 0:05:20  lr: 0.000000  loss: 6.0846 (6.0794)  loss_classifier: 5.6001 (5.5943)  loss_box_reg: 0.2531 (0.2577)  loss_objectness: 0.1434 (0.1455)  loss_rpn_box_reg: 0.0822 (0.0819)  time: 0.6537  data: 0.1357  max mem: 10714\n",
      "Training Epoch: [22]  [ 20/500]  eta: 0:05:02  lr: 0.000000  loss: 6.0846 (6.1010)  loss_classifier: 5.6001 (5.6196)  loss_box_reg: 0.2387 (0.2470)  loss_objectness: 0.1496 (0.1528)  loss_rpn_box_reg: 0.0665 (0.0817)  time: 0.6177  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [22]  [ 30/500]  eta: 0:04:52  lr: 0.000000  loss: 6.2609 (6.2090)  loss_classifier: 5.8263 (5.7475)  loss_box_reg: 0.2013 (0.2308)  loss_objectness: 0.1506 (0.1497)  loss_rpn_box_reg: 0.0700 (0.0810)  time: 0.6045  data: 0.1357  max mem: 10714\n",
      "Training Epoch: [22]  [ 40/500]  eta: 0:04:48  lr: 0.000000  loss: 6.2511 (6.2045)  loss_classifier: 5.8451 (5.7392)  loss_box_reg: 0.2263 (0.2388)  loss_objectness: 0.1355 (0.1466)  loss_rpn_box_reg: 0.0708 (0.0799)  time: 0.6215  data: 0.1364  max mem: 10714\n",
      "Training Epoch: [22]  [ 50/500]  eta: 0:04:43  lr: 0.000000  loss: 6.1438 (6.2188)  loss_classifier: 5.6213 (5.7571)  loss_box_reg: 0.2369 (0.2359)  loss_objectness: 0.1355 (0.1468)  loss_rpn_box_reg: 0.0731 (0.0789)  time: 0.6411  data: 0.1361  max mem: 10714\n",
      "Training Epoch: [22]  [ 60/500]  eta: 0:04:37  lr: 0.000000  loss: 6.1438 (6.2006)  loss_classifier: 5.7791 (5.7374)  loss_box_reg: 0.2163 (0.2376)  loss_objectness: 0.1294 (0.1453)  loss_rpn_box_reg: 0.0766 (0.0802)  time: 0.6421  data: 0.1352  max mem: 10714\n",
      "Training Epoch: [22]  [ 70/500]  eta: 0:04:29  lr: 0.000000  loss: 6.2078 (6.2245)  loss_classifier: 5.7906 (5.7594)  loss_box_reg: 0.2224 (0.2348)  loss_objectness: 0.1587 (0.1495)  loss_rpn_box_reg: 0.0770 (0.0808)  time: 0.6230  data: 0.1368  max mem: 10714\n",
      "Training Epoch: [22]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 6.1624 (6.2053)  loss_classifier: 5.7124 (5.7433)  loss_box_reg: 0.2033 (0.2312)  loss_objectness: 0.1666 (0.1507)  loss_rpn_box_reg: 0.0746 (0.0801)  time: 0.6110  data: 0.1366  max mem: 10714\n",
      "Training Epoch: [22]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 6.1412 (6.2188)  loss_classifier: 5.7124 (5.7583)  loss_box_reg: 0.2101 (0.2306)  loss_objectness: 0.1469 (0.1495)  loss_rpn_box_reg: 0.0814 (0.0805)  time: 0.6245  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [22]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 6.1392 (6.2028)  loss_classifier: 5.6214 (5.7384)  loss_box_reg: 0.2397 (0.2344)  loss_objectness: 0.1469 (0.1499)  loss_rpn_box_reg: 0.0762 (0.0801)  time: 0.6250  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [22]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 6.1399 (6.2085)  loss_classifier: 5.6015 (5.7381)  loss_box_reg: 0.2898 (0.2383)  loss_objectness: 0.1583 (0.1516)  loss_rpn_box_reg: 0.0729 (0.0805)  time: 0.6106  data: 0.1367  max mem: 10714\n",
      "Training Epoch: [22]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.1841 (6.2057)  loss_classifier: 5.6577 (5.7320)  loss_box_reg: 0.2898 (0.2412)  loss_objectness: 0.1586 (0.1523)  loss_rpn_box_reg: 0.0725 (0.0802)  time: 0.6133  data: 0.1363  max mem: 10714\n",
      "Training Epoch: [22]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.1955 (6.2037)  loss_classifier: 5.7517 (5.7352)  loss_box_reg: 0.2128 (0.2376)  loss_objectness: 0.1453 (0.1519)  loss_rpn_box_reg: 0.0633 (0.0790)  time: 0.6310  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [22]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.1998 (6.2057)  loss_classifier: 5.7178 (5.7361)  loss_box_reg: 0.2502 (0.2385)  loss_objectness: 0.1453 (0.1524)  loss_rpn_box_reg: 0.0683 (0.0788)  time: 0.6331  data: 0.1332  max mem: 10714\n",
      "Training Epoch: [22]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.1438 (6.2077)  loss_classifier: 5.7177 (5.7366)  loss_box_reg: 0.2518 (0.2397)  loss_objectness: 0.1424 (0.1523)  loss_rpn_box_reg: 0.0723 (0.0791)  time: 0.6123  data: 0.1335  max mem: 10714\n",
      "Training Epoch: [22]  [160/500]  eta: 0:03:31  lr: 0.000000  loss: 6.2033 (6.2138)  loss_classifier: 5.7830 (5.7455)  loss_box_reg: 0.2213 (0.2388)  loss_objectness: 0.1416 (0.1516)  loss_rpn_box_reg: 0.0704 (0.0779)  time: 0.6045  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [22]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 6.3499 (6.2208)  loss_classifier: 5.7013 (5.7510)  loss_box_reg: 0.2213 (0.2391)  loss_objectness: 0.1416 (0.1525)  loss_rpn_box_reg: 0.0719 (0.0783)  time: 0.6251  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [22]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.2020 (6.2305)  loss_classifier: 5.7013 (5.7613)  loss_box_reg: 0.2339 (0.2387)  loss_objectness: 0.1502 (0.1526)  loss_rpn_box_reg: 0.0759 (0.0780)  time: 0.6229  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [22]  [190/500]  eta: 0:03:12  lr: 0.000000  loss: 6.2372 (6.2269)  loss_classifier: 5.7153 (5.7567)  loss_box_reg: 0.2384 (0.2391)  loss_objectness: 0.1538 (0.1530)  loss_rpn_box_reg: 0.0778 (0.0782)  time: 0.6126  data: 0.1320  max mem: 10714\n",
      "Training Epoch: [22]  [200/500]  eta: 0:03:06  lr: 0.000000  loss: 6.1119 (6.2202)  loss_classifier: 5.6855 (5.7513)  loss_box_reg: 0.2317 (0.2380)  loss_objectness: 0.1538 (0.1531)  loss_rpn_box_reg: 0.0718 (0.0779)  time: 0.6150  data: 0.1333  max mem: 10714\n",
      "Training Epoch: [22]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.1101 (6.2219)  loss_classifier: 5.7267 (5.7535)  loss_box_reg: 0.2275 (0.2373)  loss_objectness: 0.1492 (0.1534)  loss_rpn_box_reg: 0.0700 (0.0777)  time: 0.6215  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [22]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.1642 (6.2186)  loss_classifier: 5.7267 (5.7506)  loss_box_reg: 0.2317 (0.2370)  loss_objectness: 0.1492 (0.1533)  loss_rpn_box_reg: 0.0782 (0.0777)  time: 0.6246  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [22]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.0892 (6.2165)  loss_classifier: 5.6891 (5.7474)  loss_box_reg: 0.2499 (0.2382)  loss_objectness: 0.1536 (0.1535)  loss_rpn_box_reg: 0.0674 (0.0774)  time: 0.6378  data: 0.1434  max mem: 10714\n",
      "Training Epoch: [22]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.0633 (6.2083)  loss_classifier: 5.5634 (5.7407)  loss_box_reg: 0.2351 (0.2371)  loss_objectness: 0.1536 (0.1535)  loss_rpn_box_reg: 0.0662 (0.0770)  time: 0.6479  data: 0.1493  max mem: 10714\n",
      "Training Epoch: [22]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.1477 (6.2122)  loss_classifier: 5.7304 (5.7465)  loss_box_reg: 0.2006 (0.2364)  loss_objectness: 0.1258 (0.1527)  loss_rpn_box_reg: 0.0655 (0.0766)  time: 0.6536  data: 0.1517  max mem: 10714\n",
      "Training Epoch: [22]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.2732 (6.2130)  loss_classifier: 5.8321 (5.7479)  loss_box_reg: 0.2238 (0.2356)  loss_objectness: 0.1418 (0.1527)  loss_rpn_box_reg: 0.0721 (0.0769)  time: 0.6597  data: 0.1645  max mem: 10714\n",
      "Training Epoch: [22]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.2338 (6.2169)  loss_classifier: 5.7587 (5.7508)  loss_box_reg: 0.2331 (0.2364)  loss_objectness: 0.1546 (0.1527)  loss_rpn_box_reg: 0.0776 (0.0769)  time: 0.6531  data: 0.1694  max mem: 10714\n",
      "Training Epoch: [22]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.2213 (6.2194)  loss_classifier: 5.7587 (5.7551)  loss_box_reg: 0.2382 (0.2355)  loss_objectness: 0.1352 (0.1518)  loss_rpn_box_reg: 0.0747 (0.0770)  time: 0.6643  data: 0.1672  max mem: 10714\n",
      "Training Epoch: [22]  [290/500]  eta: 0:02:12  lr: 0.000000  loss: 6.2445 (6.2234)  loss_classifier: 5.7597 (5.7590)  loss_box_reg: 0.2223 (0.2349)  loss_objectness: 0.1252 (0.1521)  loss_rpn_box_reg: 0.0752 (0.0774)  time: 0.6717  data: 0.1675  max mem: 10714\n",
      "Training Epoch: [22]  [300/500]  eta: 0:02:06  lr: 0.000000  loss: 6.2445 (6.2187)  loss_classifier: 5.7965 (5.7545)  loss_box_reg: 0.2276 (0.2355)  loss_objectness: 0.1341 (0.1515)  loss_rpn_box_reg: 0.0697 (0.0772)  time: 0.6645  data: 0.1644  max mem: 10714\n",
      "Training Epoch: [22]  [310/500]  eta: 0:02:00  lr: 0.000000  loss: 6.0732 (6.2102)  loss_classifier: 5.5780 (5.7453)  loss_box_reg: 0.2336 (0.2362)  loss_objectness: 0.1408 (0.1515)  loss_rpn_box_reg: 0.0670 (0.0772)  time: 0.6547  data: 0.1625  max mem: 10714\n",
      "Training Epoch: [22]  [320/500]  eta: 0:01:54  lr: 0.000000  loss: 6.0732 (6.2092)  loss_classifier: 5.5996 (5.7443)  loss_box_reg: 0.2322 (0.2362)  loss_objectness: 0.1500 (0.1518)  loss_rpn_box_reg: 0.0704 (0.0769)  time: 0.6611  data: 0.1659  max mem: 10714\n",
      "Training Epoch: [22]  [330/500]  eta: 0:01:47  lr: 0.000000  loss: 6.0925 (6.2098)  loss_classifier: 5.6402 (5.7448)  loss_box_reg: 0.2185 (0.2359)  loss_objectness: 0.1533 (0.1522)  loss_rpn_box_reg: 0.0667 (0.0769)  time: 0.6518  data: 0.1683  max mem: 10714\n",
      "Training Epoch: [22]  [340/500]  eta: 0:01:41  lr: 0.000000  loss: 6.0909 (6.2167)  loss_classifier: 5.6130 (5.7507)  loss_box_reg: 0.2227 (0.2363)  loss_objectness: 0.1575 (0.1525)  loss_rpn_box_reg: 0.0801 (0.0773)  time: 0.6335  data: 0.1678  max mem: 10714\n",
      "Training Epoch: [22]  [350/500]  eta: 0:01:35  lr: 0.000000  loss: 6.0678 (6.2129)  loss_classifier: 5.6475 (5.7478)  loss_box_reg: 0.2482 (0.2363)  loss_objectness: 0.1435 (0.1518)  loss_rpn_box_reg: 0.0750 (0.0769)  time: 0.6440  data: 0.1649  max mem: 10714\n",
      "Training Epoch: [22]  [360/500]  eta: 0:01:28  lr: 0.000000  loss: 6.2067 (6.2146)  loss_classifier: 5.6939 (5.7502)  loss_box_reg: 0.2414 (0.2362)  loss_objectness: 0.1326 (0.1514)  loss_rpn_box_reg: 0.0624 (0.0768)  time: 0.6517  data: 0.1627  max mem: 10714\n",
      "Training Epoch: [22]  [370/500]  eta: 0:01:22  lr: 0.000000  loss: 6.1351 (6.2106)  loss_classifier: 5.6412 (5.7463)  loss_box_reg: 0.2436 (0.2367)  loss_objectness: 0.1326 (0.1511)  loss_rpn_box_reg: 0.0659 (0.0765)  time: 0.6666  data: 0.1642  max mem: 10714\n",
      "Training Epoch: [22]  [380/500]  eta: 0:01:16  lr: 0.000000  loss: 6.1199 (6.2118)  loss_classifier: 5.6476 (5.7463)  loss_box_reg: 0.2612 (0.2371)  loss_objectness: 0.1380 (0.1516)  loss_rpn_box_reg: 0.0738 (0.0768)  time: 0.6563  data: 0.1639  max mem: 10714\n",
      "Training Epoch: [22]  [390/500]  eta: 0:01:10  lr: 0.000000  loss: 6.3099 (6.2130)  loss_classifier: 5.8556 (5.7481)  loss_box_reg: 0.2355 (0.2369)  loss_objectness: 0.1567 (0.1516)  loss_rpn_box_reg: 0.0771 (0.0764)  time: 0.6423  data: 0.1630  max mem: 10714\n",
      "Training Epoch: [22]  [400/500]  eta: 0:01:03  lr: 0.000000  loss: 6.3693 (6.2194)  loss_classifier: 5.9535 (5.7550)  loss_box_reg: 0.2284 (0.2370)  loss_objectness: 0.1542 (0.1514)  loss_rpn_box_reg: 0.0526 (0.0759)  time: 0.6485  data: 0.1646  max mem: 10714\n",
      "Training Epoch: [22]  [410/500]  eta: 0:00:57  lr: 0.000000  loss: 6.1523 (6.2139)  loss_classifier: 5.7157 (5.7496)  loss_box_reg: 0.2320 (0.2375)  loss_objectness: 0.1403 (0.1511)  loss_rpn_box_reg: 0.0502 (0.0757)  time: 0.6404  data: 0.1659  max mem: 10714\n",
      "Training Epoch: [22]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 5.9749 (6.2103)  loss_classifier: 5.4446 (5.7447)  loss_box_reg: 0.2362 (0.2382)  loss_objectness: 0.1480 (0.1516)  loss_rpn_box_reg: 0.0643 (0.0758)  time: 0.6508  data: 0.1655  max mem: 10714\n",
      "Training Epoch: [22]  [430/500]  eta: 0:00:44  lr: 0.000000  loss: 6.1674 (6.2109)  loss_classifier: 5.5749 (5.7453)  loss_box_reg: 0.2430 (0.2383)  loss_objectness: 0.1632 (0.1516)  loss_rpn_box_reg: 0.0682 (0.0757)  time: 0.6607  data: 0.1650  max mem: 10714\n",
      "Training Epoch: [22]  [440/500]  eta: 0:00:38  lr: 0.000000  loss: 6.1400 (6.2103)  loss_classifier: 5.6937 (5.7440)  loss_box_reg: 0.2461 (0.2386)  loss_objectness: 0.1388 (0.1516)  loss_rpn_box_reg: 0.0846 (0.0760)  time: 0.6590  data: 0.1652  max mem: 10714\n",
      "Training Epoch: [22]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1392 (6.2090)  loss_classifier: 5.6391 (5.7425)  loss_box_reg: 0.2349 (0.2386)  loss_objectness: 0.1374 (0.1517)  loss_rpn_box_reg: 0.0898 (0.0762)  time: 0.6522  data: 0.1645  max mem: 10714\n",
      "Training Epoch: [22]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.1225 (6.2078)  loss_classifier: 5.5266 (5.7423)  loss_box_reg: 0.2241 (0.2382)  loss_objectness: 0.1381 (0.1515)  loss_rpn_box_reg: 0.0596 (0.0758)  time: 0.6510  data: 0.1643  max mem: 10714\n",
      "Training Epoch: [22]  [470/500]  eta: 0:00:19  lr: 0.000000  loss: 6.1466 (6.2104)  loss_classifier: 5.6941 (5.7444)  loss_box_reg: 0.2419 (0.2386)  loss_objectness: 0.1381 (0.1517)  loss_rpn_box_reg: 0.0596 (0.0757)  time: 0.6483  data: 0.1633  max mem: 10714\n",
      "Training Epoch: [22]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1466 (6.2100)  loss_classifier: 5.6339 (5.7435)  loss_box_reg: 0.2528 (0.2389)  loss_objectness: 0.1534 (0.1518)  loss_rpn_box_reg: 0.0797 (0.0758)  time: 0.6426  data: 0.1639  max mem: 10714\n",
      "Training Epoch: [22]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1738 (6.2123)  loss_classifier: 5.6465 (5.7448)  loss_box_reg: 0.2731 (0.2393)  loss_objectness: 0.1617 (0.1523)  loss_rpn_box_reg: 0.0797 (0.0760)  time: 0.6488  data: 0.1671  max mem: 10714\n",
      "Training Epoch: [22]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.3000 (6.2144)  loss_classifier: 5.7738 (5.7474)  loss_box_reg: 0.2326 (0.2392)  loss_objectness: 0.1576 (0.1522)  loss_rpn_box_reg: 0.0706 (0.0756)  time: 0.6455  data: 0.1676  max mem: 10714\n",
      "Training Epoch: [22] Total time: 0:05:19 (0.6392 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:44  model_time: 0.6501 (0.6501)  evaluator_time: 0.0350 (0.0350)  time: 0.8372  data: 0.1420  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4451 (0.4494)  evaluator_time: 0.0340 (0.0341)  time: 0.6370  data: 0.1541  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4681 (0.4513)  evaluator_time: 0.0360 (0.0361)  time: 0.6608  data: 0.1483  max mem: 10714\n",
      "Test: Total time: 0:01:20 (0.6401 s / it)\n",
      "Averaged stats: model_time: 0.4681 (0.4513)  evaluator_time: 0.0360 (0.0361)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [22]  [  0/125]  eta: 0:01:19  lr: 0.000000  loss: 6.1950 (6.1950)  loss_classifier: 5.6531 (5.6531)  loss_box_reg: 0.2937 (0.2937)  loss_objectness: 0.1147 (0.1147)  loss_rpn_box_reg: 0.1335 (0.1335)  time: 0.6371  data: 0.1370  max mem: 10714\n",
      "Testing Epoch: [22]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0033 (6.1352)  loss_classifier: 5.4270 (5.6248)  loss_box_reg: 0.2609 (0.2894)  loss_objectness: 0.1290 (0.1317)  loss_rpn_box_reg: 0.0694 (0.0892)  time: 0.5850  data: 0.1454  max mem: 10714\n",
      "Testing Epoch: [22]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1617 (6.1662)  loss_classifier: 5.6843 (5.6603)  loss_box_reg: 0.2500 (0.2849)  loss_objectness: 0.1191 (0.1317)  loss_rpn_box_reg: 0.0745 (0.0894)  time: 0.6009  data: 0.1465  max mem: 10714\n",
      "Testing Epoch: [22] Total time: 0:01:14 (0.5956 s / it)\n",
      "Training Epoch: [23]  [  0/500]  eta: 0:07:55  lr: 0.000000  loss: 6.0336 (6.0336)  loss_classifier: 5.4888 (5.4888)  loss_box_reg: 0.2765 (0.2765)  loss_objectness: 0.1794 (0.1794)  loss_rpn_box_reg: 0.0889 (0.0889)  time: 0.9502  data: 0.1760  max mem: 10714\n",
      "Training Epoch: [23]  [ 10/500]  eta: 0:05:30  lr: 0.000000  loss: 6.0402 (6.1957)  loss_classifier: 5.4625 (5.6590)  loss_box_reg: 0.2473 (0.2657)  loss_objectness: 0.1794 (0.1842)  loss_rpn_box_reg: 0.0889 (0.0868)  time: 0.6743  data: 0.1559  max mem: 10714\n",
      "Training Epoch: [23]  [ 20/500]  eta: 0:05:12  lr: 0.000000  loss: 6.1841 (6.3484)  loss_classifier: 5.5980 (5.8267)  loss_box_reg: 0.2458 (0.2596)  loss_objectness: 0.1618 (0.1754)  loss_rpn_box_reg: 0.0708 (0.0867)  time: 0.6364  data: 0.1547  max mem: 10714\n",
      "Training Epoch: [23]  [ 30/500]  eta: 0:05:05  lr: 0.000000  loss: 6.2183 (6.3698)  loss_classifier: 5.7517 (5.8665)  loss_box_reg: 0.2205 (0.2444)  loss_objectness: 0.1534 (0.1711)  loss_rpn_box_reg: 0.0724 (0.0878)  time: 0.6381  data: 0.1527  max mem: 10714\n",
      "Training Epoch: [23]  [ 40/500]  eta: 0:04:56  lr: 0.000000  loss: 6.3341 (6.3347)  loss_classifier: 5.7681 (5.8298)  loss_box_reg: 0.2205 (0.2489)  loss_objectness: 0.1534 (0.1694)  loss_rpn_box_reg: 0.0780 (0.0866)  time: 0.6369  data: 0.1508  max mem: 10714\n",
      "Training Epoch: [23]  [ 50/500]  eta: 0:04:46  lr: 0.000000  loss: 6.1355 (6.2905)  loss_classifier: 5.6931 (5.7881)  loss_box_reg: 0.2535 (0.2505)  loss_objectness: 0.1493 (0.1653)  loss_rpn_box_reg: 0.0824 (0.0865)  time: 0.6168  data: 0.1507  max mem: 10714\n",
      "Training Epoch: [23]  [ 60/500]  eta: 0:04:38  lr: 0.000000  loss: 6.0565 (6.2661)  loss_classifier: 5.6558 (5.7622)  loss_box_reg: 0.2535 (0.2529)  loss_objectness: 0.1545 (0.1647)  loss_rpn_box_reg: 0.0720 (0.0863)  time: 0.6109  data: 0.1487  max mem: 10714\n",
      "Training Epoch: [23]  [ 70/500]  eta: 0:04:31  lr: 0.000000  loss: 6.0565 (6.2662)  loss_classifier: 5.6558 (5.7751)  loss_box_reg: 0.2132 (0.2461)  loss_objectness: 0.1504 (0.1619)  loss_rpn_box_reg: 0.0679 (0.0830)  time: 0.6122  data: 0.1462  max mem: 10714\n",
      "Training Epoch: [23]  [ 80/500]  eta: 0:04:25  lr: 0.000000  loss: 6.2435 (6.2355)  loss_classifier: 5.7560 (5.7512)  loss_box_reg: 0.1997 (0.2417)  loss_objectness: 0.1495 (0.1613)  loss_rpn_box_reg: 0.0627 (0.0812)  time: 0.6284  data: 0.1534  max mem: 10714\n",
      "Training Epoch: [23]  [ 90/500]  eta: 0:04:20  lr: 0.000000  loss: 6.1108 (6.2257)  loss_classifier: 5.6311 (5.7466)  loss_box_reg: 0.2090 (0.2400)  loss_objectness: 0.1421 (0.1582)  loss_rpn_box_reg: 0.0647 (0.0808)  time: 0.6508  data: 0.1567  max mem: 10714\n",
      "Training Epoch: [23]  [100/500]  eta: 0:04:13  lr: 0.000000  loss: 6.1012 (6.2200)  loss_classifier: 5.6256 (5.7448)  loss_box_reg: 0.2090 (0.2400)  loss_objectness: 0.1332 (0.1557)  loss_rpn_box_reg: 0.0670 (0.0794)  time: 0.6465  data: 0.1498  max mem: 10714\n",
      "Training Epoch: [23]  [110/500]  eta: 0:04:08  lr: 0.000000  loss: 6.1474 (6.2253)  loss_classifier: 5.6813 (5.7521)  loss_box_reg: 0.2426 (0.2414)  loss_objectness: 0.1294 (0.1531)  loss_rpn_box_reg: 0.0669 (0.0787)  time: 0.6444  data: 0.1473  max mem: 10714\n",
      "Training Epoch: [23]  [120/500]  eta: 0:04:01  lr: 0.000000  loss: 6.3225 (6.2268)  loss_classifier: 5.7646 (5.7550)  loss_box_reg: 0.2320 (0.2397)  loss_objectness: 0.1393 (0.1536)  loss_rpn_box_reg: 0.0651 (0.0785)  time: 0.6372  data: 0.1480  max mem: 10714\n",
      "Training Epoch: [23]  [130/500]  eta: 0:03:54  lr: 0.000000  loss: 6.1579 (6.2194)  loss_classifier: 5.7238 (5.7475)  loss_box_reg: 0.2356 (0.2387)  loss_objectness: 0.1484 (0.1544)  loss_rpn_box_reg: 0.0666 (0.0789)  time: 0.6198  data: 0.1511  max mem: 10714\n",
      "Training Epoch: [23]  [140/500]  eta: 0:03:49  lr: 0.000000  loss: 5.9994 (6.2116)  loss_classifier: 5.6175 (5.7417)  loss_box_reg: 0.2356 (0.2382)  loss_objectness: 0.1531 (0.1536)  loss_rpn_box_reg: 0.0732 (0.0780)  time: 0.6421  data: 0.1512  max mem: 10714\n",
      "Training Epoch: [23]  [150/500]  eta: 0:03:42  lr: 0.000000  loss: 5.9994 (6.1981)  loss_classifier: 5.5713 (5.7269)  loss_box_reg: 0.2283 (0.2383)  loss_objectness: 0.1531 (0.1543)  loss_rpn_box_reg: 0.0732 (0.0786)  time: 0.6444  data: 0.1494  max mem: 10714\n",
      "Training Epoch: [23]  [160/500]  eta: 0:03:36  lr: 0.000000  loss: 6.1674 (6.2131)  loss_classifier: 5.7239 (5.7422)  loss_box_reg: 0.2018 (0.2376)  loss_objectness: 0.1639 (0.1547)  loss_rpn_box_reg: 0.0680 (0.0786)  time: 0.6369  data: 0.1504  max mem: 10714\n",
      "Training Epoch: [23]  [170/500]  eta: 0:03:30  lr: 0.000000  loss: 6.1953 (6.2144)  loss_classifier: 5.7830 (5.7422)  loss_box_reg: 0.2409 (0.2387)  loss_objectness: 0.1689 (0.1549)  loss_rpn_box_reg: 0.0680 (0.0786)  time: 0.6523  data: 0.1502  max mem: 10714\n",
      "Training Epoch: [23]  [180/500]  eta: 0:03:24  lr: 0.000000  loss: 6.0857 (6.2126)  loss_classifier: 5.6363 (5.7392)  loss_box_reg: 0.2409 (0.2383)  loss_objectness: 0.1573 (0.1559)  loss_rpn_box_reg: 0.0839 (0.0792)  time: 0.6519  data: 0.1515  max mem: 10714\n",
      "Training Epoch: [23]  [190/500]  eta: 0:03:18  lr: 0.000000  loss: 6.0751 (6.2113)  loss_classifier: 5.5927 (5.7387)  loss_box_reg: 0.2149 (0.2389)  loss_objectness: 0.1529 (0.1553)  loss_rpn_box_reg: 0.0711 (0.0784)  time: 0.6513  data: 0.1536  max mem: 10714\n",
      "Training Epoch: [23]  [200/500]  eta: 0:03:11  lr: 0.000000  loss: 6.0942 (6.2122)  loss_classifier: 5.5927 (5.7394)  loss_box_reg: 0.2241 (0.2387)  loss_objectness: 0.1486 (0.1555)  loss_rpn_box_reg: 0.0709 (0.0786)  time: 0.6564  data: 0.1560  max mem: 10714\n",
      "Training Epoch: [23]  [210/500]  eta: 0:03:05  lr: 0.000000  loss: 6.2392 (6.2157)  loss_classifier: 5.7327 (5.7440)  loss_box_reg: 0.2125 (0.2377)  loss_objectness: 0.1499 (0.1552)  loss_rpn_box_reg: 0.0780 (0.0788)  time: 0.6473  data: 0.1541  max mem: 10714\n",
      "Training Epoch: [23]  [220/500]  eta: 0:02:59  lr: 0.000000  loss: 6.2473 (6.2219)  loss_classifier: 5.7327 (5.7497)  loss_box_reg: 0.2265 (0.2391)  loss_objectness: 0.1499 (0.1549)  loss_rpn_box_reg: 0.0682 (0.0783)  time: 0.6393  data: 0.1493  max mem: 10714\n",
      "Training Epoch: [23]  [230/500]  eta: 0:02:52  lr: 0.000000  loss: 6.3921 (6.2327)  loss_classifier: 6.0201 (5.7600)  loss_box_reg: 0.2534 (0.2392)  loss_objectness: 0.1521 (0.1546)  loss_rpn_box_reg: 0.0742 (0.0790)  time: 0.6411  data: 0.1507  max mem: 10714\n",
      "Training Epoch: [23]  [240/500]  eta: 0:02:46  lr: 0.000000  loss: 6.4417 (6.2365)  loss_classifier: 6.0201 (5.7640)  loss_box_reg: 0.2196 (0.2390)  loss_objectness: 0.1471 (0.1543)  loss_rpn_box_reg: 0.0829 (0.0793)  time: 0.6323  data: 0.1488  max mem: 10714\n",
      "Training Epoch: [23]  [250/500]  eta: 0:02:39  lr: 0.000000  loss: 6.2518 (6.2295)  loss_classifier: 5.7796 (5.7563)  loss_box_reg: 0.2309 (0.2395)  loss_objectness: 0.1501 (0.1547)  loss_rpn_box_reg: 0.0808 (0.0790)  time: 0.6389  data: 0.1482  max mem: 10714\n",
      "Training Epoch: [23]  [260/500]  eta: 0:02:33  lr: 0.000000  loss: 5.9304 (6.2278)  loss_classifier: 5.4838 (5.7547)  loss_box_reg: 0.2309 (0.2395)  loss_objectness: 0.1504 (0.1545)  loss_rpn_box_reg: 0.0728 (0.0790)  time: 0.6395  data: 0.1505  max mem: 10714\n",
      "Training Epoch: [23]  [270/500]  eta: 0:02:27  lr: 0.000000  loss: 6.1710 (6.2257)  loss_classifier: 5.6497 (5.7521)  loss_box_reg: 0.2508 (0.2397)  loss_objectness: 0.1645 (0.1550)  loss_rpn_box_reg: 0.0744 (0.0789)  time: 0.6356  data: 0.1499  max mem: 10714\n",
      "Training Epoch: [23]  [280/500]  eta: 0:02:20  lr: 0.000000  loss: 6.1586 (6.2250)  loss_classifier: 5.6827 (5.7517)  loss_box_reg: 0.2406 (0.2393)  loss_objectness: 0.1690 (0.1551)  loss_rpn_box_reg: 0.0720 (0.0789)  time: 0.6418  data: 0.1498  max mem: 10714\n",
      "Training Epoch: [23]  [290/500]  eta: 0:02:14  lr: 0.000000  loss: 6.0938 (6.2196)  loss_classifier: 5.6450 (5.7473)  loss_box_reg: 0.2247 (0.2387)  loss_objectness: 0.1513 (0.1552)  loss_rpn_box_reg: 0.0669 (0.0785)  time: 0.6343  data: 0.1495  max mem: 10714\n",
      "Training Epoch: [23]  [300/500]  eta: 0:02:07  lr: 0.000000  loss: 6.0647 (6.2207)  loss_classifier: 5.6450 (5.7468)  loss_box_reg: 0.2319 (0.2398)  loss_objectness: 0.1513 (0.1556)  loss_rpn_box_reg: 0.0669 (0.0785)  time: 0.6260  data: 0.1484  max mem: 10714\n",
      "Training Epoch: [23]  [310/500]  eta: 0:02:01  lr: 0.000000  loss: 6.2361 (6.2203)  loss_classifier: 5.7759 (5.7450)  loss_box_reg: 0.2575 (0.2406)  loss_objectness: 0.1647 (0.1562)  loss_rpn_box_reg: 0.0706 (0.0786)  time: 0.6198  data: 0.1503  max mem: 10714\n",
      "Training Epoch: [23]  [320/500]  eta: 0:01:54  lr: 0.000000  loss: 6.2091 (6.2206)  loss_classifier: 5.7815 (5.7457)  loss_box_reg: 0.2481 (0.2405)  loss_objectness: 0.1499 (0.1559)  loss_rpn_box_reg: 0.0706 (0.0785)  time: 0.6275  data: 0.1513  max mem: 10714\n",
      "Training Epoch: [23]  [330/500]  eta: 0:01:48  lr: 0.000000  loss: 6.1793 (6.2183)  loss_classifier: 5.7246 (5.7443)  loss_box_reg: 0.2197 (0.2396)  loss_objectness: 0.1384 (0.1558)  loss_rpn_box_reg: 0.0759 (0.0787)  time: 0.6367  data: 0.1500  max mem: 10714\n",
      "Training Epoch: [23]  [340/500]  eta: 0:01:42  lr: 0.000000  loss: 6.1793 (6.2240)  loss_classifier: 5.7612 (5.7505)  loss_box_reg: 0.2197 (0.2396)  loss_objectness: 0.1390 (0.1554)  loss_rpn_box_reg: 0.0681 (0.0784)  time: 0.6463  data: 0.1493  max mem: 10714\n",
      "Training Epoch: [23]  [350/500]  eta: 0:01:35  lr: 0.000000  loss: 6.3775 (6.2256)  loss_classifier: 5.8794 (5.7520)  loss_box_reg: 0.2595 (0.2400)  loss_objectness: 0.1390 (0.1551)  loss_rpn_box_reg: 0.0659 (0.0785)  time: 0.6604  data: 0.1501  max mem: 10714\n",
      "Training Epoch: [23]  [360/500]  eta: 0:01:29  lr: 0.000000  loss: 6.2646 (6.2248)  loss_classifier: 5.7764 (5.7508)  loss_box_reg: 0.2391 (0.2406)  loss_objectness: 0.1539 (0.1553)  loss_rpn_box_reg: 0.0592 (0.0781)  time: 0.6519  data: 0.1528  max mem: 10714\n",
      "Training Epoch: [23]  [370/500]  eta: 0:01:23  lr: 0.000000  loss: 6.1564 (6.2274)  loss_classifier: 5.6782 (5.7539)  loss_box_reg: 0.2407 (0.2401)  loss_objectness: 0.1554 (0.1553)  loss_rpn_box_reg: 0.0694 (0.0781)  time: 0.6472  data: 0.1517  max mem: 10714\n",
      "Training Epoch: [23]  [380/500]  eta: 0:01:16  lr: 0.000000  loss: 6.1837 (6.2260)  loss_classifier: 5.7517 (5.7536)  loss_box_reg: 0.2342 (0.2395)  loss_objectness: 0.1496 (0.1552)  loss_rpn_box_reg: 0.0667 (0.0778)  time: 0.6372  data: 0.1467  max mem: 10714\n",
      "Training Epoch: [23]  [390/500]  eta: 0:01:10  lr: 0.000000  loss: 6.0942 (6.2229)  loss_classifier: 5.6580 (5.7510)  loss_box_reg: 0.2057 (0.2393)  loss_objectness: 0.1459 (0.1552)  loss_rpn_box_reg: 0.0620 (0.0774)  time: 0.6309  data: 0.1459  max mem: 10714\n",
      "Training Epoch: [23]  [400/500]  eta: 0:01:03  lr: 0.000000  loss: 6.2337 (6.2248)  loss_classifier: 5.7109 (5.7529)  loss_box_reg: 0.2336 (0.2396)  loss_objectness: 0.1495 (0.1549)  loss_rpn_box_reg: 0.0653 (0.0774)  time: 0.6501  data: 0.1518  max mem: 10714\n",
      "Training Epoch: [23]  [410/500]  eta: 0:00:57  lr: 0.000000  loss: 6.4700 (6.2314)  loss_classifier: 5.9789 (5.7585)  loss_box_reg: 0.2440 (0.2402)  loss_objectness: 0.1535 (0.1551)  loss_rpn_box_reg: 0.0685 (0.0776)  time: 0.6567  data: 0.1532  max mem: 10714\n",
      "Training Epoch: [23]  [420/500]  eta: 0:00:51  lr: 0.000000  loss: 6.2792 (6.2309)  loss_classifier: 5.7815 (5.7581)  loss_box_reg: 0.2440 (0.2403)  loss_objectness: 0.1520 (0.1550)  loss_rpn_box_reg: 0.0580 (0.0774)  time: 0.6481  data: 0.1478  max mem: 10714\n",
      "Training Epoch: [23]  [430/500]  eta: 0:00:44  lr: 0.000000  loss: 6.1885 (6.2284)  loss_classifier: 5.6324 (5.7559)  loss_box_reg: 0.2463 (0.2404)  loss_objectness: 0.1489 (0.1550)  loss_rpn_box_reg: 0.0510 (0.0771)  time: 0.6408  data: 0.1490  max mem: 10714\n",
      "Training Epoch: [23]  [440/500]  eta: 0:00:38  lr: 0.000000  loss: 6.1024 (6.2241)  loss_classifier: 5.6003 (5.7525)  loss_box_reg: 0.2280 (0.2402)  loss_objectness: 0.1371 (0.1547)  loss_rpn_box_reg: 0.0510 (0.0767)  time: 0.6395  data: 0.1529  max mem: 10714\n",
      "Training Epoch: [23]  [450/500]  eta: 0:00:32  lr: 0.000000  loss: 5.9254 (6.2202)  loss_classifier: 5.5281 (5.7489)  loss_box_reg: 0.2280 (0.2399)  loss_objectness: 0.1556 (0.1549)  loss_rpn_box_reg: 0.0517 (0.0764)  time: 0.6413  data: 0.1500  max mem: 10714\n",
      "Training Epoch: [23]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0547 (6.2204)  loss_classifier: 5.6100 (5.7493)  loss_box_reg: 0.2321 (0.2398)  loss_objectness: 0.1556 (0.1547)  loss_rpn_box_reg: 0.0648 (0.0766)  time: 0.6330  data: 0.1487  max mem: 10714\n",
      "Training Epoch: [23]  [470/500]  eta: 0:00:19  lr: 0.000000  loss: 6.0547 (6.2166)  loss_classifier: 5.6812 (5.7463)  loss_box_reg: 0.2208 (0.2390)  loss_objectness: 0.1395 (0.1546)  loss_rpn_box_reg: 0.0648 (0.0767)  time: 0.6286  data: 0.1499  max mem: 10714\n",
      "Training Epoch: [23]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2603 (6.2204)  loss_classifier: 5.7933 (5.7514)  loss_box_reg: 0.2140 (0.2382)  loss_objectness: 0.1374 (0.1544)  loss_rpn_box_reg: 0.0579 (0.0764)  time: 0.6374  data: 0.1496  max mem: 10714\n",
      "Training Epoch: [23]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.3844 (6.2227)  loss_classifier: 5.9769 (5.7544)  loss_box_reg: 0.2140 (0.2380)  loss_objectness: 0.1342 (0.1542)  loss_rpn_box_reg: 0.0501 (0.0761)  time: 0.6495  data: 0.1496  max mem: 10714\n",
      "Training Epoch: [23]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.3314 (6.2217)  loss_classifier: 5.8894 (5.7543)  loss_box_reg: 0.2223 (0.2376)  loss_objectness: 0.1395 (0.1539)  loss_rpn_box_reg: 0.0559 (0.0759)  time: 0.6554  data: 0.1486  max mem: 10714\n",
      "Training Epoch: [23] Total time: 0:05:20 (0.6403 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:52  model_time: 0.7122 (0.7122)  evaluator_time: 0.0340 (0.0340)  time: 0.8962  data: 0.1410  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4381 (0.4526)  evaluator_time: 0.0340 (0.0370)  time: 0.6375  data: 0.1544  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4751 (0.4540)  evaluator_time: 0.0360 (0.0384)  time: 0.6536  data: 0.1413  max mem: 10714\n",
      "Test: Total time: 0:01:20 (0.6415 s / it)\n",
      "Averaged stats: model_time: 0.4751 (0.4540)  evaluator_time: 0.0360 (0.0384)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [23]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.1979 (6.1979)  loss_classifier: 5.6538 (5.6538)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1191 (0.1191)  loss_rpn_box_reg: 0.1305 (0.1305)  time: 0.6481  data: 0.1440  max mem: 10714\n",
      "Testing Epoch: [23]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0073 (6.1388)  loss_classifier: 5.4196 (5.6293)  loss_box_reg: 0.2609 (0.2891)  loss_objectness: 0.1311 (0.1314)  loss_rpn_box_reg: 0.0701 (0.0890)  time: 0.5870  data: 0.1482  max mem: 10714\n",
      "Testing Epoch: [23]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1556 (6.1683)  loss_classifier: 5.6849 (5.6634)  loss_box_reg: 0.2500 (0.2846)  loss_objectness: 0.1165 (0.1311)  loss_rpn_box_reg: 0.0745 (0.0893)  time: 0.5973  data: 0.1455  max mem: 10714\n",
      "Testing Epoch: [23] Total time: 0:01:14 (0.5963 s / it)\n",
      "Training Epoch: [24]  [  0/500]  eta: 0:07:08  lr: 0.000000  loss: 6.1443 (6.1443)  loss_classifier: 5.5761 (5.5761)  loss_box_reg: 0.2251 (0.2251)  loss_objectness: 0.2240 (0.2240)  loss_rpn_box_reg: 0.1192 (0.1192)  time: 0.8572  data: 0.1400  max mem: 10714\n",
      "Training Epoch: [24]  [ 10/500]  eta: 0:05:17  lr: 0.000000  loss: 6.0997 (6.0124)  loss_classifier: 5.6001 (5.5312)  loss_box_reg: 0.2573 (0.2629)  loss_objectness: 0.1465 (0.1474)  loss_rpn_box_reg: 0.0649 (0.0709)  time: 0.6484  data: 0.1360  max mem: 10714\n",
      "Training Epoch: [24]  [ 20/500]  eta: 0:05:06  lr: 0.000000  loss: 6.1948 (6.2419)  loss_classifier: 5.7035 (5.7754)  loss_box_reg: 0.2464 (0.2456)  loss_objectness: 0.1429 (0.1518)  loss_rpn_box_reg: 0.0634 (0.0692)  time: 0.6282  data: 0.1376  max mem: 10714\n",
      "Training Epoch: [24]  [ 30/500]  eta: 0:04:56  lr: 0.000000  loss: 6.3641 (6.2698)  loss_classifier: 5.7765 (5.7889)  loss_box_reg: 0.2501 (0.2542)  loss_objectness: 0.1482 (0.1544)  loss_rpn_box_reg: 0.0641 (0.0722)  time: 0.6200  data: 0.1362  max mem: 10714\n",
      "Training Epoch: [24]  [ 40/500]  eta: 0:04:49  lr: 0.000000  loss: 6.2559 (6.2445)  loss_classifier: 5.6951 (5.7724)  loss_box_reg: 0.2501 (0.2501)  loss_objectness: 0.1362 (0.1492)  loss_rpn_box_reg: 0.0629 (0.0727)  time: 0.6208  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [24]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 6.1798 (6.2673)  loss_classifier: 5.6877 (5.7998)  loss_box_reg: 0.2205 (0.2455)  loss_objectness: 0.1279 (0.1472)  loss_rpn_box_reg: 0.0599 (0.0749)  time: 0.6269  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [24]  [ 60/500]  eta: 0:04:37  lr: 0.000000  loss: 6.1791 (6.2263)  loss_classifier: 5.6877 (5.7581)  loss_box_reg: 0.2205 (0.2440)  loss_objectness: 0.1430 (0.1488)  loss_rpn_box_reg: 0.0762 (0.0754)  time: 0.6286  data: 0.1359  max mem: 10714\n",
      "Training Epoch: [24]  [ 70/500]  eta: 0:04:29  lr: 0.000000  loss: 6.1753 (6.2278)  loss_classifier: 5.7505 (5.7575)  loss_box_reg: 0.2243 (0.2441)  loss_objectness: 0.1505 (0.1499)  loss_rpn_box_reg: 0.0754 (0.0763)  time: 0.6212  data: 0.1373  max mem: 10714\n",
      "Training Epoch: [24]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 6.0166 (6.1889)  loss_classifier: 5.4852 (5.7192)  loss_box_reg: 0.2467 (0.2443)  loss_objectness: 0.1418 (0.1486)  loss_rpn_box_reg: 0.0746 (0.0769)  time: 0.6224  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [24]  [ 90/500]  eta: 0:04:16  lr: 0.000000  loss: 6.0298 (6.1993)  loss_classifier: 5.5423 (5.7263)  loss_box_reg: 0.2468 (0.2459)  loss_objectness: 0.1373 (0.1507)  loss_rpn_box_reg: 0.0705 (0.0764)  time: 0.6268  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [24]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 6.0607 (6.1850)  loss_classifier: 5.5423 (5.7094)  loss_box_reg: 0.2518 (0.2480)  loss_objectness: 0.1596 (0.1507)  loss_rpn_box_reg: 0.0774 (0.0768)  time: 0.6192  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [24]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 6.0191 (6.1982)  loss_classifier: 5.5567 (5.7234)  loss_box_reg: 0.2571 (0.2491)  loss_objectness: 0.1519 (0.1497)  loss_rpn_box_reg: 0.0692 (0.0759)  time: 0.6190  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [24]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.0191 (6.1816)  loss_classifier: 5.5815 (5.7037)  loss_box_reg: 0.2634 (0.2494)  loss_objectness: 0.1519 (0.1515)  loss_rpn_box_reg: 0.0692 (0.0770)  time: 0.6353  data: 0.1365  max mem: 10714\n",
      "Training Epoch: [24]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.1436 (6.1978)  loss_classifier: 5.6153 (5.7208)  loss_box_reg: 0.2243 (0.2475)  loss_objectness: 0.1566 (0.1524)  loss_rpn_box_reg: 0.0741 (0.0771)  time: 0.6351  data: 0.1379  max mem: 10714\n",
      "Training Epoch: [24]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.3578 (6.2051)  loss_classifier: 5.7991 (5.7250)  loss_box_reg: 0.2307 (0.2486)  loss_objectness: 0.1563 (0.1535)  loss_rpn_box_reg: 0.0821 (0.0780)  time: 0.6277  data: 0.1365  max mem: 10714\n",
      "Training Epoch: [24]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.1708 (6.2118)  loss_classifier: 5.7206 (5.7362)  loss_box_reg: 0.2221 (0.2461)  loss_objectness: 0.1391 (0.1526)  loss_rpn_box_reg: 0.0681 (0.0769)  time: 0.6399  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [24]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.1126 (6.2087)  loss_classifier: 5.7006 (5.7328)  loss_box_reg: 0.2221 (0.2467)  loss_objectness: 0.1353 (0.1524)  loss_rpn_box_reg: 0.0632 (0.0768)  time: 0.6355  data: 0.1361  max mem: 10714\n",
      "Training Epoch: [24]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.1996 (6.2061)  loss_classifier: 5.6650 (5.7317)  loss_box_reg: 0.2310 (0.2455)  loss_objectness: 0.1360 (0.1531)  loss_rpn_box_reg: 0.0612 (0.0759)  time: 0.6258  data: 0.1364  max mem: 10714\n",
      "Training Epoch: [24]  [180/500]  eta: 0:03:21  lr: 0.000000  loss: 6.1996 (6.2083)  loss_classifier: 5.6816 (5.7353)  loss_box_reg: 0.2326 (0.2453)  loss_objectness: 0.1356 (0.1524)  loss_rpn_box_reg: 0.0567 (0.0753)  time: 0.6253  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [24]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.1421 (6.2107)  loss_classifier: 5.6816 (5.7396)  loss_box_reg: 0.2326 (0.2437)  loss_objectness: 0.1356 (0.1520)  loss_rpn_box_reg: 0.0637 (0.0754)  time: 0.6261  data: 0.1334  max mem: 10714\n",
      "Training Epoch: [24]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.1640 (6.2149)  loss_classifier: 5.6255 (5.7422)  loss_box_reg: 0.2429 (0.2450)  loss_objectness: 0.1454 (0.1524)  loss_rpn_box_reg: 0.0681 (0.0753)  time: 0.6164  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [24]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.2576 (6.2218)  loss_classifier: 5.7953 (5.7504)  loss_box_reg: 0.2478 (0.2438)  loss_objectness: 0.1513 (0.1522)  loss_rpn_box_reg: 0.0789 (0.0755)  time: 0.6235  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [24]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.1904 (6.2160)  loss_classifier: 5.7953 (5.7467)  loss_box_reg: 0.2311 (0.2427)  loss_objectness: 0.1358 (0.1517)  loss_rpn_box_reg: 0.0600 (0.0749)  time: 0.6371  data: 0.1340  max mem: 10714\n",
      "Training Epoch: [24]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.1904 (6.2173)  loss_classifier: 5.7335 (5.7489)  loss_box_reg: 0.2257 (0.2419)  loss_objectness: 0.1340 (0.1515)  loss_rpn_box_reg: 0.0717 (0.0750)  time: 0.6256  data: 0.1324  max mem: 10714\n",
      "Training Epoch: [24]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.2880 (6.2187)  loss_classifier: 5.8119 (5.7508)  loss_box_reg: 0.2097 (0.2417)  loss_objectness: 0.1323 (0.1506)  loss_rpn_box_reg: 0.0797 (0.0756)  time: 0.6149  data: 0.1307  max mem: 10714\n",
      "Training Epoch: [24]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.2534 (6.2151)  loss_classifier: 5.8119 (5.7474)  loss_box_reg: 0.2209 (0.2413)  loss_objectness: 0.1323 (0.1507)  loss_rpn_box_reg: 0.0771 (0.0757)  time: 0.6105  data: 0.1311  max mem: 10714\n",
      "Training Epoch: [24]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.1056 (6.2065)  loss_classifier: 5.6455 (5.7399)  loss_box_reg: 0.2175 (0.2410)  loss_objectness: 0.1463 (0.1501)  loss_rpn_box_reg: 0.0672 (0.0755)  time: 0.6135  data: 0.1316  max mem: 10714\n",
      "Training Epoch: [24]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 5.9317 (6.2078)  loss_classifier: 5.5322 (5.7407)  loss_box_reg: 0.2432 (0.2415)  loss_objectness: 0.1332 (0.1497)  loss_rpn_box_reg: 0.0658 (0.0759)  time: 0.6362  data: 0.1321  max mem: 10714\n",
      "Training Epoch: [24]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.3200 (6.2194)  loss_classifier: 5.8375 (5.7518)  loss_box_reg: 0.2432 (0.2415)  loss_objectness: 0.1520 (0.1501)  loss_rpn_box_reg: 0.0869 (0.0760)  time: 0.6371  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [24]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.2674 (6.2129)  loss_classifier: 5.6541 (5.7437)  loss_box_reg: 0.2338 (0.2425)  loss_objectness: 0.1531 (0.1507)  loss_rpn_box_reg: 0.0785 (0.0760)  time: 0.6336  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [24]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.0549 (6.2133)  loss_classifier: 5.5192 (5.7438)  loss_box_reg: 0.2419 (0.2425)  loss_objectness: 0.1480 (0.1511)  loss_rpn_box_reg: 0.0731 (0.0759)  time: 0.6413  data: 0.1366  max mem: 10714\n",
      "Training Epoch: [24]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.0788 (6.2137)  loss_classifier: 5.6990 (5.7438)  loss_box_reg: 0.2240 (0.2424)  loss_objectness: 0.1502 (0.1511)  loss_rpn_box_reg: 0.0873 (0.0764)  time: 0.6422  data: 0.1357  max mem: 10714\n",
      "Training Epoch: [24]  [320/500]  eta: 0:01:53  lr: 0.000000  loss: 6.0788 (6.2085)  loss_classifier: 5.6571 (5.7393)  loss_box_reg: 0.2162 (0.2420)  loss_objectness: 0.1502 (0.1512)  loss_rpn_box_reg: 0.0735 (0.0761)  time: 0.6298  data: 0.1328  max mem: 10714\n",
      "Training Epoch: [24]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.1509 (6.2085)  loss_classifier: 5.6783 (5.7381)  loss_box_reg: 0.2284 (0.2424)  loss_objectness: 0.1533 (0.1513)  loss_rpn_box_reg: 0.0679 (0.0767)  time: 0.6178  data: 0.1328  max mem: 10714\n",
      "Training Epoch: [24]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.2164 (6.2055)  loss_classifier: 5.6851 (5.7352)  loss_box_reg: 0.2504 (0.2423)  loss_objectness: 0.1553 (0.1515)  loss_rpn_box_reg: 0.0736 (0.0765)  time: 0.6257  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [24]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.1860 (6.2078)  loss_classifier: 5.7253 (5.7364)  loss_box_reg: 0.2353 (0.2423)  loss_objectness: 0.1624 (0.1522)  loss_rpn_box_reg: 0.0737 (0.0769)  time: 0.6162  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [24]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1860 (6.2114)  loss_classifier: 5.7253 (5.7394)  loss_box_reg: 0.2191 (0.2426)  loss_objectness: 0.1725 (0.1527)  loss_rpn_box_reg: 0.0768 (0.0767)  time: 0.6127  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [24]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.2056 (6.2078)  loss_classifier: 5.7111 (5.7364)  loss_box_reg: 0.2321 (0.2425)  loss_objectness: 0.1624 (0.1527)  loss_rpn_box_reg: 0.0664 (0.0763)  time: 0.6160  data: 0.1367  max mem: 10714\n",
      "Training Epoch: [24]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.2272 (6.2113)  loss_classifier: 5.7998 (5.7393)  loss_box_reg: 0.2304 (0.2422)  loss_objectness: 0.1467 (0.1535)  loss_rpn_box_reg: 0.0698 (0.0763)  time: 0.6110  data: 0.1366  max mem: 10714\n",
      "Training Epoch: [24]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.2272 (6.2095)  loss_classifier: 5.7714 (5.7376)  loss_box_reg: 0.2045 (0.2414)  loss_objectness: 0.1509 (0.1536)  loss_rpn_box_reg: 0.0898 (0.0769)  time: 0.6166  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [24]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1333 (6.2092)  loss_classifier: 5.6112 (5.7376)  loss_box_reg: 0.2067 (0.2413)  loss_objectness: 0.1419 (0.1533)  loss_rpn_box_reg: 0.0881 (0.0770)  time: 0.6273  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [24]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1520 (6.2093)  loss_classifier: 5.6163 (5.7382)  loss_box_reg: 0.2115 (0.2406)  loss_objectness: 0.1298 (0.1531)  loss_rpn_box_reg: 0.0709 (0.0773)  time: 0.6258  data: 0.1338  max mem: 10714\n",
      "Training Epoch: [24]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.1933 (6.2109)  loss_classifier: 5.7270 (5.7406)  loss_box_reg: 0.2229 (0.2402)  loss_objectness: 0.1457 (0.1532)  loss_rpn_box_reg: 0.0639 (0.0769)  time: 0.6180  data: 0.1333  max mem: 10714\n",
      "Training Epoch: [24]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1502 (6.2072)  loss_classifier: 5.6998 (5.7382)  loss_box_reg: 0.2229 (0.2393)  loss_objectness: 0.1378 (0.1526)  loss_rpn_box_reg: 0.0639 (0.0770)  time: 0.6329  data: 0.1324  max mem: 10714\n",
      "Training Epoch: [24]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 5.9596 (6.2087)  loss_classifier: 5.5743 (5.7388)  loss_box_reg: 0.2304 (0.2402)  loss_objectness: 0.1239 (0.1528)  loss_rpn_box_reg: 0.0707 (0.0770)  time: 0.6320  data: 0.1334  max mem: 10714\n",
      "Training Epoch: [24]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.2606 (6.2102)  loss_classifier: 5.6846 (5.7406)  loss_box_reg: 0.2347 (0.2404)  loss_objectness: 0.1554 (0.1526)  loss_rpn_box_reg: 0.0591 (0.0766)  time: 0.6290  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [24]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0467 (6.2116)  loss_classifier: 5.6194 (5.7416)  loss_box_reg: 0.2358 (0.2410)  loss_objectness: 0.1299 (0.1523)  loss_rpn_box_reg: 0.0667 (0.0768)  time: 0.6346  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [24]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 5.9790 (6.2091)  loss_classifier: 5.4532 (5.7391)  loss_box_reg: 0.2456 (0.2412)  loss_objectness: 0.1396 (0.1523)  loss_rpn_box_reg: 0.0696 (0.0765)  time: 0.6387  data: 0.1359  max mem: 10714\n",
      "Training Epoch: [24]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1873 (6.2112)  loss_classifier: 5.7019 (5.7411)  loss_box_reg: 0.2458 (0.2413)  loss_objectness: 0.1600 (0.1524)  loss_rpn_box_reg: 0.0656 (0.0765)  time: 0.6296  data: 0.1368  max mem: 10714\n",
      "Training Epoch: [24]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1819 (6.2077)  loss_classifier: 5.5731 (5.7383)  loss_box_reg: 0.2350 (0.2412)  loss_objectness: 0.1435 (0.1520)  loss_rpn_box_reg: 0.0557 (0.0762)  time: 0.6178  data: 0.1336  max mem: 10714\n",
      "Training Epoch: [24]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0377 (6.2076)  loss_classifier: 5.6006 (5.7391)  loss_box_reg: 0.2236 (0.2410)  loss_objectness: 0.1352 (0.1518)  loss_rpn_box_reg: 0.0551 (0.0758)  time: 0.6196  data: 0.1325  max mem: 10714\n",
      "Training Epoch: [24] Total time: 0:05:13 (0.6263 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:55  model_time: 0.7362 (0.7362)  evaluator_time: 0.0350 (0.0350)  time: 0.9232  data: 0.1430  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4421 (0.4527)  evaluator_time: 0.0340 (0.0339)  time: 0.6375  data: 0.1544  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4711 (0.4548)  evaluator_time: 0.0370 (0.0349)  time: 0.6581  data: 0.1486  max mem: 10714\n",
      "Test: Total time: 0:01:20 (0.6435 s / it)\n",
      "Averaged stats: model_time: 0.4711 (0.4548)  evaluator_time: 0.0370 (0.0349)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [24]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1859 (6.1859)  loss_classifier: 5.6370 (5.6370)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1235 (0.1235)  loss_rpn_box_reg: 0.1309 (0.1309)  time: 0.6471  data: 0.1470  max mem: 10714\n",
      "Testing Epoch: [24]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9979 (6.1377)  loss_classifier: 5.4263 (5.6270)  loss_box_reg: 0.2609 (0.2888)  loss_objectness: 0.1309 (0.1320)  loss_rpn_box_reg: 0.0707 (0.0898)  time: 0.5876  data: 0.1445  max mem: 10714\n",
      "Testing Epoch: [24]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1737 (6.1691)  loss_classifier: 5.7001 (5.6631)  loss_box_reg: 0.2500 (0.2844)  loss_objectness: 0.1209 (0.1318)  loss_rpn_box_reg: 0.0745 (0.0898)  time: 0.6051  data: 0.1465  max mem: 10714\n",
      "Testing Epoch: [24] Total time: 0:01:14 (0.5989 s / it)\n",
      "Training Epoch: [25]  [  0/500]  eta: 0:06:11  lr: 0.000000  loss: 6.3597 (6.3597)  loss_classifier: 5.9384 (5.9384)  loss_box_reg: 0.2376 (0.2376)  loss_objectness: 0.1442 (0.1442)  loss_rpn_box_reg: 0.0395 (0.0395)  time: 0.7432  data: 0.1300  max mem: 10714\n",
      "Training Epoch: [25]  [ 10/500]  eta: 0:05:06  lr: 0.000000  loss: 6.1095 (6.2286)  loss_classifier: 5.7515 (5.8363)  loss_box_reg: 0.2110 (0.1990)  loss_objectness: 0.1442 (0.1397)  loss_rpn_box_reg: 0.0445 (0.0536)  time: 0.6247  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [25]  [ 20/500]  eta: 0:04:58  lr: 0.000000  loss: 6.1095 (6.1920)  loss_classifier: 5.6968 (5.7525)  loss_box_reg: 0.2110 (0.2179)  loss_objectness: 0.1463 (0.1455)  loss_rpn_box_reg: 0.0668 (0.0760)  time: 0.6167  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [25]  [ 30/500]  eta: 0:04:55  lr: 0.000000  loss: 6.1565 (6.1765)  loss_classifier: 5.6968 (5.7273)  loss_box_reg: 0.2549 (0.2279)  loss_objectness: 0.1445 (0.1454)  loss_rpn_box_reg: 0.0768 (0.0760)  time: 0.6325  data: 0.1373  max mem: 10714\n",
      "Training Epoch: [25]  [ 40/500]  eta: 0:04:50  lr: 0.000000  loss: 6.1634 (6.2034)  loss_classifier: 5.7186 (5.7523)  loss_box_reg: 0.2394 (0.2277)  loss_objectness: 0.1438 (0.1477)  loss_rpn_box_reg: 0.0725 (0.0756)  time: 0.6408  data: 0.1377  max mem: 10714\n",
      "Training Epoch: [25]  [ 50/500]  eta: 0:04:43  lr: 0.000000  loss: 6.1994 (6.2528)  loss_classifier: 5.7392 (5.8038)  loss_box_reg: 0.2217 (0.2267)  loss_objectness: 0.1483 (0.1472)  loss_rpn_box_reg: 0.0555 (0.0751)  time: 0.6320  data: 0.1364  max mem: 10714\n",
      "Training Epoch: [25]  [ 60/500]  eta: 0:04:37  lr: 0.000000  loss: 6.2328 (6.2570)  loss_classifier: 5.8177 (5.8040)  loss_box_reg: 0.2189 (0.2294)  loss_objectness: 0.1394 (0.1470)  loss_rpn_box_reg: 0.0598 (0.0766)  time: 0.6281  data: 0.1360  max mem: 10714\n",
      "Training Epoch: [25]  [ 70/500]  eta: 0:04:29  lr: 0.000000  loss: 6.2272 (6.2576)  loss_classifier: 5.6949 (5.8021)  loss_box_reg: 0.2309 (0.2312)  loss_objectness: 0.1394 (0.1498)  loss_rpn_box_reg: 0.0624 (0.0745)  time: 0.6146  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [25]  [ 80/500]  eta: 0:04:22  lr: 0.000000  loss: 6.2149 (6.2596)  loss_classifier: 5.6949 (5.7992)  loss_box_reg: 0.2550 (0.2336)  loss_objectness: 0.1488 (0.1503)  loss_rpn_box_reg: 0.0651 (0.0765)  time: 0.6085  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [25]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 6.1474 (6.2414)  loss_classifier: 5.7161 (5.7870)  loss_box_reg: 0.2244 (0.2309)  loss_objectness: 0.1266 (0.1486)  loss_rpn_box_reg: 0.0714 (0.0750)  time: 0.6322  data: 0.1328  max mem: 10714\n",
      "Training Epoch: [25]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 6.2281 (6.2583)  loss_classifier: 5.7675 (5.8054)  loss_box_reg: 0.2108 (0.2308)  loss_objectness: 0.1368 (0.1480)  loss_rpn_box_reg: 0.0527 (0.0742)  time: 0.6388  data: 0.1323  max mem: 10714\n",
      "Training Epoch: [25]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.2194 (6.2484)  loss_classifier: 5.7510 (5.7928)  loss_box_reg: 0.2220 (0.2321)  loss_objectness: 0.1405 (0.1475)  loss_rpn_box_reg: 0.0527 (0.0760)  time: 0.6264  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [25]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.1731 (6.2500)  loss_classifier: 5.6547 (5.7923)  loss_box_reg: 0.2441 (0.2338)  loss_objectness: 0.1339 (0.1480)  loss_rpn_box_reg: 0.0820 (0.0758)  time: 0.6299  data: 0.1369  max mem: 10714\n",
      "Training Epoch: [25]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 6.2479 (6.2400)  loss_classifier: 5.8040 (5.7842)  loss_box_reg: 0.2172 (0.2326)  loss_objectness: 0.1385 (0.1480)  loss_rpn_box_reg: 0.0622 (0.0753)  time: 0.6309  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [25]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.0889 (6.2284)  loss_classifier: 5.6497 (5.7720)  loss_box_reg: 0.2134 (0.2331)  loss_objectness: 0.1486 (0.1481)  loss_rpn_box_reg: 0.0604 (0.0751)  time: 0.6231  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [25]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.0584 (6.2193)  loss_classifier: 5.6427 (5.7628)  loss_box_reg: 0.2430 (0.2327)  loss_objectness: 0.1486 (0.1484)  loss_rpn_box_reg: 0.0798 (0.0754)  time: 0.6249  data: 0.1345  max mem: 10714\n",
      "Training Epoch: [25]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.0584 (6.2075)  loss_classifier: 5.6597 (5.7515)  loss_box_reg: 0.2146 (0.2322)  loss_objectness: 0.1371 (0.1475)  loss_rpn_box_reg: 0.0911 (0.0763)  time: 0.6117  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [25]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.1528 (6.2134)  loss_classifier: 5.6855 (5.7538)  loss_box_reg: 0.2410 (0.2328)  loss_objectness: 0.1477 (0.1495)  loss_rpn_box_reg: 0.1030 (0.0773)  time: 0.6120  data: 0.1366  max mem: 10714\n",
      "Training Epoch: [25]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.3437 (6.2096)  loss_classifier: 5.7660 (5.7501)  loss_box_reg: 0.2422 (0.2326)  loss_objectness: 0.1582 (0.1493)  loss_rpn_box_reg: 0.0866 (0.0776)  time: 0.6274  data: 0.1369  max mem: 10714\n",
      "Training Epoch: [25]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.0718 (6.1998)  loss_classifier: 5.6567 (5.7385)  loss_box_reg: 0.2461 (0.2335)  loss_objectness: 0.1478 (0.1497)  loss_rpn_box_reg: 0.0802 (0.0781)  time: 0.6233  data: 0.1335  max mem: 10714\n",
      "Training Epoch: [25]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.2046 (6.2102)  loss_classifier: 5.7646 (5.7494)  loss_box_reg: 0.2290 (0.2334)  loss_objectness: 0.1403 (0.1494)  loss_rpn_box_reg: 0.0770 (0.0779)  time: 0.6327  data: 0.1331  max mem: 10714\n",
      "Training Epoch: [25]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.2335 (6.2171)  loss_classifier: 5.8495 (5.7562)  loss_box_reg: 0.2290 (0.2341)  loss_objectness: 0.1368 (0.1494)  loss_rpn_box_reg: 0.0594 (0.0773)  time: 0.6283  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [25]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.2277 (6.2131)  loss_classifier: 5.8496 (5.7521)  loss_box_reg: 0.2407 (0.2348)  loss_objectness: 0.1473 (0.1497)  loss_rpn_box_reg: 0.0539 (0.0765)  time: 0.6166  data: 0.1370  max mem: 10714\n",
      "Training Epoch: [25]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.1268 (6.2124)  loss_classifier: 5.8374 (5.7519)  loss_box_reg: 0.2262 (0.2345)  loss_objectness: 0.1498 (0.1494)  loss_rpn_box_reg: 0.0669 (0.0766)  time: 0.6320  data: 0.1356  max mem: 10714\n",
      "Training Epoch: [25]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.1268 (6.2154)  loss_classifier: 5.7371 (5.7549)  loss_box_reg: 0.2218 (0.2340)  loss_objectness: 0.1501 (0.1498)  loss_rpn_box_reg: 0.0776 (0.0766)  time: 0.6289  data: 0.1340  max mem: 10714\n",
      "Training Epoch: [25]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.1318 (6.2119)  loss_classifier: 5.6852 (5.7512)  loss_box_reg: 0.2445 (0.2344)  loss_objectness: 0.1423 (0.1497)  loss_rpn_box_reg: 0.0735 (0.0766)  time: 0.6268  data: 0.1357  max mem: 10714\n",
      "Training Epoch: [25]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.2033 (6.2174)  loss_classifier: 5.7068 (5.7583)  loss_box_reg: 0.2294 (0.2338)  loss_objectness: 0.1423 (0.1494)  loss_rpn_box_reg: 0.0582 (0.0760)  time: 0.6329  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [25]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.2648 (6.2202)  loss_classifier: 5.7505 (5.7616)  loss_box_reg: 0.2220 (0.2335)  loss_objectness: 0.1481 (0.1493)  loss_rpn_box_reg: 0.0574 (0.0758)  time: 0.6355  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [25]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.1411 (6.2179)  loss_classifier: 5.6687 (5.7569)  loss_box_reg: 0.2245 (0.2342)  loss_objectness: 0.1601 (0.1506)  loss_rpn_box_reg: 0.0776 (0.0761)  time: 0.6418  data: 0.1388  max mem: 10714\n",
      "Training Epoch: [25]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.3142 (6.2258)  loss_classifier: 5.8420 (5.7652)  loss_box_reg: 0.2278 (0.2341)  loss_objectness: 0.1577 (0.1505)  loss_rpn_box_reg: 0.0668 (0.0759)  time: 0.6332  data: 0.1381  max mem: 10714\n",
      "Training Epoch: [25]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.1235 (6.2115)  loss_classifier: 5.6936 (5.7511)  loss_box_reg: 0.2147 (0.2338)  loss_objectness: 0.1457 (0.1509)  loss_rpn_box_reg: 0.0593 (0.0757)  time: 0.6167  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [25]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 5.9598 (6.2106)  loss_classifier: 5.4892 (5.7495)  loss_box_reg: 0.2442 (0.2341)  loss_objectness: 0.1562 (0.1511)  loss_rpn_box_reg: 0.0693 (0.0760)  time: 0.6149  data: 0.1333  max mem: 10714\n",
      "Training Epoch: [25]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1428 (6.2089)  loss_classifier: 5.6784 (5.7474)  loss_box_reg: 0.2442 (0.2344)  loss_objectness: 0.1412 (0.1510)  loss_rpn_box_reg: 0.0824 (0.0760)  time: 0.6351  data: 0.1347  max mem: 10714\n",
      "Training Epoch: [25]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.2944 (6.2103)  loss_classifier: 5.8534 (5.7484)  loss_box_reg: 0.2378 (0.2343)  loss_objectness: 0.1436 (0.1517)  loss_rpn_box_reg: 0.0763 (0.0759)  time: 0.6463  data: 0.1366  max mem: 10714\n",
      "Training Epoch: [25]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.0468 (6.2058)  loss_classifier: 5.5279 (5.7434)  loss_box_reg: 0.2428 (0.2347)  loss_objectness: 0.1561 (0.1513)  loss_rpn_box_reg: 0.0772 (0.0763)  time: 0.6302  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [25]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 5.9993 (6.2009)  loss_classifier: 5.5147 (5.7383)  loss_box_reg: 0.2490 (0.2349)  loss_objectness: 0.1460 (0.1514)  loss_rpn_box_reg: 0.0771 (0.0762)  time: 0.6247  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [25]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1360 (6.2034)  loss_classifier: 5.7267 (5.7408)  loss_box_reg: 0.2490 (0.2347)  loss_objectness: 0.1505 (0.1514)  loss_rpn_box_reg: 0.0718 (0.0764)  time: 0.6248  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [25]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1360 (6.2055)  loss_classifier: 5.7329 (5.7425)  loss_box_reg: 0.2258 (0.2347)  loss_objectness: 0.1562 (0.1521)  loss_rpn_box_reg: 0.0718 (0.0762)  time: 0.6239  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [25]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 5.9822 (6.2057)  loss_classifier: 5.5480 (5.7409)  loss_box_reg: 0.2645 (0.2363)  loss_objectness: 0.1692 (0.1525)  loss_rpn_box_reg: 0.0672 (0.0761)  time: 0.6334  data: 0.1364  max mem: 10714\n",
      "Training Epoch: [25]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 6.2603 (6.2104)  loss_classifier: 5.7279 (5.7449)  loss_box_reg: 0.2576 (0.2365)  loss_objectness: 0.1715 (0.1528)  loss_rpn_box_reg: 0.0793 (0.0761)  time: 0.6266  data: 0.1364  max mem: 10714\n",
      "Training Epoch: [25]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.3001 (6.2132)  loss_classifier: 5.8195 (5.7475)  loss_box_reg: 0.2563 (0.2369)  loss_objectness: 0.1634 (0.1529)  loss_rpn_box_reg: 0.0743 (0.0760)  time: 0.6252  data: 0.1368  max mem: 10714\n",
      "Training Epoch: [25]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2807 (6.2132)  loss_classifier: 5.7229 (5.7465)  loss_box_reg: 0.2496 (0.2371)  loss_objectness: 0.1486 (0.1531)  loss_rpn_box_reg: 0.0933 (0.0765)  time: 0.6267  data: 0.1366  max mem: 10714\n",
      "Training Epoch: [25]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.2807 (6.2219)  loss_classifier: 5.6972 (5.7542)  loss_box_reg: 0.2496 (0.2378)  loss_objectness: 0.1421 (0.1532)  loss_rpn_box_reg: 0.0933 (0.0766)  time: 0.6329  data: 0.1379  max mem: 10714\n",
      "Training Epoch: [25]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1966 (6.2205)  loss_classifier: 5.7478 (5.7523)  loss_box_reg: 0.2533 (0.2383)  loss_objectness: 0.1461 (0.1533)  loss_rpn_box_reg: 0.0777 (0.0766)  time: 0.6491  data: 0.1386  max mem: 10714\n",
      "Training Epoch: [25]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 5.9905 (6.2165)  loss_classifier: 5.5563 (5.7480)  loss_box_reg: 0.2415 (0.2388)  loss_objectness: 0.1461 (0.1533)  loss_rpn_box_reg: 0.0650 (0.0764)  time: 0.6376  data: 0.1385  max mem: 10714\n",
      "Training Epoch: [25]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 5.9905 (6.2182)  loss_classifier: 5.5563 (5.7509)  loss_box_reg: 0.2157 (0.2382)  loss_objectness: 0.1407 (0.1530)  loss_rpn_box_reg: 0.0558 (0.0761)  time: 0.6188  data: 0.1367  max mem: 10714\n",
      "Training Epoch: [25]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 5.9523 (6.2111)  loss_classifier: 5.5158 (5.7431)  loss_box_reg: 0.2324 (0.2393)  loss_objectness: 0.1355 (0.1528)  loss_rpn_box_reg: 0.0612 (0.0759)  time: 0.6210  data: 0.1336  max mem: 10714\n",
      "Training Epoch: [25]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0145 (6.2106)  loss_classifier: 5.3711 (5.7431)  loss_box_reg: 0.2408 (0.2389)  loss_objectness: 0.1395 (0.1529)  loss_rpn_box_reg: 0.0636 (0.0757)  time: 0.6152  data: 0.1353  max mem: 10714\n",
      "Training Epoch: [25]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0539 (6.2088)  loss_classifier: 5.5530 (5.7417)  loss_box_reg: 0.2260 (0.2386)  loss_objectness: 0.1466 (0.1528)  loss_rpn_box_reg: 0.0670 (0.0758)  time: 0.6167  data: 0.1359  max mem: 10714\n",
      "Training Epoch: [25]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0878 (6.2100)  loss_classifier: 5.7323 (5.7430)  loss_box_reg: 0.2283 (0.2387)  loss_objectness: 0.1399 (0.1526)  loss_rpn_box_reg: 0.0685 (0.0757)  time: 0.6316  data: 0.1340  max mem: 10714\n",
      "Training Epoch: [25]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2559 (6.2111)  loss_classifier: 5.7505 (5.7434)  loss_box_reg: 0.2593 (0.2390)  loss_objectness: 0.1445 (0.1528)  loss_rpn_box_reg: 0.0700 (0.0759)  time: 0.6229  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [25] Total time: 0:05:13 (0.6272 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:57  model_time: 0.7552 (0.7552)  evaluator_time: 0.0340 (0.0340)  time: 0.9392  data: 0.1410  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4381 (0.4535)  evaluator_time: 0.0340 (0.0348)  time: 0.6348  data: 0.1539  max mem: 10714\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4751 (0.4553)  evaluator_time: 0.0360 (0.0355)  time: 0.6626  data: 0.1544  max mem: 10714\n",
      "Test: Total time: 0:01:20 (0.6446 s / it)\n",
      "Averaged stats: model_time: 0.4751 (0.4553)  evaluator_time: 0.0360 (0.0355)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [25]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1952 (6.1952)  loss_classifier: 5.6432 (5.6432)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1244 (0.1244)  loss_rpn_box_reg: 0.1332 (0.1332)  time: 0.6461  data: 0.1420  max mem: 10714\n",
      "Testing Epoch: [25]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9917 (6.1346)  loss_classifier: 5.4143 (5.6227)  loss_box_reg: 0.2609 (0.2898)  loss_objectness: 0.1364 (0.1316)  loss_rpn_box_reg: 0.0694 (0.0905)  time: 0.5876  data: 0.1465  max mem: 10714\n",
      "Testing Epoch: [25]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1657 (6.1657)  loss_classifier: 5.6837 (5.6582)  loss_box_reg: 0.2500 (0.2851)  loss_objectness: 0.1200 (0.1318)  loss_rpn_box_reg: 0.0745 (0.0905)  time: 0.6007  data: 0.1464  max mem: 10714\n",
      "Testing Epoch: [25] Total time: 0:01:14 (0.5984 s / it)\n",
      "Training Epoch: [26]  [  0/500]  eta: 0:07:32  lr: 0.000000  loss: 6.3724 (6.3724)  loss_classifier: 5.8033 (5.8033)  loss_box_reg: 0.3142 (0.3142)  loss_objectness: 0.1606 (0.1606)  loss_rpn_box_reg: 0.0943 (0.0943)  time: 0.9052  data: 0.1320  max mem: 10714\n",
      "Training Epoch: [26]  [ 10/500]  eta: 0:05:24  lr: 0.000000  loss: 6.3724 (6.4199)  loss_classifier: 5.8858 (5.9821)  loss_box_reg: 0.2156 (0.1957)  loss_objectness: 0.1606 (0.1645)  loss_rpn_box_reg: 0.0840 (0.0776)  time: 0.6612  data: 0.1363  max mem: 10714\n",
      "Training Epoch: [26]  [ 20/500]  eta: 0:05:06  lr: 0.000000  loss: 6.2402 (6.3179)  loss_classifier: 5.8516 (5.8583)  loss_box_reg: 0.2253 (0.2262)  loss_objectness: 0.1511 (0.1555)  loss_rpn_box_reg: 0.0730 (0.0779)  time: 0.6262  data: 0.1348  max mem: 10714\n",
      "Training Epoch: [26]  [ 30/500]  eta: 0:04:58  lr: 0.000000  loss: 6.0875 (6.3000)  loss_classifier: 5.8000 (5.8503)  loss_box_reg: 0.2324 (0.2258)  loss_objectness: 0.1466 (0.1533)  loss_rpn_box_reg: 0.0529 (0.0705)  time: 0.6193  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [26]  [ 40/500]  eta: 0:04:51  lr: 0.000000  loss: 6.2237 (6.2862)  loss_classifier: 5.8423 (5.8381)  loss_box_reg: 0.2221 (0.2246)  loss_objectness: 0.1353 (0.1508)  loss_rpn_box_reg: 0.0622 (0.0728)  time: 0.6276  data: 0.1368  max mem: 10714\n",
      "Training Epoch: [26]  [ 50/500]  eta: 0:04:44  lr: 0.000000  loss: 6.2268 (6.2662)  loss_classifier: 5.8108 (5.8185)  loss_box_reg: 0.2396 (0.2285)  loss_objectness: 0.1328 (0.1481)  loss_rpn_box_reg: 0.0622 (0.0711)  time: 0.6303  data: 0.1375  max mem: 10714\n",
      "Training Epoch: [26]  [ 60/500]  eta: 0:04:35  lr: 0.000000  loss: 6.1887 (6.2468)  loss_classifier: 5.7004 (5.7970)  loss_box_reg: 0.2425 (0.2269)  loss_objectness: 0.1271 (0.1472)  loss_rpn_box_reg: 0.0656 (0.0756)  time: 0.6126  data: 0.1331  max mem: 10714\n",
      "Training Epoch: [26]  [ 70/500]  eta: 0:04:30  lr: 0.000000  loss: 5.9804 (6.2322)  loss_classifier: 5.5552 (5.7828)  loss_box_reg: 0.2345 (0.2257)  loss_objectness: 0.1472 (0.1499)  loss_rpn_box_reg: 0.0694 (0.0738)  time: 0.6209  data: 0.1334  max mem: 10714\n",
      "Training Epoch: [26]  [ 80/500]  eta: 0:04:24  lr: 0.000000  loss: 6.0756 (6.2394)  loss_classifier: 5.7768 (5.7872)  loss_box_reg: 0.2442 (0.2290)  loss_objectness: 0.1472 (0.1495)  loss_rpn_box_reg: 0.0615 (0.0737)  time: 0.6422  data: 0.1363  max mem: 10714\n",
      "Training Epoch: [26]  [ 90/500]  eta: 0:04:18  lr: 0.000000  loss: 6.2690 (6.2265)  loss_classifier: 5.7873 (5.7696)  loss_box_reg: 0.2519 (0.2315)  loss_objectness: 0.1419 (0.1498)  loss_rpn_box_reg: 0.0692 (0.0756)  time: 0.6377  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [26]  [100/500]  eta: 0:04:12  lr: 0.000000  loss: 6.2690 (6.2560)  loss_classifier: 5.7873 (5.8002)  loss_box_reg: 0.2223 (0.2314)  loss_objectness: 0.1465 (0.1496)  loss_rpn_box_reg: 0.0685 (0.0747)  time: 0.6393  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [26]  [110/500]  eta: 0:04:06  lr: 0.000000  loss: 6.2166 (6.2586)  loss_classifier: 5.8559 (5.8055)  loss_box_reg: 0.1944 (0.2288)  loss_objectness: 0.1454 (0.1501)  loss_rpn_box_reg: 0.0602 (0.0742)  time: 0.6413  data: 0.1372  max mem: 10714\n",
      "Training Epoch: [26]  [120/500]  eta: 0:03:59  lr: 0.000000  loss: 6.1526 (6.2334)  loss_classifier: 5.7232 (5.7798)  loss_box_reg: 0.1944 (0.2290)  loss_objectness: 0.1311 (0.1508)  loss_rpn_box_reg: 0.0635 (0.0738)  time: 0.6230  data: 0.1343  max mem: 10714\n",
      "Training Epoch: [26]  [130/500]  eta: 0:03:53  lr: 0.000000  loss: 6.0753 (6.2320)  loss_classifier: 5.4965 (5.7781)  loss_box_reg: 0.2209 (0.2285)  loss_objectness: 0.1558 (0.1523)  loss_rpn_box_reg: 0.0614 (0.0731)  time: 0.6208  data: 0.1339  max mem: 10714\n",
      "Training Epoch: [26]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.2422 (6.2405)  loss_classifier: 5.7736 (5.7839)  loss_box_reg: 0.2252 (0.2295)  loss_objectness: 0.1646 (0.1537)  loss_rpn_box_reg: 0.0614 (0.0735)  time: 0.6211  data: 0.1366  max mem: 10714\n",
      "Training Epoch: [26]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 6.3111 (6.2468)  loss_classifier: 5.7258 (5.7861)  loss_box_reg: 0.2467 (0.2326)  loss_objectness: 0.1616 (0.1539)  loss_rpn_box_reg: 0.0806 (0.0742)  time: 0.6216  data: 0.1374  max mem: 10714\n",
      "Training Epoch: [26]  [160/500]  eta: 0:03:34  lr: 0.000000  loss: 6.2981 (6.2469)  loss_classifier: 5.6709 (5.7870)  loss_box_reg: 0.2532 (0.2316)  loss_objectness: 0.1524 (0.1541)  loss_rpn_box_reg: 0.0718 (0.0743)  time: 0.6405  data: 0.1378  max mem: 10714\n",
      "Training Epoch: [26]  [170/500]  eta: 0:03:28  lr: 0.000000  loss: 6.0447 (6.2377)  loss_classifier: 5.6409 (5.7789)  loss_box_reg: 0.2220 (0.2317)  loss_objectness: 0.1435 (0.1534)  loss_rpn_box_reg: 0.0595 (0.0737)  time: 0.6341  data: 0.1351  max mem: 10714\n",
      "Training Epoch: [26]  [180/500]  eta: 0:03:21  lr: 0.000000  loss: 6.0447 (6.2342)  loss_classifier: 5.5746 (5.7741)  loss_box_reg: 0.2444 (0.2322)  loss_objectness: 0.1446 (0.1536)  loss_rpn_box_reg: 0.0625 (0.0743)  time: 0.6276  data: 0.1342  max mem: 10714\n",
      "Training Epoch: [26]  [190/500]  eta: 0:03:15  lr: 0.000000  loss: 5.9825 (6.2239)  loss_classifier: 5.5381 (5.7635)  loss_box_reg: 0.2400 (0.2322)  loss_objectness: 0.1415 (0.1535)  loss_rpn_box_reg: 0.0647 (0.0748)  time: 0.6340  data: 0.1367  max mem: 10714\n",
      "Training Epoch: [26]  [200/500]  eta: 0:03:09  lr: 0.000000  loss: 6.1121 (6.2262)  loss_classifier: 5.6103 (5.7670)  loss_box_reg: 0.2280 (0.2312)  loss_objectness: 0.1407 (0.1530)  loss_rpn_box_reg: 0.0639 (0.0751)  time: 0.6307  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [26]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.1478 (6.2250)  loss_classifier: 5.6384 (5.7632)  loss_box_reg: 0.2170 (0.2327)  loss_objectness: 0.1474 (0.1537)  loss_rpn_box_reg: 0.0692 (0.0754)  time: 0.6181  data: 0.1352  max mem: 10714\n",
      "Training Epoch: [26]  [220/500]  eta: 0:02:56  lr: 0.000000  loss: 6.1308 (6.2176)  loss_classifier: 5.6240 (5.7554)  loss_box_reg: 0.2387 (0.2337)  loss_objectness: 0.1472 (0.1534)  loss_rpn_box_reg: 0.0698 (0.0751)  time: 0.6188  data: 0.1365  max mem: 10714\n",
      "Training Epoch: [26]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.1023 (6.2151)  loss_classifier: 5.6544 (5.7514)  loss_box_reg: 0.2315 (0.2343)  loss_objectness: 0.1411 (0.1539)  loss_rpn_box_reg: 0.0722 (0.0755)  time: 0.6250  data: 0.1356  max mem: 10714\n",
      "Training Epoch: [26]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.1945 (6.2185)  loss_classifier: 5.7246 (5.7547)  loss_box_reg: 0.2315 (0.2352)  loss_objectness: 0.1580 (0.1537)  loss_rpn_box_reg: 0.0696 (0.0749)  time: 0.6374  data: 0.1358  max mem: 10714\n",
      "Training Epoch: [26]  [250/500]  eta: 0:02:37  lr: 0.000000  loss: 6.1781 (6.2124)  loss_classifier: 5.7246 (5.7487)  loss_box_reg: 0.2322 (0.2352)  loss_objectness: 0.1453 (0.1536)  loss_rpn_box_reg: 0.0685 (0.0749)  time: 0.6419  data: 0.1344  max mem: 10714\n",
      "Training Epoch: [26]  [260/500]  eta: 0:02:31  lr: 0.000000  loss: 6.1337 (6.2083)  loss_classifier: 5.6595 (5.7453)  loss_box_reg: 0.2428 (0.2356)  loss_objectness: 0.1381 (0.1528)  loss_rpn_box_reg: 0.0731 (0.0747)  time: 0.6288  data: 0.1327  max mem: 10714\n",
      "Training Epoch: [26]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.1337 (6.2088)  loss_classifier: 5.6595 (5.7464)  loss_box_reg: 0.2315 (0.2350)  loss_objectness: 0.1290 (0.1528)  loss_rpn_box_reg: 0.0730 (0.0747)  time: 0.6271  data: 0.1337  max mem: 10714\n",
      "Training Epoch: [26]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.3374 (6.2227)  loss_classifier: 5.9081 (5.7608)  loss_box_reg: 0.2270 (0.2346)  loss_objectness: 0.1487 (0.1531)  loss_rpn_box_reg: 0.0663 (0.0743)  time: 0.6226  data: 0.1354  max mem: 10714\n",
      "Training Epoch: [26]  [290/500]  eta: 0:02:12  lr: 0.000000  loss: 6.3374 (6.2235)  loss_classifier: 5.8969 (5.7647)  loss_box_reg: 0.2063 (0.2329)  loss_objectness: 0.1478 (0.1523)  loss_rpn_box_reg: 0.0539 (0.0736)  time: 0.6335  data: 0.1334  max mem: 10714\n",
      "Training Epoch: [26]  [300/500]  eta: 0:02:06  lr: 0.000000  loss: 6.2365 (6.2269)  loss_classifier: 5.8124 (5.7680)  loss_box_reg: 0.2063 (0.2332)  loss_objectness: 0.1411 (0.1523)  loss_rpn_box_reg: 0.0568 (0.0735)  time: 0.6491  data: 0.1327  max mem: 10714\n",
      "Training Epoch: [26]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.0532 (6.2150)  loss_classifier: 5.5825 (5.7547)  loss_box_reg: 0.2595 (0.2343)  loss_objectness: 0.1454 (0.1522)  loss_rpn_box_reg: 0.0707 (0.0738)  time: 0.6261  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [26]  [320/500]  eta: 0:01:53  lr: 0.000000  loss: 5.7745 (6.2074)  loss_classifier: 5.3194 (5.7466)  loss_box_reg: 0.2598 (0.2348)  loss_objectness: 0.1488 (0.1520)  loss_rpn_box_reg: 0.0787 (0.0740)  time: 0.6151  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [26]  [330/500]  eta: 0:01:47  lr: 0.000000  loss: 5.9791 (6.2101)  loss_classifier: 5.6435 (5.7485)  loss_box_reg: 0.2335 (0.2354)  loss_objectness: 0.1532 (0.1521)  loss_rpn_box_reg: 0.0841 (0.0741)  time: 0.6290  data: 0.1360  max mem: 10714\n",
      "Training Epoch: [26]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.0961 (6.2064)  loss_classifier: 5.5833 (5.7454)  loss_box_reg: 0.2187 (0.2351)  loss_objectness: 0.1500 (0.1518)  loss_rpn_box_reg: 0.0717 (0.0742)  time: 0.6332  data: 0.1365  max mem: 10714\n",
      "Training Epoch: [26]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.0875 (6.2059)  loss_classifier: 5.5673 (5.7433)  loss_box_reg: 0.2415 (0.2361)  loss_objectness: 0.1500 (0.1523)  loss_rpn_box_reg: 0.0662 (0.0741)  time: 0.6267  data: 0.1365  max mem: 10714\n",
      "Training Epoch: [26]  [360/500]  eta: 0:01:28  lr: 0.000000  loss: 6.1418 (6.2044)  loss_classifier: 5.7359 (5.7417)  loss_box_reg: 0.2415 (0.2359)  loss_objectness: 0.1603 (0.1523)  loss_rpn_box_reg: 0.0658 (0.0745)  time: 0.6185  data: 0.1383  max mem: 10714\n",
      "Training Epoch: [26]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1931 (6.2098)  loss_classifier: 5.7455 (5.7453)  loss_box_reg: 0.2510 (0.2375)  loss_objectness: 0.1469 (0.1523)  loss_rpn_box_reg: 0.0658 (0.0747)  time: 0.6166  data: 0.1380  max mem: 10714\n",
      "Training Epoch: [26]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.2460 (6.2105)  loss_classifier: 5.7455 (5.7442)  loss_box_reg: 0.2707 (0.2389)  loss_objectness: 0.1518 (0.1526)  loss_rpn_box_reg: 0.0752 (0.0749)  time: 0.6237  data: 0.1367  max mem: 10714\n",
      "Training Epoch: [26]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 5.9458 (6.2048)  loss_classifier: 5.3447 (5.7392)  loss_box_reg: 0.2393 (0.2387)  loss_objectness: 0.1518 (0.1525)  loss_rpn_box_reg: 0.0708 (0.0745)  time: 0.6251  data: 0.1359  max mem: 10714\n",
      "Training Epoch: [26]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 5.9371 (6.2071)  loss_classifier: 5.5377 (5.7412)  loss_box_reg: 0.2265 (0.2388)  loss_objectness: 0.1508 (0.1526)  loss_rpn_box_reg: 0.0632 (0.0745)  time: 0.6276  data: 0.1360  max mem: 10714\n",
      "Training Epoch: [26]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1508 (6.2059)  loss_classifier: 5.6612 (5.7388)  loss_box_reg: 0.2393 (0.2397)  loss_objectness: 0.1640 (0.1528)  loss_rpn_box_reg: 0.0672 (0.0747)  time: 0.6264  data: 0.1363  max mem: 10714\n",
      "Training Epoch: [26]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.0211 (6.1989)  loss_classifier: 5.5089 (5.7307)  loss_box_reg: 0.2750 (0.2401)  loss_objectness: 0.1706 (0.1531)  loss_rpn_box_reg: 0.0733 (0.0749)  time: 0.6217  data: 0.1355  max mem: 10714\n",
      "Training Epoch: [26]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.0656 (6.2032)  loss_classifier: 5.5793 (5.7346)  loss_box_reg: 0.2682 (0.2403)  loss_objectness: 0.1614 (0.1529)  loss_rpn_box_reg: 0.0704 (0.0753)  time: 0.6130  data: 0.1360  max mem: 10714\n",
      "Training Epoch: [26]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1538 (6.2028)  loss_classifier: 5.8690 (5.7357)  loss_box_reg: 0.2004 (0.2391)  loss_objectness: 0.1406 (0.1528)  loss_rpn_box_reg: 0.0668 (0.0752)  time: 0.6115  data: 0.1346  max mem: 10714\n",
      "Training Epoch: [26]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0853 (6.2024)  loss_classifier: 5.6783 (5.7355)  loss_box_reg: 0.2004 (0.2390)  loss_objectness: 0.1406 (0.1526)  loss_rpn_box_reg: 0.0651 (0.0752)  time: 0.6197  data: 0.1330  max mem: 10714\n",
      "Training Epoch: [26]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.2942 (6.2083)  loss_classifier: 5.8306 (5.7410)  loss_box_reg: 0.2501 (0.2394)  loss_objectness: 0.1464 (0.1524)  loss_rpn_box_reg: 0.0754 (0.0755)  time: 0.6273  data: 0.1350  max mem: 10714\n",
      "Training Epoch: [26]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2837 (6.2081)  loss_classifier: 5.7826 (5.7406)  loss_box_reg: 0.2711 (0.2396)  loss_objectness: 0.1462 (0.1525)  loss_rpn_box_reg: 0.0754 (0.0754)  time: 0.6261  data: 0.1349  max mem: 10714\n",
      "Training Epoch: [26]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2837 (6.2138)  loss_classifier: 5.7781 (5.7470)  loss_box_reg: 0.2165 (0.2394)  loss_objectness: 0.1361 (0.1524)  loss_rpn_box_reg: 0.0631 (0.0751)  time: 0.6246  data: 0.1341  max mem: 10714\n",
      "Training Epoch: [26]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.3115 (6.2149)  loss_classifier: 5.8561 (5.7481)  loss_box_reg: 0.2205 (0.2392)  loss_objectness: 0.1304 (0.1522)  loss_rpn_box_reg: 0.0683 (0.0753)  time: 0.6253  data: 0.1352  max mem: 10714\n",
      "Training Epoch: [26]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1969 (6.2164)  loss_classifier: 5.7153 (5.7489)  loss_box_reg: 0.2205 (0.2393)  loss_objectness: 0.1330 (0.1525)  loss_rpn_box_reg: 0.0903 (0.0757)  time: 0.6230  data: 0.1363  max mem: 10714\n",
      "Training Epoch: [26] Total time: 0:05:13 (0.6277 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:46  model_time: 0.6702 (0.6702)  evaluator_time: 0.0350 (0.0350)  time: 0.8542  data: 0.1400  max mem: 10714\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4461 (0.4542)  evaluator_time: 0.0340 (0.0361)  time: 0.6334  data: 0.1476  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4681 (0.4553)  evaluator_time: 0.0360 (0.0366)  time: 0.6534  data: 0.1476  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6440 s / it)\n",
      "Averaged stats: model_time: 0.4681 (0.4553)  evaluator_time: 0.0360 (0.0366)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [26]  [  0/125]  eta: 0:01:22  lr: 0.000000  loss: 6.2067 (6.2067)  loss_classifier: 5.6577 (5.6577)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1229 (0.1229)  loss_rpn_box_reg: 0.1316 (0.1316)  time: 0.6601  data: 0.1410  max mem: 10734\n",
      "Testing Epoch: [26]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0110 (6.1286)  loss_classifier: 5.4492 (5.6198)  loss_box_reg: 0.2609 (0.2884)  loss_objectness: 0.1300 (0.1312)  loss_rpn_box_reg: 0.0715 (0.0892)  time: 0.5888  data: 0.1481  max mem: 10734\n",
      "Testing Epoch: [26]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1771 (6.1611)  loss_classifier: 5.6888 (5.6565)  loss_box_reg: 0.2500 (0.2840)  loss_objectness: 0.1181 (0.1313)  loss_rpn_box_reg: 0.0745 (0.0894)  time: 0.6013  data: 0.1456  max mem: 10734\n",
      "Testing Epoch: [26] Total time: 0:01:14 (0.5997 s / it)\n",
      "Training Epoch: [27]  [  0/500]  eta: 0:07:27  lr: 0.000000  loss: 6.8230 (6.8230)  loss_classifier: 6.4396 (6.4396)  loss_box_reg: 0.2265 (0.2265)  loss_objectness: 0.1196 (0.1196)  loss_rpn_box_reg: 0.0373 (0.0373)  time: 0.8942  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [27]  [ 10/500]  eta: 0:05:12  lr: 0.000000  loss: 6.4120 (6.2828)  loss_classifier: 5.8457 (5.8169)  loss_box_reg: 0.2261 (0.2385)  loss_objectness: 0.1311 (0.1481)  loss_rpn_box_reg: 0.0718 (0.0792)  time: 0.6373  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [27]  [ 20/500]  eta: 0:05:00  lr: 0.000000  loss: 6.3044 (6.3003)  loss_classifier: 5.8457 (5.8439)  loss_box_reg: 0.2227 (0.2326)  loss_objectness: 0.1356 (0.1469)  loss_rpn_box_reg: 0.0731 (0.0769)  time: 0.6117  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [27]  [ 30/500]  eta: 0:04:53  lr: 0.000000  loss: 6.3044 (6.2524)  loss_classifier: 5.6409 (5.7798)  loss_box_reg: 0.2390 (0.2392)  loss_objectness: 0.1428 (0.1531)  loss_rpn_box_reg: 0.0787 (0.0804)  time: 0.6183  data: 0.1379  max mem: 10734\n",
      "Training Epoch: [27]  [ 40/500]  eta: 0:04:48  lr: 0.000000  loss: 6.0410 (6.2056)  loss_classifier: 5.5335 (5.7308)  loss_box_reg: 0.2390 (0.2432)  loss_objectness: 0.1476 (0.1527)  loss_rpn_box_reg: 0.0749 (0.0790)  time: 0.6297  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [27]  [ 50/500]  eta: 0:04:39  lr: 0.000000  loss: 6.2445 (6.2500)  loss_classifier: 5.7377 (5.7730)  loss_box_reg: 0.2269 (0.2440)  loss_objectness: 0.1532 (0.1553)  loss_rpn_box_reg: 0.0706 (0.0776)  time: 0.6165  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [27]  [ 60/500]  eta: 0:04:33  lr: 0.000000  loss: 6.2773 (6.2745)  loss_classifier: 5.8618 (5.8061)  loss_box_reg: 0.2269 (0.2410)  loss_objectness: 0.1544 (0.1538)  loss_rpn_box_reg: 0.0565 (0.0736)  time: 0.6099  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [27]  [ 70/500]  eta: 0:04:27  lr: 0.000000  loss: 6.2156 (6.2708)  loss_classifier: 5.7740 (5.8027)  loss_box_reg: 0.2205 (0.2379)  loss_objectness: 0.1436 (0.1561)  loss_rpn_box_reg: 0.0618 (0.0741)  time: 0.6236  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [27]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 6.2384 (6.2615)  loss_classifier: 5.8256 (5.7964)  loss_box_reg: 0.2269 (0.2367)  loss_objectness: 0.1436 (0.1549)  loss_rpn_box_reg: 0.0654 (0.0735)  time: 0.6412  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [27]  [ 90/500]  eta: 0:04:16  lr: 0.000000  loss: 6.1555 (6.2548)  loss_classifier: 5.6814 (5.7858)  loss_box_reg: 0.2360 (0.2401)  loss_objectness: 0.1522 (0.1561)  loss_rpn_box_reg: 0.0602 (0.0728)  time: 0.6352  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [27]  [100/500]  eta: 0:04:09  lr: 0.000000  loss: 6.1310 (6.2349)  loss_classifier: 5.6188 (5.7630)  loss_box_reg: 0.2487 (0.2416)  loss_objectness: 0.1636 (0.1579)  loss_rpn_box_reg: 0.0577 (0.0724)  time: 0.6068  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [27]  [110/500]  eta: 0:04:02  lr: 0.000000  loss: 6.2716 (6.2472)  loss_classifier: 5.8149 (5.7776)  loss_box_reg: 0.2362 (0.2398)  loss_objectness: 0.1541 (0.1579)  loss_rpn_box_reg: 0.0601 (0.0718)  time: 0.6061  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [27]  [120/500]  eta: 0:03:56  lr: 0.000000  loss: 6.3817 (6.2531)  loss_classifier: 5.9037 (5.7795)  loss_box_reg: 0.2338 (0.2408)  loss_objectness: 0.1562 (0.1596)  loss_rpn_box_reg: 0.0725 (0.0731)  time: 0.6165  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [27]  [130/500]  eta: 0:03:50  lr: 0.000000  loss: 6.3073 (6.2615)  loss_classifier: 5.8890 (5.7881)  loss_box_reg: 0.2338 (0.2411)  loss_objectness: 0.1559 (0.1585)  loss_rpn_box_reg: 0.0738 (0.0737)  time: 0.6227  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [27]  [140/500]  eta: 0:03:43  lr: 0.000000  loss: 6.3335 (6.2631)  loss_classifier: 5.8936 (5.7890)  loss_box_reg: 0.2390 (0.2405)  loss_objectness: 0.1559 (0.1592)  loss_rpn_box_reg: 0.0734 (0.0744)  time: 0.6149  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [27]  [150/500]  eta: 0:03:37  lr: 0.000000  loss: 6.2090 (6.2604)  loss_classifier: 5.8200 (5.7843)  loss_box_reg: 0.2390 (0.2421)  loss_objectness: 0.1568 (0.1596)  loss_rpn_box_reg: 0.0734 (0.0744)  time: 0.6215  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [27]  [160/500]  eta: 0:03:31  lr: 0.000000  loss: 6.0007 (6.2497)  loss_classifier: 5.6068 (5.7762)  loss_box_reg: 0.2167 (0.2412)  loss_objectness: 0.1448 (0.1584)  loss_rpn_box_reg: 0.0622 (0.0739)  time: 0.6351  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [27]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 5.9999 (6.2395)  loss_classifier: 5.5878 (5.7658)  loss_box_reg: 0.2130 (0.2411)  loss_objectness: 0.1453 (0.1579)  loss_rpn_box_reg: 0.0576 (0.0747)  time: 0.6254  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [27]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.0447 (6.2263)  loss_classifier: 5.5878 (5.7536)  loss_box_reg: 0.2117 (0.2402)  loss_objectness: 0.1550 (0.1582)  loss_rpn_box_reg: 0.0724 (0.0743)  time: 0.6246  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [27]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.1473 (6.2150)  loss_classifier: 5.6574 (5.7424)  loss_box_reg: 0.2191 (0.2414)  loss_objectness: 0.1444 (0.1568)  loss_rpn_box_reg: 0.0704 (0.0744)  time: 0.6271  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [27]  [200/500]  eta: 0:03:06  lr: 0.000000  loss: 6.1444 (6.2170)  loss_classifier: 5.6020 (5.7434)  loss_box_reg: 0.2391 (0.2418)  loss_objectness: 0.1354 (0.1574)  loss_rpn_box_reg: 0.0684 (0.0744)  time: 0.6186  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [27]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.2294 (6.2252)  loss_classifier: 5.7616 (5.7520)  loss_box_reg: 0.2334 (0.2411)  loss_objectness: 0.1457 (0.1569)  loss_rpn_box_reg: 0.0847 (0.0752)  time: 0.6271  data: 0.1370  max mem: 10734\n",
      "Training Epoch: [27]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.3300 (6.2303)  loss_classifier: 5.8945 (5.7574)  loss_box_reg: 0.2493 (0.2413)  loss_objectness: 0.1425 (0.1568)  loss_rpn_box_reg: 0.0773 (0.0748)  time: 0.6295  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [27]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.2904 (6.2346)  loss_classifier: 5.7855 (5.7628)  loss_box_reg: 0.2493 (0.2410)  loss_objectness: 0.1364 (0.1564)  loss_rpn_box_reg: 0.0456 (0.0745)  time: 0.6236  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [27]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.2315 (6.2359)  loss_classifier: 5.7751 (5.7635)  loss_box_reg: 0.2372 (0.2412)  loss_objectness: 0.1368 (0.1562)  loss_rpn_box_reg: 0.0727 (0.0751)  time: 0.6312  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [27]  [250/500]  eta: 0:02:35  lr: 0.000000  loss: 6.0570 (6.2317)  loss_classifier: 5.6624 (5.7576)  loss_box_reg: 0.2444 (0.2418)  loss_objectness: 0.1596 (0.1568)  loss_rpn_box_reg: 0.0844 (0.0755)  time: 0.6234  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [27]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 5.9919 (6.2272)  loss_classifier: 5.5363 (5.7541)  loss_box_reg: 0.2249 (0.2411)  loss_objectness: 0.1604 (0.1565)  loss_rpn_box_reg: 0.0797 (0.0754)  time: 0.6327  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [27]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.0674 (6.2230)  loss_classifier: 5.5418 (5.7478)  loss_box_reg: 0.2425 (0.2418)  loss_objectness: 0.1604 (0.1578)  loss_rpn_box_reg: 0.0610 (0.0755)  time: 0.6324  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [27]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.1543 (6.2193)  loss_classifier: 5.6258 (5.7450)  loss_box_reg: 0.2358 (0.2408)  loss_objectness: 0.1545 (0.1579)  loss_rpn_box_reg: 0.0731 (0.0756)  time: 0.6253  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [27]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.2251 (6.2227)  loss_classifier: 5.7667 (5.7480)  loss_box_reg: 0.2221 (0.2408)  loss_objectness: 0.1464 (0.1583)  loss_rpn_box_reg: 0.0714 (0.0756)  time: 0.6334  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [27]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.1007 (6.2203)  loss_classifier: 5.6648 (5.7474)  loss_box_reg: 0.2051 (0.2397)  loss_objectness: 0.1486 (0.1580)  loss_rpn_box_reg: 0.0684 (0.0751)  time: 0.6265  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [27]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.1007 (6.2232)  loss_classifier: 5.6648 (5.7501)  loss_box_reg: 0.2051 (0.2398)  loss_objectness: 0.1410 (0.1577)  loss_rpn_box_reg: 0.0684 (0.0755)  time: 0.6242  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [27]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2614 (6.2220)  loss_classifier: 5.6728 (5.7484)  loss_box_reg: 0.2520 (0.2405)  loss_objectness: 0.1460 (0.1572)  loss_rpn_box_reg: 0.0704 (0.0760)  time: 0.6340  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [27]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 5.9927 (6.2142)  loss_classifier: 5.5797 (5.7421)  loss_box_reg: 0.2520 (0.2401)  loss_objectness: 0.1334 (0.1563)  loss_rpn_box_reg: 0.0686 (0.0757)  time: 0.6460  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [27]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.1127 (6.2169)  loss_classifier: 5.6020 (5.7447)  loss_box_reg: 0.2059 (0.2400)  loss_objectness: 0.1370 (0.1563)  loss_rpn_box_reg: 0.0722 (0.0759)  time: 0.6363  data: 0.1379  max mem: 10734\n",
      "Training Epoch: [27]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.1881 (6.2160)  loss_classifier: 5.7281 (5.7435)  loss_box_reg: 0.2059 (0.2400)  loss_objectness: 0.1528 (0.1563)  loss_rpn_box_reg: 0.0785 (0.0763)  time: 0.6332  data: 0.1385  max mem: 10734\n",
      "Training Epoch: [27]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.0442 (6.2086)  loss_classifier: 5.6054 (5.7372)  loss_box_reg: 0.2242 (0.2392)  loss_objectness: 0.1506 (0.1559)  loss_rpn_box_reg: 0.0822 (0.0763)  time: 0.6293  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [27]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1748 (6.2113)  loss_classifier: 5.7598 (5.7411)  loss_box_reg: 0.2039 (0.2387)  loss_objectness: 0.1248 (0.1554)  loss_rpn_box_reg: 0.0822 (0.0761)  time: 0.6110  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [27]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.2022 (6.2093)  loss_classifier: 5.7598 (5.7390)  loss_box_reg: 0.2163 (0.2386)  loss_objectness: 0.1444 (0.1554)  loss_rpn_box_reg: 0.0779 (0.0763)  time: 0.6018  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [27]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1271 (6.2101)  loss_classifier: 5.6390 (5.7409)  loss_box_reg: 0.2163 (0.2380)  loss_objectness: 0.1344 (0.1549)  loss_rpn_box_reg: 0.0805 (0.0763)  time: 0.6087  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [27]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1271 (6.2073)  loss_classifier: 5.6953 (5.7378)  loss_box_reg: 0.2256 (0.2381)  loss_objectness: 0.1311 (0.1552)  loss_rpn_box_reg: 0.0714 (0.0761)  time: 0.6173  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [27]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2470 (6.2144)  loss_classifier: 5.8240 (5.7457)  loss_box_reg: 0.2256 (0.2374)  loss_objectness: 0.1473 (0.1551)  loss_rpn_box_reg: 0.0642 (0.0762)  time: 0.6122  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [27]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.2772 (6.2118)  loss_classifier: 5.8422 (5.7440)  loss_box_reg: 0.2045 (0.2368)  loss_objectness: 0.1501 (0.1551)  loss_rpn_box_reg: 0.0501 (0.0759)  time: 0.6253  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [27]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2889 (6.2139)  loss_classifier: 5.8475 (5.7461)  loss_box_reg: 0.2219 (0.2367)  loss_objectness: 0.1501 (0.1549)  loss_rpn_box_reg: 0.0713 (0.0762)  time: 0.6297  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [27]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2889 (6.2112)  loss_classifier: 5.8475 (5.7437)  loss_box_reg: 0.2219 (0.2367)  loss_objectness: 0.1384 (0.1547)  loss_rpn_box_reg: 0.0796 (0.0761)  time: 0.6227  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [27]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.3058 (6.2145)  loss_classifier: 5.8031 (5.7462)  loss_box_reg: 0.2371 (0.2372)  loss_objectness: 0.1414 (0.1548)  loss_rpn_box_reg: 0.0685 (0.0763)  time: 0.6385  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [27]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.3242 (6.2174)  loss_classifier: 5.9188 (5.7498)  loss_box_reg: 0.2371 (0.2370)  loss_objectness: 0.1497 (0.1547)  loss_rpn_box_reg: 0.0605 (0.0760)  time: 0.6482  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [27]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 5.9836 (6.2123)  loss_classifier: 5.5741 (5.7444)  loss_box_reg: 0.2048 (0.2369)  loss_objectness: 0.1497 (0.1548)  loss_rpn_box_reg: 0.0721 (0.0763)  time: 0.6343  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [27]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 5.9696 (6.2129)  loss_classifier: 5.5741 (5.7449)  loss_box_reg: 0.2407 (0.2369)  loss_objectness: 0.1563 (0.1549)  loss_rpn_box_reg: 0.0723 (0.0762)  time: 0.6293  data: 0.1374  max mem: 10734\n",
      "Training Epoch: [27]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.3791 (6.2166)  loss_classifier: 5.8940 (5.7479)  loss_box_reg: 0.2407 (0.2370)  loss_objectness: 0.1559 (0.1552)  loss_rpn_box_reg: 0.0708 (0.0764)  time: 0.6326  data: 0.1377  max mem: 10734\n",
      "Training Epoch: [27]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.3791 (6.2197)  loss_classifier: 5.8908 (5.7512)  loss_box_reg: 0.2286 (0.2371)  loss_objectness: 0.1496 (0.1553)  loss_rpn_box_reg: 0.0677 (0.0761)  time: 0.6280  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [27] Total time: 0:05:12 (0.6256 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:05  model_time: 0.7342 (0.7342)  evaluator_time: 0.0340 (0.0340)  time: 1.0032  data: 0.2261  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4491 (0.4539)  evaluator_time: 0.0330 (0.0340)  time: 0.6344  data: 0.1480  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4751 (0.4554)  evaluator_time: 0.0350 (0.0349)  time: 0.6547  data: 0.1474  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6446 s / it)\n",
      "Averaged stats: model_time: 0.4751 (0.4554)  evaluator_time: 0.0350 (0.0349)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [27]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.2002 (6.2002)  loss_classifier: 5.6502 (5.6502)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1222 (0.1222)  loss_rpn_box_reg: 0.1332 (0.1332)  time: 0.6441  data: 0.1420  max mem: 10734\n",
      "Testing Epoch: [27]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0142 (6.1403)  loss_classifier: 5.4343 (5.6291)  loss_box_reg: 0.2609 (0.2892)  loss_objectness: 0.1283 (0.1316)  loss_rpn_box_reg: 0.0718 (0.0903)  time: 0.5866  data: 0.1448  max mem: 10734\n",
      "Testing Epoch: [27]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1504 (6.1707)  loss_classifier: 5.6904 (5.6639)  loss_box_reg: 0.2500 (0.2847)  loss_objectness: 0.1215 (0.1318)  loss_rpn_box_reg: 0.0745 (0.0903)  time: 0.6014  data: 0.1451  max mem: 10734\n",
      "Testing Epoch: [27] Total time: 0:01:14 (0.5978 s / it)\n",
      "Training Epoch: [28]  [  0/500]  eta: 0:07:25  lr: 0.000000  loss: 5.9290 (5.9290)  loss_classifier: 5.3068 (5.3068)  loss_box_reg: 0.3717 (0.3717)  loss_objectness: 0.0802 (0.0802)  loss_rpn_box_reg: 0.1704 (0.1704)  time: 0.8912  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [28]  [ 10/500]  eta: 0:05:21  lr: 0.000000  loss: 5.9290 (6.0999)  loss_classifier: 5.5157 (5.6570)  loss_box_reg: 0.2219 (0.2302)  loss_objectness: 0.1409 (0.1422)  loss_rpn_box_reg: 0.0539 (0.0705)  time: 0.6567  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [28]  [ 20/500]  eta: 0:05:09  lr: 0.000000  loss: 5.9228 (6.1536)  loss_classifier: 5.5756 (5.6948)  loss_box_reg: 0.2219 (0.2455)  loss_objectness: 0.1394 (0.1392)  loss_rpn_box_reg: 0.0539 (0.0742)  time: 0.6334  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [28]  [ 30/500]  eta: 0:05:02  lr: 0.000000  loss: 6.1164 (6.1584)  loss_classifier: 5.6111 (5.7012)  loss_box_reg: 0.2540 (0.2401)  loss_objectness: 0.1332 (0.1404)  loss_rpn_box_reg: 0.0855 (0.0768)  time: 0.6374  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [28]  [ 40/500]  eta: 0:04:56  lr: 0.000000  loss: 6.0759 (6.1569)  loss_classifier: 5.5978 (5.6950)  loss_box_reg: 0.2293 (0.2364)  loss_objectness: 0.1493 (0.1472)  loss_rpn_box_reg: 0.0855 (0.0782)  time: 0.6430  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [28]  [ 50/500]  eta: 0:04:49  lr: 0.000000  loss: 6.1885 (6.1847)  loss_classifier: 5.7248 (5.7182)  loss_box_reg: 0.2293 (0.2376)  loss_objectness: 0.1699 (0.1524)  loss_rpn_box_reg: 0.0634 (0.0766)  time: 0.6404  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [28]  [ 60/500]  eta: 0:04:41  lr: 0.000000  loss: 6.3953 (6.2429)  loss_classifier: 5.9158 (5.7749)  loss_box_reg: 0.2410 (0.2403)  loss_objectness: 0.1543 (0.1526)  loss_rpn_box_reg: 0.0675 (0.0751)  time: 0.6320  data: 0.1381  max mem: 10734\n",
      "Training Epoch: [28]  [ 70/500]  eta: 0:04:34  lr: 0.000000  loss: 6.4175 (6.2377)  loss_classifier: 5.9158 (5.7690)  loss_box_reg: 0.2601 (0.2442)  loss_objectness: 0.1467 (0.1522)  loss_rpn_box_reg: 0.0632 (0.0724)  time: 0.6280  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [28]  [ 80/500]  eta: 0:04:28  lr: 0.000000  loss: 6.1980 (6.2372)  loss_classifier: 5.7335 (5.7699)  loss_box_reg: 0.2592 (0.2444)  loss_objectness: 0.1467 (0.1512)  loss_rpn_box_reg: 0.0515 (0.0717)  time: 0.6319  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [28]  [ 90/500]  eta: 0:04:21  lr: 0.000000  loss: 6.1640 (6.2414)  loss_classifier: 5.7338 (5.7730)  loss_box_reg: 0.2449 (0.2448)  loss_objectness: 0.1386 (0.1509)  loss_rpn_box_reg: 0.0696 (0.0727)  time: 0.6329  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [28]  [100/500]  eta: 0:04:14  lr: 0.000000  loss: 6.4145 (6.2563)  loss_classifier: 5.8375 (5.7821)  loss_box_reg: 0.2483 (0.2478)  loss_objectness: 0.1465 (0.1517)  loss_rpn_box_reg: 0.0860 (0.0746)  time: 0.6253  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [28]  [110/500]  eta: 0:04:07  lr: 0.000000  loss: 6.2590 (6.2388)  loss_classifier: 5.6560 (5.7598)  loss_box_reg: 0.2431 (0.2486)  loss_objectness: 0.1680 (0.1548)  loss_rpn_box_reg: 0.0801 (0.0756)  time: 0.6230  data: 0.1382  max mem: 10734\n",
      "Training Epoch: [28]  [120/500]  eta: 0:04:01  lr: 0.000000  loss: 6.0560 (6.2342)  loss_classifier: 5.6322 (5.7625)  loss_box_reg: 0.2024 (0.2436)  loss_objectness: 0.1601 (0.1540)  loss_rpn_box_reg: 0.0693 (0.0741)  time: 0.6274  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [28]  [130/500]  eta: 0:03:54  lr: 0.000000  loss: 6.0560 (6.2212)  loss_classifier: 5.6322 (5.7503)  loss_box_reg: 0.1944 (0.2430)  loss_objectness: 0.1434 (0.1535)  loss_rpn_box_reg: 0.0569 (0.0744)  time: 0.6295  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [28]  [140/500]  eta: 0:03:47  lr: 0.000000  loss: 6.0435 (6.2249)  loss_classifier: 5.5872 (5.7535)  loss_box_reg: 0.2248 (0.2433)  loss_objectness: 0.1427 (0.1527)  loss_rpn_box_reg: 0.0779 (0.0754)  time: 0.6270  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [28]  [150/500]  eta: 0:03:41  lr: 0.000000  loss: 6.1352 (6.2317)  loss_classifier: 5.7682 (5.7636)  loss_box_reg: 0.2234 (0.2407)  loss_objectness: 0.1427 (0.1528)  loss_rpn_box_reg: 0.0631 (0.0746)  time: 0.6319  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [28]  [160/500]  eta: 0:03:35  lr: 0.000000  loss: 6.1706 (6.2305)  loss_classifier: 5.7884 (5.7634)  loss_box_reg: 0.2038 (0.2391)  loss_objectness: 0.1444 (0.1526)  loss_rpn_box_reg: 0.0671 (0.0754)  time: 0.6368  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [28]  [170/500]  eta: 0:03:29  lr: 0.000000  loss: 5.9820 (6.2067)  loss_classifier: 5.5396 (5.7377)  loss_box_reg: 0.2229 (0.2394)  loss_objectness: 0.1614 (0.1535)  loss_rpn_box_reg: 0.0769 (0.0761)  time: 0.6441  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [28]  [180/500]  eta: 0:03:23  lr: 0.000000  loss: 6.0053 (6.2292)  loss_classifier: 5.6280 (5.7599)  loss_box_reg: 0.2341 (0.2392)  loss_objectness: 0.1732 (0.1547)  loss_rpn_box_reg: 0.0745 (0.0755)  time: 0.6433  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [28]  [190/500]  eta: 0:03:16  lr: 0.000000  loss: 6.4562 (6.2330)  loss_classifier: 6.0293 (5.7606)  loss_box_reg: 0.2535 (0.2408)  loss_objectness: 0.1683 (0.1552)  loss_rpn_box_reg: 0.0723 (0.0764)  time: 0.6273  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [28]  [200/500]  eta: 0:03:10  lr: 0.000000  loss: 6.2592 (6.2385)  loss_classifier: 5.7463 (5.7657)  loss_box_reg: 0.2549 (0.2414)  loss_objectness: 0.1449 (0.1548)  loss_rpn_box_reg: 0.0723 (0.0766)  time: 0.6277  data: 0.1376  max mem: 10734\n",
      "Training Epoch: [28]  [210/500]  eta: 0:03:03  lr: 0.000000  loss: 6.0852 (6.2336)  loss_classifier: 5.6311 (5.7575)  loss_box_reg: 0.2761 (0.2432)  loss_objectness: 0.1460 (0.1553)  loss_rpn_box_reg: 0.0825 (0.0775)  time: 0.6167  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [28]  [220/500]  eta: 0:02:57  lr: 0.000000  loss: 6.0469 (6.2294)  loss_classifier: 5.4945 (5.7553)  loss_box_reg: 0.2535 (0.2416)  loss_objectness: 0.1460 (0.1553)  loss_rpn_box_reg: 0.0801 (0.0772)  time: 0.6138  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [28]  [230/500]  eta: 0:02:50  lr: 0.000000  loss: 5.9550 (6.2285)  loss_classifier: 5.5649 (5.7552)  loss_box_reg: 0.2099 (0.2404)  loss_objectness: 0.1410 (0.1546)  loss_rpn_box_reg: 0.0732 (0.0784)  time: 0.6281  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [28]  [240/500]  eta: 0:02:44  lr: 0.000000  loss: 6.1226 (6.2194)  loss_classifier: 5.6169 (5.7440)  loss_box_reg: 0.2231 (0.2408)  loss_objectness: 0.1544 (0.1554)  loss_rpn_box_reg: 0.0713 (0.0791)  time: 0.6161  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [28]  [250/500]  eta: 0:02:37  lr: 0.000000  loss: 5.9345 (6.2105)  loss_classifier: 5.4891 (5.7341)  loss_box_reg: 0.2485 (0.2411)  loss_objectness: 0.1712 (0.1562)  loss_rpn_box_reg: 0.0713 (0.0791)  time: 0.6126  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [28]  [260/500]  eta: 0:02:31  lr: 0.000000  loss: 6.1330 (6.2075)  loss_classifier: 5.6004 (5.7325)  loss_box_reg: 0.2233 (0.2413)  loss_objectness: 0.1528 (0.1552)  loss_rpn_box_reg: 0.0649 (0.0784)  time: 0.6301  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [28]  [270/500]  eta: 0:02:25  lr: 0.000000  loss: 6.1970 (6.2126)  loss_classifier: 5.6381 (5.7385)  loss_box_reg: 0.2233 (0.2411)  loss_objectness: 0.1407 (0.1551)  loss_rpn_box_reg: 0.0560 (0.0779)  time: 0.6358  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [28]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.2199 (6.2135)  loss_classifier: 5.8495 (5.7398)  loss_box_reg: 0.2277 (0.2410)  loss_objectness: 0.1463 (0.1549)  loss_rpn_box_reg: 0.0560 (0.0778)  time: 0.6430  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [28]  [290/500]  eta: 0:02:12  lr: 0.000000  loss: 6.0798 (6.2154)  loss_classifier: 5.7173 (5.7405)  loss_box_reg: 0.2377 (0.2415)  loss_objectness: 0.1501 (0.1554)  loss_rpn_box_reg: 0.0667 (0.0780)  time: 0.6470  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [28]  [300/500]  eta: 0:02:06  lr: 0.000000  loss: 6.0798 (6.2188)  loss_classifier: 5.7173 (5.7428)  loss_box_reg: 0.2439 (0.2420)  loss_objectness: 0.1643 (0.1553)  loss_rpn_box_reg: 0.0745 (0.0787)  time: 0.6416  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [28]  [310/500]  eta: 0:02:00  lr: 0.000000  loss: 6.1473 (6.2177)  loss_classifier: 5.6843 (5.7416)  loss_box_reg: 0.2387 (0.2422)  loss_objectness: 0.1438 (0.1550)  loss_rpn_box_reg: 0.0753 (0.0789)  time: 0.6322  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [28]  [320/500]  eta: 0:01:53  lr: 0.000000  loss: 6.0213 (6.2144)  loss_classifier: 5.6298 (5.7389)  loss_box_reg: 0.2343 (0.2415)  loss_objectness: 0.1452 (0.1551)  loss_rpn_box_reg: 0.0791 (0.0790)  time: 0.6200  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [28]  [330/500]  eta: 0:01:47  lr: 0.000000  loss: 6.0456 (6.2156)  loss_classifier: 5.5840 (5.7404)  loss_box_reg: 0.2263 (0.2410)  loss_objectness: 0.1556 (0.1553)  loss_rpn_box_reg: 0.0724 (0.0789)  time: 0.6270  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [28]  [340/500]  eta: 0:01:41  lr: 0.000000  loss: 6.1682 (6.2225)  loss_classifier: 5.7072 (5.7483)  loss_box_reg: 0.2200 (0.2403)  loss_objectness: 0.1635 (0.1554)  loss_rpn_box_reg: 0.0680 (0.0785)  time: 0.6267  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [28]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.2971 (6.2248)  loss_classifier: 5.9424 (5.7518)  loss_box_reg: 0.2142 (0.2398)  loss_objectness: 0.1441 (0.1549)  loss_rpn_box_reg: 0.0571 (0.0784)  time: 0.6134  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [28]  [360/500]  eta: 0:01:28  lr: 0.000000  loss: 6.0461 (6.2174)  loss_classifier: 5.5505 (5.7443)  loss_box_reg: 0.2205 (0.2400)  loss_objectness: 0.1396 (0.1548)  loss_rpn_box_reg: 0.0544 (0.0783)  time: 0.6018  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [28]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 5.9344 (6.2136)  loss_classifier: 5.5001 (5.7422)  loss_box_reg: 0.2199 (0.2394)  loss_objectness: 0.1371 (0.1544)  loss_rpn_box_reg: 0.0544 (0.0776)  time: 0.6092  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [28]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1706 (6.2155)  loss_classifier: 5.7487 (5.7432)  loss_box_reg: 0.2376 (0.2406)  loss_objectness: 0.1409 (0.1540)  loss_rpn_box_reg: 0.0635 (0.0776)  time: 0.6134  data: 0.1308  max mem: 10734\n",
      "Training Epoch: [28]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 6.2345 (6.2206)  loss_classifier: 5.7648 (5.7485)  loss_box_reg: 0.2358 (0.2407)  loss_objectness: 0.1409 (0.1539)  loss_rpn_box_reg: 0.0723 (0.0775)  time: 0.6161  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [28]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1531 (6.2212)  loss_classifier: 5.6744 (5.7477)  loss_box_reg: 0.2358 (0.2415)  loss_objectness: 0.1436 (0.1542)  loss_rpn_box_reg: 0.0726 (0.0779)  time: 0.6216  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [28]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1591 (6.2232)  loss_classifier: 5.6885 (5.7502)  loss_box_reg: 0.2398 (0.2409)  loss_objectness: 0.1531 (0.1541)  loss_rpn_box_reg: 0.0719 (0.0779)  time: 0.6172  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [28]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.1596 (6.2211)  loss_classifier: 5.7484 (5.7498)  loss_box_reg: 0.2124 (0.2402)  loss_objectness: 0.1283 (0.1538)  loss_rpn_box_reg: 0.0606 (0.0774)  time: 0.6202  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [28]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1003 (6.2240)  loss_classifier: 5.5551 (5.7527)  loss_box_reg: 0.2290 (0.2406)  loss_objectness: 0.1511 (0.1537)  loss_rpn_box_reg: 0.0572 (0.0770)  time: 0.6182  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [28]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1333 (6.2212)  loss_classifier: 5.6156 (5.7505)  loss_box_reg: 0.2433 (0.2405)  loss_objectness: 0.1384 (0.1534)  loss_rpn_box_reg: 0.0655 (0.0768)  time: 0.6248  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [28]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1290 (6.2182)  loss_classifier: 5.6156 (5.7490)  loss_box_reg: 0.1890 (0.2396)  loss_objectness: 0.1377 (0.1532)  loss_rpn_box_reg: 0.0656 (0.0764)  time: 0.6363  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [28]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0825 (6.2148)  loss_classifier: 5.6049 (5.7466)  loss_box_reg: 0.1922 (0.2391)  loss_objectness: 0.1377 (0.1530)  loss_rpn_box_reg: 0.0586 (0.0760)  time: 0.6276  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [28]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0825 (6.2144)  loss_classifier: 5.6132 (5.7461)  loss_box_reg: 0.2439 (0.2393)  loss_objectness: 0.1422 (0.1531)  loss_rpn_box_reg: 0.0639 (0.0759)  time: 0.6124  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [28]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0261 (6.2108)  loss_classifier: 5.6132 (5.7436)  loss_box_reg: 0.2170 (0.2386)  loss_objectness: 0.1425 (0.1528)  loss_rpn_box_reg: 0.0659 (0.0759)  time: 0.6182  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [28]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.2428 (6.2151)  loss_classifier: 5.8237 (5.7477)  loss_box_reg: 0.2128 (0.2387)  loss_objectness: 0.1478 (0.1529)  loss_rpn_box_reg: 0.0643 (0.0758)  time: 0.6202  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [28]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2963 (6.2158)  loss_classifier: 5.8893 (5.7480)  loss_box_reg: 0.2228 (0.2388)  loss_objectness: 0.1563 (0.1530)  loss_rpn_box_reg: 0.0782 (0.0761)  time: 0.6175  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [28] Total time: 0:05:13 (0.6273 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:13  model_time: 0.7962 (0.7962)  evaluator_time: 0.0340 (0.0340)  time: 1.0682  data: 0.2281  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4421 (0.4546)  evaluator_time: 0.0340 (0.0351)  time: 0.6356  data: 0.1482  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4741 (0.4563)  evaluator_time: 0.0350 (0.0358)  time: 0.6564  data: 0.1478  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6455 s / it)\n",
      "Averaged stats: model_time: 0.4741 (0.4563)  evaluator_time: 0.0350 (0.0358)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [28]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1968 (6.1968)  loss_classifier: 5.6525 (5.6525)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1182 (0.1182)  loss_rpn_box_reg: 0.1315 (0.1315)  time: 0.6461  data: 0.1420  max mem: 10734\n",
      "Testing Epoch: [28]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9998 (6.1337)  loss_classifier: 5.4306 (5.6233)  loss_box_reg: 0.2609 (0.2896)  loss_objectness: 0.1294 (0.1308)  loss_rpn_box_reg: 0.0703 (0.0900)  time: 0.5875  data: 0.1458  max mem: 10734\n",
      "Testing Epoch: [28]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1610 (6.1648)  loss_classifier: 5.6796 (5.6590)  loss_box_reg: 0.2500 (0.2850)  loss_objectness: 0.1191 (0.1308)  loss_rpn_box_reg: 0.0745 (0.0900)  time: 0.6024  data: 0.1461  max mem: 10734\n",
      "Testing Epoch: [28] Total time: 0:01:14 (0.5986 s / it)\n",
      "Training Epoch: [29]  [  0/500]  eta: 0:07:22  lr: 0.000000  loss: 6.1999 (6.1999)  loss_classifier: 5.7815 (5.7815)  loss_box_reg: 0.1968 (0.1968)  loss_objectness: 0.1487 (0.1487)  loss_rpn_box_reg: 0.0729 (0.0729)  time: 0.8842  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [29]  [ 10/500]  eta: 0:05:10  lr: 0.000000  loss: 6.1999 (6.2368)  loss_classifier: 5.7680 (5.7710)  loss_box_reg: 0.2457 (0.2390)  loss_objectness: 0.1415 (0.1398)  loss_rpn_box_reg: 0.0781 (0.0870)  time: 0.6333  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [29]  [ 20/500]  eta: 0:04:59  lr: 0.000000  loss: 6.0486 (6.1268)  loss_classifier: 5.6077 (5.6810)  loss_box_reg: 0.2353 (0.2360)  loss_objectness: 0.1240 (0.1319)  loss_rpn_box_reg: 0.0686 (0.0778)  time: 0.6104  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [29]  [ 30/500]  eta: 0:04:56  lr: 0.000000  loss: 6.0246 (6.1238)  loss_classifier: 5.6157 (5.6787)  loss_box_reg: 0.2114 (0.2307)  loss_objectness: 0.1322 (0.1384)  loss_rpn_box_reg: 0.0645 (0.0759)  time: 0.6283  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [29]  [ 40/500]  eta: 0:04:49  lr: 0.000000  loss: 6.0371 (6.1204)  loss_classifier: 5.6157 (5.6673)  loss_box_reg: 0.2368 (0.2344)  loss_objectness: 0.1475 (0.1403)  loss_rpn_box_reg: 0.0741 (0.0785)  time: 0.6342  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [29]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 6.0460 (6.1102)  loss_classifier: 5.5653 (5.6431)  loss_box_reg: 0.2540 (0.2415)  loss_objectness: 0.1475 (0.1440)  loss_rpn_box_reg: 0.0894 (0.0816)  time: 0.6217  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [29]  [ 60/500]  eta: 0:04:36  lr: 0.000000  loss: 6.0922 (6.1087)  loss_classifier: 5.5917 (5.6511)  loss_box_reg: 0.2248 (0.2344)  loss_objectness: 0.1473 (0.1420)  loss_rpn_box_reg: 0.0868 (0.0813)  time: 0.6287  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [29]  [ 70/500]  eta: 0:04:30  lr: 0.000000  loss: 6.2432 (6.1147)  loss_classifier: 5.6922 (5.6528)  loss_box_reg: 0.2068 (0.2381)  loss_objectness: 0.1369 (0.1430)  loss_rpn_box_reg: 0.0832 (0.0807)  time: 0.6367  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [29]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 6.2952 (6.1345)  loss_classifier: 5.7957 (5.6737)  loss_box_reg: 0.2342 (0.2383)  loss_objectness: 0.1453 (0.1442)  loss_rpn_box_reg: 0.0563 (0.0784)  time: 0.6223  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [29]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 6.0507 (6.1191)  loss_classifier: 5.4903 (5.6596)  loss_box_reg: 0.2373 (0.2361)  loss_objectness: 0.1534 (0.1446)  loss_rpn_box_reg: 0.0620 (0.0788)  time: 0.6222  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [29]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 6.0105 (6.1281)  loss_classifier: 5.4852 (5.6691)  loss_box_reg: 0.2373 (0.2366)  loss_objectness: 0.1362 (0.1446)  loss_rpn_box_reg: 0.0761 (0.0778)  time: 0.6254  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [29]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.2256 (6.1385)  loss_classifier: 5.7717 (5.6801)  loss_box_reg: 0.2252 (0.2365)  loss_objectness: 0.1474 (0.1454)  loss_rpn_box_reg: 0.0605 (0.0765)  time: 0.6174  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [29]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.2485 (6.1591)  loss_classifier: 5.7067 (5.6969)  loss_box_reg: 0.2328 (0.2385)  loss_objectness: 0.1504 (0.1467)  loss_rpn_box_reg: 0.0654 (0.0770)  time: 0.6215  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [29]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.1572 (6.1519)  loss_classifier: 5.6127 (5.6905)  loss_box_reg: 0.2359 (0.2388)  loss_objectness: 0.1471 (0.1456)  loss_rpn_box_reg: 0.0728 (0.0770)  time: 0.6211  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [29]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 6.1608 (6.1685)  loss_classifier: 5.6790 (5.7043)  loss_box_reg: 0.2362 (0.2396)  loss_objectness: 0.1350 (0.1472)  loss_rpn_box_reg: 0.0785 (0.0774)  time: 0.6193  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [29]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.4169 (6.1797)  loss_classifier: 5.9068 (5.7140)  loss_box_reg: 0.2577 (0.2419)  loss_objectness: 0.1557 (0.1471)  loss_rpn_box_reg: 0.0751 (0.0768)  time: 0.6248  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [29]  [160/500]  eta: 0:03:31  lr: 0.000000  loss: 6.2398 (6.1807)  loss_classifier: 5.7095 (5.7129)  loss_box_reg: 0.2577 (0.2428)  loss_objectness: 0.1524 (0.1480)  loss_rpn_box_reg: 0.0664 (0.0770)  time: 0.6127  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [29]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.2050 (6.1908)  loss_classifier: 5.7095 (5.7242)  loss_box_reg: 0.2268 (0.2417)  loss_objectness: 0.1518 (0.1483)  loss_rpn_box_reg: 0.0744 (0.0765)  time: 0.6186  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [29]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.1061 (6.1797)  loss_classifier: 5.6951 (5.7141)  loss_box_reg: 0.2121 (0.2403)  loss_objectness: 0.1607 (0.1491)  loss_rpn_box_reg: 0.0744 (0.0762)  time: 0.6395  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [29]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.1210 (6.1897)  loss_classifier: 5.6951 (5.7259)  loss_box_reg: 0.2116 (0.2391)  loss_objectness: 0.1469 (0.1488)  loss_rpn_box_reg: 0.0717 (0.0759)  time: 0.6323  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [29]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.1548 (6.1897)  loss_classifier: 5.7184 (5.7250)  loss_box_reg: 0.2154 (0.2388)  loss_objectness: 0.1433 (0.1498)  loss_rpn_box_reg: 0.0734 (0.0760)  time: 0.6206  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [29]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.1403 (6.1914)  loss_classifier: 5.6137 (5.7274)  loss_box_reg: 0.2344 (0.2393)  loss_objectness: 0.1350 (0.1490)  loss_rpn_box_reg: 0.0734 (0.0756)  time: 0.6186  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [29]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.2702 (6.1968)  loss_classifier: 5.7907 (5.7313)  loss_box_reg: 0.2231 (0.2393)  loss_objectness: 0.1471 (0.1499)  loss_rpn_box_reg: 0.0676 (0.0762)  time: 0.6289  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [29]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.1184 (6.1854)  loss_classifier: 5.6567 (5.7213)  loss_box_reg: 0.2167 (0.2385)  loss_objectness: 0.1486 (0.1498)  loss_rpn_box_reg: 0.0718 (0.0757)  time: 0.6285  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [29]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.0849 (6.1879)  loss_classifier: 5.6327 (5.7231)  loss_box_reg: 0.2399 (0.2392)  loss_objectness: 0.1486 (0.1504)  loss_rpn_box_reg: 0.0633 (0.0751)  time: 0.6220  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [29]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.1961 (6.1817)  loss_classifier: 5.6704 (5.7167)  loss_box_reg: 0.2477 (0.2392)  loss_objectness: 0.1429 (0.1501)  loss_rpn_box_reg: 0.0640 (0.0756)  time: 0.6192  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [29]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.1961 (6.1827)  loss_classifier: 5.7225 (5.7186)  loss_box_reg: 0.2306 (0.2390)  loss_objectness: 0.1366 (0.1497)  loss_rpn_box_reg: 0.0688 (0.0754)  time: 0.6313  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [29]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.1205 (6.1808)  loss_classifier: 5.7225 (5.7179)  loss_box_reg: 0.2174 (0.2383)  loss_objectness: 0.1417 (0.1494)  loss_rpn_box_reg: 0.0688 (0.0752)  time: 0.6463  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [29]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.1205 (6.1798)  loss_classifier: 5.6654 (5.7166)  loss_box_reg: 0.2255 (0.2384)  loss_objectness: 0.1478 (0.1493)  loss_rpn_box_reg: 0.0752 (0.0754)  time: 0.6299  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [29]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.3611 (6.1874)  loss_classifier: 5.8066 (5.7244)  loss_box_reg: 0.2363 (0.2385)  loss_objectness: 0.1580 (0.1496)  loss_rpn_box_reg: 0.0692 (0.0749)  time: 0.6199  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [29]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.3083 (6.1921)  loss_classifier: 5.7964 (5.7291)  loss_box_reg: 0.2302 (0.2381)  loss_objectness: 0.1647 (0.1497)  loss_rpn_box_reg: 0.0583 (0.0753)  time: 0.6356  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [29]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.3438 (6.1993)  loss_classifier: 5.7964 (5.7360)  loss_box_reg: 0.2302 (0.2382)  loss_objectness: 0.1608 (0.1500)  loss_rpn_box_reg: 0.0710 (0.0751)  time: 0.6304  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [29]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.4400 (6.2016)  loss_classifier: 6.0258 (5.7384)  loss_box_reg: 0.1959 (0.2377)  loss_objectness: 0.1580 (0.1503)  loss_rpn_box_reg: 0.0770 (0.0753)  time: 0.6075  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [29]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 5.9784 (6.1988)  loss_classifier: 5.5906 (5.7340)  loss_box_reg: 0.2284 (0.2384)  loss_objectness: 0.1628 (0.1509)  loss_rpn_box_reg: 0.0819 (0.0756)  time: 0.6138  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [29]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 5.9422 (6.1938)  loss_classifier: 5.5188 (5.7300)  loss_box_reg: 0.2199 (0.2376)  loss_objectness: 0.1505 (0.1506)  loss_rpn_box_reg: 0.0773 (0.0756)  time: 0.6232  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [29]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.0950 (6.1930)  loss_classifier: 5.7328 (5.7303)  loss_box_reg: 0.2065 (0.2373)  loss_objectness: 0.1253 (0.1501)  loss_rpn_box_reg: 0.0704 (0.0753)  time: 0.6312  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [29]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.0991 (6.1960)  loss_classifier: 5.7435 (5.7333)  loss_box_reg: 0.2181 (0.2372)  loss_objectness: 0.1278 (0.1505)  loss_rpn_box_reg: 0.0606 (0.0750)  time: 0.6363  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [29]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.3356 (6.1999)  loss_classifier: 5.9147 (5.7382)  loss_box_reg: 0.2145 (0.2366)  loss_objectness: 0.1430 (0.1503)  loss_rpn_box_reg: 0.0609 (0.0748)  time: 0.6288  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [29]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.3468 (6.2042)  loss_classifier: 6.0042 (5.7426)  loss_box_reg: 0.2009 (0.2361)  loss_objectness: 0.1442 (0.1505)  loss_rpn_box_reg: 0.0689 (0.0750)  time: 0.6272  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [29]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.3089 (6.2035)  loss_classifier: 5.9154 (5.7416)  loss_box_reg: 0.2510 (0.2364)  loss_objectness: 0.1500 (0.1504)  loss_rpn_box_reg: 0.0692 (0.0751)  time: 0.6301  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [29]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2128 (6.2064)  loss_classifier: 5.7369 (5.7437)  loss_box_reg: 0.2641 (0.2373)  loss_objectness: 0.1531 (0.1503)  loss_rpn_box_reg: 0.0719 (0.0751)  time: 0.6338  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [29]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2119 (6.2080)  loss_classifier: 5.6974 (5.7442)  loss_box_reg: 0.2624 (0.2376)  loss_objectness: 0.1577 (0.1508)  loss_rpn_box_reg: 0.0866 (0.0755)  time: 0.6132  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [29]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.2003 (6.2106)  loss_classifier: 5.6909 (5.7459)  loss_box_reg: 0.2430 (0.2379)  loss_objectness: 0.1698 (0.1512)  loss_rpn_box_reg: 0.0837 (0.0757)  time: 0.5975  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [29]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2689 (6.2107)  loss_classifier: 5.8018 (5.7471)  loss_box_reg: 0.2150 (0.2372)  loss_objectness: 0.1530 (0.1512)  loss_rpn_box_reg: 0.0591 (0.0753)  time: 0.6158  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [29]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2689 (6.2127)  loss_classifier: 5.8018 (5.7490)  loss_box_reg: 0.2112 (0.2373)  loss_objectness: 0.1442 (0.1510)  loss_rpn_box_reg: 0.0569 (0.0753)  time: 0.6327  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [29]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.2057 (6.2089)  loss_classifier: 5.7129 (5.7443)  loss_box_reg: 0.2329 (0.2376)  loss_objectness: 0.1404 (0.1516)  loss_rpn_box_reg: 0.0764 (0.0755)  time: 0.6285  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [29]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 5.9571 (6.2058)  loss_classifier: 5.4991 (5.7412)  loss_box_reg: 0.2476 (0.2375)  loss_objectness: 0.1683 (0.1518)  loss_rpn_box_reg: 0.0753 (0.0754)  time: 0.6233  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [29]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0093 (6.2037)  loss_classifier: 5.5759 (5.7391)  loss_box_reg: 0.2436 (0.2376)  loss_objectness: 0.1481 (0.1517)  loss_rpn_box_reg: 0.0606 (0.0754)  time: 0.6380  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [29]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2676 (6.2115)  loss_classifier: 5.7926 (5.7464)  loss_box_reg: 0.2543 (0.2378)  loss_objectness: 0.1429 (0.1516)  loss_rpn_box_reg: 0.0675 (0.0757)  time: 0.6401  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [29]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.2331 (6.2091)  loss_classifier: 5.7722 (5.7435)  loss_box_reg: 0.2491 (0.2377)  loss_objectness: 0.1506 (0.1518)  loss_rpn_box_reg: 0.0903 (0.0762)  time: 0.6301  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [29]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2331 (6.2112)  loss_classifier: 5.7044 (5.7445)  loss_box_reg: 0.2489 (0.2384)  loss_objectness: 0.1554 (0.1521)  loss_rpn_box_reg: 0.0752 (0.0762)  time: 0.6309  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [29] Total time: 0:05:12 (0.6259 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:50  model_time: 0.6151 (0.6151)  evaluator_time: 0.0350 (0.0350)  time: 0.8852  data: 0.2261  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4451 (0.4542)  evaluator_time: 0.0340 (0.0378)  time: 0.6411  data: 0.1539  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4771 (0.4557)  evaluator_time: 0.0350 (0.0380)  time: 0.6629  data: 0.1551  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6440 s / it)\n",
      "Averaged stats: model_time: 0.4771 (0.4557)  evaluator_time: 0.0350 (0.0380)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [29]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.2052 (6.2052)  loss_classifier: 5.6597 (5.6597)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1201 (0.1201)  loss_rpn_box_reg: 0.1309 (0.1309)  time: 0.6491  data: 0.1450  max mem: 10734\n",
      "Testing Epoch: [29]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0023 (6.1325)  loss_classifier: 5.4512 (5.6230)  loss_box_reg: 0.2609 (0.2885)  loss_objectness: 0.1254 (0.1315)  loss_rpn_box_reg: 0.0740 (0.0895)  time: 0.5895  data: 0.1467  max mem: 10734\n",
      "Testing Epoch: [29]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1532 (6.1635)  loss_classifier: 5.6830 (5.6584)  loss_box_reg: 0.2500 (0.2841)  loss_objectness: 0.1134 (0.1314)  loss_rpn_box_reg: 0.0745 (0.0896)  time: 0.5987  data: 0.1448  max mem: 10734\n",
      "Testing Epoch: [29] Total time: 0:01:14 (0.5977 s / it)\n",
      "Training Epoch: [30]  [  0/500]  eta: 0:06:54  lr: 0.000000  loss: 6.4407 (6.4407)  loss_classifier: 5.9069 (5.9069)  loss_box_reg: 0.2902 (0.2902)  loss_objectness: 0.1692 (0.1692)  loss_rpn_box_reg: 0.0744 (0.0744)  time: 0.8292  data: 0.1390  max mem: 10734\n",
      "Training Epoch: [30]  [ 10/500]  eta: 0:05:20  lr: 0.000000  loss: 6.2754 (6.4126)  loss_classifier: 5.7979 (5.9499)  loss_box_reg: 0.1952 (0.2192)  loss_objectness: 0.1692 (0.1724)  loss_rpn_box_reg: 0.0704 (0.0712)  time: 0.6533  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [30]  [ 20/500]  eta: 0:05:10  lr: 0.000000  loss: 6.2004 (6.2540)  loss_classifier: 5.7592 (5.7782)  loss_box_reg: 0.2185 (0.2346)  loss_objectness: 0.1519 (0.1645)  loss_rpn_box_reg: 0.0704 (0.0767)  time: 0.6370  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [30]  [ 30/500]  eta: 0:04:59  lr: 0.000000  loss: 6.1458 (6.2445)  loss_classifier: 5.6058 (5.7788)  loss_box_reg: 0.2287 (0.2360)  loss_objectness: 0.1514 (0.1593)  loss_rpn_box_reg: 0.0639 (0.0704)  time: 0.6268  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [30]  [ 40/500]  eta: 0:04:52  lr: 0.000000  loss: 6.1436 (6.2404)  loss_classifier: 5.6649 (5.7732)  loss_box_reg: 0.2164 (0.2362)  loss_objectness: 0.1541 (0.1597)  loss_rpn_box_reg: 0.0679 (0.0712)  time: 0.6266  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [30]  [ 50/500]  eta: 0:04:44  lr: 0.000000  loss: 6.1982 (6.2939)  loss_classifier: 5.7746 (5.8214)  loss_box_reg: 0.2189 (0.2404)  loss_objectness: 0.1503 (0.1579)  loss_rpn_box_reg: 0.0776 (0.0743)  time: 0.6269  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [30]  [ 60/500]  eta: 0:04:36  lr: 0.000000  loss: 6.2693 (6.3118)  loss_classifier: 5.8207 (5.8357)  loss_box_reg: 0.2365 (0.2430)  loss_objectness: 0.1444 (0.1569)  loss_rpn_box_reg: 0.0818 (0.0762)  time: 0.6132  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [30]  [ 70/500]  eta: 0:04:29  lr: 0.000000  loss: 6.3494 (6.3161)  loss_classifier: 5.8992 (5.8465)  loss_box_reg: 0.2310 (0.2401)  loss_objectness: 0.1419 (0.1550)  loss_rpn_box_reg: 0.0718 (0.0745)  time: 0.6101  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [30]  [ 80/500]  eta: 0:04:22  lr: 0.000000  loss: 6.2485 (6.2869)  loss_classifier: 5.6876 (5.8157)  loss_box_reg: 0.2411 (0.2435)  loss_objectness: 0.1402 (0.1529)  loss_rpn_box_reg: 0.0687 (0.0747)  time: 0.6156  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [30]  [ 90/500]  eta: 0:04:16  lr: 0.000000  loss: 6.2485 (6.2865)  loss_classifier: 5.6876 (5.8092)  loss_box_reg: 0.2555 (0.2475)  loss_objectness: 0.1325 (0.1538)  loss_rpn_box_reg: 0.0812 (0.0760)  time: 0.6241  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [30]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 6.3646 (6.2898)  loss_classifier: 5.8805 (5.8167)  loss_box_reg: 0.2515 (0.2462)  loss_objectness: 0.1314 (0.1519)  loss_rpn_box_reg: 0.0730 (0.0750)  time: 0.6283  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [30]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 6.0256 (6.2675)  loss_classifier: 5.6198 (5.7928)  loss_box_reg: 0.2121 (0.2453)  loss_objectness: 0.1497 (0.1529)  loss_rpn_box_reg: 0.0695 (0.0765)  time: 0.6212  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [30]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 5.9942 (6.2597)  loss_classifier: 5.5811 (5.7888)  loss_box_reg: 0.2259 (0.2445)  loss_objectness: 0.1497 (0.1515)  loss_rpn_box_reg: 0.0612 (0.0749)  time: 0.6169  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [30]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.0679 (6.2581)  loss_classifier: 5.5887 (5.7867)  loss_box_reg: 0.2246 (0.2445)  loss_objectness: 0.1441 (0.1512)  loss_rpn_box_reg: 0.0646 (0.0756)  time: 0.6226  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [30]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 6.3301 (6.2660)  loss_classifier: 5.7774 (5.7956)  loss_box_reg: 0.2421 (0.2453)  loss_objectness: 0.1478 (0.1509)  loss_rpn_box_reg: 0.0673 (0.0742)  time: 0.6093  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [30]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.3244 (6.2689)  loss_classifier: 5.8772 (5.7987)  loss_box_reg: 0.2421 (0.2449)  loss_objectness: 0.1465 (0.1510)  loss_rpn_box_reg: 0.0630 (0.0743)  time: 0.6156  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [30]  [160/500]  eta: 0:03:31  lr: 0.000000  loss: 6.3060 (6.2725)  loss_classifier: 5.8282 (5.8010)  loss_box_reg: 0.2225 (0.2446)  loss_objectness: 0.1415 (0.1514)  loss_rpn_box_reg: 0.0848 (0.0755)  time: 0.6264  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [30]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 6.2876 (6.2682)  loss_classifier: 5.7767 (5.7966)  loss_box_reg: 0.2436 (0.2448)  loss_objectness: 0.1396 (0.1506)  loss_rpn_box_reg: 0.0836 (0.0761)  time: 0.6191  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [30]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.1070 (6.2620)  loss_classifier: 5.6319 (5.7881)  loss_box_reg: 0.2484 (0.2453)  loss_objectness: 0.1372 (0.1515)  loss_rpn_box_reg: 0.0836 (0.0770)  time: 0.6333  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [30]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.1831 (6.2579)  loss_classifier: 5.6319 (5.7833)  loss_box_reg: 0.2462 (0.2452)  loss_objectness: 0.1517 (0.1521)  loss_rpn_box_reg: 0.0905 (0.0773)  time: 0.6248  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [30]  [200/500]  eta: 0:03:06  lr: 0.000000  loss: 6.2217 (6.2518)  loss_classifier: 5.6902 (5.7772)  loss_box_reg: 0.2462 (0.2457)  loss_objectness: 0.1517 (0.1515)  loss_rpn_box_reg: 0.0773 (0.0774)  time: 0.6153  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [30]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.2294 (6.2492)  loss_classifier: 5.6902 (5.7752)  loss_box_reg: 0.2413 (0.2454)  loss_objectness: 0.1454 (0.1517)  loss_rpn_box_reg: 0.0656 (0.0768)  time: 0.6263  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [30]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.2220 (6.2445)  loss_classifier: 5.7514 (5.7705)  loss_box_reg: 0.2199 (0.2448)  loss_objectness: 0.1551 (0.1523)  loss_rpn_box_reg: 0.0631 (0.0769)  time: 0.6118  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [30]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.2220 (6.2579)  loss_classifier: 5.7514 (5.7845)  loss_box_reg: 0.2146 (0.2444)  loss_objectness: 0.1583 (0.1527)  loss_rpn_box_reg: 0.0631 (0.0763)  time: 0.6137  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [30]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.3405 (6.2698)  loss_classifier: 5.8115 (5.7958)  loss_box_reg: 0.2343 (0.2448)  loss_objectness: 0.1485 (0.1524)  loss_rpn_box_reg: 0.0602 (0.0768)  time: 0.6428  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [30]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.2090 (6.2645)  loss_classifier: 5.7508 (5.7920)  loss_box_reg: 0.2297 (0.2438)  loss_objectness: 0.1436 (0.1522)  loss_rpn_box_reg: 0.0641 (0.0765)  time: 0.6431  data: 0.1384  max mem: 10734\n",
      "Training Epoch: [30]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.1906 (6.2624)  loss_classifier: 5.7508 (5.7904)  loss_box_reg: 0.2191 (0.2439)  loss_objectness: 0.1424 (0.1519)  loss_rpn_box_reg: 0.0649 (0.0762)  time: 0.6354  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [30]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.0547 (6.2574)  loss_classifier: 5.6866 (5.7869)  loss_box_reg: 0.2346 (0.2432)  loss_objectness: 0.1375 (0.1515)  loss_rpn_box_reg: 0.0613 (0.0759)  time: 0.6304  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [30]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.0513 (6.2552)  loss_classifier: 5.6993 (5.7856)  loss_box_reg: 0.2346 (0.2427)  loss_objectness: 0.1406 (0.1513)  loss_rpn_box_reg: 0.0555 (0.0757)  time: 0.6202  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [30]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.2543 (6.2522)  loss_classifier: 5.7384 (5.7827)  loss_box_reg: 0.2202 (0.2418)  loss_objectness: 0.1562 (0.1519)  loss_rpn_box_reg: 0.0596 (0.0758)  time: 0.6227  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [30]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.1064 (6.2490)  loss_classifier: 5.5960 (5.7787)  loss_box_reg: 0.2305 (0.2425)  loss_objectness: 0.1649 (0.1523)  loss_rpn_box_reg: 0.0664 (0.0755)  time: 0.6290  data: 0.1386  max mem: 10734\n",
      "Training Epoch: [30]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.0790 (6.2456)  loss_classifier: 5.6394 (5.7760)  loss_box_reg: 0.2303 (0.2416)  loss_objectness: 0.1436 (0.1522)  loss_rpn_box_reg: 0.0668 (0.0758)  time: 0.6288  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [30]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2445 (6.2466)  loss_classifier: 5.7473 (5.7774)  loss_box_reg: 0.2140 (0.2412)  loss_objectness: 0.1453 (0.1522)  loss_rpn_box_reg: 0.0732 (0.0758)  time: 0.6199  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [30]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.1799 (6.2426)  loss_classifier: 5.6866 (5.7727)  loss_box_reg: 0.2318 (0.2418)  loss_objectness: 0.1453 (0.1521)  loss_rpn_box_reg: 0.0748 (0.0760)  time: 0.6344  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [30]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.1497 (6.2388)  loss_classifier: 5.6413 (5.7687)  loss_box_reg: 0.2346 (0.2417)  loss_objectness: 0.1453 (0.1527)  loss_rpn_box_reg: 0.0748 (0.0758)  time: 0.6354  data: 0.1385  max mem: 10734\n",
      "Training Epoch: [30]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 5.9683 (6.2329)  loss_classifier: 5.5369 (5.7620)  loss_box_reg: 0.2357 (0.2420)  loss_objectness: 0.1554 (0.1528)  loss_rpn_box_reg: 0.0754 (0.0760)  time: 0.6285  data: 0.1376  max mem: 10734\n",
      "Training Epoch: [30]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 5.9939 (6.2262)  loss_classifier: 5.4230 (5.7567)  loss_box_reg: 0.2138 (0.2409)  loss_objectness: 0.1479 (0.1528)  loss_rpn_box_reg: 0.0652 (0.0758)  time: 0.6398  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [30]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 5.9939 (6.2214)  loss_classifier: 5.4720 (5.7524)  loss_box_reg: 0.2024 (0.2405)  loss_objectness: 0.1340 (0.1524)  loss_rpn_box_reg: 0.0652 (0.0760)  time: 0.6324  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [30]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 5.9269 (6.2159)  loss_classifier: 5.4720 (5.7485)  loss_box_reg: 0.2024 (0.2397)  loss_objectness: 0.1344 (0.1520)  loss_rpn_box_reg: 0.0569 (0.0757)  time: 0.6343  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [30]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.0639 (6.2128)  loss_classifier: 5.5511 (5.7441)  loss_box_reg: 0.2209 (0.2404)  loss_objectness: 0.1511 (0.1526)  loss_rpn_box_reg: 0.0696 (0.0757)  time: 0.6267  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [30]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1839 (6.2123)  loss_classifier: 5.5910 (5.7444)  loss_box_reg: 0.2367 (0.2403)  loss_objectness: 0.1566 (0.1523)  loss_rpn_box_reg: 0.0672 (0.0754)  time: 0.6074  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [30]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2373 (6.2149)  loss_classifier: 5.8387 (5.7463)  loss_box_reg: 0.2168 (0.2405)  loss_objectness: 0.1343 (0.1524)  loss_rpn_box_reg: 0.0610 (0.0757)  time: 0.6212  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [30]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.3442 (6.2154)  loss_classifier: 5.8579 (5.7459)  loss_box_reg: 0.2406 (0.2406)  loss_objectness: 0.1734 (0.1533)  loss_rpn_box_reg: 0.0700 (0.0757)  time: 0.6245  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [30]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1357 (6.2135)  loss_classifier: 5.6312 (5.7427)  loss_box_reg: 0.2592 (0.2414)  loss_objectness: 0.1827 (0.1536)  loss_rpn_box_reg: 0.0746 (0.0758)  time: 0.6192  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [30]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.0386 (6.2127)  loss_classifier: 5.6302 (5.7430)  loss_box_reg: 0.2311 (0.2407)  loss_objectness: 0.1611 (0.1537)  loss_rpn_box_reg: 0.0577 (0.0752)  time: 0.6349  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [30]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0319 (6.2104)  loss_classifier: 5.6507 (5.7421)  loss_box_reg: 0.1781 (0.2393)  loss_objectness: 0.1450 (0.1537)  loss_rpn_box_reg: 0.0577 (0.0753)  time: 0.6310  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [30]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0618 (6.2121)  loss_classifier: 5.6507 (5.7439)  loss_box_reg: 0.1893 (0.2391)  loss_objectness: 0.1536 (0.1538)  loss_rpn_box_reg: 0.0782 (0.0754)  time: 0.6244  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [30]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1119 (6.2133)  loss_classifier: 5.6463 (5.7448)  loss_box_reg: 0.2459 (0.2395)  loss_objectness: 0.1448 (0.1535)  loss_rpn_box_reg: 0.0782 (0.0755)  time: 0.6333  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [30]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0972 (6.2092)  loss_classifier: 5.5758 (5.7410)  loss_box_reg: 0.2342 (0.2397)  loss_objectness: 0.1298 (0.1531)  loss_rpn_box_reg: 0.0711 (0.0755)  time: 0.6377  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [30]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0972 (6.2093)  loss_classifier: 5.5998 (5.7410)  loss_box_reg: 0.2009 (0.2395)  loss_objectness: 0.1346 (0.1532)  loss_rpn_box_reg: 0.0711 (0.0756)  time: 0.6371  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [30]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2909 (6.2139)  loss_classifier: 5.7421 (5.7445)  loss_box_reg: 0.2394 (0.2401)  loss_objectness: 0.1479 (0.1535)  loss_rpn_box_reg: 0.0666 (0.0758)  time: 0.6316  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [30] Total time: 0:05:13 (0.6265 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:44  model_time: 0.6421 (0.6421)  evaluator_time: 0.0350 (0.0350)  time: 0.8342  data: 0.1480  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4431 (0.4515)  evaluator_time: 0.0340 (0.0341)  time: 0.6339  data: 0.1483  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4801 (0.4534)  evaluator_time: 0.0360 (0.0350)  time: 0.6567  data: 0.1489  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6414 s / it)\n",
      "Averaged stats: model_time: 0.4801 (0.4534)  evaluator_time: 0.0360 (0.0350)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [30]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.2128 (6.2128)  loss_classifier: 5.6627 (5.6627)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1246 (0.1246)  loss_rpn_box_reg: 0.1309 (0.1309)  time: 0.6401  data: 0.1410  max mem: 10734\n",
      "Testing Epoch: [30]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0132 (6.1294)  loss_classifier: 5.4312 (5.6170)  loss_box_reg: 0.2609 (0.2903)  loss_objectness: 0.1326 (0.1322)  loss_rpn_box_reg: 0.0709 (0.0899)  time: 0.5890  data: 0.1458  max mem: 10734\n",
      "Testing Epoch: [30]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1701 (6.1615)  loss_classifier: 5.7032 (5.6539)  loss_box_reg: 0.2500 (0.2855)  loss_objectness: 0.1220 (0.1321)  loss_rpn_box_reg: 0.0745 (0.0900)  time: 0.6025  data: 0.1474  max mem: 10734\n",
      "Testing Epoch: [30] Total time: 0:01:14 (0.5975 s / it)\n",
      "Training Epoch: [31]  [  0/500]  eta: 0:07:00  lr: 0.000000  loss: 5.5096 (5.5096)  loss_classifier: 5.2102 (5.2102)  loss_box_reg: 0.1311 (0.1311)  loss_objectness: 0.1256 (0.1256)  loss_rpn_box_reg: 0.0427 (0.0427)  time: 0.8402  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [31]  [ 10/500]  eta: 0:05:13  lr: 0.000000  loss: 6.1996 (6.0770)  loss_classifier: 5.6164 (5.5837)  loss_box_reg: 0.2534 (0.2423)  loss_objectness: 0.1458 (0.1544)  loss_rpn_box_reg: 0.0786 (0.0967)  time: 0.6398  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [31]  [ 20/500]  eta: 0:05:08  lr: 0.000000  loss: 6.0176 (6.0642)  loss_classifier: 5.5479 (5.5957)  loss_box_reg: 0.2181 (0.2423)  loss_objectness: 0.1458 (0.1473)  loss_rpn_box_reg: 0.0623 (0.0789)  time: 0.6318  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [31]  [ 30/500]  eta: 0:04:55  lr: 0.000000  loss: 6.0176 (6.0927)  loss_classifier: 5.6212 (5.6208)  loss_box_reg: 0.2290 (0.2481)  loss_objectness: 0.1473 (0.1475)  loss_rpn_box_reg: 0.0595 (0.0762)  time: 0.6220  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [31]  [ 40/500]  eta: 0:04:49  lr: 0.000000  loss: 6.1913 (6.0753)  loss_classifier: 5.6749 (5.6118)  loss_box_reg: 0.2290 (0.2431)  loss_objectness: 0.1473 (0.1470)  loss_rpn_box_reg: 0.0671 (0.0733)  time: 0.6162  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [31]  [ 50/500]  eta: 0:04:43  lr: 0.000000  loss: 6.3503 (6.1346)  loss_classifier: 5.8884 (5.6663)  loss_box_reg: 0.2237 (0.2429)  loss_objectness: 0.1458 (0.1470)  loss_rpn_box_reg: 0.0684 (0.0784)  time: 0.6318  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [31]  [ 60/500]  eta: 0:04:37  lr: 0.000000  loss: 6.3697 (6.1432)  loss_classifier: 5.7129 (5.6593)  loss_box_reg: 0.2471 (0.2512)  loss_objectness: 0.1544 (0.1515)  loss_rpn_box_reg: 0.0808 (0.0812)  time: 0.6340  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [31]  [ 70/500]  eta: 0:04:30  lr: 0.000000  loss: 6.3890 (6.1821)  loss_classifier: 5.7986 (5.6980)  loss_box_reg: 0.2535 (0.2492)  loss_objectness: 0.1784 (0.1548)  loss_rpn_box_reg: 0.0730 (0.0800)  time: 0.6316  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [31]  [ 80/500]  eta: 0:04:24  lr: 0.000000  loss: 6.3890 (6.2030)  loss_classifier: 5.9914 (5.7201)  loss_box_reg: 0.2341 (0.2480)  loss_objectness: 0.1646 (0.1553)  loss_rpn_box_reg: 0.0730 (0.0797)  time: 0.6268  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [31]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 6.3179 (6.2278)  loss_classifier: 5.9386 (5.7426)  loss_box_reg: 0.2374 (0.2496)  loss_objectness: 0.1491 (0.1558)  loss_rpn_box_reg: 0.0757 (0.0797)  time: 0.6200  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [31]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 6.2350 (6.2266)  loss_classifier: 5.6950 (5.7435)  loss_box_reg: 0.2531 (0.2500)  loss_objectness: 0.1513 (0.1551)  loss_rpn_box_reg: 0.0634 (0.0781)  time: 0.6291  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [31]  [110/500]  eta: 0:04:05  lr: 0.000000  loss: 6.1476 (6.2116)  loss_classifier: 5.6409 (5.7349)  loss_box_reg: 0.2458 (0.2474)  loss_objectness: 0.1266 (0.1533)  loss_rpn_box_reg: 0.0561 (0.0759)  time: 0.6357  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [31]  [120/500]  eta: 0:03:59  lr: 0.000000  loss: 6.1476 (6.2144)  loss_classifier: 5.6850 (5.7366)  loss_box_reg: 0.2137 (0.2478)  loss_objectness: 0.1437 (0.1543)  loss_rpn_box_reg: 0.0532 (0.0757)  time: 0.6409  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [31]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 6.3021 (6.2241)  loss_classifier: 5.6850 (5.7436)  loss_box_reg: 0.2312 (0.2476)  loss_objectness: 0.1653 (0.1560)  loss_rpn_box_reg: 0.0682 (0.0769)  time: 0.6294  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [31]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.1614 (6.2176)  loss_classifier: 5.6149 (5.7399)  loss_box_reg: 0.2172 (0.2454)  loss_objectness: 0.1619 (0.1556)  loss_rpn_box_reg: 0.0682 (0.0766)  time: 0.6134  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [31]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 6.0673 (6.2112)  loss_classifier: 5.5992 (5.7360)  loss_box_reg: 0.2162 (0.2433)  loss_objectness: 0.1501 (0.1555)  loss_rpn_box_reg: 0.0659 (0.0764)  time: 0.6246  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [31]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 5.9693 (6.1997)  loss_classifier: 5.4879 (5.7252)  loss_box_reg: 0.2355 (0.2433)  loss_objectness: 0.1501 (0.1552)  loss_rpn_box_reg: 0.0659 (0.0760)  time: 0.6204  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [31]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.0496 (6.2017)  loss_classifier: 5.6686 (5.7265)  loss_box_reg: 0.2512 (0.2438)  loss_objectness: 0.1519 (0.1552)  loss_rpn_box_reg: 0.0733 (0.0762)  time: 0.6178  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [31]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.2337 (6.2014)  loss_classifier: 5.7821 (5.7247)  loss_box_reg: 0.2586 (0.2445)  loss_objectness: 0.1522 (0.1550)  loss_rpn_box_reg: 0.0789 (0.0771)  time: 0.6231  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [31]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.3295 (6.2112)  loss_classifier: 5.8294 (5.7361)  loss_box_reg: 0.2313 (0.2434)  loss_objectness: 0.1474 (0.1548)  loss_rpn_box_reg: 0.0747 (0.0769)  time: 0.6131  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [31]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.2163 (6.2156)  loss_classifier: 5.9265 (5.7435)  loss_box_reg: 0.1986 (0.2416)  loss_objectness: 0.1440 (0.1539)  loss_rpn_box_reg: 0.0596 (0.0766)  time: 0.6290  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [31]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.0696 (6.2091)  loss_classifier: 5.6269 (5.7374)  loss_box_reg: 0.2217 (0.2415)  loss_objectness: 0.1431 (0.1534)  loss_rpn_box_reg: 0.0578 (0.0768)  time: 0.6371  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [31]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.0696 (6.2128)  loss_classifier: 5.6457 (5.7406)  loss_box_reg: 0.2553 (0.2419)  loss_objectness: 0.1434 (0.1538)  loss_rpn_box_reg: 0.0706 (0.0764)  time: 0.6222  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [31]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.2173 (6.2023)  loss_classifier: 5.7130 (5.7275)  loss_box_reg: 0.2759 (0.2433)  loss_objectness: 0.1443 (0.1540)  loss_rpn_box_reg: 0.0886 (0.0775)  time: 0.6175  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [31]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.1122 (6.2034)  loss_classifier: 5.6539 (5.7288)  loss_box_reg: 0.2622 (0.2439)  loss_objectness: 0.1443 (0.1534)  loss_rpn_box_reg: 0.0827 (0.0773)  time: 0.6181  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [31]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.1122 (6.2003)  loss_classifier: 5.6539 (5.7259)  loss_box_reg: 0.2561 (0.2438)  loss_objectness: 0.1497 (0.1537)  loss_rpn_box_reg: 0.0640 (0.0769)  time: 0.6204  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [31]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.1415 (6.2070)  loss_classifier: 5.6311 (5.7335)  loss_box_reg: 0.2374 (0.2437)  loss_objectness: 0.1400 (0.1531)  loss_rpn_box_reg: 0.0640 (0.0768)  time: 0.6254  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [31]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.1415 (6.2045)  loss_classifier: 5.7509 (5.7312)  loss_box_reg: 0.2202 (0.2432)  loss_objectness: 0.1364 (0.1532)  loss_rpn_box_reg: 0.0691 (0.0769)  time: 0.6224  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [31]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.2577 (6.2094)  loss_classifier: 5.7688 (5.7356)  loss_box_reg: 0.2413 (0.2436)  loss_objectness: 0.1388 (0.1530)  loss_rpn_box_reg: 0.0677 (0.0772)  time: 0.6190  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [31]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.2748 (6.2100)  loss_classifier: 5.7940 (5.7360)  loss_box_reg: 0.2413 (0.2435)  loss_objectness: 0.1477 (0.1531)  loss_rpn_box_reg: 0.0662 (0.0774)  time: 0.6353  data: 0.1377  max mem: 10734\n",
      "Training Epoch: [31]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.2546 (6.2107)  loss_classifier: 5.7798 (5.7388)  loss_box_reg: 0.2053 (0.2420)  loss_objectness: 0.1465 (0.1525)  loss_rpn_box_reg: 0.0714 (0.0774)  time: 0.6481  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [31]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.1079 (6.2022)  loss_classifier: 5.6303 (5.7297)  loss_box_reg: 0.2033 (0.2425)  loss_objectness: 0.1389 (0.1525)  loss_rpn_box_reg: 0.0776 (0.0775)  time: 0.6411  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [31]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.0837 (6.2025)  loss_classifier: 5.5922 (5.7301)  loss_box_reg: 0.2078 (0.2420)  loss_objectness: 0.1531 (0.1533)  loss_rpn_box_reg: 0.0714 (0.0772)  time: 0.6287  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [31]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.1294 (6.2003)  loss_classifier: 5.6462 (5.7278)  loss_box_reg: 0.2126 (0.2424)  loss_objectness: 0.1682 (0.1531)  loss_rpn_box_reg: 0.0648 (0.0769)  time: 0.6228  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [31]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.1294 (6.2053)  loss_classifier: 5.7013 (5.7325)  loss_box_reg: 0.2457 (0.2424)  loss_objectness: 0.1553 (0.1532)  loss_rpn_box_reg: 0.0670 (0.0772)  time: 0.6254  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [31]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.2480 (6.2093)  loss_classifier: 5.7636 (5.7376)  loss_box_reg: 0.2090 (0.2417)  loss_objectness: 0.1512 (0.1529)  loss_rpn_box_reg: 0.0709 (0.0770)  time: 0.6282  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [31]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 5.9595 (6.2023)  loss_classifier: 5.4406 (5.7305)  loss_box_reg: 0.2016 (0.2415)  loss_objectness: 0.1512 (0.1531)  loss_rpn_box_reg: 0.0709 (0.0773)  time: 0.6094  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [31]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 5.7960 (6.1933)  loss_classifier: 5.4380 (5.7233)  loss_box_reg: 0.2347 (0.2407)  loss_objectness: 0.1405 (0.1524)  loss_rpn_box_reg: 0.0578 (0.0768)  time: 0.6249  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [31]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 5.8908 (6.1879)  loss_classifier: 5.4470 (5.7179)  loss_box_reg: 0.2023 (0.2408)  loss_objectness: 0.1390 (0.1524)  loss_rpn_box_reg: 0.0587 (0.0769)  time: 0.6334  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [31]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.2574 (6.1945)  loss_classifier: 5.7004 (5.7245)  loss_box_reg: 0.2451 (0.2409)  loss_objectness: 0.1489 (0.1522)  loss_rpn_box_reg: 0.0755 (0.0769)  time: 0.6195  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [31]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1533 (6.1922)  loss_classifier: 5.7004 (5.7224)  loss_box_reg: 0.2647 (0.2410)  loss_objectness: 0.1429 (0.1522)  loss_rpn_box_reg: 0.0642 (0.0766)  time: 0.6203  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [31]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1213 (6.1933)  loss_classifier: 5.6436 (5.7239)  loss_box_reg: 0.2638 (0.2411)  loss_objectness: 0.1418 (0.1519)  loss_rpn_box_reg: 0.0575 (0.0764)  time: 0.6235  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [31]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.1940 (6.1976)  loss_classifier: 5.7667 (5.7296)  loss_box_reg: 0.2199 (0.2403)  loss_objectness: 0.1404 (0.1515)  loss_rpn_box_reg: 0.0601 (0.0763)  time: 0.6306  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [31]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1940 (6.1985)  loss_classifier: 5.7667 (5.7296)  loss_box_reg: 0.2315 (0.2412)  loss_objectness: 0.1374 (0.1514)  loss_rpn_box_reg: 0.0654 (0.0763)  time: 0.6435  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [31]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1588 (6.2021)  loss_classifier: 5.6928 (5.7320)  loss_box_reg: 0.2645 (0.2416)  loss_objectness: 0.1456 (0.1520)  loss_rpn_box_reg: 0.0754 (0.0765)  time: 0.6431  data: 0.1380  max mem: 10734\n",
      "Training Epoch: [31]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.2878 (6.2083)  loss_classifier: 5.8641 (5.7391)  loss_box_reg: 0.2234 (0.2412)  loss_objectness: 0.1498 (0.1516)  loss_rpn_box_reg: 0.0665 (0.0764)  time: 0.6386  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [31]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.2878 (6.2078)  loss_classifier: 5.8253 (5.7383)  loss_box_reg: 0.2505 (0.2414)  loss_objectness: 0.1565 (0.1519)  loss_rpn_box_reg: 0.0579 (0.0761)  time: 0.6352  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [31]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0267 (6.2055)  loss_classifier: 5.5251 (5.7355)  loss_box_reg: 0.2624 (0.2415)  loss_objectness: 0.1655 (0.1522)  loss_rpn_box_reg: 0.0674 (0.0763)  time: 0.6288  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [31]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2231 (6.2104)  loss_classifier: 5.6483 (5.7405)  loss_box_reg: 0.2247 (0.2411)  loss_objectness: 0.1726 (0.1526)  loss_rpn_box_reg: 0.0766 (0.0762)  time: 0.6328  data: 0.1370  max mem: 10734\n",
      "Training Epoch: [31]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.4231 (6.2185)  loss_classifier: 6.0009 (5.7488)  loss_box_reg: 0.2062 (0.2407)  loss_objectness: 0.1561 (0.1527)  loss_rpn_box_reg: 0.0755 (0.0763)  time: 0.6291  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [31]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2170 (6.2166)  loss_classifier: 5.7692 (5.7471)  loss_box_reg: 0.2084 (0.2408)  loss_objectness: 0.1375 (0.1526)  loss_rpn_box_reg: 0.0697 (0.0761)  time: 0.6181  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [31] Total time: 0:05:13 (0.6275 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:51  model_time: 0.7012 (0.7012)  evaluator_time: 0.0340 (0.0340)  time: 0.8902  data: 0.1460  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4421 (0.4525)  evaluator_time: 0.0340 (0.0340)  time: 0.6328  data: 0.1484  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4721 (0.4543)  evaluator_time: 0.0360 (0.0349)  time: 0.6573  data: 0.1488  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6431 s / it)\n",
      "Averaged stats: model_time: 0.4721 (0.4543)  evaluator_time: 0.0360 (0.0349)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [31]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1952 (6.1952)  loss_classifier: 5.6458 (5.6458)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1225 (0.1225)  loss_rpn_box_reg: 0.1324 (0.1324)  time: 0.6401  data: 0.1360  max mem: 10734\n",
      "Testing Epoch: [31]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0079 (6.1246)  loss_classifier: 5.4161 (5.6127)  loss_box_reg: 0.2609 (0.2908)  loss_objectness: 0.1300 (0.1318)  loss_rpn_box_reg: 0.0736 (0.0893)  time: 0.5878  data: 0.1471  max mem: 10734\n",
      "Testing Epoch: [31]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1421 (6.1570)  loss_classifier: 5.6815 (5.6498)  loss_box_reg: 0.2500 (0.2860)  loss_objectness: 0.1175 (0.1318)  loss_rpn_box_reg: 0.0745 (0.0894)  time: 0.5991  data: 0.1447  max mem: 10734\n",
      "Testing Epoch: [31] Total time: 0:01:14 (0.5983 s / it)\n",
      "Training Epoch: [32]  [  0/500]  eta: 0:07:55  lr: 0.000000  loss: 5.9767 (5.9767)  loss_classifier: 5.5501 (5.5501)  loss_box_reg: 0.2370 (0.2370)  loss_objectness: 0.1527 (0.1527)  loss_rpn_box_reg: 0.0369 (0.0369)  time: 0.9512  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [32]  [ 10/500]  eta: 0:05:18  lr: 0.000000  loss: 6.3146 (6.1792)  loss_classifier: 5.8867 (5.6784)  loss_box_reg: 0.2563 (0.2686)  loss_objectness: 0.1561 (0.1546)  loss_rpn_box_reg: 0.0734 (0.0777)  time: 0.6494  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [32]  [ 20/500]  eta: 0:05:02  lr: 0.000000  loss: 6.3036 (6.1656)  loss_classifier: 5.8810 (5.6786)  loss_box_reg: 0.2445 (0.2476)  loss_objectness: 0.1549 (0.1562)  loss_rpn_box_reg: 0.0758 (0.0832)  time: 0.6143  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [32]  [ 30/500]  eta: 0:04:54  lr: 0.000000  loss: 6.0712 (6.1719)  loss_classifier: 5.6543 (5.6902)  loss_box_reg: 0.2219 (0.2463)  loss_objectness: 0.1395 (0.1543)  loss_rpn_box_reg: 0.0722 (0.0811)  time: 0.6151  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [32]  [ 40/500]  eta: 0:04:48  lr: 0.000000  loss: 6.1690 (6.2247)  loss_classifier: 5.7532 (5.7476)  loss_box_reg: 0.2346 (0.2452)  loss_objectness: 0.1371 (0.1543)  loss_rpn_box_reg: 0.0664 (0.0775)  time: 0.6236  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [32]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 6.3100 (6.2540)  loss_classifier: 5.9200 (5.7778)  loss_box_reg: 0.2346 (0.2432)  loss_objectness: 0.1533 (0.1554)  loss_rpn_box_reg: 0.0680 (0.0775)  time: 0.6313  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [32]  [ 60/500]  eta: 0:04:34  lr: 0.000000  loss: 6.1930 (6.2290)  loss_classifier: 5.7962 (5.7452)  loss_box_reg: 0.2505 (0.2483)  loss_objectness: 0.1597 (0.1562)  loss_rpn_box_reg: 0.0743 (0.0792)  time: 0.6173  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [32]  [ 70/500]  eta: 0:04:29  lr: 0.000000  loss: 6.2052 (6.2512)  loss_classifier: 5.7440 (5.7712)  loss_box_reg: 0.2468 (0.2472)  loss_objectness: 0.1453 (0.1552)  loss_rpn_box_reg: 0.0702 (0.0776)  time: 0.6207  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [32]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 6.2052 (6.2293)  loss_classifier: 5.7440 (5.7554)  loss_box_reg: 0.2012 (0.2420)  loss_objectness: 0.1453 (0.1548)  loss_rpn_box_reg: 0.0653 (0.0772)  time: 0.6397  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [32]  [ 90/500]  eta: 0:04:16  lr: 0.000000  loss: 5.9211 (6.2149)  loss_classifier: 5.4369 (5.7396)  loss_box_reg: 0.2162 (0.2440)  loss_objectness: 0.1419 (0.1542)  loss_rpn_box_reg: 0.0676 (0.0771)  time: 0.6231  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [32]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 5.9795 (6.2071)  loss_classifier: 5.5878 (5.7370)  loss_box_reg: 0.2494 (0.2404)  loss_objectness: 0.1370 (0.1534)  loss_rpn_box_reg: 0.0704 (0.0763)  time: 0.6281  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [32]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.1435 (6.2199)  loss_classifier: 5.6685 (5.7484)  loss_box_reg: 0.2206 (0.2401)  loss_objectness: 0.1508 (0.1551)  loss_rpn_box_reg: 0.0719 (0.0762)  time: 0.6375  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [32]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.3739 (6.2296)  loss_classifier: 6.0059 (5.7592)  loss_box_reg: 0.2206 (0.2370)  loss_objectness: 0.1741 (0.1577)  loss_rpn_box_reg: 0.0708 (0.0757)  time: 0.6213  data: 0.1379  max mem: 10734\n",
      "Training Epoch: [32]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.1452 (6.2171)  loss_classifier: 5.6311 (5.7472)  loss_box_reg: 0.2204 (0.2377)  loss_objectness: 0.1587 (0.1562)  loss_rpn_box_reg: 0.0698 (0.0760)  time: 0.6219  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [32]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 5.9997 (6.2071)  loss_classifier: 5.5663 (5.7389)  loss_box_reg: 0.2150 (0.2365)  loss_objectness: 0.1429 (0.1565)  loss_rpn_box_reg: 0.0698 (0.0752)  time: 0.6295  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [32]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.0826 (6.2074)  loss_classifier: 5.6238 (5.7421)  loss_box_reg: 0.1912 (0.2354)  loss_objectness: 0.1429 (0.1559)  loss_rpn_box_reg: 0.0537 (0.0740)  time: 0.6351  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [32]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.1785 (6.2108)  loss_classifier: 5.7813 (5.7424)  loss_box_reg: 0.2277 (0.2375)  loss_objectness: 0.1625 (0.1570)  loss_rpn_box_reg: 0.0577 (0.0738)  time: 0.6253  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [32]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.1110 (6.2030)  loss_classifier: 5.6419 (5.7326)  loss_box_reg: 0.2528 (0.2387)  loss_objectness: 0.1621 (0.1568)  loss_rpn_box_reg: 0.0754 (0.0749)  time: 0.6235  data: 0.1388  max mem: 10734\n",
      "Training Epoch: [32]  [180/500]  eta: 0:03:21  lr: 0.000000  loss: 6.2267 (6.2126)  loss_classifier: 5.6656 (5.7382)  loss_box_reg: 0.2576 (0.2409)  loss_objectness: 0.1621 (0.1580)  loss_rpn_box_reg: 0.0785 (0.0754)  time: 0.6405  data: 0.1385  max mem: 10734\n",
      "Training Epoch: [32]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.2267 (6.2087)  loss_classifier: 5.6656 (5.7347)  loss_box_reg: 0.2448 (0.2408)  loss_objectness: 0.1713 (0.1579)  loss_rpn_box_reg: 0.0785 (0.0754)  time: 0.6340  data: 0.1397  max mem: 10734\n",
      "Training Epoch: [32]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.0955 (6.2153)  loss_classifier: 5.6218 (5.7379)  loss_box_reg: 0.2636 (0.2432)  loss_objectness: 0.1647 (0.1584)  loss_rpn_box_reg: 0.0778 (0.0758)  time: 0.6219  data: 0.1392  max mem: 10734\n",
      "Training Epoch: [32]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.1503 (6.2128)  loss_classifier: 5.7079 (5.7347)  loss_box_reg: 0.2478 (0.2433)  loss_objectness: 0.1647 (0.1584)  loss_rpn_box_reg: 0.0778 (0.0764)  time: 0.6263  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [32]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.0369 (6.2099)  loss_classifier: 5.6686 (5.7324)  loss_box_reg: 0.2210 (0.2431)  loss_objectness: 0.1560 (0.1585)  loss_rpn_box_reg: 0.0729 (0.0759)  time: 0.6198  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [32]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.0367 (6.2027)  loss_classifier: 5.6197 (5.7268)  loss_box_reg: 0.2235 (0.2422)  loss_objectness: 0.1478 (0.1580)  loss_rpn_box_reg: 0.0647 (0.0758)  time: 0.6254  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [32]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.0246 (6.1938)  loss_classifier: 5.5620 (5.7203)  loss_box_reg: 0.2273 (0.2407)  loss_objectness: 0.1305 (0.1572)  loss_rpn_box_reg: 0.0554 (0.0756)  time: 0.6367  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [32]  [250/500]  eta: 0:02:37  lr: 0.000000  loss: 6.1512 (6.2026)  loss_classifier: 5.7029 (5.7298)  loss_box_reg: 0.2273 (0.2407)  loss_objectness: 0.1252 (0.1565)  loss_rpn_box_reg: 0.0589 (0.0755)  time: 0.6411  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [32]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.4147 (6.2254)  loss_classifier: 5.9797 (5.7531)  loss_box_reg: 0.2265 (0.2398)  loss_objectness: 0.1556 (0.1571)  loss_rpn_box_reg: 0.0595 (0.0754)  time: 0.6356  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [32]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.5135 (6.2329)  loss_classifier: 6.0093 (5.7615)  loss_box_reg: 0.2229 (0.2392)  loss_objectness: 0.1556 (0.1570)  loss_rpn_box_reg: 0.0745 (0.0752)  time: 0.6222  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [32]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.0609 (6.2200)  loss_classifier: 5.6474 (5.7497)  loss_box_reg: 0.2229 (0.2388)  loss_objectness: 0.1323 (0.1565)  loss_rpn_box_reg: 0.0653 (0.0749)  time: 0.6230  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [32]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 5.8750 (6.2134)  loss_classifier: 5.4177 (5.7430)  loss_box_reg: 0.2391 (0.2390)  loss_objectness: 0.1323 (0.1564)  loss_rpn_box_reg: 0.0694 (0.0750)  time: 0.6244  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [32]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.0324 (6.2127)  loss_classifier: 5.5987 (5.7414)  loss_box_reg: 0.2298 (0.2392)  loss_objectness: 0.1394 (0.1566)  loss_rpn_box_reg: 0.0750 (0.0755)  time: 0.6214  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [32]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.2327 (6.2154)  loss_classifier: 5.7388 (5.7462)  loss_box_reg: 0.1978 (0.2380)  loss_objectness: 0.1391 (0.1560)  loss_rpn_box_reg: 0.0741 (0.0752)  time: 0.6272  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [32]  [320/500]  eta: 0:01:53  lr: 0.000000  loss: 6.2327 (6.2175)  loss_classifier: 5.7388 (5.7491)  loss_box_reg: 0.2060 (0.2376)  loss_objectness: 0.1332 (0.1559)  loss_rpn_box_reg: 0.0590 (0.0749)  time: 0.6444  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [32]  [330/500]  eta: 0:01:47  lr: 0.000000  loss: 6.2329 (6.2209)  loss_classifier: 5.8486 (5.7530)  loss_box_reg: 0.2216 (0.2374)  loss_objectness: 0.1427 (0.1557)  loss_rpn_box_reg: 0.0625 (0.0748)  time: 0.6534  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [32]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.2523 (6.2247)  loss_classifier: 5.7532 (5.7575)  loss_box_reg: 0.2201 (0.2372)  loss_objectness: 0.1427 (0.1553)  loss_rpn_box_reg: 0.0703 (0.0747)  time: 0.6481  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [32]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 5.9842 (6.2189)  loss_classifier: 5.5108 (5.7517)  loss_box_reg: 0.2316 (0.2375)  loss_objectness: 0.1333 (0.1549)  loss_rpn_box_reg: 0.0667 (0.0748)  time: 0.6393  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [32]  [360/500]  eta: 0:01:28  lr: 0.000000  loss: 5.8396 (6.2145)  loss_classifier: 5.3645 (5.7476)  loss_box_reg: 0.2351 (0.2374)  loss_objectness: 0.1333 (0.1546)  loss_rpn_box_reg: 0.0770 (0.0749)  time: 0.6362  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [32]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 5.9674 (6.2047)  loss_classifier: 5.4767 (5.7388)  loss_box_reg: 0.2351 (0.2373)  loss_objectness: 0.1366 (0.1543)  loss_rpn_box_reg: 0.0589 (0.0742)  time: 0.6278  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [32]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.0041 (6.2028)  loss_classifier: 5.5559 (5.7383)  loss_box_reg: 0.1991 (0.2366)  loss_objectness: 0.1402 (0.1539)  loss_rpn_box_reg: 0.0529 (0.0740)  time: 0.6385  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [32]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 6.2986 (6.2075)  loss_classifier: 5.8680 (5.7443)  loss_box_reg: 0.1981 (0.2358)  loss_objectness: 0.1394 (0.1536)  loss_rpn_box_reg: 0.0480 (0.0738)  time: 0.6330  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [32]  [400/500]  eta: 0:01:03  lr: 0.000000  loss: 6.3102 (6.2106)  loss_classifier: 5.8962 (5.7484)  loss_box_reg: 0.2037 (0.2354)  loss_objectness: 0.1322 (0.1531)  loss_rpn_box_reg: 0.0577 (0.0737)  time: 0.6194  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [32]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2065 (6.2109)  loss_classifier: 5.7797 (5.7492)  loss_box_reg: 0.2037 (0.2349)  loss_objectness: 0.1408 (0.1531)  loss_rpn_box_reg: 0.0615 (0.0737)  time: 0.6207  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [32]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.2250 (6.2107)  loss_classifier: 5.6740 (5.7467)  loss_box_reg: 0.2461 (0.2360)  loss_objectness: 0.1577 (0.1535)  loss_rpn_box_reg: 0.0692 (0.0745)  time: 0.6192  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [32]  [430/500]  eta: 0:00:44  lr: 0.000000  loss: 6.2446 (6.2116)  loss_classifier: 5.6731 (5.7471)  loss_box_reg: 0.2440 (0.2358)  loss_objectness: 0.1626 (0.1535)  loss_rpn_box_reg: 0.1001 (0.0752)  time: 0.6159  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [32]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2446 (6.2114)  loss_classifier: 5.7805 (5.7464)  loss_box_reg: 0.2299 (0.2361)  loss_objectness: 0.1494 (0.1536)  loss_rpn_box_reg: 0.0972 (0.0753)  time: 0.6208  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [32]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.2019 (6.2116)  loss_classifier: 5.7805 (5.7469)  loss_box_reg: 0.2218 (0.2354)  loss_objectness: 0.1595 (0.1537)  loss_rpn_box_reg: 0.0879 (0.0756)  time: 0.6314  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [32]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.2019 (6.2104)  loss_classifier: 5.7412 (5.7444)  loss_box_reg: 0.2284 (0.2365)  loss_objectness: 0.1595 (0.1537)  loss_rpn_box_reg: 0.0833 (0.0759)  time: 0.6350  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [32]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1666 (6.2107)  loss_classifier: 5.6710 (5.7446)  loss_box_reg: 0.2745 (0.2365)  loss_objectness: 0.1542 (0.1536)  loss_rpn_box_reg: 0.0807 (0.0760)  time: 0.6358  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [32]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1485 (6.2104)  loss_classifier: 5.6115 (5.7434)  loss_box_reg: 0.2615 (0.2373)  loss_objectness: 0.1397 (0.1534)  loss_rpn_box_reg: 0.0820 (0.0762)  time: 0.6241  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [32]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1581 (6.2108)  loss_classifier: 5.6306 (5.7442)  loss_box_reg: 0.2324 (0.2373)  loss_objectness: 0.1369 (0.1532)  loss_rpn_box_reg: 0.0679 (0.0761)  time: 0.6228  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [32]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1581 (6.2143)  loss_classifier: 5.7326 (5.7480)  loss_box_reg: 0.2324 (0.2377)  loss_objectness: 0.1363 (0.1528)  loss_rpn_box_reg: 0.0582 (0.0758)  time: 0.6338  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [32] Total time: 0:05:14 (0.6294 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:04  model_time: 0.7242 (0.7242)  evaluator_time: 0.1200 (0.1200)  time: 0.9952  data: 0.1410  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4481 (0.4546)  evaluator_time: 0.0340 (0.0350)  time: 0.6405  data: 0.1536  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4761 (0.4562)  evaluator_time: 0.0350 (0.0357)  time: 0.6569  data: 0.1482  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6447 s / it)\n",
      "Averaged stats: model_time: 0.4761 (0.4562)  evaluator_time: 0.0350 (0.0357)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [32]  [  0/125]  eta: 0:01:31  lr: 0.000000  loss: 6.2254 (6.2254)  loss_classifier: 5.6664 (5.6664)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1329 (0.1329)  loss_rpn_box_reg: 0.1316 (0.1316)  time: 0.7352  data: 0.2341  max mem: 10734\n",
      "Testing Epoch: [32]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9994 (6.1222)  loss_classifier: 5.4311 (5.6106)  loss_box_reg: 0.2609 (0.2901)  loss_objectness: 0.1296 (0.1317)  loss_rpn_box_reg: 0.0730 (0.0899)  time: 0.5876  data: 0.1456  max mem: 10734\n",
      "Testing Epoch: [32]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1534 (6.1553)  loss_classifier: 5.6799 (5.6482)  loss_box_reg: 0.2500 (0.2854)  loss_objectness: 0.1202 (0.1318)  loss_rpn_box_reg: 0.0745 (0.0900)  time: 0.6037  data: 0.1471  max mem: 10734\n",
      "Testing Epoch: [32] Total time: 0:01:15 (0.6002 s / it)\n",
      "Training Epoch: [33]  [  0/500]  eta: 0:06:06  lr: 0.000000  loss: 6.0879 (6.0879)  loss_classifier: 5.6427 (5.6427)  loss_box_reg: 0.2754 (0.2754)  loss_objectness: 0.1274 (0.1274)  loss_rpn_box_reg: 0.0423 (0.0423)  time: 0.7332  data: 0.1310  max mem: 10734\n",
      "Training Epoch: [33]  [ 10/500]  eta: 0:05:06  lr: 0.000000  loss: 6.3344 (6.3013)  loss_classifier: 5.8499 (5.7927)  loss_box_reg: 0.2757 (0.2763)  loss_objectness: 0.1496 (0.1555)  loss_rpn_box_reg: 0.0733 (0.0768)  time: 0.6260  data: 0.1382  max mem: 10734\n",
      "Training Epoch: [33]  [ 20/500]  eta: 0:05:02  lr: 0.000000  loss: 6.2506 (6.2205)  loss_classifier: 5.7298 (5.7589)  loss_box_reg: 0.2196 (0.2410)  loss_objectness: 0.1496 (0.1534)  loss_rpn_box_reg: 0.0680 (0.0671)  time: 0.6258  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [33]  [ 30/500]  eta: 0:04:58  lr: 0.000000  loss: 6.1072 (6.2264)  loss_classifier: 5.7030 (5.7628)  loss_box_reg: 0.2194 (0.2417)  loss_objectness: 0.1372 (0.1513)  loss_rpn_box_reg: 0.0578 (0.0707)  time: 0.6401  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [33]  [ 40/500]  eta: 0:04:52  lr: 0.000000  loss: 6.2666 (6.2842)  loss_classifier: 5.7740 (5.8121)  loss_box_reg: 0.2543 (0.2422)  loss_objectness: 0.1506 (0.1552)  loss_rpn_box_reg: 0.0867 (0.0747)  time: 0.6403  data: 0.1382  max mem: 10734\n",
      "Training Epoch: [33]  [ 50/500]  eta: 0:04:44  lr: 0.000000  loss: 6.2838 (6.2454)  loss_classifier: 5.8828 (5.7797)  loss_box_reg: 0.2383 (0.2380)  loss_objectness: 0.1571 (0.1536)  loss_rpn_box_reg: 0.0831 (0.0741)  time: 0.6279  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [33]  [ 60/500]  eta: 0:04:37  lr: 0.000000  loss: 6.1669 (6.2348)  loss_classifier: 5.7473 (5.7740)  loss_box_reg: 0.2247 (0.2375)  loss_objectness: 0.1424 (0.1519)  loss_rpn_box_reg: 0.0565 (0.0713)  time: 0.6211  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [33]  [ 70/500]  eta: 0:04:29  lr: 0.000000  loss: 5.9756 (6.1961)  loss_classifier: 5.5856 (5.7339)  loss_box_reg: 0.2164 (0.2373)  loss_objectness: 0.1369 (0.1530)  loss_rpn_box_reg: 0.0604 (0.0718)  time: 0.6160  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [33]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 5.7327 (6.1577)  loss_classifier: 5.3433 (5.7013)  loss_box_reg: 0.2127 (0.2347)  loss_objectness: 0.1333 (0.1504)  loss_rpn_box_reg: 0.0708 (0.0714)  time: 0.6206  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [33]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 5.9797 (6.1511)  loss_classifier: 5.5608 (5.6965)  loss_box_reg: 0.2070 (0.2330)  loss_objectness: 0.1354 (0.1507)  loss_rpn_box_reg: 0.0634 (0.0709)  time: 0.6283  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [33]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 6.1694 (6.1622)  loss_classifier: 5.7153 (5.7035)  loss_box_reg: 0.2425 (0.2373)  loss_objectness: 0.1438 (0.1498)  loss_rpn_box_reg: 0.0709 (0.0716)  time: 0.6320  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [33]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.1064 (6.1555)  loss_classifier: 5.4570 (5.6967)  loss_box_reg: 0.2677 (0.2379)  loss_objectness: 0.1391 (0.1488)  loss_rpn_box_reg: 0.0780 (0.0721)  time: 0.6260  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [33]  [120/500]  eta: 0:03:59  lr: 0.000000  loss: 6.0505 (6.1572)  loss_classifier: 5.5822 (5.6973)  loss_box_reg: 0.2645 (0.2403)  loss_objectness: 0.1323 (0.1477)  loss_rpn_box_reg: 0.0543 (0.0719)  time: 0.6308  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [33]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 6.1493 (6.1656)  loss_classifier: 5.6672 (5.7072)  loss_box_reg: 0.2590 (0.2387)  loss_objectness: 0.1357 (0.1477)  loss_rpn_box_reg: 0.0616 (0.0720)  time: 0.6385  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [33]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.1493 (6.1692)  loss_classifier: 5.8486 (5.7126)  loss_box_reg: 0.1839 (0.2364)  loss_objectness: 0.1471 (0.1481)  loss_rpn_box_reg: 0.0583 (0.0720)  time: 0.6321  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [33]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.0585 (6.1608)  loss_classifier: 5.5908 (5.7043)  loss_box_reg: 0.1981 (0.2347)  loss_objectness: 0.1478 (0.1486)  loss_rpn_box_reg: 0.0661 (0.0732)  time: 0.6199  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [33]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 5.9838 (6.1562)  loss_classifier: 5.5611 (5.6984)  loss_box_reg: 0.2200 (0.2357)  loss_objectness: 0.1538 (0.1492)  loss_rpn_box_reg: 0.0682 (0.0729)  time: 0.6221  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [33]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.0763 (6.1651)  loss_classifier: 5.6484 (5.7061)  loss_box_reg: 0.2190 (0.2350)  loss_objectness: 0.1573 (0.1497)  loss_rpn_box_reg: 0.0687 (0.0742)  time: 0.6341  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [33]  [180/500]  eta: 0:03:21  lr: 0.000000  loss: 6.2637 (6.1726)  loss_classifier: 5.7943 (5.7143)  loss_box_reg: 0.2146 (0.2341)  loss_objectness: 0.1582 (0.1498)  loss_rpn_box_reg: 0.0749 (0.0744)  time: 0.6447  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [33]  [190/500]  eta: 0:03:15  lr: 0.000000  loss: 6.3532 (6.1830)  loss_classifier: 5.8191 (5.7236)  loss_box_reg: 0.2206 (0.2335)  loss_objectness: 0.1454 (0.1502)  loss_rpn_box_reg: 0.0903 (0.0758)  time: 0.6396  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [33]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.2583 (6.1817)  loss_classifier: 5.7508 (5.7235)  loss_box_reg: 0.2314 (0.2338)  loss_objectness: 0.1396 (0.1493)  loss_rpn_box_reg: 0.0722 (0.0750)  time: 0.6239  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [33]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.0240 (6.1745)  loss_classifier: 5.6344 (5.7164)  loss_box_reg: 0.2327 (0.2341)  loss_objectness: 0.1396 (0.1493)  loss_rpn_box_reg: 0.0606 (0.0748)  time: 0.6355  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [33]  [220/500]  eta: 0:02:56  lr: 0.000000  loss: 6.2109 (6.2031)  loss_classifier: 5.7249 (5.7435)  loss_box_reg: 0.2492 (0.2354)  loss_objectness: 0.1593 (0.1499)  loss_rpn_box_reg: 0.0681 (0.0744)  time: 0.6256  data: 0.1375  max mem: 10734\n",
      "Training Epoch: [33]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.2138 (6.2029)  loss_classifier: 5.7725 (5.7428)  loss_box_reg: 0.2531 (0.2358)  loss_objectness: 0.1451 (0.1499)  loss_rpn_box_reg: 0.0681 (0.0744)  time: 0.6137  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [33]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.2563 (6.2118)  loss_classifier: 5.7604 (5.7514)  loss_box_reg: 0.2319 (0.2362)  loss_objectness: 0.1451 (0.1498)  loss_rpn_box_reg: 0.0709 (0.0743)  time: 0.6160  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [33]  [250/500]  eta: 0:02:37  lr: 0.000000  loss: 6.3280 (6.2190)  loss_classifier: 5.8605 (5.7584)  loss_box_reg: 0.2201 (0.2355)  loss_objectness: 0.1553 (0.1506)  loss_rpn_box_reg: 0.0694 (0.0746)  time: 0.6209  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [33]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.2242 (6.2168)  loss_classifier: 5.7721 (5.7566)  loss_box_reg: 0.2196 (0.2353)  loss_objectness: 0.1626 (0.1506)  loss_rpn_box_reg: 0.0694 (0.0743)  time: 0.6207  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [33]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.1937 (6.2142)  loss_classifier: 5.6959 (5.7545)  loss_box_reg: 0.2276 (0.2353)  loss_objectness: 0.1417 (0.1500)  loss_rpn_box_reg: 0.0737 (0.0744)  time: 0.6298  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [33]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.3357 (6.2260)  loss_classifier: 5.8896 (5.7645)  loss_box_reg: 0.2382 (0.2355)  loss_objectness: 0.1530 (0.1509)  loss_rpn_box_reg: 0.0763 (0.0752)  time: 0.6468  data: 0.1370  max mem: 10734\n",
      "Training Epoch: [33]  [290/500]  eta: 0:02:12  lr: 0.000000  loss: 6.5201 (6.2345)  loss_classifier: 6.0412 (5.7725)  loss_box_reg: 0.2277 (0.2353)  loss_objectness: 0.1629 (0.1518)  loss_rpn_box_reg: 0.0797 (0.0749)  time: 0.6362  data: 0.1375  max mem: 10734\n",
      "Training Epoch: [33]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.2493 (6.2319)  loss_classifier: 5.7245 (5.7685)  loss_box_reg: 0.2407 (0.2369)  loss_objectness: 0.1569 (0.1515)  loss_rpn_box_reg: 0.0724 (0.0750)  time: 0.6041  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [33]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.1092 (6.2300)  loss_classifier: 5.5608 (5.7657)  loss_box_reg: 0.2755 (0.2373)  loss_objectness: 0.1556 (0.1516)  loss_rpn_box_reg: 0.0860 (0.0754)  time: 0.6094  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [33]  [320/500]  eta: 0:01:53  lr: 0.000000  loss: 6.2292 (6.2304)  loss_classifier: 5.7281 (5.7659)  loss_box_reg: 0.2349 (0.2376)  loss_objectness: 0.1503 (0.1514)  loss_rpn_box_reg: 0.0832 (0.0757)  time: 0.6334  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [33]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 5.9742 (6.2223)  loss_classifier: 5.5432 (5.7581)  loss_box_reg: 0.2455 (0.2382)  loss_objectness: 0.1366 (0.1506)  loss_rpn_box_reg: 0.0661 (0.0753)  time: 0.6265  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [33]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 5.8873 (6.2163)  loss_classifier: 5.5343 (5.7519)  loss_box_reg: 0.2471 (0.2380)  loss_objectness: 0.1344 (0.1508)  loss_rpn_box_reg: 0.0605 (0.0755)  time: 0.6228  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [33]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.0606 (6.2150)  loss_classifier: 5.6143 (5.7515)  loss_box_reg: 0.2371 (0.2377)  loss_objectness: 0.1376 (0.1506)  loss_rpn_box_reg: 0.0582 (0.0752)  time: 0.6304  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [33]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.0606 (6.2089)  loss_classifier: 5.6314 (5.7459)  loss_box_reg: 0.2176 (0.2379)  loss_objectness: 0.1292 (0.1502)  loss_rpn_box_reg: 0.0582 (0.0749)  time: 0.6348  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [33]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.0910 (6.2125)  loss_classifier: 5.6314 (5.7485)  loss_box_reg: 0.2728 (0.2390)  loss_objectness: 0.1408 (0.1504)  loss_rpn_box_reg: 0.0584 (0.0746)  time: 0.6320  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [33]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1582 (6.2120)  loss_classifier: 5.6042 (5.7463)  loss_box_reg: 0.2773 (0.2404)  loss_objectness: 0.1525 (0.1506)  loss_rpn_box_reg: 0.0726 (0.0748)  time: 0.6355  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [33]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 6.0211 (6.2076)  loss_classifier: 5.5474 (5.7400)  loss_box_reg: 0.2515 (0.2412)  loss_objectness: 0.1610 (0.1511)  loss_rpn_box_reg: 0.0838 (0.0753)  time: 0.6286  data: 0.1370  max mem: 10734\n",
      "Training Epoch: [33]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 5.9305 (6.2097)  loss_classifier: 5.3837 (5.7423)  loss_box_reg: 0.2447 (0.2413)  loss_objectness: 0.1542 (0.1511)  loss_rpn_box_reg: 0.0831 (0.0751)  time: 0.6212  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [33]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 5.9881 (6.2056)  loss_classifier: 5.4968 (5.7386)  loss_box_reg: 0.2295 (0.2412)  loss_objectness: 0.1422 (0.1510)  loss_rpn_box_reg: 0.0610 (0.0748)  time: 0.6260  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [33]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.0570 (6.2085)  loss_classifier: 5.6105 (5.7410)  loss_box_reg: 0.2295 (0.2415)  loss_objectness: 0.1427 (0.1511)  loss_rpn_box_reg: 0.0679 (0.0750)  time: 0.6268  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [33]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2482 (6.2168)  loss_classifier: 5.8607 (5.7501)  loss_box_reg: 0.2253 (0.2411)  loss_objectness: 0.1417 (0.1507)  loss_rpn_box_reg: 0.0666 (0.0749)  time: 0.6166  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [33]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2840 (6.2163)  loss_classifier: 5.8561 (5.7492)  loss_box_reg: 0.2395 (0.2410)  loss_objectness: 0.1495 (0.1512)  loss_rpn_box_reg: 0.0656 (0.0750)  time: 0.6212  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [33]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.2101 (6.2149)  loss_classifier: 5.7793 (5.7485)  loss_box_reg: 0.2234 (0.2403)  loss_objectness: 0.1495 (0.1511)  loss_rpn_box_reg: 0.0724 (0.0749)  time: 0.6282  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [33]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.2278 (6.2139)  loss_classifier: 5.7092 (5.7469)  loss_box_reg: 0.2201 (0.2404)  loss_objectness: 0.1455 (0.1512)  loss_rpn_box_reg: 0.0921 (0.0754)  time: 0.6291  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [33]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1860 (6.2111)  loss_classifier: 5.6596 (5.7435)  loss_box_reg: 0.2423 (0.2404)  loss_objectness: 0.1556 (0.1516)  loss_rpn_box_reg: 0.0967 (0.0756)  time: 0.6359  data: 0.1374  max mem: 10734\n",
      "Training Epoch: [33]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1556 (6.2113)  loss_classifier: 5.7065 (5.7444)  loss_box_reg: 0.2491 (0.2402)  loss_objectness: 0.1559 (0.1514)  loss_rpn_box_reg: 0.0670 (0.0753)  time: 0.6379  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [33]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0573 (6.2089)  loss_classifier: 5.6202 (5.7415)  loss_box_reg: 0.2573 (0.2403)  loss_objectness: 0.1440 (0.1515)  loss_rpn_box_reg: 0.0718 (0.0757)  time: 0.6242  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [33]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0880 (6.2093)  loss_classifier: 5.6249 (5.7418)  loss_box_reg: 0.2353 (0.2401)  loss_objectness: 0.1440 (0.1516)  loss_rpn_box_reg: 0.0726 (0.0758)  time: 0.6210  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [33] Total time: 0:05:13 (0.6279 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:54  model_time: 0.7312 (0.7312)  evaluator_time: 0.0340 (0.0340)  time: 0.9172  data: 0.1420  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4421 (0.4541)  evaluator_time: 0.0340 (0.0361)  time: 0.6309  data: 0.1478  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4691 (0.4555)  evaluator_time: 0.0360 (0.0366)  time: 0.6530  data: 0.1474  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6441 s / it)\n",
      "Averaged stats: model_time: 0.4691 (0.4555)  evaluator_time: 0.0360 (0.0366)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [33]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.2033 (6.2033)  loss_classifier: 5.6478 (5.6478)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1261 (0.1261)  loss_rpn_box_reg: 0.1349 (0.1349)  time: 0.6451  data: 0.1450  max mem: 10734\n",
      "Testing Epoch: [33]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0079 (6.1298)  loss_classifier: 5.4336 (5.6196)  loss_box_reg: 0.2609 (0.2891)  loss_objectness: 0.1337 (0.1312)  loss_rpn_box_reg: 0.0705 (0.0899)  time: 0.5864  data: 0.1452  max mem: 10734\n",
      "Testing Epoch: [33]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1745 (6.1624)  loss_classifier: 5.6879 (5.6564)  loss_box_reg: 0.2500 (0.2846)  loss_objectness: 0.1185 (0.1314)  loss_rpn_box_reg: 0.0745 (0.0900)  time: 0.6017  data: 0.1449  max mem: 10734\n",
      "Testing Epoch: [33] Total time: 0:01:14 (0.5992 s / it)\n",
      "Training Epoch: [34]  [  0/500]  eta: 0:06:37  lr: 0.000000  loss: 6.1167 (6.1167)  loss_classifier: 5.5730 (5.5730)  loss_box_reg: 0.2879 (0.2879)  loss_objectness: 0.1840 (0.1840)  loss_rpn_box_reg: 0.0718 (0.0718)  time: 0.7942  data: 0.1400  max mem: 10734\n",
      "Training Epoch: [34]  [ 10/500]  eta: 0:05:07  lr: 0.000000  loss: 6.0416 (6.0531)  loss_classifier: 5.5398 (5.5772)  loss_box_reg: 0.2575 (0.2523)  loss_objectness: 0.1379 (0.1478)  loss_rpn_box_reg: 0.0789 (0.0759)  time: 0.6271  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [34]  [ 20/500]  eta: 0:04:57  lr: 0.000000  loss: 6.0416 (6.0978)  loss_classifier: 5.5398 (5.6141)  loss_box_reg: 0.2506 (0.2531)  loss_objectness: 0.1467 (0.1543)  loss_rpn_box_reg: 0.0763 (0.0763)  time: 0.6102  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [34]  [ 30/500]  eta: 0:04:51  lr: 0.000000  loss: 6.3400 (6.2186)  loss_classifier: 5.7644 (5.7463)  loss_box_reg: 0.2506 (0.2473)  loss_objectness: 0.1547 (0.1501)  loss_rpn_box_reg: 0.0655 (0.0749)  time: 0.6178  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [34]  [ 40/500]  eta: 0:04:46  lr: 0.000000  loss: 6.3552 (6.2648)  loss_classifier: 5.9407 (5.7961)  loss_box_reg: 0.2431 (0.2487)  loss_objectness: 0.1346 (0.1469)  loss_rpn_box_reg: 0.0650 (0.0731)  time: 0.6277  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [34]  [ 50/500]  eta: 0:04:39  lr: 0.000000  loss: 6.3156 (6.2591)  loss_classifier: 5.9407 (5.7843)  loss_box_reg: 0.2424 (0.2506)  loss_objectness: 0.1489 (0.1501)  loss_rpn_box_reg: 0.0696 (0.0742)  time: 0.6190  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [34]  [ 60/500]  eta: 0:04:33  lr: 0.000000  loss: 6.3059 (6.2664)  loss_classifier: 5.7785 (5.7874)  loss_box_reg: 0.2424 (0.2508)  loss_objectness: 0.1604 (0.1514)  loss_rpn_box_reg: 0.0789 (0.0769)  time: 0.6149  data: 0.1385  max mem: 10734\n",
      "Training Epoch: [34]  [ 70/500]  eta: 0:04:26  lr: 0.000000  loss: 6.1191 (6.2367)  loss_classifier: 5.6620 (5.7516)  loss_box_reg: 0.2456 (0.2534)  loss_objectness: 0.1481 (0.1549)  loss_rpn_box_reg: 0.0767 (0.0767)  time: 0.6210  data: 0.1392  max mem: 10734\n",
      "Training Epoch: [34]  [ 80/500]  eta: 0:04:20  lr: 0.000000  loss: 6.0094 (6.1920)  loss_classifier: 5.4370 (5.7111)  loss_box_reg: 0.2591 (0.2523)  loss_objectness: 0.1411 (0.1521)  loss_rpn_box_reg: 0.0691 (0.0765)  time: 0.6204  data: 0.1374  max mem: 10734\n",
      "Training Epoch: [34]  [ 90/500]  eta: 0:04:15  lr: 0.000000  loss: 5.7689 (6.1804)  loss_classifier: 5.3242 (5.7040)  loss_box_reg: 0.2248 (0.2468)  loss_objectness: 0.1417 (0.1527)  loss_rpn_box_reg: 0.0691 (0.0770)  time: 0.6304  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [34]  [100/500]  eta: 0:04:09  lr: 0.000000  loss: 6.2633 (6.1943)  loss_classifier: 5.7423 (5.7206)  loss_box_reg: 0.2092 (0.2453)  loss_objectness: 0.1565 (0.1525)  loss_rpn_box_reg: 0.0680 (0.0759)  time: 0.6399  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [34]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.2085 (6.1890)  loss_classifier: 5.7423 (5.7173)  loss_box_reg: 0.2092 (0.2427)  loss_objectness: 0.1508 (0.1523)  loss_rpn_box_reg: 0.0680 (0.0768)  time: 0.6447  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [34]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.3552 (6.2097)  loss_classifier: 5.7849 (5.7355)  loss_box_reg: 0.2257 (0.2440)  loss_objectness: 0.1467 (0.1531)  loss_rpn_box_reg: 0.0771 (0.0770)  time: 0.6253  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [34]  [130/500]  eta: 0:03:50  lr: 0.000000  loss: 6.2069 (6.2045)  loss_classifier: 5.8560 (5.7304)  loss_box_reg: 0.2434 (0.2430)  loss_objectness: 0.1467 (0.1537)  loss_rpn_box_reg: 0.0876 (0.0774)  time: 0.6099  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [34]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 6.1056 (6.2011)  loss_classifier: 5.6535 (5.7261)  loss_box_reg: 0.2200 (0.2442)  loss_objectness: 0.1324 (0.1528)  loss_rpn_box_reg: 0.0867 (0.0779)  time: 0.6178  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [34]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.1810 (6.2018)  loss_classifier: 5.7409 (5.7277)  loss_box_reg: 0.2483 (0.2447)  loss_objectness: 0.1264 (0.1527)  loss_rpn_box_reg: 0.0672 (0.0768)  time: 0.6270  data: 0.1376  max mem: 10734\n",
      "Training Epoch: [34]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.1810 (6.1963)  loss_classifier: 5.7385 (5.7223)  loss_box_reg: 0.2420 (0.2440)  loss_objectness: 0.1371 (0.1525)  loss_rpn_box_reg: 0.0692 (0.0775)  time: 0.6331  data: 0.1386  max mem: 10734\n",
      "Training Epoch: [34]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.1528 (6.2100)  loss_classifier: 5.7164 (5.7384)  loss_box_reg: 0.2208 (0.2428)  loss_objectness: 0.1371 (0.1523)  loss_rpn_box_reg: 0.0728 (0.0766)  time: 0.6468  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [34]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.3163 (6.2115)  loss_classifier: 5.8055 (5.7386)  loss_box_reg: 0.2377 (0.2436)  loss_objectness: 0.1519 (0.1528)  loss_rpn_box_reg: 0.0687 (0.0766)  time: 0.6489  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [34]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.3409 (6.2222)  loss_classifier: 5.8529 (5.7497)  loss_box_reg: 0.2293 (0.2431)  loss_objectness: 0.1519 (0.1530)  loss_rpn_box_reg: 0.0695 (0.0764)  time: 0.6419  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [34]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.3909 (6.2220)  loss_classifier: 5.9276 (5.7501)  loss_box_reg: 0.2380 (0.2436)  loss_objectness: 0.1451 (0.1524)  loss_rpn_box_reg: 0.0724 (0.0760)  time: 0.6397  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [34]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.1210 (6.2251)  loss_classifier: 5.7284 (5.7529)  loss_box_reg: 0.2438 (0.2436)  loss_objectness: 0.1436 (0.1524)  loss_rpn_box_reg: 0.0738 (0.0762)  time: 0.6380  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [34]  [220/500]  eta: 0:02:56  lr: 0.000000  loss: 6.1132 (6.2156)  loss_classifier: 5.6451 (5.7430)  loss_box_reg: 0.2526 (0.2446)  loss_objectness: 0.1436 (0.1520)  loss_rpn_box_reg: 0.0670 (0.0761)  time: 0.6283  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [34]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.0501 (6.2129)  loss_classifier: 5.6225 (5.7413)  loss_box_reg: 0.2336 (0.2433)  loss_objectness: 0.1395 (0.1523)  loss_rpn_box_reg: 0.0605 (0.0760)  time: 0.6248  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [34]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.2872 (6.2226)  loss_classifier: 5.7350 (5.7491)  loss_box_reg: 0.2480 (0.2442)  loss_objectness: 0.1564 (0.1533)  loss_rpn_box_reg: 0.0711 (0.0760)  time: 0.6267  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [34]  [250/500]  eta: 0:02:37  lr: 0.000000  loss: 6.2907 (6.2301)  loss_classifier: 5.8548 (5.7566)  loss_box_reg: 0.2403 (0.2439)  loss_objectness: 0.1533 (0.1535)  loss_rpn_box_reg: 0.0753 (0.0761)  time: 0.6215  data: 0.1376  max mem: 10734\n",
      "Training Epoch: [34]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.2138 (6.2280)  loss_classifier: 5.7962 (5.7555)  loss_box_reg: 0.2362 (0.2432)  loss_objectness: 0.1484 (0.1536)  loss_rpn_box_reg: 0.0631 (0.0758)  time: 0.6333  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [34]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.0258 (6.2211)  loss_classifier: 5.5152 (5.7478)  loss_box_reg: 0.2390 (0.2433)  loss_objectness: 0.1485 (0.1534)  loss_rpn_box_reg: 0.0782 (0.0767)  time: 0.6399  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [34]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.2447 (6.2247)  loss_classifier: 5.7457 (5.7510)  loss_box_reg: 0.2559 (0.2431)  loss_objectness: 0.1485 (0.1537)  loss_rpn_box_reg: 0.0857 (0.0768)  time: 0.6382  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [34]  [290/500]  eta: 0:02:12  lr: 0.000000  loss: 6.2447 (6.2239)  loss_classifier: 5.7487 (5.7504)  loss_box_reg: 0.2568 (0.2433)  loss_objectness: 0.1463 (0.1535)  loss_rpn_box_reg: 0.0679 (0.0766)  time: 0.6242  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [34]  [300/500]  eta: 0:02:06  lr: 0.000000  loss: 6.2519 (6.2325)  loss_classifier: 5.7988 (5.7601)  loss_box_reg: 0.2264 (0.2428)  loss_objectness: 0.1468 (0.1531)  loss_rpn_box_reg: 0.0618 (0.0764)  time: 0.6384  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [34]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.3147 (6.2312)  loss_classifier: 5.8582 (5.7589)  loss_box_reg: 0.2344 (0.2427)  loss_objectness: 0.1522 (0.1533)  loss_rpn_box_reg: 0.0618 (0.0763)  time: 0.6428  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [34]  [320/500]  eta: 0:01:53  lr: 0.000000  loss: 6.1662 (6.2298)  loss_classifier: 5.7961 (5.7589)  loss_box_reg: 0.2344 (0.2419)  loss_objectness: 0.1522 (0.1530)  loss_rpn_box_reg: 0.0585 (0.0760)  time: 0.6306  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [34]  [330/500]  eta: 0:01:47  lr: 0.000000  loss: 6.1647 (6.2308)  loss_classifier: 5.6752 (5.7584)  loss_box_reg: 0.2356 (0.2428)  loss_objectness: 0.1473 (0.1529)  loss_rpn_box_reg: 0.0734 (0.0768)  time: 0.6352  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [34]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.2412 (6.2342)  loss_classifier: 5.7516 (5.7616)  loss_box_reg: 0.2328 (0.2422)  loss_objectness: 0.1566 (0.1534)  loss_rpn_box_reg: 0.0849 (0.0771)  time: 0.6369  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [34]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.3043 (6.2382)  loss_classifier: 5.9058 (5.7663)  loss_box_reg: 0.2230 (0.2418)  loss_objectness: 0.1690 (0.1532)  loss_rpn_box_reg: 0.0675 (0.0768)  time: 0.6321  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [34]  [360/500]  eta: 0:01:28  lr: 0.000000  loss: 6.2622 (6.2415)  loss_classifier: 5.7660 (5.7691)  loss_box_reg: 0.2217 (0.2417)  loss_objectness: 0.1478 (0.1536)  loss_rpn_box_reg: 0.0749 (0.0771)  time: 0.6220  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [34]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.2025 (6.2400)  loss_classifier: 5.6759 (5.7683)  loss_box_reg: 0.2217 (0.2418)  loss_objectness: 0.1479 (0.1534)  loss_rpn_box_reg: 0.0672 (0.0766)  time: 0.6149  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [34]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1241 (6.2403)  loss_classifier: 5.6686 (5.7692)  loss_box_reg: 0.2247 (0.2409)  loss_objectness: 0.1467 (0.1535)  loss_rpn_box_reg: 0.0681 (0.0768)  time: 0.6174  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [34]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 6.0741 (6.2385)  loss_classifier: 5.5808 (5.7685)  loss_box_reg: 0.2087 (0.2401)  loss_objectness: 0.1439 (0.1534)  loss_rpn_box_reg: 0.0615 (0.0764)  time: 0.6338  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [34]  [400/500]  eta: 0:01:03  lr: 0.000000  loss: 6.1133 (6.2375)  loss_classifier: 5.7121 (5.7673)  loss_box_reg: 0.2167 (0.2403)  loss_objectness: 0.1439 (0.1538)  loss_rpn_box_reg: 0.0603 (0.0762)  time: 0.6454  data: 0.1384  max mem: 10734\n",
      "Training Epoch: [34]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2650 (6.2359)  loss_classifier: 5.7224 (5.7657)  loss_box_reg: 0.2247 (0.2402)  loss_objectness: 0.1426 (0.1535)  loss_rpn_box_reg: 0.0672 (0.0765)  time: 0.6351  data: 0.1374  max mem: 10734\n",
      "Training Epoch: [34]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.2770 (6.2384)  loss_classifier: 5.7224 (5.7675)  loss_box_reg: 0.2258 (0.2405)  loss_objectness: 0.1481 (0.1539)  loss_rpn_box_reg: 0.0693 (0.0765)  time: 0.6127  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [34]  [430/500]  eta: 0:00:44  lr: 0.000000  loss: 6.0776 (6.2312)  loss_classifier: 5.5639 (5.7603)  loss_box_reg: 0.2428 (0.2409)  loss_objectness: 0.1569 (0.1537)  loss_rpn_box_reg: 0.0684 (0.0764)  time: 0.6182  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [34]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 5.9434 (6.2266)  loss_classifier: 5.4599 (5.7567)  loss_box_reg: 0.2160 (0.2403)  loss_objectness: 0.1441 (0.1535)  loss_rpn_box_reg: 0.0628 (0.0762)  time: 0.6303  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [34]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0784 (6.2233)  loss_classifier: 5.5853 (5.7534)  loss_box_reg: 0.2160 (0.2402)  loss_objectness: 0.1353 (0.1534)  loss_rpn_box_reg: 0.0780 (0.0763)  time: 0.6271  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [34]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.1530 (6.2254)  loss_classifier: 5.7215 (5.7556)  loss_box_reg: 0.2333 (0.2398)  loss_objectness: 0.1527 (0.1533)  loss_rpn_box_reg: 0.0780 (0.0766)  time: 0.6361  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [34]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2279 (6.2251)  loss_classifier: 5.7383 (5.7567)  loss_box_reg: 0.2209 (0.2391)  loss_objectness: 0.1387 (0.1530)  loss_rpn_box_reg: 0.0727 (0.0763)  time: 0.6493  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [34]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0265 (6.2207)  loss_classifier: 5.5562 (5.7532)  loss_box_reg: 0.2123 (0.2385)  loss_objectness: 0.1387 (0.1529)  loss_rpn_box_reg: 0.0569 (0.0761)  time: 0.6333  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [34]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0265 (6.2196)  loss_classifier: 5.5407 (5.7522)  loss_box_reg: 0.2253 (0.2384)  loss_objectness: 0.1463 (0.1530)  loss_rpn_box_reg: 0.0678 (0.0760)  time: 0.6157  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [34]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0554 (6.2184)  loss_classifier: 5.5533 (5.7514)  loss_box_reg: 0.2286 (0.2379)  loss_objectness: 0.1463 (0.1529)  loss_rpn_box_reg: 0.0716 (0.0762)  time: 0.6228  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [34] Total time: 0:05:14 (0.6295 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:51  model_time: 0.6151 (0.6151)  evaluator_time: 0.0350 (0.0350)  time: 0.8926  data: 0.2334  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4401 (0.4519)  evaluator_time: 0.0340 (0.0380)  time: 0.6394  data: 0.1544  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4791 (0.4543)  evaluator_time: 0.0350 (0.0381)  time: 0.6642  data: 0.1546  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6438 s / it)\n",
      "Averaged stats: model_time: 0.4791 (0.4543)  evaluator_time: 0.0350 (0.0381)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [34]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.2102 (6.2102)  loss_classifier: 5.6584 (5.6584)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1242 (0.1242)  loss_rpn_box_reg: 0.1331 (0.1331)  time: 0.6431  data: 0.1380  max mem: 10734\n",
      "Testing Epoch: [34]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0047 (6.1280)  loss_classifier: 5.4196 (5.6177)  loss_box_reg: 0.2609 (0.2886)  loss_objectness: 0.1323 (0.1319)  loss_rpn_box_reg: 0.0694 (0.0898)  time: 0.5896  data: 0.1457  max mem: 10734\n",
      "Testing Epoch: [34]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1710 (6.1607)  loss_classifier: 5.6974 (5.6547)  loss_box_reg: 0.2500 (0.2842)  loss_objectness: 0.1175 (0.1319)  loss_rpn_box_reg: 0.0745 (0.0899)  time: 0.6010  data: 0.1456  max mem: 10734\n",
      "Testing Epoch: [34] Total time: 0:01:14 (0.5976 s / it)\n",
      "Training Epoch: [35]  [  0/500]  eta: 0:07:42  lr: 0.000000  loss: 7.1928 (7.1928)  loss_classifier: 6.6765 (6.6765)  loss_box_reg: 0.3077 (0.3077)  loss_objectness: 0.1374 (0.1374)  loss_rpn_box_reg: 0.0712 (0.0712)  time: 0.9242  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [35]  [ 10/500]  eta: 0:05:22  lr: 0.000000  loss: 6.0810 (6.2244)  loss_classifier: 5.7542 (5.7638)  loss_box_reg: 0.2488 (0.2442)  loss_objectness: 0.1313 (0.1415)  loss_rpn_box_reg: 0.0586 (0.0749)  time: 0.6582  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [35]  [ 20/500]  eta: 0:05:11  lr: 0.000000  loss: 6.0580 (6.2208)  loss_classifier: 5.5880 (5.7610)  loss_box_reg: 0.2488 (0.2431)  loss_objectness: 0.1306 (0.1472)  loss_rpn_box_reg: 0.0596 (0.0695)  time: 0.6355  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [35]  [ 30/500]  eta: 0:05:00  lr: 0.000000  loss: 6.2384 (6.2158)  loss_classifier: 5.6876 (5.7705)  loss_box_reg: 0.2313 (0.2344)  loss_objectness: 0.1306 (0.1437)  loss_rpn_box_reg: 0.0610 (0.0673)  time: 0.6305  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [35]  [ 40/500]  eta: 0:04:56  lr: 0.000000  loss: 6.1155 (6.1658)  loss_classifier: 5.6887 (5.7205)  loss_box_reg: 0.2109 (0.2343)  loss_objectness: 0.1389 (0.1433)  loss_rpn_box_reg: 0.0539 (0.0676)  time: 0.6390  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [35]  [ 50/500]  eta: 0:04:48  lr: 0.000000  loss: 6.1155 (6.1947)  loss_classifier: 5.6887 (5.7433)  loss_box_reg: 0.2140 (0.2355)  loss_objectness: 0.1447 (0.1460)  loss_rpn_box_reg: 0.0598 (0.0700)  time: 0.6403  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [35]  [ 60/500]  eta: 0:04:41  lr: 0.000000  loss: 6.1885 (6.1909)  loss_classifier: 5.7016 (5.7359)  loss_box_reg: 0.2329 (0.2352)  loss_objectness: 0.1424 (0.1470)  loss_rpn_box_reg: 0.0735 (0.0728)  time: 0.6275  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [35]  [ 70/500]  eta: 0:04:33  lr: 0.000000  loss: 6.0531 (6.1833)  loss_classifier: 5.6409 (5.7242)  loss_box_reg: 0.2349 (0.2378)  loss_objectness: 0.1567 (0.1486)  loss_rpn_box_reg: 0.0693 (0.0727)  time: 0.6222  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [35]  [ 80/500]  eta: 0:04:26  lr: 0.000000  loss: 6.0250 (6.1843)  loss_classifier: 5.5798 (5.7232)  loss_box_reg: 0.2447 (0.2381)  loss_objectness: 0.1454 (0.1488)  loss_rpn_box_reg: 0.0693 (0.0743)  time: 0.6175  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [35]  [ 90/500]  eta: 0:04:19  lr: 0.000000  loss: 6.1145 (6.1727)  loss_classifier: 5.6437 (5.7108)  loss_box_reg: 0.2447 (0.2379)  loss_objectness: 0.1454 (0.1496)  loss_rpn_box_reg: 0.0741 (0.0745)  time: 0.6287  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [35]  [100/500]  eta: 0:04:12  lr: 0.000000  loss: 6.1145 (6.1958)  loss_classifier: 5.6632 (5.7299)  loss_box_reg: 0.2445 (0.2395)  loss_objectness: 0.1465 (0.1510)  loss_rpn_box_reg: 0.0778 (0.0754)  time: 0.6209  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [35]  [110/500]  eta: 0:04:05  lr: 0.000000  loss: 6.1420 (6.1958)  loss_classifier: 5.7301 (5.7300)  loss_box_reg: 0.2352 (0.2401)  loss_objectness: 0.1465 (0.1507)  loss_rpn_box_reg: 0.0802 (0.0751)  time: 0.6161  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [35]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.1179 (6.1809)  loss_classifier: 5.6191 (5.7188)  loss_box_reg: 0.2071 (0.2358)  loss_objectness: 0.1465 (0.1513)  loss_rpn_box_reg: 0.0671 (0.0750)  time: 0.6177  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [35]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 6.0686 (6.1859)  loss_classifier: 5.5958 (5.7231)  loss_box_reg: 0.2163 (0.2360)  loss_objectness: 0.1487 (0.1520)  loss_rpn_box_reg: 0.0710 (0.0748)  time: 0.6184  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [35]  [140/500]  eta: 0:03:47  lr: 0.000000  loss: 6.3677 (6.2102)  loss_classifier: 5.9560 (5.7459)  loss_box_reg: 0.2476 (0.2377)  loss_objectness: 0.1487 (0.1520)  loss_rpn_box_reg: 0.0710 (0.0746)  time: 0.6458  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [35]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 6.2096 (6.1975)  loss_classifier: 5.6815 (5.7323)  loss_box_reg: 0.2476 (0.2389)  loss_objectness: 0.1485 (0.1524)  loss_rpn_box_reg: 0.0595 (0.0739)  time: 0.6410  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [35]  [160/500]  eta: 0:03:34  lr: 0.000000  loss: 6.0493 (6.2048)  loss_classifier: 5.6249 (5.7376)  loss_box_reg: 0.2418 (0.2395)  loss_objectness: 0.1497 (0.1526)  loss_rpn_box_reg: 0.0664 (0.0750)  time: 0.6333  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [35]  [170/500]  eta: 0:03:28  lr: 0.000000  loss: 6.1467 (6.1997)  loss_classifier: 5.6843 (5.7325)  loss_box_reg: 0.2434 (0.2402)  loss_objectness: 0.1420 (0.1524)  loss_rpn_box_reg: 0.0827 (0.0746)  time: 0.6357  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [35]  [180/500]  eta: 0:03:22  lr: 0.000000  loss: 6.1290 (6.1997)  loss_classifier: 5.7693 (5.7337)  loss_box_reg: 0.2380 (0.2399)  loss_objectness: 0.1507 (0.1522)  loss_rpn_box_reg: 0.0552 (0.0739)  time: 0.6306  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [35]  [190/500]  eta: 0:03:15  lr: 0.000000  loss: 6.0944 (6.1978)  loss_classifier: 5.5500 (5.7292)  loss_box_reg: 0.2484 (0.2421)  loss_objectness: 0.1546 (0.1519)  loss_rpn_box_reg: 0.0730 (0.0746)  time: 0.6311  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [35]  [200/500]  eta: 0:03:09  lr: 0.000000  loss: 6.0646 (6.1968)  loss_classifier: 5.5220 (5.7290)  loss_box_reg: 0.2361 (0.2414)  loss_objectness: 0.1382 (0.1515)  loss_rpn_box_reg: 0.0836 (0.0749)  time: 0.6185  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [35]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.1042 (6.1962)  loss_classifier: 5.6428 (5.7275)  loss_box_reg: 0.2283 (0.2422)  loss_objectness: 0.1412 (0.1514)  loss_rpn_box_reg: 0.0692 (0.0751)  time: 0.6155  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [35]  [220/500]  eta: 0:02:56  lr: 0.000000  loss: 6.1703 (6.2043)  loss_classifier: 5.6666 (5.7362)  loss_box_reg: 0.2269 (0.2416)  loss_objectness: 0.1412 (0.1517)  loss_rpn_box_reg: 0.0667 (0.0747)  time: 0.6275  data: 0.1385  max mem: 10734\n",
      "Training Epoch: [35]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.1238 (6.2071)  loss_classifier: 5.7874 (5.7397)  loss_box_reg: 0.2265 (0.2408)  loss_objectness: 0.1487 (0.1516)  loss_rpn_box_reg: 0.0698 (0.0749)  time: 0.6258  data: 0.1380  max mem: 10734\n",
      "Training Epoch: [35]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.1538 (6.2090)  loss_classifier: 5.7874 (5.7410)  loss_box_reg: 0.2265 (0.2415)  loss_objectness: 0.1487 (0.1514)  loss_rpn_box_reg: 0.0805 (0.0751)  time: 0.6204  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [35]  [250/500]  eta: 0:02:37  lr: 0.000000  loss: 6.3494 (6.2225)  loss_classifier: 5.8211 (5.7540)  loss_box_reg: 0.2265 (0.2415)  loss_objectness: 0.1504 (0.1516)  loss_rpn_box_reg: 0.0787 (0.0754)  time: 0.6241  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [35]  [260/500]  eta: 0:02:31  lr: 0.000000  loss: 6.3568 (6.2198)  loss_classifier: 5.9399 (5.7513)  loss_box_reg: 0.2272 (0.2418)  loss_objectness: 0.1504 (0.1513)  loss_rpn_box_reg: 0.0787 (0.0755)  time: 0.6329  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [35]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.3538 (6.2219)  loss_classifier: 5.8284 (5.7533)  loss_box_reg: 0.2272 (0.2415)  loss_objectness: 0.1615 (0.1517)  loss_rpn_box_reg: 0.0543 (0.0754)  time: 0.6344  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [35]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.2517 (6.2270)  loss_classifier: 5.8806 (5.7591)  loss_box_reg: 0.2284 (0.2416)  loss_objectness: 0.1591 (0.1513)  loss_rpn_box_reg: 0.0607 (0.0750)  time: 0.6219  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [35]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.2517 (6.2249)  loss_classifier: 5.7122 (5.7560)  loss_box_reg: 0.2436 (0.2424)  loss_objectness: 0.1476 (0.1512)  loss_rpn_box_reg: 0.0716 (0.0753)  time: 0.6025  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [35]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.1893 (6.2230)  loss_classifier: 5.6895 (5.7537)  loss_box_reg: 0.2436 (0.2424)  loss_objectness: 0.1487 (0.1513)  loss_rpn_box_reg: 0.0811 (0.0755)  time: 0.6050  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [35]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.1396 (6.2183)  loss_classifier: 5.6637 (5.7499)  loss_box_reg: 0.2273 (0.2417)  loss_objectness: 0.1474 (0.1508)  loss_rpn_box_reg: 0.0811 (0.0758)  time: 0.6267  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [35]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1652 (6.2223)  loss_classifier: 5.7007 (5.7541)  loss_box_reg: 0.2273 (0.2419)  loss_objectness: 0.1484 (0.1508)  loss_rpn_box_reg: 0.0637 (0.0755)  time: 0.6205  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [35]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.3545 (6.2249)  loss_classifier: 5.9299 (5.7555)  loss_box_reg: 0.2447 (0.2427)  loss_objectness: 0.1520 (0.1509)  loss_rpn_box_reg: 0.0662 (0.0759)  time: 0.6245  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [35]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.3102 (6.2231)  loss_classifier: 5.8579 (5.7549)  loss_box_reg: 0.2173 (0.2425)  loss_objectness: 0.1428 (0.1507)  loss_rpn_box_reg: 0.0518 (0.0750)  time: 0.6315  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [35]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.0054 (6.2175)  loss_classifier: 5.5587 (5.7494)  loss_box_reg: 0.2270 (0.2424)  loss_objectness: 0.1395 (0.1508)  loss_rpn_box_reg: 0.0515 (0.0748)  time: 0.6178  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [35]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1788 (6.2200)  loss_classifier: 5.6369 (5.7511)  loss_box_reg: 0.2392 (0.2423)  loss_objectness: 0.1668 (0.1519)  loss_rpn_box_reg: 0.0656 (0.0747)  time: 0.6260  data: 0.1390  max mem: 10734\n",
      "Training Epoch: [35]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1922 (6.2192)  loss_classifier: 5.7101 (5.7505)  loss_box_reg: 0.2235 (0.2415)  loss_objectness: 0.1628 (0.1520)  loss_rpn_box_reg: 0.0734 (0.0751)  time: 0.6348  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [35]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1777 (6.2175)  loss_classifier: 5.6966 (5.7490)  loss_box_reg: 0.2397 (0.2417)  loss_objectness: 0.1519 (0.1517)  loss_rpn_box_reg: 0.0734 (0.0751)  time: 0.6334  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [35]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 6.1153 (6.2216)  loss_classifier: 5.6966 (5.7546)  loss_box_reg: 0.2239 (0.2405)  loss_objectness: 0.1449 (0.1516)  loss_rpn_box_reg: 0.0620 (0.0749)  time: 0.6332  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [35]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.4000 (6.2291)  loss_classifier: 5.9208 (5.7631)  loss_box_reg: 0.2124 (0.2399)  loss_objectness: 0.1436 (0.1512)  loss_rpn_box_reg: 0.0659 (0.0749)  time: 0.6402  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [35]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2291 (6.2267)  loss_classifier: 5.8124 (5.7599)  loss_box_reg: 0.2375 (0.2401)  loss_objectness: 0.1448 (0.1514)  loss_rpn_box_reg: 0.0760 (0.0754)  time: 0.6383  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [35]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.0656 (6.2202)  loss_classifier: 5.5723 (5.7539)  loss_box_reg: 0.2327 (0.2398)  loss_objectness: 0.1518 (0.1510)  loss_rpn_box_reg: 0.0781 (0.0755)  time: 0.6255  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [35]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.0708 (6.2186)  loss_classifier: 5.6380 (5.7521)  loss_box_reg: 0.2280 (0.2401)  loss_objectness: 0.1305 (0.1508)  loss_rpn_box_reg: 0.0778 (0.0756)  time: 0.6294  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [35]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1917 (6.2201)  loss_classifier: 5.7104 (5.7540)  loss_box_reg: 0.2125 (0.2396)  loss_objectness: 0.1334 (0.1509)  loss_rpn_box_reg: 0.0688 (0.0757)  time: 0.6254  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [35]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1895 (6.2190)  loss_classifier: 5.7543 (5.7523)  loss_box_reg: 0.2293 (0.2402)  loss_objectness: 0.1366 (0.1507)  loss_rpn_box_reg: 0.0715 (0.0759)  time: 0.6318  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [35]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0999 (6.2160)  loss_classifier: 5.6835 (5.7494)  loss_box_reg: 0.2627 (0.2401)  loss_objectness: 0.1392 (0.1506)  loss_rpn_box_reg: 0.0612 (0.0758)  time: 0.6402  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [35]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0315 (6.2168)  loss_classifier: 5.6901 (5.7503)  loss_box_reg: 0.2080 (0.2397)  loss_objectness: 0.1392 (0.1507)  loss_rpn_box_reg: 0.0612 (0.0760)  time: 0.6337  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [35]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0360 (6.2159)  loss_classifier: 5.5669 (5.7488)  loss_box_reg: 0.2305 (0.2403)  loss_objectness: 0.1444 (0.1508)  loss_rpn_box_reg: 0.0801 (0.0760)  time: 0.6328  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [35]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1847 (6.2169)  loss_classifier: 5.6355 (5.7494)  loss_box_reg: 0.2582 (0.2406)  loss_objectness: 0.1566 (0.1510)  loss_rpn_box_reg: 0.0683 (0.0759)  time: 0.6308  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [35]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1164 (6.2125)  loss_classifier: 5.5318 (5.7449)  loss_box_reg: 0.2267 (0.2406)  loss_objectness: 0.1569 (0.1512)  loss_rpn_box_reg: 0.0620 (0.0758)  time: 0.6386  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [35] Total time: 0:05:14 (0.6290 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:51  model_time: 0.7032 (0.7032)  evaluator_time: 0.0350 (0.0350)  time: 0.8912  data: 0.1440  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4501 (0.4535)  evaluator_time: 0.0340 (0.0341)  time: 0.6365  data: 0.1481  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4761 (0.4550)  evaluator_time: 0.0360 (0.0361)  time: 0.6549  data: 0.1411  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6427 s / it)\n",
      "Averaged stats: model_time: 0.4761 (0.4550)  evaluator_time: 0.0360 (0.0361)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [35]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.1921 (6.1921)  loss_classifier: 5.6430 (5.6430)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1216 (0.1216)  loss_rpn_box_reg: 0.1329 (0.1329)  time: 0.6481  data: 0.1460  max mem: 10734\n",
      "Testing Epoch: [35]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0247 (6.1244)  loss_classifier: 5.4320 (5.6127)  loss_box_reg: 0.2609 (0.2894)  loss_objectness: 0.1292 (0.1322)  loss_rpn_box_reg: 0.0705 (0.0901)  time: 0.5881  data: 0.1470  max mem: 10734\n",
      "Testing Epoch: [35]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1587 (6.1573)  loss_classifier: 5.6768 (5.6501)  loss_box_reg: 0.2500 (0.2849)  loss_objectness: 0.1193 (0.1322)  loss_rpn_box_reg: 0.0745 (0.0901)  time: 0.6007  data: 0.1453  max mem: 10734\n",
      "Testing Epoch: [35] Total time: 0:01:14 (0.5976 s / it)\n",
      "Training Epoch: [36]  [  0/500]  eta: 0:06:43  lr: 0.000000  loss: 6.0644 (6.0644)  loss_classifier: 5.5281 (5.5281)  loss_box_reg: 0.3010 (0.3010)  loss_objectness: 0.1523 (0.1523)  loss_rpn_box_reg: 0.0829 (0.0829)  time: 0.8062  data: 0.1400  max mem: 10734\n",
      "Training Epoch: [36]  [ 10/500]  eta: 0:05:00  lr: 0.000000  loss: 6.1082 (6.2056)  loss_classifier: 5.5377 (5.7145)  loss_box_reg: 0.2781 (0.2630)  loss_objectness: 0.1523 (0.1484)  loss_rpn_box_reg: 0.0829 (0.0797)  time: 0.6139  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [36]  [ 20/500]  eta: 0:05:00  lr: 0.000000  loss: 6.0709 (6.1204)  loss_classifier: 5.5293 (5.6392)  loss_box_reg: 0.2368 (0.2512)  loss_objectness: 0.1487 (0.1543)  loss_rpn_box_reg: 0.0684 (0.0756)  time: 0.6163  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [36]  [ 30/500]  eta: 0:04:57  lr: 0.000000  loss: 6.1893 (6.1388)  loss_classifier: 5.6941 (5.6665)  loss_box_reg: 0.2430 (0.2499)  loss_objectness: 0.1468 (0.1499)  loss_rpn_box_reg: 0.0668 (0.0724)  time: 0.6422  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [36]  [ 40/500]  eta: 0:04:49  lr: 0.000000  loss: 6.1893 (6.1096)  loss_classifier: 5.6232 (5.6201)  loss_box_reg: 0.2583 (0.2593)  loss_objectness: 0.1392 (0.1513)  loss_rpn_box_reg: 0.0774 (0.0789)  time: 0.6356  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [36]  [ 50/500]  eta: 0:04:43  lr: 0.000000  loss: 6.1539 (6.1340)  loss_classifier: 5.6308 (5.6529)  loss_box_reg: 0.2588 (0.2535)  loss_objectness: 0.1500 (0.1505)  loss_rpn_box_reg: 0.0847 (0.0770)  time: 0.6268  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [36]  [ 60/500]  eta: 0:04:37  lr: 0.000000  loss: 6.2479 (6.1367)  loss_classifier: 5.8331 (5.6538)  loss_box_reg: 0.2522 (0.2535)  loss_objectness: 0.1579 (0.1526)  loss_rpn_box_reg: 0.0653 (0.0767)  time: 0.6287  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [36]  [ 70/500]  eta: 0:04:32  lr: 0.000000  loss: 5.9392 (6.1121)  loss_classifier: 5.5236 (5.6347)  loss_box_reg: 0.2355 (0.2499)  loss_objectness: 0.1425 (0.1517)  loss_rpn_box_reg: 0.0653 (0.0758)  time: 0.6396  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [36]  [ 80/500]  eta: 0:04:25  lr: 0.000000  loss: 6.0214 (6.1395)  loss_classifier: 5.6001 (5.6654)  loss_box_reg: 0.2260 (0.2468)  loss_objectness: 0.1313 (0.1527)  loss_rpn_box_reg: 0.0611 (0.0746)  time: 0.6374  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [36]  [ 90/500]  eta: 0:04:18  lr: 0.000000  loss: 6.2508 (6.1488)  loss_classifier: 5.8004 (5.6739)  loss_box_reg: 0.2314 (0.2458)  loss_objectness: 0.1496 (0.1529)  loss_rpn_box_reg: 0.0754 (0.0762)  time: 0.6170  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [36]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 6.3025 (6.1630)  loss_classifier: 5.8180 (5.6914)  loss_box_reg: 0.2454 (0.2441)  loss_objectness: 0.1496 (0.1517)  loss_rpn_box_reg: 0.0758 (0.0758)  time: 0.6205  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [36]  [110/500]  eta: 0:04:05  lr: 0.000000  loss: 6.3578 (6.1882)  loss_classifier: 5.9234 (5.7124)  loss_box_reg: 0.2454 (0.2453)  loss_objectness: 0.1525 (0.1535)  loss_rpn_box_reg: 0.0758 (0.0769)  time: 0.6331  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [36]  [120/500]  eta: 0:04:00  lr: 0.000000  loss: 6.3578 (6.1891)  loss_classifier: 5.8982 (5.7121)  loss_box_reg: 0.2273 (0.2460)  loss_objectness: 0.1494 (0.1526)  loss_rpn_box_reg: 0.0918 (0.0784)  time: 0.6426  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [36]  [130/500]  eta: 0:03:53  lr: 0.000000  loss: 6.1709 (6.1914)  loss_classifier: 5.6904 (5.7152)  loss_box_reg: 0.2273 (0.2454)  loss_objectness: 0.1430 (0.1519)  loss_rpn_box_reg: 0.0783 (0.0790)  time: 0.6417  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [36]  [140/500]  eta: 0:03:47  lr: 0.000000  loss: 6.2228 (6.2131)  loss_classifier: 5.7601 (5.7415)  loss_box_reg: 0.2234 (0.2430)  loss_objectness: 0.1339 (0.1511)  loss_rpn_box_reg: 0.0688 (0.0775)  time: 0.6310  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [36]  [150/500]  eta: 0:03:41  lr: 0.000000  loss: 6.2291 (6.2189)  loss_classifier: 5.7962 (5.7487)  loss_box_reg: 0.2134 (0.2418)  loss_objectness: 0.1352 (0.1510)  loss_rpn_box_reg: 0.0605 (0.0774)  time: 0.6319  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [36]  [160/500]  eta: 0:03:34  lr: 0.000000  loss: 6.2540 (6.2149)  loss_classifier: 5.7962 (5.7438)  loss_box_reg: 0.2168 (0.2432)  loss_objectness: 0.1355 (0.1510)  loss_rpn_box_reg: 0.0742 (0.0770)  time: 0.6318  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [36]  [170/500]  eta: 0:03:28  lr: 0.000000  loss: 6.1207 (6.2006)  loss_classifier: 5.6111 (5.7304)  loss_box_reg: 0.2517 (0.2426)  loss_objectness: 0.1343 (0.1508)  loss_rpn_box_reg: 0.0742 (0.0768)  time: 0.6245  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [36]  [180/500]  eta: 0:03:21  lr: 0.000000  loss: 6.0781 (6.2080)  loss_classifier: 5.5987 (5.7369)  loss_box_reg: 0.2517 (0.2443)  loss_objectness: 0.1478 (0.1502)  loss_rpn_box_reg: 0.0732 (0.0765)  time: 0.6223  data: 0.1312  max mem: 10734\n",
      "Training Epoch: [36]  [190/500]  eta: 0:03:15  lr: 0.000000  loss: 6.3716 (6.2153)  loss_classifier: 5.8806 (5.7416)  loss_box_reg: 0.2464 (0.2442)  loss_objectness: 0.1577 (0.1516)  loss_rpn_box_reg: 0.0756 (0.0778)  time: 0.6294  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [36]  [200/500]  eta: 0:03:09  lr: 0.000000  loss: 6.2266 (6.2140)  loss_classifier: 5.7094 (5.7402)  loss_box_reg: 0.2214 (0.2438)  loss_objectness: 0.1673 (0.1517)  loss_rpn_box_reg: 0.0810 (0.0783)  time: 0.6331  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [36]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.0612 (6.2075)  loss_classifier: 5.5845 (5.7357)  loss_box_reg: 0.2142 (0.2431)  loss_objectness: 0.1438 (0.1511)  loss_rpn_box_reg: 0.0652 (0.0777)  time: 0.6106  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [36]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 5.7725 (6.1983)  loss_classifier: 5.4100 (5.7274)  loss_box_reg: 0.2172 (0.2423)  loss_objectness: 0.1440 (0.1511)  loss_rpn_box_reg: 0.0652 (0.0775)  time: 0.6018  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [36]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.1035 (6.1977)  loss_classifier: 5.6135 (5.7271)  loss_box_reg: 0.2303 (0.2424)  loss_objectness: 0.1522 (0.1515)  loss_rpn_box_reg: 0.0620 (0.0767)  time: 0.6227  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [36]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.2552 (6.2079)  loss_classifier: 5.7837 (5.7373)  loss_box_reg: 0.2256 (0.2426)  loss_objectness: 0.1444 (0.1515)  loss_rpn_box_reg: 0.0588 (0.0766)  time: 0.6402  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [36]  [250/500]  eta: 0:02:37  lr: 0.000000  loss: 6.3450 (6.2083)  loss_classifier: 5.8221 (5.7361)  loss_box_reg: 0.2297 (0.2431)  loss_objectness: 0.1579 (0.1520)  loss_rpn_box_reg: 0.0784 (0.0771)  time: 0.6356  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [36]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 5.9148 (6.1948)  loss_classifier: 5.5070 (5.7250)  loss_box_reg: 0.2283 (0.2417)  loss_objectness: 0.1579 (0.1515)  loss_rpn_box_reg: 0.0734 (0.0766)  time: 0.6191  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [36]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 5.9148 (6.1948)  loss_classifier: 5.4141 (5.7243)  loss_box_reg: 0.2321 (0.2425)  loss_objectness: 0.1426 (0.1515)  loss_rpn_box_reg: 0.0707 (0.0765)  time: 0.6193  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [36]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.2863 (6.2000)  loss_classifier: 5.8033 (5.7302)  loss_box_reg: 0.2469 (0.2425)  loss_objectness: 0.1367 (0.1514)  loss_rpn_box_reg: 0.0723 (0.0760)  time: 0.6224  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [36]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.1592 (6.1939)  loss_classifier: 5.6591 (5.7225)  loss_box_reg: 0.2469 (0.2431)  loss_objectness: 0.1584 (0.1521)  loss_rpn_box_reg: 0.0723 (0.0762)  time: 0.6168  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [36]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.0620 (6.1903)  loss_classifier: 5.6274 (5.7195)  loss_box_reg: 0.2214 (0.2422)  loss_objectness: 0.1650 (0.1520)  loss_rpn_box_reg: 0.0775 (0.0766)  time: 0.6251  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [36]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.0977 (6.1899)  loss_classifier: 5.7994 (5.7201)  loss_box_reg: 0.2077 (0.2417)  loss_objectness: 0.1407 (0.1518)  loss_rpn_box_reg: 0.0680 (0.0764)  time: 0.6387  data: 0.1370  max mem: 10734\n",
      "Training Epoch: [36]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.4053 (6.1974)  loss_classifier: 6.0090 (5.7291)  loss_box_reg: 0.2033 (0.2405)  loss_objectness: 0.1407 (0.1515)  loss_rpn_box_reg: 0.0658 (0.0763)  time: 0.6208  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [36]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.2913 (6.1947)  loss_classifier: 5.7811 (5.7267)  loss_box_reg: 0.2033 (0.2398)  loss_objectness: 0.1589 (0.1520)  loss_rpn_box_reg: 0.0734 (0.0762)  time: 0.6114  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [36]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.0237 (6.1895)  loss_classifier: 5.5973 (5.7207)  loss_box_reg: 0.2442 (0.2406)  loss_objectness: 0.1663 (0.1519)  loss_rpn_box_reg: 0.0734 (0.0763)  time: 0.6241  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [36]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.0208 (6.1896)  loss_classifier: 5.5219 (5.7206)  loss_box_reg: 0.2446 (0.2409)  loss_objectness: 0.1417 (0.1519)  loss_rpn_box_reg: 0.0745 (0.0762)  time: 0.6208  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [36]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1971 (6.1912)  loss_classifier: 5.7624 (5.7231)  loss_box_reg: 0.2346 (0.2407)  loss_objectness: 0.1260 (0.1513)  loss_rpn_box_reg: 0.0722 (0.0761)  time: 0.6224  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [36]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.2548 (6.1921)  loss_classifier: 5.8259 (5.7247)  loss_box_reg: 0.2278 (0.2405)  loss_objectness: 0.1300 (0.1512)  loss_rpn_box_reg: 0.0592 (0.0757)  time: 0.6315  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [36]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.0133 (6.1920)  loss_classifier: 5.5576 (5.7249)  loss_box_reg: 0.2379 (0.2404)  loss_objectness: 0.1439 (0.1510)  loss_rpn_box_reg: 0.0671 (0.0757)  time: 0.6339  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [36]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 6.2698 (6.1961)  loss_classifier: 5.7890 (5.7281)  loss_box_reg: 0.2571 (0.2412)  loss_objectness: 0.1480 (0.1513)  loss_rpn_box_reg: 0.0705 (0.0756)  time: 0.6378  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [36]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.3660 (6.2023)  loss_classifier: 5.8356 (5.7345)  loss_box_reg: 0.2498 (0.2408)  loss_objectness: 0.1559 (0.1512)  loss_rpn_box_reg: 0.0716 (0.0758)  time: 0.6317  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [36]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.4205 (6.2056)  loss_classifier: 5.9069 (5.7378)  loss_box_reg: 0.2362 (0.2406)  loss_objectness: 0.1479 (0.1513)  loss_rpn_box_reg: 0.0809 (0.0760)  time: 0.6202  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [36]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.3589 (6.2088)  loss_classifier: 5.8829 (5.7408)  loss_box_reg: 0.2365 (0.2402)  loss_objectness: 0.1548 (0.1519)  loss_rpn_box_reg: 0.0696 (0.0759)  time: 0.6275  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [36]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.4342 (6.2157)  loss_classifier: 5.9706 (5.7474)  loss_box_reg: 0.2327 (0.2405)  loss_objectness: 0.1553 (0.1520)  loss_rpn_box_reg: 0.0663 (0.0759)  time: 0.6308  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [36]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.3654 (6.2163)  loss_classifier: 5.8787 (5.7476)  loss_box_reg: 0.2327 (0.2406)  loss_objectness: 0.1402 (0.1518)  loss_rpn_box_reg: 0.0701 (0.0763)  time: 0.6282  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [36]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1276 (6.2126)  loss_classifier: 5.6709 (5.7438)  loss_box_reg: 0.2288 (0.2405)  loss_objectness: 0.1465 (0.1518)  loss_rpn_box_reg: 0.0717 (0.0766)  time: 0.6294  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [36]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0070 (6.2083)  loss_classifier: 5.5601 (5.7395)  loss_box_reg: 0.2340 (0.2406)  loss_objectness: 0.1485 (0.1518)  loss_rpn_box_reg: 0.0713 (0.0764)  time: 0.6239  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [36]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0780 (6.2076)  loss_classifier: 5.6284 (5.7392)  loss_box_reg: 0.2340 (0.2403)  loss_objectness: 0.1410 (0.1518)  loss_rpn_box_reg: 0.0598 (0.0763)  time: 0.6262  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [36]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2227 (6.2136)  loss_classifier: 5.7633 (5.7449)  loss_box_reg: 0.2258 (0.2404)  loss_objectness: 0.1597 (0.1521)  loss_rpn_box_reg: 0.0706 (0.0762)  time: 0.6322  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [36]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.3213 (6.2134)  loss_classifier: 5.8631 (5.7453)  loss_box_reg: 0.2233 (0.2400)  loss_objectness: 0.1438 (0.1519)  loss_rpn_box_reg: 0.0672 (0.0762)  time: 0.6278  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [36]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1213 (6.2117)  loss_classifier: 5.7246 (5.7442)  loss_box_reg: 0.2233 (0.2399)  loss_objectness: 0.1351 (0.1517)  loss_rpn_box_reg: 0.0604 (0.0759)  time: 0.6201  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [36] Total time: 0:05:13 (0.6273 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:47  model_time: 0.6742 (0.6742)  evaluator_time: 0.0340 (0.0340)  time: 0.8612  data: 0.1440  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4411 (0.4509)  evaluator_time: 0.0340 (0.0368)  time: 0.6322  data: 0.1483  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4691 (0.4531)  evaluator_time: 0.0350 (0.0372)  time: 0.6562  data: 0.1482  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6407 s / it)\n",
      "Averaged stats: model_time: 0.4691 (0.4531)  evaluator_time: 0.0350 (0.0372)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [36]  [  0/125]  eta: 0:01:19  lr: 0.000000  loss: 6.1840 (6.1840)  loss_classifier: 5.6403 (5.6403)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1163 (0.1163)  loss_rpn_box_reg: 0.1329 (0.1329)  time: 0.6361  data: 0.1360  max mem: 10734\n",
      "Testing Epoch: [36]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0120 (6.1285)  loss_classifier: 5.4323 (5.6178)  loss_box_reg: 0.2609 (0.2889)  loss_objectness: 0.1281 (0.1322)  loss_rpn_box_reg: 0.0706 (0.0897)  time: 0.5895  data: 0.1467  max mem: 10734\n",
      "Testing Epoch: [36]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1691 (6.1598)  loss_classifier: 5.6894 (5.6540)  loss_box_reg: 0.2500 (0.2844)  loss_objectness: 0.1187 (0.1317)  loss_rpn_box_reg: 0.0745 (0.0897)  time: 0.5992  data: 0.1452  max mem: 10734\n",
      "Testing Epoch: [36] Total time: 0:01:14 (0.5973 s / it)\n",
      "Training Epoch: [37]  [  0/500]  eta: 0:06:47  lr: 0.000000  loss: 5.7898 (5.7898)  loss_classifier: 5.4029 (5.4029)  loss_box_reg: 0.1588 (0.1588)  loss_objectness: 0.1066 (0.1066)  loss_rpn_box_reg: 0.1215 (0.1215)  time: 0.8142  data: 0.1210  max mem: 10734\n",
      "Training Epoch: [37]  [ 10/500]  eta: 0:05:08  lr: 0.000000  loss: 6.2695 (6.2342)  loss_classifier: 5.9196 (5.8054)  loss_box_reg: 0.1916 (0.2304)  loss_objectness: 0.1178 (0.1272)  loss_rpn_box_reg: 0.0682 (0.0712)  time: 0.6301  data: 0.1299  max mem: 10734\n",
      "Training Epoch: [37]  [ 20/500]  eta: 0:04:59  lr: 0.000000  loss: 6.4188 (6.3747)  loss_classifier: 5.9196 (5.9183)  loss_box_reg: 0.2134 (0.2353)  loss_objectness: 0.1369 (0.1420)  loss_rpn_box_reg: 0.0802 (0.0790)  time: 0.6140  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [37]  [ 30/500]  eta: 0:04:52  lr: 0.000000  loss: 6.1455 (6.2649)  loss_classifier: 5.5877 (5.8122)  loss_box_reg: 0.2134 (0.2336)  loss_objectness: 0.1470 (0.1461)  loss_rpn_box_reg: 0.0695 (0.0729)  time: 0.6190  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [37]  [ 40/500]  eta: 0:04:47  lr: 0.000000  loss: 6.0274 (6.2772)  loss_classifier: 5.5833 (5.8236)  loss_box_reg: 0.2223 (0.2340)  loss_objectness: 0.1470 (0.1491)  loss_rpn_box_reg: 0.0611 (0.0705)  time: 0.6250  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [37]  [ 50/500]  eta: 0:04:39  lr: 0.000000  loss: 6.3733 (6.2886)  loss_classifier: 5.8616 (5.8278)  loss_box_reg: 0.2428 (0.2365)  loss_objectness: 0.1563 (0.1517)  loss_rpn_box_reg: 0.0692 (0.0726)  time: 0.6203  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [37]  [ 60/500]  eta: 0:04:34  lr: 0.000000  loss: 6.4188 (6.2962)  loss_classifier: 5.8616 (5.8329)  loss_box_reg: 0.2469 (0.2425)  loss_objectness: 0.1388 (0.1495)  loss_rpn_box_reg: 0.0692 (0.0712)  time: 0.6214  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [37]  [ 70/500]  eta: 0:04:27  lr: 0.000000  loss: 6.2628 (6.2593)  loss_classifier: 5.8083 (5.7975)  loss_box_reg: 0.2351 (0.2431)  loss_objectness: 0.1344 (0.1485)  loss_rpn_box_reg: 0.0599 (0.0702)  time: 0.6266  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [37]  [ 80/500]  eta: 0:04:22  lr: 0.000000  loss: 6.0868 (6.2474)  loss_classifier: 5.7706 (5.7884)  loss_box_reg: 0.2208 (0.2406)  loss_objectness: 0.1532 (0.1491)  loss_rpn_box_reg: 0.0591 (0.0693)  time: 0.6341  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [37]  [ 90/500]  eta: 0:04:16  lr: 0.000000  loss: 6.3267 (6.2684)  loss_classifier: 5.7820 (5.8067)  loss_box_reg: 0.2240 (0.2414)  loss_objectness: 0.1584 (0.1492)  loss_rpn_box_reg: 0.0723 (0.0711)  time: 0.6318  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [37]  [100/500]  eta: 0:04:09  lr: 0.000000  loss: 6.1685 (6.2348)  loss_classifier: 5.7183 (5.7700)  loss_box_reg: 0.2610 (0.2432)  loss_objectness: 0.1563 (0.1492)  loss_rpn_box_reg: 0.0815 (0.0724)  time: 0.6184  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [37]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 5.9620 (6.2196)  loss_classifier: 5.4668 (5.7532)  loss_box_reg: 0.2544 (0.2419)  loss_objectness: 0.1561 (0.1502)  loss_rpn_box_reg: 0.0869 (0.0743)  time: 0.6240  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [37]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.0297 (6.2016)  loss_classifier: 5.5866 (5.7367)  loss_box_reg: 0.2489 (0.2413)  loss_objectness: 0.1398 (0.1497)  loss_rpn_box_reg: 0.0849 (0.0739)  time: 0.6319  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [37]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 5.9820 (6.1745)  loss_classifier: 5.4837 (5.7077)  loss_box_reg: 0.2490 (0.2416)  loss_objectness: 0.1473 (0.1503)  loss_rpn_box_reg: 0.0848 (0.0749)  time: 0.6261  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [37]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 5.9975 (6.1719)  loss_classifier: 5.4550 (5.7063)  loss_box_reg: 0.2142 (0.2415)  loss_objectness: 0.1445 (0.1494)  loss_rpn_box_reg: 0.0837 (0.0747)  time: 0.6248  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [37]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.1106 (6.1842)  loss_classifier: 5.6042 (5.7152)  loss_box_reg: 0.2377 (0.2426)  loss_objectness: 0.1445 (0.1510)  loss_rpn_box_reg: 0.0695 (0.0754)  time: 0.6248  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [37]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.1955 (6.1860)  loss_classifier: 5.7668 (5.7188)  loss_box_reg: 0.2415 (0.2412)  loss_objectness: 0.1633 (0.1512)  loss_rpn_box_reg: 0.0653 (0.0748)  time: 0.6247  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [37]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.1997 (6.1886)  loss_classifier: 5.7531 (5.7231)  loss_box_reg: 0.2008 (0.2397)  loss_objectness: 0.1492 (0.1512)  loss_rpn_box_reg: 0.0545 (0.0746)  time: 0.6291  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [37]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.1997 (6.1880)  loss_classifier: 5.7552 (5.7232)  loss_box_reg: 0.2034 (0.2395)  loss_objectness: 0.1426 (0.1506)  loss_rpn_box_reg: 0.0609 (0.0746)  time: 0.6232  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [37]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.1983 (6.1911)  loss_classifier: 5.7673 (5.7280)  loss_box_reg: 0.1970 (0.2380)  loss_objectness: 0.1426 (0.1505)  loss_rpn_box_reg: 0.0656 (0.0746)  time: 0.6311  data: 0.1315  max mem: 10734\n",
      "Training Epoch: [37]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.2371 (6.2000)  loss_classifier: 5.7808 (5.7334)  loss_box_reg: 0.2183 (0.2400)  loss_objectness: 0.1493 (0.1512)  loss_rpn_box_reg: 0.0656 (0.0754)  time: 0.6297  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [37]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.1920 (6.2034)  loss_classifier: 5.8084 (5.7372)  loss_box_reg: 0.2487 (0.2400)  loss_objectness: 0.1461 (0.1510)  loss_rpn_box_reg: 0.0749 (0.0752)  time: 0.6271  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [37]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.0540 (6.1964)  loss_classifier: 5.6295 (5.7317)  loss_box_reg: 0.2226 (0.2395)  loss_objectness: 0.1396 (0.1507)  loss_rpn_box_reg: 0.0510 (0.0746)  time: 0.6327  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [37]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.1549 (6.2099)  loss_classifier: 5.7904 (5.7462)  loss_box_reg: 0.2172 (0.2388)  loss_objectness: 0.1301 (0.1502)  loss_rpn_box_reg: 0.0576 (0.0746)  time: 0.6321  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [37]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.2609 (6.2101)  loss_classifier: 5.7910 (5.7454)  loss_box_reg: 0.2359 (0.2384)  loss_objectness: 0.1552 (0.1513)  loss_rpn_box_reg: 0.0752 (0.0751)  time: 0.6220  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [37]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.2685 (6.2174)  loss_classifier: 5.7910 (5.7513)  loss_box_reg: 0.2473 (0.2395)  loss_objectness: 0.1644 (0.1517)  loss_rpn_box_reg: 0.0723 (0.0750)  time: 0.6131  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [37]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.2685 (6.2149)  loss_classifier: 5.8452 (5.7495)  loss_box_reg: 0.2565 (0.2397)  loss_objectness: 0.1363 (0.1513)  loss_rpn_box_reg: 0.0618 (0.0744)  time: 0.6198  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [37]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.2097 (6.2226)  loss_classifier: 5.8465 (5.7594)  loss_box_reg: 0.2235 (0.2387)  loss_objectness: 0.1299 (0.1504)  loss_rpn_box_reg: 0.0587 (0.0741)  time: 0.6292  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [37]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.3138 (6.2270)  loss_classifier: 5.8935 (5.7637)  loss_box_reg: 0.2153 (0.2381)  loss_objectness: 0.1318 (0.1509)  loss_rpn_box_reg: 0.0675 (0.0743)  time: 0.6186  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [37]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.2451 (6.2281)  loss_classifier: 5.7635 (5.7647)  loss_box_reg: 0.2233 (0.2380)  loss_objectness: 0.1495 (0.1511)  loss_rpn_box_reg: 0.0773 (0.0743)  time: 0.6091  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [37]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.1750 (6.2266)  loss_classifier: 5.6718 (5.7620)  loss_box_reg: 0.2279 (0.2385)  loss_objectness: 0.1597 (0.1518)  loss_rpn_box_reg: 0.0751 (0.0743)  time: 0.6222  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [37]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.1060 (6.2273)  loss_classifier: 5.6192 (5.7626)  loss_box_reg: 0.2216 (0.2377)  loss_objectness: 0.1709 (0.1523)  loss_rpn_box_reg: 0.0706 (0.0747)  time: 0.6367  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [37]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2676 (6.2241)  loss_classifier: 5.7065 (5.7583)  loss_box_reg: 0.2206 (0.2387)  loss_objectness: 0.1475 (0.1524)  loss_rpn_box_reg: 0.0706 (0.0747)  time: 0.6425  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [37]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 5.8612 (6.2117)  loss_classifier: 5.4638 (5.7464)  loss_box_reg: 0.2194 (0.2374)  loss_objectness: 0.1588 (0.1527)  loss_rpn_box_reg: 0.0677 (0.0753)  time: 0.6335  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [37]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 5.9036 (6.2123)  loss_classifier: 5.4638 (5.7470)  loss_box_reg: 0.2211 (0.2378)  loss_objectness: 0.1419 (0.1524)  loss_rpn_box_reg: 0.0773 (0.0751)  time: 0.6234  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [37]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.0895 (6.2167)  loss_classifier: 5.7002 (5.7507)  loss_box_reg: 0.2247 (0.2375)  loss_objectness: 0.1423 (0.1532)  loss_rpn_box_reg: 0.0708 (0.0752)  time: 0.6154  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [37]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.2019 (6.2164)  loss_classifier: 5.6594 (5.7507)  loss_box_reg: 0.2185 (0.2374)  loss_objectness: 0.1485 (0.1533)  loss_rpn_box_reg: 0.0689 (0.0750)  time: 0.6157  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [37]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.2019 (6.2137)  loss_classifier: 5.7002 (5.7494)  loss_box_reg: 0.2043 (0.2366)  loss_objectness: 0.1376 (0.1530)  loss_rpn_box_reg: 0.0642 (0.0746)  time: 0.6165  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [37]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1530 (6.2131)  loss_classifier: 5.6894 (5.7477)  loss_box_reg: 0.2275 (0.2370)  loss_objectness: 0.1570 (0.1534)  loss_rpn_box_reg: 0.0690 (0.0750)  time: 0.6216  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [37]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1530 (6.2122)  loss_classifier: 5.6399 (5.7459)  loss_box_reg: 0.2374 (0.2370)  loss_objectness: 0.1758 (0.1540)  loss_rpn_box_reg: 0.0848 (0.0753)  time: 0.6214  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [37]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.0035 (6.2065)  loss_classifier: 5.5351 (5.7388)  loss_box_reg: 0.2606 (0.2381)  loss_objectness: 0.1626 (0.1541)  loss_rpn_box_reg: 0.0785 (0.0755)  time: 0.6108  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [37]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.0444 (6.2067)  loss_classifier: 5.5484 (5.7386)  loss_box_reg: 0.2606 (0.2383)  loss_objectness: 0.1513 (0.1542)  loss_rpn_box_reg: 0.0706 (0.0755)  time: 0.6121  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [37]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1915 (6.2072)  loss_classifier: 5.8409 (5.7400)  loss_box_reg: 0.2396 (0.2383)  loss_objectness: 0.1346 (0.1536)  loss_rpn_box_reg: 0.0706 (0.0754)  time: 0.6321  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [37]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2231 (6.2080)  loss_classifier: 5.8086 (5.7412)  loss_box_reg: 0.2073 (0.2378)  loss_objectness: 0.1304 (0.1535)  loss_rpn_box_reg: 0.0706 (0.0755)  time: 0.6429  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [37]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.0883 (6.2051)  loss_classifier: 5.6418 (5.7382)  loss_box_reg: 0.2068 (0.2378)  loss_objectness: 0.1535 (0.1535)  loss_rpn_box_reg: 0.0778 (0.0757)  time: 0.6335  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [37]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0883 (6.2087)  loss_classifier: 5.6718 (5.7413)  loss_box_reg: 0.2216 (0.2380)  loss_objectness: 0.1535 (0.1536)  loss_rpn_box_reg: 0.0778 (0.0758)  time: 0.6172  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [37]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.0762 (6.2048)  loss_classifier: 5.6489 (5.7372)  loss_box_reg: 0.2501 (0.2383)  loss_objectness: 0.1446 (0.1534)  loss_rpn_box_reg: 0.0710 (0.0759)  time: 0.6144  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [37]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1149 (6.2096)  loss_classifier: 5.7178 (5.7417)  loss_box_reg: 0.2655 (0.2386)  loss_objectness: 0.1446 (0.1532)  loss_rpn_box_reg: 0.0759 (0.0761)  time: 0.6235  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [37]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.4704 (6.2133)  loss_classifier: 5.8795 (5.7451)  loss_box_reg: 0.2392 (0.2386)  loss_objectness: 0.1455 (0.1532)  loss_rpn_box_reg: 0.0762 (0.0763)  time: 0.6233  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [37]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.2576 (6.2120)  loss_classifier: 5.7284 (5.7433)  loss_box_reg: 0.2559 (0.2393)  loss_objectness: 0.1537 (0.1534)  loss_rpn_box_reg: 0.0632 (0.0761)  time: 0.6247  data: 0.1377  max mem: 10734\n",
      "Training Epoch: [37]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0511 (6.2125)  loss_classifier: 5.5856 (5.7443)  loss_box_reg: 0.2634 (0.2394)  loss_objectness: 0.1444 (0.1530)  loss_rpn_box_reg: 0.0632 (0.0759)  time: 0.6178  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [37] Total time: 0:05:12 (0.6244 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:05  model_time: 0.7312 (0.7312)  evaluator_time: 0.0340 (0.0340)  time: 1.0036  data: 0.2294  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4471 (0.4516)  evaluator_time: 0.0340 (0.0353)  time: 0.6372  data: 0.1516  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4711 (0.4533)  evaluator_time: 0.0360 (0.0360)  time: 0.6570  data: 0.1508  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6446 s / it)\n",
      "Averaged stats: model_time: 0.4711 (0.4533)  evaluator_time: 0.0360 (0.0360)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.28s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [37]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.1964 (6.1964)  loss_classifier: 5.6490 (5.6490)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1218 (0.1218)  loss_rpn_box_reg: 0.1311 (0.1311)  time: 0.6531  data: 0.1440  max mem: 10734\n",
      "Testing Epoch: [37]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9965 (6.1276)  loss_classifier: 5.4330 (5.6184)  loss_box_reg: 0.2609 (0.2879)  loss_objectness: 0.1304 (0.1322)  loss_rpn_box_reg: 0.0710 (0.0890)  time: 0.5852  data: 0.1439  max mem: 10734\n",
      "Testing Epoch: [37]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1758 (6.1600)  loss_classifier: 5.6734 (5.6551)  loss_box_reg: 0.2500 (0.2837)  loss_objectness: 0.1230 (0.1319)  loss_rpn_box_reg: 0.0745 (0.0893)  time: 0.6004  data: 0.1461  max mem: 10734\n",
      "Testing Epoch: [37] Total time: 0:01:14 (0.5976 s / it)\n",
      "Training Epoch: [38]  [  0/500]  eta: 0:07:51  lr: 0.000000  loss: 6.3301 (6.3301)  loss_classifier: 5.7501 (5.7501)  loss_box_reg: 0.2825 (0.2825)  loss_objectness: 0.1603 (0.1603)  loss_rpn_box_reg: 0.1371 (0.1371)  time: 0.9432  data: 0.1410  max mem: 10734\n",
      "Training Epoch: [38]  [ 10/500]  eta: 0:05:21  lr: 0.000000  loss: 6.0540 (6.0658)  loss_classifier: 5.7018 (5.6051)  loss_box_reg: 0.2318 (0.2301)  loss_objectness: 0.1603 (0.1525)  loss_rpn_box_reg: 0.0765 (0.0782)  time: 0.6568  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [38]  [ 20/500]  eta: 0:05:13  lr: 0.000000  loss: 6.2270 (6.2902)  loss_classifier: 5.8229 (5.8228)  loss_box_reg: 0.2499 (0.2366)  loss_objectness: 0.1572 (0.1542)  loss_rpn_box_reg: 0.0695 (0.0766)  time: 0.6383  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [38]  [ 30/500]  eta: 0:05:03  lr: 0.000000  loss: 6.4524 (6.3102)  loss_classifier: 5.9183 (5.8494)  loss_box_reg: 0.2219 (0.2283)  loss_objectness: 0.1572 (0.1548)  loss_rpn_box_reg: 0.0686 (0.0777)  time: 0.6386  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [38]  [ 40/500]  eta: 0:04:53  lr: 0.000000  loss: 6.1628 (6.2553)  loss_classifier: 5.7337 (5.7858)  loss_box_reg: 0.2137 (0.2327)  loss_objectness: 0.1601 (0.1598)  loss_rpn_box_reg: 0.0682 (0.0770)  time: 0.6224  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [38]  [ 50/500]  eta: 0:04:46  lr: 0.000000  loss: 6.4252 (6.3338)  loss_classifier: 5.8170 (5.8554)  loss_box_reg: 0.2267 (0.2375)  loss_objectness: 0.1601 (0.1608)  loss_rpn_box_reg: 0.0800 (0.0801)  time: 0.6215  data: 0.1379  max mem: 10734\n",
      "Training Epoch: [38]  [ 60/500]  eta: 0:04:38  lr: 0.000000  loss: 6.3937 (6.3081)  loss_classifier: 5.8904 (5.8342)  loss_box_reg: 0.2267 (0.2344)  loss_objectness: 0.1510 (0.1600)  loss_rpn_box_reg: 0.0810 (0.0794)  time: 0.6210  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [38]  [ 70/500]  eta: 0:04:32  lr: 0.000000  loss: 6.1917 (6.2775)  loss_classifier: 5.6296 (5.7995)  loss_box_reg: 0.2235 (0.2387)  loss_objectness: 0.1426 (0.1578)  loss_rpn_box_reg: 0.0797 (0.0816)  time: 0.6281  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [38]  [ 80/500]  eta: 0:04:26  lr: 0.000000  loss: 6.1917 (6.2729)  loss_classifier: 5.6296 (5.7997)  loss_box_reg: 0.2235 (0.2359)  loss_objectness: 0.1351 (0.1566)  loss_rpn_box_reg: 0.0744 (0.0806)  time: 0.6384  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [38]  [ 90/500]  eta: 0:04:19  lr: 0.000000  loss: 6.3153 (6.2857)  loss_classifier: 5.8921 (5.8196)  loss_box_reg: 0.2111 (0.2330)  loss_objectness: 0.1327 (0.1540)  loss_rpn_box_reg: 0.0600 (0.0790)  time: 0.6317  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [38]  [100/500]  eta: 0:04:13  lr: 0.000000  loss: 6.2810 (6.2830)  loss_classifier: 5.9374 (5.8175)  loss_box_reg: 0.2290 (0.2348)  loss_objectness: 0.1352 (0.1547)  loss_rpn_box_reg: 0.0538 (0.0760)  time: 0.6271  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [38]  [110/500]  eta: 0:04:06  lr: 0.000000  loss: 6.1717 (6.2756)  loss_classifier: 5.6515 (5.8063)  loss_box_reg: 0.2548 (0.2379)  loss_objectness: 0.1449 (0.1539)  loss_rpn_box_reg: 0.0600 (0.0774)  time: 0.6294  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [38]  [120/500]  eta: 0:04:00  lr: 0.000000  loss: 6.1090 (6.2672)  loss_classifier: 5.6226 (5.7998)  loss_box_reg: 0.2548 (0.2369)  loss_objectness: 0.1447 (0.1534)  loss_rpn_box_reg: 0.0732 (0.0772)  time: 0.6284  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [38]  [130/500]  eta: 0:03:53  lr: 0.000000  loss: 6.2517 (6.2624)  loss_classifier: 5.7642 (5.7933)  loss_box_reg: 0.2309 (0.2361)  loss_objectness: 0.1668 (0.1546)  loss_rpn_box_reg: 0.0898 (0.0785)  time: 0.6174  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [38]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.2518 (6.2473)  loss_classifier: 5.7642 (5.7810)  loss_box_reg: 0.2309 (0.2356)  loss_objectness: 0.1519 (0.1526)  loss_rpn_box_reg: 0.0748 (0.0782)  time: 0.6155  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [38]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 6.3910 (6.2731)  loss_classifier: 5.8633 (5.8056)  loss_box_reg: 0.2342 (0.2352)  loss_objectness: 0.1440 (0.1534)  loss_rpn_box_reg: 0.0680 (0.0789)  time: 0.6340  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [38]  [160/500]  eta: 0:03:34  lr: 0.000000  loss: 6.4457 (6.2731)  loss_classifier: 5.9609 (5.8041)  loss_box_reg: 0.2317 (0.2353)  loss_objectness: 0.1631 (0.1550)  loss_rpn_box_reg: 0.0735 (0.0787)  time: 0.6285  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [38]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.1307 (6.2647)  loss_classifier: 5.5904 (5.7934)  loss_box_reg: 0.2317 (0.2358)  loss_objectness: 0.1631 (0.1556)  loss_rpn_box_reg: 0.0834 (0.0799)  time: 0.6149  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [38]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.1307 (6.2569)  loss_classifier: 5.6339 (5.7830)  loss_box_reg: 0.2406 (0.2382)  loss_objectness: 0.1607 (0.1559)  loss_rpn_box_reg: 0.0844 (0.0799)  time: 0.6140  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [38]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.1312 (6.2458)  loss_classifier: 5.6223 (5.7724)  loss_box_reg: 0.2482 (0.2394)  loss_objectness: 0.1562 (0.1549)  loss_rpn_box_reg: 0.0660 (0.0791)  time: 0.6249  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [38]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.1450 (6.2428)  loss_classifier: 5.7577 (5.7723)  loss_box_reg: 0.2246 (0.2383)  loss_objectness: 0.1370 (0.1542)  loss_rpn_box_reg: 0.0603 (0.0780)  time: 0.6411  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [38]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.1368 (6.2360)  loss_classifier: 5.5794 (5.7684)  loss_box_reg: 0.2020 (0.2371)  loss_objectness: 0.1329 (0.1537)  loss_rpn_box_reg: 0.0512 (0.0767)  time: 0.6318  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [38]  [220/500]  eta: 0:02:56  lr: 0.000000  loss: 5.8501 (6.2303)  loss_classifier: 5.5487 (5.7634)  loss_box_reg: 0.2188 (0.2364)  loss_objectness: 0.1312 (0.1529)  loss_rpn_box_reg: 0.0646 (0.0776)  time: 0.6347  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [38]  [230/500]  eta: 0:02:50  lr: 0.000000  loss: 5.8372 (6.2187)  loss_classifier: 5.6023 (5.7546)  loss_box_reg: 0.2269 (0.2355)  loss_objectness: 0.1246 (0.1520)  loss_rpn_box_reg: 0.0613 (0.0765)  time: 0.6453  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [38]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 5.9340 (6.2149)  loss_classifier: 5.4601 (5.7510)  loss_box_reg: 0.2065 (0.2351)  loss_objectness: 0.1462 (0.1526)  loss_rpn_box_reg: 0.0579 (0.0762)  time: 0.6289  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [38]  [250/500]  eta: 0:02:37  lr: 0.000000  loss: 6.0058 (6.2071)  loss_classifier: 5.5318 (5.7429)  loss_box_reg: 0.2211 (0.2352)  loss_objectness: 0.1592 (0.1530)  loss_rpn_box_reg: 0.0639 (0.0759)  time: 0.6256  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [38]  [260/500]  eta: 0:02:31  lr: 0.000000  loss: 6.1216 (6.1980)  loss_classifier: 5.6227 (5.7328)  loss_box_reg: 0.2619 (0.2370)  loss_objectness: 0.1468 (0.1526)  loss_rpn_box_reg: 0.0637 (0.0756)  time: 0.6372  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [38]  [270/500]  eta: 0:02:25  lr: 0.000000  loss: 6.1571 (6.2015)  loss_classifier: 5.6748 (5.7370)  loss_box_reg: 0.2587 (0.2367)  loss_objectness: 0.1401 (0.1526)  loss_rpn_box_reg: 0.0599 (0.0751)  time: 0.6455  data: 0.1379  max mem: 10734\n",
      "Training Epoch: [38]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.1696 (6.1993)  loss_classifier: 5.7211 (5.7356)  loss_box_reg: 0.2279 (0.2365)  loss_objectness: 0.1382 (0.1522)  loss_rpn_box_reg: 0.0592 (0.0750)  time: 0.6355  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [38]  [290/500]  eta: 0:02:12  lr: 0.000000  loss: 6.0927 (6.1952)  loss_classifier: 5.6360 (5.7334)  loss_box_reg: 0.2275 (0.2358)  loss_objectness: 0.1344 (0.1515)  loss_rpn_box_reg: 0.0560 (0.0745)  time: 0.6240  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [38]  [300/500]  eta: 0:02:06  lr: 0.000000  loss: 6.2766 (6.2037)  loss_classifier: 5.8147 (5.7407)  loss_box_reg: 0.2275 (0.2361)  loss_objectness: 0.1431 (0.1523)  loss_rpn_box_reg: 0.0683 (0.0747)  time: 0.6275  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [38]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.3320 (6.2102)  loss_classifier: 5.8417 (5.7459)  loss_box_reg: 0.2413 (0.2369)  loss_objectness: 0.1685 (0.1527)  loss_rpn_box_reg: 0.0725 (0.0748)  time: 0.6210  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [38]  [320/500]  eta: 0:01:53  lr: 0.000000  loss: 6.3126 (6.2144)  loss_classifier: 5.8417 (5.7505)  loss_box_reg: 0.2402 (0.2366)  loss_objectness: 0.1590 (0.1526)  loss_rpn_box_reg: 0.0677 (0.0746)  time: 0.6248  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [38]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.2394 (6.2139)  loss_classifier: 5.7108 (5.7495)  loss_box_reg: 0.2252 (0.2370)  loss_objectness: 0.1423 (0.1529)  loss_rpn_box_reg: 0.0660 (0.0746)  time: 0.6204  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [38]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.3184 (6.2203)  loss_classifier: 5.8199 (5.7544)  loss_box_reg: 0.2592 (0.2373)  loss_objectness: 0.1535 (0.1537)  loss_rpn_box_reg: 0.0687 (0.0748)  time: 0.6167  data: 0.1389  max mem: 10734\n",
      "Training Epoch: [38]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.4387 (6.2197)  loss_classifier: 5.8967 (5.7542)  loss_box_reg: 0.2320 (0.2368)  loss_objectness: 0.1653 (0.1539)  loss_rpn_box_reg: 0.0701 (0.0748)  time: 0.6280  data: 0.1375  max mem: 10734\n",
      "Training Epoch: [38]  [360/500]  eta: 0:01:28  lr: 0.000000  loss: 6.0844 (6.2142)  loss_classifier: 5.5555 (5.7485)  loss_box_reg: 0.2191 (0.2367)  loss_objectness: 0.1593 (0.1538)  loss_rpn_box_reg: 0.0614 (0.0752)  time: 0.6364  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [38]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.2298 (6.2173)  loss_classifier: 5.7233 (5.7507)  loss_box_reg: 0.2253 (0.2368)  loss_objectness: 0.1554 (0.1542)  loss_rpn_box_reg: 0.0618 (0.0756)  time: 0.6216  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [38]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.2827 (6.2156)  loss_classifier: 5.7552 (5.7478)  loss_box_reg: 0.2520 (0.2377)  loss_objectness: 0.1528 (0.1543)  loss_rpn_box_reg: 0.0792 (0.0759)  time: 0.6022  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [38]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 6.1011 (6.2126)  loss_classifier: 5.5778 (5.7456)  loss_box_reg: 0.2334 (0.2373)  loss_objectness: 0.1418 (0.1540)  loss_rpn_box_reg: 0.0783 (0.0757)  time: 0.6194  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [38]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.3132 (6.2172)  loss_classifier: 5.8606 (5.7491)  loss_box_reg: 0.2371 (0.2379)  loss_objectness: 0.1490 (0.1542)  loss_rpn_box_reg: 0.0726 (0.0761)  time: 0.6218  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [38]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.3009 (6.2152)  loss_classifier: 5.8754 (5.7476)  loss_box_reg: 0.2399 (0.2377)  loss_objectness: 0.1507 (0.1541)  loss_rpn_box_reg: 0.0701 (0.0758)  time: 0.6074  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [38]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.2353 (6.2202)  loss_classifier: 5.8524 (5.7533)  loss_box_reg: 0.2275 (0.2374)  loss_objectness: 0.1511 (0.1540)  loss_rpn_box_reg: 0.0645 (0.0755)  time: 0.6247  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [38]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1699 (6.2161)  loss_classifier: 5.7199 (5.7490)  loss_box_reg: 0.2340 (0.2375)  loss_objectness: 0.1530 (0.1542)  loss_rpn_box_reg: 0.0609 (0.0753)  time: 0.6294  data: 0.1379  max mem: 10734\n",
      "Training Epoch: [38]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.0168 (6.2170)  loss_classifier: 5.6231 (5.7507)  loss_box_reg: 0.2264 (0.2370)  loss_objectness: 0.1516 (0.1540)  loss_rpn_box_reg: 0.0596 (0.0752)  time: 0.6111  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [38]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0173 (6.2126)  loss_classifier: 5.7424 (5.7461)  loss_box_reg: 0.2251 (0.2377)  loss_objectness: 0.1367 (0.1537)  loss_rpn_box_reg: 0.0596 (0.0752)  time: 0.6068  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [38]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0173 (6.2098)  loss_classifier: 5.6431 (5.7431)  loss_box_reg: 0.2585 (0.2378)  loss_objectness: 0.1413 (0.1535)  loss_rpn_box_reg: 0.0681 (0.0753)  time: 0.6216  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [38]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0149 (6.2073)  loss_classifier: 5.5021 (5.7408)  loss_box_reg: 0.2276 (0.2377)  loss_objectness: 0.1491 (0.1533)  loss_rpn_box_reg: 0.0774 (0.0754)  time: 0.6208  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [38]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2448 (6.2108)  loss_classifier: 5.7811 (5.7438)  loss_box_reg: 0.2264 (0.2377)  loss_objectness: 0.1512 (0.1535)  loss_rpn_box_reg: 0.0799 (0.0758)  time: 0.6231  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [38]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.2988 (6.2113)  loss_classifier: 5.8050 (5.7436)  loss_box_reg: 0.2435 (0.2380)  loss_objectness: 0.1569 (0.1536)  loss_rpn_box_reg: 0.0816 (0.0760)  time: 0.6367  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [38]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2564 (6.2154)  loss_classifier: 5.8136 (5.7476)  loss_box_reg: 0.2495 (0.2382)  loss_objectness: 0.1514 (0.1534)  loss_rpn_box_reg: 0.0837 (0.0763)  time: 0.6294  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [38] Total time: 0:05:13 (0.6266 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:57  model_time: 0.6682 (0.6682)  evaluator_time: 0.0340 (0.0340)  time: 0.9402  data: 0.2291  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4421 (0.4521)  evaluator_time: 0.0340 (0.0361)  time: 0.6370  data: 0.1541  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4651 (0.4541)  evaluator_time: 0.0360 (0.0366)  time: 0.6649  data: 0.1559  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6430 s / it)\n",
      "Averaged stats: model_time: 0.4651 (0.4541)  evaluator_time: 0.0360 (0.0366)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [38]  [  0/125]  eta: 0:01:22  lr: 0.000000  loss: 6.1977 (6.1977)  loss_classifier: 5.6553 (5.6553)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1145 (0.1145)  loss_rpn_box_reg: 0.1334 (0.1334)  time: 0.6581  data: 0.1560  max mem: 10734\n",
      "Testing Epoch: [38]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0273 (6.1301)  loss_classifier: 5.4250 (5.6203)  loss_box_reg: 0.2609 (0.2890)  loss_objectness: 0.1292 (0.1312)  loss_rpn_box_reg: 0.0726 (0.0895)  time: 0.5858  data: 0.1476  max mem: 10734\n",
      "Testing Epoch: [38]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1593 (6.1620)  loss_classifier: 5.6758 (5.6566)  loss_box_reg: 0.2500 (0.2845)  loss_objectness: 0.1260 (0.1313)  loss_rpn_box_reg: 0.0745 (0.0896)  time: 0.6019  data: 0.1484  max mem: 10734\n",
      "Testing Epoch: [38] Total time: 0:01:14 (0.5965 s / it)\n",
      "Training Epoch: [39]  [  0/500]  eta: 0:06:32  lr: 0.000000  loss: 5.7658 (5.7658)  loss_classifier: 5.2834 (5.2834)  loss_box_reg: 0.1948 (0.1948)  loss_objectness: 0.2132 (0.2132)  loss_rpn_box_reg: 0.0744 (0.0744)  time: 0.7852  data: 0.1400  max mem: 10734\n",
      "Training Epoch: [39]  [ 10/500]  eta: 0:05:22  lr: 0.000000  loss: 6.2259 (6.2348)  loss_classifier: 5.7353 (5.7537)  loss_box_reg: 0.2386 (0.2384)  loss_objectness: 0.1596 (0.1623)  loss_rpn_box_reg: 0.0808 (0.0804)  time: 0.6580  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [39]  [ 20/500]  eta: 0:05:08  lr: 0.000000  loss: 6.2852 (6.3153)  loss_classifier: 5.7880 (5.8356)  loss_box_reg: 0.2386 (0.2498)  loss_objectness: 0.1448 (0.1556)  loss_rpn_box_reg: 0.0753 (0.0743)  time: 0.6355  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [39]  [ 30/500]  eta: 0:04:59  lr: 0.000000  loss: 6.2140 (6.2941)  loss_classifier: 5.7589 (5.8242)  loss_box_reg: 0.2465 (0.2485)  loss_objectness: 0.1422 (0.1518)  loss_rpn_box_reg: 0.0619 (0.0696)  time: 0.6253  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [39]  [ 40/500]  eta: 0:04:52  lr: 0.000000  loss: 5.9372 (6.2415)  loss_classifier: 5.4724 (5.7632)  loss_box_reg: 0.2425 (0.2471)  loss_objectness: 0.1551 (0.1560)  loss_rpn_box_reg: 0.0708 (0.0751)  time: 0.6290  data: 0.1370  max mem: 10734\n",
      "Training Epoch: [39]  [ 50/500]  eta: 0:04:45  lr: 0.000000  loss: 5.8861 (6.1900)  loss_classifier: 5.4695 (5.7185)  loss_box_reg: 0.2316 (0.2428)  loss_objectness: 0.1442 (0.1538)  loss_rpn_box_reg: 0.0761 (0.0749)  time: 0.6297  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [39]  [ 60/500]  eta: 0:04:37  lr: 0.000000  loss: 5.9937 (6.2165)  loss_classifier: 5.6719 (5.7485)  loss_box_reg: 0.2410 (0.2428)  loss_objectness: 0.1375 (0.1517)  loss_rpn_box_reg: 0.0687 (0.0735)  time: 0.6179  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [39]  [ 70/500]  eta: 0:04:30  lr: 0.000000  loss: 6.1316 (6.2190)  loss_classifier: 5.7957 (5.7533)  loss_box_reg: 0.2410 (0.2417)  loss_objectness: 0.1417 (0.1510)  loss_rpn_box_reg: 0.0677 (0.0730)  time: 0.6138  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [39]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 6.2397 (6.2202)  loss_classifier: 5.7782 (5.7537)  loss_box_reg: 0.2226 (0.2401)  loss_objectness: 0.1563 (0.1535)  loss_rpn_box_reg: 0.0630 (0.0730)  time: 0.6220  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [39]  [ 90/500]  eta: 0:04:18  lr: 0.000000  loss: 6.4084 (6.2399)  loss_classifier: 5.8567 (5.7701)  loss_box_reg: 0.2372 (0.2415)  loss_objectness: 0.1650 (0.1546)  loss_rpn_box_reg: 0.0633 (0.0736)  time: 0.6343  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [39]  [100/500]  eta: 0:04:12  lr: 0.000000  loss: 6.3123 (6.2386)  loss_classifier: 5.8364 (5.7691)  loss_box_reg: 0.2544 (0.2412)  loss_objectness: 0.1537 (0.1547)  loss_rpn_box_reg: 0.0681 (0.0737)  time: 0.6464  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [39]  [110/500]  eta: 0:04:05  lr: 0.000000  loss: 6.1214 (6.2245)  loss_classifier: 5.6613 (5.7528)  loss_box_reg: 0.2214 (0.2415)  loss_objectness: 0.1482 (0.1554)  loss_rpn_box_reg: 0.0681 (0.0748)  time: 0.6267  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [39]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.0791 (6.2275)  loss_classifier: 5.5281 (5.7539)  loss_box_reg: 0.2369 (0.2424)  loss_objectness: 0.1583 (0.1562)  loss_rpn_box_reg: 0.0851 (0.0751)  time: 0.6118  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [39]  [130/500]  eta: 0:03:53  lr: 0.000000  loss: 6.3778 (6.2416)  loss_classifier: 5.9354 (5.7703)  loss_box_reg: 0.2321 (0.2420)  loss_objectness: 0.1486 (0.1550)  loss_rpn_box_reg: 0.0715 (0.0742)  time: 0.6420  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [39]  [140/500]  eta: 0:03:47  lr: 0.000000  loss: 6.2631 (6.2497)  loss_classifier: 5.9037 (5.7821)  loss_box_reg: 0.2099 (0.2400)  loss_objectness: 0.1334 (0.1538)  loss_rpn_box_reg: 0.0659 (0.0738)  time: 0.6556  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [39]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 6.1703 (6.2560)  loss_classifier: 5.7833 (5.7908)  loss_box_reg: 0.2067 (0.2381)  loss_objectness: 0.1457 (0.1536)  loss_rpn_box_reg: 0.0599 (0.0735)  time: 0.6323  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [39]  [160/500]  eta: 0:03:34  lr: 0.000000  loss: 6.1550 (6.2553)  loss_classifier: 5.7394 (5.7940)  loss_box_reg: 0.1981 (0.2361)  loss_objectness: 0.1457 (0.1526)  loss_rpn_box_reg: 0.0557 (0.0727)  time: 0.6189  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [39]  [170/500]  eta: 0:03:28  lr: 0.000000  loss: 6.0290 (6.2427)  loss_classifier: 5.6506 (5.7830)  loss_box_reg: 0.2252 (0.2360)  loss_objectness: 0.1261 (0.1512)  loss_rpn_box_reg: 0.0645 (0.0725)  time: 0.6252  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [39]  [180/500]  eta: 0:03:21  lr: 0.000000  loss: 6.1562 (6.2531)  loss_classifier: 5.7014 (5.7939)  loss_box_reg: 0.2412 (0.2357)  loss_objectness: 0.1340 (0.1511)  loss_rpn_box_reg: 0.0668 (0.0724)  time: 0.6191  data: 0.1388  max mem: 10734\n",
      "Training Epoch: [39]  [190/500]  eta: 0:03:15  lr: 0.000000  loss: 6.2640 (6.2511)  loss_classifier: 5.8149 (5.7900)  loss_box_reg: 0.2500 (0.2377)  loss_objectness: 0.1477 (0.1505)  loss_rpn_box_reg: 0.0713 (0.0728)  time: 0.6213  data: 0.1445  max mem: 10734\n",
      "Training Epoch: [39]  [200/500]  eta: 0:03:09  lr: 0.000000  loss: 6.0838 (6.2397)  loss_classifier: 5.6464 (5.7771)  loss_box_reg: 0.2514 (0.2377)  loss_objectness: 0.1502 (0.1519)  loss_rpn_box_reg: 0.0723 (0.0730)  time: 0.6364  data: 0.1447  max mem: 10734\n",
      "Training Epoch: [39]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 5.9185 (6.2360)  loss_classifier: 5.4282 (5.7728)  loss_box_reg: 0.2414 (0.2379)  loss_objectness: 0.1533 (0.1516)  loss_rpn_box_reg: 0.0669 (0.0737)  time: 0.6344  data: 0.1435  max mem: 10734\n",
      "Training Epoch: [39]  [220/500]  eta: 0:02:56  lr: 0.000000  loss: 5.8739 (6.2268)  loss_classifier: 5.4263 (5.7650)  loss_box_reg: 0.2328 (0.2380)  loss_objectness: 0.1451 (0.1512)  loss_rpn_box_reg: 0.0518 (0.0727)  time: 0.6234  data: 0.1422  max mem: 10734\n",
      "Training Epoch: [39]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 5.8806 (6.2195)  loss_classifier: 5.5116 (5.7573)  loss_box_reg: 0.2354 (0.2390)  loss_objectness: 0.1314 (0.1510)  loss_rpn_box_reg: 0.0510 (0.0722)  time: 0.6081  data: 0.1409  max mem: 10734\n",
      "Training Epoch: [39]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.0570 (6.2180)  loss_classifier: 5.6121 (5.7535)  loss_box_reg: 0.2438 (0.2399)  loss_objectness: 0.1511 (0.1517)  loss_rpn_box_reg: 0.0689 (0.0729)  time: 0.6186  data: 0.1410  max mem: 10734\n",
      "Training Epoch: [39]  [250/500]  eta: 0:02:37  lr: 0.000000  loss: 6.1259 (6.2098)  loss_classifier: 5.6270 (5.7469)  loss_box_reg: 0.2373 (0.2395)  loss_objectness: 0.1388 (0.1508)  loss_rpn_box_reg: 0.0606 (0.0726)  time: 0.6393  data: 0.1403  max mem: 10734\n",
      "Training Epoch: [39]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.0524 (6.2172)  loss_classifier: 5.7286 (5.7547)  loss_box_reg: 0.2413 (0.2390)  loss_objectness: 0.1281 (0.1505)  loss_rpn_box_reg: 0.0617 (0.0729)  time: 0.6220  data: 0.1390  max mem: 10734\n",
      "Training Epoch: [39]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.4161 (6.2235)  loss_classifier: 5.8955 (5.7599)  loss_box_reg: 0.2410 (0.2392)  loss_objectness: 0.1643 (0.1515)  loss_rpn_box_reg: 0.0617 (0.0729)  time: 0.6058  data: 0.1409  max mem: 10734\n",
      "Training Epoch: [39]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.3697 (6.2223)  loss_classifier: 5.8218 (5.7577)  loss_box_reg: 0.2361 (0.2394)  loss_objectness: 0.1731 (0.1519)  loss_rpn_box_reg: 0.0637 (0.0733)  time: 0.6135  data: 0.1411  max mem: 10734\n",
      "Training Epoch: [39]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.0836 (6.2148)  loss_classifier: 5.4631 (5.7502)  loss_box_reg: 0.2355 (0.2389)  loss_objectness: 0.1422 (0.1517)  loss_rpn_box_reg: 0.0801 (0.0740)  time: 0.6214  data: 0.1382  max mem: 10734\n",
      "Training Epoch: [39]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.0414 (6.2095)  loss_classifier: 5.4457 (5.7432)  loss_box_reg: 0.2219 (0.2398)  loss_objectness: 0.1615 (0.1523)  loss_rpn_box_reg: 0.0801 (0.0741)  time: 0.6211  data: 0.1399  max mem: 10734\n",
      "Training Epoch: [39]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 5.9491 (6.2043)  loss_classifier: 5.4527 (5.7378)  loss_box_reg: 0.2401 (0.2402)  loss_objectness: 0.1395 (0.1517)  loss_rpn_box_reg: 0.0829 (0.0746)  time: 0.6256  data: 0.1397  max mem: 10734\n",
      "Training Epoch: [39]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.0904 (6.2124)  loss_classifier: 5.5438 (5.7459)  loss_box_reg: 0.2390 (0.2405)  loss_objectness: 0.1377 (0.1514)  loss_rpn_box_reg: 0.0817 (0.0747)  time: 0.6360  data: 0.1385  max mem: 10734\n",
      "Training Epoch: [39]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.3905 (6.2154)  loss_classifier: 5.8396 (5.7482)  loss_box_reg: 0.2208 (0.2409)  loss_objectness: 0.1409 (0.1516)  loss_rpn_box_reg: 0.0696 (0.0747)  time: 0.6422  data: 0.1405  max mem: 10734\n",
      "Training Epoch: [39]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.3247 (6.2168)  loss_classifier: 5.8396 (5.7492)  loss_box_reg: 0.2413 (0.2414)  loss_objectness: 0.1485 (0.1517)  loss_rpn_box_reg: 0.0696 (0.0745)  time: 0.6383  data: 0.1387  max mem: 10734\n",
      "Training Epoch: [39]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.2545 (6.2184)  loss_classifier: 5.7684 (5.7504)  loss_box_reg: 0.2484 (0.2412)  loss_objectness: 0.1494 (0.1518)  loss_rpn_box_reg: 0.0694 (0.0749)  time: 0.6137  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [39]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1771 (6.2204)  loss_classifier: 5.7485 (5.7524)  loss_box_reg: 0.2269 (0.2410)  loss_objectness: 0.1494 (0.1518)  loss_rpn_box_reg: 0.0899 (0.0752)  time: 0.6008  data: 0.1375  max mem: 10734\n",
      "Training Epoch: [39]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.3149 (6.2210)  loss_classifier: 5.8420 (5.7547)  loss_box_reg: 0.2213 (0.2403)  loss_objectness: 0.1355 (0.1513)  loss_rpn_box_reg: 0.0626 (0.0747)  time: 0.6212  data: 0.1391  max mem: 10734\n",
      "Training Epoch: [39]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.2242 (6.2192)  loss_classifier: 5.7856 (5.7520)  loss_box_reg: 0.2103 (0.2410)  loss_objectness: 0.1381 (0.1511)  loss_rpn_box_reg: 0.0600 (0.0750)  time: 0.6403  data: 0.1391  max mem: 10734\n",
      "Training Epoch: [39]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1617 (6.2169)  loss_classifier: 5.6494 (5.7499)  loss_box_reg: 0.2150 (0.2404)  loss_objectness: 0.1462 (0.1514)  loss_rpn_box_reg: 0.0756 (0.0752)  time: 0.6377  data: 0.1393  max mem: 10734\n",
      "Training Epoch: [39]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2580 (6.2216)  loss_classifier: 5.7134 (5.7529)  loss_box_reg: 0.2434 (0.2412)  loss_objectness: 0.1557 (0.1519)  loss_rpn_box_reg: 0.0783 (0.0756)  time: 0.6368  data: 0.1417  max mem: 10734\n",
      "Training Epoch: [39]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.4051 (6.2240)  loss_classifier: 5.8765 (5.7557)  loss_box_reg: 0.2253 (0.2405)  loss_objectness: 0.1547 (0.1519)  loss_rpn_box_reg: 0.0835 (0.0759)  time: 0.6367  data: 0.1414  max mem: 10734\n",
      "Training Epoch: [39]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.4073 (6.2238)  loss_classifier: 5.8765 (5.7563)  loss_box_reg: 0.2157 (0.2402)  loss_objectness: 0.1405 (0.1515)  loss_rpn_box_reg: 0.0728 (0.0757)  time: 0.6344  data: 0.1385  max mem: 10734\n",
      "Training Epoch: [39]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1001 (6.2211)  loss_classifier: 5.6002 (5.7530)  loss_box_reg: 0.2360 (0.2404)  loss_objectness: 0.1285 (0.1518)  loss_rpn_box_reg: 0.0727 (0.0758)  time: 0.6388  data: 0.1392  max mem: 10734\n",
      "Training Epoch: [39]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 5.9594 (6.2161)  loss_classifier: 5.4383 (5.7482)  loss_box_reg: 0.2420 (0.2406)  loss_objectness: 0.1321 (0.1516)  loss_rpn_box_reg: 0.0717 (0.0757)  time: 0.6402  data: 0.1389  max mem: 10734\n",
      "Training Epoch: [39]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0589 (6.2184)  loss_classifier: 5.5231 (5.7511)  loss_box_reg: 0.2178 (0.2400)  loss_objectness: 0.1364 (0.1517)  loss_rpn_box_reg: 0.0580 (0.0756)  time: 0.6280  data: 0.1385  max mem: 10734\n",
      "Training Epoch: [39]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0589 (6.2180)  loss_classifier: 5.5271 (5.7509)  loss_box_reg: 0.2121 (0.2398)  loss_objectness: 0.1488 (0.1518)  loss_rpn_box_reg: 0.0654 (0.0754)  time: 0.6227  data: 0.1384  max mem: 10734\n",
      "Training Epoch: [39]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 5.9052 (6.2179)  loss_classifier: 5.4449 (5.7505)  loss_box_reg: 0.2330 (0.2402)  loss_objectness: 0.1307 (0.1516)  loss_rpn_box_reg: 0.0728 (0.0757)  time: 0.6316  data: 0.1398  max mem: 10734\n",
      "Training Epoch: [39]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1716 (6.2142)  loss_classifier: 5.6862 (5.7465)  loss_box_reg: 0.2330 (0.2402)  loss_objectness: 0.1414 (0.1516)  loss_rpn_box_reg: 0.0859 (0.0760)  time: 0.6337  data: 0.1407  max mem: 10734\n",
      "Training Epoch: [39]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1699 (6.2117)  loss_classifier: 5.5990 (5.7436)  loss_box_reg: 0.2418 (0.2406)  loss_objectness: 0.1570 (0.1517)  loss_rpn_box_reg: 0.0806 (0.0758)  time: 0.6265  data: 0.1444  max mem: 10734\n",
      "Training Epoch: [39]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1132 (6.2139)  loss_classifier: 5.5461 (5.7454)  loss_box_reg: 0.2567 (0.2407)  loss_objectness: 0.1530 (0.1517)  loss_rpn_box_reg: 0.0682 (0.0760)  time: 0.6291  data: 0.1463  max mem: 10734\n",
      "Training Epoch: [39] Total time: 0:05:14 (0.6285 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:48  model_time: 0.6732 (0.6732)  evaluator_time: 0.0350 (0.0350)  time: 0.8662  data: 0.1490  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4391 (0.4503)  evaluator_time: 0.0340 (0.0368)  time: 0.6309  data: 0.1470  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4651 (0.4523)  evaluator_time: 0.0360 (0.0372)  time: 0.6525  data: 0.1479  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6409 s / it)\n",
      "Averaged stats: model_time: 0.4651 (0.4523)  evaluator_time: 0.0360 (0.0372)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [39]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1934 (6.1934)  loss_classifier: 5.6425 (5.6425)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1257 (0.1257)  loss_rpn_box_reg: 0.1306 (0.1306)  time: 0.6411  data: 0.1400  max mem: 10734\n",
      "Testing Epoch: [39]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9893 (6.1278)  loss_classifier: 5.4154 (5.6183)  loss_box_reg: 0.2609 (0.2886)  loss_objectness: 0.1318 (0.1321)  loss_rpn_box_reg: 0.0711 (0.0888)  time: 0.5845  data: 0.1450  max mem: 10734\n",
      "Testing Epoch: [39]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1500 (6.1614)  loss_classifier: 5.6906 (5.6558)  loss_box_reg: 0.2500 (0.2842)  loss_objectness: 0.1221 (0.1323)  loss_rpn_box_reg: 0.0745 (0.0890)  time: 0.5975  data: 0.1448  max mem: 10734\n",
      "Testing Epoch: [39] Total time: 0:01:14 (0.5958 s / it)\n",
      "Training Epoch: [40]  [  0/500]  eta: 0:06:27  lr: 0.000000  loss: 5.7637 (5.7637)  loss_classifier: 5.2718 (5.2718)  loss_box_reg: 0.2508 (0.2508)  loss_objectness: 0.1439 (0.1439)  loss_rpn_box_reg: 0.0971 (0.0971)  time: 0.7752  data: 0.1230  max mem: 10734\n",
      "Training Epoch: [40]  [ 10/500]  eta: 0:05:10  lr: 0.000000  loss: 6.1779 (6.1038)  loss_classifier: 5.5466 (5.5347)  loss_box_reg: 0.2677 (0.2978)  loss_objectness: 0.1727 (0.1685)  loss_rpn_box_reg: 0.0997 (0.1027)  time: 0.6341  data: 0.1384  max mem: 10734\n",
      "Training Epoch: [40]  [ 20/500]  eta: 0:05:01  lr: 0.000000  loss: 6.1779 (6.1366)  loss_classifier: 5.7135 (5.6211)  loss_box_reg: 0.2493 (0.2690)  loss_objectness: 0.1503 (0.1561)  loss_rpn_box_reg: 0.0781 (0.0905)  time: 0.6210  data: 0.1378  max mem: 10734\n",
      "Training Epoch: [40]  [ 30/500]  eta: 0:04:57  lr: 0.000000  loss: 6.1872 (6.2187)  loss_classifier: 5.7834 (5.7154)  loss_box_reg: 0.2264 (0.2575)  loss_objectness: 0.1385 (0.1569)  loss_rpn_box_reg: 0.0715 (0.0891)  time: 0.6324  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [40]  [ 40/500]  eta: 0:04:50  lr: 0.000000  loss: 6.1079 (6.1677)  loss_classifier: 5.6201 (5.6686)  loss_box_reg: 0.2190 (0.2565)  loss_objectness: 0.1431 (0.1528)  loss_rpn_box_reg: 0.0899 (0.0898)  time: 0.6340  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [40]  [ 50/500]  eta: 0:04:44  lr: 0.000000  loss: 6.0946 (6.1723)  loss_classifier: 5.6904 (5.6839)  loss_box_reg: 0.2190 (0.2496)  loss_objectness: 0.1416 (0.1509)  loss_rpn_box_reg: 0.0903 (0.0880)  time: 0.6288  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [40]  [ 60/500]  eta: 0:04:37  lr: 0.000000  loss: 6.1597 (6.2040)  loss_classifier: 5.7478 (5.7177)  loss_box_reg: 0.2087 (0.2471)  loss_objectness: 0.1442 (0.1523)  loss_rpn_box_reg: 0.0736 (0.0869)  time: 0.6268  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [40]  [ 70/500]  eta: 0:04:31  lr: 0.000000  loss: 5.9626 (6.1651)  loss_classifier: 5.5864 (5.6847)  loss_box_reg: 0.2407 (0.2465)  loss_objectness: 0.1420 (0.1499)  loss_rpn_box_reg: 0.0712 (0.0839)  time: 0.6275  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [40]  [ 80/500]  eta: 0:04:24  lr: 0.000000  loss: 5.9626 (6.1699)  loss_classifier: 5.5501 (5.6850)  loss_box_reg: 0.2558 (0.2475)  loss_objectness: 0.1420 (0.1519)  loss_rpn_box_reg: 0.0713 (0.0855)  time: 0.6303  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [40]  [ 90/500]  eta: 0:04:18  lr: 0.000000  loss: 6.0817 (6.1451)  loss_classifier: 5.4888 (5.6657)  loss_box_reg: 0.2551 (0.2443)  loss_objectness: 0.1567 (0.1513)  loss_rpn_box_reg: 0.0685 (0.0838)  time: 0.6297  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [40]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 6.0028 (6.1370)  loss_classifier: 5.4888 (5.6614)  loss_box_reg: 0.2035 (0.2398)  loss_objectness: 0.1597 (0.1520)  loss_rpn_box_reg: 0.0685 (0.0838)  time: 0.6243  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [40]  [110/500]  eta: 0:04:05  lr: 0.000000  loss: 6.1551 (6.1609)  loss_classifier: 5.7339 (5.6863)  loss_box_reg: 0.2000 (0.2399)  loss_objectness: 0.1620 (0.1516)  loss_rpn_box_reg: 0.0723 (0.0831)  time: 0.6228  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [40]  [120/500]  eta: 0:03:59  lr: 0.000000  loss: 6.3027 (6.1885)  loss_classifier: 5.9813 (5.7138)  loss_box_reg: 0.2337 (0.2400)  loss_objectness: 0.1530 (0.1528)  loss_rpn_box_reg: 0.0723 (0.0818)  time: 0.6351  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [40]  [130/500]  eta: 0:03:53  lr: 0.000000  loss: 6.2450 (6.1936)  loss_classifier: 5.7703 (5.7184)  loss_box_reg: 0.2394 (0.2402)  loss_objectness: 0.1636 (0.1538)  loss_rpn_box_reg: 0.0682 (0.0812)  time: 0.6353  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [40]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.2207 (6.1994)  loss_classifier: 5.7072 (5.7252)  loss_box_reg: 0.2212 (0.2399)  loss_objectness: 0.1537 (0.1537)  loss_rpn_box_reg: 0.0665 (0.0806)  time: 0.6150  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [40]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 6.1259 (6.1945)  loss_classifier: 5.6940 (5.7231)  loss_box_reg: 0.2253 (0.2381)  loss_objectness: 0.1418 (0.1534)  loss_rpn_box_reg: 0.0551 (0.0799)  time: 0.6230  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [40]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.1259 (6.1958)  loss_classifier: 5.6788 (5.7244)  loss_box_reg: 0.2268 (0.2381)  loss_objectness: 0.1571 (0.1541)  loss_rpn_box_reg: 0.0556 (0.0792)  time: 0.6273  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [40]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.4438 (6.2193)  loss_classifier: 5.9554 (5.7494)  loss_box_reg: 0.2144 (0.2361)  loss_objectness: 0.1624 (0.1542)  loss_rpn_box_reg: 0.0814 (0.0797)  time: 0.6079  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [40]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.4522 (6.2255)  loss_classifier: 6.0410 (5.7541)  loss_box_reg: 0.2220 (0.2386)  loss_objectness: 0.1451 (0.1538)  loss_rpn_box_reg: 0.0747 (0.0790)  time: 0.6030  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [40]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.1601 (6.2253)  loss_classifier: 5.7290 (5.7539)  loss_box_reg: 0.2724 (0.2402)  loss_objectness: 0.1274 (0.1524)  loss_rpn_box_reg: 0.0670 (0.0788)  time: 0.6100  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [40]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.3018 (6.2308)  loss_classifier: 5.7631 (5.7580)  loss_box_reg: 0.2485 (0.2409)  loss_objectness: 0.1308 (0.1530)  loss_rpn_box_reg: 0.0724 (0.0789)  time: 0.6090  data: 0.1314  max mem: 10734\n",
      "Training Epoch: [40]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.2661 (6.2226)  loss_classifier: 5.7631 (5.7512)  loss_box_reg: 0.2248 (0.2400)  loss_objectness: 0.1454 (0.1525)  loss_rpn_box_reg: 0.0759 (0.0789)  time: 0.5997  data: 0.1308  max mem: 10734\n",
      "Training Epoch: [40]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.2661 (6.2192)  loss_classifier: 5.6798 (5.7485)  loss_box_reg: 0.2133 (0.2391)  loss_objectness: 0.1406 (0.1526)  loss_rpn_box_reg: 0.0858 (0.0790)  time: 0.6115  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [40]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.2764 (6.2165)  loss_classifier: 5.6798 (5.7459)  loss_box_reg: 0.2258 (0.2395)  loss_objectness: 0.1376 (0.1524)  loss_rpn_box_reg: 0.0637 (0.0787)  time: 0.6281  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [40]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.2728 (6.2193)  loss_classifier: 5.7891 (5.7502)  loss_box_reg: 0.2282 (0.2389)  loss_objectness: 0.1368 (0.1518)  loss_rpn_box_reg: 0.0573 (0.0784)  time: 0.6328  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [40]  [250/500]  eta: 0:02:35  lr: 0.000000  loss: 6.2728 (6.2176)  loss_classifier: 5.7513 (5.7495)  loss_box_reg: 0.2178 (0.2389)  loss_objectness: 0.1368 (0.1515)  loss_rpn_box_reg: 0.0513 (0.0776)  time: 0.6322  data: 0.1313  max mem: 10734\n",
      "Training Epoch: [40]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.1065 (6.2164)  loss_classifier: 5.6697 (5.7483)  loss_box_reg: 0.2437 (0.2393)  loss_objectness: 0.1382 (0.1515)  loss_rpn_box_reg: 0.0494 (0.0772)  time: 0.6230  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [40]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.1514 (6.2188)  loss_classifier: 5.6920 (5.7502)  loss_box_reg: 0.2614 (0.2401)  loss_objectness: 0.1346 (0.1516)  loss_rpn_box_reg: 0.0566 (0.0769)  time: 0.6168  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [40]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.1308 (6.2151)  loss_classifier: 5.6985 (5.7464)  loss_box_reg: 0.2358 (0.2400)  loss_objectness: 0.1533 (0.1516)  loss_rpn_box_reg: 0.0684 (0.0772)  time: 0.6213  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [40]  [290/500]  eta: 0:02:10  lr: 0.000000  loss: 6.1308 (6.2149)  loss_classifier: 5.6209 (5.7445)  loss_box_reg: 0.2651 (0.2414)  loss_objectness: 0.1550 (0.1520)  loss_rpn_box_reg: 0.0715 (0.0770)  time: 0.6271  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [40]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.3302 (6.2179)  loss_classifier: 5.7549 (5.7437)  loss_box_reg: 0.2736 (0.2438)  loss_objectness: 0.1749 (0.1528)  loss_rpn_box_reg: 0.0743 (0.0776)  time: 0.6239  data: 0.1375  max mem: 10734\n",
      "Training Epoch: [40]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.1723 (6.2154)  loss_classifier: 5.7123 (5.7421)  loss_box_reg: 0.2651 (0.2436)  loss_objectness: 0.1577 (0.1523)  loss_rpn_box_reg: 0.0898 (0.0774)  time: 0.6287  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [40]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1723 (6.2205)  loss_classifier: 5.7123 (5.7479)  loss_box_reg: 0.2121 (0.2429)  loss_objectness: 0.1339 (0.1519)  loss_rpn_box_reg: 0.0736 (0.0778)  time: 0.6435  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [40]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.3060 (6.2191)  loss_classifier: 5.8329 (5.7479)  loss_box_reg: 0.2126 (0.2424)  loss_objectness: 0.1407 (0.1514)  loss_rpn_box_reg: 0.0644 (0.0773)  time: 0.6364  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [40]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.1516 (6.2175)  loss_classifier: 5.7223 (5.7463)  loss_box_reg: 0.2248 (0.2430)  loss_objectness: 0.1412 (0.1513)  loss_rpn_box_reg: 0.0514 (0.0769)  time: 0.6291  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [40]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 5.9992 (6.2158)  loss_classifier: 5.6394 (5.7454)  loss_box_reg: 0.2423 (0.2430)  loss_objectness: 0.1400 (0.1508)  loss_rpn_box_reg: 0.0521 (0.0766)  time: 0.6273  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [40]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 5.9406 (6.2130)  loss_classifier: 5.5205 (5.7410)  loss_box_reg: 0.2541 (0.2437)  loss_objectness: 0.1382 (0.1515)  loss_rpn_box_reg: 0.0750 (0.0768)  time: 0.6154  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [40]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.3649 (6.2159)  loss_classifier: 5.7967 (5.7427)  loss_box_reg: 0.2427 (0.2441)  loss_objectness: 0.1815 (0.1518)  loss_rpn_box_reg: 0.0855 (0.0773)  time: 0.6164  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [40]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.3649 (6.2122)  loss_classifier: 5.7933 (5.7392)  loss_box_reg: 0.2400 (0.2437)  loss_objectness: 0.1519 (0.1520)  loss_rpn_box_reg: 0.0757 (0.0774)  time: 0.6247  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [40]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.0540 (6.2098)  loss_classifier: 5.6462 (5.7382)  loss_box_reg: 0.2210 (0.2429)  loss_objectness: 0.1497 (0.1518)  loss_rpn_box_reg: 0.0590 (0.0770)  time: 0.6212  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [40]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1347 (6.2104)  loss_classifier: 5.6800 (5.7400)  loss_box_reg: 0.2161 (0.2423)  loss_objectness: 0.1416 (0.1512)  loss_rpn_box_reg: 0.0558 (0.0770)  time: 0.6357  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [40]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.0620 (6.2057)  loss_classifier: 5.6192 (5.7366)  loss_box_reg: 0.1969 (0.2413)  loss_objectness: 0.1316 (0.1511)  loss_rpn_box_reg: 0.0586 (0.0769)  time: 0.6340  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [40]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.0620 (6.2095)  loss_classifier: 5.6190 (5.7410)  loss_box_reg: 0.1987 (0.2407)  loss_objectness: 0.1529 (0.1512)  loss_rpn_box_reg: 0.0637 (0.0766)  time: 0.6209  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [40]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2917 (6.2147)  loss_classifier: 5.7380 (5.7459)  loss_box_reg: 0.2493 (0.2415)  loss_objectness: 0.1451 (0.1510)  loss_rpn_box_reg: 0.0573 (0.0763)  time: 0.6248  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [40]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1798 (6.2072)  loss_classifier: 5.7380 (5.7386)  loss_box_reg: 0.2638 (0.2414)  loss_objectness: 0.1385 (0.1509)  loss_rpn_box_reg: 0.0594 (0.0764)  time: 0.6175  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [40]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.2646 (6.2147)  loss_classifier: 5.8616 (5.7458)  loss_box_reg: 0.2371 (0.2413)  loss_objectness: 0.1472 (0.1508)  loss_rpn_box_reg: 0.0834 (0.0768)  time: 0.6187  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [40]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.4079 (6.2117)  loss_classifier: 5.9067 (5.7428)  loss_box_reg: 0.2425 (0.2411)  loss_objectness: 0.1472 (0.1510)  loss_rpn_box_reg: 0.0783 (0.0768)  time: 0.6306  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [40]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1625 (6.2146)  loss_classifier: 5.7432 (5.7462)  loss_box_reg: 0.2346 (0.2406)  loss_objectness: 0.1556 (0.1513)  loss_rpn_box_reg: 0.0630 (0.0765)  time: 0.6342  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [40]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2150 (6.2150)  loss_classifier: 5.7809 (5.7466)  loss_box_reg: 0.2101 (0.2403)  loss_objectness: 0.1584 (0.1516)  loss_rpn_box_reg: 0.0581 (0.0765)  time: 0.6429  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [40]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.2011 (6.2138)  loss_classifier: 5.7698 (5.7451)  loss_box_reg: 0.2293 (0.2405)  loss_objectness: 0.1560 (0.1518)  loss_rpn_box_reg: 0.0725 (0.0764)  time: 0.6391  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [40]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1748 (6.2133)  loss_classifier: 5.6425 (5.7454)  loss_box_reg: 0.2293 (0.2403)  loss_objectness: 0.1560 (0.1516)  loss_rpn_box_reg: 0.0665 (0.0761)  time: 0.6285  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [40] Total time: 0:05:12 (0.6257 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:01  model_time: 0.7012 (0.7012)  evaluator_time: 0.0340 (0.0340)  time: 0.9699  data: 0.2247  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4381 (0.4505)  evaluator_time: 0.0340 (0.0379)  time: 0.6333  data: 0.1532  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4661 (0.4518)  evaluator_time: 0.0350 (0.0380)  time: 0.6560  data: 0.1540  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6400 s / it)\n",
      "Averaged stats: model_time: 0.4661 (0.4518)  evaluator_time: 0.0350 (0.0380)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [40]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.1862 (6.1862)  loss_classifier: 5.6435 (5.6435)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1163 (0.1163)  loss_rpn_box_reg: 0.1320 (0.1320)  time: 0.6521  data: 0.1360  max mem: 10734\n",
      "Testing Epoch: [40]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0213 (6.1232)  loss_classifier: 5.4221 (5.6121)  loss_box_reg: 0.2609 (0.2901)  loss_objectness: 0.1293 (0.1311)  loss_rpn_box_reg: 0.0720 (0.0899)  time: 0.5842  data: 0.1449  max mem: 10734\n",
      "Testing Epoch: [40]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1585 (6.1565)  loss_classifier: 5.6737 (5.6501)  loss_box_reg: 0.2500 (0.2854)  loss_objectness: 0.1189 (0.1311)  loss_rpn_box_reg: 0.0745 (0.0899)  time: 0.5987  data: 0.1458  max mem: 10734\n",
      "Testing Epoch: [40] Total time: 0:01:14 (0.5964 s / it)\n",
      "Training Epoch: [41]  [  0/500]  eta: 0:07:15  lr: 0.000000  loss: 6.3768 (6.3768)  loss_classifier: 5.9726 (5.9726)  loss_box_reg: 0.1843 (0.1843)  loss_objectness: 0.1463 (0.1463)  loss_rpn_box_reg: 0.0736 (0.0736)  time: 0.8702  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [41]  [ 10/500]  eta: 0:05:20  lr: 0.000000  loss: 6.1582 (6.0578)  loss_classifier: 5.6655 (5.5730)  loss_box_reg: 0.2554 (0.2597)  loss_objectness: 0.1312 (0.1438)  loss_rpn_box_reg: 0.0766 (0.0813)  time: 0.6541  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [41]  [ 20/500]  eta: 0:05:10  lr: 0.000000  loss: 6.1582 (6.1562)  loss_classifier: 5.6655 (5.6528)  loss_box_reg: 0.2615 (0.2661)  loss_objectness: 0.1312 (0.1495)  loss_rpn_box_reg: 0.0753 (0.0878)  time: 0.6368  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [41]  [ 30/500]  eta: 0:05:00  lr: 0.000000  loss: 6.2658 (6.1731)  loss_classifier: 5.7037 (5.6721)  loss_box_reg: 0.2974 (0.2679)  loss_objectness: 0.1406 (0.1485)  loss_rpn_box_reg: 0.0709 (0.0847)  time: 0.6316  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [41]  [ 40/500]  eta: 0:04:54  lr: 0.000000  loss: 6.1830 (6.1547)  loss_classifier: 5.6103 (5.6616)  loss_box_reg: 0.2234 (0.2566)  loss_objectness: 0.1478 (0.1534)  loss_rpn_box_reg: 0.0663 (0.0832)  time: 0.6318  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [41]  [ 50/500]  eta: 0:04:47  lr: 0.000000  loss: 6.0700 (6.1765)  loss_classifier: 5.6819 (5.6920)  loss_box_reg: 0.2226 (0.2501)  loss_objectness: 0.1589 (0.1536)  loss_rpn_box_reg: 0.0661 (0.0809)  time: 0.6398  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [41]  [ 60/500]  eta: 0:04:41  lr: 0.000000  loss: 6.3789 (6.2364)  loss_classifier: 5.8957 (5.7603)  loss_box_reg: 0.2071 (0.2458)  loss_objectness: 0.1491 (0.1527)  loss_rpn_box_reg: 0.0578 (0.0776)  time: 0.6403  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [41]  [ 70/500]  eta: 0:04:35  lr: 0.000000  loss: 6.3274 (6.2323)  loss_classifier: 5.8762 (5.7629)  loss_box_reg: 0.2132 (0.2421)  loss_objectness: 0.1491 (0.1515)  loss_rpn_box_reg: 0.0588 (0.0758)  time: 0.6408  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [41]  [ 80/500]  eta: 0:04:26  lr: 0.000000  loss: 6.1896 (6.2176)  loss_classifier: 5.7546 (5.7486)  loss_box_reg: 0.2188 (0.2431)  loss_objectness: 0.1459 (0.1512)  loss_rpn_box_reg: 0.0588 (0.0746)  time: 0.6213  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [41]  [ 90/500]  eta: 0:04:20  lr: 0.000000  loss: 6.1904 (6.2107)  loss_classifier: 5.7546 (5.7448)  loss_box_reg: 0.2188 (0.2391)  loss_objectness: 0.1459 (0.1516)  loss_rpn_box_reg: 0.0597 (0.0752)  time: 0.6177  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [41]  [100/500]  eta: 0:04:13  lr: 0.000000  loss: 6.0840 (6.2054)  loss_classifier: 5.6514 (5.7484)  loss_box_reg: 0.1900 (0.2356)  loss_objectness: 0.1264 (0.1484)  loss_rpn_box_reg: 0.0693 (0.0731)  time: 0.6329  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [41]  [110/500]  eta: 0:04:06  lr: 0.000000  loss: 6.2891 (6.2144)  loss_classifier: 5.7255 (5.7529)  loss_box_reg: 0.2406 (0.2369)  loss_objectness: 0.1264 (0.1507)  loss_rpn_box_reg: 0.0693 (0.0739)  time: 0.6240  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [41]  [120/500]  eta: 0:04:00  lr: 0.000000  loss: 6.3038 (6.2338)  loss_classifier: 5.7255 (5.7699)  loss_box_reg: 0.2546 (0.2383)  loss_objectness: 0.1562 (0.1508)  loss_rpn_box_reg: 0.0735 (0.0748)  time: 0.6200  data: 0.1375  max mem: 10734\n",
      "Training Epoch: [41]  [130/500]  eta: 0:03:54  lr: 0.000000  loss: 6.0629 (6.2140)  loss_classifier: 5.5773 (5.7481)  loss_box_reg: 0.2471 (0.2392)  loss_objectness: 0.1492 (0.1508)  loss_rpn_box_reg: 0.0799 (0.0758)  time: 0.6393  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [41]  [140/500]  eta: 0:03:48  lr: 0.000000  loss: 6.0629 (6.2206)  loss_classifier: 5.6253 (5.7578)  loss_box_reg: 0.2113 (0.2362)  loss_objectness: 0.1489 (0.1515)  loss_rpn_box_reg: 0.0731 (0.0752)  time: 0.6452  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [41]  [150/500]  eta: 0:03:42  lr: 0.000000  loss: 6.0511 (6.2065)  loss_classifier: 5.7129 (5.7410)  loss_box_reg: 0.2149 (0.2388)  loss_objectness: 0.1526 (0.1517)  loss_rpn_box_reg: 0.0731 (0.0750)  time: 0.6396  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [41]  [160/500]  eta: 0:03:35  lr: 0.000000  loss: 5.8451 (6.1904)  loss_classifier: 5.3599 (5.7253)  loss_box_reg: 0.2350 (0.2380)  loss_objectness: 0.1566 (0.1522)  loss_rpn_box_reg: 0.0657 (0.0749)  time: 0.6317  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [41]  [170/500]  eta: 0:03:29  lr: 0.000000  loss: 6.1894 (6.1974)  loss_classifier: 5.7347 (5.7287)  loss_box_reg: 0.2517 (0.2412)  loss_objectness: 0.1514 (0.1525)  loss_rpn_box_reg: 0.0657 (0.0750)  time: 0.6245  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [41]  [180/500]  eta: 0:03:22  lr: 0.000000  loss: 6.2664 (6.1976)  loss_classifier: 5.7347 (5.7293)  loss_box_reg: 0.2634 (0.2404)  loss_objectness: 0.1514 (0.1528)  loss_rpn_box_reg: 0.0678 (0.0750)  time: 0.6347  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [41]  [190/500]  eta: 0:03:16  lr: 0.000000  loss: 6.1162 (6.2057)  loss_classifier: 5.6776 (5.7370)  loss_box_reg: 0.2273 (0.2400)  loss_objectness: 0.1667 (0.1536)  loss_rpn_box_reg: 0.0671 (0.0751)  time: 0.6336  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [41]  [200/500]  eta: 0:03:10  lr: 0.000000  loss: 6.0997 (6.2069)  loss_classifier: 5.6941 (5.7399)  loss_box_reg: 0.2408 (0.2399)  loss_objectness: 0.1329 (0.1521)  loss_rpn_box_reg: 0.0697 (0.0749)  time: 0.6395  data: 0.1370  max mem: 10734\n",
      "Training Epoch: [41]  [210/500]  eta: 0:03:04  lr: 0.000000  loss: 6.0679 (6.2018)  loss_classifier: 5.6662 (5.7357)  loss_box_reg: 0.2202 (0.2385)  loss_objectness: 0.1329 (0.1523)  loss_rpn_box_reg: 0.0807 (0.0754)  time: 0.6548  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [41]  [220/500]  eta: 0:02:57  lr: 0.000000  loss: 6.0909 (6.2019)  loss_classifier: 5.6492 (5.7364)  loss_box_reg: 0.2154 (0.2379)  loss_objectness: 0.1430 (0.1521)  loss_rpn_box_reg: 0.0618 (0.0754)  time: 0.6383  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [41]  [230/500]  eta: 0:02:51  lr: 0.000000  loss: 6.0909 (6.1927)  loss_classifier: 5.6267 (5.7259)  loss_box_reg: 0.2268 (0.2385)  loss_objectness: 0.1401 (0.1522)  loss_rpn_box_reg: 0.0617 (0.0760)  time: 0.6226  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [41]  [240/500]  eta: 0:02:44  lr: 0.000000  loss: 6.1190 (6.1992)  loss_classifier: 5.6277 (5.7337)  loss_box_reg: 0.2391 (0.2383)  loss_objectness: 0.1401 (0.1518)  loss_rpn_box_reg: 0.0613 (0.0754)  time: 0.6220  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [41]  [250/500]  eta: 0:02:38  lr: 0.000000  loss: 6.3267 (6.2054)  loss_classifier: 5.8335 (5.7379)  loss_box_reg: 0.2334 (0.2390)  loss_objectness: 0.1532 (0.1527)  loss_rpn_box_reg: 0.0654 (0.0757)  time: 0.6334  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [41]  [260/500]  eta: 0:02:32  lr: 0.000000  loss: 6.3267 (6.2071)  loss_classifier: 5.7926 (5.7398)  loss_box_reg: 0.2334 (0.2384)  loss_objectness: 0.1516 (0.1529)  loss_rpn_box_reg: 0.0785 (0.0760)  time: 0.6321  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [41]  [270/500]  eta: 0:02:25  lr: 0.000000  loss: 6.0800 (6.2025)  loss_classifier: 5.6108 (5.7355)  loss_box_reg: 0.2204 (0.2378)  loss_objectness: 0.1499 (0.1529)  loss_rpn_box_reg: 0.0761 (0.0763)  time: 0.6133  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [41]  [280/500]  eta: 0:02:19  lr: 0.000000  loss: 6.0800 (6.2061)  loss_classifier: 5.6894 (5.7393)  loss_box_reg: 0.2204 (0.2376)  loss_objectness: 0.1504 (0.1529)  loss_rpn_box_reg: 0.0699 (0.0762)  time: 0.6132  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [41]  [290/500]  eta: 0:02:12  lr: 0.000000  loss: 6.2438 (6.2022)  loss_classifier: 5.7354 (5.7341)  loss_box_reg: 0.2684 (0.2388)  loss_objectness: 0.1360 (0.1525)  loss_rpn_box_reg: 0.0719 (0.0767)  time: 0.6182  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [41]  [300/500]  eta: 0:02:06  lr: 0.000000  loss: 6.2438 (6.2043)  loss_classifier: 5.7299 (5.7364)  loss_box_reg: 0.2590 (0.2394)  loss_objectness: 0.1325 (0.1522)  loss_rpn_box_reg: 0.0755 (0.0763)  time: 0.6217  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [41]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.1979 (6.2030)  loss_classifier: 5.6491 (5.7346)  loss_box_reg: 0.2463 (0.2397)  loss_objectness: 0.1429 (0.1526)  loss_rpn_box_reg: 0.0706 (0.0761)  time: 0.6245  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [41]  [320/500]  eta: 0:01:53  lr: 0.000000  loss: 6.2914 (6.2083)  loss_classifier: 5.7121 (5.7391)  loss_box_reg: 0.2511 (0.2402)  loss_objectness: 0.1731 (0.1532)  loss_rpn_box_reg: 0.0667 (0.0759)  time: 0.6132  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [41]  [330/500]  eta: 0:01:47  lr: 0.000000  loss: 6.0933 (6.2046)  loss_classifier: 5.7018 (5.7340)  loss_box_reg: 0.2621 (0.2411)  loss_objectness: 0.1473 (0.1534)  loss_rpn_box_reg: 0.0740 (0.0761)  time: 0.6082  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [41]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.0933 (6.2131)  loss_classifier: 5.6928 (5.7432)  loss_box_reg: 0.2296 (0.2412)  loss_objectness: 0.1423 (0.1530)  loss_rpn_box_reg: 0.0706 (0.0757)  time: 0.6212  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [41]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.1995 (6.2049)  loss_classifier: 5.6928 (5.7339)  loss_box_reg: 0.2195 (0.2418)  loss_objectness: 0.1496 (0.1535)  loss_rpn_box_reg: 0.0682 (0.0758)  time: 0.6198  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [41]  [360/500]  eta: 0:01:28  lr: 0.000000  loss: 5.9790 (6.2027)  loss_classifier: 5.5811 (5.7310)  loss_box_reg: 0.2336 (0.2422)  loss_objectness: 0.1534 (0.1535)  loss_rpn_box_reg: 0.0725 (0.0760)  time: 0.6069  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [41]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1297 (6.2044)  loss_classifier: 5.6498 (5.7335)  loss_box_reg: 0.2133 (0.2417)  loss_objectness: 0.1504 (0.1532)  loss_rpn_box_reg: 0.0571 (0.0760)  time: 0.6071  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [41]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.3865 (6.2099)  loss_classifier: 5.8099 (5.7401)  loss_box_reg: 0.1982 (0.2413)  loss_objectness: 0.1272 (0.1527)  loss_rpn_box_reg: 0.0600 (0.0757)  time: 0.6120  data: 0.1315  max mem: 10734\n",
      "Training Epoch: [41]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 6.0875 (6.2097)  loss_classifier: 5.7778 (5.7403)  loss_box_reg: 0.1982 (0.2410)  loss_objectness: 0.1271 (0.1528)  loss_rpn_box_reg: 0.0600 (0.0757)  time: 0.6183  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [41]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.0875 (6.2089)  loss_classifier: 5.6848 (5.7404)  loss_box_reg: 0.2130 (0.2400)  loss_objectness: 0.1411 (0.1531)  loss_rpn_box_reg: 0.0623 (0.0755)  time: 0.6340  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [41]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2017 (6.2129)  loss_classifier: 5.7214 (5.7437)  loss_box_reg: 0.2209 (0.2409)  loss_objectness: 0.1432 (0.1528)  loss_rpn_box_reg: 0.0588 (0.0755)  time: 0.6328  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [41]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.2627 (6.2178)  loss_classifier: 5.8656 (5.7489)  loss_box_reg: 0.2385 (0.2407)  loss_objectness: 0.1308 (0.1527)  loss_rpn_box_reg: 0.0613 (0.0754)  time: 0.6112  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [41]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1935 (6.2132)  loss_classifier: 5.6808 (5.7444)  loss_box_reg: 0.2215 (0.2405)  loss_objectness: 0.1443 (0.1529)  loss_rpn_box_reg: 0.0620 (0.0755)  time: 0.6077  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [41]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 5.9257 (6.2065)  loss_classifier: 5.4525 (5.7383)  loss_box_reg: 0.1955 (0.2400)  loss_objectness: 0.1539 (0.1530)  loss_rpn_box_reg: 0.0620 (0.0752)  time: 0.6259  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [41]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0219 (6.2095)  loss_classifier: 5.6071 (5.7422)  loss_box_reg: 0.2112 (0.2397)  loss_objectness: 0.1445 (0.1526)  loss_rpn_box_reg: 0.0679 (0.0750)  time: 0.6215  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [41]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.1628 (6.2093)  loss_classifier: 5.7373 (5.7423)  loss_box_reg: 0.2159 (0.2393)  loss_objectness: 0.1518 (0.1528)  loss_rpn_box_reg: 0.0723 (0.0749)  time: 0.6138  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [41]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.3215 (6.2158)  loss_classifier: 5.8331 (5.7473)  loss_box_reg: 0.2245 (0.2398)  loss_objectness: 0.1571 (0.1531)  loss_rpn_box_reg: 0.0723 (0.0756)  time: 0.6140  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [41]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.3160 (6.2147)  loss_classifier: 5.8330 (5.7469)  loss_box_reg: 0.1963 (0.2392)  loss_objectness: 0.1551 (0.1533)  loss_rpn_box_reg: 0.0602 (0.0753)  time: 0.6182  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [41]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1925 (6.2138)  loss_classifier: 5.7895 (5.7451)  loss_box_reg: 0.2259 (0.2395)  loss_objectness: 0.1632 (0.1538)  loss_rpn_box_reg: 0.0543 (0.0754)  time: 0.6132  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [41]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1235 (6.2138)  loss_classifier: 5.7096 (5.7455)  loss_box_reg: 0.2259 (0.2390)  loss_objectness: 0.1632 (0.1536)  loss_rpn_box_reg: 0.0699 (0.0757)  time: 0.6192  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [41] Total time: 0:05:13 (0.6260 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:54  model_time: 0.7242 (0.7242)  evaluator_time: 0.0350 (0.0350)  time: 0.9162  data: 0.1470  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4441 (0.4534)  evaluator_time: 0.0340 (0.0341)  time: 0.6385  data: 0.1539  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4661 (0.4546)  evaluator_time: 0.0360 (0.0350)  time: 0.6527  data: 0.1477  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6432 s / it)\n",
      "Averaged stats: model_time: 0.4661 (0.4546)  evaluator_time: 0.0360 (0.0350)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [41]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1999 (6.1999)  loss_classifier: 5.6533 (5.6533)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1207 (0.1207)  loss_rpn_box_reg: 0.1314 (0.1314)  time: 0.6471  data: 0.1440  max mem: 10734\n",
      "Testing Epoch: [41]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9939 (6.1358)  loss_classifier: 5.4087 (5.6246)  loss_box_reg: 0.2609 (0.2899)  loss_objectness: 0.1308 (0.1318)  loss_rpn_box_reg: 0.0732 (0.0895)  time: 0.5887  data: 0.1480  max mem: 10734\n",
      "Testing Epoch: [41]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1738 (6.1672)  loss_classifier: 5.6804 (5.6604)  loss_box_reg: 0.2500 (0.2853)  loss_objectness: 0.1198 (0.1319)  loss_rpn_box_reg: 0.0745 (0.0896)  time: 0.6017  data: 0.1469  max mem: 10734\n",
      "Testing Epoch: [41] Total time: 0:01:14 (0.5979 s / it)\n",
      "Training Epoch: [42]  [  0/500]  eta: 0:06:46  lr: 0.000000  loss: 6.1113 (6.1113)  loss_classifier: 5.5780 (5.5780)  loss_box_reg: 0.2025 (0.2025)  loss_objectness: 0.1548 (0.1548)  loss_rpn_box_reg: 0.1761 (0.1761)  time: 0.8132  data: 0.1290  max mem: 10734\n",
      "Training Epoch: [42]  [ 10/500]  eta: 0:05:18  lr: 0.000000  loss: 5.8450 (5.8321)  loss_classifier: 5.3358 (5.3130)  loss_box_reg: 0.2796 (0.2777)  loss_objectness: 0.1548 (0.1507)  loss_rpn_box_reg: 0.0780 (0.0908)  time: 0.6509  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [42]  [ 20/500]  eta: 0:05:06  lr: 0.000000  loss: 5.8576 (5.9744)  loss_classifier: 5.4580 (5.4961)  loss_box_reg: 0.2038 (0.2495)  loss_objectness: 0.1386 (0.1442)  loss_rpn_box_reg: 0.0674 (0.0847)  time: 0.6305  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [42]  [ 30/500]  eta: 0:05:01  lr: 0.000000  loss: 6.0214 (6.0507)  loss_classifier: 5.6239 (5.5849)  loss_box_reg: 0.2153 (0.2424)  loss_objectness: 0.1446 (0.1455)  loss_rpn_box_reg: 0.0638 (0.0780)  time: 0.6365  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [42]  [ 40/500]  eta: 0:04:52  lr: 0.000000  loss: 6.2223 (6.1472)  loss_classifier: 5.7823 (5.6822)  loss_box_reg: 0.2154 (0.2382)  loss_objectness: 0.1550 (0.1502)  loss_rpn_box_reg: 0.0599 (0.0766)  time: 0.6329  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [42]  [ 50/500]  eta: 0:04:43  lr: 0.000000  loss: 6.3541 (6.1595)  loss_classifier: 5.8599 (5.6932)  loss_box_reg: 0.2154 (0.2393)  loss_objectness: 0.1513 (0.1497)  loss_rpn_box_reg: 0.0688 (0.0772)  time: 0.6118  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [42]  [ 60/500]  eta: 0:04:37  lr: 0.000000  loss: 6.2772 (6.1806)  loss_classifier: 5.7474 (5.7045)  loss_box_reg: 0.2632 (0.2464)  loss_objectness: 0.1370 (0.1484)  loss_rpn_box_reg: 0.0770 (0.0814)  time: 0.6176  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [42]  [ 70/500]  eta: 0:04:30  lr: 0.000000  loss: 6.1792 (6.1926)  loss_classifier: 5.7474 (5.7254)  loss_box_reg: 0.2388 (0.2436)  loss_objectness: 0.1378 (0.1461)  loss_rpn_box_reg: 0.0696 (0.0775)  time: 0.6268  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [42]  [ 80/500]  eta: 0:04:24  lr: 0.000000  loss: 6.1792 (6.1939)  loss_classifier: 5.7097 (5.7215)  loss_box_reg: 0.2535 (0.2477)  loss_objectness: 0.1383 (0.1455)  loss_rpn_box_reg: 0.0616 (0.0792)  time: 0.6283  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [42]  [ 90/500]  eta: 0:04:18  lr: 0.000000  loss: 6.1650 (6.1852)  loss_classifier: 5.6925 (5.7090)  loss_box_reg: 0.2648 (0.2499)  loss_objectness: 0.1508 (0.1471)  loss_rpn_box_reg: 0.0740 (0.0791)  time: 0.6331  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [42]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 5.9025 (6.1591)  loss_classifier: 5.4721 (5.6789)  loss_box_reg: 0.2473 (0.2522)  loss_objectness: 0.1571 (0.1479)  loss_rpn_box_reg: 0.0740 (0.0801)  time: 0.6175  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [42]  [110/500]  eta: 0:04:05  lr: 0.000000  loss: 6.0944 (6.1710)  loss_classifier: 5.5139 (5.6914)  loss_box_reg: 0.2295 (0.2519)  loss_objectness: 0.1460 (0.1487)  loss_rpn_box_reg: 0.0710 (0.0791)  time: 0.6238  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [42]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.2423 (6.1980)  loss_classifier: 5.8037 (5.7203)  loss_box_reg: 0.2283 (0.2496)  loss_objectness: 0.1524 (0.1500)  loss_rpn_box_reg: 0.0613 (0.0781)  time: 0.6372  data: 0.1383  max mem: 10734\n",
      "Training Epoch: [42]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 6.2423 (6.2007)  loss_classifier: 5.8037 (5.7252)  loss_box_reg: 0.2147 (0.2480)  loss_objectness: 0.1523 (0.1493)  loss_rpn_box_reg: 0.0595 (0.0783)  time: 0.6258  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [42]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.1571 (6.1886)  loss_classifier: 5.7708 (5.7156)  loss_box_reg: 0.2064 (0.2475)  loss_objectness: 0.1345 (0.1479)  loss_rpn_box_reg: 0.0595 (0.0775)  time: 0.6159  data: 0.1307  max mem: 10734\n",
      "Training Epoch: [42]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.2840 (6.2146)  loss_classifier: 5.8600 (5.7432)  loss_box_reg: 0.2064 (0.2456)  loss_objectness: 0.1316 (0.1482)  loss_rpn_box_reg: 0.0684 (0.0776)  time: 0.6206  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [42]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.3541 (6.2156)  loss_classifier: 5.8707 (5.7440)  loss_box_reg: 0.2351 (0.2459)  loss_objectness: 0.1458 (0.1484)  loss_rpn_box_reg: 0.0658 (0.0773)  time: 0.6244  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [42]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.2920 (6.2172)  loss_classifier: 5.8654 (5.7470)  loss_box_reg: 0.2333 (0.2451)  loss_objectness: 0.1419 (0.1482)  loss_rpn_box_reg: 0.0658 (0.0769)  time: 0.6268  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [42]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.2751 (6.2142)  loss_classifier: 5.7727 (5.7449)  loss_box_reg: 0.2333 (0.2452)  loss_objectness: 0.1393 (0.1476)  loss_rpn_box_reg: 0.0693 (0.0766)  time: 0.6367  data: 0.1378  max mem: 10734\n",
      "Training Epoch: [42]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.1966 (6.2106)  loss_classifier: 5.7192 (5.7449)  loss_box_reg: 0.2147 (0.2430)  loss_objectness: 0.1386 (0.1473)  loss_rpn_box_reg: 0.0560 (0.0753)  time: 0.6274  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [42]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.1495 (6.2076)  loss_classifier: 5.7798 (5.7436)  loss_box_reg: 0.2204 (0.2422)  loss_objectness: 0.1301 (0.1468)  loss_rpn_box_reg: 0.0607 (0.0750)  time: 0.6130  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [42]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.2338 (6.2113)  loss_classifier: 5.7421 (5.7461)  loss_box_reg: 0.2379 (0.2425)  loss_objectness: 0.1306 (0.1471)  loss_rpn_box_reg: 0.0655 (0.0755)  time: 0.6289  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [42]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.2468 (6.2147)  loss_classifier: 5.7421 (5.7506)  loss_box_reg: 0.2213 (0.2416)  loss_objectness: 0.1469 (0.1478)  loss_rpn_box_reg: 0.0498 (0.0747)  time: 0.6356  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [42]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.4251 (6.2191)  loss_classifier: 6.0181 (5.7555)  loss_box_reg: 0.2070 (0.2402)  loss_objectness: 0.1471 (0.1484)  loss_rpn_box_reg: 0.0580 (0.0750)  time: 0.6232  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [42]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.3611 (6.2251)  loss_classifier: 5.9269 (5.7609)  loss_box_reg: 0.2146 (0.2405)  loss_objectness: 0.1448 (0.1486)  loss_rpn_box_reg: 0.0733 (0.0751)  time: 0.6263  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [42]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.2025 (6.2190)  loss_classifier: 5.7259 (5.7551)  loss_box_reg: 0.2206 (0.2402)  loss_objectness: 0.1448 (0.1488)  loss_rpn_box_reg: 0.0591 (0.0751)  time: 0.6234  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [42]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.1567 (6.2199)  loss_classifier: 5.6211 (5.7555)  loss_box_reg: 0.2111 (0.2404)  loss_objectness: 0.1590 (0.1490)  loss_rpn_box_reg: 0.0600 (0.0751)  time: 0.6195  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [42]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.3499 (6.2171)  loss_classifier: 5.8327 (5.7521)  loss_box_reg: 0.2432 (0.2406)  loss_objectness: 0.1491 (0.1492)  loss_rpn_box_reg: 0.0697 (0.0751)  time: 0.6342  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [42]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.0849 (6.2099)  loss_classifier: 5.6241 (5.7430)  loss_box_reg: 0.2524 (0.2424)  loss_objectness: 0.1379 (0.1487)  loss_rpn_box_reg: 0.0841 (0.0758)  time: 0.6246  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [42]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.1325 (6.2128)  loss_classifier: 5.6241 (5.7453)  loss_box_reg: 0.2405 (0.2426)  loss_objectness: 0.1339 (0.1488)  loss_rpn_box_reg: 0.0841 (0.0762)  time: 0.6100  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [42]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.1325 (6.2095)  loss_classifier: 5.5434 (5.7413)  loss_box_reg: 0.2368 (0.2428)  loss_objectness: 0.1474 (0.1492)  loss_rpn_box_reg: 0.0745 (0.0761)  time: 0.6207  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [42]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.1004 (6.2070)  loss_classifier: 5.5990 (5.7375)  loss_box_reg: 0.2513 (0.2437)  loss_objectness: 0.1577 (0.1495)  loss_rpn_box_reg: 0.0738 (0.0763)  time: 0.6146  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [42]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2313 (6.2105)  loss_classifier: 5.6740 (5.7411)  loss_box_reg: 0.2349 (0.2434)  loss_objectness: 0.1590 (0.1495)  loss_rpn_box_reg: 0.0738 (0.0765)  time: 0.6186  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [42]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.0610 (6.2053)  loss_classifier: 5.6272 (5.7354)  loss_box_reg: 0.2333 (0.2438)  loss_objectness: 0.1506 (0.1497)  loss_rpn_box_reg: 0.0726 (0.0764)  time: 0.6189  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [42]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.0610 (6.2128)  loss_classifier: 5.6545 (5.7420)  loss_box_reg: 0.2585 (0.2440)  loss_objectness: 0.1506 (0.1503)  loss_rpn_box_reg: 0.0717 (0.0765)  time: 0.6184  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [42]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.2868 (6.2125)  loss_classifier: 5.8385 (5.7419)  loss_box_reg: 0.2482 (0.2436)  loss_objectness: 0.1705 (0.1506)  loss_rpn_box_reg: 0.0601 (0.0764)  time: 0.6282  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [42]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.2095 (6.2145)  loss_classifier: 5.8385 (5.7455)  loss_box_reg: 0.2115 (0.2426)  loss_objectness: 0.1357 (0.1502)  loss_rpn_box_reg: 0.0601 (0.0762)  time: 0.6273  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [42]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.0944 (6.2096)  loss_classifier: 5.6967 (5.7408)  loss_box_reg: 0.2243 (0.2426)  loss_objectness: 0.1463 (0.1503)  loss_rpn_box_reg: 0.0611 (0.0760)  time: 0.6260  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [42]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 5.9819 (6.2067)  loss_classifier: 5.5093 (5.7371)  loss_box_reg: 0.2313 (0.2422)  loss_objectness: 0.1569 (0.1507)  loss_rpn_box_reg: 0.0747 (0.0767)  time: 0.6272  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [42]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1343 (6.2054)  loss_classifier: 5.6258 (5.7362)  loss_box_reg: 0.2357 (0.2420)  loss_objectness: 0.1650 (0.1508)  loss_rpn_box_reg: 0.0710 (0.0764)  time: 0.6200  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [42]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1636 (6.2079)  loss_classifier: 5.7481 (5.7384)  loss_box_reg: 0.2357 (0.2416)  loss_objectness: 0.1607 (0.1513)  loss_rpn_box_reg: 0.0623 (0.0765)  time: 0.6096  data: 0.1379  max mem: 10734\n",
      "Training Epoch: [42]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1010 (6.2072)  loss_classifier: 5.6512 (5.7378)  loss_box_reg: 0.2364 (0.2418)  loss_objectness: 0.1669 (0.1515)  loss_rpn_box_reg: 0.0583 (0.0761)  time: 0.6134  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [42]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1221 (6.2095)  loss_classifier: 5.6512 (5.7405)  loss_box_reg: 0.2250 (0.2414)  loss_objectness: 0.1501 (0.1516)  loss_rpn_box_reg: 0.0616 (0.0761)  time: 0.6300  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [42]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2326 (6.2100)  loss_classifier: 5.7815 (5.7409)  loss_box_reg: 0.2170 (0.2414)  loss_objectness: 0.1501 (0.1517)  loss_rpn_box_reg: 0.0649 (0.0761)  time: 0.6317  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [42]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2987 (6.2142)  loss_classifier: 5.8052 (5.7447)  loss_box_reg: 0.2211 (0.2413)  loss_objectness: 0.1490 (0.1518)  loss_rpn_box_reg: 0.0862 (0.0764)  time: 0.6156  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [42]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.3309 (6.2202)  loss_classifier: 5.8472 (5.7510)  loss_box_reg: 0.2210 (0.2412)  loss_objectness: 0.1421 (0.1516)  loss_rpn_box_reg: 0.0672 (0.0763)  time: 0.6227  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [42]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.3723 (6.2261)  loss_classifier: 5.8472 (5.7569)  loss_box_reg: 0.2432 (0.2415)  loss_objectness: 0.1349 (0.1514)  loss_rpn_box_reg: 0.0639 (0.0763)  time: 0.6362  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [42]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.3723 (6.2266)  loss_classifier: 5.8419 (5.7581)  loss_box_reg: 0.2432 (0.2414)  loss_objectness: 0.1393 (0.1512)  loss_rpn_box_reg: 0.0613 (0.0760)  time: 0.6310  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [42]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1783 (6.2218)  loss_classifier: 5.7505 (5.7534)  loss_box_reg: 0.2125 (0.2409)  loss_objectness: 0.1409 (0.1515)  loss_rpn_box_reg: 0.0555 (0.0760)  time: 0.6354  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [42]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.2261 (6.2227)  loss_classifier: 5.7514 (5.7542)  loss_box_reg: 0.2118 (0.2406)  loss_objectness: 0.1553 (0.1518)  loss_rpn_box_reg: 0.0655 (0.0760)  time: 0.6368  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [42]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1859 (6.2205)  loss_classifier: 5.7386 (5.7521)  loss_box_reg: 0.2118 (0.2405)  loss_objectness: 0.1429 (0.1517)  loss_rpn_box_reg: 0.0655 (0.0761)  time: 0.6329  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [42] Total time: 0:05:12 (0.6257 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:53  model_time: 0.7212 (0.7212)  evaluator_time: 0.0350 (0.0350)  time: 0.9072  data: 0.1410  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4421 (0.4524)  evaluator_time: 0.0340 (0.0349)  time: 0.6376  data: 0.1541  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4691 (0.4538)  evaluator_time: 0.0360 (0.0356)  time: 0.6585  data: 0.1540  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6431 s / it)\n",
      "Averaged stats: model_time: 0.4691 (0.4538)  evaluator_time: 0.0360 (0.0356)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [42]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.2036 (6.2036)  loss_classifier: 5.6526 (5.6526)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1251 (0.1251)  loss_rpn_box_reg: 0.1314 (0.1314)  time: 0.6471  data: 0.1460  max mem: 10734\n",
      "Testing Epoch: [42]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0008 (6.1224)  loss_classifier: 5.4160 (5.6104)  loss_box_reg: 0.2609 (0.2908)  loss_objectness: 0.1287 (0.1314)  loss_rpn_box_reg: 0.0708 (0.0899)  time: 0.5858  data: 0.1463  max mem: 10734\n",
      "Testing Epoch: [42]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1716 (6.1559)  loss_classifier: 5.6868 (5.6485)  loss_box_reg: 0.2500 (0.2859)  loss_objectness: 0.1144 (0.1314)  loss_rpn_box_reg: 0.0745 (0.0900)  time: 0.5987  data: 0.1463  max mem: 10734\n",
      "Testing Epoch: [42] Total time: 0:01:14 (0.5966 s / it)\n",
      "Training Epoch: [43]  [  0/500]  eta: 0:06:42  lr: 0.000000  loss: 5.9312 (5.9312)  loss_classifier: 5.4186 (5.4186)  loss_box_reg: 0.2133 (0.2133)  loss_objectness: 0.2176 (0.2176)  loss_rpn_box_reg: 0.0817 (0.0817)  time: 0.8042  data: 0.1380  max mem: 10734\n",
      "Training Epoch: [43]  [ 10/500]  eta: 0:05:24  lr: 0.000000  loss: 6.1538 (6.2186)  loss_classifier: 5.6534 (5.7601)  loss_box_reg: 0.2133 (0.2324)  loss_objectness: 0.1418 (0.1520)  loss_rpn_box_reg: 0.0817 (0.0740)  time: 0.6631  data: 0.1305  max mem: 10734\n",
      "Training Epoch: [43]  [ 20/500]  eta: 0:05:08  lr: 0.000000  loss: 6.1581 (6.2623)  loss_classifier: 5.7172 (5.7995)  loss_box_reg: 0.2006 (0.2356)  loss_objectness: 0.1418 (0.1526)  loss_rpn_box_reg: 0.0758 (0.0746)  time: 0.6347  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [43]  [ 30/500]  eta: 0:05:00  lr: 0.000000  loss: 6.1581 (6.2702)  loss_classifier: 5.7902 (5.8139)  loss_box_reg: 0.2096 (0.2342)  loss_objectness: 0.1469 (0.1485)  loss_rpn_box_reg: 0.0748 (0.0737)  time: 0.6265  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [43]  [ 40/500]  eta: 0:04:52  lr: 0.000000  loss: 6.1251 (6.2210)  loss_classifier: 5.7902 (5.7574)  loss_box_reg: 0.2472 (0.2424)  loss_objectness: 0.1361 (0.1477)  loss_rpn_box_reg: 0.0637 (0.0735)  time: 0.6297  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [43]  [ 50/500]  eta: 0:04:46  lr: 0.000000  loss: 6.0989 (6.2263)  loss_classifier: 5.5590 (5.7582)  loss_box_reg: 0.2538 (0.2423)  loss_objectness: 0.1496 (0.1504)  loss_rpn_box_reg: 0.0770 (0.0754)  time: 0.6325  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [43]  [ 60/500]  eta: 0:04:39  lr: 0.000000  loss: 6.0401 (6.2111)  loss_classifier: 5.5209 (5.7407)  loss_box_reg: 0.2406 (0.2429)  loss_objectness: 0.1523 (0.1526)  loss_rpn_box_reg: 0.0654 (0.0748)  time: 0.6342  data: 0.1377  max mem: 10734\n",
      "Training Epoch: [43]  [ 70/500]  eta: 0:04:33  lr: 0.000000  loss: 6.0401 (6.2145)  loss_classifier: 5.4696 (5.7400)  loss_box_reg: 0.2323 (0.2442)  loss_objectness: 0.1644 (0.1533)  loss_rpn_box_reg: 0.0641 (0.0770)  time: 0.6335  data: 0.1392  max mem: 10734\n",
      "Training Epoch: [43]  [ 80/500]  eta: 0:04:26  lr: 0.000000  loss: 6.2962 (6.2377)  loss_classifier: 5.8832 (5.7640)  loss_box_reg: 0.2323 (0.2436)  loss_objectness: 0.1643 (0.1538)  loss_rpn_box_reg: 0.0641 (0.0763)  time: 0.6323  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [43]  [ 90/500]  eta: 0:04:19  lr: 0.000000  loss: 5.9794 (6.2097)  loss_classifier: 5.4208 (5.7368)  loss_box_reg: 0.2416 (0.2448)  loss_objectness: 0.1452 (0.1522)  loss_rpn_box_reg: 0.0623 (0.0758)  time: 0.6266  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [43]  [100/500]  eta: 0:04:12  lr: 0.000000  loss: 5.8360 (6.1946)  loss_classifier: 5.3670 (5.7183)  loss_box_reg: 0.2684 (0.2476)  loss_objectness: 0.1498 (0.1526)  loss_rpn_box_reg: 0.0752 (0.0761)  time: 0.6166  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [43]  [110/500]  eta: 0:04:06  lr: 0.000000  loss: 6.0302 (6.1853)  loss_classifier: 5.5886 (5.7083)  loss_box_reg: 0.2641 (0.2474)  loss_objectness: 0.1498 (0.1525)  loss_rpn_box_reg: 0.0775 (0.0771)  time: 0.6232  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [43]  [120/500]  eta: 0:04:00  lr: 0.000000  loss: 6.1489 (6.1858)  loss_classifier: 5.6634 (5.7109)  loss_box_reg: 0.2334 (0.2466)  loss_objectness: 0.1381 (0.1517)  loss_rpn_box_reg: 0.0700 (0.0767)  time: 0.6363  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [43]  [130/500]  eta: 0:03:53  lr: 0.000000  loss: 6.2172 (6.1893)  loss_classifier: 5.7633 (5.7158)  loss_box_reg: 0.2367 (0.2466)  loss_objectness: 0.1426 (0.1514)  loss_rpn_box_reg: 0.0606 (0.0755)  time: 0.6265  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [43]  [140/500]  eta: 0:03:47  lr: 0.000000  loss: 6.2406 (6.1921)  loss_classifier: 5.7631 (5.7181)  loss_box_reg: 0.2367 (0.2463)  loss_objectness: 0.1459 (0.1516)  loss_rpn_box_reg: 0.0677 (0.0761)  time: 0.6253  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [43]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 6.2299 (6.2040)  loss_classifier: 5.7455 (5.7334)  loss_box_reg: 0.2066 (0.2443)  loss_objectness: 0.1386 (0.1508)  loss_rpn_box_reg: 0.0687 (0.0756)  time: 0.6161  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [43]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.3224 (6.2193)  loss_classifier: 5.8583 (5.7469)  loss_box_reg: 0.2373 (0.2444)  loss_objectness: 0.1496 (0.1522)  loss_rpn_box_reg: 0.0650 (0.0758)  time: 0.6051  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [43]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.3098 (6.2099)  loss_classifier: 5.8583 (5.7383)  loss_box_reg: 0.2484 (0.2438)  loss_objectness: 0.1524 (0.1521)  loss_rpn_box_reg: 0.0650 (0.0757)  time: 0.6242  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [43]  [180/500]  eta: 0:03:21  lr: 0.000000  loss: 6.0015 (6.2033)  loss_classifier: 5.6465 (5.7294)  loss_box_reg: 0.2390 (0.2448)  loss_objectness: 0.1449 (0.1526)  loss_rpn_box_reg: 0.0914 (0.0765)  time: 0.6420  data: 0.1375  max mem: 10734\n",
      "Training Epoch: [43]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.0961 (6.2095)  loss_classifier: 5.6694 (5.7381)  loss_box_reg: 0.2150 (0.2432)  loss_objectness: 0.1478 (0.1525)  loss_rpn_box_reg: 0.0627 (0.0757)  time: 0.6325  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [43]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.2150 (6.2057)  loss_classifier: 5.7671 (5.7356)  loss_box_reg: 0.2103 (0.2424)  loss_objectness: 0.1456 (0.1522)  loss_rpn_box_reg: 0.0627 (0.0755)  time: 0.6171  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [43]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.3265 (6.2143)  loss_classifier: 5.8024 (5.7429)  loss_box_reg: 0.2233 (0.2421)  loss_objectness: 0.1547 (0.1534)  loss_rpn_box_reg: 0.0779 (0.0759)  time: 0.6152  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [43]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.4066 (6.2318)  loss_classifier: 5.8834 (5.7600)  loss_box_reg: 0.2659 (0.2428)  loss_objectness: 0.1547 (0.1526)  loss_rpn_box_reg: 0.0843 (0.0763)  time: 0.6222  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [43]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.2323 (6.2278)  loss_classifier: 5.7591 (5.7570)  loss_box_reg: 0.2285 (0.2421)  loss_objectness: 0.1364 (0.1524)  loss_rpn_box_reg: 0.0748 (0.0763)  time: 0.6275  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [43]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.1041 (6.2202)  loss_classifier: 5.6443 (5.7485)  loss_box_reg: 0.2244 (0.2424)  loss_objectness: 0.1428 (0.1522)  loss_rpn_box_reg: 0.0791 (0.0770)  time: 0.6260  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [43]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.1724 (6.2225)  loss_classifier: 5.7047 (5.7513)  loss_box_reg: 0.2388 (0.2425)  loss_objectness: 0.1428 (0.1523)  loss_rpn_box_reg: 0.0713 (0.0765)  time: 0.6129  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [43]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.1426 (6.2173)  loss_classifier: 5.7134 (5.7465)  loss_box_reg: 0.2110 (0.2415)  loss_objectness: 0.1589 (0.1531)  loss_rpn_box_reg: 0.0629 (0.0762)  time: 0.6029  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [43]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.1072 (6.2197)  loss_classifier: 5.7134 (5.7490)  loss_box_reg: 0.2077 (0.2411)  loss_objectness: 0.1655 (0.1533)  loss_rpn_box_reg: 0.0705 (0.0763)  time: 0.6157  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [43]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.1602 (6.2199)  loss_classifier: 5.6382 (5.7494)  loss_box_reg: 0.2181 (0.2407)  loss_objectness: 0.1568 (0.1534)  loss_rpn_box_reg: 0.0778 (0.0765)  time: 0.6250  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [43]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.1232 (6.2271)  loss_classifier: 5.6828 (5.7560)  loss_box_reg: 0.2242 (0.2403)  loss_objectness: 0.1584 (0.1541)  loss_rpn_box_reg: 0.0772 (0.0766)  time: 0.6192  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [43]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.0280 (6.2207)  loss_classifier: 5.4687 (5.7497)  loss_box_reg: 0.2242 (0.2400)  loss_objectness: 0.1611 (0.1545)  loss_rpn_box_reg: 0.0658 (0.0766)  time: 0.6215  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [43]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 5.9174 (6.2119)  loss_classifier: 5.4408 (5.7408)  loss_box_reg: 0.2487 (0.2404)  loss_objectness: 0.1539 (0.1546)  loss_rpn_box_reg: 0.0645 (0.0761)  time: 0.6208  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [43]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 5.9451 (6.2087)  loss_classifier: 5.5427 (5.7376)  loss_box_reg: 0.2387 (0.2400)  loss_objectness: 0.1538 (0.1548)  loss_rpn_box_reg: 0.0649 (0.0764)  time: 0.6196  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [43]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 5.9881 (6.2109)  loss_classifier: 5.6130 (5.7406)  loss_box_reg: 0.2288 (0.2401)  loss_objectness: 0.1376 (0.1542)  loss_rpn_box_reg: 0.0653 (0.0760)  time: 0.6176  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [43]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 5.9214 (6.2048)  loss_classifier: 5.5850 (5.7358)  loss_box_reg: 0.2119 (0.2396)  loss_objectness: 0.1281 (0.1534)  loss_rpn_box_reg: 0.0597 (0.0759)  time: 0.6290  data: 0.1315  max mem: 10734\n",
      "Training Epoch: [43]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.1015 (6.2068)  loss_classifier: 5.6672 (5.7388)  loss_box_reg: 0.2051 (0.2388)  loss_objectness: 0.1255 (0.1535)  loss_rpn_box_reg: 0.0620 (0.0758)  time: 0.6481  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [43]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.2228 (6.2115)  loss_classifier: 5.8070 (5.7428)  loss_box_reg: 0.2098 (0.2392)  loss_objectness: 0.1350 (0.1534)  loss_rpn_box_reg: 0.0700 (0.0761)  time: 0.6308  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [43]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.4352 (6.2146)  loss_classifier: 5.8105 (5.7463)  loss_box_reg: 0.2234 (0.2387)  loss_objectness: 0.1485 (0.1535)  loss_rpn_box_reg: 0.0739 (0.0761)  time: 0.6112  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [43]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.3306 (6.2215)  loss_classifier: 5.8520 (5.7528)  loss_box_reg: 0.2463 (0.2392)  loss_objectness: 0.1581 (0.1535)  loss_rpn_box_reg: 0.0683 (0.0760)  time: 0.6169  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [43]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.2987 (6.2214)  loss_classifier: 5.8520 (5.7532)  loss_box_reg: 0.2478 (0.2391)  loss_objectness: 0.1461 (0.1532)  loss_rpn_box_reg: 0.0683 (0.0760)  time: 0.6363  data: 0.1385  max mem: 10734\n",
      "Training Epoch: [43]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1312 (6.2154)  loss_classifier: 5.6628 (5.7476)  loss_box_reg: 0.2187 (0.2390)  loss_objectness: 0.1446 (0.1529)  loss_rpn_box_reg: 0.0706 (0.0759)  time: 0.6302  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [43]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 5.9569 (6.2130)  loss_classifier: 5.5049 (5.7455)  loss_box_reg: 0.2131 (0.2385)  loss_objectness: 0.1589 (0.1531)  loss_rpn_box_reg: 0.0726 (0.0759)  time: 0.6058  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [43]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1382 (6.2141)  loss_classifier: 5.5169 (5.7466)  loss_box_reg: 0.2258 (0.2383)  loss_objectness: 0.1643 (0.1533)  loss_rpn_box_reg: 0.0732 (0.0759)  time: 0.6109  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [43]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1382 (6.2143)  loss_classifier: 5.6590 (5.7468)  loss_box_reg: 0.2403 (0.2386)  loss_objectness: 0.1785 (0.1532)  loss_rpn_box_reg: 0.0666 (0.0757)  time: 0.6291  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [43]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.3017 (6.2179)  loss_classifier: 5.7506 (5.7500)  loss_box_reg: 0.2471 (0.2388)  loss_objectness: 0.1506 (0.1532)  loss_rpn_box_reg: 0.0663 (0.0760)  time: 0.6317  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [43]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.2917 (6.2173)  loss_classifier: 5.7493 (5.7490)  loss_box_reg: 0.2442 (0.2389)  loss_objectness: 0.1565 (0.1535)  loss_rpn_box_reg: 0.0668 (0.0759)  time: 0.6337  data: 0.1385  max mem: 10734\n",
      "Training Epoch: [43]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.1453 (6.2146)  loss_classifier: 5.6757 (5.7454)  loss_box_reg: 0.2442 (0.2390)  loss_objectness: 0.1607 (0.1540)  loss_rpn_box_reg: 0.0760 (0.0762)  time: 0.6371  data: 0.1390  max mem: 10734\n",
      "Training Epoch: [43]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 5.9877 (6.2120)  loss_classifier: 5.5185 (5.7427)  loss_box_reg: 0.2414 (0.2392)  loss_objectness: 0.1502 (0.1538)  loss_rpn_box_reg: 0.0760 (0.0763)  time: 0.6349  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [43]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 5.9877 (6.2123)  loss_classifier: 5.5657 (5.7429)  loss_box_reg: 0.2444 (0.2394)  loss_objectness: 0.1502 (0.1540)  loss_rpn_box_reg: 0.0679 (0.0761)  time: 0.6261  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [43]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1471 (6.2139)  loss_classifier: 5.7041 (5.7453)  loss_box_reg: 0.2465 (0.2388)  loss_objectness: 0.1524 (0.1538)  loss_rpn_box_reg: 0.0679 (0.0759)  time: 0.6179  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [43]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1034 (6.2135)  loss_classifier: 5.6036 (5.7455)  loss_box_reg: 0.2192 (0.2384)  loss_objectness: 0.1560 (0.1539)  loss_rpn_box_reg: 0.0708 (0.0757)  time: 0.6257  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [43] Total time: 0:05:12 (0.6255 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:51  model_time: 0.7012 (0.7012)  evaluator_time: 0.0340 (0.0340)  time: 0.8882  data: 0.1440  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4401 (0.4520)  evaluator_time: 0.0340 (0.0359)  time: 0.6371  data: 0.1533  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4661 (0.4536)  evaluator_time: 0.0360 (0.0364)  time: 0.6539  data: 0.1480  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6412 s / it)\n",
      "Averaged stats: model_time: 0.4661 (0.4536)  evaluator_time: 0.0360 (0.0364)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [43]  [  0/125]  eta: 0:01:19  lr: 0.000000  loss: 6.1981 (6.1981)  loss_classifier: 5.6470 (5.6470)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1256 (0.1256)  loss_rpn_box_reg: 0.1310 (0.1310)  time: 0.6391  data: 0.1380  max mem: 10734\n",
      "Testing Epoch: [43]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0124 (6.1270)  loss_classifier: 5.4242 (5.6164)  loss_box_reg: 0.2609 (0.2895)  loss_objectness: 0.1287 (0.1319)  loss_rpn_box_reg: 0.0729 (0.0892)  time: 0.5848  data: 0.1445  max mem: 10734\n",
      "Testing Epoch: [43]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1546 (6.1602)  loss_classifier: 5.6779 (5.6539)  loss_box_reg: 0.2500 (0.2849)  loss_objectness: 0.1225 (0.1320)  loss_rpn_box_reg: 0.0745 (0.0894)  time: 0.6003  data: 0.1463  max mem: 10734\n",
      "Testing Epoch: [43] Total time: 0:01:14 (0.5956 s / it)\n",
      "Training Epoch: [44]  [  0/500]  eta: 0:07:12  lr: 0.000000  loss: 5.5244 (5.5244)  loss_classifier: 5.0502 (5.0502)  loss_box_reg: 0.2795 (0.2795)  loss_objectness: 0.1428 (0.1428)  loss_rpn_box_reg: 0.0519 (0.0519)  time: 0.8652  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [44]  [ 10/500]  eta: 0:05:16  lr: 0.000000  loss: 5.9953 (6.0678)  loss_classifier: 5.5728 (5.5937)  loss_box_reg: 0.2563 (0.2431)  loss_objectness: 0.1538 (0.1615)  loss_rpn_box_reg: 0.0672 (0.0694)  time: 0.6450  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [44]  [ 20/500]  eta: 0:05:07  lr: 0.000000  loss: 6.2569 (6.2440)  loss_classifier: 5.7149 (5.7558)  loss_box_reg: 0.2533 (0.2495)  loss_objectness: 0.1497 (0.1629)  loss_rpn_box_reg: 0.0705 (0.0758)  time: 0.6297  data: 0.1386  max mem: 10734\n",
      "Training Epoch: [44]  [ 30/500]  eta: 0:04:58  lr: 0.000000  loss: 6.2764 (6.2617)  loss_classifier: 5.7606 (5.7781)  loss_box_reg: 0.2474 (0.2494)  loss_objectness: 0.1456 (0.1559)  loss_rpn_box_reg: 0.0807 (0.0783)  time: 0.6310  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [44]  [ 40/500]  eta: 0:04:49  lr: 0.000000  loss: 6.1707 (6.2302)  loss_classifier: 5.7239 (5.7564)  loss_box_reg: 0.2278 (0.2418)  loss_objectness: 0.1311 (0.1504)  loss_rpn_box_reg: 0.0724 (0.0816)  time: 0.6154  data: 0.1315  max mem: 10734\n",
      "Training Epoch: [44]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 6.2508 (6.2278)  loss_classifier: 5.7621 (5.7605)  loss_box_reg: 0.2251 (0.2403)  loss_objectness: 0.1389 (0.1497)  loss_rpn_box_reg: 0.0603 (0.0772)  time: 0.6147  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [44]  [ 60/500]  eta: 0:04:36  lr: 0.000000  loss: 6.2016 (6.2166)  loss_classifier: 5.7201 (5.7513)  loss_box_reg: 0.2396 (0.2426)  loss_objectness: 0.1317 (0.1485)  loss_rpn_box_reg: 0.0580 (0.0742)  time: 0.6274  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [44]  [ 70/500]  eta: 0:04:30  lr: 0.000000  loss: 6.1416 (6.1997)  loss_classifier: 5.6345 (5.7300)  loss_box_reg: 0.2566 (0.2451)  loss_objectness: 0.1619 (0.1500)  loss_rpn_box_reg: 0.0689 (0.0746)  time: 0.6301  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [44]  [ 80/500]  eta: 0:04:22  lr: 0.000000  loss: 6.2379 (6.2065)  loss_classifier: 5.8005 (5.7346)  loss_box_reg: 0.2566 (0.2445)  loss_objectness: 0.1619 (0.1504)  loss_rpn_box_reg: 0.0845 (0.0770)  time: 0.6179  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [44]  [ 90/500]  eta: 0:04:16  lr: 0.000000  loss: 6.1972 (6.2026)  loss_classifier: 5.8091 (5.7331)  loss_box_reg: 0.2208 (0.2430)  loss_objectness: 0.1235 (0.1491)  loss_rpn_box_reg: 0.0785 (0.0774)  time: 0.6201  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [44]  [100/500]  eta: 0:04:09  lr: 0.000000  loss: 6.2260 (6.2011)  loss_classifier: 5.8558 (5.7309)  loss_box_reg: 0.2365 (0.2433)  loss_objectness: 0.1360 (0.1489)  loss_rpn_box_reg: 0.0767 (0.0778)  time: 0.6205  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [44]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 6.0207 (6.1753)  loss_classifier: 5.5745 (5.7048)  loss_box_reg: 0.2597 (0.2438)  loss_objectness: 0.1360 (0.1483)  loss_rpn_box_reg: 0.0767 (0.0784)  time: 0.6159  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [44]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 5.9463 (6.1718)  loss_classifier: 5.5346 (5.7044)  loss_box_reg: 0.2402 (0.2420)  loss_objectness: 0.1392 (0.1485)  loss_rpn_box_reg: 0.0697 (0.0769)  time: 0.6355  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [44]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.1796 (6.1807)  loss_classifier: 5.7837 (5.7110)  loss_box_reg: 0.2349 (0.2436)  loss_objectness: 0.1546 (0.1493)  loss_rpn_box_reg: 0.0709 (0.0768)  time: 0.6304  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [44]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.2918 (6.1841)  loss_classifier: 5.8355 (5.7192)  loss_box_reg: 0.2290 (0.2408)  loss_objectness: 0.1541 (0.1489)  loss_rpn_box_reg: 0.0648 (0.0752)  time: 0.6217  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [44]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.1874 (6.1787)  loss_classifier: 5.6547 (5.7130)  loss_box_reg: 0.2221 (0.2406)  loss_objectness: 0.1489 (0.1488)  loss_rpn_box_reg: 0.0674 (0.0763)  time: 0.6247  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [44]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.1853 (6.1738)  loss_classifier: 5.5864 (5.7086)  loss_box_reg: 0.2206 (0.2391)  loss_objectness: 0.1530 (0.1495)  loss_rpn_box_reg: 0.0710 (0.0766)  time: 0.6170  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [44]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.1853 (6.1675)  loss_classifier: 5.6976 (5.7008)  loss_box_reg: 0.2147 (0.2405)  loss_objectness: 0.1530 (0.1495)  loss_rpn_box_reg: 0.0637 (0.0768)  time: 0.6228  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [44]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.1491 (6.1692)  loss_classifier: 5.6976 (5.7017)  loss_box_reg: 0.2368 (0.2409)  loss_objectness: 0.1501 (0.1499)  loss_rpn_box_reg: 0.0683 (0.0767)  time: 0.6123  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [44]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.2437 (6.1780)  loss_classifier: 5.7602 (5.7115)  loss_box_reg: 0.2358 (0.2406)  loss_objectness: 0.1231 (0.1493)  loss_rpn_box_reg: 0.0666 (0.0766)  time: 0.6092  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [44]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.1695 (6.1759)  loss_classifier: 5.6128 (5.7105)  loss_box_reg: 0.2321 (0.2397)  loss_objectness: 0.1277 (0.1488)  loss_rpn_box_reg: 0.0701 (0.0768)  time: 0.6354  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [44]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.0043 (6.1715)  loss_classifier: 5.5916 (5.7062)  loss_box_reg: 0.2395 (0.2402)  loss_objectness: 0.1350 (0.1489)  loss_rpn_box_reg: 0.0618 (0.0762)  time: 0.6286  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [44]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.0508 (6.1639)  loss_classifier: 5.5985 (5.7005)  loss_box_reg: 0.2360 (0.2393)  loss_objectness: 0.1350 (0.1482)  loss_rpn_box_reg: 0.0616 (0.0758)  time: 0.6180  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [44]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 5.8007 (6.1568)  loss_classifier: 5.4468 (5.6920)  loss_box_reg: 0.2181 (0.2400)  loss_objectness: 0.1451 (0.1485)  loss_rpn_box_reg: 0.0708 (0.0764)  time: 0.6183  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [44]  [240/500]  eta: 0:02:41  lr: 0.000000  loss: 6.0623 (6.1636)  loss_classifier: 5.6030 (5.6970)  loss_box_reg: 0.2537 (0.2407)  loss_objectness: 0.1497 (0.1494)  loss_rpn_box_reg: 0.0840 (0.0765)  time: 0.6124  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [44]  [250/500]  eta: 0:02:35  lr: 0.000000  loss: 6.1442 (6.1679)  loss_classifier: 5.6798 (5.7008)  loss_box_reg: 0.2537 (0.2408)  loss_objectness: 0.1497 (0.1501)  loss_rpn_box_reg: 0.0669 (0.0763)  time: 0.6156  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [44]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.2236 (6.1720)  loss_classifier: 5.7266 (5.7042)  loss_box_reg: 0.2288 (0.2411)  loss_objectness: 0.1395 (0.1500)  loss_rpn_box_reg: 0.0660 (0.0767)  time: 0.6219  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [44]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.2919 (6.1790)  loss_classifier: 5.8220 (5.7105)  loss_box_reg: 0.2310 (0.2417)  loss_objectness: 0.1377 (0.1499)  loss_rpn_box_reg: 0.0745 (0.0769)  time: 0.6204  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [44]  [280/500]  eta: 0:02:16  lr: 0.000000  loss: 6.3002 (6.1847)  loss_classifier: 5.8278 (5.7180)  loss_box_reg: 0.2271 (0.2407)  loss_objectness: 0.1377 (0.1493)  loss_rpn_box_reg: 0.0739 (0.0767)  time: 0.6183  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [44]  [290/500]  eta: 0:02:10  lr: 0.000000  loss: 6.2759 (6.1919)  loss_classifier: 5.7794 (5.7254)  loss_box_reg: 0.2342 (0.2409)  loss_objectness: 0.1355 (0.1491)  loss_rpn_box_reg: 0.0689 (0.0764)  time: 0.6210  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [44]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.2759 (6.1976)  loss_classifier: 5.7441 (5.7308)  loss_box_reg: 0.2468 (0.2412)  loss_objectness: 0.1372 (0.1491)  loss_rpn_box_reg: 0.0712 (0.0765)  time: 0.6309  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [44]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.2180 (6.1975)  loss_classifier: 5.7619 (5.7297)  loss_box_reg: 0.2546 (0.2416)  loss_objectness: 0.1507 (0.1494)  loss_rpn_box_reg: 0.0777 (0.0767)  time: 0.6302  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [44]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1714 (6.1995)  loss_classifier: 5.6789 (5.7312)  loss_box_reg: 0.2545 (0.2417)  loss_objectness: 0.1507 (0.1497)  loss_rpn_box_reg: 0.0808 (0.0769)  time: 0.6298  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [44]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.0834 (6.1942)  loss_classifier: 5.6263 (5.7262)  loss_box_reg: 0.2162 (0.2416)  loss_objectness: 0.1521 (0.1498)  loss_rpn_box_reg: 0.0658 (0.0765)  time: 0.6451  data: 0.1370  max mem: 10734\n",
      "Training Epoch: [44]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.0501 (6.1989)  loss_classifier: 5.6626 (5.7317)  loss_box_reg: 0.2009 (0.2406)  loss_objectness: 0.1547 (0.1499)  loss_rpn_box_reg: 0.0716 (0.0767)  time: 0.6379  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [44]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.3027 (6.2031)  loss_classifier: 5.7614 (5.7356)  loss_box_reg: 0.2039 (0.2406)  loss_objectness: 0.1650 (0.1502)  loss_rpn_box_reg: 0.0711 (0.0767)  time: 0.6197  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [44]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.3482 (6.2069)  loss_classifier: 5.9391 (5.7401)  loss_box_reg: 0.2276 (0.2403)  loss_objectness: 0.1603 (0.1501)  loss_rpn_box_reg: 0.0678 (0.0764)  time: 0.6226  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [44]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.3622 (6.2046)  loss_classifier: 5.9231 (5.7396)  loss_box_reg: 0.2013 (0.2387)  loss_objectness: 0.1455 (0.1500)  loss_rpn_box_reg: 0.0678 (0.0762)  time: 0.6379  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [44]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.2219 (6.2066)  loss_classifier: 5.8619 (5.7419)  loss_box_reg: 0.2130 (0.2388)  loss_objectness: 0.1421 (0.1499)  loss_rpn_box_reg: 0.0692 (0.0759)  time: 0.6400  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [44]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1706 (6.2080)  loss_classifier: 5.7178 (5.7439)  loss_box_reg: 0.2355 (0.2384)  loss_objectness: 0.1471 (0.1499)  loss_rpn_box_reg: 0.0581 (0.0758)  time: 0.6311  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [44]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1264 (6.2062)  loss_classifier: 5.6255 (5.7417)  loss_box_reg: 0.2443 (0.2388)  loss_objectness: 0.1462 (0.1497)  loss_rpn_box_reg: 0.0723 (0.0760)  time: 0.6241  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [44]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1877 (6.2076)  loss_classifier: 5.7439 (5.7438)  loss_box_reg: 0.2348 (0.2386)  loss_objectness: 0.1428 (0.1496)  loss_rpn_box_reg: 0.0677 (0.0756)  time: 0.6276  data: 0.1295  max mem: 10734\n",
      "Training Epoch: [44]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.1422 (6.2061)  loss_classifier: 5.7008 (5.7420)  loss_box_reg: 0.2348 (0.2390)  loss_objectness: 0.1375 (0.1495)  loss_rpn_box_reg: 0.0677 (0.0757)  time: 0.6322  data: 0.1310  max mem: 10734\n",
      "Training Epoch: [44]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.0735 (6.2041)  loss_classifier: 5.6624 (5.7402)  loss_box_reg: 0.2314 (0.2389)  loss_objectness: 0.1375 (0.1490)  loss_rpn_box_reg: 0.0750 (0.0759)  time: 0.6306  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [44]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1086 (6.2055)  loss_classifier: 5.7000 (5.7422)  loss_box_reg: 0.2162 (0.2385)  loss_objectness: 0.1345 (0.1490)  loss_rpn_box_reg: 0.0742 (0.0757)  time: 0.6316  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [44]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.3984 (6.2090)  loss_classifier: 5.9829 (5.7458)  loss_box_reg: 0.2279 (0.2385)  loss_objectness: 0.1473 (0.1491)  loss_rpn_box_reg: 0.0580 (0.0758)  time: 0.6270  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [44]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.3816 (6.2108)  loss_classifier: 5.8049 (5.7462)  loss_box_reg: 0.2507 (0.2390)  loss_objectness: 0.1412 (0.1493)  loss_rpn_box_reg: 0.0726 (0.0762)  time: 0.6181  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [44]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2207 (6.2107)  loss_classifier: 5.6963 (5.7452)  loss_box_reg: 0.2518 (0.2393)  loss_objectness: 0.1679 (0.1500)  loss_rpn_box_reg: 0.0791 (0.0762)  time: 0.6157  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [44]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2706 (6.2133)  loss_classifier: 5.7695 (5.7466)  loss_box_reg: 0.2691 (0.2398)  loss_objectness: 0.1680 (0.1504)  loss_rpn_box_reg: 0.0782 (0.0765)  time: 0.6104  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [44]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0922 (6.2119)  loss_classifier: 5.7030 (5.7453)  loss_box_reg: 0.2517 (0.2397)  loss_objectness: 0.1626 (0.1508)  loss_rpn_box_reg: 0.0680 (0.0761)  time: 0.6084  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [44]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0922 (6.2114)  loss_classifier: 5.7030 (5.7447)  loss_box_reg: 0.2163 (0.2396)  loss_objectness: 0.1565 (0.1510)  loss_rpn_box_reg: 0.0610 (0.0762)  time: 0.6235  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [44] Total time: 0:05:12 (0.6246 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:52  model_time: 0.7162 (0.7162)  evaluator_time: 0.0350 (0.0350)  time: 0.9032  data: 0.1430  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4351 (0.4483)  evaluator_time: 0.0340 (0.0339)  time: 0.6352  data: 0.1534  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4721 (0.4502)  evaluator_time: 0.0360 (0.0359)  time: 0.6589  data: 0.1473  max mem: 10734\n",
      "Test: Total time: 0:01:19 (0.6383 s / it)\n",
      "Averaged stats: model_time: 0.4721 (0.4502)  evaluator_time: 0.0360 (0.0359)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [44]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1979 (6.1979)  loss_classifier: 5.6448 (5.6448)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1259 (0.1259)  loss_rpn_box_reg: 0.1328 (0.1328)  time: 0.6401  data: 0.1380  max mem: 10734\n",
      "Testing Epoch: [44]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9882 (6.1259)  loss_classifier: 5.4206 (5.6158)  loss_box_reg: 0.2609 (0.2890)  loss_objectness: 0.1292 (0.1322)  loss_rpn_box_reg: 0.0702 (0.0890)  time: 0.5873  data: 0.1462  max mem: 10734\n",
      "Testing Epoch: [44]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1596 (6.1588)  loss_classifier: 5.6965 (5.6533)  loss_box_reg: 0.2500 (0.2845)  loss_objectness: 0.1175 (0.1318)  loss_rpn_box_reg: 0.0745 (0.0892)  time: 0.6020  data: 0.1467  max mem: 10734\n",
      "Testing Epoch: [44] Total time: 0:01:14 (0.5965 s / it)\n",
      "Training Epoch: [45]  [  0/500]  eta: 0:06:38  lr: 0.000000  loss: 6.4222 (6.4222)  loss_classifier: 6.0144 (6.0144)  loss_box_reg: 0.1614 (0.1614)  loss_objectness: 0.1671 (0.1671)  loss_rpn_box_reg: 0.0794 (0.0794)  time: 0.7972  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [45]  [ 10/500]  eta: 0:05:01  lr: 0.000000  loss: 6.4222 (6.2930)  loss_classifier: 5.9771 (5.7817)  loss_box_reg: 0.2610 (0.2448)  loss_objectness: 0.1671 (0.1719)  loss_rpn_box_reg: 0.0930 (0.0945)  time: 0.6160  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [45]  [ 20/500]  eta: 0:04:59  lr: 0.000000  loss: 6.1952 (6.2174)  loss_classifier: 5.5320 (5.7340)  loss_box_reg: 0.2610 (0.2428)  loss_objectness: 0.1513 (0.1614)  loss_rpn_box_reg: 0.0643 (0.0792)  time: 0.6152  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [45]  [ 30/500]  eta: 0:04:57  lr: 0.000000  loss: 6.1668 (6.2275)  loss_classifier: 5.7450 (5.7690)  loss_box_reg: 0.2062 (0.2356)  loss_objectness: 0.1345 (0.1499)  loss_rpn_box_reg: 0.0593 (0.0731)  time: 0.6429  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [45]  [ 40/500]  eta: 0:04:50  lr: 0.000000  loss: 6.1668 (6.2337)  loss_classifier: 5.7937 (5.7812)  loss_box_reg: 0.2090 (0.2326)  loss_objectness: 0.1220 (0.1456)  loss_rpn_box_reg: 0.0657 (0.0743)  time: 0.6373  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [45]  [ 50/500]  eta: 0:04:44  lr: 0.000000  loss: 6.4618 (6.2861)  loss_classifier: 5.9412 (5.8311)  loss_box_reg: 0.2394 (0.2369)  loss_objectness: 0.1298 (0.1459)  loss_rpn_box_reg: 0.0698 (0.0722)  time: 0.6286  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [45]  [ 60/500]  eta: 0:04:38  lr: 0.000000  loss: 6.2335 (6.2446)  loss_classifier: 5.7876 (5.7887)  loss_box_reg: 0.2394 (0.2380)  loss_objectness: 0.1417 (0.1471)  loss_rpn_box_reg: 0.0605 (0.0707)  time: 0.6369  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [45]  [ 70/500]  eta: 0:04:32  lr: 0.000000  loss: 6.0936 (6.2394)  loss_classifier: 5.6060 (5.7744)  loss_box_reg: 0.2271 (0.2385)  loss_objectness: 0.1585 (0.1529)  loss_rpn_box_reg: 0.0668 (0.0736)  time: 0.6398  data: 0.1417  max mem: 10734\n",
      "Training Epoch: [45]  [ 80/500]  eta: 0:04:26  lr: 0.000000  loss: 6.2755 (6.2371)  loss_classifier: 5.7822 (5.7700)  loss_box_reg: 0.2489 (0.2383)  loss_objectness: 0.1585 (0.1533)  loss_rpn_box_reg: 0.0817 (0.0756)  time: 0.6440  data: 0.1434  max mem: 10734\n",
      "Training Epoch: [45]  [ 90/500]  eta: 0:04:20  lr: 0.000000  loss: 6.2755 (6.2309)  loss_classifier: 5.7845 (5.7647)  loss_box_reg: 0.2191 (0.2378)  loss_objectness: 0.1522 (0.1528)  loss_rpn_box_reg: 0.0812 (0.0756)  time: 0.6442  data: 0.1394  max mem: 10734\n",
      "Training Epoch: [45]  [100/500]  eta: 0:04:14  lr: 0.000000  loss: 6.1162 (6.2106)  loss_classifier: 5.7131 (5.7458)  loss_box_reg: 0.2151 (0.2382)  loss_objectness: 0.1342 (0.1511)  loss_rpn_box_reg: 0.0767 (0.0755)  time: 0.6367  data: 0.1384  max mem: 10734\n",
      "Training Epoch: [45]  [110/500]  eta: 0:04:07  lr: 0.000000  loss: 6.0094 (6.2056)  loss_classifier: 5.4978 (5.7382)  loss_box_reg: 0.2314 (0.2392)  loss_objectness: 0.1342 (0.1513)  loss_rpn_box_reg: 0.0783 (0.0769)  time: 0.6213  data: 0.1392  max mem: 10734\n",
      "Training Epoch: [45]  [120/500]  eta: 0:04:00  lr: 0.000000  loss: 6.0094 (6.1812)  loss_classifier: 5.4311 (5.7161)  loss_box_reg: 0.2269 (0.2383)  loss_objectness: 0.1350 (0.1498)  loss_rpn_box_reg: 0.0729 (0.0769)  time: 0.6154  data: 0.1381  max mem: 10734\n",
      "Training Epoch: [45]  [130/500]  eta: 0:03:54  lr: 0.000000  loss: 5.9292 (6.1748)  loss_classifier: 5.4869 (5.7090)  loss_box_reg: 0.2269 (0.2386)  loss_objectness: 0.1396 (0.1507)  loss_rpn_box_reg: 0.0704 (0.0765)  time: 0.6269  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [45]  [140/500]  eta: 0:03:47  lr: 0.000000  loss: 6.1005 (6.1800)  loss_classifier: 5.6225 (5.7142)  loss_box_reg: 0.2368 (0.2384)  loss_objectness: 0.1567 (0.1505)  loss_rpn_box_reg: 0.0764 (0.0769)  time: 0.6338  data: 0.1382  max mem: 10734\n",
      "Training Epoch: [45]  [150/500]  eta: 0:03:41  lr: 0.000000  loss: 6.1666 (6.1801)  loss_classifier: 5.7136 (5.7171)  loss_box_reg: 0.2426 (0.2384)  loss_objectness: 0.1340 (0.1483)  loss_rpn_box_reg: 0.0678 (0.0762)  time: 0.6327  data: 0.1401  max mem: 10734\n",
      "Training Epoch: [45]  [160/500]  eta: 0:03:34  lr: 0.000000  loss: 6.2538 (6.1920)  loss_classifier: 5.7577 (5.7307)  loss_box_reg: 0.2426 (0.2382)  loss_objectness: 0.1347 (0.1483)  loss_rpn_box_reg: 0.0601 (0.0748)  time: 0.6183  data: 0.1393  max mem: 10734\n",
      "Training Epoch: [45]  [170/500]  eta: 0:03:28  lr: 0.000000  loss: 6.2538 (6.1946)  loss_classifier: 5.7577 (5.7350)  loss_box_reg: 0.2312 (0.2375)  loss_objectness: 0.1514 (0.1484)  loss_rpn_box_reg: 0.0495 (0.0738)  time: 0.6148  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [45]  [180/500]  eta: 0:03:21  lr: 0.000000  loss: 6.0459 (6.1947)  loss_classifier: 5.5583 (5.7354)  loss_box_reg: 0.2312 (0.2366)  loss_objectness: 0.1571 (0.1488)  loss_rpn_box_reg: 0.0613 (0.0739)  time: 0.6316  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [45]  [190/500]  eta: 0:03:15  lr: 0.000000  loss: 6.0054 (6.1893)  loss_classifier: 5.5583 (5.7308)  loss_box_reg: 0.2287 (0.2369)  loss_objectness: 0.1356 (0.1481)  loss_rpn_box_reg: 0.0657 (0.0736)  time: 0.6243  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [45]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.1376 (6.1943)  loss_classifier: 5.6105 (5.7359)  loss_box_reg: 0.2084 (0.2363)  loss_objectness: 0.1356 (0.1481)  loss_rpn_box_reg: 0.0680 (0.0740)  time: 0.6107  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [45]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.1549 (6.1890)  loss_classifier: 5.7335 (5.7299)  loss_box_reg: 0.2209 (0.2365)  loss_objectness: 0.1507 (0.1487)  loss_rpn_box_reg: 0.0671 (0.0738)  time: 0.6231  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [45]  [220/500]  eta: 0:02:56  lr: 0.000000  loss: 6.1440 (6.1863)  loss_classifier: 5.6854 (5.7274)  loss_box_reg: 0.2209 (0.2368)  loss_objectness: 0.1601 (0.1489)  loss_rpn_box_reg: 0.0584 (0.0731)  time: 0.6312  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [45]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.1601 (6.2007)  loss_classifier: 5.7650 (5.7409)  loss_box_reg: 0.2381 (0.2370)  loss_objectness: 0.1639 (0.1496)  loss_rpn_box_reg: 0.0618 (0.0732)  time: 0.6233  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [45]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.3793 (6.2063)  loss_classifier: 6.0293 (5.7472)  loss_box_reg: 0.2522 (0.2377)  loss_objectness: 0.1380 (0.1488)  loss_rpn_box_reg: 0.0593 (0.0726)  time: 0.6283  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [45]  [250/500]  eta: 0:02:37  lr: 0.000000  loss: 6.4735 (6.2107)  loss_classifier: 6.0293 (5.7514)  loss_box_reg: 0.2418 (0.2374)  loss_objectness: 0.1329 (0.1487)  loss_rpn_box_reg: 0.0674 (0.0732)  time: 0.6245  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [45]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.3132 (6.2107)  loss_classifier: 5.8465 (5.7510)  loss_box_reg: 0.2465 (0.2381)  loss_objectness: 0.1354 (0.1489)  loss_rpn_box_reg: 0.0668 (0.0727)  time: 0.6136  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [45]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 5.9996 (6.2019)  loss_classifier: 5.6708 (5.7426)  loss_box_reg: 0.2465 (0.2379)  loss_objectness: 0.1406 (0.1489)  loss_rpn_box_reg: 0.0609 (0.0725)  time: 0.6167  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [45]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.0598 (6.2032)  loss_classifier: 5.6698 (5.7423)  loss_box_reg: 0.2358 (0.2390)  loss_objectness: 0.1444 (0.1493)  loss_rpn_box_reg: 0.0640 (0.0727)  time: 0.6156  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [45]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.2403 (6.2032)  loss_classifier: 5.6698 (5.7400)  loss_box_reg: 0.2674 (0.2403)  loss_objectness: 0.1557 (0.1496)  loss_rpn_box_reg: 0.0884 (0.0732)  time: 0.6071  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [45]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.4127 (6.2135)  loss_classifier: 5.8422 (5.7499)  loss_box_reg: 0.2480 (0.2405)  loss_objectness: 0.1481 (0.1499)  loss_rpn_box_reg: 0.0705 (0.0733)  time: 0.6265  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [45]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.4738 (6.2194)  loss_classifier: 5.9327 (5.7563)  loss_box_reg: 0.2207 (0.2404)  loss_objectness: 0.1441 (0.1498)  loss_rpn_box_reg: 0.0591 (0.0729)  time: 0.6330  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [45]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2267 (6.2201)  loss_classifier: 5.7423 (5.7567)  loss_box_reg: 0.2289 (0.2402)  loss_objectness: 0.1521 (0.1499)  loss_rpn_box_reg: 0.0622 (0.0733)  time: 0.6215  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [45]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.2267 (6.2243)  loss_classifier: 5.6799 (5.7598)  loss_box_reg: 0.2243 (0.2402)  loss_objectness: 0.1521 (0.1504)  loss_rpn_box_reg: 0.0782 (0.0739)  time: 0.6169  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [45]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.1671 (6.2206)  loss_classifier: 5.6814 (5.7558)  loss_box_reg: 0.2236 (0.2401)  loss_objectness: 0.1541 (0.1506)  loss_rpn_box_reg: 0.0782 (0.0741)  time: 0.5975  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [45]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.0926 (6.2172)  loss_classifier: 5.6814 (5.7539)  loss_box_reg: 0.2030 (0.2392)  loss_objectness: 0.1436 (0.1503)  loss_rpn_box_reg: 0.0575 (0.0738)  time: 0.6093  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [45]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.0832 (6.2155)  loss_classifier: 5.7138 (5.7522)  loss_box_reg: 0.2177 (0.2392)  loss_objectness: 0.1387 (0.1501)  loss_rpn_box_reg: 0.0553 (0.0740)  time: 0.6336  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [45]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.3728 (6.2186)  loss_classifier: 5.8931 (5.7542)  loss_box_reg: 0.2395 (0.2395)  loss_objectness: 0.1573 (0.1505)  loss_rpn_box_reg: 0.0829 (0.0743)  time: 0.6162  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [45]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.1952 (6.2221)  loss_classifier: 5.6788 (5.7560)  loss_box_reg: 0.2397 (0.2404)  loss_objectness: 0.1597 (0.1509)  loss_rpn_box_reg: 0.0871 (0.0749)  time: 0.6135  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [45]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1018 (6.2155)  loss_classifier: 5.5738 (5.7481)  loss_box_reg: 0.2738 (0.2406)  loss_objectness: 0.1672 (0.1516)  loss_rpn_box_reg: 0.0871 (0.0753)  time: 0.6221  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [45]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.0742 (6.2139)  loss_classifier: 5.5148 (5.7458)  loss_box_reg: 0.2496 (0.2412)  loss_objectness: 0.1448 (0.1515)  loss_rpn_box_reg: 0.0797 (0.0755)  time: 0.6142  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [45]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1811 (6.2102)  loss_classifier: 5.5824 (5.7413)  loss_box_reg: 0.2450 (0.2415)  loss_objectness: 0.1378 (0.1515)  loss_rpn_box_reg: 0.0835 (0.0759)  time: 0.6170  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [45]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1975 (6.2172)  loss_classifier: 5.7240 (5.7485)  loss_box_reg: 0.2311 (0.2411)  loss_objectness: 0.1546 (0.1516)  loss_rpn_box_reg: 0.0873 (0.0760)  time: 0.6161  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [45]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2169 (6.2148)  loss_classifier: 5.7328 (5.7465)  loss_box_reg: 0.2215 (0.2408)  loss_objectness: 0.1546 (0.1517)  loss_rpn_box_reg: 0.0693 (0.0758)  time: 0.6216  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [45]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.0211 (6.2096)  loss_classifier: 5.5456 (5.7415)  loss_box_reg: 0.2215 (0.2405)  loss_objectness: 0.1651 (0.1520)  loss_rpn_box_reg: 0.0671 (0.0757)  time: 0.6333  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [45]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 5.9711 (6.2083)  loss_classifier: 5.3914 (5.7395)  loss_box_reg: 0.2344 (0.2407)  loss_objectness: 0.1651 (0.1522)  loss_rpn_box_reg: 0.0786 (0.0760)  time: 0.6210  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [45]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.1536 (6.2110)  loss_classifier: 5.6384 (5.7420)  loss_box_reg: 0.2392 (0.2408)  loss_objectness: 0.1509 (0.1522)  loss_rpn_box_reg: 0.0764 (0.0759)  time: 0.6128  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [45]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1982 (6.2099)  loss_classifier: 5.7564 (5.7415)  loss_box_reg: 0.2392 (0.2408)  loss_objectness: 0.1357 (0.1518)  loss_rpn_box_reg: 0.0584 (0.0758)  time: 0.6251  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [45]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2699 (6.2108)  loss_classifier: 5.7167 (5.7416)  loss_box_reg: 0.2373 (0.2411)  loss_objectness: 0.1571 (0.1522)  loss_rpn_box_reg: 0.0584 (0.0759)  time: 0.6287  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [45]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.3282 (6.2152)  loss_classifier: 5.8354 (5.7461)  loss_box_reg: 0.2202 (0.2410)  loss_objectness: 0.1696 (0.1522)  loss_rpn_box_reg: 0.0802 (0.0759)  time: 0.6353  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [45]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2898 (6.2137)  loss_classifier: 5.8997 (5.7446)  loss_box_reg: 0.2202 (0.2412)  loss_objectness: 0.1414 (0.1520)  loss_rpn_box_reg: 0.0725 (0.0759)  time: 0.6297  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [45] Total time: 0:05:12 (0.6243 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:44  model_time: 0.6531 (0.6531)  evaluator_time: 0.0340 (0.0340)  time: 0.8392  data: 0.1430  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4481 (0.4523)  evaluator_time: 0.0330 (0.0369)  time: 0.6376  data: 0.1533  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4681 (0.4534)  evaluator_time: 0.0350 (0.0373)  time: 0.6524  data: 0.1489  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6407 s / it)\n",
      "Averaged stats: model_time: 0.4681 (0.4534)  evaluator_time: 0.0350 (0.0373)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [45]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.2058 (6.2058)  loss_classifier: 5.6525 (5.6525)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1247 (0.1247)  loss_rpn_box_reg: 0.1341 (0.1341)  time: 0.6491  data: 0.1470  max mem: 10734\n",
      "Testing Epoch: [45]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0052 (6.1272)  loss_classifier: 5.4138 (5.6161)  loss_box_reg: 0.2609 (0.2896)  loss_objectness: 0.1277 (0.1312)  loss_rpn_box_reg: 0.0706 (0.0903)  time: 0.5837  data: 0.1454  max mem: 10734\n",
      "Testing Epoch: [45]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1613 (6.1610)  loss_classifier: 5.6986 (5.6541)  loss_box_reg: 0.2500 (0.2850)  loss_objectness: 0.1185 (0.1316)  loss_rpn_box_reg: 0.0745 (0.0903)  time: 0.5973  data: 0.1446  max mem: 10734\n",
      "Testing Epoch: [45] Total time: 0:01:14 (0.5940 s / it)\n",
      "Training Epoch: [46]  [  0/500]  eta: 0:06:59  lr: 0.000000  loss: 6.2966 (6.2966)  loss_classifier: 5.7553 (5.7553)  loss_box_reg: 0.1906 (0.1906)  loss_objectness: 0.2196 (0.2196)  loss_rpn_box_reg: 0.1310 (0.1310)  time: 0.8382  data: 0.1420  max mem: 10734\n",
      "Training Epoch: [46]  [ 10/500]  eta: 0:05:19  lr: 0.000000  loss: 6.0194 (5.9743)  loss_classifier: 5.4592 (5.5038)  loss_box_reg: 0.2090 (0.2329)  loss_objectness: 0.1375 (0.1479)  loss_rpn_box_reg: 0.0826 (0.0897)  time: 0.6517  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [46]  [ 20/500]  eta: 0:05:08  lr: 0.000000  loss: 6.0194 (6.1117)  loss_classifier: 5.4279 (5.6104)  loss_box_reg: 0.2615 (0.2593)  loss_objectness: 0.1504 (0.1561)  loss_rpn_box_reg: 0.0804 (0.0859)  time: 0.6325  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [46]  [ 30/500]  eta: 0:04:58  lr: 0.000000  loss: 6.1229 (6.1981)  loss_classifier: 5.5972 (5.7190)  loss_box_reg: 0.2471 (0.2489)  loss_objectness: 0.1496 (0.1479)  loss_rpn_box_reg: 0.0783 (0.0822)  time: 0.6251  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [46]  [ 40/500]  eta: 0:04:52  lr: 0.000000  loss: 6.3456 (6.1896)  loss_classifier: 5.9024 (5.7177)  loss_box_reg: 0.2245 (0.2462)  loss_objectness: 0.1323 (0.1455)  loss_rpn_box_reg: 0.0696 (0.0802)  time: 0.6270  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [46]  [ 50/500]  eta: 0:04:46  lr: 0.000000  loss: 6.1613 (6.1778)  loss_classifier: 5.6757 (5.7134)  loss_box_reg: 0.2267 (0.2406)  loss_objectness: 0.1388 (0.1475)  loss_rpn_box_reg: 0.0607 (0.0763)  time: 0.6386  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [46]  [ 60/500]  eta: 0:04:39  lr: 0.000000  loss: 5.9370 (6.1673)  loss_classifier: 5.4875 (5.7052)  loss_box_reg: 0.2267 (0.2377)  loss_objectness: 0.1588 (0.1481)  loss_rpn_box_reg: 0.0600 (0.0763)  time: 0.6384  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [46]  [ 70/500]  eta: 0:04:33  lr: 0.000000  loss: 5.9314 (6.1523)  loss_classifier: 5.4715 (5.6872)  loss_box_reg: 0.2362 (0.2425)  loss_objectness: 0.1469 (0.1465)  loss_rpn_box_reg: 0.0688 (0.0762)  time: 0.6377  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [46]  [ 80/500]  eta: 0:04:26  lr: 0.000000  loss: 6.0701 (6.1450)  loss_classifier: 5.4795 (5.6851)  loss_box_reg: 0.2350 (0.2395)  loss_objectness: 0.1324 (0.1454)  loss_rpn_box_reg: 0.0664 (0.0751)  time: 0.6315  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [46]  [ 90/500]  eta: 0:04:19  lr: 0.000000  loss: 6.1965 (6.1755)  loss_classifier: 5.7296 (5.7104)  loss_box_reg: 0.2134 (0.2419)  loss_objectness: 0.1523 (0.1480)  loss_rpn_box_reg: 0.0664 (0.0752)  time: 0.6172  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [46]  [100/500]  eta: 0:04:13  lr: 0.000000  loss: 6.3382 (6.1721)  loss_classifier: 5.8239 (5.7093)  loss_box_reg: 0.2313 (0.2405)  loss_objectness: 0.1523 (0.1478)  loss_rpn_box_reg: 0.0721 (0.0746)  time: 0.6248  data: 0.1375  max mem: 10734\n",
      "Training Epoch: [46]  [110/500]  eta: 0:04:07  lr: 0.000000  loss: 6.3691 (6.1923)  loss_classifier: 5.9097 (5.7311)  loss_box_reg: 0.2184 (0.2408)  loss_objectness: 0.1251 (0.1470)  loss_rpn_box_reg: 0.0643 (0.0733)  time: 0.6391  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [46]  [120/500]  eta: 0:03:59  lr: 0.000000  loss: 6.2265 (6.1890)  loss_classifier: 5.6777 (5.7284)  loss_box_reg: 0.2134 (0.2390)  loss_objectness: 0.1396 (0.1475)  loss_rpn_box_reg: 0.0718 (0.0740)  time: 0.6210  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [46]  [130/500]  eta: 0:03:53  lr: 0.000000  loss: 6.2265 (6.1982)  loss_classifier: 5.6654 (5.7349)  loss_box_reg: 0.2068 (0.2401)  loss_objectness: 0.1575 (0.1487)  loss_rpn_box_reg: 0.0741 (0.0744)  time: 0.6087  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [46]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.1196 (6.1900)  loss_classifier: 5.6806 (5.7261)  loss_box_reg: 0.2205 (0.2398)  loss_objectness: 0.1575 (0.1493)  loss_rpn_box_reg: 0.0666 (0.0747)  time: 0.6194  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [46]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.0291 (6.1762)  loss_classifier: 5.5871 (5.7161)  loss_box_reg: 0.2064 (0.2375)  loss_objectness: 0.1345 (0.1483)  loss_rpn_box_reg: 0.0677 (0.0743)  time: 0.6162  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [46]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 5.9997 (6.1770)  loss_classifier: 5.5336 (5.7159)  loss_box_reg: 0.2086 (0.2370)  loss_objectness: 0.1362 (0.1492)  loss_rpn_box_reg: 0.0785 (0.0750)  time: 0.6065  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [46]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.1363 (6.1855)  loss_classifier: 5.5993 (5.7233)  loss_box_reg: 0.2388 (0.2374)  loss_objectness: 0.1585 (0.1493)  loss_rpn_box_reg: 0.0864 (0.0755)  time: 0.6162  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [46]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.3827 (6.1921)  loss_classifier: 5.7944 (5.7272)  loss_box_reg: 0.2735 (0.2393)  loss_objectness: 0.1551 (0.1501)  loss_rpn_box_reg: 0.0763 (0.0754)  time: 0.6312  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [46]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.4241 (6.2134)  loss_classifier: 5.9561 (5.7469)  loss_box_reg: 0.2735 (0.2394)  loss_objectness: 0.1685 (0.1516)  loss_rpn_box_reg: 0.0739 (0.0756)  time: 0.6266  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [46]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.3989 (6.2034)  loss_classifier: 5.8231 (5.7355)  loss_box_reg: 0.2196 (0.2385)  loss_objectness: 0.1685 (0.1521)  loss_rpn_box_reg: 0.0858 (0.0773)  time: 0.6212  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [46]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.0734 (6.2119)  loss_classifier: 5.6185 (5.7427)  loss_box_reg: 0.2250 (0.2400)  loss_objectness: 0.1466 (0.1516)  loss_rpn_box_reg: 0.0881 (0.0775)  time: 0.6193  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [46]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.3543 (6.2187)  loss_classifier: 5.8514 (5.7486)  loss_box_reg: 0.2473 (0.2402)  loss_objectness: 0.1466 (0.1524)  loss_rpn_box_reg: 0.0747 (0.0775)  time: 0.6125  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [46]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.3075 (6.2153)  loss_classifier: 5.8348 (5.7436)  loss_box_reg: 0.2387 (0.2408)  loss_objectness: 0.1666 (0.1527)  loss_rpn_box_reg: 0.0830 (0.0782)  time: 0.6091  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [46]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 5.9784 (6.2118)  loss_classifier: 5.5183 (5.7400)  loss_box_reg: 0.2473 (0.2414)  loss_objectness: 0.1587 (0.1525)  loss_rpn_box_reg: 0.0719 (0.0779)  time: 0.6207  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [46]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 5.9869 (6.2109)  loss_classifier: 5.5183 (5.7383)  loss_box_reg: 0.2294 (0.2422)  loss_objectness: 0.1469 (0.1525)  loss_rpn_box_reg: 0.0635 (0.0780)  time: 0.6317  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [46]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.1875 (6.2087)  loss_classifier: 5.6034 (5.7333)  loss_box_reg: 0.2492 (0.2437)  loss_objectness: 0.1570 (0.1532)  loss_rpn_box_reg: 0.0859 (0.0785)  time: 0.6383  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [46]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.0748 (6.2099)  loss_classifier: 5.5961 (5.7357)  loss_box_reg: 0.2532 (0.2427)  loss_objectness: 0.1553 (0.1531)  loss_rpn_box_reg: 0.0815 (0.0784)  time: 0.6356  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [46]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.0748 (6.2111)  loss_classifier: 5.6558 (5.7373)  loss_box_reg: 0.2331 (0.2428)  loss_objectness: 0.1474 (0.1533)  loss_rpn_box_reg: 0.0585 (0.0778)  time: 0.6083  data: 0.1308  max mem: 10734\n",
      "Training Epoch: [46]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 5.9226 (6.2017)  loss_classifier: 5.3335 (5.7266)  loss_box_reg: 0.2433 (0.2436)  loss_objectness: 0.1407 (0.1536)  loss_rpn_box_reg: 0.0605 (0.0780)  time: 0.6116  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [46]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.0261 (6.2057)  loss_classifier: 5.5509 (5.7293)  loss_box_reg: 0.2434 (0.2440)  loss_objectness: 0.1579 (0.1543)  loss_rpn_box_reg: 0.0784 (0.0781)  time: 0.6308  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [46]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.3310 (6.2145)  loss_classifier: 5.8435 (5.7390)  loss_box_reg: 0.2248 (0.2436)  loss_objectness: 0.1395 (0.1540)  loss_rpn_box_reg: 0.0778 (0.0779)  time: 0.6316  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [46]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2787 (6.2176)  loss_classifier: 5.8272 (5.7424)  loss_box_reg: 0.2225 (0.2437)  loss_objectness: 0.1388 (0.1538)  loss_rpn_box_reg: 0.0576 (0.0776)  time: 0.6307  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [46]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.1147 (6.2179)  loss_classifier: 5.6436 (5.7439)  loss_box_reg: 0.2183 (0.2430)  loss_objectness: 0.1516 (0.1536)  loss_rpn_box_reg: 0.0528 (0.0773)  time: 0.6294  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [46]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 5.9536 (6.2080)  loss_classifier: 5.4903 (5.7354)  loss_box_reg: 0.2049 (0.2421)  loss_objectness: 0.1525 (0.1532)  loss_rpn_box_reg: 0.0700 (0.0772)  time: 0.6291  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [46]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 5.9581 (6.2103)  loss_classifier: 5.5584 (5.7366)  loss_box_reg: 0.2517 (0.2433)  loss_objectness: 0.1359 (0.1530)  loss_rpn_box_reg: 0.0739 (0.0775)  time: 0.6264  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [46]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1648 (6.2150)  loss_classifier: 5.7331 (5.7411)  loss_box_reg: 0.2517 (0.2431)  loss_objectness: 0.1508 (0.1534)  loss_rpn_box_reg: 0.0739 (0.0774)  time: 0.6326  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [46]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.0303 (6.2118)  loss_classifier: 5.5459 (5.7381)  loss_box_reg: 0.2242 (0.2429)  loss_objectness: 0.1554 (0.1535)  loss_rpn_box_reg: 0.0714 (0.0774)  time: 0.6313  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [46]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 5.9888 (6.2141)  loss_classifier: 5.5070 (5.7403)  loss_box_reg: 0.2321 (0.2431)  loss_objectness: 0.1508 (0.1533)  loss_rpn_box_reg: 0.0728 (0.0774)  time: 0.6166  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [46]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 5.9499 (6.2082)  loss_classifier: 5.5070 (5.7354)  loss_box_reg: 0.2321 (0.2427)  loss_objectness: 0.1498 (0.1530)  loss_rpn_box_reg: 0.0713 (0.0771)  time: 0.6158  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [46]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 5.9139 (6.2040)  loss_classifier: 5.4902 (5.7315)  loss_box_reg: 0.2045 (0.2426)  loss_objectness: 0.1406 (0.1531)  loss_rpn_box_reg: 0.0626 (0.0768)  time: 0.6320  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [46]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 5.9595 (6.2026)  loss_classifier: 5.5891 (5.7311)  loss_box_reg: 0.2134 (0.2419)  loss_objectness: 0.1403 (0.1529)  loss_rpn_box_reg: 0.0613 (0.0766)  time: 0.6391  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [46]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 5.9564 (6.2003)  loss_classifier: 5.6706 (5.7296)  loss_box_reg: 0.2134 (0.2412)  loss_objectness: 0.1384 (0.1527)  loss_rpn_box_reg: 0.0650 (0.0768)  time: 0.6289  data: 0.1312  max mem: 10734\n",
      "Training Epoch: [46]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1021 (6.2005)  loss_classifier: 5.6931 (5.7300)  loss_box_reg: 0.2246 (0.2412)  loss_objectness: 0.1331 (0.1527)  loss_rpn_box_reg: 0.0644 (0.0766)  time: 0.6311  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [46]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2797 (6.2050)  loss_classifier: 5.8234 (5.7357)  loss_box_reg: 0.2224 (0.2408)  loss_objectness: 0.1224 (0.1525)  loss_rpn_box_reg: 0.0546 (0.0761)  time: 0.6379  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [46]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.2921 (6.2067)  loss_classifier: 5.8643 (5.7372)  loss_box_reg: 0.2086 (0.2411)  loss_objectness: 0.1339 (0.1526)  loss_rpn_box_reg: 0.0505 (0.0758)  time: 0.6255  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [46]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.2048 (6.2053)  loss_classifier: 5.7087 (5.7367)  loss_box_reg: 0.2448 (0.2407)  loss_objectness: 0.1445 (0.1524)  loss_rpn_box_reg: 0.0605 (0.0755)  time: 0.6249  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [46]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2140 (6.2079)  loss_classifier: 5.7258 (5.7395)  loss_box_reg: 0.2331 (0.2403)  loss_objectness: 0.1418 (0.1525)  loss_rpn_box_reg: 0.0652 (0.0756)  time: 0.6328  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [46]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2694 (6.2101)  loss_classifier: 5.8000 (5.7419)  loss_box_reg: 0.2292 (0.2402)  loss_objectness: 0.1418 (0.1522)  loss_rpn_box_reg: 0.0652 (0.0758)  time: 0.6265  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [46]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.2447 (6.2089)  loss_classifier: 5.6954 (5.7405)  loss_box_reg: 0.2301 (0.2402)  loss_objectness: 0.1459 (0.1523)  loss_rpn_box_reg: 0.0594 (0.0759)  time: 0.6312  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [46]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2447 (6.2119)  loss_classifier: 5.6176 (5.7434)  loss_box_reg: 0.2416 (0.2403)  loss_objectness: 0.1525 (0.1523)  loss_rpn_box_reg: 0.0727 (0.0758)  time: 0.6294  data: 0.1374  max mem: 10734\n",
      "Training Epoch: [46] Total time: 0:05:13 (0.6267 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:55  model_time: 0.7382 (0.7382)  evaluator_time: 0.0350 (0.0350)  time: 0.9262  data: 0.1430  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4511 (0.4536)  evaluator_time: 0.0350 (0.0380)  time: 0.6391  data: 0.1490  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4711 (0.4554)  evaluator_time: 0.0360 (0.0382)  time: 0.6576  data: 0.1493  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6439 s / it)\n",
      "Averaged stats: model_time: 0.4711 (0.4554)  evaluator_time: 0.0360 (0.0382)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.28s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [46]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.1872 (6.1872)  loss_classifier: 5.6403 (5.6403)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1198 (0.1198)  loss_rpn_box_reg: 0.1326 (0.1326)  time: 0.6541  data: 0.1480  max mem: 10734\n",
      "Testing Epoch: [46]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9987 (6.1391)  loss_classifier: 5.4335 (5.6302)  loss_box_reg: 0.2609 (0.2891)  loss_objectness: 0.1314 (0.1308)  loss_rpn_box_reg: 0.0714 (0.0889)  time: 0.5891  data: 0.1462  max mem: 10734\n",
      "Testing Epoch: [46]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1810 (6.1697)  loss_classifier: 5.6877 (5.6651)  loss_box_reg: 0.2500 (0.2846)  loss_objectness: 0.1200 (0.1309)  loss_rpn_box_reg: 0.0745 (0.0891)  time: 0.6046  data: 0.1479  max mem: 10734\n",
      "Testing Epoch: [46] Total time: 0:01:15 (0.6005 s / it)\n",
      "Training Epoch: [47]  [  0/500]  eta: 0:07:27  lr: 0.000000  loss: 5.5016 (5.5016)  loss_classifier: 5.1398 (5.1398)  loss_box_reg: 0.1508 (0.1508)  loss_objectness: 0.1336 (0.1336)  loss_rpn_box_reg: 0.0773 (0.0773)  time: 0.8952  data: 0.1290  max mem: 10734\n",
      "Training Epoch: [47]  [ 10/500]  eta: 0:05:16  lr: 0.000000  loss: 5.9736 (6.1640)  loss_classifier: 5.4868 (5.7087)  loss_box_reg: 0.2143 (0.2166)  loss_objectness: 0.1451 (0.1541)  loss_rpn_box_reg: 0.0863 (0.0846)  time: 0.6464  data: 0.1297  max mem: 10734\n",
      "Training Epoch: [47]  [ 20/500]  eta: 0:05:00  lr: 0.000000  loss: 5.9710 (6.1232)  loss_classifier: 5.4868 (5.6768)  loss_box_reg: 0.2143 (0.2226)  loss_objectness: 0.1451 (0.1489)  loss_rpn_box_reg: 0.0690 (0.0748)  time: 0.6133  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [47]  [ 30/500]  eta: 0:04:55  lr: 0.000000  loss: 6.0448 (6.1906)  loss_classifier: 5.5058 (5.7295)  loss_box_reg: 0.2444 (0.2348)  loss_objectness: 0.1536 (0.1533)  loss_rpn_box_reg: 0.0585 (0.0730)  time: 0.6193  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [47]  [ 40/500]  eta: 0:04:48  lr: 0.000000  loss: 6.2269 (6.1731)  loss_classifier: 5.7494 (5.7252)  loss_box_reg: 0.2420 (0.2309)  loss_objectness: 0.1363 (0.1469)  loss_rpn_box_reg: 0.0585 (0.0702)  time: 0.6276  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [47]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 6.1775 (6.1704)  loss_classifier: 5.7200 (5.7210)  loss_box_reg: 0.2236 (0.2278)  loss_objectness: 0.1390 (0.1499)  loss_rpn_box_reg: 0.0663 (0.0716)  time: 0.6243  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [47]  [ 60/500]  eta: 0:04:36  lr: 0.000000  loss: 6.2262 (6.1889)  loss_classifier: 5.7503 (5.7401)  loss_box_reg: 0.2255 (0.2268)  loss_objectness: 0.1560 (0.1511)  loss_rpn_box_reg: 0.0697 (0.0710)  time: 0.6287  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [47]  [ 70/500]  eta: 0:04:29  lr: 0.000000  loss: 6.2590 (6.2059)  loss_classifier: 5.7503 (5.7563)  loss_box_reg: 0.2256 (0.2289)  loss_objectness: 0.1491 (0.1503)  loss_rpn_box_reg: 0.0635 (0.0704)  time: 0.6274  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [47]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 6.2953 (6.2339)  loss_classifier: 5.6848 (5.7719)  loss_box_reg: 0.2434 (0.2335)  loss_objectness: 0.1506 (0.1541)  loss_rpn_box_reg: 0.0785 (0.0745)  time: 0.6265  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [47]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 6.2953 (6.2275)  loss_classifier: 5.6881 (5.7612)  loss_box_reg: 0.2611 (0.2349)  loss_objectness: 0.1516 (0.1543)  loss_rpn_box_reg: 0.0871 (0.0771)  time: 0.6299  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [47]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 6.1402 (6.2241)  loss_classifier: 5.6778 (5.7612)  loss_box_reg: 0.2133 (0.2336)  loss_objectness: 0.1516 (0.1532)  loss_rpn_box_reg: 0.0680 (0.0761)  time: 0.6358  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [47]  [110/500]  eta: 0:04:06  lr: 0.000000  loss: 6.2206 (6.2349)  loss_classifier: 5.7822 (5.7750)  loss_box_reg: 0.2091 (0.2325)  loss_objectness: 0.1279 (0.1523)  loss_rpn_box_reg: 0.0605 (0.0751)  time: 0.6458  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [47]  [120/500]  eta: 0:03:59  lr: 0.000000  loss: 6.3225 (6.2373)  loss_classifier: 5.8793 (5.7788)  loss_box_reg: 0.2152 (0.2309)  loss_objectness: 0.1382 (0.1515)  loss_rpn_box_reg: 0.0689 (0.0761)  time: 0.6443  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [47]  [130/500]  eta: 0:03:53  lr: 0.000000  loss: 6.2125 (6.2412)  loss_classifier: 5.7125 (5.7792)  loss_box_reg: 0.2307 (0.2330)  loss_objectness: 0.1528 (0.1521)  loss_rpn_box_reg: 0.0689 (0.0769)  time: 0.6315  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [47]  [140/500]  eta: 0:03:47  lr: 0.000000  loss: 6.3304 (6.2594)  loss_classifier: 5.8688 (5.7985)  loss_box_reg: 0.2391 (0.2312)  loss_objectness: 0.1528 (0.1519)  loss_rpn_box_reg: 0.0769 (0.0778)  time: 0.6261  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [47]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 6.2436 (6.2487)  loss_classifier: 5.8372 (5.7894)  loss_box_reg: 0.2171 (0.2307)  loss_objectness: 0.1507 (0.1520)  loss_rpn_box_reg: 0.0661 (0.0767)  time: 0.6249  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [47]  [160/500]  eta: 0:03:34  lr: 0.000000  loss: 5.9989 (6.2511)  loss_classifier: 5.5379 (5.7910)  loss_box_reg: 0.2300 (0.2319)  loss_objectness: 0.1507 (0.1514)  loss_rpn_box_reg: 0.0652 (0.0767)  time: 0.6293  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [47]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 5.9989 (6.2467)  loss_classifier: 5.5444 (5.7820)  loss_box_reg: 0.2458 (0.2354)  loss_objectness: 0.1389 (0.1518)  loss_rpn_box_reg: 0.0743 (0.0775)  time: 0.6209  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [47]  [180/500]  eta: 0:03:21  lr: 0.000000  loss: 6.0565 (6.2426)  loss_classifier: 5.5580 (5.7777)  loss_box_reg: 0.2274 (0.2356)  loss_objectness: 0.1484 (0.1521)  loss_rpn_box_reg: 0.0725 (0.0772)  time: 0.6129  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [47]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.1457 (6.2465)  loss_classifier: 5.6723 (5.7816)  loss_box_reg: 0.2240 (0.2357)  loss_objectness: 0.1598 (0.1530)  loss_rpn_box_reg: 0.0591 (0.0763)  time: 0.6181  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [47]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.1457 (6.2384)  loss_classifier: 5.6505 (5.7719)  loss_box_reg: 0.2286 (0.2369)  loss_objectness: 0.1598 (0.1533)  loss_rpn_box_reg: 0.0606 (0.0763)  time: 0.6180  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [47]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 5.7992 (6.2230)  loss_classifier: 5.3635 (5.7553)  loss_box_reg: 0.2609 (0.2380)  loss_objectness: 0.1511 (0.1530)  loss_rpn_box_reg: 0.0730 (0.0767)  time: 0.6227  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [47]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 5.7992 (6.2222)  loss_classifier: 5.3451 (5.7541)  loss_box_reg: 0.2310 (0.2379)  loss_objectness: 0.1538 (0.1533)  loss_rpn_box_reg: 0.0730 (0.0769)  time: 0.6278  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [47]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.3582 (6.2329)  loss_classifier: 5.8634 (5.7627)  loss_box_reg: 0.2350 (0.2387)  loss_objectness: 0.1774 (0.1539)  loss_rpn_box_reg: 0.0722 (0.0777)  time: 0.6390  data: 0.1377  max mem: 10734\n",
      "Training Epoch: [47]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.3037 (6.2335)  loss_classifier: 5.7783 (5.7631)  loss_box_reg: 0.2350 (0.2383)  loss_objectness: 0.1489 (0.1541)  loss_rpn_box_reg: 0.0746 (0.0781)  time: 0.6442  data: 0.1378  max mem: 10734\n",
      "Training Epoch: [47]  [250/500]  eta: 0:02:37  lr: 0.000000  loss: 6.1256 (6.2295)  loss_classifier: 5.6703 (5.7595)  loss_box_reg: 0.2102 (0.2379)  loss_objectness: 0.1427 (0.1537)  loss_rpn_box_reg: 0.0724 (0.0784)  time: 0.6315  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [47]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.1185 (6.2295)  loss_classifier: 5.6319 (5.7594)  loss_box_reg: 0.2500 (0.2390)  loss_objectness: 0.1329 (0.1533)  loss_rpn_box_reg: 0.0712 (0.0778)  time: 0.6249  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [47]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.3315 (6.2388)  loss_classifier: 5.8809 (5.7687)  loss_box_reg: 0.2416 (0.2385)  loss_objectness: 0.1311 (0.1536)  loss_rpn_box_reg: 0.0656 (0.0781)  time: 0.6230  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [47]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.1456 (6.2359)  loss_classifier: 5.6617 (5.7665)  loss_box_reg: 0.2291 (0.2381)  loss_objectness: 0.1323 (0.1533)  loss_rpn_box_reg: 0.0691 (0.0780)  time: 0.6276  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [47]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.1456 (6.2331)  loss_classifier: 5.7367 (5.7642)  loss_box_reg: 0.2190 (0.2377)  loss_objectness: 0.1330 (0.1533)  loss_rpn_box_reg: 0.0649 (0.0780)  time: 0.6264  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [47]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.2982 (6.2423)  loss_classifier: 5.8855 (5.7732)  loss_box_reg: 0.2236 (0.2379)  loss_objectness: 0.1515 (0.1538)  loss_rpn_box_reg: 0.0641 (0.0774)  time: 0.6214  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [47]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.4791 (6.2469)  loss_classifier: 6.0761 (5.7768)  loss_box_reg: 0.2416 (0.2382)  loss_objectness: 0.1758 (0.1546)  loss_rpn_box_reg: 0.0641 (0.0772)  time: 0.6306  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [47]  [320/500]  eta: 0:01:53  lr: 0.000000  loss: 6.1896 (6.2363)  loss_classifier: 5.6427 (5.7655)  loss_box_reg: 0.2544 (0.2386)  loss_objectness: 0.1771 (0.1547)  loss_rpn_box_reg: 0.0683 (0.0775)  time: 0.6242  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [47]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 5.9780 (6.2308)  loss_classifier: 5.4732 (5.7600)  loss_box_reg: 0.2556 (0.2389)  loss_objectness: 0.1417 (0.1543)  loss_rpn_box_reg: 0.0810 (0.0776)  time: 0.5981  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [47]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 5.9690 (6.2248)  loss_classifier: 5.4732 (5.7539)  loss_box_reg: 0.2556 (0.2393)  loss_objectness: 0.1445 (0.1541)  loss_rpn_box_reg: 0.0810 (0.0775)  time: 0.5999  data: 0.1308  max mem: 10734\n",
      "Training Epoch: [47]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.0397 (6.2240)  loss_classifier: 5.5138 (5.7522)  loss_box_reg: 0.2551 (0.2396)  loss_objectness: 0.1460 (0.1544)  loss_rpn_box_reg: 0.0744 (0.0777)  time: 0.6206  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [47]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1113 (6.2265)  loss_classifier: 5.6313 (5.7561)  loss_box_reg: 0.2050 (0.2384)  loss_objectness: 0.1398 (0.1545)  loss_rpn_box_reg: 0.0741 (0.0775)  time: 0.6149  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [47]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1818 (6.2286)  loss_classifier: 5.6868 (5.7586)  loss_box_reg: 0.2155 (0.2385)  loss_objectness: 0.1443 (0.1542)  loss_rpn_box_reg: 0.0657 (0.0773)  time: 0.6165  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [47]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.0539 (6.2210)  loss_classifier: 5.6278 (5.7523)  loss_box_reg: 0.2208 (0.2379)  loss_objectness: 0.1528 (0.1539)  loss_rpn_box_reg: 0.0586 (0.0768)  time: 0.6213  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [47]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 5.9815 (6.2236)  loss_classifier: 5.6213 (5.7552)  loss_box_reg: 0.2208 (0.2377)  loss_objectness: 0.1503 (0.1537)  loss_rpn_box_reg: 0.0654 (0.0770)  time: 0.6160  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [47]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1898 (6.2267)  loss_classifier: 5.7995 (5.7587)  loss_box_reg: 0.2234 (0.2375)  loss_objectness: 0.1491 (0.1538)  loss_rpn_box_reg: 0.0725 (0.0768)  time: 0.6285  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [47]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1689 (6.2245)  loss_classifier: 5.6449 (5.7553)  loss_box_reg: 0.2488 (0.2380)  loss_objectness: 0.1675 (0.1543)  loss_rpn_box_reg: 0.0705 (0.0769)  time: 0.6216  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [47]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1689 (6.2227)  loss_classifier: 5.6370 (5.7533)  loss_box_reg: 0.2552 (0.2383)  loss_objectness: 0.1781 (0.1545)  loss_rpn_box_reg: 0.0672 (0.0766)  time: 0.6069  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [47]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.0939 (6.2200)  loss_classifier: 5.6155 (5.7502)  loss_box_reg: 0.2415 (0.2388)  loss_objectness: 0.1669 (0.1543)  loss_rpn_box_reg: 0.0684 (0.0767)  time: 0.6216  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [47]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 5.9614 (6.2194)  loss_classifier: 5.5719 (5.7513)  loss_box_reg: 0.2081 (0.2379)  loss_objectness: 0.1404 (0.1540)  loss_rpn_box_reg: 0.0684 (0.0763)  time: 0.6344  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [47]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0118 (6.2147)  loss_classifier: 5.6050 (5.7475)  loss_box_reg: 0.2097 (0.2376)  loss_objectness: 0.1254 (0.1535)  loss_rpn_box_reg: 0.0644 (0.0761)  time: 0.6193  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [47]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.1137 (6.2161)  loss_classifier: 5.6294 (5.7482)  loss_box_reg: 0.2318 (0.2376)  loss_objectness: 0.1359 (0.1538)  loss_rpn_box_reg: 0.0703 (0.0765)  time: 0.6229  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [47]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2185 (6.2141)  loss_classifier: 5.6402 (5.7463)  loss_box_reg: 0.2353 (0.2378)  loss_objectness: 0.1514 (0.1535)  loss_rpn_box_reg: 0.0909 (0.0764)  time: 0.6385  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [47]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0996 (6.2133)  loss_classifier: 5.6166 (5.7455)  loss_box_reg: 0.2362 (0.2381)  loss_objectness: 0.1443 (0.1535)  loss_rpn_box_reg: 0.0710 (0.0762)  time: 0.6319  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [47]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0996 (6.2131)  loss_classifier: 5.7018 (5.7457)  loss_box_reg: 0.2225 (0.2380)  loss_objectness: 0.1402 (0.1533)  loss_rpn_box_reg: 0.0670 (0.0760)  time: 0.6285  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [47]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2072 (6.2139)  loss_classifier: 5.7440 (5.7458)  loss_box_reg: 0.2359 (0.2387)  loss_objectness: 0.1482 (0.1532)  loss_rpn_box_reg: 0.0633 (0.0762)  time: 0.6311  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [47] Total time: 0:05:12 (0.6257 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:55  model_time: 0.7332 (0.7332)  evaluator_time: 0.0340 (0.0340)  time: 0.9202  data: 0.1430  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4471 (0.4524)  evaluator_time: 0.0340 (0.0352)  time: 0.6339  data: 0.1485  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4771 (0.4539)  evaluator_time: 0.0360 (0.0359)  time: 0.6553  data: 0.1489  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6427 s / it)\n",
      "Averaged stats: model_time: 0.4771 (0.4539)  evaluator_time: 0.0360 (0.0359)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.28s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [47]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.1989 (6.1989)  loss_classifier: 5.6465 (5.6465)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1245 (0.1245)  loss_rpn_box_reg: 0.1334 (0.1334)  time: 0.6531  data: 0.1370  max mem: 10734\n",
      "Testing Epoch: [47]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9843 (6.1287)  loss_classifier: 5.4283 (5.6193)  loss_box_reg: 0.2609 (0.2886)  loss_objectness: 0.1274 (0.1319)  loss_rpn_box_reg: 0.0732 (0.0888)  time: 0.5883  data: 0.1470  max mem: 10734\n",
      "Testing Epoch: [47]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1689 (6.1607)  loss_classifier: 5.6815 (5.6560)  loss_box_reg: 0.2500 (0.2842)  loss_objectness: 0.1154 (0.1315)  loss_rpn_box_reg: 0.0745 (0.0891)  time: 0.5990  data: 0.1458  max mem: 10734\n",
      "Testing Epoch: [47] Total time: 0:01:14 (0.5961 s / it)\n",
      "Training Epoch: [48]  [  0/500]  eta: 0:06:55  lr: 0.000000  loss: 6.3708 (6.3708)  loss_classifier: 5.8237 (5.8237)  loss_box_reg: 0.2898 (0.2898)  loss_objectness: 0.1421 (0.1421)  loss_rpn_box_reg: 0.1151 (0.1151)  time: 0.8302  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [48]  [ 10/500]  eta: 0:05:10  lr: 0.000000  loss: 6.0650 (6.2178)  loss_classifier: 5.7011 (5.7408)  loss_box_reg: 0.2480 (0.2610)  loss_objectness: 0.1421 (0.1447)  loss_rpn_box_reg: 0.0716 (0.0713)  time: 0.6329  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [48]  [ 20/500]  eta: 0:05:02  lr: 0.000000  loss: 6.2435 (6.2320)  loss_classifier: 5.7011 (5.7417)  loss_box_reg: 0.2530 (0.2579)  loss_objectness: 0.1507 (0.1516)  loss_rpn_box_reg: 0.0749 (0.0807)  time: 0.6199  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [48]  [ 30/500]  eta: 0:04:56  lr: 0.000000  loss: 6.2781 (6.2592)  loss_classifier: 5.7934 (5.7701)  loss_box_reg: 0.2537 (0.2520)  loss_objectness: 0.1523 (0.1520)  loss_rpn_box_reg: 0.0921 (0.0851)  time: 0.6302  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [48]  [ 40/500]  eta: 0:04:49  lr: 0.000000  loss: 6.2021 (6.2751)  loss_classifier: 5.7311 (5.7924)  loss_box_reg: 0.2350 (0.2518)  loss_objectness: 0.1393 (0.1517)  loss_rpn_box_reg: 0.0755 (0.0792)  time: 0.6285  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [48]  [ 50/500]  eta: 0:04:41  lr: 0.000000  loss: 5.9995 (6.2368)  loss_classifier: 5.5716 (5.7511)  loss_box_reg: 0.2387 (0.2509)  loss_objectness: 0.1467 (0.1565)  loss_rpn_box_reg: 0.0646 (0.0784)  time: 0.6162  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [48]  [ 60/500]  eta: 0:04:34  lr: 0.000000  loss: 6.0524 (6.2319)  loss_classifier: 5.5649 (5.7501)  loss_box_reg: 0.2156 (0.2485)  loss_objectness: 0.1410 (0.1544)  loss_rpn_box_reg: 0.0763 (0.0790)  time: 0.6120  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [48]  [ 70/500]  eta: 0:04:27  lr: 0.000000  loss: 6.1408 (6.2130)  loss_classifier: 5.6767 (5.7282)  loss_box_reg: 0.2187 (0.2516)  loss_objectness: 0.1374 (0.1519)  loss_rpn_box_reg: 0.0763 (0.0813)  time: 0.6111  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [48]  [ 80/500]  eta: 0:04:21  lr: 0.000000  loss: 6.0972 (6.2003)  loss_classifier: 5.5098 (5.7201)  loss_box_reg: 0.2347 (0.2462)  loss_objectness: 0.1432 (0.1523)  loss_rpn_box_reg: 0.0652 (0.0818)  time: 0.6226  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [48]  [ 90/500]  eta: 0:04:15  lr: 0.000000  loss: 6.0173 (6.1923)  loss_classifier: 5.6013 (5.7184)  loss_box_reg: 0.2142 (0.2438)  loss_objectness: 0.1383 (0.1498)  loss_rpn_box_reg: 0.0630 (0.0803)  time: 0.6309  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [48]  [100/500]  eta: 0:04:09  lr: 0.000000  loss: 6.0173 (6.1798)  loss_classifier: 5.6013 (5.7092)  loss_box_reg: 0.2121 (0.2427)  loss_objectness: 0.1332 (0.1484)  loss_rpn_box_reg: 0.0608 (0.0794)  time: 0.6264  data: 0.1310  max mem: 10734\n",
      "Training Epoch: [48]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 6.1782 (6.1843)  loss_classifier: 5.7685 (5.7154)  loss_box_reg: 0.2147 (0.2418)  loss_objectness: 0.1376 (0.1490)  loss_rpn_box_reg: 0.0595 (0.0781)  time: 0.6283  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [48]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.2765 (6.1894)  loss_classifier: 5.7550 (5.7190)  loss_box_reg: 0.2200 (0.2416)  loss_objectness: 0.1568 (0.1505)  loss_rpn_box_reg: 0.0595 (0.0783)  time: 0.6265  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [48]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.3367 (6.2080)  loss_classifier: 5.7792 (5.7374)  loss_box_reg: 0.2354 (0.2421)  loss_objectness: 0.1587 (0.1503)  loss_rpn_box_reg: 0.0653 (0.0781)  time: 0.6311  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [48]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 6.3681 (6.2116)  loss_classifier: 5.9776 (5.7426)  loss_box_reg: 0.2300 (0.2407)  loss_objectness: 0.1587 (0.1510)  loss_rpn_box_reg: 0.0648 (0.0774)  time: 0.6212  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [48]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.4252 (6.2202)  loss_classifier: 5.9776 (5.7574)  loss_box_reg: 0.2089 (0.2382)  loss_objectness: 0.1391 (0.1491)  loss_rpn_box_reg: 0.0431 (0.0756)  time: 0.6133  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [48]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.1542 (6.2102)  loss_classifier: 5.7701 (5.7507)  loss_box_reg: 0.2021 (0.2356)  loss_objectness: 0.1266 (0.1483)  loss_rpn_box_reg: 0.0496 (0.0756)  time: 0.6307  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [48]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.0034 (6.2079)  loss_classifier: 5.5016 (5.7491)  loss_box_reg: 0.2072 (0.2359)  loss_objectness: 0.1292 (0.1480)  loss_rpn_box_reg: 0.0596 (0.0749)  time: 0.6434  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [48]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.0831 (6.2088)  loss_classifier: 5.6544 (5.7518)  loss_box_reg: 0.2307 (0.2336)  loss_objectness: 0.1480 (0.1490)  loss_rpn_box_reg: 0.0524 (0.0743)  time: 0.6383  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [48]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.2647 (6.2222)  loss_classifier: 5.8426 (5.7655)  loss_box_reg: 0.2173 (0.2337)  loss_objectness: 0.1473 (0.1489)  loss_rpn_box_reg: 0.0526 (0.0740)  time: 0.6251  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [48]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.1577 (6.2202)  loss_classifier: 5.6371 (5.7618)  loss_box_reg: 0.2534 (0.2348)  loss_objectness: 0.1414 (0.1490)  loss_rpn_box_reg: 0.0750 (0.0745)  time: 0.6218  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [48]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.2924 (6.2298)  loss_classifier: 5.8592 (5.7715)  loss_box_reg: 0.2539 (0.2356)  loss_objectness: 0.1515 (0.1489)  loss_rpn_box_reg: 0.0591 (0.0738)  time: 0.6182  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [48]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.3580 (6.2368)  loss_classifier: 5.8789 (5.7788)  loss_box_reg: 0.2320 (0.2352)  loss_objectness: 0.1515 (0.1491)  loss_rpn_box_reg: 0.0588 (0.0737)  time: 0.6242  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [48]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.2929 (6.2360)  loss_classifier: 5.7290 (5.7774)  loss_box_reg: 0.2223 (0.2354)  loss_objectness: 0.1504 (0.1497)  loss_rpn_box_reg: 0.0588 (0.0736)  time: 0.6333  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [48]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.3402 (6.2444)  loss_classifier: 5.7172 (5.7820)  loss_box_reg: 0.2525 (0.2376)  loss_objectness: 0.1581 (0.1508)  loss_rpn_box_reg: 0.0645 (0.0739)  time: 0.6258  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [48]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.3402 (6.2458)  loss_classifier: 5.7119 (5.7851)  loss_box_reg: 0.2385 (0.2367)  loss_objectness: 0.1514 (0.1502)  loss_rpn_box_reg: 0.0700 (0.0738)  time: 0.6197  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [48]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.2102 (6.2426)  loss_classifier: 5.5740 (5.7814)  loss_box_reg: 0.2153 (0.2373)  loss_objectness: 0.1237 (0.1501)  loss_rpn_box_reg: 0.0698 (0.0738)  time: 0.6274  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [48]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 5.9625 (6.2340)  loss_classifier: 5.5315 (5.7733)  loss_box_reg: 0.2334 (0.2370)  loss_objectness: 0.1262 (0.1496)  loss_rpn_box_reg: 0.0734 (0.0741)  time: 0.6344  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [48]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 5.8888 (6.2327)  loss_classifier: 5.4653 (5.7709)  loss_box_reg: 0.2331 (0.2371)  loss_objectness: 0.1435 (0.1504)  loss_rpn_box_reg: 0.0817 (0.0743)  time: 0.6331  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [48]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 5.9839 (6.2241)  loss_classifier: 5.4985 (5.7639)  loss_box_reg: 0.2280 (0.2358)  loss_objectness: 0.1537 (0.1502)  loss_rpn_box_reg: 0.0758 (0.0741)  time: 0.6312  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [48]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 5.9839 (6.2226)  loss_classifier: 5.5142 (5.7605)  loss_box_reg: 0.2356 (0.2376)  loss_objectness: 0.1670 (0.1506)  loss_rpn_box_reg: 0.0598 (0.0739)  time: 0.6226  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [48]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.1875 (6.2263)  loss_classifier: 5.7860 (5.7651)  loss_box_reg: 0.2542 (0.2371)  loss_objectness: 0.1495 (0.1505)  loss_rpn_box_reg: 0.0567 (0.0736)  time: 0.6193  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [48]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1681 (6.2249)  loss_classifier: 5.8275 (5.7641)  loss_box_reg: 0.2131 (0.2364)  loss_objectness: 0.1484 (0.1509)  loss_rpn_box_reg: 0.0630 (0.0736)  time: 0.6305  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [48]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.2527 (6.2291)  loss_classifier: 5.7649 (5.7670)  loss_box_reg: 0.2345 (0.2368)  loss_objectness: 0.1604 (0.1513)  loss_rpn_box_reg: 0.0804 (0.0740)  time: 0.6267  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [48]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.3139 (6.2370)  loss_classifier: 5.7696 (5.7726)  loss_box_reg: 0.2544 (0.2379)  loss_objectness: 0.1665 (0.1520)  loss_rpn_box_reg: 0.0891 (0.0746)  time: 0.6090  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [48]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.1847 (6.2324)  loss_classifier: 5.7300 (5.7681)  loss_box_reg: 0.2544 (0.2377)  loss_objectness: 0.1687 (0.1521)  loss_rpn_box_reg: 0.0791 (0.0744)  time: 0.6084  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [48]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.0951 (6.2284)  loss_classifier: 5.5554 (5.7629)  loss_box_reg: 0.2379 (0.2382)  loss_objectness: 0.1676 (0.1525)  loss_rpn_box_reg: 0.0660 (0.0748)  time: 0.6207  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [48]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.0251 (6.2264)  loss_classifier: 5.5554 (5.7613)  loss_box_reg: 0.2337 (0.2376)  loss_objectness: 0.1548 (0.1526)  loss_rpn_box_reg: 0.0742 (0.0750)  time: 0.6247  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [48]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.2077 (6.2273)  loss_classifier: 5.5864 (5.7620)  loss_box_reg: 0.2210 (0.2374)  loss_objectness: 0.1649 (0.1529)  loss_rpn_box_reg: 0.0736 (0.0751)  time: 0.6183  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [48]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.2077 (6.2231)  loss_classifier: 5.6772 (5.7572)  loss_box_reg: 0.2349 (0.2378)  loss_objectness: 0.1686 (0.1531)  loss_rpn_box_reg: 0.0694 (0.0749)  time: 0.6121  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [48]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2415 (6.2248)  loss_classifier: 5.7658 (5.7591)  loss_box_reg: 0.2407 (0.2376)  loss_objectness: 0.1501 (0.1529)  loss_rpn_box_reg: 0.0694 (0.0752)  time: 0.6072  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [48]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2415 (6.2233)  loss_classifier: 5.7658 (5.7563)  loss_box_reg: 0.2428 (0.2383)  loss_objectness: 0.1465 (0.1532)  loss_rpn_box_reg: 0.0799 (0.0755)  time: 0.6151  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [48]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1670 (6.2267)  loss_classifier: 5.6386 (5.7594)  loss_box_reg: 0.2375 (0.2383)  loss_objectness: 0.1564 (0.1534)  loss_rpn_box_reg: 0.0789 (0.0756)  time: 0.6192  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [48]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2499 (6.2278)  loss_classifier: 5.7124 (5.7606)  loss_box_reg: 0.2279 (0.2385)  loss_objectness: 0.1641 (0.1535)  loss_rpn_box_reg: 0.0706 (0.0753)  time: 0.6149  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [48]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1819 (6.2269)  loss_classifier: 5.6072 (5.7598)  loss_box_reg: 0.2350 (0.2386)  loss_objectness: 0.1514 (0.1532)  loss_rpn_box_reg: 0.0688 (0.0754)  time: 0.6144  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [48]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1149 (6.2271)  loss_classifier: 5.6072 (5.7598)  loss_box_reg: 0.2392 (0.2388)  loss_objectness: 0.1386 (0.1530)  loss_rpn_box_reg: 0.0685 (0.0755)  time: 0.6171  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [48]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.0268 (6.2231)  loss_classifier: 5.6014 (5.7555)  loss_box_reg: 0.2299 (0.2388)  loss_objectness: 0.1386 (0.1530)  loss_rpn_box_reg: 0.0738 (0.0758)  time: 0.6270  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [48]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0268 (6.2211)  loss_classifier: 5.5651 (5.7523)  loss_box_reg: 0.2190 (0.2394)  loss_objectness: 0.1678 (0.1533)  loss_rpn_box_reg: 0.0879 (0.0761)  time: 0.6269  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [48]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1661 (6.2201)  loss_classifier: 5.6701 (5.7520)  loss_box_reg: 0.2281 (0.2391)  loss_objectness: 0.1595 (0.1533)  loss_rpn_box_reg: 0.0662 (0.0757)  time: 0.6319  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [48]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1096 (6.2158)  loss_classifier: 5.6582 (5.7476)  loss_box_reg: 0.2281 (0.2389)  loss_objectness: 0.1397 (0.1534)  loss_rpn_box_reg: 0.0662 (0.0759)  time: 0.6359  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [48]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0486 (6.2163)  loss_classifier: 5.5818 (5.7478)  loss_box_reg: 0.2569 (0.2393)  loss_objectness: 0.1472 (0.1531)  loss_rpn_box_reg: 0.0738 (0.0760)  time: 0.6168  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [48] Total time: 0:05:11 (0.6237 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:49  model_time: 0.6902 (0.6902)  evaluator_time: 0.0340 (0.0340)  time: 0.8762  data: 0.1430  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4401 (0.4505)  evaluator_time: 0.0340 (0.0367)  time: 0.6354  data: 0.1538  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4661 (0.4518)  evaluator_time: 0.0350 (0.0370)  time: 0.6501  data: 0.1479  max mem: 10734\n",
      "Test: Total time: 0:01:19 (0.6388 s / it)\n",
      "Averaged stats: model_time: 0.4661 (0.4518)  evaluator_time: 0.0350 (0.0370)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [48]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.2008 (6.2008)  loss_classifier: 5.6486 (5.6486)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1268 (0.1268)  loss_rpn_box_reg: 0.1310 (0.1310)  time: 0.6521  data: 0.1430  max mem: 10734\n",
      "Testing Epoch: [48]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0001 (6.1339)  loss_classifier: 5.4291 (5.6231)  loss_box_reg: 0.2609 (0.2901)  loss_objectness: 0.1310 (0.1315)  loss_rpn_box_reg: 0.0716 (0.0892)  time: 0.5843  data: 0.1445  max mem: 10734\n",
      "Testing Epoch: [48]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1749 (6.1662)  loss_classifier: 5.6946 (5.6599)  loss_box_reg: 0.2500 (0.2854)  loss_objectness: 0.1178 (0.1316)  loss_rpn_box_reg: 0.0745 (0.0893)  time: 0.5978  data: 0.1446  max mem: 10734\n",
      "Testing Epoch: [48] Total time: 0:01:14 (0.5964 s / it)\n",
      "Training Epoch: [49]  [  0/500]  eta: 0:06:52  lr: 0.000000  loss: 6.3250 (6.3250)  loss_classifier: 5.7429 (5.7429)  loss_box_reg: 0.3033 (0.3033)  loss_objectness: 0.1573 (0.1573)  loss_rpn_box_reg: 0.1214 (0.1214)  time: 0.8252  data: 0.1420  max mem: 10734\n",
      "Training Epoch: [49]  [ 10/500]  eta: 0:05:17  lr: 0.000000  loss: 6.2199 (6.1171)  loss_classifier: 5.6777 (5.6111)  loss_box_reg: 0.2462 (0.2618)  loss_objectness: 0.1485 (0.1623)  loss_rpn_box_reg: 0.0782 (0.0820)  time: 0.6471  data: 0.1383  max mem: 10734\n",
      "Training Epoch: [49]  [ 20/500]  eta: 0:05:02  lr: 0.000000  loss: 5.9947 (6.0241)  loss_classifier: 5.5009 (5.5107)  loss_box_reg: 0.2462 (0.2698)  loss_objectness: 0.1468 (0.1553)  loss_rpn_box_reg: 0.0873 (0.0883)  time: 0.6201  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [49]  [ 30/500]  eta: 0:04:55  lr: 0.000000  loss: 6.0311 (6.1173)  loss_classifier: 5.5563 (5.6129)  loss_box_reg: 0.2335 (0.2577)  loss_objectness: 0.1513 (0.1617)  loss_rpn_box_reg: 0.0792 (0.0850)  time: 0.6185  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [49]  [ 40/500]  eta: 0:04:47  lr: 0.000000  loss: 6.1486 (6.1115)  loss_classifier: 5.6153 (5.6131)  loss_box_reg: 0.2153 (0.2540)  loss_objectness: 0.1740 (0.1628)  loss_rpn_box_reg: 0.0707 (0.0815)  time: 0.6217  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [49]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 6.1486 (6.1402)  loss_classifier: 5.6776 (5.6507)  loss_box_reg: 0.2281 (0.2492)  loss_objectness: 0.1585 (0.1610)  loss_rpn_box_reg: 0.0624 (0.0793)  time: 0.6287  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [49]  [ 60/500]  eta: 0:04:37  lr: 0.000000  loss: 6.1422 (6.1217)  loss_classifier: 5.6723 (5.6407)  loss_box_reg: 0.2063 (0.2433)  loss_objectness: 0.1472 (0.1591)  loss_rpn_box_reg: 0.0609 (0.0786)  time: 0.6371  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [49]  [ 70/500]  eta: 0:04:30  lr: 0.000000  loss: 6.0866 (6.1412)  loss_classifier: 5.6646 (5.6623)  loss_box_reg: 0.2063 (0.2424)  loss_objectness: 0.1436 (0.1589)  loss_rpn_box_reg: 0.0500 (0.0776)  time: 0.6298  data: 0.1310  max mem: 10734\n",
      "Training Epoch: [49]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 6.2252 (6.1382)  loss_classifier: 5.7546 (5.6564)  loss_box_reg: 0.2376 (0.2450)  loss_objectness: 0.1414 (0.1582)  loss_rpn_box_reg: 0.0631 (0.0786)  time: 0.6236  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [49]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 6.0413 (6.1536)  loss_classifier: 5.5687 (5.6766)  loss_box_reg: 0.2284 (0.2416)  loss_objectness: 0.1416 (0.1581)  loss_rpn_box_reg: 0.0706 (0.0773)  time: 0.6197  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [49]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 6.0534 (6.1483)  loss_classifier: 5.5271 (5.6700)  loss_box_reg: 0.2237 (0.2422)  loss_objectness: 0.1474 (0.1580)  loss_rpn_box_reg: 0.0699 (0.0782)  time: 0.6221  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [49]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.0345 (6.1443)  loss_classifier: 5.4828 (5.6685)  loss_box_reg: 0.2396 (0.2416)  loss_objectness: 0.1449 (0.1565)  loss_rpn_box_reg: 0.0692 (0.0777)  time: 0.6273  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [49]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 5.9901 (6.1387)  loss_classifier: 5.4541 (5.6600)  loss_box_reg: 0.2664 (0.2445)  loss_objectness: 0.1479 (0.1563)  loss_rpn_box_reg: 0.0727 (0.0778)  time: 0.6243  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [49]  [130/500]  eta: 0:03:53  lr: 0.000000  loss: 5.9995 (6.1284)  loss_classifier: 5.5089 (5.6515)  loss_box_reg: 0.2456 (0.2428)  loss_objectness: 0.1470 (0.1554)  loss_rpn_box_reg: 0.0869 (0.0787)  time: 0.6460  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [49]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 5.9995 (6.1216)  loss_classifier: 5.5105 (5.6433)  loss_box_reg: 0.2229 (0.2440)  loss_objectness: 0.1462 (0.1556)  loss_rpn_box_reg: 0.0729 (0.0788)  time: 0.6511  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [49]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 6.0911 (6.1287)  loss_classifier: 5.6733 (5.6507)  loss_box_reg: 0.2229 (0.2449)  loss_objectness: 0.1485 (0.1549)  loss_rpn_box_reg: 0.0677 (0.0782)  time: 0.6360  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [49]  [160/500]  eta: 0:03:34  lr: 0.000000  loss: 6.0925 (6.1305)  loss_classifier: 5.7119 (5.6536)  loss_box_reg: 0.2242 (0.2428)  loss_objectness: 0.1528 (0.1554)  loss_rpn_box_reg: 0.0577 (0.0788)  time: 0.6321  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [49]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.0159 (6.1292)  loss_classifier: 5.6532 (5.6539)  loss_box_reg: 0.2242 (0.2428)  loss_objectness: 0.1554 (0.1548)  loss_rpn_box_reg: 0.0557 (0.0777)  time: 0.6244  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [49]  [180/500]  eta: 0:03:21  lr: 0.000000  loss: 6.2892 (6.1427)  loss_classifier: 5.8262 (5.6670)  loss_box_reg: 0.2437 (0.2435)  loss_objectness: 0.1350 (0.1547)  loss_rpn_box_reg: 0.0557 (0.0775)  time: 0.6240  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [49]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.3464 (6.1525)  loss_classifier: 5.8378 (5.6770)  loss_box_reg: 0.2536 (0.2431)  loss_objectness: 0.1350 (0.1547)  loss_rpn_box_reg: 0.0703 (0.0776)  time: 0.6160  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [49]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.3163 (6.1657)  loss_classifier: 5.8084 (5.6921)  loss_box_reg: 0.2402 (0.2419)  loss_objectness: 0.1322 (0.1541)  loss_rpn_box_reg: 0.0703 (0.0776)  time: 0.6095  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [49]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.2882 (6.1753)  loss_classifier: 5.8258 (5.7034)  loss_box_reg: 0.2024 (0.2409)  loss_objectness: 0.1315 (0.1537)  loss_rpn_box_reg: 0.0680 (0.0773)  time: 0.6212  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [49]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.2770 (6.1780)  loss_classifier: 5.8258 (5.7079)  loss_box_reg: 0.1909 (0.2386)  loss_objectness: 0.1509 (0.1544)  loss_rpn_box_reg: 0.0672 (0.0772)  time: 0.6189  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [49]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.2199 (6.1808)  loss_classifier: 5.7814 (5.7120)  loss_box_reg: 0.2357 (0.2392)  loss_objectness: 0.1464 (0.1530)  loss_rpn_box_reg: 0.0564 (0.0766)  time: 0.6188  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [49]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.1465 (6.1784)  loss_classifier: 5.6650 (5.7101)  loss_box_reg: 0.2563 (0.2394)  loss_objectness: 0.1236 (0.1524)  loss_rpn_box_reg: 0.0675 (0.0765)  time: 0.6255  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [49]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.1465 (6.1907)  loss_classifier: 5.7181 (5.7221)  loss_box_reg: 0.2563 (0.2396)  loss_objectness: 0.1521 (0.1525)  loss_rpn_box_reg: 0.0728 (0.0765)  time: 0.6194  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [49]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.1603 (6.1853)  loss_classifier: 5.7512 (5.7194)  loss_box_reg: 0.2152 (0.2378)  loss_objectness: 0.1474 (0.1524)  loss_rpn_box_reg: 0.0601 (0.0757)  time: 0.6231  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [49]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.1502 (6.1867)  loss_classifier: 5.7474 (5.7217)  loss_box_reg: 0.2012 (0.2375)  loss_objectness: 0.1389 (0.1521)  loss_rpn_box_reg: 0.0577 (0.0754)  time: 0.6344  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [49]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.2558 (6.1944)  loss_classifier: 5.7169 (5.7300)  loss_box_reg: 0.2036 (0.2370)  loss_objectness: 0.1389 (0.1521)  loss_rpn_box_reg: 0.0725 (0.0754)  time: 0.6344  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [49]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.1554 (6.1858)  loss_classifier: 5.6524 (5.7205)  loss_box_reg: 0.2564 (0.2377)  loss_objectness: 0.1612 (0.1525)  loss_rpn_box_reg: 0.0721 (0.0751)  time: 0.6188  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [49]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.2392 (6.1953)  loss_classifier: 5.7738 (5.7303)  loss_box_reg: 0.2643 (0.2378)  loss_objectness: 0.1393 (0.1523)  loss_rpn_box_reg: 0.0630 (0.0749)  time: 0.6190  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [49]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.1883 (6.1935)  loss_classifier: 5.5995 (5.7281)  loss_box_reg: 0.2458 (0.2384)  loss_objectness: 0.1342 (0.1522)  loss_rpn_box_reg: 0.0630 (0.0748)  time: 0.6220  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [49]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1883 (6.1933)  loss_classifier: 5.5995 (5.7281)  loss_box_reg: 0.2427 (0.2384)  loss_objectness: 0.1429 (0.1519)  loss_rpn_box_reg: 0.0617 (0.0749)  time: 0.6226  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [49]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.2727 (6.2006)  loss_classifier: 5.7927 (5.7348)  loss_box_reg: 0.2539 (0.2389)  loss_objectness: 0.1429 (0.1522)  loss_rpn_box_reg: 0.0625 (0.0747)  time: 0.6126  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [49]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.3700 (6.2028)  loss_classifier: 5.8893 (5.7369)  loss_box_reg: 0.2469 (0.2392)  loss_objectness: 0.1482 (0.1521)  loss_rpn_box_reg: 0.0649 (0.0745)  time: 0.6073  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [49]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.2126 (6.2011)  loss_classifier: 5.7636 (5.7349)  loss_box_reg: 0.2329 (0.2387)  loss_objectness: 0.1498 (0.1527)  loss_rpn_box_reg: 0.0755 (0.0748)  time: 0.6186  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [49]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.0982 (6.1968)  loss_classifier: 5.5499 (5.7303)  loss_box_reg: 0.2161 (0.2383)  loss_objectness: 0.1731 (0.1530)  loss_rpn_box_reg: 0.0795 (0.0753)  time: 0.6178  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [49]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1265 (6.1996)  loss_classifier: 5.5909 (5.7322)  loss_box_reg: 0.2178 (0.2388)  loss_objectness: 0.1542 (0.1530)  loss_rpn_box_reg: 0.0778 (0.0756)  time: 0.6257  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [49]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.1734 (6.1942)  loss_classifier: 5.6941 (5.7270)  loss_box_reg: 0.2289 (0.2387)  loss_objectness: 0.1372 (0.1528)  loss_rpn_box_reg: 0.0756 (0.0757)  time: 0.6302  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [49]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1734 (6.2016)  loss_classifier: 5.7732 (5.7343)  loss_box_reg: 0.2159 (0.2389)  loss_objectness: 0.1667 (0.1532)  loss_rpn_box_reg: 0.0524 (0.0752)  time: 0.6199  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [49]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.4454 (6.2017)  loss_classifier: 5.9650 (5.7344)  loss_box_reg: 0.2224 (0.2387)  loss_objectness: 0.1750 (0.1532)  loss_rpn_box_reg: 0.0510 (0.0753)  time: 0.6153  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [49]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1727 (6.2041)  loss_classifier: 5.6631 (5.7365)  loss_box_reg: 0.2284 (0.2388)  loss_objectness: 0.1590 (0.1534)  loss_rpn_box_reg: 0.0623 (0.0753)  time: 0.6260  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [49]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1727 (6.2036)  loss_classifier: 5.7050 (5.7364)  loss_box_reg: 0.2487 (0.2387)  loss_objectness: 0.1490 (0.1532)  loss_rpn_box_reg: 0.0700 (0.0754)  time: 0.6180  data: 0.1375  max mem: 10734\n",
      "Training Epoch: [49]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1822 (6.2061)  loss_classifier: 5.7262 (5.7399)  loss_box_reg: 0.2127 (0.2379)  loss_objectness: 0.1485 (0.1532)  loss_rpn_box_reg: 0.0668 (0.0751)  time: 0.6164  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [49]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.3351 (6.2134)  loss_classifier: 5.8589 (5.7465)  loss_box_reg: 0.2156 (0.2384)  loss_objectness: 0.1539 (0.1533)  loss_rpn_box_reg: 0.0651 (0.0753)  time: 0.6199  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [49]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.2927 (6.2145)  loss_classifier: 5.8226 (5.7472)  loss_box_reg: 0.2499 (0.2387)  loss_objectness: 0.1501 (0.1532)  loss_rpn_box_reg: 0.0666 (0.0754)  time: 0.6128  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [49]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.0897 (6.2149)  loss_classifier: 5.6287 (5.7480)  loss_box_reg: 0.2366 (0.2382)  loss_objectness: 0.1501 (0.1535)  loss_rpn_box_reg: 0.0767 (0.0753)  time: 0.6345  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [49]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0857 (6.2159)  loss_classifier: 5.6287 (5.7477)  loss_box_reg: 0.2343 (0.2387)  loss_objectness: 0.1629 (0.1539)  loss_rpn_box_reg: 0.0810 (0.0756)  time: 0.6463  data: 0.1381  max mem: 10734\n",
      "Training Epoch: [49]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0828 (6.2151)  loss_classifier: 5.5092 (5.7463)  loss_box_reg: 0.2552 (0.2395)  loss_objectness: 0.1582 (0.1538)  loss_rpn_box_reg: 0.0739 (0.0756)  time: 0.6364  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [49]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0152 (6.2129)  loss_classifier: 5.4706 (5.7442)  loss_box_reg: 0.2444 (0.2395)  loss_objectness: 0.1442 (0.1537)  loss_rpn_box_reg: 0.0721 (0.0755)  time: 0.6203  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [49]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2464 (6.2130)  loss_classifier: 5.8470 (5.7445)  loss_box_reg: 0.2402 (0.2391)  loss_objectness: 0.1361 (0.1534)  loss_rpn_box_reg: 0.0754 (0.0760)  time: 0.6192  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [49] Total time: 0:05:12 (0.6248 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:55  model_time: 0.7342 (0.7342)  evaluator_time: 0.0350 (0.0350)  time: 0.9212  data: 0.1420  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4381 (0.4535)  evaluator_time: 0.0330 (0.0351)  time: 0.6311  data: 0.1483  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4691 (0.4553)  evaluator_time: 0.0360 (0.0358)  time: 0.6582  data: 0.1490  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6441 s / it)\n",
      "Averaged stats: model_time: 0.4691 (0.4553)  evaluator_time: 0.0360 (0.0358)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [49]  [  0/125]  eta: 0:01:22  lr: 0.000000  loss: 6.2038 (6.2038)  loss_classifier: 5.6512 (5.6512)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1236 (0.1236)  loss_rpn_box_reg: 0.1345 (0.1345)  time: 0.6631  data: 0.1420  max mem: 10734\n",
      "Testing Epoch: [49]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9949 (6.1357)  loss_classifier: 5.4248 (5.6250)  loss_box_reg: 0.2609 (0.2894)  loss_objectness: 0.1330 (0.1320)  loss_rpn_box_reg: 0.0711 (0.0892)  time: 0.5861  data: 0.1460  max mem: 10734\n",
      "Testing Epoch: [49]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1625 (6.1678)  loss_classifier: 5.6960 (5.6614)  loss_box_reg: 0.2500 (0.2849)  loss_objectness: 0.1204 (0.1322)  loss_rpn_box_reg: 0.0745 (0.0894)  time: 0.6010  data: 0.1472  max mem: 10734\n",
      "Testing Epoch: [49] Total time: 0:01:14 (0.5977 s / it)\n",
      "Training Epoch: [50]  [  0/500]  eta: 0:06:44  lr: 0.000000  loss: 6.7297 (6.7297)  loss_classifier: 6.0106 (6.0106)  loss_box_reg: 0.3647 (0.3647)  loss_objectness: 0.2552 (0.2552)  loss_rpn_box_reg: 0.0992 (0.0992)  time: 0.8092  data: 0.1510  max mem: 10734\n",
      "Training Epoch: [50]  [ 10/500]  eta: 0:05:16  lr: 0.000000  loss: 6.7297 (6.4092)  loss_classifier: 6.1829 (5.8967)  loss_box_reg: 0.2622 (0.2555)  loss_objectness: 0.1627 (0.1597)  loss_rpn_box_reg: 0.0992 (0.0972)  time: 0.6450  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [50]  [ 20/500]  eta: 0:05:06  lr: 0.000000  loss: 6.2187 (6.2358)  loss_classifier: 5.5944 (5.7219)  loss_box_reg: 0.2401 (0.2601)  loss_objectness: 0.1627 (0.1608)  loss_rpn_box_reg: 0.0831 (0.0931)  time: 0.6300  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [50]  [ 30/500]  eta: 0:04:57  lr: 0.000000  loss: 6.1350 (6.2153)  loss_classifier: 5.6683 (5.7085)  loss_box_reg: 0.2404 (0.2586)  loss_objectness: 0.1619 (0.1580)  loss_rpn_box_reg: 0.0831 (0.0903)  time: 0.6270  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [50]  [ 40/500]  eta: 0:04:51  lr: 0.000000  loss: 6.1059 (6.1749)  loss_classifier: 5.6960 (5.6860)  loss_box_reg: 0.2193 (0.2497)  loss_objectness: 0.1423 (0.1557)  loss_rpn_box_reg: 0.0686 (0.0835)  time: 0.6279  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [50]  [ 50/500]  eta: 0:04:44  lr: 0.000000  loss: 6.0721 (6.2003)  loss_classifier: 5.6958 (5.7172)  loss_box_reg: 0.2323 (0.2460)  loss_objectness: 0.1465 (0.1549)  loss_rpn_box_reg: 0.0645 (0.0822)  time: 0.6288  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [50]  [ 60/500]  eta: 0:04:38  lr: 0.000000  loss: 6.2245 (6.2315)  loss_classifier: 5.7471 (5.7544)  loss_box_reg: 0.2353 (0.2435)  loss_objectness: 0.1443 (0.1536)  loss_rpn_box_reg: 0.0645 (0.0799)  time: 0.6301  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [50]  [ 70/500]  eta: 0:04:31  lr: 0.000000  loss: 6.3013 (6.2440)  loss_classifier: 5.8803 (5.7718)  loss_box_reg: 0.2353 (0.2415)  loss_objectness: 0.1393 (0.1524)  loss_rpn_box_reg: 0.0576 (0.0783)  time: 0.6334  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [50]  [ 80/500]  eta: 0:04:24  lr: 0.000000  loss: 6.2802 (6.2231)  loss_classifier: 5.8130 (5.7563)  loss_box_reg: 0.2316 (0.2412)  loss_objectness: 0.1323 (0.1482)  loss_rpn_box_reg: 0.0558 (0.0774)  time: 0.6229  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [50]  [ 90/500]  eta: 0:04:18  lr: 0.000000  loss: 6.2465 (6.2432)  loss_classifier: 5.8130 (5.7800)  loss_box_reg: 0.2240 (0.2395)  loss_objectness: 0.1296 (0.1479)  loss_rpn_box_reg: 0.0525 (0.0757)  time: 0.6303  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [50]  [100/500]  eta: 0:04:12  lr: 0.000000  loss: 6.2354 (6.2359)  loss_classifier: 5.7410 (5.7742)  loss_box_reg: 0.2191 (0.2400)  loss_objectness: 0.1349 (0.1472)  loss_rpn_box_reg: 0.0486 (0.0744)  time: 0.6386  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [50]  [110/500]  eta: 0:04:06  lr: 0.000000  loss: 5.9943 (6.2227)  loss_classifier: 5.5059 (5.7613)  loss_box_reg: 0.2425 (0.2403)  loss_objectness: 0.1349 (0.1470)  loss_rpn_box_reg: 0.0532 (0.0740)  time: 0.6281  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [50]  [120/500]  eta: 0:03:59  lr: 0.000000  loss: 6.1584 (6.2355)  loss_classifier: 5.6518 (5.7760)  loss_box_reg: 0.2104 (0.2395)  loss_objectness: 0.1432 (0.1466)  loss_rpn_box_reg: 0.0626 (0.0735)  time: 0.6234  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [50]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 6.2154 (6.2370)  loss_classifier: 5.7996 (5.7760)  loss_box_reg: 0.1798 (0.2390)  loss_objectness: 0.1564 (0.1483)  loss_rpn_box_reg: 0.0520 (0.0736)  time: 0.6204  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [50]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.2043 (6.2321)  loss_classifier: 5.7367 (5.7678)  loss_box_reg: 0.2237 (0.2411)  loss_objectness: 0.1577 (0.1486)  loss_rpn_box_reg: 0.0704 (0.0745)  time: 0.6316  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [50]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 6.1782 (6.2217)  loss_classifier: 5.6222 (5.7568)  loss_box_reg: 0.2237 (0.2418)  loss_objectness: 0.1499 (0.1482)  loss_rpn_box_reg: 0.0816 (0.0749)  time: 0.6343  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [50]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.1082 (6.2160)  loss_classifier: 5.5348 (5.7515)  loss_box_reg: 0.2361 (0.2418)  loss_objectness: 0.1533 (0.1489)  loss_rpn_box_reg: 0.0670 (0.0738)  time: 0.6144  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [50]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.2423 (6.2305)  loss_classifier: 5.8365 (5.7682)  loss_box_reg: 0.2327 (0.2404)  loss_objectness: 0.1545 (0.1489)  loss_rpn_box_reg: 0.0577 (0.0730)  time: 0.6206  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [50]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.3535 (6.2331)  loss_classifier: 5.9135 (5.7718)  loss_box_reg: 0.1951 (0.2395)  loss_objectness: 0.1395 (0.1485)  loss_rpn_box_reg: 0.0657 (0.0733)  time: 0.6209  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [50]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.0675 (6.2196)  loss_classifier: 5.5766 (5.7562)  loss_box_reg: 0.2335 (0.2406)  loss_objectness: 0.1307 (0.1484)  loss_rpn_box_reg: 0.0751 (0.0743)  time: 0.6082  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [50]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.0189 (6.2233)  loss_classifier: 5.5692 (5.7584)  loss_box_reg: 0.2416 (0.2414)  loss_objectness: 0.1565 (0.1492)  loss_rpn_box_reg: 0.0840 (0.0743)  time: 0.6124  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [50]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.0535 (6.2238)  loss_classifier: 5.5796 (5.7584)  loss_box_reg: 0.2212 (0.2415)  loss_objectness: 0.1565 (0.1493)  loss_rpn_box_reg: 0.0805 (0.0746)  time: 0.6217  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [50]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.0155 (6.2186)  loss_classifier: 5.5016 (5.7532)  loss_box_reg: 0.2253 (0.2418)  loss_objectness: 0.1407 (0.1488)  loss_rpn_box_reg: 0.0747 (0.0748)  time: 0.6300  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [50]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.0890 (6.2133)  loss_classifier: 5.4868 (5.7455)  loss_box_reg: 0.2610 (0.2426)  loss_objectness: 0.1417 (0.1498)  loss_rpn_box_reg: 0.0728 (0.0753)  time: 0.6220  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [50]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.1974 (6.2159)  loss_classifier: 5.7642 (5.7476)  loss_box_reg: 0.2665 (0.2435)  loss_objectness: 0.1341 (0.1490)  loss_rpn_box_reg: 0.0900 (0.0758)  time: 0.6211  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [50]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.2265 (6.2119)  loss_classifier: 5.7489 (5.7435)  loss_box_reg: 0.2231 (0.2426)  loss_objectness: 0.1433 (0.1495)  loss_rpn_box_reg: 0.0900 (0.0764)  time: 0.6292  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [50]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.2265 (6.2168)  loss_classifier: 5.7489 (5.7507)  loss_box_reg: 0.2022 (0.2409)  loss_objectness: 0.1514 (0.1495)  loss_rpn_box_reg: 0.0666 (0.0756)  time: 0.6245  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [50]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.3184 (6.2198)  loss_classifier: 5.8067 (5.7519)  loss_box_reg: 0.2022 (0.2422)  loss_objectness: 0.1563 (0.1501)  loss_rpn_box_reg: 0.0618 (0.0756)  time: 0.6169  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [50]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 5.9942 (6.2095)  loss_classifier: 5.4767 (5.7416)  loss_box_reg: 0.2394 (0.2419)  loss_objectness: 0.1623 (0.1500)  loss_rpn_box_reg: 0.0737 (0.0759)  time: 0.6160  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [50]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 5.8432 (6.2066)  loss_classifier: 5.4293 (5.7378)  loss_box_reg: 0.2354 (0.2426)  loss_objectness: 0.1557 (0.1502)  loss_rpn_box_reg: 0.0760 (0.0761)  time: 0.6150  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [50]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.3737 (6.2176)  loss_classifier: 5.9306 (5.7492)  loss_box_reg: 0.2211 (0.2417)  loss_objectness: 0.1557 (0.1504)  loss_rpn_box_reg: 0.0762 (0.0763)  time: 0.6275  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [50]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.2378 (6.2182)  loss_classifier: 5.7393 (5.7503)  loss_box_reg: 0.2111 (0.2413)  loss_objectness: 0.1519 (0.1502)  loss_rpn_box_reg: 0.0858 (0.0764)  time: 0.6265  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [50]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1365 (6.2182)  loss_classifier: 5.6181 (5.7498)  loss_box_reg: 0.2111 (0.2416)  loss_objectness: 0.1519 (0.1505)  loss_rpn_box_reg: 0.0718 (0.0763)  time: 0.6124  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [50]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.1365 (6.2187)  loss_classifier: 5.7167 (5.7498)  loss_box_reg: 0.2650 (0.2418)  loss_objectness: 0.1563 (0.1506)  loss_rpn_box_reg: 0.0652 (0.0764)  time: 0.6179  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [50]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.3354 (6.2229)  loss_classifier: 5.8323 (5.7526)  loss_box_reg: 0.2662 (0.2430)  loss_objectness: 0.1590 (0.1510)  loss_rpn_box_reg: 0.0662 (0.0762)  time: 0.6273  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [50]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.3354 (6.2260)  loss_classifier: 5.8799 (5.7557)  loss_box_reg: 0.2178 (0.2422)  loss_objectness: 0.1629 (0.1517)  loss_rpn_box_reg: 0.0662 (0.0764)  time: 0.6383  data: 0.1378  max mem: 10734\n",
      "Training Epoch: [50]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.3131 (6.2298)  loss_classifier: 5.8511 (5.7593)  loss_box_reg: 0.2178 (0.2422)  loss_objectness: 0.1583 (0.1517)  loss_rpn_box_reg: 0.0769 (0.0767)  time: 0.6365  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [50]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1651 (6.2218)  loss_classifier: 5.6202 (5.7510)  loss_box_reg: 0.2253 (0.2423)  loss_objectness: 0.1501 (0.1520)  loss_rpn_box_reg: 0.0730 (0.0765)  time: 0.6186  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [50]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.1039 (6.2281)  loss_classifier: 5.6202 (5.7586)  loss_box_reg: 0.2045 (0.2413)  loss_objectness: 0.1454 (0.1517)  loss_rpn_box_reg: 0.0710 (0.0765)  time: 0.6130  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [50]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1926 (6.2285)  loss_classifier: 5.7525 (5.7592)  loss_box_reg: 0.2056 (0.2409)  loss_objectness: 0.1453 (0.1517)  loss_rpn_box_reg: 0.0747 (0.0767)  time: 0.6179  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [50]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1795 (6.2312)  loss_classifier: 5.6991 (5.7613)  loss_box_reg: 0.2258 (0.2410)  loss_objectness: 0.1491 (0.1519)  loss_rpn_box_reg: 0.0745 (0.0770)  time: 0.6147  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [50]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1795 (6.2269)  loss_classifier: 5.7236 (5.7578)  loss_box_reg: 0.2339 (0.2407)  loss_objectness: 0.1401 (0.1516)  loss_rpn_box_reg: 0.0726 (0.0769)  time: 0.6200  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [50]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1335 (6.2259)  loss_classifier: 5.5894 (5.7552)  loss_box_reg: 0.2339 (0.2415)  loss_objectness: 0.1448 (0.1523)  loss_rpn_box_reg: 0.0680 (0.0770)  time: 0.6251  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [50]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1335 (6.2199)  loss_classifier: 5.5942 (5.7495)  loss_box_reg: 0.2354 (0.2416)  loss_objectness: 0.1501 (0.1521)  loss_rpn_box_reg: 0.0649 (0.0767)  time: 0.6187  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [50]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1530 (6.2204)  loss_classifier: 5.7082 (5.7500)  loss_box_reg: 0.2377 (0.2417)  loss_objectness: 0.1577 (0.1523)  loss_rpn_box_reg: 0.0610 (0.0764)  time: 0.6156  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [50]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.2510 (6.2228)  loss_classifier: 5.8836 (5.7525)  loss_box_reg: 0.2269 (0.2416)  loss_objectness: 0.1562 (0.1522)  loss_rpn_box_reg: 0.0645 (0.0764)  time: 0.6138  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [50]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 5.9110 (6.2150)  loss_classifier: 5.5463 (5.7451)  loss_box_reg: 0.2269 (0.2414)  loss_objectness: 0.1424 (0.1520)  loss_rpn_box_reg: 0.0773 (0.0764)  time: 0.6244  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [50]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0295 (6.2230)  loss_classifier: 5.5458 (5.7538)  loss_box_reg: 0.2362 (0.2412)  loss_objectness: 0.1304 (0.1517)  loss_rpn_box_reg: 0.0777 (0.0763)  time: 0.6363  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [50]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1522 (6.2198)  loss_classifier: 5.7119 (5.7515)  loss_box_reg: 0.2259 (0.2408)  loss_objectness: 0.1269 (0.1515)  loss_rpn_box_reg: 0.0673 (0.0760)  time: 0.6382  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [50]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 5.9895 (6.2162)  loss_classifier: 5.4748 (5.7473)  loss_box_reg: 0.2403 (0.2412)  loss_objectness: 0.1560 (0.1517)  loss_rpn_box_reg: 0.0684 (0.0761)  time: 0.6354  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [50]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 5.9895 (6.2134)  loss_classifier: 5.5105 (5.7458)  loss_box_reg: 0.2395 (0.2404)  loss_objectness: 0.1505 (0.1515)  loss_rpn_box_reg: 0.0677 (0.0758)  time: 0.6267  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [50] Total time: 0:05:12 (0.6247 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:53  model_time: 0.6361 (0.6361)  evaluator_time: 0.0340 (0.0340)  time: 0.9062  data: 0.2271  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4461 (0.4493)  evaluator_time: 0.0340 (0.0339)  time: 0.6365  data: 0.1534  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4651 (0.4510)  evaluator_time: 0.0360 (0.0348)  time: 0.6586  data: 0.1545  max mem: 10734\n",
      "Test: Total time: 0:01:19 (0.6399 s / it)\n",
      "Averaged stats: model_time: 0.4651 (0.4510)  evaluator_time: 0.0360 (0.0348)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [50]  [  0/125]  eta: 0:01:19  lr: 0.000000  loss: 6.2057 (6.2057)  loss_classifier: 5.6462 (5.6462)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1338 (0.1338)  loss_rpn_box_reg: 0.1312 (0.1312)  time: 0.6351  data: 0.1370  max mem: 10734\n",
      "Testing Epoch: [50]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9984 (6.1362)  loss_classifier: 5.4293 (5.6264)  loss_box_reg: 0.2609 (0.2894)  loss_objectness: 0.1282 (0.1315)  loss_rpn_box_reg: 0.0714 (0.0890)  time: 0.5824  data: 0.1434  max mem: 10734\n",
      "Testing Epoch: [50]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1661 (6.1676)  loss_classifier: 5.6829 (5.6619)  loss_box_reg: 0.2500 (0.2848)  loss_objectness: 0.1217 (0.1316)  loss_rpn_box_reg: 0.0745 (0.0892)  time: 0.5980  data: 0.1446  max mem: 10734\n",
      "Testing Epoch: [50] Total time: 0:01:14 (0.5937 s / it)\n",
      "Training Epoch: [51]  [  0/500]  eta: 0:06:49  lr: 0.000000  loss: 6.2441 (6.2441)  loss_classifier: 5.8588 (5.8588)  loss_box_reg: 0.2112 (0.2112)  loss_objectness: 0.1131 (0.1131)  loss_rpn_box_reg: 0.0609 (0.0609)  time: 0.8192  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [51]  [ 10/500]  eta: 0:05:19  lr: 0.000000  loss: 6.3425 (6.2585)  loss_classifier: 5.9328 (5.7875)  loss_box_reg: 0.2249 (0.2374)  loss_objectness: 0.1513 (0.1611)  loss_rpn_box_reg: 0.0682 (0.0726)  time: 0.6513  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [51]  [ 20/500]  eta: 0:05:06  lr: 0.000000  loss: 6.2443 (6.1868)  loss_classifier: 5.7439 (5.6980)  loss_box_reg: 0.2339 (0.2545)  loss_objectness: 0.1513 (0.1551)  loss_rpn_box_reg: 0.0757 (0.0791)  time: 0.6290  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [51]  [ 30/500]  eta: 0:04:54  lr: 0.000000  loss: 6.1843 (6.1330)  loss_classifier: 5.6280 (5.6602)  loss_box_reg: 0.2339 (0.2442)  loss_objectness: 0.1393 (0.1539)  loss_rpn_box_reg: 0.0757 (0.0747)  time: 0.6119  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [51]  [ 40/500]  eta: 0:04:49  lr: 0.000000  loss: 6.2454 (6.1658)  loss_classifier: 5.7862 (5.6977)  loss_box_reg: 0.2250 (0.2415)  loss_objectness: 0.1398 (0.1533)  loss_rpn_box_reg: 0.0594 (0.0734)  time: 0.6196  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [51]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 6.2694 (6.2295)  loss_classifier: 5.8271 (5.7610)  loss_box_reg: 0.2303 (0.2402)  loss_objectness: 0.1418 (0.1555)  loss_rpn_box_reg: 0.0594 (0.0728)  time: 0.6287  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [51]  [ 60/500]  eta: 0:04:36  lr: 0.000000  loss: 6.1213 (6.2039)  loss_classifier: 5.7126 (5.7396)  loss_box_reg: 0.2389 (0.2369)  loss_objectness: 0.1572 (0.1539)  loss_rpn_box_reg: 0.0575 (0.0735)  time: 0.6259  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [51]  [ 70/500]  eta: 0:04:28  lr: 0.000000  loss: 6.1213 (6.2358)  loss_classifier: 5.7650 (5.7703)  loss_box_reg: 0.2294 (0.2362)  loss_objectness: 0.1589 (0.1556)  loss_rpn_box_reg: 0.0679 (0.0738)  time: 0.6205  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [51]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 6.2945 (6.2603)  loss_classifier: 5.8825 (5.7995)  loss_box_reg: 0.2294 (0.2333)  loss_objectness: 0.1573 (0.1543)  loss_rpn_box_reg: 0.0690 (0.0732)  time: 0.6274  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [51]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 6.3400 (6.2626)  loss_classifier: 5.8930 (5.8006)  loss_box_reg: 0.2250 (0.2350)  loss_objectness: 0.1323 (0.1539)  loss_rpn_box_reg: 0.0521 (0.0732)  time: 0.6437  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [51]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 6.2072 (6.2608)  loss_classifier: 5.6560 (5.7922)  loss_box_reg: 0.2588 (0.2393)  loss_objectness: 0.1489 (0.1546)  loss_rpn_box_reg: 0.0824 (0.0747)  time: 0.6326  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [51]  [110/500]  eta: 0:04:05  lr: 0.000000  loss: 6.1671 (6.2657)  loss_classifier: 5.6674 (5.7973)  loss_box_reg: 0.2552 (0.2398)  loss_objectness: 0.1520 (0.1544)  loss_rpn_box_reg: 0.0734 (0.0744)  time: 0.6342  data: 0.1377  max mem: 10734\n",
      "Training Epoch: [51]  [120/500]  eta: 0:03:59  lr: 0.000000  loss: 6.1458 (6.2349)  loss_classifier: 5.5476 (5.7642)  loss_box_reg: 0.2202 (0.2411)  loss_objectness: 0.1494 (0.1537)  loss_rpn_box_reg: 0.0740 (0.0759)  time: 0.6408  data: 0.1378  max mem: 10734\n",
      "Training Epoch: [51]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 5.7977 (6.2212)  loss_classifier: 5.3762 (5.7490)  loss_box_reg: 0.2420 (0.2423)  loss_objectness: 0.1552 (0.1546)  loss_rpn_box_reg: 0.0640 (0.0753)  time: 0.6226  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [51]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.0361 (6.2301)  loss_classifier: 5.4761 (5.7581)  loss_box_reg: 0.2574 (0.2426)  loss_objectness: 0.1552 (0.1541)  loss_rpn_box_reg: 0.0628 (0.0752)  time: 0.6208  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [51]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.2207 (6.2425)  loss_classifier: 5.7782 (5.7702)  loss_box_reg: 0.2404 (0.2427)  loss_objectness: 0.1573 (0.1543)  loss_rpn_box_reg: 0.0695 (0.0753)  time: 0.6196  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [51]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.1817 (6.2303)  loss_classifier: 5.7201 (5.7585)  loss_box_reg: 0.2561 (0.2435)  loss_objectness: 0.1535 (0.1535)  loss_rpn_box_reg: 0.0695 (0.0749)  time: 0.6145  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [51]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.2056 (6.2355)  loss_classifier: 5.7201 (5.7605)  loss_box_reg: 0.2505 (0.2442)  loss_objectness: 0.1447 (0.1544)  loss_rpn_box_reg: 0.0753 (0.0763)  time: 0.6226  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [51]  [180/500]  eta: 0:03:21  lr: 0.000000  loss: 6.1585 (6.2285)  loss_classifier: 5.5925 (5.7522)  loss_box_reg: 0.2403 (0.2445)  loss_objectness: 0.1473 (0.1552)  loss_rpn_box_reg: 0.0861 (0.0767)  time: 0.6381  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [51]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.0683 (6.2338)  loss_classifier: 5.5587 (5.7600)  loss_box_reg: 0.2309 (0.2433)  loss_objectness: 0.1350 (0.1540)  loss_rpn_box_reg: 0.0759 (0.0766)  time: 0.6381  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [51]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.1920 (6.2277)  loss_classifier: 5.7147 (5.7545)  loss_box_reg: 0.2135 (0.2426)  loss_objectness: 0.1316 (0.1539)  loss_rpn_box_reg: 0.0627 (0.0767)  time: 0.6316  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [51]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.0327 (6.2099)  loss_classifier: 5.5765 (5.7383)  loss_box_reg: 0.2114 (0.2422)  loss_objectness: 0.1250 (0.1531)  loss_rpn_box_reg: 0.0633 (0.0762)  time: 0.6377  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [51]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.2132 (6.2206)  loss_classifier: 5.7832 (5.7506)  loss_box_reg: 0.2005 (0.2406)  loss_objectness: 0.1250 (0.1534)  loss_rpn_box_reg: 0.0642 (0.0760)  time: 0.6221  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [51]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.3596 (6.2269)  loss_classifier: 5.8703 (5.7568)  loss_box_reg: 0.2210 (0.2403)  loss_objectness: 0.1645 (0.1540)  loss_rpn_box_reg: 0.0696 (0.0757)  time: 0.6172  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [51]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.0959 (6.2179)  loss_classifier: 5.5838 (5.7473)  loss_box_reg: 0.2469 (0.2407)  loss_objectness: 0.1569 (0.1542)  loss_rpn_box_reg: 0.0627 (0.0757)  time: 0.6185  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [51]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.0179 (6.2135)  loss_classifier: 5.4948 (5.7438)  loss_box_reg: 0.2430 (0.2403)  loss_objectness: 0.1464 (0.1537)  loss_rpn_box_reg: 0.0696 (0.0757)  time: 0.6225  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [51]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.3352 (6.2231)  loss_classifier: 5.8441 (5.7534)  loss_box_reg: 0.2284 (0.2403)  loss_objectness: 0.1536 (0.1540)  loss_rpn_box_reg: 0.0689 (0.0755)  time: 0.6388  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [51]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.3352 (6.2162)  loss_classifier: 5.8722 (5.7474)  loss_box_reg: 0.2203 (0.2397)  loss_objectness: 0.1497 (0.1540)  loss_rpn_box_reg: 0.0574 (0.0751)  time: 0.6373  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [51]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.1252 (6.2181)  loss_classifier: 5.6249 (5.7493)  loss_box_reg: 0.2269 (0.2404)  loss_objectness: 0.1450 (0.1534)  loss_rpn_box_reg: 0.0554 (0.0750)  time: 0.6273  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [51]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.3048 (6.2237)  loss_classifier: 5.7968 (5.7564)  loss_box_reg: 0.2347 (0.2390)  loss_objectness: 0.1431 (0.1534)  loss_rpn_box_reg: 0.0639 (0.0748)  time: 0.6297  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [51]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.3048 (6.2291)  loss_classifier: 5.7968 (5.7619)  loss_box_reg: 0.2199 (0.2392)  loss_objectness: 0.1435 (0.1531)  loss_rpn_box_reg: 0.0658 (0.0748)  time: 0.6294  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [51]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.3929 (6.2365)  loss_classifier: 5.7884 (5.7691)  loss_box_reg: 0.2262 (0.2387)  loss_objectness: 0.1575 (0.1533)  loss_rpn_box_reg: 0.0878 (0.0753)  time: 0.6285  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [51]  [320/500]  eta: 0:01:53  lr: 0.000000  loss: 6.4004 (6.2400)  loss_classifier: 5.9705 (5.7737)  loss_box_reg: 0.2202 (0.2380)  loss_objectness: 0.1565 (0.1532)  loss_rpn_box_reg: 0.0678 (0.0751)  time: 0.6252  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [51]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.4026 (6.2385)  loss_classifier: 5.9453 (5.7729)  loss_box_reg: 0.2202 (0.2375)  loss_objectness: 0.1511 (0.1531)  loss_rpn_box_reg: 0.0585 (0.0750)  time: 0.6197  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [51]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.1519 (6.2411)  loss_classifier: 5.7986 (5.7760)  loss_box_reg: 0.2170 (0.2372)  loss_objectness: 0.1430 (0.1529)  loss_rpn_box_reg: 0.0711 (0.0749)  time: 0.6171  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [51]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.1519 (6.2400)  loss_classifier: 5.7248 (5.7750)  loss_box_reg: 0.2140 (0.2375)  loss_objectness: 0.1283 (0.1524)  loss_rpn_box_reg: 0.0784 (0.0751)  time: 0.6161  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [51]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.0254 (6.2323)  loss_classifier: 5.5590 (5.7661)  loss_box_reg: 0.2546 (0.2382)  loss_objectness: 0.1464 (0.1524)  loss_rpn_box_reg: 0.0781 (0.0755)  time: 0.6184  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [51]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 5.9879 (6.2330)  loss_classifier: 5.4309 (5.7663)  loss_box_reg: 0.2432 (0.2385)  loss_objectness: 0.1519 (0.1526)  loss_rpn_box_reg: 0.0771 (0.0756)  time: 0.6187  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [51]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1386 (6.2322)  loss_classifier: 5.7428 (5.7647)  loss_box_reg: 0.2378 (0.2387)  loss_objectness: 0.1515 (0.1531)  loss_rpn_box_reg: 0.0771 (0.0757)  time: 0.6201  data: 0.1374  max mem: 10734\n",
      "Training Epoch: [51]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.3342 (6.2346)  loss_classifier: 5.8564 (5.7651)  loss_box_reg: 0.2597 (0.2397)  loss_objectness: 0.1515 (0.1532)  loss_rpn_box_reg: 0.0791 (0.0766)  time: 0.6248  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [51]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.3342 (6.2323)  loss_classifier: 5.7807 (5.7615)  loss_box_reg: 0.2655 (0.2408)  loss_objectness: 0.1486 (0.1533)  loss_rpn_box_reg: 0.1018 (0.0768)  time: 0.6203  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [51]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.3653 (6.2374)  loss_classifier: 5.7807 (5.7675)  loss_box_reg: 0.2259 (0.2399)  loss_objectness: 0.1550 (0.1532)  loss_rpn_box_reg: 0.0775 (0.0768)  time: 0.6104  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [51]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.3639 (6.2356)  loss_classifier: 5.9390 (5.7654)  loss_box_reg: 0.2155 (0.2402)  loss_objectness: 0.1550 (0.1533)  loss_rpn_box_reg: 0.0612 (0.0767)  time: 0.6011  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [51]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2878 (6.2349)  loss_classifier: 5.6656 (5.7644)  loss_box_reg: 0.2392 (0.2402)  loss_objectness: 0.1630 (0.1536)  loss_rpn_box_reg: 0.0582 (0.0766)  time: 0.6030  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [51]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.4025 (6.2405)  loss_classifier: 5.8983 (5.7689)  loss_box_reg: 0.2420 (0.2410)  loss_objectness: 0.1613 (0.1538)  loss_rpn_box_reg: 0.0718 (0.0767)  time: 0.6152  data: 0.1374  max mem: 10734\n",
      "Training Epoch: [51]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.3797 (6.2402)  loss_classifier: 5.9082 (5.7693)  loss_box_reg: 0.2273 (0.2405)  loss_objectness: 0.1613 (0.1539)  loss_rpn_box_reg: 0.0602 (0.0766)  time: 0.6186  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [51]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 5.9714 (6.2358)  loss_classifier: 5.6158 (5.7655)  loss_box_reg: 0.2040 (0.2402)  loss_objectness: 0.1464 (0.1536)  loss_rpn_box_reg: 0.0619 (0.0765)  time: 0.6279  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [51]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 5.9423 (6.2311)  loss_classifier: 5.5071 (5.7618)  loss_box_reg: 0.2052 (0.2398)  loss_objectness: 0.1302 (0.1531)  loss_rpn_box_reg: 0.0657 (0.0763)  time: 0.6230  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [51]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0310 (6.2296)  loss_classifier: 5.5071 (5.7601)  loss_box_reg: 0.2066 (0.2404)  loss_objectness: 0.1302 (0.1530)  loss_rpn_box_reg: 0.0629 (0.0762)  time: 0.6307  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [51]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0900 (6.2245)  loss_classifier: 5.5796 (5.7552)  loss_box_reg: 0.2608 (0.2407)  loss_objectness: 0.1362 (0.1526)  loss_rpn_box_reg: 0.0644 (0.0761)  time: 0.6393  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [51]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 5.9939 (6.2210)  loss_classifier: 5.5796 (5.7523)  loss_box_reg: 0.2197 (0.2403)  loss_objectness: 0.1304 (0.1524)  loss_rpn_box_reg: 0.0675 (0.0759)  time: 0.6271  data: 0.1313  max mem: 10734\n",
      "Training Epoch: [51] Total time: 0:05:12 (0.6251 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:54  model_time: 0.7292 (0.7292)  evaluator_time: 0.0340 (0.0340)  time: 0.9172  data: 0.1430  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4451 (0.4529)  evaluator_time: 0.0340 (0.0371)  time: 0.6296  data: 0.1476  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4671 (0.4546)  evaluator_time: 0.0360 (0.0374)  time: 0.6558  data: 0.1488  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6426 s / it)\n",
      "Averaged stats: model_time: 0.4671 (0.4546)  evaluator_time: 0.0360 (0.0374)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [51]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.2069 (6.2069)  loss_classifier: 5.6608 (5.6608)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1210 (0.1210)  loss_rpn_box_reg: 0.1306 (0.1306)  time: 0.6511  data: 0.1480  max mem: 10734\n",
      "Testing Epoch: [51]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0084 (6.1243)  loss_classifier: 5.4279 (5.6132)  loss_box_reg: 0.2609 (0.2887)  loss_objectness: 0.1288 (0.1318)  loss_rpn_box_reg: 0.0739 (0.0906)  time: 0.5840  data: 0.1440  max mem: 10734\n",
      "Testing Epoch: [51]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1569 (6.1584)  loss_classifier: 5.6974 (5.6519)  loss_box_reg: 0.2500 (0.2842)  loss_objectness: 0.1204 (0.1319)  loss_rpn_box_reg: 0.0745 (0.0905)  time: 0.6027  data: 0.1471  max mem: 10734\n",
      "Testing Epoch: [51] Total time: 0:01:14 (0.5968 s / it)\n",
      "Training Epoch: [52]  [  0/500]  eta: 0:06:10  lr: 0.000000  loss: 5.8419 (5.8419)  loss_classifier: 5.4971 (5.4971)  loss_box_reg: 0.1472 (0.1472)  loss_objectness: 0.1681 (0.1681)  loss_rpn_box_reg: 0.0294 (0.0294)  time: 0.7402  data: 0.1250  max mem: 10734\n",
      "Training Epoch: [52]  [ 10/500]  eta: 0:05:17  lr: 0.000000  loss: 6.0696 (6.1122)  loss_classifier: 5.4971 (5.6163)  loss_box_reg: 0.2410 (0.2571)  loss_objectness: 0.1658 (0.1480)  loss_rpn_box_reg: 0.1032 (0.0908)  time: 0.6481  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [52]  [ 20/500]  eta: 0:05:09  lr: 0.000000  loss: 6.2253 (6.1882)  loss_classifier: 5.7178 (5.7252)  loss_box_reg: 0.2410 (0.2381)  loss_objectness: 0.1539 (0.1531)  loss_rpn_box_reg: 0.0678 (0.0718)  time: 0.6399  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [52]  [ 30/500]  eta: 0:05:01  lr: 0.000000  loss: 6.2253 (6.1998)  loss_classifier: 5.7695 (5.7390)  loss_box_reg: 0.2212 (0.2387)  loss_objectness: 0.1517 (0.1518)  loss_rpn_box_reg: 0.0598 (0.0702)  time: 0.6375  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [52]  [ 40/500]  eta: 0:04:54  lr: 0.000000  loss: 6.0279 (6.1643)  loss_classifier: 5.5508 (5.6970)  loss_box_reg: 0.2327 (0.2443)  loss_objectness: 0.1499 (0.1525)  loss_rpn_box_reg: 0.0668 (0.0704)  time: 0.6344  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [52]  [ 50/500]  eta: 0:04:48  lr: 0.000000  loss: 6.0847 (6.1688)  loss_classifier: 5.6550 (5.7015)  loss_box_reg: 0.2312 (0.2443)  loss_objectness: 0.1561 (0.1544)  loss_rpn_box_reg: 0.0657 (0.0687)  time: 0.6427  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [52]  [ 60/500]  eta: 0:04:40  lr: 0.000000  loss: 6.0847 (6.1501)  loss_classifier: 5.6550 (5.6863)  loss_box_reg: 0.2081 (0.2430)  loss_objectness: 0.1523 (0.1533)  loss_rpn_box_reg: 0.0579 (0.0674)  time: 0.6306  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [52]  [ 70/500]  eta: 0:04:33  lr: 0.000000  loss: 5.9016 (6.1646)  loss_classifier: 5.5446 (5.7041)  loss_box_reg: 0.2224 (0.2410)  loss_objectness: 0.1380 (0.1516)  loss_rpn_box_reg: 0.0579 (0.0678)  time: 0.6228  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [52]  [ 80/500]  eta: 0:04:25  lr: 0.000000  loss: 6.1899 (6.1788)  loss_classifier: 5.7400 (5.7223)  loss_box_reg: 0.2234 (0.2378)  loss_objectness: 0.1385 (0.1514)  loss_rpn_box_reg: 0.0619 (0.0674)  time: 0.6161  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [52]  [ 90/500]  eta: 0:04:18  lr: 0.000000  loss: 6.2768 (6.1855)  loss_classifier: 5.9619 (5.7316)  loss_box_reg: 0.2194 (0.2353)  loss_objectness: 0.1468 (0.1511)  loss_rpn_box_reg: 0.0577 (0.0676)  time: 0.6077  data: 0.1306  max mem: 10734\n",
      "Training Epoch: [52]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 6.2768 (6.1926)  loss_classifier: 5.8940 (5.7392)  loss_box_reg: 0.2234 (0.2345)  loss_objectness: 0.1428 (0.1507)  loss_rpn_box_reg: 0.0579 (0.0682)  time: 0.6076  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [52]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 6.1112 (6.1724)  loss_classifier: 5.5275 (5.7136)  loss_box_reg: 0.2360 (0.2352)  loss_objectness: 0.1614 (0.1536)  loss_rpn_box_reg: 0.0579 (0.0700)  time: 0.6019  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [52]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 5.9840 (6.1708)  loss_classifier: 5.4546 (5.7097)  loss_box_reg: 0.2444 (0.2369)  loss_objectness: 0.1551 (0.1532)  loss_rpn_box_reg: 0.0709 (0.0709)  time: 0.6079  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [52]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.1876 (6.1805)  loss_classifier: 5.6298 (5.7174)  loss_box_reg: 0.2485 (0.2390)  loss_objectness: 0.1435 (0.1535)  loss_rpn_box_reg: 0.0627 (0.0706)  time: 0.6236  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [52]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.3137 (6.1877)  loss_classifier: 5.7868 (5.7280)  loss_box_reg: 0.2115 (0.2361)  loss_objectness: 0.1384 (0.1530)  loss_rpn_box_reg: 0.0590 (0.0706)  time: 0.6326  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [52]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.4752 (6.2063)  loss_classifier: 5.9680 (5.7437)  loss_box_reg: 0.2071 (0.2376)  loss_objectness: 0.1440 (0.1542)  loss_rpn_box_reg: 0.0651 (0.0708)  time: 0.6390  data: 0.1380  max mem: 10734\n",
      "Training Epoch: [52]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.4651 (6.2120)  loss_classifier: 5.8710 (5.7489)  loss_box_reg: 0.2522 (0.2384)  loss_objectness: 0.1463 (0.1535)  loss_rpn_box_reg: 0.0656 (0.0712)  time: 0.6351  data: 0.1378  max mem: 10734\n",
      "Training Epoch: [52]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.2481 (6.2289)  loss_classifier: 5.8446 (5.7658)  loss_box_reg: 0.2159 (0.2373)  loss_objectness: 0.1378 (0.1534)  loss_rpn_box_reg: 0.0656 (0.0723)  time: 0.6134  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [52]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.0715 (6.2147)  loss_classifier: 5.7386 (5.7508)  loss_box_reg: 0.2152 (0.2372)  loss_objectness: 0.1485 (0.1539)  loss_rpn_box_reg: 0.0915 (0.0728)  time: 0.6232  data: 0.1375  max mem: 10734\n",
      "Training Epoch: [52]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.0715 (6.2083)  loss_classifier: 5.7050 (5.7461)  loss_box_reg: 0.2016 (0.2353)  loss_objectness: 0.1689 (0.1545)  loss_rpn_box_reg: 0.0752 (0.0724)  time: 0.6239  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [52]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.2409 (6.2099)  loss_classifier: 5.7050 (5.7471)  loss_box_reg: 0.2143 (0.2363)  loss_objectness: 0.1541 (0.1541)  loss_rpn_box_reg: 0.0588 (0.0724)  time: 0.6195  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [52]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.3906 (6.2253)  loss_classifier: 5.8735 (5.7623)  loss_box_reg: 0.2296 (0.2357)  loss_objectness: 0.1465 (0.1546)  loss_rpn_box_reg: 0.0732 (0.0727)  time: 0.6321  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [52]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.3906 (6.2259)  loss_classifier: 5.9309 (5.7611)  loss_box_reg: 0.2296 (0.2360)  loss_objectness: 0.1675 (0.1552)  loss_rpn_box_reg: 0.0916 (0.0736)  time: 0.6250  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [52]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.2094 (6.2310)  loss_classifier: 5.7068 (5.7664)  loss_box_reg: 0.2206 (0.2361)  loss_objectness: 0.1580 (0.1552)  loss_rpn_box_reg: 0.0774 (0.0734)  time: 0.6185  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [52]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.2727 (6.2395)  loss_classifier: 5.7538 (5.7728)  loss_box_reg: 0.2271 (0.2369)  loss_objectness: 0.1479 (0.1565)  loss_rpn_box_reg: 0.0650 (0.0734)  time: 0.6229  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [52]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.2920 (6.2393)  loss_classifier: 5.7434 (5.7716)  loss_box_reg: 0.2618 (0.2370)  loss_objectness: 0.1579 (0.1569)  loss_rpn_box_reg: 0.0787 (0.0738)  time: 0.6186  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [52]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.2920 (6.2408)  loss_classifier: 5.8033 (5.7732)  loss_box_reg: 0.2169 (0.2369)  loss_objectness: 0.1498 (0.1562)  loss_rpn_box_reg: 0.0805 (0.0745)  time: 0.6232  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [52]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.1907 (6.2393)  loss_classifier: 5.7641 (5.7710)  loss_box_reg: 0.2449 (0.2377)  loss_objectness: 0.1441 (0.1559)  loss_rpn_box_reg: 0.0780 (0.0748)  time: 0.6284  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [52]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.1728 (6.2423)  loss_classifier: 5.7028 (5.7742)  loss_box_reg: 0.2449 (0.2377)  loss_objectness: 0.1380 (0.1556)  loss_rpn_box_reg: 0.0769 (0.0748)  time: 0.6181  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [52]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.1838 (6.2443)  loss_classifier: 5.7827 (5.7779)  loss_box_reg: 0.2263 (0.2367)  loss_objectness: 0.1326 (0.1549)  loss_rpn_box_reg: 0.0769 (0.0748)  time: 0.6157  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [52]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.1252 (6.2390)  loss_classifier: 5.6385 (5.7713)  loss_box_reg: 0.2239 (0.2374)  loss_objectness: 0.1539 (0.1552)  loss_rpn_box_reg: 0.0734 (0.0751)  time: 0.6132  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [52]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 5.9370 (6.2306)  loss_classifier: 5.4782 (5.7625)  loss_box_reg: 0.2598 (0.2380)  loss_objectness: 0.1582 (0.1548)  loss_rpn_box_reg: 0.0734 (0.0754)  time: 0.6076  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [52]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2604 (6.2362)  loss_classifier: 5.7694 (5.7688)  loss_box_reg: 0.2466 (0.2375)  loss_objectness: 0.1389 (0.1544)  loss_rpn_box_reg: 0.0807 (0.0755)  time: 0.6175  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [52]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.3746 (6.2389)  loss_classifier: 5.9255 (5.7723)  loss_box_reg: 0.2224 (0.2370)  loss_objectness: 0.1427 (0.1542)  loss_rpn_box_reg: 0.0675 (0.0754)  time: 0.6359  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [52]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.0434 (6.2357)  loss_classifier: 5.7315 (5.7714)  loss_box_reg: 0.2148 (0.2359)  loss_objectness: 0.1355 (0.1534)  loss_rpn_box_reg: 0.0650 (0.0750)  time: 0.6478  data: 0.1398  max mem: 10734\n",
      "Training Epoch: [52]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.1761 (6.2380)  loss_classifier: 5.7437 (5.7732)  loss_box_reg: 0.2064 (0.2359)  loss_objectness: 0.1408 (0.1538)  loss_rpn_box_reg: 0.0657 (0.0752)  time: 0.6443  data: 0.1400  max mem: 10734\n",
      "Training Epoch: [52]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1540 (6.2351)  loss_classifier: 5.7437 (5.7695)  loss_box_reg: 0.2240 (0.2367)  loss_objectness: 0.1528 (0.1535)  loss_rpn_box_reg: 0.0775 (0.0755)  time: 0.6265  data: 0.1377  max mem: 10734\n",
      "Training Epoch: [52]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1582 (6.2375)  loss_classifier: 5.7055 (5.7714)  loss_box_reg: 0.2522 (0.2370)  loss_objectness: 0.1536 (0.1533)  loss_rpn_box_reg: 0.0784 (0.0759)  time: 0.6138  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [52]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.2584 (6.2342)  loss_classifier: 5.7374 (5.7678)  loss_box_reg: 0.2463 (0.2373)  loss_objectness: 0.1461 (0.1533)  loss_rpn_box_reg: 0.0653 (0.0758)  time: 0.6257  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [52]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.2187 (6.2345)  loss_classifier: 5.7333 (5.7677)  loss_box_reg: 0.2326 (0.2372)  loss_objectness: 0.1427 (0.1535)  loss_rpn_box_reg: 0.0710 (0.0760)  time: 0.6262  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [52]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1273 (6.2316)  loss_classifier: 5.6394 (5.7647)  loss_box_reg: 0.2326 (0.2375)  loss_objectness: 0.1414 (0.1533)  loss_rpn_box_reg: 0.0796 (0.0761)  time: 0.6241  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [52]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1125 (6.2260)  loss_classifier: 5.5619 (5.7604)  loss_box_reg: 0.2400 (0.2367)  loss_objectness: 0.1410 (0.1533)  loss_rpn_box_reg: 0.0687 (0.0757)  time: 0.6309  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [52]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1398 (6.2278)  loss_classifier: 5.6188 (5.7610)  loss_box_reg: 0.2557 (0.2377)  loss_objectness: 0.1392 (0.1533)  loss_rpn_box_reg: 0.0687 (0.0758)  time: 0.6249  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [52]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1404 (6.2252)  loss_classifier: 5.6219 (5.7593)  loss_box_reg: 0.2288 (0.2372)  loss_objectness: 0.1392 (0.1532)  loss_rpn_box_reg: 0.0660 (0.0755)  time: 0.6321  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [52]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.0930 (6.2252)  loss_classifier: 5.6678 (5.7598)  loss_box_reg: 0.2270 (0.2371)  loss_objectness: 0.1413 (0.1529)  loss_rpn_box_reg: 0.0603 (0.0754)  time: 0.6390  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [52]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0930 (6.2209)  loss_classifier: 5.7122 (5.7552)  loss_box_reg: 0.2371 (0.2373)  loss_objectness: 0.1434 (0.1528)  loss_rpn_box_reg: 0.0595 (0.0755)  time: 0.6379  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [52]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0455 (6.2226)  loss_classifier: 5.5632 (5.7565)  loss_box_reg: 0.2436 (0.2378)  loss_objectness: 0.1407 (0.1527)  loss_rpn_box_reg: 0.0693 (0.0756)  time: 0.6299  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [52]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0253 (6.2160)  loss_classifier: 5.5632 (5.7505)  loss_box_reg: 0.2155 (0.2372)  loss_objectness: 0.1387 (0.1525)  loss_rpn_box_reg: 0.0719 (0.0758)  time: 0.6177  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [52]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0253 (6.2207)  loss_classifier: 5.6215 (5.7548)  loss_box_reg: 0.2148 (0.2377)  loss_objectness: 0.1369 (0.1526)  loss_rpn_box_reg: 0.0654 (0.0756)  time: 0.6293  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [52]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.2607 (6.2190)  loss_classifier: 5.6778 (5.7518)  loss_box_reg: 0.2379 (0.2384)  loss_objectness: 0.1591 (0.1530)  loss_rpn_box_reg: 0.0715 (0.0758)  time: 0.6301  data: 0.1394  max mem: 10734\n",
      "Training Epoch: [52]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0699 (6.2158)  loss_classifier: 5.5796 (5.7485)  loss_box_reg: 0.2574 (0.2387)  loss_objectness: 0.1553 (0.1529)  loss_rpn_box_reg: 0.0783 (0.0758)  time: 0.6192  data: 0.1383  max mem: 10734\n",
      "Training Epoch: [52] Total time: 0:05:12 (0.6257 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:57  model_time: 0.7582 (0.7582)  evaluator_time: 0.0350 (0.0350)  time: 0.9432  data: 0.1410  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4381 (0.4514)  evaluator_time: 0.0340 (0.0349)  time: 0.6329  data: 0.1535  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4701 (0.4533)  evaluator_time: 0.0360 (0.0357)  time: 0.6536  data: 0.1481  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6406 s / it)\n",
      "Averaged stats: model_time: 0.4701 (0.4533)  evaluator_time: 0.0360 (0.0357)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [52]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.2073 (6.2073)  loss_classifier: 5.6558 (5.6558)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1238 (0.1238)  loss_rpn_box_reg: 0.1332 (0.1332)  time: 0.6501  data: 0.1450  max mem: 10734\n",
      "Testing Epoch: [52]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9895 (6.1300)  loss_classifier: 5.4193 (5.6188)  loss_box_reg: 0.2609 (0.2896)  loss_objectness: 0.1312 (0.1314)  loss_rpn_box_reg: 0.0725 (0.0901)  time: 0.5832  data: 0.1443  max mem: 10734\n",
      "Testing Epoch: [52]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1770 (6.1624)  loss_classifier: 5.6957 (5.6557)  loss_box_reg: 0.2500 (0.2850)  loss_objectness: 0.1210 (0.1315)  loss_rpn_box_reg: 0.0745 (0.0901)  time: 0.5997  data: 0.1456  max mem: 10734\n",
      "Testing Epoch: [52] Total time: 0:01:14 (0.5955 s / it)\n",
      "Training Epoch: [53]  [  0/500]  eta: 0:06:29  lr: 0.000000  loss: 5.3697 (5.3697)  loss_classifier: 4.7968 (4.7968)  loss_box_reg: 0.3169 (0.3169)  loss_objectness: 0.1665 (0.1665)  loss_rpn_box_reg: 0.0895 (0.0895)  time: 0.7792  data: 0.1370  max mem: 10734\n",
      "Training Epoch: [53]  [ 10/500]  eta: 0:05:10  lr: 0.000000  loss: 6.0977 (6.1436)  loss_classifier: 5.5555 (5.6419)  loss_box_reg: 0.2418 (0.2689)  loss_objectness: 0.1642 (0.1632)  loss_rpn_box_reg: 0.0725 (0.0697)  time: 0.6332  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [53]  [ 20/500]  eta: 0:04:55  lr: 0.000000  loss: 6.0977 (6.1703)  loss_classifier: 5.5717 (5.6902)  loss_box_reg: 0.2392 (0.2507)  loss_objectness: 0.1621 (0.1626)  loss_rpn_box_reg: 0.0670 (0.0669)  time: 0.6066  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [53]  [ 30/500]  eta: 0:04:47  lr: 0.000000  loss: 6.4599 (6.3138)  loss_classifier: 6.0190 (5.8430)  loss_box_reg: 0.2392 (0.2457)  loss_objectness: 0.1510 (0.1588)  loss_rpn_box_reg: 0.0569 (0.0663)  time: 0.5987  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [53]  [ 40/500]  eta: 0:04:43  lr: 0.000000  loss: 6.4871 (6.3234)  loss_classifier: 6.0190 (5.8448)  loss_box_reg: 0.2369 (0.2484)  loss_objectness: 0.1572 (0.1622)  loss_rpn_box_reg: 0.0593 (0.0680)  time: 0.6174  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [53]  [ 50/500]  eta: 0:04:40  lr: 0.000000  loss: 6.3631 (6.3039)  loss_classifier: 5.8315 (5.8262)  loss_box_reg: 0.2443 (0.2468)  loss_objectness: 0.1586 (0.1604)  loss_rpn_box_reg: 0.0793 (0.0705)  time: 0.6445  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [53]  [ 60/500]  eta: 0:04:32  lr: 0.000000  loss: 6.2223 (6.2867)  loss_classifier: 5.6663 (5.8110)  loss_box_reg: 0.2220 (0.2405)  loss_objectness: 0.1628 (0.1603)  loss_rpn_box_reg: 0.0829 (0.0749)  time: 0.6290  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [53]  [ 70/500]  eta: 0:04:27  lr: 0.000000  loss: 6.2223 (6.3089)  loss_classifier: 5.6856 (5.8308)  loss_box_reg: 0.2220 (0.2427)  loss_objectness: 0.1579 (0.1604)  loss_rpn_box_reg: 0.0798 (0.0750)  time: 0.6199  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [53]  [ 80/500]  eta: 0:04:21  lr: 0.000000  loss: 6.2077 (6.2878)  loss_classifier: 5.6856 (5.8153)  loss_box_reg: 0.2389 (0.2424)  loss_objectness: 0.1457 (0.1576)  loss_rpn_box_reg: 0.0590 (0.0726)  time: 0.6309  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [53]  [ 90/500]  eta: 0:04:16  lr: 0.000000  loss: 5.9748 (6.2950)  loss_classifier: 5.4781 (5.8207)  loss_box_reg: 0.2350 (0.2430)  loss_objectness: 0.1416 (0.1568)  loss_rpn_box_reg: 0.0644 (0.0745)  time: 0.6309  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [53]  [100/500]  eta: 0:04:09  lr: 0.000000  loss: 6.0297 (6.2639)  loss_classifier: 5.5180 (5.7917)  loss_box_reg: 0.2294 (0.2405)  loss_objectness: 0.1395 (0.1572)  loss_rpn_box_reg: 0.0768 (0.0745)  time: 0.6318  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [53]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 6.1133 (6.2631)  loss_classifier: 5.6547 (5.7899)  loss_box_reg: 0.2347 (0.2417)  loss_objectness: 0.1398 (0.1571)  loss_rpn_box_reg: 0.0764 (0.0745)  time: 0.6235  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [53]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.2285 (6.2648)  loss_classifier: 5.7497 (5.7907)  loss_box_reg: 0.2530 (0.2422)  loss_objectness: 0.1467 (0.1567)  loss_rpn_box_reg: 0.0804 (0.0752)  time: 0.6186  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [53]  [130/500]  eta: 0:03:50  lr: 0.000000  loss: 6.1584 (6.2471)  loss_classifier: 5.7391 (5.7730)  loss_box_reg: 0.2429 (0.2417)  loss_objectness: 0.1425 (0.1571)  loss_rpn_box_reg: 0.0779 (0.0754)  time: 0.6166  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [53]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 5.8734 (6.2359)  loss_classifier: 5.4398 (5.7615)  loss_box_reg: 0.2400 (0.2416)  loss_objectness: 0.1588 (0.1576)  loss_rpn_box_reg: 0.0719 (0.0753)  time: 0.6257  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [53]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.0092 (6.2191)  loss_classifier: 5.5366 (5.7451)  loss_box_reg: 0.2426 (0.2418)  loss_objectness: 0.1563 (0.1566)  loss_rpn_box_reg: 0.0660 (0.0756)  time: 0.6430  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [53]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.0317 (6.2127)  loss_classifier: 5.5366 (5.7378)  loss_box_reg: 0.2521 (0.2439)  loss_objectness: 0.1466 (0.1556)  loss_rpn_box_reg: 0.0660 (0.0754)  time: 0.6412  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [53]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 5.8680 (6.1942)  loss_classifier: 5.4140 (5.7178)  loss_box_reg: 0.2524 (0.2448)  loss_objectness: 0.1432 (0.1551)  loss_rpn_box_reg: 0.0763 (0.0765)  time: 0.6307  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [53]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 5.9685 (6.1891)  loss_classifier: 5.4140 (5.7126)  loss_box_reg: 0.2447 (0.2440)  loss_objectness: 0.1495 (0.1549)  loss_rpn_box_reg: 0.0981 (0.0775)  time: 0.6282  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [53]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.1411 (6.1861)  loss_classifier: 5.6688 (5.7084)  loss_box_reg: 0.2344 (0.2444)  loss_objectness: 0.1466 (0.1549)  loss_rpn_box_reg: 0.0835 (0.0783)  time: 0.6100  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [53]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.1750 (6.1958)  loss_classifier: 5.7216 (5.7196)  loss_box_reg: 0.2440 (0.2435)  loss_objectness: 0.1376 (0.1539)  loss_rpn_box_reg: 0.0813 (0.0788)  time: 0.6085  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [53]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.4065 (6.2133)  loss_classifier: 5.8928 (5.7357)  loss_box_reg: 0.2374 (0.2441)  loss_objectness: 0.1415 (0.1547)  loss_rpn_box_reg: 0.0793 (0.0788)  time: 0.6239  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [53]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.3411 (6.2179)  loss_classifier: 5.8558 (5.7389)  loss_box_reg: 0.2534 (0.2451)  loss_objectness: 0.1578 (0.1553)  loss_rpn_box_reg: 0.0724 (0.0786)  time: 0.6108  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [53]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.3278 (6.2249)  loss_classifier: 5.8451 (5.7468)  loss_box_reg: 0.2565 (0.2447)  loss_objectness: 0.1584 (0.1553)  loss_rpn_box_reg: 0.0676 (0.0780)  time: 0.6125  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [53]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.3737 (6.2349)  loss_classifier: 5.9542 (5.7571)  loss_box_reg: 0.2382 (0.2447)  loss_objectness: 0.1566 (0.1552)  loss_rpn_box_reg: 0.0669 (0.0779)  time: 0.6248  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [53]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.3737 (6.2370)  loss_classifier: 5.9438 (5.7582)  loss_box_reg: 0.2533 (0.2451)  loss_objectness: 0.1486 (0.1554)  loss_rpn_box_reg: 0.0788 (0.0784)  time: 0.6297  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [53]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.2291 (6.2296)  loss_classifier: 5.7043 (5.7522)  loss_box_reg: 0.2204 (0.2440)  loss_objectness: 0.1493 (0.1553)  loss_rpn_box_reg: 0.0788 (0.0782)  time: 0.6358  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [53]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.2620 (6.2373)  loss_classifier: 5.7862 (5.7613)  loss_box_reg: 0.2140 (0.2436)  loss_objectness: 0.1407 (0.1548)  loss_rpn_box_reg: 0.0674 (0.0777)  time: 0.6319  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [53]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.3032 (6.2389)  loss_classifier: 5.7987 (5.7618)  loss_box_reg: 0.2403 (0.2435)  loss_objectness: 0.1493 (0.1556)  loss_rpn_box_reg: 0.0719 (0.0780)  time: 0.6213  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [53]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.1158 (6.2357)  loss_classifier: 5.6868 (5.7608)  loss_box_reg: 0.2403 (0.2426)  loss_objectness: 0.1434 (0.1551)  loss_rpn_box_reg: 0.0681 (0.0773)  time: 0.6277  data: 0.1375  max mem: 10734\n",
      "Training Epoch: [53]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.1807 (6.2376)  loss_classifier: 5.7809 (5.7629)  loss_box_reg: 0.2251 (0.2431)  loss_objectness: 0.1356 (0.1548)  loss_rpn_box_reg: 0.0470 (0.0767)  time: 0.6335  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [53]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.2682 (6.2406)  loss_classifier: 5.8326 (5.7667)  loss_box_reg: 0.2175 (0.2425)  loss_objectness: 0.1441 (0.1550)  loss_rpn_box_reg: 0.0528 (0.0765)  time: 0.6233  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [53]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.0879 (6.2337)  loss_classifier: 5.6139 (5.7601)  loss_box_reg: 0.2150 (0.2424)  loss_objectness: 0.1484 (0.1547)  loss_rpn_box_reg: 0.0709 (0.0765)  time: 0.6194  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [53]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.0454 (6.2316)  loss_classifier: 5.6139 (5.7578)  loss_box_reg: 0.2384 (0.2424)  loss_objectness: 0.1470 (0.1546)  loss_rpn_box_reg: 0.0733 (0.0768)  time: 0.6236  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [53]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.1795 (6.2267)  loss_classifier: 5.6898 (5.7545)  loss_box_reg: 0.2287 (0.2419)  loss_objectness: 0.1337 (0.1538)  loss_rpn_box_reg: 0.0676 (0.0765)  time: 0.6391  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [53]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.0940 (6.2184)  loss_classifier: 5.6343 (5.7481)  loss_box_reg: 0.2282 (0.2412)  loss_objectness: 0.1202 (0.1533)  loss_rpn_box_reg: 0.0477 (0.0758)  time: 0.6317  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [53]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.0067 (6.2184)  loss_classifier: 5.5904 (5.7491)  loss_box_reg: 0.2103 (0.2406)  loss_objectness: 0.1240 (0.1531)  loss_rpn_box_reg: 0.0646 (0.0757)  time: 0.6284  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [53]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 5.9951 (6.2163)  loss_classifier: 5.6061 (5.7478)  loss_box_reg: 0.2108 (0.2402)  loss_objectness: 0.1358 (0.1526)  loss_rpn_box_reg: 0.0722 (0.0756)  time: 0.6319  data: 0.1306  max mem: 10734\n",
      "Training Epoch: [53]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1681 (6.2184)  loss_classifier: 5.6266 (5.7491)  loss_box_reg: 0.2321 (0.2408)  loss_objectness: 0.1325 (0.1524)  loss_rpn_box_reg: 0.0794 (0.0760)  time: 0.6195  data: 0.1310  max mem: 10734\n",
      "Training Epoch: [53]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.4017 (6.2196)  loss_classifier: 5.8095 (5.7512)  loss_box_reg: 0.2403 (0.2406)  loss_objectness: 0.1285 (0.1521)  loss_rpn_box_reg: 0.0630 (0.0757)  time: 0.6219  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [53]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.3659 (6.2216)  loss_classifier: 5.8779 (5.7533)  loss_box_reg: 0.2217 (0.2400)  loss_objectness: 0.1481 (0.1524)  loss_rpn_box_reg: 0.0600 (0.0758)  time: 0.6239  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [53]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2532 (6.2235)  loss_classifier: 5.7087 (5.7555)  loss_box_reg: 0.2224 (0.2400)  loss_objectness: 0.1486 (0.1523)  loss_rpn_box_reg: 0.0658 (0.0757)  time: 0.6156  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [53]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.2048 (6.2220)  loss_classifier: 5.6934 (5.7544)  loss_box_reg: 0.2288 (0.2398)  loss_objectness: 0.1420 (0.1521)  loss_rpn_box_reg: 0.0649 (0.0756)  time: 0.6189  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [53]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1261 (6.2186)  loss_classifier: 5.6642 (5.7509)  loss_box_reg: 0.2283 (0.2398)  loss_objectness: 0.1564 (0.1523)  loss_rpn_box_reg: 0.0703 (0.0756)  time: 0.6208  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [53]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.0685 (6.2164)  loss_classifier: 5.5961 (5.7486)  loss_box_reg: 0.2305 (0.2397)  loss_objectness: 0.1490 (0.1523)  loss_rpn_box_reg: 0.0726 (0.0758)  time: 0.6166  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [53]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0825 (6.2170)  loss_classifier: 5.6298 (5.7491)  loss_box_reg: 0.2245 (0.2395)  loss_objectness: 0.1441 (0.1522)  loss_rpn_box_reg: 0.0977 (0.0763)  time: 0.6223  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [53]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.1836 (6.2151)  loss_classifier: 5.6298 (5.7474)  loss_box_reg: 0.2088 (0.2392)  loss_objectness: 0.1456 (0.1524)  loss_rpn_box_reg: 0.0750 (0.0761)  time: 0.6289  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [53]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2102 (6.2182)  loss_classifier: 5.7034 (5.7502)  loss_box_reg: 0.2139 (0.2394)  loss_objectness: 0.1546 (0.1526)  loss_rpn_box_reg: 0.0728 (0.0760)  time: 0.6339  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [53]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1408 (6.2152)  loss_classifier: 5.6397 (5.7470)  loss_box_reg: 0.2200 (0.2392)  loss_objectness: 0.1579 (0.1530)  loss_rpn_box_reg: 0.0673 (0.0760)  time: 0.6159  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [53]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0406 (6.2151)  loss_classifier: 5.5325 (5.7466)  loss_box_reg: 0.2363 (0.2394)  loss_objectness: 0.1554 (0.1530)  loss_rpn_box_reg: 0.0602 (0.0761)  time: 0.5982  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [53]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1870 (6.2181)  loss_classifier: 5.6937 (5.7498)  loss_box_reg: 0.2494 (0.2394)  loss_objectness: 0.1492 (0.1531)  loss_rpn_box_reg: 0.0602 (0.0758)  time: 0.6079  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [53] Total time: 0:05:11 (0.6237 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:53  model_time: 0.7272 (0.7272)  evaluator_time: 0.0340 (0.0340)  time: 0.9112  data: 0.1410  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4411 (0.4513)  evaluator_time: 0.0340 (0.0368)  time: 0.6324  data: 0.1531  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4681 (0.4539)  evaluator_time: 0.0350 (0.0372)  time: 0.6582  data: 0.1484  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6412 s / it)\n",
      "Averaged stats: model_time: 0.4681 (0.4539)  evaluator_time: 0.0350 (0.0372)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.29s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [53]  [  0/125]  eta: 0:01:22  lr: 0.000000  loss: 6.2078 (6.2078)  loss_classifier: 5.6626 (5.6626)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1172 (0.1172)  loss_rpn_box_reg: 0.1336 (0.1336)  time: 0.6631  data: 0.1560  max mem: 10734\n",
      "Testing Epoch: [53]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0170 (6.1334)  loss_classifier: 5.4359 (5.6231)  loss_box_reg: 0.2609 (0.2891)  loss_objectness: 0.1261 (0.1320)  loss_rpn_box_reg: 0.0723 (0.0892)  time: 0.5827  data: 0.1447  max mem: 10734\n",
      "Testing Epoch: [53]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1471 (6.1647)  loss_classifier: 5.6919 (5.6588)  loss_box_reg: 0.2500 (0.2846)  loss_objectness: 0.1186 (0.1319)  loss_rpn_box_reg: 0.0745 (0.0893)  time: 0.5976  data: 0.1449  max mem: 10734\n",
      "Testing Epoch: [53] Total time: 0:01:14 (0.5958 s / it)\n",
      "Training Epoch: [54]  [  0/500]  eta: 0:06:32  lr: 0.000000  loss: 5.7014 (5.7014)  loss_classifier: 5.2931 (5.2931)  loss_box_reg: 0.1941 (0.1941)  loss_objectness: 0.1440 (0.1440)  loss_rpn_box_reg: 0.0701 (0.0701)  time: 0.7852  data: 0.1310  max mem: 10734\n",
      "Training Epoch: [54]  [ 10/500]  eta: 0:05:22  lr: 0.000000  loss: 6.1627 (6.1119)  loss_classifier: 5.6190 (5.6818)  loss_box_reg: 0.2053 (0.2166)  loss_objectness: 0.1494 (0.1465)  loss_rpn_box_reg: 0.0617 (0.0670)  time: 0.6579  data: 0.1376  max mem: 10734\n",
      "Training Epoch: [54]  [ 20/500]  eta: 0:05:08  lr: 0.000000  loss: 6.1627 (6.1745)  loss_classifier: 5.6190 (5.7071)  loss_box_reg: 0.2288 (0.2401)  loss_objectness: 0.1509 (0.1560)  loss_rpn_box_reg: 0.0617 (0.0713)  time: 0.6355  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [54]  [ 30/500]  eta: 0:04:56  lr: 0.000000  loss: 6.0795 (6.2358)  loss_classifier: 5.6576 (5.7628)  loss_box_reg: 0.2388 (0.2374)  loss_objectness: 0.1648 (0.1598)  loss_rpn_box_reg: 0.0708 (0.0758)  time: 0.6175  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [54]  [ 40/500]  eta: 0:04:48  lr: 0.000000  loss: 6.0795 (6.2257)  loss_classifier: 5.6576 (5.7460)  loss_box_reg: 0.2371 (0.2402)  loss_objectness: 0.1559 (0.1606)  loss_rpn_box_reg: 0.0750 (0.0789)  time: 0.6119  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [54]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 6.1620 (6.1906)  loss_classifier: 5.6905 (5.7135)  loss_box_reg: 0.2371 (0.2385)  loss_objectness: 0.1477 (0.1585)  loss_rpn_box_reg: 0.0771 (0.0800)  time: 0.6202  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [54]  [ 60/500]  eta: 0:04:34  lr: 0.000000  loss: 6.1835 (6.2360)  loss_classifier: 5.6986 (5.7578)  loss_box_reg: 0.2373 (0.2408)  loss_objectness: 0.1487 (0.1574)  loss_rpn_box_reg: 0.0771 (0.0800)  time: 0.6149  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [54]  [ 70/500]  eta: 0:04:28  lr: 0.000000  loss: 6.6002 (6.3003)  loss_classifier: 6.1337 (5.8259)  loss_box_reg: 0.2194 (0.2398)  loss_objectness: 0.1487 (0.1564)  loss_rpn_box_reg: 0.0701 (0.0783)  time: 0.6135  data: 0.1312  max mem: 10734\n",
      "Training Epoch: [54]  [ 80/500]  eta: 0:04:22  lr: 0.000000  loss: 6.2608 (6.2825)  loss_classifier: 5.9115 (5.8145)  loss_box_reg: 0.2127 (0.2370)  loss_objectness: 0.1422 (0.1539)  loss_rpn_box_reg: 0.0628 (0.0771)  time: 0.6282  data: 0.1305  max mem: 10734\n",
      "Training Epoch: [54]  [ 90/500]  eta: 0:04:16  lr: 0.000000  loss: 6.0287 (6.2797)  loss_classifier: 5.5240 (5.8079)  loss_box_reg: 0.2486 (0.2403)  loss_objectness: 0.1473 (0.1551)  loss_rpn_box_reg: 0.0628 (0.0763)  time: 0.6352  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [54]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 6.0145 (6.2653)  loss_classifier: 5.4710 (5.7912)  loss_box_reg: 0.2554 (0.2410)  loss_objectness: 0.1646 (0.1556)  loss_rpn_box_reg: 0.0631 (0.0775)  time: 0.6327  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [54]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.1918 (6.2631)  loss_classifier: 5.7640 (5.7924)  loss_box_reg: 0.2011 (0.2373)  loss_objectness: 0.1503 (0.1555)  loss_rpn_box_reg: 0.0794 (0.0778)  time: 0.6278  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [54]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.0555 (6.2445)  loss_classifier: 5.6799 (5.7754)  loss_box_reg: 0.2097 (0.2381)  loss_objectness: 0.1485 (0.1551)  loss_rpn_box_reg: 0.0568 (0.0759)  time: 0.6258  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [54]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 5.9511 (6.2405)  loss_classifier: 5.5328 (5.7691)  loss_box_reg: 0.2325 (0.2401)  loss_objectness: 0.1457 (0.1547)  loss_rpn_box_reg: 0.0627 (0.0765)  time: 0.6259  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [54]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.2690 (6.2522)  loss_classifier: 5.7718 (5.7778)  loss_box_reg: 0.2438 (0.2410)  loss_objectness: 0.1530 (0.1558)  loss_rpn_box_reg: 0.0863 (0.0776)  time: 0.6184  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [54]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.2619 (6.2514)  loss_classifier: 5.7718 (5.7754)  loss_box_reg: 0.2438 (0.2413)  loss_objectness: 0.1698 (0.1569)  loss_rpn_box_reg: 0.0863 (0.0778)  time: 0.6163  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [54]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.1935 (6.2396)  loss_classifier: 5.7165 (5.7636)  loss_box_reg: 0.2321 (0.2420)  loss_objectness: 0.1569 (0.1569)  loss_rpn_box_reg: 0.0627 (0.0772)  time: 0.6209  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [54]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 6.1935 (6.2418)  loss_classifier: 5.7703 (5.7646)  loss_box_reg: 0.2347 (0.2430)  loss_objectness: 0.1548 (0.1568)  loss_rpn_box_reg: 0.0761 (0.0774)  time: 0.6141  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [54]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.2679 (6.2446)  loss_classifier: 5.7745 (5.7695)  loss_box_reg: 0.2164 (0.2421)  loss_objectness: 0.1434 (0.1560)  loss_rpn_box_reg: 0.0761 (0.0770)  time: 0.6235  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [54]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.2679 (6.2438)  loss_classifier: 5.7533 (5.7697)  loss_box_reg: 0.2199 (0.2422)  loss_objectness: 0.1393 (0.1555)  loss_rpn_box_reg: 0.0609 (0.0764)  time: 0.6396  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [54]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.1789 (6.2464)  loss_classifier: 5.7169 (5.7734)  loss_box_reg: 0.2288 (0.2420)  loss_objectness: 0.1393 (0.1549)  loss_rpn_box_reg: 0.0622 (0.0761)  time: 0.6395  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [54]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.1698 (6.2427)  loss_classifier: 5.7159 (5.7699)  loss_box_reg: 0.2330 (0.2424)  loss_objectness: 0.1374 (0.1547)  loss_rpn_box_reg: 0.0622 (0.0757)  time: 0.6409  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [54]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.1589 (6.2397)  loss_classifier: 5.7092 (5.7673)  loss_box_reg: 0.2348 (0.2423)  loss_objectness: 0.1402 (0.1546)  loss_rpn_box_reg: 0.0589 (0.0755)  time: 0.6298  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [54]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.2151 (6.2418)  loss_classifier: 5.7736 (5.7722)  loss_box_reg: 0.2149 (0.2405)  loss_objectness: 0.1402 (0.1542)  loss_rpn_box_reg: 0.0578 (0.0749)  time: 0.6188  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [54]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.2081 (6.2419)  loss_classifier: 5.7736 (5.7756)  loss_box_reg: 0.1858 (0.2381)  loss_objectness: 0.1345 (0.1535)  loss_rpn_box_reg: 0.0622 (0.0747)  time: 0.6325  data: 0.1308  max mem: 10734\n",
      "Training Epoch: [54]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 5.8660 (6.2399)  loss_classifier: 5.4597 (5.7740)  loss_box_reg: 0.2028 (0.2383)  loss_objectness: 0.1215 (0.1527)  loss_rpn_box_reg: 0.0689 (0.0748)  time: 0.6366  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [54]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.2408 (6.2442)  loss_classifier: 5.7843 (5.7768)  loss_box_reg: 0.2415 (0.2391)  loss_objectness: 0.1417 (0.1533)  loss_rpn_box_reg: 0.0729 (0.0751)  time: 0.6233  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [54]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.2101 (6.2378)  loss_classifier: 5.7300 (5.7714)  loss_box_reg: 0.2325 (0.2384)  loss_objectness: 0.1638 (0.1533)  loss_rpn_box_reg: 0.0706 (0.0747)  time: 0.6238  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [54]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.0424 (6.2313)  loss_classifier: 5.5519 (5.7647)  loss_box_reg: 0.2317 (0.2386)  loss_objectness: 0.1311 (0.1529)  loss_rpn_box_reg: 0.0619 (0.0750)  time: 0.6196  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [54]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.0566 (6.2326)  loss_classifier: 5.6373 (5.7668)  loss_box_reg: 0.2109 (0.2377)  loss_objectness: 0.1394 (0.1530)  loss_rpn_box_reg: 0.0707 (0.0752)  time: 0.6157  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [54]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.2472 (6.2365)  loss_classifier: 5.7216 (5.7705)  loss_box_reg: 0.2088 (0.2376)  loss_objectness: 0.1511 (0.1532)  loss_rpn_box_reg: 0.0626 (0.0752)  time: 0.6169  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [54]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.2824 (6.2380)  loss_classifier: 5.8003 (5.7734)  loss_box_reg: 0.2220 (0.2368)  loss_objectness: 0.1413 (0.1527)  loss_rpn_box_reg: 0.0566 (0.0751)  time: 0.6140  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [54]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.0431 (6.2302)  loss_classifier: 5.5437 (5.7656)  loss_box_reg: 0.2220 (0.2369)  loss_objectness: 0.1338 (0.1528)  loss_rpn_box_reg: 0.0589 (0.0749)  time: 0.6158  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [54]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.0436 (6.2276)  loss_classifier: 5.6038 (5.7630)  loss_box_reg: 0.2538 (0.2370)  loss_objectness: 0.1362 (0.1528)  loss_rpn_box_reg: 0.0602 (0.0749)  time: 0.6200  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [54]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.1299 (6.2273)  loss_classifier: 5.6446 (5.7625)  loss_box_reg: 0.2232 (0.2372)  loss_objectness: 0.1454 (0.1528)  loss_rpn_box_reg: 0.0753 (0.0748)  time: 0.6235  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [54]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.2216 (6.2305)  loss_classifier: 5.8351 (5.7649)  loss_box_reg: 0.2195 (0.2371)  loss_objectness: 0.1551 (0.1533)  loss_rpn_box_reg: 0.0753 (0.0752)  time: 0.6196  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [54]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.3165 (6.2289)  loss_classifier: 5.8690 (5.7631)  loss_box_reg: 0.2144 (0.2369)  loss_objectness: 0.1696 (0.1538)  loss_rpn_box_reg: 0.0646 (0.0752)  time: 0.6193  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [54]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1632 (6.2316)  loss_classifier: 5.6301 (5.7655)  loss_box_reg: 0.2298 (0.2369)  loss_objectness: 0.1680 (0.1539)  loss_rpn_box_reg: 0.0738 (0.0753)  time: 0.6163  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [54]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.1318 (6.2362)  loss_classifier: 5.6195 (5.7707)  loss_box_reg: 0.2298 (0.2363)  loss_objectness: 0.1340 (0.1537)  loss_rpn_box_reg: 0.0744 (0.0755)  time: 0.6193  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [54]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.0462 (6.2337)  loss_classifier: 5.6195 (5.7679)  loss_box_reg: 0.2343 (0.2369)  loss_objectness: 0.1322 (0.1533)  loss_rpn_box_reg: 0.0721 (0.0755)  time: 0.6293  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [54]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 5.8594 (6.2244)  loss_classifier: 5.3939 (5.7580)  loss_box_reg: 0.2484 (0.2373)  loss_objectness: 0.1408 (0.1533)  loss_rpn_box_reg: 0.0721 (0.0757)  time: 0.6294  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [54]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 5.8604 (6.2213)  loss_classifier: 5.4096 (5.7553)  loss_box_reg: 0.2292 (0.2370)  loss_objectness: 0.1537 (0.1534)  loss_rpn_box_reg: 0.0643 (0.0756)  time: 0.6130  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [54]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.0368 (6.2176)  loss_classifier: 5.6378 (5.7519)  loss_box_reg: 0.2241 (0.2372)  loss_objectness: 0.1469 (0.1530)  loss_rpn_box_reg: 0.0632 (0.0755)  time: 0.6108  data: 0.1309  max mem: 10734\n",
      "Training Epoch: [54]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1599 (6.2148)  loss_classifier: 5.7739 (5.7488)  loss_box_reg: 0.2266 (0.2376)  loss_objectness: 0.1393 (0.1527)  loss_rpn_box_reg: 0.0606 (0.0756)  time: 0.6288  data: 0.1313  max mem: 10734\n",
      "Training Epoch: [54]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2946 (6.2182)  loss_classifier: 5.7815 (5.7522)  loss_box_reg: 0.2346 (0.2375)  loss_objectness: 0.1437 (0.1529)  loss_rpn_box_reg: 0.0649 (0.0756)  time: 0.6227  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [54]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1957 (6.2178)  loss_classifier: 5.7322 (5.7523)  loss_box_reg: 0.2322 (0.2373)  loss_objectness: 0.1432 (0.1527)  loss_rpn_box_reg: 0.0667 (0.0755)  time: 0.6292  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [54]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.1240 (6.2187)  loss_classifier: 5.7156 (5.7537)  loss_box_reg: 0.2225 (0.2373)  loss_objectness: 0.1402 (0.1523)  loss_rpn_box_reg: 0.0675 (0.0754)  time: 0.6274  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [54]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1022 (6.2157)  loss_classifier: 5.6730 (5.7502)  loss_box_reg: 0.2129 (0.2373)  loss_objectness: 0.1533 (0.1527)  loss_rpn_box_reg: 0.0827 (0.0756)  time: 0.6076  data: 0.1303  max mem: 10734\n",
      "Training Epoch: [54]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0780 (6.2135)  loss_classifier: 5.5779 (5.7482)  loss_box_reg: 0.2085 (0.2373)  loss_objectness: 0.1576 (0.1524)  loss_rpn_box_reg: 0.0815 (0.0757)  time: 0.6105  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [54]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1765 (6.2137)  loss_classifier: 5.7724 (5.7478)  loss_box_reg: 0.2201 (0.2376)  loss_objectness: 0.1330 (0.1526)  loss_rpn_box_reg: 0.0750 (0.0757)  time: 0.6211  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [54]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0315 (6.2077)  loss_classifier: 5.5680 (5.7420)  loss_box_reg: 0.2625 (0.2377)  loss_objectness: 0.1369 (0.1524)  loss_rpn_box_reg: 0.0562 (0.0755)  time: 0.6300  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [54] Total time: 0:05:11 (0.6238 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:01  model_time: 0.7882 (0.7882)  evaluator_time: 0.0350 (0.0350)  time: 0.9722  data: 0.1400  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4371 (0.4516)  evaluator_time: 0.0340 (0.0352)  time: 0.6314  data: 0.1531  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4651 (0.4535)  evaluator_time: 0.0360 (0.0358)  time: 0.6536  data: 0.1479  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6409 s / it)\n",
      "Averaged stats: model_time: 0.4651 (0.4535)  evaluator_time: 0.0360 (0.0358)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.28s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [54]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1876 (6.1876)  loss_classifier: 5.6417 (5.6417)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1208 (0.1208)  loss_rpn_box_reg: 0.1306 (0.1306)  time: 0.6451  data: 0.1460  max mem: 10734\n",
      "Testing Epoch: [54]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9965 (6.1354)  loss_classifier: 5.4381 (5.6235)  loss_box_reg: 0.2609 (0.2900)  loss_objectness: 0.1316 (0.1324)  loss_rpn_box_reg: 0.0718 (0.0894)  time: 0.5842  data: 0.1458  max mem: 10734\n",
      "Testing Epoch: [54]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1660 (6.1664)  loss_classifier: 5.6952 (5.6594)  loss_box_reg: 0.2500 (0.2853)  loss_objectness: 0.1184 (0.1321)  loss_rpn_box_reg: 0.0745 (0.0895)  time: 0.5983  data: 0.1437  max mem: 10734\n",
      "Testing Epoch: [54] Total time: 0:01:14 (0.5965 s / it)\n",
      "Training Epoch: [55]  [  0/500]  eta: 0:07:42  lr: 0.000000  loss: 6.2995 (6.2995)  loss_classifier: 5.8282 (5.8282)  loss_box_reg: 0.2026 (0.2026)  loss_objectness: 0.1359 (0.1359)  loss_rpn_box_reg: 0.1327 (0.1327)  time: 0.9252  data: 0.1380  max mem: 10734\n",
      "Training Epoch: [55]  [ 10/500]  eta: 0:05:22  lr: 0.000000  loss: 6.3467 (6.2727)  loss_classifier: 5.8496 (5.8222)  loss_box_reg: 0.1962 (0.2074)  loss_objectness: 0.1580 (0.1556)  loss_rpn_box_reg: 0.0785 (0.0875)  time: 0.6590  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [55]  [ 20/500]  eta: 0:05:08  lr: 0.000000  loss: 6.2801 (6.2527)  loss_classifier: 5.7484 (5.8045)  loss_box_reg: 0.1962 (0.2139)  loss_objectness: 0.1563 (0.1531)  loss_rpn_box_reg: 0.0753 (0.0813)  time: 0.6278  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [55]  [ 30/500]  eta: 0:05:02  lr: 0.000000  loss: 6.0785 (6.2014)  loss_classifier: 5.6522 (5.7630)  loss_box_reg: 0.1944 (0.2049)  loss_objectness: 0.1563 (0.1563)  loss_rpn_box_reg: 0.0753 (0.0772)  time: 0.6337  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [55]  [ 40/500]  eta: 0:04:51  lr: 0.000000  loss: 6.0711 (6.2051)  loss_classifier: 5.6769 (5.7613)  loss_box_reg: 0.1944 (0.2127)  loss_objectness: 0.1514 (0.1554)  loss_rpn_box_reg: 0.0579 (0.0757)  time: 0.6271  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [55]  [ 50/500]  eta: 0:04:43  lr: 0.000000  loss: 6.2950 (6.2819)  loss_classifier: 5.7871 (5.8451)  loss_box_reg: 0.1921 (0.2110)  loss_objectness: 0.1444 (0.1535)  loss_rpn_box_reg: 0.0526 (0.0723)  time: 0.6111  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [55]  [ 60/500]  eta: 0:04:36  lr: 0.000000  loss: 6.3328 (6.2624)  loss_classifier: 5.8079 (5.8243)  loss_box_reg: 0.1921 (0.2117)  loss_objectness: 0.1430 (0.1535)  loss_rpn_box_reg: 0.0576 (0.0730)  time: 0.6178  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [55]  [ 70/500]  eta: 0:04:29  lr: 0.000000  loss: 6.3125 (6.2630)  loss_classifier: 5.7779 (5.8120)  loss_box_reg: 0.2448 (0.2199)  loss_objectness: 0.1430 (0.1532)  loss_rpn_box_reg: 0.0761 (0.0779)  time: 0.6207  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [55]  [ 80/500]  eta: 0:04:24  lr: 0.000000  loss: 6.3622 (6.2682)  loss_classifier: 5.7779 (5.8136)  loss_box_reg: 0.2487 (0.2239)  loss_objectness: 0.1430 (0.1521)  loss_rpn_box_reg: 0.0904 (0.0786)  time: 0.6280  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [55]  [ 90/500]  eta: 0:04:18  lr: 0.000000  loss: 6.0021 (6.2254)  loss_classifier: 5.5379 (5.7667)  loss_box_reg: 0.2498 (0.2274)  loss_objectness: 0.1535 (0.1538)  loss_rpn_box_reg: 0.0789 (0.0775)  time: 0.6356  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [55]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 6.0961 (6.2315)  loss_classifier: 5.5482 (5.7725)  loss_box_reg: 0.2547 (0.2285)  loss_objectness: 0.1596 (0.1541)  loss_rpn_box_reg: 0.0654 (0.0764)  time: 0.6289  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [55]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.2233 (6.2262)  loss_classifier: 5.7656 (5.7666)  loss_box_reg: 0.2392 (0.2294)  loss_objectness: 0.1427 (0.1540)  loss_rpn_box_reg: 0.0647 (0.0763)  time: 0.6205  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [55]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.0233 (6.2050)  loss_classifier: 5.5200 (5.7400)  loss_box_reg: 0.2478 (0.2325)  loss_objectness: 0.1487 (0.1551)  loss_rpn_box_reg: 0.0771 (0.0774)  time: 0.6204  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [55]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 5.9590 (6.2087)  loss_classifier: 5.5668 (5.7462)  loss_box_reg: 0.2231 (0.2321)  loss_objectness: 0.1462 (0.1534)  loss_rpn_box_reg: 0.0763 (0.0770)  time: 0.6272  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [55]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.0465 (6.1939)  loss_classifier: 5.6062 (5.7351)  loss_box_reg: 0.2166 (0.2304)  loss_objectness: 0.1438 (0.1525)  loss_rpn_box_reg: 0.0593 (0.0758)  time: 0.6191  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [55]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.0465 (6.2010)  loss_classifier: 5.6062 (5.7397)  loss_box_reg: 0.2281 (0.2328)  loss_objectness: 0.1449 (0.1525)  loss_rpn_box_reg: 0.0620 (0.0760)  time: 0.6196  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [55]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.4199 (6.2095)  loss_classifier: 5.8967 (5.7469)  loss_box_reg: 0.2369 (0.2331)  loss_objectness: 0.1518 (0.1536)  loss_rpn_box_reg: 0.0670 (0.0759)  time: 0.6260  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [55]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.1706 (6.2002)  loss_classifier: 5.6943 (5.7395)  loss_box_reg: 0.2204 (0.2325)  loss_objectness: 0.1511 (0.1530)  loss_rpn_box_reg: 0.0617 (0.0752)  time: 0.6307  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [55]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.0593 (6.1885)  loss_classifier: 5.4723 (5.7263)  loss_box_reg: 0.2241 (0.2346)  loss_objectness: 0.1408 (0.1528)  loss_rpn_box_reg: 0.0578 (0.0747)  time: 0.6231  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [55]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.1438 (6.1995)  loss_classifier: 5.7122 (5.7359)  loss_box_reg: 0.2241 (0.2349)  loss_objectness: 0.1537 (0.1539)  loss_rpn_box_reg: 0.0679 (0.0748)  time: 0.6224  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [55]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.2766 (6.2043)  loss_classifier: 5.8158 (5.7432)  loss_box_reg: 0.2106 (0.2338)  loss_objectness: 0.1364 (0.1528)  loss_rpn_box_reg: 0.0593 (0.0744)  time: 0.6399  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [55]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.1684 (6.2125)  loss_classifier: 5.7190 (5.7499)  loss_box_reg: 0.2291 (0.2345)  loss_objectness: 0.1518 (0.1537)  loss_rpn_box_reg: 0.0589 (0.0744)  time: 0.6291  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [55]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.1196 (6.2135)  loss_classifier: 5.6865 (5.7482)  loss_box_reg: 0.2515 (0.2358)  loss_objectness: 0.1718 (0.1543)  loss_rpn_box_reg: 0.0716 (0.0752)  time: 0.6226  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [55]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.3133 (6.2238)  loss_classifier: 5.8168 (5.7592)  loss_box_reg: 0.2441 (0.2354)  loss_objectness: 0.1581 (0.1539)  loss_rpn_box_reg: 0.0720 (0.0754)  time: 0.6221  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [55]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.3133 (6.2356)  loss_classifier: 5.8216 (5.7704)  loss_box_reg: 0.2149 (0.2360)  loss_objectness: 0.1466 (0.1536)  loss_rpn_box_reg: 0.0669 (0.0755)  time: 0.6205  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [55]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.2086 (6.2355)  loss_classifier: 5.7892 (5.7717)  loss_box_reg: 0.2159 (0.2357)  loss_objectness: 0.1370 (0.1530)  loss_rpn_box_reg: 0.0662 (0.0751)  time: 0.6239  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [55]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 5.9833 (6.2253)  loss_classifier: 5.5062 (5.7606)  loss_box_reg: 0.2336 (0.2371)  loss_objectness: 0.1437 (0.1527)  loss_rpn_box_reg: 0.0551 (0.0750)  time: 0.6254  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [55]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.0909 (6.2339)  loss_classifier: 5.6077 (5.7691)  loss_box_reg: 0.2323 (0.2369)  loss_objectness: 0.1447 (0.1526)  loss_rpn_box_reg: 0.0735 (0.0753)  time: 0.6217  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [55]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.4523 (6.2385)  loss_classifier: 5.9465 (5.7733)  loss_box_reg: 0.2254 (0.2372)  loss_objectness: 0.1281 (0.1523)  loss_rpn_box_reg: 0.0850 (0.0757)  time: 0.6287  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [55]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.1387 (6.2340)  loss_classifier: 5.7549 (5.7685)  loss_box_reg: 0.2472 (0.2379)  loss_objectness: 0.1295 (0.1522)  loss_rpn_box_reg: 0.0700 (0.0753)  time: 0.6449  data: 0.1315  max mem: 10734\n",
      "Training Epoch: [55]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.2082 (6.2428)  loss_classifier: 5.7859 (5.7772)  loss_box_reg: 0.2307 (0.2376)  loss_objectness: 0.1430 (0.1525)  loss_rpn_box_reg: 0.0632 (0.0755)  time: 0.6311  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [55]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.2082 (6.2431)  loss_classifier: 5.8060 (5.7755)  loss_box_reg: 0.2350 (0.2387)  loss_objectness: 0.1522 (0.1531)  loss_rpn_box_reg: 0.0815 (0.0758)  time: 0.6029  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [55]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1330 (6.2422)  loss_classifier: 5.5747 (5.7748)  loss_box_reg: 0.2625 (0.2384)  loss_objectness: 0.1614 (0.1531)  loss_rpn_box_reg: 0.0674 (0.0759)  time: 0.6048  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [55]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 5.9551 (6.2371)  loss_classifier: 5.5612 (5.7692)  loss_box_reg: 0.2558 (0.2391)  loss_objectness: 0.1483 (0.1530)  loss_rpn_box_reg: 0.0541 (0.0757)  time: 0.6328  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [55]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.0101 (6.2351)  loss_classifier: 5.6410 (5.7678)  loss_box_reg: 0.2373 (0.2389)  loss_objectness: 0.1482 (0.1529)  loss_rpn_box_reg: 0.0691 (0.0755)  time: 0.6357  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [55]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.0101 (6.2316)  loss_classifier: 5.6410 (5.7646)  loss_box_reg: 0.2203 (0.2389)  loss_objectness: 0.1465 (0.1529)  loss_rpn_box_reg: 0.0704 (0.0753)  time: 0.6267  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [55]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 5.8500 (6.2253)  loss_classifier: 5.4358 (5.7561)  loss_box_reg: 0.2526 (0.2402)  loss_objectness: 0.1501 (0.1532)  loss_rpn_box_reg: 0.0704 (0.0759)  time: 0.6193  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [55]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.0893 (6.2227)  loss_classifier: 5.4400 (5.7532)  loss_box_reg: 0.2473 (0.2403)  loss_objectness: 0.1563 (0.1533)  loss_rpn_box_reg: 0.0803 (0.0759)  time: 0.6170  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [55]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1473 (6.2245)  loss_classifier: 5.6353 (5.7559)  loss_box_reg: 0.2334 (0.2400)  loss_objectness: 0.1389 (0.1530)  loss_rpn_box_reg: 0.0541 (0.0756)  time: 0.6208  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [55]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.0316 (6.2202)  loss_classifier: 5.5866 (5.7517)  loss_box_reg: 0.2334 (0.2404)  loss_objectness: 0.1326 (0.1529)  loss_rpn_box_reg: 0.0496 (0.0752)  time: 0.6132  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [55]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1317 (6.2171)  loss_classifier: 5.5754 (5.7488)  loss_box_reg: 0.2232 (0.2404)  loss_objectness: 0.1502 (0.1529)  loss_rpn_box_reg: 0.0549 (0.0751)  time: 0.6212  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [55]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1610 (6.2144)  loss_classifier: 5.6112 (5.7475)  loss_box_reg: 0.2114 (0.2397)  loss_objectness: 0.1363 (0.1523)  loss_rpn_box_reg: 0.0688 (0.0749)  time: 0.6303  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [55]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.1710 (6.2150)  loss_classifier: 5.6112 (5.7482)  loss_box_reg: 0.2141 (0.2396)  loss_objectness: 0.1355 (0.1522)  loss_rpn_box_reg: 0.0671 (0.0750)  time: 0.6249  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [55]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2627 (6.2187)  loss_classifier: 5.7791 (5.7525)  loss_box_reg: 0.2263 (0.2396)  loss_objectness: 0.1353 (0.1518)  loss_rpn_box_reg: 0.0596 (0.0749)  time: 0.6227  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [55]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2190 (6.2173)  loss_classifier: 5.7714 (5.7508)  loss_box_reg: 0.2195 (0.2398)  loss_objectness: 0.1353 (0.1519)  loss_rpn_box_reg: 0.0614 (0.0749)  time: 0.6133  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [55]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0918 (6.2135)  loss_classifier: 5.6513 (5.7466)  loss_box_reg: 0.2465 (0.2399)  loss_objectness: 0.1440 (0.1519)  loss_rpn_box_reg: 0.0768 (0.0750)  time: 0.6148  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [55]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.1364 (6.2144)  loss_classifier: 5.7001 (5.7484)  loss_box_reg: 0.2162 (0.2396)  loss_objectness: 0.1413 (0.1517)  loss_rpn_box_reg: 0.0706 (0.0748)  time: 0.6306  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [55]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2753 (6.2137)  loss_classifier: 5.8190 (5.7471)  loss_box_reg: 0.2049 (0.2395)  loss_objectness: 0.1413 (0.1519)  loss_rpn_box_reg: 0.0602 (0.0753)  time: 0.6287  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [55]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2753 (6.2154)  loss_classifier: 5.7207 (5.7482)  loss_box_reg: 0.2392 (0.2400)  loss_objectness: 0.1453 (0.1519)  loss_rpn_box_reg: 0.0874 (0.0753)  time: 0.6134  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [55]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1263 (6.2126)  loss_classifier: 5.5598 (5.7447)  loss_box_reg: 0.2481 (0.2398)  loss_objectness: 0.1498 (0.1521)  loss_rpn_box_reg: 0.0874 (0.0759)  time: 0.6038  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [55]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1263 (6.2122)  loss_classifier: 5.5741 (5.7444)  loss_box_reg: 0.2449 (0.2398)  loss_objectness: 0.1364 (0.1519)  loss_rpn_box_reg: 0.0787 (0.0760)  time: 0.6139  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [55] Total time: 0:05:12 (0.6241 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:03  model_time: 0.7172 (0.7172)  evaluator_time: 0.0350 (0.0350)  time: 0.9902  data: 0.2281  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4441 (0.4514)  evaluator_time: 0.0340 (0.0372)  time: 0.6272  data: 0.1474  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4691 (0.4531)  evaluator_time: 0.0360 (0.0375)  time: 0.6582  data: 0.1539  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6415 s / it)\n",
      "Averaged stats: model_time: 0.4691 (0.4531)  evaluator_time: 0.0360 (0.0375)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [55]  [  0/125]  eta: 0:01:19  lr: 0.000000  loss: 6.2044 (6.2044)  loss_classifier: 5.6541 (5.6541)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1225 (0.1225)  loss_rpn_box_reg: 0.1333 (0.1333)  time: 0.6381  data: 0.1350  max mem: 10734\n",
      "Testing Epoch: [55]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0028 (6.1262)  loss_classifier: 5.4271 (5.6157)  loss_box_reg: 0.2609 (0.2894)  loss_objectness: 0.1325 (0.1315)  loss_rpn_box_reg: 0.0724 (0.0895)  time: 0.5765  data: 0.1399  max mem: 10734\n",
      "Testing Epoch: [55]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1723 (6.1601)  loss_classifier: 5.6955 (5.6537)  loss_box_reg: 0.2500 (0.2848)  loss_objectness: 0.1214 (0.1319)  loss_rpn_box_reg: 0.0745 (0.0897)  time: 0.5977  data: 0.1455  max mem: 10734\n",
      "Testing Epoch: [55] Total time: 0:01:14 (0.5942 s / it)\n",
      "Training Epoch: [56]  [  0/500]  eta: 0:06:05  lr: 0.000000  loss: 6.7505 (6.7505)  loss_classifier: 6.2750 (6.2750)  loss_box_reg: 0.3101 (0.3101)  loss_objectness: 0.1275 (0.1275)  loss_rpn_box_reg: 0.0379 (0.0379)  time: 0.7312  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [56]  [ 10/500]  eta: 0:05:19  lr: 0.000000  loss: 6.3131 (6.2865)  loss_classifier: 5.9317 (5.8227)  loss_box_reg: 0.2396 (0.2339)  loss_objectness: 0.1625 (0.1559)  loss_rpn_box_reg: 0.0660 (0.0741)  time: 0.6527  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [56]  [ 20/500]  eta: 0:05:03  lr: 0.000000  loss: 6.0462 (6.1493)  loss_classifier: 5.5553 (5.6751)  loss_box_reg: 0.2396 (0.2412)  loss_objectness: 0.1625 (0.1595)  loss_rpn_box_reg: 0.0646 (0.0735)  time: 0.6265  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [56]  [ 30/500]  eta: 0:04:52  lr: 0.000000  loss: 5.9165 (6.1111)  loss_classifier: 5.4000 (5.6309)  loss_box_reg: 0.2572 (0.2468)  loss_objectness: 0.1364 (0.1533)  loss_rpn_box_reg: 0.0766 (0.0802)  time: 0.6058  data: 0.1297  max mem: 10734\n",
      "Training Epoch: [56]  [ 40/500]  eta: 0:04:44  lr: 0.000000  loss: 6.1145 (6.1797)  loss_classifier: 5.6192 (5.6908)  loss_box_reg: 0.2485 (0.2462)  loss_objectness: 0.1559 (0.1572)  loss_rpn_box_reg: 0.1003 (0.0855)  time: 0.6026  data: 0.1302  max mem: 10734\n",
      "Training Epoch: [56]  [ 50/500]  eta: 0:04:37  lr: 0.000000  loss: 6.2784 (6.2051)  loss_classifier: 5.7144 (5.7028)  loss_box_reg: 0.2631 (0.2514)  loss_objectness: 0.1758 (0.1628)  loss_rpn_box_reg: 0.1017 (0.0882)  time: 0.6098  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [56]  [ 60/500]  eta: 0:04:32  lr: 0.000000  loss: 6.1591 (6.1740)  loss_classifier: 5.6434 (5.6765)  loss_box_reg: 0.2706 (0.2535)  loss_objectness: 0.1509 (0.1594)  loss_rpn_box_reg: 0.0652 (0.0846)  time: 0.6265  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [56]  [ 70/500]  eta: 0:04:26  lr: 0.000000  loss: 5.9861 (6.1569)  loss_classifier: 5.4942 (5.6593)  loss_box_reg: 0.2536 (0.2550)  loss_objectness: 0.1485 (0.1598)  loss_rpn_box_reg: 0.0602 (0.0827)  time: 0.6290  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [56]  [ 80/500]  eta: 0:04:20  lr: 0.000000  loss: 6.2180 (6.1803)  loss_classifier: 5.6123 (5.6775)  loss_box_reg: 0.2564 (0.2584)  loss_objectness: 0.1641 (0.1619)  loss_rpn_box_reg: 0.0647 (0.0824)  time: 0.6190  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [56]  [ 90/500]  eta: 0:04:13  lr: 0.000000  loss: 6.2180 (6.1756)  loss_classifier: 5.6123 (5.6782)  loss_box_reg: 0.2621 (0.2570)  loss_objectness: 0.1560 (0.1604)  loss_rpn_box_reg: 0.0642 (0.0801)  time: 0.6043  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [56]  [100/500]  eta: 0:04:07  lr: 0.000000  loss: 6.0314 (6.1484)  loss_classifier: 5.5343 (5.6542)  loss_box_reg: 0.2421 (0.2561)  loss_objectness: 0.1448 (0.1594)  loss_rpn_box_reg: 0.0616 (0.0786)  time: 0.6161  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [56]  [110/500]  eta: 0:04:01  lr: 0.000000  loss: 6.0656 (6.1428)  loss_classifier: 5.5412 (5.6492)  loss_box_reg: 0.2320 (0.2551)  loss_objectness: 0.1563 (0.1597)  loss_rpn_box_reg: 0.0649 (0.0788)  time: 0.6333  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [56]  [120/500]  eta: 0:03:56  lr: 0.000000  loss: 6.0656 (6.1442)  loss_classifier: 5.5460 (5.6515)  loss_box_reg: 0.2165 (0.2549)  loss_objectness: 0.1569 (0.1580)  loss_rpn_box_reg: 0.0842 (0.0798)  time: 0.6307  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [56]  [130/500]  eta: 0:03:50  lr: 0.000000  loss: 6.3084 (6.1530)  loss_classifier: 5.7789 (5.6584)  loss_box_reg: 0.2617 (0.2563)  loss_objectness: 0.1490 (0.1581)  loss_rpn_box_reg: 0.0779 (0.0803)  time: 0.6365  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [56]  [140/500]  eta: 0:03:43  lr: 0.000000  loss: 6.1380 (6.1616)  loss_classifier: 5.6478 (5.6702)  loss_box_reg: 0.2475 (0.2539)  loss_objectness: 0.1490 (0.1580)  loss_rpn_box_reg: 0.0718 (0.0794)  time: 0.6192  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [56]  [150/500]  eta: 0:03:37  lr: 0.000000  loss: 6.0456 (6.1626)  loss_classifier: 5.5767 (5.6711)  loss_box_reg: 0.2264 (0.2533)  loss_objectness: 0.1535 (0.1584)  loss_rpn_box_reg: 0.0736 (0.0797)  time: 0.6198  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [56]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.1294 (6.1709)  loss_classifier: 5.6957 (5.6815)  loss_box_reg: 0.2264 (0.2520)  loss_objectness: 0.1473 (0.1579)  loss_rpn_box_reg: 0.0745 (0.0794)  time: 0.6470  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [56]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.3090 (6.1851)  loss_classifier: 5.8552 (5.6995)  loss_box_reg: 0.2236 (0.2501)  loss_objectness: 0.1441 (0.1570)  loss_rpn_box_reg: 0.0628 (0.0785)  time: 0.6488  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [56]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.1663 (6.1724)  loss_classifier: 5.6691 (5.6886)  loss_box_reg: 0.2387 (0.2499)  loss_objectness: 0.1421 (0.1565)  loss_rpn_box_reg: 0.0563 (0.0775)  time: 0.6360  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [56]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.0870 (6.1714)  loss_classifier: 5.5494 (5.6849)  loss_box_reg: 0.2493 (0.2517)  loss_objectness: 0.1609 (0.1570)  loss_rpn_box_reg: 0.0800 (0.0779)  time: 0.6168  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [56]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.1775 (6.1751)  loss_classifier: 5.6481 (5.6901)  loss_box_reg: 0.2496 (0.2503)  loss_objectness: 0.1523 (0.1571)  loss_rpn_box_reg: 0.0781 (0.0776)  time: 0.6118  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [56]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.2269 (6.1744)  loss_classifier: 5.7648 (5.6927)  loss_box_reg: 0.2072 (0.2483)  loss_objectness: 0.1396 (0.1561)  loss_rpn_box_reg: 0.0611 (0.0774)  time: 0.6207  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [56]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.0370 (6.1749)  loss_classifier: 5.6670 (5.6925)  loss_box_reg: 0.2287 (0.2485)  loss_objectness: 0.1424 (0.1565)  loss_rpn_box_reg: 0.0686 (0.0773)  time: 0.6239  data: 0.1314  max mem: 10734\n",
      "Training Epoch: [56]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.1750 (6.1791)  loss_classifier: 5.7152 (5.6995)  loss_box_reg: 0.2222 (0.2467)  loss_objectness: 0.1424 (0.1557)  loss_rpn_box_reg: 0.0693 (0.0772)  time: 0.6311  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [56]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.2761 (6.1831)  loss_classifier: 5.8785 (5.7048)  loss_box_reg: 0.2046 (0.2467)  loss_objectness: 0.1347 (0.1551)  loss_rpn_box_reg: 0.0620 (0.0765)  time: 0.6294  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [56]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.3422 (6.1924)  loss_classifier: 5.8922 (5.7157)  loss_box_reg: 0.2051 (0.2455)  loss_objectness: 0.1435 (0.1550)  loss_rpn_box_reg: 0.0622 (0.0763)  time: 0.6231  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [56]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.2470 (6.1962)  loss_classifier: 5.7703 (5.7200)  loss_box_reg: 0.2097 (0.2451)  loss_objectness: 0.1563 (0.1552)  loss_rpn_box_reg: 0.0622 (0.0758)  time: 0.6194  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [56]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.0486 (6.1900)  loss_classifier: 5.5852 (5.7134)  loss_box_reg: 0.2360 (0.2455)  loss_objectness: 0.1448 (0.1548)  loss_rpn_box_reg: 0.0645 (0.0763)  time: 0.6179  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [56]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.0053 (6.1917)  loss_classifier: 5.5806 (5.7165)  loss_box_reg: 0.2245 (0.2450)  loss_objectness: 0.1366 (0.1543)  loss_rpn_box_reg: 0.0719 (0.0759)  time: 0.6321  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [56]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.0612 (6.1843)  loss_classifier: 5.6194 (5.7097)  loss_box_reg: 0.2179 (0.2441)  loss_objectness: 0.1423 (0.1543)  loss_rpn_box_reg: 0.0719 (0.0763)  time: 0.6338  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [56]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.3675 (6.2057)  loss_classifier: 5.8730 (5.7316)  loss_box_reg: 0.2179 (0.2438)  loss_objectness: 0.1410 (0.1537)  loss_rpn_box_reg: 0.0848 (0.0766)  time: 0.6322  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [56]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.5924 (6.2058)  loss_classifier: 6.1411 (5.7326)  loss_box_reg: 0.2374 (0.2434)  loss_objectness: 0.1266 (0.1534)  loss_rpn_box_reg: 0.0678 (0.0764)  time: 0.6283  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [56]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2608 (6.2124)  loss_classifier: 5.7400 (5.7405)  loss_box_reg: 0.2245 (0.2426)  loss_objectness: 0.1261 (0.1529)  loss_rpn_box_reg: 0.0714 (0.0764)  time: 0.6227  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [56]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.3990 (6.2163)  loss_classifier: 5.8287 (5.7455)  loss_box_reg: 0.1860 (0.2418)  loss_objectness: 0.1364 (0.1530)  loss_rpn_box_reg: 0.0714 (0.0760)  time: 0.6273  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [56]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.2787 (6.2137)  loss_classifier: 5.8113 (5.7431)  loss_box_reg: 0.2058 (0.2419)  loss_objectness: 0.1460 (0.1529)  loss_rpn_box_reg: 0.0704 (0.0758)  time: 0.6285  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [56]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.0958 (6.2200)  loss_classifier: 5.6897 (5.7504)  loss_box_reg: 0.2253 (0.2417)  loss_objectness: 0.1434 (0.1526)  loss_rpn_box_reg: 0.0631 (0.0754)  time: 0.6379  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [56]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.2045 (6.2272)  loss_classifier: 5.8335 (5.7577)  loss_box_reg: 0.2253 (0.2410)  loss_objectness: 0.1348 (0.1527)  loss_rpn_box_reg: 0.0478 (0.0758)  time: 0.6374  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [56]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1876 (6.2297)  loss_classifier: 5.7706 (5.7606)  loss_box_reg: 0.2307 (0.2405)  loss_objectness: 0.1465 (0.1527)  loss_rpn_box_reg: 0.0727 (0.0758)  time: 0.6243  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [56]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1596 (6.2248)  loss_classifier: 5.7190 (5.7558)  loss_box_reg: 0.2365 (0.2409)  loss_objectness: 0.1495 (0.1526)  loss_rpn_box_reg: 0.0664 (0.0755)  time: 0.6268  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [56]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1596 (6.2230)  loss_classifier: 5.6063 (5.7540)  loss_box_reg: 0.2568 (0.2411)  loss_objectness: 0.1405 (0.1523)  loss_rpn_box_reg: 0.0615 (0.0756)  time: 0.6372  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [56]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2703 (6.2217)  loss_classifier: 5.6728 (5.7531)  loss_box_reg: 0.2172 (0.2404)  loss_objectness: 0.1422 (0.1525)  loss_rpn_box_reg: 0.0778 (0.0758)  time: 0.6415  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [56]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2226 (6.2207)  loss_classifier: 5.7571 (5.7524)  loss_box_reg: 0.1996 (0.2402)  loss_objectness: 0.1480 (0.1523)  loss_rpn_box_reg: 0.0764 (0.0758)  time: 0.6323  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [56]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.2226 (6.2203)  loss_classifier: 5.7571 (5.7521)  loss_box_reg: 0.2182 (0.2401)  loss_objectness: 0.1437 (0.1524)  loss_rpn_box_reg: 0.0730 (0.0758)  time: 0.6249  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [56]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1511 (6.2194)  loss_classifier: 5.6466 (5.7513)  loss_box_reg: 0.2276 (0.2397)  loss_objectness: 0.1482 (0.1524)  loss_rpn_box_reg: 0.0644 (0.0759)  time: 0.6236  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [56]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.0859 (6.2212)  loss_classifier: 5.5484 (5.7530)  loss_box_reg: 0.2122 (0.2399)  loss_objectness: 0.1547 (0.1524)  loss_rpn_box_reg: 0.0644 (0.0759)  time: 0.6185  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [56]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.4109 (6.2249)  loss_classifier: 5.9144 (5.7569)  loss_box_reg: 0.2171 (0.2397)  loss_objectness: 0.1547 (0.1525)  loss_rpn_box_reg: 0.0624 (0.0759)  time: 0.6166  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [56]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.2891 (6.2237)  loss_classifier: 5.8408 (5.7571)  loss_box_reg: 0.2056 (0.2389)  loss_objectness: 0.1384 (0.1520)  loss_rpn_box_reg: 0.0624 (0.0757)  time: 0.6159  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [56]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0699 (6.2210)  loss_classifier: 5.6377 (5.7538)  loss_box_reg: 0.2256 (0.2396)  loss_objectness: 0.1257 (0.1520)  loss_rpn_box_reg: 0.0655 (0.0757)  time: 0.6129  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [56]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 5.9899 (6.2187)  loss_classifier: 5.5568 (5.7518)  loss_box_reg: 0.2423 (0.2395)  loss_objectness: 0.1317 (0.1517)  loss_rpn_box_reg: 0.0655 (0.0757)  time: 0.6199  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [56]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 5.9131 (6.2145)  loss_classifier: 5.5265 (5.7481)  loss_box_reg: 0.2345 (0.2392)  loss_objectness: 0.1317 (0.1514)  loss_rpn_box_reg: 0.0744 (0.0758)  time: 0.6372  data: 0.1315  max mem: 10734\n",
      "Training Epoch: [56]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 5.9086 (6.2120)  loss_classifier: 5.4004 (5.7443)  loss_box_reg: 0.2375 (0.2400)  loss_objectness: 0.1382 (0.1516)  loss_rpn_box_reg: 0.0815 (0.0760)  time: 0.6240  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [56] Total time: 0:05:12 (0.6257 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:46  model_time: 0.6661 (0.6661)  evaluator_time: 0.0350 (0.0350)  time: 0.8512  data: 0.1400  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4421 (0.4513)  evaluator_time: 0.0330 (0.0350)  time: 0.6284  data: 0.1480  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4701 (0.4526)  evaluator_time: 0.0350 (0.0357)  time: 0.6576  data: 0.1551  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6421 s / it)\n",
      "Averaged stats: model_time: 0.4701 (0.4526)  evaluator_time: 0.0350 (0.0357)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [56]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.1780 (6.1780)  loss_classifier: 5.6352 (5.6352)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1166 (0.1166)  loss_rpn_box_reg: 0.1316 (0.1316)  time: 0.6491  data: 0.1400  max mem: 10734\n",
      "Testing Epoch: [56]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9854 (6.1296)  loss_classifier: 5.4169 (5.6202)  loss_box_reg: 0.2609 (0.2891)  loss_objectness: 0.1304 (0.1310)  loss_rpn_box_reg: 0.0702 (0.0893)  time: 0.5825  data: 0.1441  max mem: 10734\n",
      "Testing Epoch: [56]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1415 (6.1618)  loss_classifier: 5.7009 (5.6564)  loss_box_reg: 0.2500 (0.2846)  loss_objectness: 0.1148 (0.1314)  loss_rpn_box_reg: 0.0745 (0.0894)  time: 0.5927  data: 0.1410  max mem: 10734\n",
      "Testing Epoch: [56] Total time: 0:01:14 (0.5937 s / it)\n",
      "Training Epoch: [57]  [  0/500]  eta: 0:06:47  lr: 0.000000  loss: 5.9457 (5.9457)  loss_classifier: 5.5108 (5.5108)  loss_box_reg: 0.1899 (0.1899)  loss_objectness: 0.1593 (0.1593)  loss_rpn_box_reg: 0.0857 (0.0857)  time: 0.8142  data: 0.1420  max mem: 10734\n",
      "Training Epoch: [57]  [ 10/500]  eta: 0:05:09  lr: 0.000000  loss: 5.9462 (6.1077)  loss_classifier: 5.5108 (5.6738)  loss_box_reg: 0.1967 (0.2139)  loss_objectness: 0.1356 (0.1431)  loss_rpn_box_reg: 0.0613 (0.0769)  time: 0.6310  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [57]  [ 20/500]  eta: 0:05:03  lr: 0.000000  loss: 6.2096 (6.2517)  loss_classifier: 5.7566 (5.7905)  loss_box_reg: 0.2185 (0.2260)  loss_objectness: 0.1474 (0.1505)  loss_rpn_box_reg: 0.0819 (0.0848)  time: 0.6237  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [57]  [ 30/500]  eta: 0:04:57  lr: 0.000000  loss: 6.2396 (6.2679)  loss_classifier: 5.7231 (5.8074)  loss_box_reg: 0.2185 (0.2289)  loss_objectness: 0.1543 (0.1510)  loss_rpn_box_reg: 0.0824 (0.0807)  time: 0.6339  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [57]  [ 40/500]  eta: 0:04:50  lr: 0.000000  loss: 6.2884 (6.3036)  loss_classifier: 5.7721 (5.8469)  loss_box_reg: 0.2219 (0.2269)  loss_objectness: 0.1543 (0.1530)  loss_rpn_box_reg: 0.0652 (0.0767)  time: 0.6312  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [57]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 6.3600 (6.2859)  loss_classifier: 5.8872 (5.8262)  loss_box_reg: 0.2422 (0.2301)  loss_objectness: 0.1578 (0.1516)  loss_rpn_box_reg: 0.0646 (0.0779)  time: 0.6223  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [57]  [ 60/500]  eta: 0:04:35  lr: 0.000000  loss: 6.2434 (6.2659)  loss_classifier: 5.6933 (5.7995)  loss_box_reg: 0.2516 (0.2328)  loss_objectness: 0.1453 (0.1524)  loss_rpn_box_reg: 0.0815 (0.0813)  time: 0.6159  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [57]  [ 70/500]  eta: 0:04:28  lr: 0.000000  loss: 6.1570 (6.2542)  loss_classifier: 5.6659 (5.7854)  loss_box_reg: 0.2451 (0.2349)  loss_objectness: 0.1418 (0.1527)  loss_rpn_box_reg: 0.0738 (0.0811)  time: 0.6170  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [57]  [ 80/500]  eta: 0:04:22  lr: 0.000000  loss: 6.1269 (6.2339)  loss_classifier: 5.5757 (5.7717)  loss_box_reg: 0.2188 (0.2321)  loss_objectness: 0.1360 (0.1511)  loss_rpn_box_reg: 0.0675 (0.0790)  time: 0.6152  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [57]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 6.1442 (6.2711)  loss_classifier: 5.6625 (5.8157)  loss_box_reg: 0.2132 (0.2288)  loss_objectness: 0.1360 (0.1499)  loss_rpn_box_reg: 0.0513 (0.0767)  time: 0.6399  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [57]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 6.1574 (6.2574)  loss_classifier: 5.7048 (5.7977)  loss_box_reg: 0.2223 (0.2318)  loss_objectness: 0.1508 (0.1518)  loss_rpn_box_reg: 0.0539 (0.0761)  time: 0.6357  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [57]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.1104 (6.2494)  loss_classifier: 5.6516 (5.7901)  loss_box_reg: 0.2308 (0.2325)  loss_objectness: 0.1446 (0.1502)  loss_rpn_box_reg: 0.0683 (0.0765)  time: 0.6217  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [57]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.0602 (6.2313)  loss_classifier: 5.5222 (5.7732)  loss_box_reg: 0.2214 (0.2317)  loss_objectness: 0.1441 (0.1499)  loss_rpn_box_reg: 0.0701 (0.0766)  time: 0.6337  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [57]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 5.9454 (6.2316)  loss_classifier: 5.5106 (5.7717)  loss_box_reg: 0.2440 (0.2339)  loss_objectness: 0.1538 (0.1510)  loss_rpn_box_reg: 0.0535 (0.0750)  time: 0.6311  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [57]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.3598 (6.2432)  loss_classifier: 5.8590 (5.7812)  loss_box_reg: 0.2551 (0.2357)  loss_objectness: 0.1491 (0.1511)  loss_rpn_box_reg: 0.0632 (0.0752)  time: 0.6356  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [57]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 6.2656 (6.2382)  loss_classifier: 5.7517 (5.7740)  loss_box_reg: 0.2661 (0.2359)  loss_objectness: 0.1595 (0.1535)  loss_rpn_box_reg: 0.0673 (0.0748)  time: 0.6342  data: 0.1400  max mem: 10734\n",
      "Training Epoch: [57]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.2288 (6.2461)  loss_classifier: 5.7360 (5.7834)  loss_box_reg: 0.2146 (0.2334)  loss_objectness: 0.1738 (0.1542)  loss_rpn_box_reg: 0.0648 (0.0751)  time: 0.6229  data: 0.1388  max mem: 10734\n",
      "Training Epoch: [57]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.1846 (6.2378)  loss_classifier: 5.8427 (5.7734)  loss_box_reg: 0.2195 (0.2347)  loss_objectness: 0.1496 (0.1541)  loss_rpn_box_reg: 0.0648 (0.0756)  time: 0.6205  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [57]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 5.8218 (6.2268)  loss_classifier: 5.4076 (5.7618)  loss_box_reg: 0.2522 (0.2359)  loss_objectness: 0.1338 (0.1537)  loss_rpn_box_reg: 0.0645 (0.0754)  time: 0.6197  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [57]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 5.8761 (6.2156)  loss_classifier: 5.4157 (5.7500)  loss_box_reg: 0.2339 (0.2377)  loss_objectness: 0.1369 (0.1529)  loss_rpn_box_reg: 0.0557 (0.0750)  time: 0.6212  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [57]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.1468 (6.2209)  loss_classifier: 5.6631 (5.7536)  loss_box_reg: 0.2260 (0.2383)  loss_objectness: 0.1471 (0.1531)  loss_rpn_box_reg: 0.0723 (0.0758)  time: 0.6329  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [57]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.1468 (6.2100)  loss_classifier: 5.6944 (5.7432)  loss_box_reg: 0.2178 (0.2378)  loss_objectness: 0.1476 (0.1526)  loss_rpn_box_reg: 0.0823 (0.0764)  time: 0.6412  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [57]  [220/500]  eta: 0:02:56  lr: 0.000000  loss: 5.9151 (6.2059)  loss_classifier: 5.4357 (5.7381)  loss_box_reg: 0.2224 (0.2383)  loss_objectness: 0.1444 (0.1526)  loss_rpn_box_reg: 0.0785 (0.0769)  time: 0.6383  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [57]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.1071 (6.2076)  loss_classifier: 5.6571 (5.7386)  loss_box_reg: 0.2490 (0.2388)  loss_objectness: 0.1444 (0.1529)  loss_rpn_box_reg: 0.0810 (0.0773)  time: 0.6358  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [57]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.0909 (6.2097)  loss_classifier: 5.6861 (5.7421)  loss_box_reg: 0.2277 (0.2380)  loss_objectness: 0.1460 (0.1525)  loss_rpn_box_reg: 0.0700 (0.0772)  time: 0.6330  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [57]  [250/500]  eta: 0:02:37  lr: 0.000000  loss: 6.1530 (6.2137)  loss_classifier: 5.7795 (5.7481)  loss_box_reg: 0.2368 (0.2370)  loss_objectness: 0.1346 (0.1517)  loss_rpn_box_reg: 0.0700 (0.0769)  time: 0.6186  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [57]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.1728 (6.2142)  loss_classifier: 5.8282 (5.7487)  loss_box_reg: 0.2396 (0.2374)  loss_objectness: 0.1346 (0.1513)  loss_rpn_box_reg: 0.0607 (0.0768)  time: 0.6104  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [57]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.1728 (6.2173)  loss_classifier: 5.8282 (5.7512)  loss_box_reg: 0.2531 (0.2375)  loss_objectness: 0.1479 (0.1517)  loss_rpn_box_reg: 0.0665 (0.0768)  time: 0.6162  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [57]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.0667 (6.2059)  loss_classifier: 5.6093 (5.7384)  loss_box_reg: 0.2412 (0.2380)  loss_objectness: 0.1593 (0.1519)  loss_rpn_box_reg: 0.0806 (0.0776)  time: 0.6106  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [57]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.0588 (6.2035)  loss_classifier: 5.5748 (5.7348)  loss_box_reg: 0.2432 (0.2386)  loss_objectness: 0.1527 (0.1519)  loss_rpn_box_reg: 0.0909 (0.0781)  time: 0.6183  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [57]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 5.8322 (6.1935)  loss_classifier: 5.4370 (5.7242)  loss_box_reg: 0.2432 (0.2389)  loss_objectness: 0.1527 (0.1523)  loss_rpn_box_reg: 0.0767 (0.0780)  time: 0.6269  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [57]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 5.8371 (6.1922)  loss_classifier: 5.4906 (5.7247)  loss_box_reg: 0.2318 (0.2380)  loss_objectness: 0.1461 (0.1519)  loss_rpn_box_reg: 0.0655 (0.0775)  time: 0.6222  data: 0.1309  max mem: 10734\n",
      "Training Epoch: [57]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1811 (6.1872)  loss_classifier: 5.6766 (5.7195)  loss_box_reg: 0.2101 (0.2382)  loss_objectness: 0.1461 (0.1521)  loss_rpn_box_reg: 0.0655 (0.0774)  time: 0.6232  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [57]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.2159 (6.1924)  loss_classifier: 5.7361 (5.7227)  loss_box_reg: 0.2243 (0.2391)  loss_objectness: 0.1526 (0.1529)  loss_rpn_box_reg: 0.0810 (0.0778)  time: 0.6234  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [57]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.4586 (6.1977)  loss_classifier: 5.9381 (5.7277)  loss_box_reg: 0.2361 (0.2395)  loss_objectness: 0.1503 (0.1528)  loss_rpn_box_reg: 0.0785 (0.0777)  time: 0.6307  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [57]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.2813 (6.1951)  loss_classifier: 5.9381 (5.7251)  loss_box_reg: 0.2295 (0.2392)  loss_objectness: 0.1489 (0.1528)  loss_rpn_box_reg: 0.0809 (0.0780)  time: 0.6317  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [57]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1295 (6.1969)  loss_classifier: 5.5732 (5.7272)  loss_box_reg: 0.2298 (0.2390)  loss_objectness: 0.1423 (0.1527)  loss_rpn_box_reg: 0.0640 (0.0779)  time: 0.6274  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [57]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1295 (6.1946)  loss_classifier: 5.5914 (5.7254)  loss_box_reg: 0.2237 (0.2386)  loss_objectness: 0.1401 (0.1529)  loss_rpn_box_reg: 0.0625 (0.0777)  time: 0.6211  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [57]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1338 (6.1968)  loss_classifier: 5.6172 (5.7266)  loss_box_reg: 0.2315 (0.2394)  loss_objectness: 0.1552 (0.1531)  loss_rpn_box_reg: 0.0742 (0.0778)  time: 0.6180  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [57]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.4401 (6.2020)  loss_classifier: 5.9012 (5.7323)  loss_box_reg: 0.2430 (0.2393)  loss_objectness: 0.1538 (0.1530)  loss_rpn_box_reg: 0.0708 (0.0775)  time: 0.6140  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [57]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.0527 (6.1988)  loss_classifier: 5.5923 (5.7290)  loss_box_reg: 0.2362 (0.2392)  loss_objectness: 0.1449 (0.1530)  loss_rpn_box_reg: 0.0642 (0.0776)  time: 0.6140  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [57]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.0527 (6.2042)  loss_classifier: 5.5923 (5.7341)  loss_box_reg: 0.2362 (0.2394)  loss_objectness: 0.1426 (0.1528)  loss_rpn_box_reg: 0.0791 (0.0779)  time: 0.6130  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [57]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.2697 (6.2015)  loss_classifier: 5.7813 (5.7318)  loss_box_reg: 0.2089 (0.2388)  loss_objectness: 0.1508 (0.1532)  loss_rpn_box_reg: 0.0791 (0.0777)  time: 0.6136  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [57]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2697 (6.2042)  loss_classifier: 5.8850 (5.7353)  loss_box_reg: 0.2080 (0.2383)  loss_objectness: 0.1578 (0.1533)  loss_rpn_box_reg: 0.0629 (0.0774)  time: 0.6183  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [57]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2608 (6.2056)  loss_classifier: 5.7208 (5.7372)  loss_box_reg: 0.2256 (0.2382)  loss_objectness: 0.1503 (0.1531)  loss_rpn_box_reg: 0.0622 (0.0771)  time: 0.6224  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [57]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0975 (6.2035)  loss_classifier: 5.6592 (5.7354)  loss_box_reg: 0.2337 (0.2380)  loss_objectness: 0.1439 (0.1532)  loss_rpn_box_reg: 0.0602 (0.0769)  time: 0.6263  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [57]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.1749 (6.2085)  loss_classifier: 5.8839 (5.7422)  loss_box_reg: 0.1935 (0.2370)  loss_objectness: 0.1508 (0.1530)  loss_rpn_box_reg: 0.0464 (0.0764)  time: 0.6338  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [57]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2459 (6.2097)  loss_classifier: 5.8839 (5.7425)  loss_box_reg: 0.2253 (0.2377)  loss_objectness: 0.1508 (0.1531)  loss_rpn_box_reg: 0.0566 (0.0764)  time: 0.6401  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [57]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.3465 (6.2183)  loss_classifier: 5.8890 (5.7513)  loss_box_reg: 0.2553 (0.2376)  loss_objectness: 0.1452 (0.1530)  loss_rpn_box_reg: 0.0778 (0.0764)  time: 0.6417  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [57]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.3529 (6.2154)  loss_classifier: 5.9398 (5.7487)  loss_box_reg: 0.2369 (0.2376)  loss_objectness: 0.1334 (0.1529)  loss_rpn_box_reg: 0.0714 (0.0761)  time: 0.6434  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [57]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 5.8867 (6.2148)  loss_classifier: 5.4851 (5.7476)  loss_box_reg: 0.2308 (0.2379)  loss_objectness: 0.1337 (0.1530)  loss_rpn_box_reg: 0.0717 (0.0762)  time: 0.6340  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [57] Total time: 0:05:13 (0.6263 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:52  model_time: 0.7152 (0.7152)  evaluator_time: 0.0350 (0.0350)  time: 0.8992  data: 0.1400  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4401 (0.4520)  evaluator_time: 0.0340 (0.0352)  time: 0.6328  data: 0.1503  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4651 (0.4530)  evaluator_time: 0.0360 (0.0359)  time: 0.6526  data: 0.1500  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6433 s / it)\n",
      "Averaged stats: model_time: 0.4651 (0.4530)  evaluator_time: 0.0360 (0.0359)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [57]  [  0/125]  eta: 0:01:22  lr: 0.000000  loss: 6.2121 (6.2121)  loss_classifier: 5.6555 (5.6555)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1289 (0.1289)  loss_rpn_box_reg: 0.1332 (0.1332)  time: 0.6611  data: 0.1550  max mem: 10734\n",
      "Testing Epoch: [57]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0153 (6.1265)  loss_classifier: 5.4302 (5.6154)  loss_box_reg: 0.2609 (0.2891)  loss_objectness: 0.1269 (0.1319)  loss_rpn_box_reg: 0.0704 (0.0902)  time: 0.5885  data: 0.1502  max mem: 10734\n",
      "Testing Epoch: [57]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1616 (6.1589)  loss_classifier: 5.6784 (5.6527)  loss_box_reg: 0.2500 (0.2846)  loss_objectness: 0.1164 (0.1314)  loss_rpn_box_reg: 0.0745 (0.0902)  time: 0.6023  data: 0.1479  max mem: 10734\n",
      "Testing Epoch: [57] Total time: 0:01:14 (0.5980 s / it)\n",
      "Training Epoch: [58]  [  0/500]  eta: 0:06:12  lr: 0.000000  loss: 6.2886 (6.2886)  loss_classifier: 5.8174 (5.8174)  loss_box_reg: 0.2253 (0.2253)  loss_objectness: 0.1453 (0.1453)  loss_rpn_box_reg: 0.1005 (0.1005)  time: 0.7442  data: 0.1280  max mem: 10734\n",
      "Training Epoch: [58]  [ 10/500]  eta: 0:05:15  lr: 0.000000  loss: 6.0262 (6.2496)  loss_classifier: 5.6612 (5.7493)  loss_box_reg: 0.2317 (0.2653)  loss_objectness: 0.1435 (0.1400)  loss_rpn_box_reg: 0.0988 (0.0950)  time: 0.6437  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [58]  [ 20/500]  eta: 0:05:06  lr: 0.000000  loss: 6.1173 (6.3233)  loss_classifier: 5.6913 (5.8420)  loss_box_reg: 0.2317 (0.2455)  loss_objectness: 0.1461 (0.1503)  loss_rpn_box_reg: 0.0922 (0.0856)  time: 0.6340  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [58]  [ 30/500]  eta: 0:04:57  lr: 0.000000  loss: 6.2872 (6.3214)  loss_classifier: 5.7474 (5.8218)  loss_box_reg: 0.2338 (0.2478)  loss_objectness: 0.1558 (0.1565)  loss_rpn_box_reg: 0.0810 (0.0952)  time: 0.6265  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [58]  [ 40/500]  eta: 0:04:51  lr: 0.000000  loss: 6.2149 (6.3129)  loss_classifier: 5.7964 (5.8264)  loss_box_reg: 0.2321 (0.2425)  loss_objectness: 0.1558 (0.1561)  loss_rpn_box_reg: 0.0707 (0.0879)  time: 0.6280  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [58]  [ 50/500]  eta: 0:04:44  lr: 0.000000  loss: 6.2828 (6.3451)  loss_classifier: 5.8571 (5.8593)  loss_box_reg: 0.2331 (0.2433)  loss_objectness: 0.1496 (0.1563)  loss_rpn_box_reg: 0.0688 (0.0862)  time: 0.6308  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [58]  [ 60/500]  eta: 0:04:39  lr: 0.000000  loss: 6.3882 (6.3498)  loss_classifier: 5.9317 (5.8733)  loss_box_reg: 0.2522 (0.2405)  loss_objectness: 0.1337 (0.1530)  loss_rpn_box_reg: 0.0688 (0.0830)  time: 0.6361  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [58]  [ 70/500]  eta: 0:04:31  lr: 0.000000  loss: 6.1677 (6.2990)  loss_classifier: 5.7221 (5.8269)  loss_box_reg: 0.2356 (0.2415)  loss_objectness: 0.1288 (0.1501)  loss_rpn_box_reg: 0.0631 (0.0804)  time: 0.6308  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [58]  [ 80/500]  eta: 0:04:24  lr: 0.000000  loss: 6.1677 (6.2850)  loss_classifier: 5.7051 (5.8153)  loss_box_reg: 0.2356 (0.2414)  loss_objectness: 0.1297 (0.1494)  loss_rpn_box_reg: 0.0551 (0.0790)  time: 0.6122  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [58]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 6.1809 (6.2567)  loss_classifier: 5.7150 (5.7873)  loss_box_reg: 0.2423 (0.2423)  loss_objectness: 0.1419 (0.1483)  loss_rpn_box_reg: 0.0564 (0.0788)  time: 0.6188  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [58]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 5.9835 (6.2220)  loss_classifier: 5.3948 (5.7500)  loss_box_reg: 0.2423 (0.2437)  loss_objectness: 0.1483 (0.1488)  loss_rpn_box_reg: 0.0663 (0.0796)  time: 0.6279  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [58]  [110/500]  eta: 0:04:05  lr: 0.000000  loss: 5.9443 (6.2285)  loss_classifier: 5.3989 (5.7573)  loss_box_reg: 0.2426 (0.2442)  loss_objectness: 0.1470 (0.1488)  loss_rpn_box_reg: 0.0663 (0.0782)  time: 0.6352  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [58]  [120/500]  eta: 0:03:59  lr: 0.000000  loss: 5.9964 (6.2166)  loss_classifier: 5.5808 (5.7465)  loss_box_reg: 0.2312 (0.2425)  loss_objectness: 0.1483 (0.1486)  loss_rpn_box_reg: 0.0671 (0.0790)  time: 0.6338  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [58]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 6.1044 (6.2227)  loss_classifier: 5.6157 (5.7503)  loss_box_reg: 0.2312 (0.2437)  loss_objectness: 0.1607 (0.1495)  loss_rpn_box_reg: 0.0851 (0.0792)  time: 0.6154  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [58]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.2235 (6.2240)  loss_classifier: 5.7668 (5.7523)  loss_box_reg: 0.2317 (0.2430)  loss_objectness: 0.1518 (0.1494)  loss_rpn_box_reg: 0.0726 (0.0792)  time: 0.6038  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [58]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.2235 (6.2122)  loss_classifier: 5.7648 (5.7401)  loss_box_reg: 0.2141 (0.2416)  loss_objectness: 0.1403 (0.1503)  loss_rpn_box_reg: 0.0778 (0.0801)  time: 0.6000  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [58]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.1256 (6.2174)  loss_classifier: 5.7269 (5.7465)  loss_box_reg: 0.2141 (0.2415)  loss_objectness: 0.1530 (0.1502)  loss_rpn_box_reg: 0.0687 (0.0793)  time: 0.6155  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [58]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.1223 (6.2133)  loss_classifier: 5.6571 (5.7407)  loss_box_reg: 0.2290 (0.2421)  loss_objectness: 0.1532 (0.1508)  loss_rpn_box_reg: 0.0687 (0.0797)  time: 0.6302  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [58]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.1123 (6.2031)  loss_classifier: 5.6098 (5.7305)  loss_box_reg: 0.2354 (0.2422)  loss_objectness: 0.1552 (0.1516)  loss_rpn_box_reg: 0.0724 (0.0788)  time: 0.6076  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [58]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.1064 (6.1941)  loss_classifier: 5.5947 (5.7238)  loss_box_reg: 0.2281 (0.2410)  loss_objectness: 0.1579 (0.1514)  loss_rpn_box_reg: 0.0606 (0.0779)  time: 0.6105  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [58]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.1064 (6.1878)  loss_classifier: 5.5961 (5.7175)  loss_box_reg: 0.2300 (0.2413)  loss_objectness: 0.1505 (0.1513)  loss_rpn_box_reg: 0.0673 (0.0776)  time: 0.6409  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [58]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.2558 (6.1922)  loss_classifier: 5.7075 (5.7223)  loss_box_reg: 0.2354 (0.2417)  loss_objectness: 0.1505 (0.1511)  loss_rpn_box_reg: 0.0604 (0.0771)  time: 0.6372  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [58]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.2887 (6.1985)  loss_classifier: 5.8730 (5.7300)  loss_box_reg: 0.2286 (0.2409)  loss_objectness: 0.1446 (0.1503)  loss_rpn_box_reg: 0.0586 (0.0774)  time: 0.6274  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [58]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.4636 (6.2109)  loss_classifier: 5.9571 (5.7429)  loss_box_reg: 0.2013 (0.2401)  loss_objectness: 0.1483 (0.1510)  loss_rpn_box_reg: 0.0595 (0.0768)  time: 0.6186  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [58]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.3698 (6.2043)  loss_classifier: 5.8324 (5.7368)  loss_box_reg: 0.2133 (0.2403)  loss_objectness: 0.1506 (0.1507)  loss_rpn_box_reg: 0.0588 (0.0766)  time: 0.6171  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [58]  [250/500]  eta: 0:02:35  lr: 0.000000  loss: 6.1260 (6.2086)  loss_classifier: 5.6400 (5.7403)  loss_box_reg: 0.2371 (0.2405)  loss_objectness: 0.1471 (0.1511)  loss_rpn_box_reg: 0.0715 (0.0766)  time: 0.6103  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [58]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 5.9897 (6.1997)  loss_classifier: 5.5914 (5.7309)  loss_box_reg: 0.2421 (0.2404)  loss_objectness: 0.1633 (0.1517)  loss_rpn_box_reg: 0.0715 (0.0767)  time: 0.6099  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [58]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 5.9065 (6.2031)  loss_classifier: 5.4927 (5.7336)  loss_box_reg: 0.2480 (0.2408)  loss_objectness: 0.1610 (0.1520)  loss_rpn_box_reg: 0.0619 (0.0767)  time: 0.6121  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [58]  [280/500]  eta: 0:02:16  lr: 0.000000  loss: 6.1863 (6.2006)  loss_classifier: 5.6467 (5.7307)  loss_box_reg: 0.2330 (0.2404)  loss_objectness: 0.1486 (0.1525)  loss_rpn_box_reg: 0.0745 (0.0769)  time: 0.6037  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [58]  [290/500]  eta: 0:02:10  lr: 0.000000  loss: 6.1790 (6.1997)  loss_classifier: 5.6361 (5.7303)  loss_box_reg: 0.2273 (0.2403)  loss_objectness: 0.1486 (0.1523)  loss_rpn_box_reg: 0.0744 (0.0769)  time: 0.6161  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [58]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.1755 (6.2025)  loss_classifier: 5.6175 (5.7325)  loss_box_reg: 0.2364 (0.2402)  loss_objectness: 0.1554 (0.1529)  loss_rpn_box_reg: 0.0667 (0.0768)  time: 0.6242  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [58]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.1796 (6.2006)  loss_classifier: 5.6689 (5.7289)  loss_box_reg: 0.2577 (0.2413)  loss_objectness: 0.1663 (0.1532)  loss_rpn_box_reg: 0.0775 (0.0772)  time: 0.6202  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [58]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.0760 (6.1955)  loss_classifier: 5.6689 (5.7249)  loss_box_reg: 0.2577 (0.2410)  loss_objectness: 0.1417 (0.1528)  loss_rpn_box_reg: 0.0723 (0.0768)  time: 0.6278  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [58]  [330/500]  eta: 0:01:45  lr: 0.000000  loss: 6.1461 (6.1987)  loss_classifier: 5.7210 (5.7289)  loss_box_reg: 0.2489 (0.2410)  loss_objectness: 0.1335 (0.1524)  loss_rpn_box_reg: 0.0585 (0.0765)  time: 0.6289  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [58]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.2533 (6.2038)  loss_classifier: 5.7782 (5.7345)  loss_box_reg: 0.2203 (0.2408)  loss_objectness: 0.1452 (0.1524)  loss_rpn_box_reg: 0.0625 (0.0761)  time: 0.6351  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [58]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.1491 (6.2028)  loss_classifier: 5.6251 (5.7347)  loss_box_reg: 0.2166 (0.2402)  loss_objectness: 0.1414 (0.1521)  loss_rpn_box_reg: 0.0626 (0.0759)  time: 0.6401  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [58]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1911 (6.2007)  loss_classifier: 5.7956 (5.7324)  loss_box_reg: 0.2066 (0.2401)  loss_objectness: 0.1375 (0.1521)  loss_rpn_box_reg: 0.0674 (0.0762)  time: 0.6168  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [58]  [370/500]  eta: 0:01:20  lr: 0.000000  loss: 6.1165 (6.1945)  loss_classifier: 5.6222 (5.7270)  loss_box_reg: 0.2191 (0.2399)  loss_objectness: 0.1381 (0.1519)  loss_rpn_box_reg: 0.0642 (0.0758)  time: 0.6104  data: 0.1311  max mem: 10734\n",
      "Training Epoch: [58]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.1604 (6.2029)  loss_classifier: 5.6412 (5.7344)  loss_box_reg: 0.2383 (0.2403)  loss_objectness: 0.1614 (0.1527)  loss_rpn_box_reg: 0.0610 (0.0754)  time: 0.6059  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [58]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.2807 (6.2038)  loss_classifier: 5.7763 (5.7344)  loss_box_reg: 0.2409 (0.2404)  loss_objectness: 0.1770 (0.1532)  loss_rpn_box_reg: 0.0723 (0.0758)  time: 0.6155  data: 0.1374  max mem: 10734\n",
      "Training Epoch: [58]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1806 (6.2030)  loss_classifier: 5.6559 (5.7330)  loss_box_reg: 0.2424 (0.2409)  loss_objectness: 0.1560 (0.1533)  loss_rpn_box_reg: 0.0744 (0.0758)  time: 0.6316  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [58]  [410/500]  eta: 0:00:55  lr: 0.000000  loss: 6.0721 (6.2028)  loss_classifier: 5.7491 (5.7338)  loss_box_reg: 0.2377 (0.2404)  loss_objectness: 0.1444 (0.1530)  loss_rpn_box_reg: 0.0676 (0.0756)  time: 0.6246  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [58]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 5.9943 (6.1978)  loss_classifier: 5.6089 (5.7291)  loss_box_reg: 0.2031 (0.2405)  loss_objectness: 0.1292 (0.1529)  loss_rpn_box_reg: 0.0531 (0.0753)  time: 0.6148  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [58]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 5.9943 (6.1968)  loss_classifier: 5.4673 (5.7292)  loss_box_reg: 0.2115 (0.2401)  loss_objectness: 0.1382 (0.1524)  loss_rpn_box_reg: 0.0563 (0.0752)  time: 0.6260  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [58]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2195 (6.1995)  loss_classifier: 5.7434 (5.7307)  loss_box_reg: 0.2574 (0.2407)  loss_objectness: 0.1501 (0.1528)  loss_rpn_box_reg: 0.0611 (0.0753)  time: 0.6371  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [58]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1714 (6.1946)  loss_classifier: 5.6748 (5.7260)  loss_box_reg: 0.2482 (0.2401)  loss_objectness: 0.1680 (0.1530)  loss_rpn_box_reg: 0.0756 (0.0755)  time: 0.6304  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [58]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.1687 (6.1974)  loss_classifier: 5.6450 (5.7289)  loss_box_reg: 0.2194 (0.2401)  loss_objectness: 0.1396 (0.1528)  loss_rpn_box_reg: 0.0764 (0.0757)  time: 0.6223  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [58]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2616 (6.2014)  loss_classifier: 5.8664 (5.7335)  loss_box_reg: 0.2115 (0.2395)  loss_objectness: 0.1412 (0.1526)  loss_rpn_box_reg: 0.0731 (0.0757)  time: 0.6218  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [58]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.3302 (6.2054)  loss_classifier: 5.8524 (5.7376)  loss_box_reg: 0.2318 (0.2396)  loss_objectness: 0.1351 (0.1525)  loss_rpn_box_reg: 0.0709 (0.0756)  time: 0.6280  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [58]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.3302 (6.2079)  loss_classifier: 5.8094 (5.7397)  loss_box_reg: 0.2561 (0.2397)  loss_objectness: 0.1499 (0.1526)  loss_rpn_box_reg: 0.0720 (0.0758)  time: 0.6221  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [58]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.4107 (6.2126)  loss_classifier: 5.8087 (5.7454)  loss_box_reg: 0.2160 (0.2391)  loss_objectness: 0.1479 (0.1524)  loss_rpn_box_reg: 0.0670 (0.0757)  time: 0.6279  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [58] Total time: 0:05:11 (0.6230 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:03  model_time: 0.7162 (0.7162)  evaluator_time: 0.0350 (0.0350)  time: 0.9872  data: 0.2261  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4431 (0.4528)  evaluator_time: 0.0330 (0.0384)  time: 0.6434  data: 0.1491  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4761 (0.4549)  evaluator_time: 0.0370 (0.0390)  time: 0.6760  data: 0.1654  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6465 s / it)\n",
      "Averaged stats: model_time: 0.4761 (0.4549)  evaluator_time: 0.0370 (0.0390)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.35s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [58]  [  0/125]  eta: 0:01:31  lr: 0.000000  loss: 6.1956 (6.1956)  loss_classifier: 5.6473 (5.6473)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1222 (0.1222)  loss_rpn_box_reg: 0.1315 (0.1315)  time: 0.7352  data: 0.1660  max mem: 10734\n",
      "Testing Epoch: [58]  [100/125]  eta: 0:00:15  lr: 0.000000  loss: 6.0077 (6.1370)  loss_classifier: 5.4184 (5.6285)  loss_box_reg: 0.2609 (0.2883)  loss_objectness: 0.1290 (0.1310)  loss_rpn_box_reg: 0.0709 (0.0892)  time: 0.6047  data: 0.1615  max mem: 10734\n",
      "Testing Epoch: [58]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1662 (6.1682)  loss_classifier: 5.6719 (5.6639)  loss_box_reg: 0.2500 (0.2839)  loss_objectness: 0.1195 (0.1310)  loss_rpn_box_reg: 0.0745 (0.0893)  time: 0.6308  data: 0.1730  max mem: 10734\n",
      "Testing Epoch: [58] Total time: 0:01:17 (0.6188 s / it)\n",
      "Training Epoch: [59]  [  0/500]  eta: 0:06:43  lr: 0.000000  loss: 6.5227 (6.5227)  loss_classifier: 6.1159 (6.1159)  loss_box_reg: 0.1899 (0.1899)  loss_objectness: 0.1356 (0.1356)  loss_rpn_box_reg: 0.0814 (0.0814)  time: 0.8072  data: 0.1490  max mem: 10734\n",
      "Training Epoch: [59]  [ 10/500]  eta: 0:05:38  lr: 0.000000  loss: 6.1872 (6.2527)  loss_classifier: 5.8238 (5.7999)  loss_box_reg: 0.2228 (0.2341)  loss_objectness: 0.1372 (0.1427)  loss_rpn_box_reg: 0.0610 (0.0759)  time: 0.6901  data: 0.1513  max mem: 10734\n",
      "Training Epoch: [59]  [ 20/500]  eta: 0:05:16  lr: 0.000000  loss: 6.3105 (6.4153)  loss_classifier: 5.8351 (5.9506)  loss_box_reg: 0.2260 (0.2397)  loss_objectness: 0.1372 (0.1449)  loss_rpn_box_reg: 0.0638 (0.0801)  time: 0.6524  data: 0.1541  max mem: 10734\n",
      "Training Epoch: [59]  [ 30/500]  eta: 0:05:04  lr: 0.000000  loss: 6.3736 (6.3462)  loss_classifier: 5.8775 (5.8832)  loss_box_reg: 0.2415 (0.2386)  loss_objectness: 0.1609 (0.1496)  loss_rpn_box_reg: 0.0590 (0.0749)  time: 0.6231  data: 0.1526  max mem: 10734\n",
      "Training Epoch: [59]  [ 40/500]  eta: 0:04:58  lr: 0.000000  loss: 6.3214 (6.3960)  loss_classifier: 5.8775 (5.9328)  loss_box_reg: 0.2316 (0.2351)  loss_objectness: 0.1643 (0.1544)  loss_rpn_box_reg: 0.0590 (0.0738)  time: 0.6363  data: 0.1541  max mem: 10734\n",
      "Training Epoch: [59]  [ 50/500]  eta: 0:04:50  lr: 0.000000  loss: 6.3115 (6.3556)  loss_classifier: 5.8394 (5.9024)  loss_box_reg: 0.2217 (0.2335)  loss_objectness: 0.1437 (0.1499)  loss_rpn_box_reg: 0.0609 (0.0697)  time: 0.6418  data: 0.1510  max mem: 10734\n",
      "Training Epoch: [59]  [ 60/500]  eta: 0:04:41  lr: 0.000000  loss: 6.3063 (6.3528)  loss_classifier: 5.8394 (5.8909)  loss_box_reg: 0.2217 (0.2365)  loss_objectness: 0.1388 (0.1538)  loss_rpn_box_reg: 0.0590 (0.0716)  time: 0.6235  data: 0.1415  max mem: 10734\n",
      "Training Epoch: [59]  [ 70/500]  eta: 0:04:33  lr: 0.000000  loss: 6.3208 (6.3534)  loss_classifier: 5.8437 (5.8847)  loss_box_reg: 0.2415 (0.2374)  loss_objectness: 0.1709 (0.1569)  loss_rpn_box_reg: 0.0757 (0.0744)  time: 0.6120  data: 0.1402  max mem: 10734\n",
      "Training Epoch: [59]  [ 80/500]  eta: 0:04:27  lr: 0.000000  loss: 6.3208 (6.3428)  loss_classifier: 5.7880 (5.8668)  loss_box_reg: 0.2438 (0.2401)  loss_objectness: 0.1709 (0.1591)  loss_rpn_box_reg: 0.0886 (0.0767)  time: 0.6247  data: 0.1410  max mem: 10734\n",
      "Training Epoch: [59]  [ 90/500]  eta: 0:04:21  lr: 0.000000  loss: 5.9916 (6.3004)  loss_classifier: 5.5324 (5.8255)  loss_box_reg: 0.2306 (0.2392)  loss_objectness: 0.1598 (0.1593)  loss_rpn_box_reg: 0.0757 (0.0764)  time: 0.6412  data: 0.1404  max mem: 10734\n",
      "Training Epoch: [59]  [100/500]  eta: 0:04:14  lr: 0.000000  loss: 6.0253 (6.2992)  loss_classifier: 5.5427 (5.8260)  loss_box_reg: 0.2141 (0.2381)  loss_objectness: 0.1436 (0.1585)  loss_rpn_box_reg: 0.0732 (0.0766)  time: 0.6380  data: 0.1375  max mem: 10734\n",
      "Training Epoch: [59]  [110/500]  eta: 0:04:06  lr: 0.000000  loss: 6.2652 (6.2995)  loss_classifier: 5.8149 (5.8281)  loss_box_reg: 0.2141 (0.2363)  loss_objectness: 0.1512 (0.1586)  loss_rpn_box_reg: 0.0766 (0.0765)  time: 0.6145  data: 0.1381  max mem: 10734\n",
      "Training Epoch: [59]  [120/500]  eta: 0:04:00  lr: 0.000000  loss: 6.3769 (6.3052)  loss_classifier: 5.8391 (5.8316)  loss_box_reg: 0.2290 (0.2371)  loss_objectness: 0.1542 (0.1590)  loss_rpn_box_reg: 0.0829 (0.0774)  time: 0.6080  data: 0.1411  max mem: 10734\n",
      "Training Epoch: [59]  [130/500]  eta: 0:03:53  lr: 0.000000  loss: 6.3692 (6.3080)  loss_classifier: 5.9295 (5.8334)  loss_box_reg: 0.2404 (0.2385)  loss_objectness: 0.1511 (0.1585)  loss_rpn_box_reg: 0.0749 (0.0776)  time: 0.6248  data: 0.1410  max mem: 10734\n",
      "Training Epoch: [59]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.3279 (6.2977)  loss_classifier: 5.8746 (5.8238)  loss_box_reg: 0.2372 (0.2382)  loss_objectness: 0.1402 (0.1584)  loss_rpn_box_reg: 0.0587 (0.0772)  time: 0.6211  data: 0.1384  max mem: 10734\n",
      "Training Epoch: [59]  [150/500]  eta: 0:03:41  lr: 0.000000  loss: 6.0759 (6.2881)  loss_classifier: 5.7195 (5.8148)  loss_box_reg: 0.2285 (0.2383)  loss_objectness: 0.1362 (0.1583)  loss_rpn_box_reg: 0.0655 (0.0766)  time: 0.6329  data: 0.1384  max mem: 10734\n",
      "Training Epoch: [59]  [160/500]  eta: 0:03:35  lr: 0.000000  loss: 6.0678 (6.2818)  loss_classifier: 5.6856 (5.8105)  loss_box_reg: 0.2146 (0.2370)  loss_objectness: 0.1438 (0.1573)  loss_rpn_box_reg: 0.0693 (0.0770)  time: 0.6489  data: 0.1379  max mem: 10734\n",
      "Training Epoch: [59]  [170/500]  eta: 0:03:29  lr: 0.000000  loss: 6.3171 (6.2942)  loss_classifier: 5.9221 (5.8288)  loss_box_reg: 0.1987 (0.2338)  loss_objectness: 0.1351 (0.1559)  loss_rpn_box_reg: 0.0575 (0.0756)  time: 0.6463  data: 0.1381  max mem: 10734\n",
      "Training Epoch: [59]  [180/500]  eta: 0:03:23  lr: 0.000000  loss: 6.4564 (6.2923)  loss_classifier: 6.0598 (5.8237)  loss_box_reg: 0.2095 (0.2358)  loss_objectness: 0.1494 (0.1564)  loss_rpn_box_reg: 0.0575 (0.0764)  time: 0.6501  data: 0.1409  max mem: 10734\n",
      "Training Epoch: [59]  [190/500]  eta: 0:03:16  lr: 0.000000  loss: 6.2077 (6.2908)  loss_classifier: 5.7379 (5.8229)  loss_box_reg: 0.2319 (0.2353)  loss_objectness: 0.1605 (0.1562)  loss_rpn_box_reg: 0.0708 (0.0764)  time: 0.6371  data: 0.1422  max mem: 10734\n",
      "Training Epoch: [59]  [200/500]  eta: 0:03:10  lr: 0.000000  loss: 6.1349 (6.2876)  loss_classifier: 5.6479 (5.8200)  loss_box_reg: 0.2255 (0.2350)  loss_objectness: 0.1573 (0.1562)  loss_rpn_box_reg: 0.0779 (0.0764)  time: 0.6254  data: 0.1396  max mem: 10734\n",
      "Training Epoch: [59]  [210/500]  eta: 0:03:03  lr: 0.000000  loss: 6.0469 (6.2786)  loss_classifier: 5.4740 (5.8083)  loss_box_reg: 0.2437 (0.2366)  loss_objectness: 0.1488 (0.1558)  loss_rpn_box_reg: 0.0882 (0.0779)  time: 0.6257  data: 0.1383  max mem: 10734\n",
      "Training Epoch: [59]  [220/500]  eta: 0:02:56  lr: 0.000000  loss: 5.8719 (6.2676)  loss_classifier: 5.4039 (5.7941)  loss_box_reg: 0.2788 (0.2395)  loss_objectness: 0.1488 (0.1556)  loss_rpn_box_reg: 0.0843 (0.0783)  time: 0.6061  data: 0.1383  max mem: 10734\n",
      "Training Epoch: [59]  [230/500]  eta: 0:02:50  lr: 0.000000  loss: 5.8455 (6.2564)  loss_classifier: 5.2975 (5.7841)  loss_box_reg: 0.2730 (0.2397)  loss_objectness: 0.1324 (0.1548)  loss_rpn_box_reg: 0.0680 (0.0778)  time: 0.6118  data: 0.1383  max mem: 10734\n",
      "Training Epoch: [59]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.1290 (6.2554)  loss_classifier: 5.7552 (5.7844)  loss_box_reg: 0.2078 (0.2391)  loss_objectness: 0.1405 (0.1545)  loss_rpn_box_reg: 0.0650 (0.0774)  time: 0.6226  data: 0.1378  max mem: 10734\n",
      "Training Epoch: [59]  [250/500]  eta: 0:02:37  lr: 0.000000  loss: 6.1694 (6.2512)  loss_classifier: 5.7068 (5.7819)  loss_box_reg: 0.1906 (0.2381)  loss_objectness: 0.1405 (0.1537)  loss_rpn_box_reg: 0.0657 (0.0774)  time: 0.6284  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [59]  [260/500]  eta: 0:02:31  lr: 0.000000  loss: 6.0989 (6.2496)  loss_classifier: 5.6965 (5.7806)  loss_box_reg: 0.1906 (0.2376)  loss_objectness: 0.1345 (0.1540)  loss_rpn_box_reg: 0.0694 (0.0774)  time: 0.6395  data: 0.1397  max mem: 10734\n",
      "Training Epoch: [59]  [270/500]  eta: 0:02:25  lr: 0.000000  loss: 6.0989 (6.2414)  loss_classifier: 5.6383 (5.7736)  loss_box_reg: 0.2119 (0.2370)  loss_objectness: 0.1602 (0.1539)  loss_rpn_box_reg: 0.0640 (0.0768)  time: 0.6338  data: 0.1403  max mem: 10734\n",
      "Training Epoch: [59]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.0613 (6.2404)  loss_classifier: 5.5951 (5.7733)  loss_box_reg: 0.2108 (0.2365)  loss_objectness: 0.1511 (0.1539)  loss_rpn_box_reg: 0.0643 (0.0767)  time: 0.6295  data: 0.1401  max mem: 10734\n",
      "Training Epoch: [59]  [290/500]  eta: 0:02:12  lr: 0.000000  loss: 6.0262 (6.2329)  loss_classifier: 5.5806 (5.7660)  loss_box_reg: 0.2161 (0.2365)  loss_objectness: 0.1456 (0.1535)  loss_rpn_box_reg: 0.0704 (0.0769)  time: 0.6346  data: 0.1389  max mem: 10734\n",
      "Training Epoch: [59]  [300/500]  eta: 0:02:06  lr: 0.000000  loss: 6.0011 (6.2291)  loss_classifier: 5.5863 (5.7625)  loss_box_reg: 0.2274 (0.2363)  loss_objectness: 0.1404 (0.1532)  loss_rpn_box_reg: 0.0749 (0.0771)  time: 0.6315  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [59]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.0668 (6.2248)  loss_classifier: 5.5863 (5.7580)  loss_box_reg: 0.2317 (0.2368)  loss_objectness: 0.1394 (0.1530)  loss_rpn_box_reg: 0.0692 (0.0770)  time: 0.6235  data: 0.1384  max mem: 10734\n",
      "Training Epoch: [59]  [320/500]  eta: 0:01:53  lr: 0.000000  loss: 6.0668 (6.2198)  loss_classifier: 5.5887 (5.7532)  loss_box_reg: 0.2317 (0.2365)  loss_objectness: 0.1490 (0.1529)  loss_rpn_box_reg: 0.0674 (0.0771)  time: 0.6190  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [59]  [330/500]  eta: 0:01:47  lr: 0.000000  loss: 6.0119 (6.2151)  loss_classifier: 5.5984 (5.7475)  loss_box_reg: 0.2394 (0.2369)  loss_objectness: 0.1480 (0.1531)  loss_rpn_box_reg: 0.0900 (0.0776)  time: 0.6126  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [59]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.1060 (6.2100)  loss_classifier: 5.6896 (5.7427)  loss_box_reg: 0.2504 (0.2369)  loss_objectness: 0.1439 (0.1530)  loss_rpn_box_reg: 0.0664 (0.0774)  time: 0.6313  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [59]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.2004 (6.2091)  loss_classifier: 5.7698 (5.7422)  loss_box_reg: 0.2384 (0.2369)  loss_objectness: 0.1436 (0.1531)  loss_rpn_box_reg: 0.0501 (0.0769)  time: 0.6332  data: 0.1393  max mem: 10734\n",
      "Training Epoch: [59]  [360/500]  eta: 0:01:28  lr: 0.000000  loss: 6.2215 (6.2140)  loss_classifier: 5.7698 (5.7467)  loss_box_reg: 0.2665 (0.2379)  loss_objectness: 0.1383 (0.1530)  loss_rpn_box_reg: 0.0482 (0.0765)  time: 0.6167  data: 0.1401  max mem: 10734\n",
      "Training Epoch: [59]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.0928 (6.2130)  loss_classifier: 5.5975 (5.7446)  loss_box_reg: 0.2577 (0.2381)  loss_objectness: 0.1400 (0.1533)  loss_rpn_box_reg: 0.0760 (0.0769)  time: 0.6193  data: 0.1404  max mem: 10734\n",
      "Training Epoch: [59]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1189 (6.2107)  loss_classifier: 5.5797 (5.7432)  loss_box_reg: 0.2260 (0.2375)  loss_objectness: 0.1497 (0.1531)  loss_rpn_box_reg: 0.0846 (0.0769)  time: 0.6296  data: 0.1395  max mem: 10734\n",
      "Training Epoch: [59]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 6.1867 (6.2140)  loss_classifier: 5.6880 (5.7452)  loss_box_reg: 0.2284 (0.2379)  loss_objectness: 0.1563 (0.1538)  loss_rpn_box_reg: 0.0736 (0.0770)  time: 0.6408  data: 0.1406  max mem: 10734\n",
      "Training Epoch: [59]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2778 (6.2132)  loss_classifier: 5.6806 (5.7441)  loss_box_reg: 0.2457 (0.2383)  loss_objectness: 0.1601 (0.1538)  loss_rpn_box_reg: 0.0706 (0.0770)  time: 0.6223  data: 0.1420  max mem: 10734\n",
      "Training Epoch: [59]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2778 (6.2175)  loss_classifier: 5.7720 (5.7481)  loss_box_reg: 0.2457 (0.2387)  loss_objectness: 0.1463 (0.1539)  loss_rpn_box_reg: 0.0658 (0.0769)  time: 0.6042  data: 0.1406  max mem: 10734\n",
      "Training Epoch: [59]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.1016 (6.2142)  loss_classifier: 5.5183 (5.7441)  loss_box_reg: 0.2511 (0.2391)  loss_objectness: 0.1606 (0.1542)  loss_rpn_box_reg: 0.0736 (0.0768)  time: 0.6128  data: 0.1412  max mem: 10734\n",
      "Training Epoch: [59]  [430/500]  eta: 0:00:44  lr: 0.000000  loss: 6.1016 (6.2168)  loss_classifier: 5.5769 (5.7463)  loss_box_reg: 0.2511 (0.2393)  loss_objectness: 0.1606 (0.1544)  loss_rpn_box_reg: 0.0736 (0.0767)  time: 0.6308  data: 0.1420  max mem: 10734\n",
      "Training Epoch: [59]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2625 (6.2127)  loss_classifier: 5.7658 (5.7422)  loss_box_reg: 0.2445 (0.2397)  loss_objectness: 0.1371 (0.1539)  loss_rpn_box_reg: 0.0743 (0.0768)  time: 0.6391  data: 0.1403  max mem: 10734\n",
      "Training Epoch: [59]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.2625 (6.2152)  loss_classifier: 5.7580 (5.7440)  loss_box_reg: 0.2578 (0.2406)  loss_objectness: 0.1330 (0.1537)  loss_rpn_box_reg: 0.0743 (0.0768)  time: 0.6291  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [59]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.1284 (6.2093)  loss_classifier: 5.6637 (5.7388)  loss_box_reg: 0.2330 (0.2401)  loss_objectness: 0.1455 (0.1539)  loss_rpn_box_reg: 0.0613 (0.0764)  time: 0.6362  data: 0.1397  max mem: 10734\n",
      "Training Epoch: [59]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0954 (6.2119)  loss_classifier: 5.6574 (5.7416)  loss_box_reg: 0.2145 (0.2401)  loss_objectness: 0.1539 (0.1539)  loss_rpn_box_reg: 0.0698 (0.0764)  time: 0.6415  data: 0.1414  max mem: 10734\n",
      "Training Epoch: [59]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1856 (6.2096)  loss_classifier: 5.6574 (5.7396)  loss_box_reg: 0.2122 (0.2400)  loss_objectness: 0.1328 (0.1537)  loss_rpn_box_reg: 0.0714 (0.0763)  time: 0.6341  data: 0.1374  max mem: 10734\n",
      "Training Epoch: [59]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0744 (6.2113)  loss_classifier: 5.5852 (5.7417)  loss_box_reg: 0.2133 (0.2399)  loss_objectness: 0.1345 (0.1536)  loss_rpn_box_reg: 0.0608 (0.0761)  time: 0.6363  data: 0.1391  max mem: 10734\n",
      "Training Epoch: [59]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2667 (6.2114)  loss_classifier: 5.7407 (5.7430)  loss_box_reg: 0.2174 (0.2391)  loss_objectness: 0.1470 (0.1535)  loss_rpn_box_reg: 0.0608 (0.0759)  time: 0.6369  data: 0.1403  max mem: 10734\n",
      "Training Epoch: [59] Total time: 0:05:14 (0.6296 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:58  model_time: 0.7562 (0.7562)  evaluator_time: 0.0350 (0.0350)  time: 0.9482  data: 0.1480  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4391 (0.4514)  evaluator_time: 0.0340 (0.0342)  time: 0.6330  data: 0.1483  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4721 (0.4531)  evaluator_time: 0.0350 (0.0351)  time: 0.6546  data: 0.1479  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6446 s / it)\n",
      "Averaged stats: model_time: 0.4721 (0.4531)  evaluator_time: 0.0350 (0.0351)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [59]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.1999 (6.1999)  loss_classifier: 5.6451 (5.6451)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1267 (0.1267)  loss_rpn_box_reg: 0.1336 (0.1336)  time: 0.6481  data: 0.1500  max mem: 10734\n",
      "Testing Epoch: [59]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9946 (6.1281)  loss_classifier: 5.4192 (5.6198)  loss_box_reg: 0.2609 (0.2886)  loss_objectness: 0.1265 (0.1306)  loss_rpn_box_reg: 0.0715 (0.0892)  time: 0.5859  data: 0.1453  max mem: 10734\n",
      "Testing Epoch: [59]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1697 (6.1606)  loss_classifier: 5.6787 (5.6561)  loss_box_reg: 0.2500 (0.2842)  loss_objectness: 0.1194 (0.1310)  loss_rpn_box_reg: 0.0745 (0.0894)  time: 0.5990  data: 0.1462  max mem: 10734\n",
      "Testing Epoch: [59] Total time: 0:01:14 (0.5953 s / it)\n",
      "Training Epoch: [60]  [  0/500]  eta: 0:06:42  lr: 0.000000  loss: 6.3906 (6.3906)  loss_classifier: 5.9371 (5.9371)  loss_box_reg: 0.2376 (0.2376)  loss_objectness: 0.1346 (0.1346)  loss_rpn_box_reg: 0.0812 (0.0812)  time: 0.8042  data: 0.1300  max mem: 10734\n",
      "Training Epoch: [60]  [ 10/500]  eta: 0:05:10  lr: 0.000000  loss: 6.3700 (6.2994)  loss_classifier: 5.8535 (5.8102)  loss_box_reg: 0.2376 (0.2346)  loss_objectness: 0.1637 (0.1708)  loss_rpn_box_reg: 0.0884 (0.0838)  time: 0.6335  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [60]  [ 20/500]  eta: 0:04:57  lr: 0.000000  loss: 6.3700 (6.3614)  loss_classifier: 5.8535 (5.8722)  loss_box_reg: 0.2402 (0.2379)  loss_objectness: 0.1675 (0.1698)  loss_rpn_box_reg: 0.0748 (0.0815)  time: 0.6111  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [60]  [ 30/500]  eta: 0:04:51  lr: 0.000000  loss: 6.3472 (6.3631)  loss_classifier: 5.8812 (5.8912)  loss_box_reg: 0.2392 (0.2348)  loss_objectness: 0.1521 (0.1585)  loss_rpn_box_reg: 0.0696 (0.0787)  time: 0.6130  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [60]  [ 40/500]  eta: 0:04:46  lr: 0.000000  loss: 6.1514 (6.2830)  loss_classifier: 5.7028 (5.8083)  loss_box_reg: 0.2392 (0.2373)  loss_objectness: 0.1382 (0.1578)  loss_rpn_box_reg: 0.0696 (0.0795)  time: 0.6262  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [60]  [ 50/500]  eta: 0:04:39  lr: 0.000000  loss: 6.0203 (6.2616)  loss_classifier: 5.5997 (5.7931)  loss_box_reg: 0.2408 (0.2371)  loss_objectness: 0.1404 (0.1527)  loss_rpn_box_reg: 0.0627 (0.0786)  time: 0.6234  data: 0.1315  max mem: 10734\n",
      "Training Epoch: [60]  [ 60/500]  eta: 0:04:33  lr: 0.000000  loss: 6.1320 (6.2530)  loss_classifier: 5.6619 (5.7816)  loss_box_reg: 0.2408 (0.2391)  loss_objectness: 0.1404 (0.1546)  loss_rpn_box_reg: 0.0627 (0.0777)  time: 0.6213  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [60]  [ 70/500]  eta: 0:04:28  lr: 0.000000  loss: 6.2060 (6.2412)  loss_classifier: 5.6947 (5.7721)  loss_box_reg: 0.2283 (0.2362)  loss_objectness: 0.1538 (0.1543)  loss_rpn_box_reg: 0.0738 (0.0786)  time: 0.6338  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [60]  [ 80/500]  eta: 0:04:22  lr: 0.000000  loss: 6.3028 (6.2615)  loss_classifier: 5.8011 (5.7878)  loss_box_reg: 0.2263 (0.2389)  loss_objectness: 0.1497 (0.1555)  loss_rpn_box_reg: 0.0750 (0.0794)  time: 0.6339  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [60]  [ 90/500]  eta: 0:04:16  lr: 0.000000  loss: 6.3360 (6.2489)  loss_classifier: 5.8124 (5.7756)  loss_box_reg: 0.2295 (0.2387)  loss_objectness: 0.1477 (0.1553)  loss_rpn_box_reg: 0.0728 (0.0793)  time: 0.6314  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [60]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 6.1536 (6.2279)  loss_classifier: 5.6871 (5.7589)  loss_box_reg: 0.2194 (0.2369)  loss_objectness: 0.1393 (0.1547)  loss_rpn_box_reg: 0.0628 (0.0773)  time: 0.6345  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [60]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.1410 (6.2285)  loss_classifier: 5.6871 (5.7637)  loss_box_reg: 0.2157 (0.2352)  loss_objectness: 0.1349 (0.1532)  loss_rpn_box_reg: 0.0592 (0.0764)  time: 0.6290  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [60]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.1558 (6.2275)  loss_classifier: 5.6988 (5.7629)  loss_box_reg: 0.2168 (0.2352)  loss_objectness: 0.1349 (0.1530)  loss_rpn_box_reg: 0.0682 (0.0764)  time: 0.6350  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [60]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 6.1265 (6.2372)  loss_classifier: 5.6245 (5.7716)  loss_box_reg: 0.2126 (0.2356)  loss_objectness: 0.1498 (0.1532)  loss_rpn_box_reg: 0.0729 (0.0768)  time: 0.6309  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [60]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.0940 (6.2220)  loss_classifier: 5.5894 (5.7553)  loss_box_reg: 0.2117 (0.2356)  loss_objectness: 0.1466 (0.1528)  loss_rpn_box_reg: 0.0729 (0.0783)  time: 0.6318  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [60]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 5.9235 (6.2161)  loss_classifier: 5.5503 (5.7519)  loss_box_reg: 0.2317 (0.2349)  loss_objectness: 0.1386 (0.1516)  loss_rpn_box_reg: 0.0724 (0.0777)  time: 0.6396  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [60]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.1595 (6.2124)  loss_classifier: 5.6634 (5.7489)  loss_box_reg: 0.2317 (0.2348)  loss_objectness: 0.1464 (0.1517)  loss_rpn_box_reg: 0.0571 (0.0770)  time: 0.6282  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [60]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.1084 (6.2062)  loss_classifier: 5.6571 (5.7439)  loss_box_reg: 0.2236 (0.2342)  loss_objectness: 0.1479 (0.1516)  loss_rpn_box_reg: 0.0563 (0.0766)  time: 0.6228  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [60]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.1084 (6.2123)  loss_classifier: 5.6571 (5.7492)  loss_box_reg: 0.2453 (0.2353)  loss_objectness: 0.1511 (0.1520)  loss_rpn_box_reg: 0.0570 (0.0757)  time: 0.6178  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [60]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.0765 (6.2109)  loss_classifier: 5.5818 (5.7485)  loss_box_reg: 0.2465 (0.2353)  loss_objectness: 0.1620 (0.1522)  loss_rpn_box_reg: 0.0569 (0.0748)  time: 0.6132  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [60]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.2678 (6.2183)  loss_classifier: 5.7458 (5.7537)  loss_box_reg: 0.2342 (0.2365)  loss_objectness: 0.1620 (0.1532)  loss_rpn_box_reg: 0.0581 (0.0749)  time: 0.6235  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [60]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.4388 (6.2276)  loss_classifier: 5.9351 (5.7646)  loss_box_reg: 0.2227 (0.2346)  loss_objectness: 0.1609 (0.1537)  loss_rpn_box_reg: 0.0730 (0.0746)  time: 0.6400  data: 0.1380  max mem: 10734\n",
      "Training Epoch: [60]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.2752 (6.2318)  loss_classifier: 5.7486 (5.7670)  loss_box_reg: 0.2122 (0.2356)  loss_objectness: 0.1603 (0.1543)  loss_rpn_box_reg: 0.0730 (0.0748)  time: 0.6252  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [60]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.2752 (6.2370)  loss_classifier: 5.8032 (5.7724)  loss_box_reg: 0.2244 (0.2357)  loss_objectness: 0.1504 (0.1538)  loss_rpn_box_reg: 0.0694 (0.0750)  time: 0.6110  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [60]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.0663 (6.2219)  loss_classifier: 5.5780 (5.7589)  loss_box_reg: 0.2090 (0.2355)  loss_objectness: 0.1350 (0.1530)  loss_rpn_box_reg: 0.0640 (0.0745)  time: 0.6226  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [60]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.0287 (6.2221)  loss_classifier: 5.5780 (5.7584)  loss_box_reg: 0.2211 (0.2358)  loss_objectness: 0.1357 (0.1530)  loss_rpn_box_reg: 0.0618 (0.0747)  time: 0.6154  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [60]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.1272 (6.2184)  loss_classifier: 5.6531 (5.7512)  loss_box_reg: 0.2572 (0.2379)  loss_objectness: 0.1547 (0.1534)  loss_rpn_box_reg: 0.0832 (0.0759)  time: 0.6073  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [60]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.1894 (6.2245)  loss_classifier: 5.6280 (5.7563)  loss_box_reg: 0.2531 (0.2379)  loss_objectness: 0.1587 (0.1540)  loss_rpn_box_reg: 0.0943 (0.0763)  time: 0.6315  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [60]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.0085 (6.2183)  loss_classifier: 5.5747 (5.7503)  loss_box_reg: 0.2185 (0.2375)  loss_objectness: 0.1587 (0.1540)  loss_rpn_box_reg: 0.0824 (0.0765)  time: 0.6291  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [60]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 5.9547 (6.2152)  loss_classifier: 5.4076 (5.7475)  loss_box_reg: 0.2322 (0.2379)  loss_objectness: 0.1444 (0.1534)  loss_rpn_box_reg: 0.0824 (0.0765)  time: 0.6131  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [60]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.0999 (6.2141)  loss_classifier: 5.6502 (5.7469)  loss_box_reg: 0.2424 (0.2374)  loss_objectness: 0.1383 (0.1532)  loss_rpn_box_reg: 0.0806 (0.0766)  time: 0.6157  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [60]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 5.9799 (6.2095)  loss_classifier: 5.5585 (5.7422)  loss_box_reg: 0.2487 (0.2380)  loss_objectness: 0.1350 (0.1531)  loss_rpn_box_reg: 0.0590 (0.0762)  time: 0.6258  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [60]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.3463 (6.2141)  loss_classifier: 5.8178 (5.7483)  loss_box_reg: 0.2426 (0.2373)  loss_objectness: 0.1359 (0.1530)  loss_rpn_box_reg: 0.0537 (0.0755)  time: 0.6288  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [60]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.3463 (6.2143)  loss_classifier: 5.8178 (5.7484)  loss_box_reg: 0.2298 (0.2367)  loss_objectness: 0.1479 (0.1534)  loss_rpn_box_reg: 0.0634 (0.0758)  time: 0.6231  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [60]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.0757 (6.2139)  loss_classifier: 5.6902 (5.7474)  loss_box_reg: 0.2168 (0.2368)  loss_objectness: 0.1554 (0.1537)  loss_rpn_box_reg: 0.0709 (0.0760)  time: 0.6267  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [60]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.2345 (6.2172)  loss_classifier: 5.7740 (5.7515)  loss_box_reg: 0.2276 (0.2364)  loss_objectness: 0.1388 (0.1533)  loss_rpn_box_reg: 0.0582 (0.0760)  time: 0.6278  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [60]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.2345 (6.2185)  loss_classifier: 5.8038 (5.7532)  loss_box_reg: 0.2276 (0.2362)  loss_objectness: 0.1378 (0.1533)  loss_rpn_box_reg: 0.0598 (0.0757)  time: 0.6237  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [60]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1777 (6.2186)  loss_classifier: 5.7429 (5.7533)  loss_box_reg: 0.2113 (0.2360)  loss_objectness: 0.1560 (0.1536)  loss_rpn_box_reg: 0.0705 (0.0758)  time: 0.6169  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [60]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.1986 (6.2186)  loss_classifier: 5.7956 (5.7543)  loss_box_reg: 0.1965 (0.2352)  loss_objectness: 0.1518 (0.1536)  loss_rpn_box_reg: 0.0705 (0.0755)  time: 0.6136  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [60]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1912 (6.2193)  loss_classifier: 5.8278 (5.7560)  loss_box_reg: 0.2148 (0.2348)  loss_objectness: 0.1369 (0.1533)  loss_rpn_box_reg: 0.0644 (0.0751)  time: 0.6183  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [60]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2355 (6.2204)  loss_classifier: 5.7968 (5.7572)  loss_box_reg: 0.2249 (0.2350)  loss_objectness: 0.1487 (0.1534)  loss_rpn_box_reg: 0.0589 (0.0749)  time: 0.6332  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [60]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2733 (6.2209)  loss_classifier: 5.8276 (5.7572)  loss_box_reg: 0.2394 (0.2356)  loss_objectness: 0.1487 (0.1534)  loss_rpn_box_reg: 0.0618 (0.0748)  time: 0.6415  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [60]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.1994 (6.2177)  loss_classifier: 5.6420 (5.7533)  loss_box_reg: 0.2420 (0.2355)  loss_objectness: 0.1693 (0.1538)  loss_rpn_box_reg: 0.0704 (0.0751)  time: 0.6390  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [60]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 5.9835 (6.2128)  loss_classifier: 5.5561 (5.7496)  loss_box_reg: 0.2290 (0.2351)  loss_objectness: 0.1489 (0.1533)  loss_rpn_box_reg: 0.0635 (0.0748)  time: 0.6375  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [60]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2523 (6.2164)  loss_classifier: 5.8938 (5.7520)  loss_box_reg: 0.2307 (0.2355)  loss_objectness: 0.1512 (0.1535)  loss_rpn_box_reg: 0.0688 (0.0754)  time: 0.6454  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [60]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.3841 (6.2189)  loss_classifier: 5.9035 (5.7547)  loss_box_reg: 0.2307 (0.2353)  loss_objectness: 0.1512 (0.1534)  loss_rpn_box_reg: 0.0795 (0.0755)  time: 0.6278  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [60]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.3698 (6.2213)  loss_classifier: 5.7664 (5.7553)  loss_box_reg: 0.2284 (0.2358)  loss_objectness: 0.1514 (0.1542)  loss_rpn_box_reg: 0.0767 (0.0759)  time: 0.6074  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [60]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2771 (6.2225)  loss_classifier: 5.7620 (5.7564)  loss_box_reg: 0.2294 (0.2358)  loss_objectness: 0.1514 (0.1542)  loss_rpn_box_reg: 0.0970 (0.0761)  time: 0.6100  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [60]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1992 (6.2177)  loss_classifier: 5.5712 (5.7513)  loss_box_reg: 0.2411 (0.2366)  loss_objectness: 0.1400 (0.1539)  loss_rpn_box_reg: 0.0728 (0.0759)  time: 0.6127  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [60]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0645 (6.2184)  loss_classifier: 5.5712 (5.7525)  loss_box_reg: 0.2224 (0.2358)  loss_objectness: 0.1393 (0.1540)  loss_rpn_box_reg: 0.0695 (0.0761)  time: 0.6326  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [60]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2256 (6.2179)  loss_classifier: 5.8122 (5.7520)  loss_box_reg: 0.1960 (0.2356)  loss_objectness: 0.1488 (0.1540)  loss_rpn_box_reg: 0.0799 (0.0763)  time: 0.6311  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [60] Total time: 0:05:12 (0.6255 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:45  model_time: 0.6551 (0.6551)  evaluator_time: 0.0340 (0.0340)  time: 0.8412  data: 0.1430  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4371 (0.4501)  evaluator_time: 0.0340 (0.0362)  time: 0.6306  data: 0.1484  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4691 (0.4518)  evaluator_time: 0.0360 (0.0378)  time: 0.6532  data: 0.1417  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6401 s / it)\n",
      "Averaged stats: model_time: 0.4691 (0.4518)  evaluator_time: 0.0360 (0.0378)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.28s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [60]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.2047 (6.2047)  loss_classifier: 5.6516 (5.6516)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1265 (0.1265)  loss_rpn_box_reg: 0.1321 (0.1321)  time: 0.6441  data: 0.1430  max mem: 10734\n",
      "Testing Epoch: [60]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0023 (6.1347)  loss_classifier: 5.4061 (5.6220)  loss_box_reg: 0.2609 (0.2893)  loss_objectness: 0.1291 (0.1324)  loss_rpn_box_reg: 0.0694 (0.0910)  time: 0.5871  data: 0.1460  max mem: 10734\n",
      "Testing Epoch: [60]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1740 (6.1659)  loss_classifier: 5.6887 (5.6584)  loss_box_reg: 0.2500 (0.2847)  loss_objectness: 0.1197 (0.1321)  loss_rpn_box_reg: 0.0745 (0.0908)  time: 0.6001  data: 0.1466  max mem: 10734\n",
      "Testing Epoch: [60] Total time: 0:01:14 (0.5975 s / it)\n",
      "Training Epoch: [61]  [  0/500]  eta: 0:06:22  lr: 0.000000  loss: 6.3564 (6.3564)  loss_classifier: 5.8543 (5.8543)  loss_box_reg: 0.3023 (0.3023)  loss_objectness: 0.1413 (0.1413)  loss_rpn_box_reg: 0.0586 (0.0586)  time: 0.7652  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [61]  [ 10/500]  eta: 0:05:13  lr: 0.000000  loss: 6.2201 (6.3216)  loss_classifier: 5.7045 (5.8709)  loss_box_reg: 0.2278 (0.2331)  loss_objectness: 0.1413 (0.1480)  loss_rpn_box_reg: 0.0611 (0.0698)  time: 0.6391  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [61]  [ 20/500]  eta: 0:05:00  lr: 0.000000  loss: 6.0772 (6.2810)  loss_classifier: 5.6754 (5.8132)  loss_box_reg: 0.2278 (0.2405)  loss_objectness: 0.1592 (0.1534)  loss_rpn_box_reg: 0.0723 (0.0739)  time: 0.6201  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [61]  [ 30/500]  eta: 0:04:55  lr: 0.000000  loss: 5.9453 (6.1655)  loss_classifier: 5.4453 (5.7080)  loss_box_reg: 0.2305 (0.2357)  loss_objectness: 0.1469 (0.1499)  loss_rpn_box_reg: 0.0723 (0.0719)  time: 0.6245  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [61]  [ 40/500]  eta: 0:04:46  lr: 0.000000  loss: 5.9126 (6.1705)  loss_classifier: 5.4477 (5.7119)  loss_box_reg: 0.2270 (0.2363)  loss_objectness: 0.1453 (0.1512)  loss_rpn_box_reg: 0.0532 (0.0711)  time: 0.6179  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [61]  [ 50/500]  eta: 0:04:39  lr: 0.000000  loss: 6.1214 (6.1671)  loss_classifier: 5.5475 (5.7002)  loss_box_reg: 0.2458 (0.2385)  loss_objectness: 0.1649 (0.1575)  loss_rpn_box_reg: 0.0609 (0.0708)  time: 0.6088  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [61]  [ 60/500]  eta: 0:04:30  lr: 0.000000  loss: 6.1427 (6.1908)  loss_classifier: 5.7142 (5.7322)  loss_box_reg: 0.2385 (0.2332)  loss_objectness: 0.1376 (0.1535)  loss_rpn_box_reg: 0.0713 (0.0719)  time: 0.6019  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [61]  [ 70/500]  eta: 0:04:25  lr: 0.000000  loss: 6.1436 (6.1991)  loss_classifier: 5.7399 (5.7376)  loss_box_reg: 0.2082 (0.2339)  loss_objectness: 0.1411 (0.1559)  loss_rpn_box_reg: 0.0622 (0.0717)  time: 0.6037  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [61]  [ 80/500]  eta: 0:04:18  lr: 0.000000  loss: 6.2774 (6.2083)  loss_classifier: 5.9108 (5.7446)  loss_box_reg: 0.2292 (0.2340)  loss_objectness: 0.1586 (0.1572)  loss_rpn_box_reg: 0.0696 (0.0725)  time: 0.6161  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [61]  [ 90/500]  eta: 0:04:13  lr: 0.000000  loss: 6.2568 (6.2073)  loss_classifier: 5.7826 (5.7425)  loss_box_reg: 0.2289 (0.2360)  loss_objectness: 0.1538 (0.1563)  loss_rpn_box_reg: 0.0696 (0.0725)  time: 0.6251  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [61]  [100/500]  eta: 0:04:07  lr: 0.000000  loss: 6.2513 (6.2109)  loss_classifier: 5.7142 (5.7444)  loss_box_reg: 0.2320 (0.2365)  loss_objectness: 0.1361 (0.1557)  loss_rpn_box_reg: 0.0784 (0.0744)  time: 0.6323  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [61]  [110/500]  eta: 0:04:01  lr: 0.000000  loss: 6.2258 (6.2089)  loss_classifier: 5.7196 (5.7433)  loss_box_reg: 0.2112 (0.2346)  loss_objectness: 0.1525 (0.1557)  loss_rpn_box_reg: 0.0792 (0.0754)  time: 0.6274  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [61]  [120/500]  eta: 0:03:54  lr: 0.000000  loss: 6.2258 (6.2162)  loss_classifier: 5.7249 (5.7468)  loss_box_reg: 0.2294 (0.2374)  loss_objectness: 0.1563 (0.1564)  loss_rpn_box_reg: 0.0729 (0.0757)  time: 0.6125  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [61]  [130/500]  eta: 0:03:49  lr: 0.000000  loss: 6.2898 (6.2325)  loss_classifier: 5.8407 (5.7666)  loss_box_reg: 0.2173 (0.2345)  loss_objectness: 0.1553 (0.1560)  loss_rpn_box_reg: 0.0698 (0.0754)  time: 0.6171  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [61]  [140/500]  eta: 0:03:42  lr: 0.000000  loss: 6.1210 (6.2154)  loss_classifier: 5.6193 (5.7510)  loss_box_reg: 0.2125 (0.2336)  loss_objectness: 0.1347 (0.1552)  loss_rpn_box_reg: 0.0698 (0.0755)  time: 0.6244  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [61]  [150/500]  eta: 0:03:36  lr: 0.000000  loss: 6.0804 (6.2202)  loss_classifier: 5.6182 (5.7522)  loss_box_reg: 0.2372 (0.2358)  loss_objectness: 0.1643 (0.1566)  loss_rpn_box_reg: 0.0685 (0.0755)  time: 0.6073  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [61]  [160/500]  eta: 0:03:30  lr: 0.000000  loss: 6.1344 (6.2197)  loss_classifier: 5.6953 (5.7494)  loss_box_reg: 0.2595 (0.2378)  loss_objectness: 0.1643 (0.1562)  loss_rpn_box_reg: 0.0823 (0.0763)  time: 0.6092  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [61]  [170/500]  eta: 0:03:24  lr: 0.000000  loss: 6.2814 (6.2180)  loss_classifier: 5.8301 (5.7479)  loss_box_reg: 0.2438 (0.2378)  loss_objectness: 0.1471 (0.1561)  loss_rpn_box_reg: 0.0884 (0.0761)  time: 0.6226  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [61]  [180/500]  eta: 0:03:17  lr: 0.000000  loss: 6.0478 (6.2113)  loss_classifier: 5.6461 (5.7416)  loss_box_reg: 0.2331 (0.2376)  loss_objectness: 0.1569 (0.1566)  loss_rpn_box_reg: 0.0693 (0.0755)  time: 0.6137  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [61]  [190/500]  eta: 0:03:11  lr: 0.000000  loss: 6.0089 (6.2050)  loss_classifier: 5.6001 (5.7366)  loss_box_reg: 0.2439 (0.2376)  loss_objectness: 0.1569 (0.1561)  loss_rpn_box_reg: 0.0642 (0.0748)  time: 0.6021  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [61]  [200/500]  eta: 0:03:05  lr: 0.000000  loss: 6.0361 (6.2040)  loss_classifier: 5.6302 (5.7347)  loss_box_reg: 0.2521 (0.2393)  loss_objectness: 0.1393 (0.1554)  loss_rpn_box_reg: 0.0609 (0.0747)  time: 0.6284  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [61]  [210/500]  eta: 0:02:59  lr: 0.000000  loss: 5.9923 (6.1948)  loss_classifier: 5.5341 (5.7247)  loss_box_reg: 0.2527 (0.2401)  loss_objectness: 0.1417 (0.1550)  loss_rpn_box_reg: 0.0739 (0.0750)  time: 0.6483  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [61]  [220/500]  eta: 0:02:53  lr: 0.000000  loss: 5.9923 (6.1912)  loss_classifier: 5.5051 (5.7190)  loss_box_reg: 0.2551 (0.2412)  loss_objectness: 0.1590 (0.1552)  loss_rpn_box_reg: 0.0843 (0.0758)  time: 0.6433  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [61]  [230/500]  eta: 0:02:47  lr: 0.000000  loss: 6.1452 (6.1854)  loss_classifier: 5.5051 (5.7129)  loss_box_reg: 0.2492 (0.2412)  loss_objectness: 0.1598 (0.1552)  loss_rpn_box_reg: 0.0865 (0.0761)  time: 0.6181  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [61]  [240/500]  eta: 0:02:41  lr: 0.000000  loss: 6.3249 (6.2030)  loss_classifier: 5.9201 (5.7313)  loss_box_reg: 0.2151 (0.2408)  loss_objectness: 0.1578 (0.1552)  loss_rpn_box_reg: 0.0762 (0.0757)  time: 0.6094  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [61]  [250/500]  eta: 0:02:35  lr: 0.000000  loss: 6.4391 (6.2114)  loss_classifier: 6.0133 (5.7409)  loss_box_reg: 0.2138 (0.2403)  loss_objectness: 0.1403 (0.1544)  loss_rpn_box_reg: 0.0694 (0.0757)  time: 0.6286  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [61]  [260/500]  eta: 0:02:28  lr: 0.000000  loss: 6.3332 (6.2118)  loss_classifier: 5.8395 (5.7397)  loss_box_reg: 0.2380 (0.2411)  loss_objectness: 0.1514 (0.1551)  loss_rpn_box_reg: 0.0740 (0.0759)  time: 0.6321  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [61]  [270/500]  eta: 0:02:22  lr: 0.000000  loss: 6.3234 (6.2152)  loss_classifier: 5.8395 (5.7433)  loss_box_reg: 0.2410 (0.2403)  loss_objectness: 0.1634 (0.1550)  loss_rpn_box_reg: 0.0740 (0.0765)  time: 0.6248  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [61]  [280/500]  eta: 0:02:16  lr: 0.000000  loss: 6.2534 (6.2171)  loss_classifier: 5.8962 (5.7458)  loss_box_reg: 0.2216 (0.2404)  loss_objectness: 0.1385 (0.1543)  loss_rpn_box_reg: 0.0737 (0.0766)  time: 0.6268  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [61]  [290/500]  eta: 0:02:10  lr: 0.000000  loss: 6.1550 (6.2186)  loss_classifier: 5.7726 (5.7479)  loss_box_reg: 0.2216 (0.2399)  loss_objectness: 0.1384 (0.1542)  loss_rpn_box_reg: 0.0715 (0.0766)  time: 0.6239  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [61]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.1744 (6.2251)  loss_classifier: 5.7726 (5.7540)  loss_box_reg: 0.2305 (0.2404)  loss_objectness: 0.1405 (0.1539)  loss_rpn_box_reg: 0.0715 (0.0767)  time: 0.6138  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [61]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.1744 (6.2223)  loss_classifier: 5.6384 (5.7512)  loss_box_reg: 0.2465 (0.2406)  loss_objectness: 0.1488 (0.1542)  loss_rpn_box_reg: 0.0677 (0.0763)  time: 0.6239  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [61]  [320/500]  eta: 0:01:51  lr: 0.000000  loss: 6.2195 (6.2235)  loss_classifier: 5.7276 (5.7512)  loss_box_reg: 0.2648 (0.2412)  loss_objectness: 0.1597 (0.1547)  loss_rpn_box_reg: 0.0595 (0.0764)  time: 0.6246  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [61]  [330/500]  eta: 0:01:45  lr: 0.000000  loss: 6.2407 (6.2258)  loss_classifier: 5.7400 (5.7539)  loss_box_reg: 0.2541 (0.2414)  loss_objectness: 0.1371 (0.1546)  loss_rpn_box_reg: 0.0598 (0.0761)  time: 0.6159  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [61]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.3345 (6.2286)  loss_classifier: 5.8452 (5.7572)  loss_box_reg: 0.2517 (0.2415)  loss_objectness: 0.1323 (0.1542)  loss_rpn_box_reg: 0.0601 (0.0757)  time: 0.6121  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [61]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.3345 (6.2286)  loss_classifier: 5.7826 (5.7583)  loss_box_reg: 0.2525 (0.2407)  loss_objectness: 0.1293 (0.1541)  loss_rpn_box_reg: 0.0601 (0.0755)  time: 0.6108  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [61]  [360/500]  eta: 0:01:26  lr: 0.000000  loss: 5.9841 (6.2210)  loss_classifier: 5.6513 (5.7522)  loss_box_reg: 0.2339 (0.2404)  loss_objectness: 0.1203 (0.1534)  loss_rpn_box_reg: 0.0550 (0.0751)  time: 0.6265  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [61]  [370/500]  eta: 0:01:20  lr: 0.000000  loss: 6.0369 (6.2204)  loss_classifier: 5.5334 (5.7512)  loss_box_reg: 0.2270 (0.2399)  loss_objectness: 0.1460 (0.1537)  loss_rpn_box_reg: 0.0669 (0.0755)  time: 0.6320  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [61]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.3146 (6.2249)  loss_classifier: 5.6868 (5.7561)  loss_box_reg: 0.2207 (0.2398)  loss_objectness: 0.1390 (0.1533)  loss_rpn_box_reg: 0.0728 (0.0757)  time: 0.6260  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [61]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1030 (6.2222)  loss_classifier: 5.6626 (5.7538)  loss_box_reg: 0.2267 (0.2396)  loss_objectness: 0.1342 (0.1532)  loss_rpn_box_reg: 0.0777 (0.0756)  time: 0.6290  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [61]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1030 (6.2233)  loss_classifier: 5.7335 (5.7552)  loss_box_reg: 0.2379 (0.2399)  loss_objectness: 0.1464 (0.1531)  loss_rpn_box_reg: 0.0580 (0.0751)  time: 0.6282  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [61]  [410/500]  eta: 0:00:55  lr: 0.000000  loss: 6.2681 (6.2253)  loss_classifier: 5.8168 (5.7574)  loss_box_reg: 0.2543 (0.2395)  loss_objectness: 0.1480 (0.1530)  loss_rpn_box_reg: 0.0615 (0.0753)  time: 0.6347  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [61]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1192 (6.2227)  loss_classifier: 5.6210 (5.7547)  loss_box_reg: 0.2598 (0.2396)  loss_objectness: 0.1448 (0.1528)  loss_rpn_box_reg: 0.0823 (0.0755)  time: 0.6363  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [61]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.0876 (6.2195)  loss_classifier: 5.5906 (5.7502)  loss_box_reg: 0.2781 (0.2406)  loss_objectness: 0.1430 (0.1530)  loss_rpn_box_reg: 0.0785 (0.0757)  time: 0.6266  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [61]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1147 (6.2185)  loss_classifier: 5.6820 (5.7502)  loss_box_reg: 0.2128 (0.2398)  loss_objectness: 0.1458 (0.1529)  loss_rpn_box_reg: 0.0731 (0.0756)  time: 0.6194  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [61]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.3409 (6.2223)  loss_classifier: 5.8209 (5.7543)  loss_box_reg: 0.2016 (0.2395)  loss_objectness: 0.1345 (0.1528)  loss_rpn_box_reg: 0.0731 (0.0758)  time: 0.6273  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [61]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.1153 (6.2178)  loss_classifier: 5.7360 (5.7497)  loss_box_reg: 0.2307 (0.2396)  loss_objectness: 0.1445 (0.1528)  loss_rpn_box_reg: 0.0731 (0.0756)  time: 0.6314  data: 0.1380  max mem: 10734\n",
      "Training Epoch: [61]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0355 (6.2187)  loss_classifier: 5.5246 (5.7517)  loss_box_reg: 0.2188 (0.2384)  loss_objectness: 0.1549 (0.1529)  loss_rpn_box_reg: 0.0683 (0.0757)  time: 0.6247  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [61]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1156 (6.2179)  loss_classifier: 5.6476 (5.7503)  loss_box_reg: 0.1974 (0.2385)  loss_objectness: 0.1656 (0.1533)  loss_rpn_box_reg: 0.0621 (0.0758)  time: 0.6178  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [61]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0759 (6.2129)  loss_classifier: 5.5855 (5.7453)  loss_box_reg: 0.2273 (0.2384)  loss_objectness: 0.1481 (0.1532)  loss_rpn_box_reg: 0.0807 (0.0759)  time: 0.6122  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [61]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0487 (6.2114)  loss_classifier: 5.5671 (5.7438)  loss_box_reg: 0.2339 (0.2384)  loss_objectness: 0.1473 (0.1534)  loss_rpn_box_reg: 0.0807 (0.0759)  time: 0.6211  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [61] Total time: 0:05:11 (0.6222 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:47  model_time: 0.6742 (0.6742)  evaluator_time: 0.0340 (0.0340)  time: 0.8582  data: 0.1410  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4461 (0.4530)  evaluator_time: 0.0340 (0.0369)  time: 0.6419  data: 0.1544  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4691 (0.4550)  evaluator_time: 0.0360 (0.0373)  time: 0.6582  data: 0.1484  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6426 s / it)\n",
      "Averaged stats: model_time: 0.4691 (0.4550)  evaluator_time: 0.0360 (0.0373)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [61]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.2034 (6.2034)  loss_classifier: 5.6520 (5.6520)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1268 (0.1268)  loss_rpn_box_reg: 0.1301 (0.1301)  time: 0.6441  data: 0.1440  max mem: 10734\n",
      "Testing Epoch: [61]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0049 (6.1375)  loss_classifier: 5.4248 (5.6258)  loss_box_reg: 0.2609 (0.2903)  loss_objectness: 0.1301 (0.1312)  loss_rpn_box_reg: 0.0725 (0.0902)  time: 0.5848  data: 0.1458  max mem: 10734\n",
      "Testing Epoch: [61]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1413 (6.1682)  loss_classifier: 5.6918 (5.6613)  loss_box_reg: 0.2500 (0.2855)  loss_objectness: 0.1182 (0.1312)  loss_rpn_box_reg: 0.0745 (0.0902)  time: 0.5947  data: 0.1414  max mem: 10734\n",
      "Testing Epoch: [61] Total time: 0:01:14 (0.5960 s / it)\n",
      "Training Epoch: [62]  [  0/500]  eta: 0:05:53  lr: 0.000000  loss: 6.0819 (6.0819)  loss_classifier: 5.5892 (5.5892)  loss_box_reg: 0.2407 (0.2407)  loss_objectness: 0.1607 (0.1607)  loss_rpn_box_reg: 0.0914 (0.0914)  time: 0.7072  data: 0.1430  max mem: 10734\n",
      "Training Epoch: [62]  [ 10/500]  eta: 0:04:59  lr: 0.000000  loss: 6.3524 (6.3729)  loss_classifier: 5.7938 (5.8875)  loss_box_reg: 0.2270 (0.2538)  loss_objectness: 0.1510 (0.1646)  loss_rpn_box_reg: 0.0583 (0.0670)  time: 0.6107  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [62]  [ 20/500]  eta: 0:04:57  lr: 0.000000  loss: 6.1922 (6.3300)  loss_classifier: 5.7040 (5.8572)  loss_box_reg: 0.2266 (0.2453)  loss_objectness: 0.1423 (0.1564)  loss_rpn_box_reg: 0.0685 (0.0710)  time: 0.6153  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [62]  [ 30/500]  eta: 0:04:51  lr: 0.000000  loss: 6.3508 (6.3702)  loss_classifier: 5.8825 (5.8921)  loss_box_reg: 0.2438 (0.2521)  loss_objectness: 0.1386 (0.1541)  loss_rpn_box_reg: 0.0693 (0.0720)  time: 0.6264  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [62]  [ 40/500]  eta: 0:04:42  lr: 0.000000  loss: 6.3254 (6.3028)  loss_classifier: 5.8233 (5.8228)  loss_box_reg: 0.2434 (0.2513)  loss_objectness: 0.1477 (0.1537)  loss_rpn_box_reg: 0.0679 (0.0750)  time: 0.6090  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [62]  [ 50/500]  eta: 0:04:36  lr: 0.000000  loss: 6.1748 (6.3075)  loss_classifier: 5.7216 (5.8350)  loss_box_reg: 0.2402 (0.2473)  loss_objectness: 0.1401 (0.1504)  loss_rpn_box_reg: 0.0697 (0.0748)  time: 0.6052  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [62]  [ 60/500]  eta: 0:04:32  lr: 0.000000  loss: 6.3048 (6.3011)  loss_classifier: 5.8155 (5.8300)  loss_box_reg: 0.2305 (0.2454)  loss_objectness: 0.1448 (0.1508)  loss_rpn_box_reg: 0.0697 (0.0750)  time: 0.6269  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [62]  [ 70/500]  eta: 0:04:28  lr: 0.000000  loss: 6.1416 (6.2942)  loss_classifier: 5.8044 (5.8228)  loss_box_reg: 0.2269 (0.2450)  loss_objectness: 0.1499 (0.1503)  loss_rpn_box_reg: 0.0729 (0.0762)  time: 0.6465  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [62]  [ 80/500]  eta: 0:04:21  lr: 0.000000  loss: 6.0157 (6.2377)  loss_classifier: 5.5542 (5.7604)  loss_box_reg: 0.2580 (0.2492)  loss_objectness: 0.1357 (0.1505)  loss_rpn_box_reg: 0.0865 (0.0776)  time: 0.6302  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [62]  [ 90/500]  eta: 0:04:15  lr: 0.000000  loss: 5.9740 (6.2302)  loss_classifier: 5.3230 (5.7554)  loss_box_reg: 0.2492 (0.2486)  loss_objectness: 0.1357 (0.1497)  loss_rpn_box_reg: 0.0758 (0.0766)  time: 0.6240  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [62]  [100/500]  eta: 0:04:09  lr: 0.000000  loss: 6.1496 (6.2187)  loss_classifier: 5.6963 (5.7470)  loss_box_reg: 0.2111 (0.2444)  loss_objectness: 0.1550 (0.1511)  loss_rpn_box_reg: 0.0733 (0.0761)  time: 0.6271  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [62]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 6.0081 (6.2068)  loss_classifier: 5.5551 (5.7418)  loss_box_reg: 0.2065 (0.2416)  loss_objectness: 0.1376 (0.1492)  loss_rpn_box_reg: 0.0589 (0.0742)  time: 0.6218  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [62]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 5.9541 (6.1917)  loss_classifier: 5.5551 (5.7242)  loss_box_reg: 0.2661 (0.2461)  loss_objectness: 0.1249 (0.1473)  loss_rpn_box_reg: 0.0620 (0.0741)  time: 0.6338  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [62]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.0601 (6.1947)  loss_classifier: 5.6699 (5.7274)  loss_box_reg: 0.2726 (0.2463)  loss_objectness: 0.1286 (0.1471)  loss_rpn_box_reg: 0.0637 (0.0739)  time: 0.6368  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [62]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.1475 (6.2042)  loss_classifier: 5.6818 (5.7377)  loss_box_reg: 0.2348 (0.2456)  loss_objectness: 0.1471 (0.1470)  loss_rpn_box_reg: 0.0597 (0.0739)  time: 0.6306  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [62]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.0316 (6.1857)  loss_classifier: 5.4867 (5.7194)  loss_box_reg: 0.2256 (0.2453)  loss_objectness: 0.1392 (0.1471)  loss_rpn_box_reg: 0.0710 (0.0739)  time: 0.6104  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [62]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 5.9793 (6.1860)  loss_classifier: 5.4723 (5.7196)  loss_box_reg: 0.2120 (0.2433)  loss_objectness: 0.1373 (0.1486)  loss_rpn_box_reg: 0.0797 (0.0745)  time: 0.6182  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [62]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 6.0910 (6.1819)  loss_classifier: 5.7424 (5.7141)  loss_box_reg: 0.2129 (0.2432)  loss_objectness: 0.1553 (0.1499)  loss_rpn_box_reg: 0.0632 (0.0747)  time: 0.6298  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [62]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.0380 (6.1781)  loss_classifier: 5.6342 (5.7120)  loss_box_reg: 0.2161 (0.2413)  loss_objectness: 0.1425 (0.1496)  loss_rpn_box_reg: 0.0621 (0.0752)  time: 0.6280  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [62]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.1875 (6.1902)  loss_classifier: 5.7420 (5.7244)  loss_box_reg: 0.2349 (0.2420)  loss_objectness: 0.1277 (0.1491)  loss_rpn_box_reg: 0.0623 (0.0747)  time: 0.6365  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [62]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.3005 (6.1961)  loss_classifier: 5.8126 (5.7327)  loss_box_reg: 0.2349 (0.2405)  loss_objectness: 0.1277 (0.1490)  loss_rpn_box_reg: 0.0602 (0.0738)  time: 0.6262  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [62]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.3464 (6.2071)  loss_classifier: 5.9633 (5.7452)  loss_box_reg: 0.1979 (0.2396)  loss_objectness: 0.1434 (0.1490)  loss_rpn_box_reg: 0.0560 (0.0733)  time: 0.6077  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [62]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.3904 (6.2117)  loss_classifier: 5.8861 (5.7487)  loss_box_reg: 0.2230 (0.2393)  loss_objectness: 0.1568 (0.1496)  loss_rpn_box_reg: 0.0721 (0.0742)  time: 0.6058  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [62]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.1192 (6.2090)  loss_classifier: 5.6398 (5.7456)  loss_box_reg: 0.2289 (0.2393)  loss_objectness: 0.1642 (0.1500)  loss_rpn_box_reg: 0.0754 (0.0742)  time: 0.6217  data: 0.1378  max mem: 10734\n",
      "Training Epoch: [62]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.1072 (6.1995)  loss_classifier: 5.6253 (5.7367)  loss_box_reg: 0.2256 (0.2394)  loss_objectness: 0.1474 (0.1495)  loss_rpn_box_reg: 0.0647 (0.0740)  time: 0.6319  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [62]  [250/500]  eta: 0:02:35  lr: 0.000000  loss: 6.2266 (6.2059)  loss_classifier: 5.6498 (5.7431)  loss_box_reg: 0.2206 (0.2388)  loss_objectness: 0.1405 (0.1498)  loss_rpn_box_reg: 0.0727 (0.0742)  time: 0.6280  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [62]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.2676 (6.2104)  loss_classifier: 5.8876 (5.7469)  loss_box_reg: 0.2322 (0.2385)  loss_objectness: 0.1499 (0.1501)  loss_rpn_box_reg: 0.0902 (0.0750)  time: 0.6092  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [62]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.1476 (6.2058)  loss_classifier: 5.6372 (5.7392)  loss_box_reg: 0.2411 (0.2400)  loss_objectness: 0.1633 (0.1510)  loss_rpn_box_reg: 0.0904 (0.0756)  time: 0.6041  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [62]  [280/500]  eta: 0:02:16  lr: 0.000000  loss: 6.1476 (6.2108)  loss_classifier: 5.6132 (5.7411)  loss_box_reg: 0.2685 (0.2414)  loss_objectness: 0.1853 (0.1520)  loss_rpn_box_reg: 0.0986 (0.0763)  time: 0.6160  data: 0.1403  max mem: 10734\n",
      "Training Epoch: [62]  [290/500]  eta: 0:02:10  lr: 0.000000  loss: 6.2070 (6.2097)  loss_classifier: 5.6813 (5.7417)  loss_box_reg: 0.2447 (0.2397)  loss_objectness: 0.1658 (0.1523)  loss_rpn_box_reg: 0.0716 (0.0760)  time: 0.6197  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [62]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.3033 (6.2150)  loss_classifier: 5.9576 (5.7481)  loss_box_reg: 0.2020 (0.2392)  loss_objectness: 0.1423 (0.1517)  loss_rpn_box_reg: 0.0681 (0.0760)  time: 0.6284  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [62]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.1535 (6.2123)  loss_classifier: 5.7158 (5.7447)  loss_box_reg: 0.2335 (0.2400)  loss_objectness: 0.1433 (0.1519)  loss_rpn_box_reg: 0.0786 (0.0757)  time: 0.6299  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [62]  [320/500]  eta: 0:01:51  lr: 0.000000  loss: 6.1535 (6.2131)  loss_classifier: 5.6704 (5.7450)  loss_box_reg: 0.2335 (0.2397)  loss_objectness: 0.1658 (0.1525)  loss_rpn_box_reg: 0.0769 (0.0758)  time: 0.6127  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [62]  [330/500]  eta: 0:01:45  lr: 0.000000  loss: 6.3274 (6.2158)  loss_classifier: 5.8271 (5.7465)  loss_box_reg: 0.2586 (0.2413)  loss_objectness: 0.1569 (0.1522)  loss_rpn_box_reg: 0.0712 (0.0758)  time: 0.6076  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [62]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.2039 (6.2177)  loss_classifier: 5.7081 (5.7495)  loss_box_reg: 0.2469 (0.2412)  loss_objectness: 0.1380 (0.1520)  loss_rpn_box_reg: 0.0540 (0.0750)  time: 0.6170  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [62]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.1552 (6.2132)  loss_classifier: 5.6877 (5.7442)  loss_box_reg: 0.2345 (0.2413)  loss_objectness: 0.1541 (0.1525)  loss_rpn_box_reg: 0.0589 (0.0753)  time: 0.6178  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [62]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1043 (6.2133)  loss_classifier: 5.6877 (5.7443)  loss_box_reg: 0.2312 (0.2404)  loss_objectness: 0.1659 (0.1532)  loss_rpn_box_reg: 0.0720 (0.0754)  time: 0.6159  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [62]  [370/500]  eta: 0:01:20  lr: 0.000000  loss: 6.2848 (6.2137)  loss_classifier: 5.7774 (5.7450)  loss_box_reg: 0.2271 (0.2399)  loss_objectness: 0.1572 (0.1534)  loss_rpn_box_reg: 0.0735 (0.0754)  time: 0.6186  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [62]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.3291 (6.2154)  loss_classifier: 5.7984 (5.7461)  loss_box_reg: 0.2380 (0.2403)  loss_objectness: 0.1406 (0.1533)  loss_rpn_box_reg: 0.0721 (0.0756)  time: 0.6245  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [62]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.2034 (6.2079)  loss_classifier: 5.6302 (5.7393)  loss_box_reg: 0.2298 (0.2398)  loss_objectness: 0.1432 (0.1532)  loss_rpn_box_reg: 0.0699 (0.0756)  time: 0.6191  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [62]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2144 (6.2159)  loss_classifier: 5.7777 (5.7472)  loss_box_reg: 0.2152 (0.2399)  loss_objectness: 0.1535 (0.1534)  loss_rpn_box_reg: 0.0646 (0.0754)  time: 0.6183  data: 0.1314  max mem: 10734\n",
      "Training Epoch: [62]  [410/500]  eta: 0:00:55  lr: 0.000000  loss: 6.4052 (6.2209)  loss_classifier: 5.8967 (5.7524)  loss_box_reg: 0.2600 (0.2397)  loss_objectness: 0.1435 (0.1530)  loss_rpn_box_reg: 0.0726 (0.0758)  time: 0.6170  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [62]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1460 (6.2142)  loss_classifier: 5.7473 (5.7449)  loss_box_reg: 0.2492 (0.2401)  loss_objectness: 0.1435 (0.1532)  loss_rpn_box_reg: 0.0781 (0.0760)  time: 0.6221  data: 0.1312  max mem: 10734\n",
      "Training Epoch: [62]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 5.8947 (6.2118)  loss_classifier: 5.5940 (5.7425)  loss_box_reg: 0.2492 (0.2402)  loss_objectness: 0.1550 (0.1532)  loss_rpn_box_reg: 0.0720 (0.0760)  time: 0.6317  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [62]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2412 (6.2117)  loss_classifier: 5.7241 (5.7430)  loss_box_reg: 0.2160 (0.2397)  loss_objectness: 0.1518 (0.1532)  loss_rpn_box_reg: 0.0737 (0.0758)  time: 0.6283  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [62]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1481 (6.2083)  loss_classifier: 5.7625 (5.7408)  loss_box_reg: 0.2097 (0.2392)  loss_objectness: 0.1437 (0.1527)  loss_rpn_box_reg: 0.0652 (0.0755)  time: 0.6352  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [62]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.3287 (6.2128)  loss_classifier: 5.8585 (5.7446)  loss_box_reg: 0.2381 (0.2398)  loss_objectness: 0.1437 (0.1529)  loss_rpn_box_reg: 0.0652 (0.0756)  time: 0.6302  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [62]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.3287 (6.2122)  loss_classifier: 5.8467 (5.7443)  loss_box_reg: 0.2431 (0.2396)  loss_objectness: 0.1546 (0.1530)  loss_rpn_box_reg: 0.0603 (0.0753)  time: 0.6200  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [62]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0899 (6.2112)  loss_classifier: 5.6967 (5.7434)  loss_box_reg: 0.2301 (0.2394)  loss_objectness: 0.1546 (0.1530)  loss_rpn_box_reg: 0.0603 (0.0753)  time: 0.6274  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [62]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1265 (6.2106)  loss_classifier: 5.5413 (5.7415)  loss_box_reg: 0.2605 (0.2401)  loss_objectness: 0.1521 (0.1533)  loss_rpn_box_reg: 0.0892 (0.0758)  time: 0.6244  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [62]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1305 (6.2124)  loss_classifier: 5.6560 (5.7433)  loss_box_reg: 0.2552 (0.2402)  loss_objectness: 0.1393 (0.1529)  loss_rpn_box_reg: 0.0956 (0.0761)  time: 0.6245  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [62] Total time: 0:05:11 (0.6226 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:51  model_time: 0.7042 (0.7042)  evaluator_time: 0.0340 (0.0340)  time: 0.8892  data: 0.1410  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4491 (0.4516)  evaluator_time: 0.0340 (0.0368)  time: 0.6392  data: 0.1538  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4671 (0.4529)  evaluator_time: 0.0360 (0.0372)  time: 0.6513  data: 0.1480  max mem: 10734\n",
      "Test: Total time: 0:01:19 (0.6400 s / it)\n",
      "Averaged stats: model_time: 0.4671 (0.4529)  evaluator_time: 0.0360 (0.0372)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [62]  [  0/125]  eta: 0:01:22  lr: 0.000000  loss: 6.1933 (6.1933)  loss_classifier: 5.6525 (5.6525)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1138 (0.1138)  loss_rpn_box_reg: 0.1325 (0.1325)  time: 0.6561  data: 0.1510  max mem: 10734\n",
      "Testing Epoch: [62]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9961 (6.1196)  loss_classifier: 5.4411 (5.6105)  loss_box_reg: 0.2609 (0.2891)  loss_objectness: 0.1307 (0.1311)  loss_rpn_box_reg: 0.0710 (0.0888)  time: 0.5832  data: 0.1437  max mem: 10734\n",
      "Testing Epoch: [62]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1744 (6.1538)  loss_classifier: 5.6926 (5.6489)  loss_box_reg: 0.2500 (0.2846)  loss_objectness: 0.1179 (0.1313)  loss_rpn_box_reg: 0.0745 (0.0891)  time: 0.5971  data: 0.1441  max mem: 10734\n",
      "Testing Epoch: [62] Total time: 0:01:14 (0.5941 s / it)\n",
      "Training Epoch: [63]  [  0/500]  eta: 0:07:45  lr: 0.000000  loss: 6.0047 (6.0047)  loss_classifier: 5.5321 (5.5321)  loss_box_reg: 0.2831 (0.2831)  loss_objectness: 0.1366 (0.1366)  loss_rpn_box_reg: 0.0528 (0.0528)  time: 0.9302  data: 0.1400  max mem: 10734\n",
      "Training Epoch: [63]  [ 10/500]  eta: 0:05:28  lr: 0.000000  loss: 6.2665 (6.1940)  loss_classifier: 5.7537 (5.7484)  loss_box_reg: 0.2091 (0.2060)  loss_objectness: 0.1457 (0.1571)  loss_rpn_box_reg: 0.0778 (0.0825)  time: 0.6714  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [63]  [ 20/500]  eta: 0:05:10  lr: 0.000000  loss: 6.2665 (6.2579)  loss_classifier: 5.7537 (5.8099)  loss_box_reg: 0.2091 (0.2215)  loss_objectness: 0.1457 (0.1474)  loss_rpn_box_reg: 0.0769 (0.0791)  time: 0.6335  data: 0.1314  max mem: 10734\n",
      "Training Epoch: [63]  [ 30/500]  eta: 0:05:00  lr: 0.000000  loss: 6.2134 (6.2453)  loss_classifier: 5.7135 (5.7931)  loss_box_reg: 0.2272 (0.2266)  loss_objectness: 0.1485 (0.1498)  loss_rpn_box_reg: 0.0575 (0.0758)  time: 0.6216  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [63]  [ 40/500]  eta: 0:04:52  lr: 0.000000  loss: 6.1351 (6.1720)  loss_classifier: 5.6818 (5.7271)  loss_box_reg: 0.2078 (0.2261)  loss_objectness: 0.1485 (0.1456)  loss_rpn_box_reg: 0.0552 (0.0732)  time: 0.6256  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [63]  [ 50/500]  eta: 0:04:45  lr: 0.000000  loss: 5.9816 (6.1462)  loss_classifier: 5.5139 (5.6962)  loss_box_reg: 0.2132 (0.2321)  loss_objectness: 0.1221 (0.1447)  loss_rpn_box_reg: 0.0575 (0.0732)  time: 0.6295  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [63]  [ 60/500]  eta: 0:04:39  lr: 0.000000  loss: 5.9981 (6.1388)  loss_classifier: 5.5610 (5.6818)  loss_box_reg: 0.2558 (0.2360)  loss_objectness: 0.1367 (0.1466)  loss_rpn_box_reg: 0.0681 (0.0744)  time: 0.6299  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [63]  [ 70/500]  eta: 0:04:32  lr: 0.000000  loss: 6.2228 (6.1759)  loss_classifier: 5.7554 (5.7180)  loss_box_reg: 0.2415 (0.2370)  loss_objectness: 0.1383 (0.1460)  loss_rpn_box_reg: 0.0723 (0.0749)  time: 0.6315  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [63]  [ 80/500]  eta: 0:04:25  lr: 0.000000  loss: 6.0548 (6.1514)  loss_classifier: 5.6083 (5.6842)  loss_box_reg: 0.2397 (0.2415)  loss_objectness: 0.1410 (0.1483)  loss_rpn_box_reg: 0.0856 (0.0774)  time: 0.6290  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [63]  [ 90/500]  eta: 0:04:20  lr: 0.000000  loss: 5.9795 (6.1311)  loss_classifier: 5.4840 (5.6653)  loss_box_reg: 0.2397 (0.2420)  loss_objectness: 0.1448 (0.1477)  loss_rpn_box_reg: 0.0715 (0.0762)  time: 0.6365  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [63]  [100/500]  eta: 0:04:13  lr: 0.000000  loss: 6.0870 (6.1421)  loss_classifier: 5.6287 (5.6747)  loss_box_reg: 0.2523 (0.2432)  loss_objectness: 0.1446 (0.1479)  loss_rpn_box_reg: 0.0624 (0.0763)  time: 0.6321  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [63]  [110/500]  eta: 0:04:05  lr: 0.000000  loss: 6.3716 (6.1629)  loss_classifier: 5.8893 (5.6977)  loss_box_reg: 0.2365 (0.2401)  loss_objectness: 0.1448 (0.1496)  loss_rpn_box_reg: 0.0624 (0.0756)  time: 0.6079  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [63]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.4283 (6.1816)  loss_classifier: 5.9826 (5.7170)  loss_box_reg: 0.2004 (0.2392)  loss_objectness: 0.1529 (0.1503)  loss_rpn_box_reg: 0.0639 (0.0751)  time: 0.6066  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [63]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 6.1514 (6.1749)  loss_classifier: 5.6620 (5.7114)  loss_box_reg: 0.2203 (0.2374)  loss_objectness: 0.1529 (0.1514)  loss_rpn_box_reg: 0.0682 (0.0746)  time: 0.6138  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [63]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.2066 (6.1826)  loss_classifier: 5.7642 (5.7214)  loss_box_reg: 0.2198 (0.2348)  loss_objectness: 0.1491 (0.1512)  loss_rpn_box_reg: 0.0682 (0.0751)  time: 0.6222  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [63]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.2066 (6.1825)  loss_classifier: 5.7642 (5.7207)  loss_box_reg: 0.2294 (0.2367)  loss_objectness: 0.1448 (0.1500)  loss_rpn_box_reg: 0.0732 (0.0750)  time: 0.6135  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [63]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.1969 (6.1831)  loss_classifier: 5.6411 (5.7211)  loss_box_reg: 0.2515 (0.2376)  loss_objectness: 0.1410 (0.1493)  loss_rpn_box_reg: 0.0716 (0.0751)  time: 0.6032  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [63]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.2932 (6.1954)  loss_classifier: 5.8250 (5.7357)  loss_box_reg: 0.2393 (0.2362)  loss_objectness: 0.1345 (0.1487)  loss_rpn_box_reg: 0.0618 (0.0747)  time: 0.6156  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [63]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.2932 (6.1932)  loss_classifier: 5.8777 (5.7311)  loss_box_reg: 0.2226 (0.2372)  loss_objectness: 0.1476 (0.1491)  loss_rpn_box_reg: 0.0808 (0.0758)  time: 0.6268  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [63]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.1854 (6.1955)  loss_classifier: 5.6257 (5.7308)  loss_box_reg: 0.2445 (0.2385)  loss_objectness: 0.1499 (0.1495)  loss_rpn_box_reg: 0.0826 (0.0767)  time: 0.6293  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [63]  [200/500]  eta: 0:03:06  lr: 0.000000  loss: 6.1854 (6.1946)  loss_classifier: 5.7495 (5.7300)  loss_box_reg: 0.2058 (0.2384)  loss_objectness: 0.1491 (0.1498)  loss_rpn_box_reg: 0.0746 (0.0765)  time: 0.6073  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [63]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 5.9674 (6.1853)  loss_classifier: 5.4641 (5.7199)  loss_box_reg: 0.2205 (0.2385)  loss_objectness: 0.1512 (0.1505)  loss_rpn_box_reg: 0.0678 (0.0764)  time: 0.6161  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [63]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 5.9429 (6.1833)  loss_classifier: 5.4307 (5.7148)  loss_box_reg: 0.2678 (0.2402)  loss_objectness: 0.1512 (0.1513)  loss_rpn_box_reg: 0.0784 (0.0770)  time: 0.6295  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [63]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.1874 (6.1884)  loss_classifier: 5.6182 (5.7209)  loss_box_reg: 0.2460 (0.2392)  loss_objectness: 0.1451 (0.1515)  loss_rpn_box_reg: 0.0835 (0.0768)  time: 0.6187  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [63]  [240/500]  eta: 0:02:41  lr: 0.000000  loss: 6.1892 (6.1902)  loss_classifier: 5.7240 (5.7207)  loss_box_reg: 0.2460 (0.2407)  loss_objectness: 0.1606 (0.1522)  loss_rpn_box_reg: 0.0701 (0.0766)  time: 0.6155  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [63]  [250/500]  eta: 0:02:35  lr: 0.000000  loss: 6.1793 (6.1916)  loss_classifier: 5.7445 (5.7216)  loss_box_reg: 0.2348 (0.2410)  loss_objectness: 0.1606 (0.1522)  loss_rpn_box_reg: 0.0708 (0.0768)  time: 0.6072  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [63]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.1030 (6.1923)  loss_classifier: 5.5721 (5.7209)  loss_box_reg: 0.2276 (0.2414)  loss_objectness: 0.1479 (0.1524)  loss_rpn_box_reg: 0.0884 (0.0776)  time: 0.6077  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [63]  [270/500]  eta: 0:02:22  lr: 0.000000  loss: 6.1284 (6.1967)  loss_classifier: 5.7031 (5.7236)  loss_box_reg: 0.2480 (0.2418)  loss_objectness: 0.1577 (0.1532)  loss_rpn_box_reg: 0.0916 (0.0780)  time: 0.6124  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [63]  [280/500]  eta: 0:02:16  lr: 0.000000  loss: 6.1547 (6.1939)  loss_classifier: 5.7111 (5.7218)  loss_box_reg: 0.2358 (0.2409)  loss_objectness: 0.1609 (0.1535)  loss_rpn_box_reg: 0.0745 (0.0777)  time: 0.6251  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [63]  [290/500]  eta: 0:02:10  lr: 0.000000  loss: 6.0389 (6.1911)  loss_classifier: 5.6669 (5.7205)  loss_box_reg: 0.2125 (0.2400)  loss_objectness: 0.1491 (0.1533)  loss_rpn_box_reg: 0.0490 (0.0774)  time: 0.6148  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [63]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.1443 (6.1925)  loss_classifier: 5.7524 (5.7198)  loss_box_reg: 0.2298 (0.2411)  loss_objectness: 0.1540 (0.1539)  loss_rpn_box_reg: 0.0744 (0.0778)  time: 0.6158  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [63]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.3371 (6.1962)  loss_classifier: 5.7650 (5.7221)  loss_box_reg: 0.2381 (0.2418)  loss_objectness: 0.1619 (0.1547)  loss_rpn_box_reg: 0.0756 (0.0776)  time: 0.6413  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [63]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.0958 (6.1910)  loss_classifier: 5.5777 (5.7153)  loss_box_reg: 0.2485 (0.2427)  loss_objectness: 0.1753 (0.1550)  loss_rpn_box_reg: 0.0756 (0.0780)  time: 0.6386  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [63]  [330/500]  eta: 0:01:45  lr: 0.000000  loss: 6.0772 (6.1899)  loss_classifier: 5.4364 (5.7147)  loss_box_reg: 0.2403 (0.2422)  loss_objectness: 0.1604 (0.1549)  loss_rpn_box_reg: 0.0813 (0.0780)  time: 0.6192  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [63]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.0414 (6.1840)  loss_classifier: 5.5520 (5.7095)  loss_box_reg: 0.2239 (0.2415)  loss_objectness: 0.1575 (0.1553)  loss_rpn_box_reg: 0.0650 (0.0777)  time: 0.6162  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [63]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 5.8599 (6.1814)  loss_classifier: 5.4538 (5.7074)  loss_box_reg: 0.2296 (0.2416)  loss_objectness: 0.1460 (0.1550)  loss_rpn_box_reg: 0.0561 (0.0774)  time: 0.6398  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [63]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1624 (6.1927)  loss_classifier: 5.7292 (5.7184)  loss_box_reg: 0.2369 (0.2412)  loss_objectness: 0.1460 (0.1552)  loss_rpn_box_reg: 0.0684 (0.0778)  time: 0.6346  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [63]  [370/500]  eta: 0:01:20  lr: 0.000000  loss: 6.2580 (6.1928)  loss_classifier: 5.8351 (5.7190)  loss_box_reg: 0.2246 (0.2411)  loss_objectness: 0.1518 (0.1550)  loss_rpn_box_reg: 0.0687 (0.0777)  time: 0.6159  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [63]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.1487 (6.1921)  loss_classifier: 5.6589 (5.7194)  loss_box_reg: 0.2328 (0.2409)  loss_objectness: 0.1237 (0.1541)  loss_rpn_box_reg: 0.0691 (0.0776)  time: 0.6222  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [63]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 5.9809 (6.1880)  loss_classifier: 5.5091 (5.7164)  loss_box_reg: 0.2328 (0.2406)  loss_objectness: 0.1237 (0.1538)  loss_rpn_box_reg: 0.0706 (0.0772)  time: 0.6452  data: 0.1377  max mem: 10734\n",
      "Training Epoch: [63]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2600 (6.1941)  loss_classifier: 5.7482 (5.7226)  loss_box_reg: 0.2515 (0.2409)  loss_objectness: 0.1387 (0.1536)  loss_rpn_box_reg: 0.0570 (0.0769)  time: 0.6321  data: 0.1385  max mem: 10734\n",
      "Training Epoch: [63]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2305 (6.1903)  loss_classifier: 5.6740 (5.7185)  loss_box_reg: 0.2715 (0.2413)  loss_objectness: 0.1487 (0.1539)  loss_rpn_box_reg: 0.0637 (0.0766)  time: 0.6227  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [63]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.0866 (6.1921)  loss_classifier: 5.5936 (5.7212)  loss_box_reg: 0.2171 (0.2409)  loss_objectness: 0.1414 (0.1536)  loss_rpn_box_reg: 0.0637 (0.0764)  time: 0.6341  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [63]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.0866 (6.1890)  loss_classifier: 5.6823 (5.7187)  loss_box_reg: 0.2169 (0.2406)  loss_objectness: 0.1372 (0.1535)  loss_rpn_box_reg: 0.0600 (0.0761)  time: 0.6164  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [63]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2353 (6.1921)  loss_classifier: 5.8008 (5.7230)  loss_box_reg: 0.2269 (0.2402)  loss_objectness: 0.1299 (0.1531)  loss_rpn_box_reg: 0.0600 (0.0757)  time: 0.6198  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [63]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.3644 (6.1993)  loss_classifier: 5.9239 (5.7312)  loss_box_reg: 0.2198 (0.2398)  loss_objectness: 0.1356 (0.1529)  loss_rpn_box_reg: 0.0529 (0.0754)  time: 0.6322  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [63]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.3303 (6.2035)  loss_classifier: 5.8867 (5.7356)  loss_box_reg: 0.2083 (0.2395)  loss_objectness: 0.1472 (0.1531)  loss_rpn_box_reg: 0.0646 (0.0753)  time: 0.6265  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [63]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.3303 (6.2052)  loss_classifier: 5.8598 (5.7370)  loss_box_reg: 0.2002 (0.2395)  loss_objectness: 0.1669 (0.1534)  loss_rpn_box_reg: 0.0661 (0.0753)  time: 0.6263  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [63]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.4255 (6.2103)  loss_classifier: 5.9314 (5.7417)  loss_box_reg: 0.2431 (0.2395)  loss_objectness: 0.1436 (0.1535)  loss_rpn_box_reg: 0.0787 (0.0756)  time: 0.6174  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [63]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.3885 (6.2114)  loss_classifier: 5.9493 (5.7437)  loss_box_reg: 0.2216 (0.2391)  loss_objectness: 0.1366 (0.1531)  loss_rpn_box_reg: 0.0861 (0.0756)  time: 0.6124  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [63]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1949 (6.2132)  loss_classifier: 5.8477 (5.7449)  loss_box_reg: 0.2216 (0.2394)  loss_objectness: 0.1337 (0.1530)  loss_rpn_box_reg: 0.0772 (0.0760)  time: 0.6251  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [63] Total time: 0:05:11 (0.6238 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:46  model_time: 0.6662 (0.6662)  evaluator_time: 0.0350 (0.0350)  time: 0.8532  data: 0.1430  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4411 (0.4508)  evaluator_time: 0.0340 (0.0379)  time: 0.6298  data: 0.1482  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4781 (0.4532)  evaluator_time: 0.0360 (0.0381)  time: 0.6648  data: 0.1552  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6418 s / it)\n",
      "Averaged stats: model_time: 0.4781 (0.4532)  evaluator_time: 0.0360 (0.0381)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [63]  [  0/125]  eta: 0:01:19  lr: 0.000000  loss: 6.2006 (6.2006)  loss_classifier: 5.6525 (5.6525)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1216 (0.1216)  loss_rpn_box_reg: 0.1320 (0.1320)  time: 0.6381  data: 0.1380  max mem: 10734\n",
      "Testing Epoch: [63]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0076 (6.1297)  loss_classifier: 5.4289 (5.6189)  loss_box_reg: 0.2609 (0.2887)  loss_objectness: 0.1306 (0.1323)  loss_rpn_box_reg: 0.0694 (0.0898)  time: 0.5879  data: 0.1448  max mem: 10734\n",
      "Testing Epoch: [63]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1601 (6.1622)  loss_classifier: 5.6802 (5.6559)  loss_box_reg: 0.2500 (0.2843)  loss_objectness: 0.1169 (0.1322)  loss_rpn_box_reg: 0.0745 (0.0899)  time: 0.5966  data: 0.1440  max mem: 10734\n",
      "Testing Epoch: [63] Total time: 0:01:14 (0.5962 s / it)\n",
      "Training Epoch: [64]  [  0/500]  eta: 0:07:32  lr: 0.000000  loss: 6.4005 (6.4005)  loss_classifier: 5.8751 (5.8751)  loss_box_reg: 0.2773 (0.2773)  loss_objectness: 0.1573 (0.1573)  loss_rpn_box_reg: 0.0908 (0.0908)  time: 0.9042  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [64]  [ 10/500]  eta: 0:05:15  lr: 0.000000  loss: 6.4005 (6.5079)  loss_classifier: 5.9472 (6.0626)  loss_box_reg: 0.2165 (0.2404)  loss_objectness: 0.1437 (0.1379)  loss_rpn_box_reg: 0.0582 (0.0670)  time: 0.6435  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [64]  [ 20/500]  eta: 0:05:03  lr: 0.000000  loss: 6.3772 (6.3991)  loss_classifier: 5.9270 (5.9356)  loss_box_reg: 0.2451 (0.2430)  loss_objectness: 0.1480 (0.1504)  loss_rpn_box_reg: 0.0591 (0.0702)  time: 0.6181  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [64]  [ 30/500]  eta: 0:04:54  lr: 0.000000  loss: 6.2959 (6.3076)  loss_classifier: 5.8227 (5.8431)  loss_box_reg: 0.2451 (0.2397)  loss_objectness: 0.1526 (0.1487)  loss_rpn_box_reg: 0.0704 (0.0761)  time: 0.6184  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [64]  [ 40/500]  eta: 0:04:49  lr: 0.000000  loss: 6.2557 (6.2923)  loss_classifier: 5.8227 (5.8274)  loss_box_reg: 0.2320 (0.2425)  loss_objectness: 0.1394 (0.1495)  loss_rpn_box_reg: 0.0695 (0.0730)  time: 0.6254  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [64]  [ 50/500]  eta: 0:04:43  lr: 0.000000  loss: 6.1491 (6.2377)  loss_classifier: 5.6359 (5.7739)  loss_box_reg: 0.2394 (0.2421)  loss_objectness: 0.1430 (0.1480)  loss_rpn_box_reg: 0.0695 (0.0737)  time: 0.6321  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [64]  [ 60/500]  eta: 0:04:37  lr: 0.000000  loss: 6.0106 (6.2364)  loss_classifier: 5.6147 (5.7692)  loss_box_reg: 0.2307 (0.2432)  loss_objectness: 0.1559 (0.1506)  loss_rpn_box_reg: 0.0720 (0.0733)  time: 0.6362  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [64]  [ 70/500]  eta: 0:04:30  lr: 0.000000  loss: 6.2453 (6.2244)  loss_classifier: 5.6147 (5.7571)  loss_box_reg: 0.2110 (0.2432)  loss_objectness: 0.1560 (0.1508)  loss_rpn_box_reg: 0.0600 (0.0733)  time: 0.6280  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [64]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 6.2305 (6.2291)  loss_classifier: 5.6537 (5.7627)  loss_box_reg: 0.2139 (0.2421)  loss_objectness: 0.1475 (0.1516)  loss_rpn_box_reg: 0.0549 (0.0727)  time: 0.6189  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [64]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 6.1293 (6.2114)  loss_classifier: 5.6537 (5.7413)  loss_box_reg: 0.2376 (0.2443)  loss_objectness: 0.1486 (0.1516)  loss_rpn_box_reg: 0.0721 (0.0742)  time: 0.6208  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [64]  [100/500]  eta: 0:04:09  lr: 0.000000  loss: 6.0475 (6.1919)  loss_classifier: 5.6247 (5.7245)  loss_box_reg: 0.2521 (0.2444)  loss_objectness: 0.1408 (0.1508)  loss_rpn_box_reg: 0.0675 (0.0722)  time: 0.6099  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [64]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 6.0845 (6.1997)  loss_classifier: 5.7016 (5.7324)  loss_box_reg: 0.2279 (0.2440)  loss_objectness: 0.1384 (0.1503)  loss_rpn_box_reg: 0.0661 (0.0731)  time: 0.6188  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [64]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.2435 (6.1922)  loss_classifier: 5.7605 (5.7248)  loss_box_reg: 0.2213 (0.2420)  loss_objectness: 0.1596 (0.1514)  loss_rpn_box_reg: 0.0661 (0.0740)  time: 0.6321  data: 0.1374  max mem: 10734\n",
      "Training Epoch: [64]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.3350 (6.2036)  loss_classifier: 5.7342 (5.7348)  loss_box_reg: 0.2318 (0.2416)  loss_objectness: 0.1597 (0.1521)  loss_rpn_box_reg: 0.0620 (0.0751)  time: 0.6331  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [64]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.3702 (6.2150)  loss_classifier: 5.9036 (5.7469)  loss_box_reg: 0.2432 (0.2429)  loss_objectness: 0.1430 (0.1513)  loss_rpn_box_reg: 0.0575 (0.0740)  time: 0.6260  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [64]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.1824 (6.2157)  loss_classifier: 5.7694 (5.7484)  loss_box_reg: 0.2213 (0.2412)  loss_objectness: 0.1430 (0.1515)  loss_rpn_box_reg: 0.0605 (0.0745)  time: 0.6148  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [64]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.0832 (6.1978)  loss_classifier: 5.6842 (5.7317)  loss_box_reg: 0.2180 (0.2402)  loss_objectness: 0.1537 (0.1516)  loss_rpn_box_reg: 0.0684 (0.0743)  time: 0.6300  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [64]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.0541 (6.1995)  loss_classifier: 5.6221 (5.7337)  loss_box_reg: 0.2252 (0.2400)  loss_objectness: 0.1332 (0.1507)  loss_rpn_box_reg: 0.0651 (0.0750)  time: 0.6430  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [64]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.0977 (6.1959)  loss_classifier: 5.6449 (5.7300)  loss_box_reg: 0.2252 (0.2404)  loss_objectness: 0.1353 (0.1507)  loss_rpn_box_reg: 0.0632 (0.0749)  time: 0.6215  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [64]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.0121 (6.1952)  loss_classifier: 5.6449 (5.7283)  loss_box_reg: 0.2250 (0.2399)  loss_objectness: 0.1540 (0.1513)  loss_rpn_box_reg: 0.0614 (0.0757)  time: 0.6132  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [64]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.2208 (6.1906)  loss_classifier: 5.6988 (5.7234)  loss_box_reg: 0.2250 (0.2406)  loss_objectness: 0.1517 (0.1509)  loss_rpn_box_reg: 0.0665 (0.0756)  time: 0.6377  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [64]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.2381 (6.2028)  loss_classifier: 5.7419 (5.7375)  loss_box_reg: 0.2366 (0.2398)  loss_objectness: 0.1420 (0.1509)  loss_rpn_box_reg: 0.0526 (0.0746)  time: 0.6264  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [64]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.4982 (6.2110)  loss_classifier: 6.0206 (5.7450)  loss_box_reg: 0.2037 (0.2393)  loss_objectness: 0.1640 (0.1519)  loss_rpn_box_reg: 0.0504 (0.0748)  time: 0.6020  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [64]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.1820 (6.2090)  loss_classifier: 5.7472 (5.7430)  loss_box_reg: 0.1955 (0.2386)  loss_objectness: 0.1707 (0.1526)  loss_rpn_box_reg: 0.0733 (0.0748)  time: 0.6169  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [64]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.1653 (6.2074)  loss_classifier: 5.6616 (5.7416)  loss_box_reg: 0.2104 (0.2379)  loss_objectness: 0.1707 (0.1530)  loss_rpn_box_reg: 0.0672 (0.0748)  time: 0.6407  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [64]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.1744 (6.2073)  loss_classifier: 5.7316 (5.7404)  loss_box_reg: 0.2202 (0.2391)  loss_objectness: 0.1500 (0.1533)  loss_rpn_box_reg: 0.0672 (0.0745)  time: 0.6260  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [64]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.2320 (6.2139)  loss_classifier: 5.7932 (5.7462)  loss_box_reg: 0.2610 (0.2394)  loss_objectness: 0.1489 (0.1537)  loss_rpn_box_reg: 0.0682 (0.0746)  time: 0.6101  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [64]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.1975 (6.2144)  loss_classifier: 5.6765 (5.7465)  loss_box_reg: 0.2305 (0.2405)  loss_objectness: 0.1443 (0.1534)  loss_rpn_box_reg: 0.0621 (0.0741)  time: 0.6207  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [64]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.1094 (6.2198)  loss_classifier: 5.5830 (5.7491)  loss_box_reg: 0.2867 (0.2424)  loss_objectness: 0.1515 (0.1539)  loss_rpn_box_reg: 0.0634 (0.0744)  time: 0.6233  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [64]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.1769 (6.2247)  loss_classifier: 5.6798 (5.7563)  loss_box_reg: 0.2232 (0.2410)  loss_objectness: 0.1422 (0.1532)  loss_rpn_box_reg: 0.0718 (0.0742)  time: 0.6362  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [64]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.1623 (6.2219)  loss_classifier: 5.6768 (5.7537)  loss_box_reg: 0.1983 (0.2405)  loss_objectness: 0.1276 (0.1533)  loss_rpn_box_reg: 0.0718 (0.0744)  time: 0.6348  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [64]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.1059 (6.2189)  loss_classifier: 5.6216 (5.7503)  loss_box_reg: 0.2246 (0.2405)  loss_objectness: 0.1470 (0.1534)  loss_rpn_box_reg: 0.0764 (0.0746)  time: 0.6248  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [64]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1059 (6.2222)  loss_classifier: 5.6340 (5.7541)  loss_box_reg: 0.2501 (0.2401)  loss_objectness: 0.1489 (0.1533)  loss_rpn_box_reg: 0.0790 (0.0748)  time: 0.6251  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [64]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.0440 (6.2176)  loss_classifier: 5.5854 (5.7480)  loss_box_reg: 0.2550 (0.2412)  loss_objectness: 0.1503 (0.1536)  loss_rpn_box_reg: 0.0757 (0.0748)  time: 0.6159  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [64]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.1991 (6.2227)  loss_classifier: 5.7171 (5.7540)  loss_box_reg: 0.2667 (0.2404)  loss_objectness: 0.1558 (0.1536)  loss_rpn_box_reg: 0.0632 (0.0747)  time: 0.6130  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [64]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.2373 (6.2229)  loss_classifier: 5.8830 (5.7539)  loss_box_reg: 0.2157 (0.2404)  loss_objectness: 0.1579 (0.1537)  loss_rpn_box_reg: 0.0632 (0.0749)  time: 0.6241  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [64]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 5.9731 (6.2180)  loss_classifier: 5.3995 (5.7477)  loss_box_reg: 0.2629 (0.2412)  loss_objectness: 0.1560 (0.1538)  loss_rpn_box_reg: 0.0676 (0.0753)  time: 0.6244  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [64]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.0976 (6.2206)  loss_classifier: 5.5342 (5.7494)  loss_box_reg: 0.2629 (0.2421)  loss_objectness: 0.1484 (0.1537)  loss_rpn_box_reg: 0.0676 (0.0754)  time: 0.6203  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [64]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.1566 (6.2161)  loss_classifier: 5.6029 (5.7457)  loss_box_reg: 0.2459 (0.2417)  loss_objectness: 0.1453 (0.1536)  loss_rpn_box_reg: 0.0592 (0.0751)  time: 0.6259  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [64]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.0820 (6.2124)  loss_classifier: 5.5941 (5.7417)  loss_box_reg: 0.2295 (0.2419)  loss_objectness: 0.1312 (0.1530)  loss_rpn_box_reg: 0.0702 (0.0757)  time: 0.6276  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [64]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2176 (6.2221)  loss_classifier: 5.8000 (5.7513)  loss_box_reg: 0.2295 (0.2417)  loss_objectness: 0.1364 (0.1535)  loss_rpn_box_reg: 0.0702 (0.0756)  time: 0.6176  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [64]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2644 (6.2206)  loss_classifier: 5.8216 (5.7494)  loss_box_reg: 0.2427 (0.2418)  loss_objectness: 0.1606 (0.1535)  loss_rpn_box_reg: 0.0670 (0.0759)  time: 0.6226  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [64]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1680 (6.2245)  loss_classifier: 5.6822 (5.7534)  loss_box_reg: 0.2427 (0.2415)  loss_objectness: 0.1430 (0.1535)  loss_rpn_box_reg: 0.0677 (0.0761)  time: 0.6341  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [64]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1428 (6.2214)  loss_classifier: 5.6822 (5.7515)  loss_box_reg: 0.2283 (0.2409)  loss_objectness: 0.1273 (0.1532)  loss_rpn_box_reg: 0.0753 (0.0759)  time: 0.6181  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [64]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.0612 (6.2218)  loss_classifier: 5.6769 (5.7526)  loss_box_reg: 0.2134 (0.2404)  loss_objectness: 0.1250 (0.1530)  loss_rpn_box_reg: 0.0753 (0.0758)  time: 0.6124  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [64]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0478 (6.2187)  loss_classifier: 5.6490 (5.7494)  loss_box_reg: 0.2289 (0.2408)  loss_objectness: 0.1328 (0.1526)  loss_rpn_box_reg: 0.0771 (0.0759)  time: 0.6178  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [64]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.0478 (6.2197)  loss_classifier: 5.6187 (5.7504)  loss_box_reg: 0.2422 (0.2407)  loss_objectness: 0.1389 (0.1526)  loss_rpn_box_reg: 0.0775 (0.0760)  time: 0.6287  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [64]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2258 (6.2195)  loss_classifier: 5.7353 (5.7510)  loss_box_reg: 0.2140 (0.2403)  loss_objectness: 0.1420 (0.1525)  loss_rpn_box_reg: 0.0693 (0.0758)  time: 0.6359  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [64]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0715 (6.2174)  loss_classifier: 5.6806 (5.7494)  loss_box_reg: 0.2069 (0.2404)  loss_objectness: 0.1356 (0.1521)  loss_rpn_box_reg: 0.0640 (0.0756)  time: 0.6333  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [64]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.2947 (6.2246)  loss_classifier: 5.8333 (5.7574)  loss_box_reg: 0.2069 (0.2397)  loss_objectness: 0.1267 (0.1519)  loss_rpn_box_reg: 0.0640 (0.0755)  time: 0.6218  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [64]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1060 (6.2204)  loss_classifier: 5.7681 (5.7527)  loss_box_reg: 0.2193 (0.2397)  loss_objectness: 0.1471 (0.1521)  loss_rpn_box_reg: 0.0669 (0.0760)  time: 0.6061  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [64] Total time: 0:05:11 (0.6240 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:06  model_time: 0.8172 (0.8172)  evaluator_time: 0.0350 (0.0350)  time: 1.0082  data: 0.1460  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4391 (0.4513)  evaluator_time: 0.0340 (0.0342)  time: 0.6277  data: 0.1483  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4641 (0.4526)  evaluator_time: 0.0360 (0.0360)  time: 0.6516  data: 0.1417  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6402 s / it)\n",
      "Averaged stats: model_time: 0.4641 (0.4526)  evaluator_time: 0.0360 (0.0360)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [64]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1921 (6.1921)  loss_classifier: 5.6520 (5.6520)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1140 (0.1140)  loss_rpn_box_reg: 0.1317 (0.1317)  time: 0.6421  data: 0.1410  max mem: 10734\n",
      "Testing Epoch: [64]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0058 (6.1238)  loss_classifier: 5.4248 (5.6111)  loss_box_reg: 0.2609 (0.2906)  loss_objectness: 0.1349 (0.1316)  loss_rpn_box_reg: 0.0712 (0.0905)  time: 0.5850  data: 0.1461  max mem: 10734\n",
      "Testing Epoch: [64]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1642 (6.1575)  loss_classifier: 5.7001 (5.6496)  loss_box_reg: 0.2500 (0.2858)  loss_objectness: 0.1209 (0.1316)  loss_rpn_box_reg: 0.0745 (0.0905)  time: 0.5970  data: 0.1448  max mem: 10734\n",
      "Testing Epoch: [64] Total time: 0:01:14 (0.5955 s / it)\n",
      "Training Epoch: [65]  [  0/500]  eta: 0:06:19  lr: 0.000000  loss: 6.2096 (6.2096)  loss_classifier: 5.6802 (5.6802)  loss_box_reg: 0.2323 (0.2323)  loss_objectness: 0.1873 (0.1873)  loss_rpn_box_reg: 0.1098 (0.1098)  time: 0.7592  data: 0.1400  max mem: 10734\n",
      "Training Epoch: [65]  [ 10/500]  eta: 0:05:18  lr: 0.000000  loss: 6.2750 (6.3275)  loss_classifier: 5.8317 (5.8313)  loss_box_reg: 0.2428 (0.2442)  loss_objectness: 0.1558 (0.1659)  loss_rpn_box_reg: 0.0931 (0.0861)  time: 0.6500  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [65]  [ 20/500]  eta: 0:05:07  lr: 0.000000  loss: 6.2696 (6.2672)  loss_classifier: 5.7056 (5.7725)  loss_box_reg: 0.2428 (0.2405)  loss_objectness: 0.1558 (0.1608)  loss_rpn_box_reg: 0.0912 (0.0933)  time: 0.6357  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [65]  [ 30/500]  eta: 0:04:55  lr: 0.000000  loss: 6.2001 (6.2317)  loss_classifier: 5.6664 (5.7407)  loss_box_reg: 0.2321 (0.2434)  loss_objectness: 0.1502 (0.1587)  loss_rpn_box_reg: 0.0862 (0.0889)  time: 0.6164  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [65]  [ 40/500]  eta: 0:04:45  lr: 0.000000  loss: 6.3482 (6.2705)  loss_classifier: 5.8057 (5.7761)  loss_box_reg: 0.2371 (0.2437)  loss_objectness: 0.1502 (0.1592)  loss_rpn_box_reg: 0.0786 (0.0916)  time: 0.6006  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [65]  [ 50/500]  eta: 0:04:40  lr: 0.000000  loss: 6.1631 (6.2376)  loss_classifier: 5.7614 (5.7523)  loss_box_reg: 0.2382 (0.2407)  loss_objectness: 0.1482 (0.1571)  loss_rpn_box_reg: 0.0691 (0.0875)  time: 0.6129  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [65]  [ 60/500]  eta: 0:04:33  lr: 0.000000  loss: 6.0225 (6.2293)  loss_classifier: 5.6155 (5.7387)  loss_box_reg: 0.2417 (0.2437)  loss_objectness: 0.1581 (0.1589)  loss_rpn_box_reg: 0.0653 (0.0881)  time: 0.6211  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [65]  [ 70/500]  eta: 0:04:27  lr: 0.000000  loss: 6.1546 (6.2521)  loss_classifier: 5.6711 (5.7645)  loss_box_reg: 0.2417 (0.2413)  loss_objectness: 0.1601 (0.1601)  loss_rpn_box_reg: 0.0689 (0.0862)  time: 0.6257  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [65]  [ 80/500]  eta: 0:04:22  lr: 0.000000  loss: 6.2153 (6.2460)  loss_classifier: 5.7147 (5.7633)  loss_box_reg: 0.2163 (0.2405)  loss_objectness: 0.1572 (0.1593)  loss_rpn_box_reg: 0.0624 (0.0829)  time: 0.6363  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [65]  [ 90/500]  eta: 0:04:16  lr: 0.000000  loss: 6.1358 (6.2477)  loss_classifier: 5.6519 (5.7670)  loss_box_reg: 0.2174 (0.2400)  loss_objectness: 0.1391 (0.1570)  loss_rpn_box_reg: 0.0635 (0.0837)  time: 0.6394  data: 0.1380  max mem: 10734\n",
      "Training Epoch: [65]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 6.0423 (6.2277)  loss_classifier: 5.5222 (5.7469)  loss_box_reg: 0.2284 (0.2425)  loss_objectness: 0.1413 (0.1566)  loss_rpn_box_reg: 0.0685 (0.0818)  time: 0.6375  data: 0.1378  max mem: 10734\n",
      "Training Epoch: [65]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.0131 (6.2350)  loss_classifier: 5.5170 (5.7575)  loss_box_reg: 0.2284 (0.2406)  loss_objectness: 0.1572 (0.1556)  loss_rpn_box_reg: 0.0685 (0.0812)  time: 0.6263  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [65]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.1348 (6.2272)  loss_classifier: 5.7552 (5.7536)  loss_box_reg: 0.2214 (0.2381)  loss_objectness: 0.1498 (0.1551)  loss_rpn_box_reg: 0.0747 (0.0804)  time: 0.6176  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [65]  [130/500]  eta: 0:03:50  lr: 0.000000  loss: 6.1547 (6.2246)  loss_classifier: 5.8166 (5.7558)  loss_box_reg: 0.2214 (0.2367)  loss_objectness: 0.1443 (0.1537)  loss_rpn_box_reg: 0.0578 (0.0784)  time: 0.6102  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [65]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 6.0906 (6.2020)  loss_classifier: 5.6441 (5.7292)  loss_box_reg: 0.2365 (0.2387)  loss_objectness: 0.1443 (0.1553)  loss_rpn_box_reg: 0.0578 (0.0788)  time: 0.6153  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [65]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.1318 (6.2134)  loss_classifier: 5.6441 (5.7427)  loss_box_reg: 0.2482 (0.2370)  loss_objectness: 0.1568 (0.1554)  loss_rpn_box_reg: 0.0554 (0.0783)  time: 0.6205  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [65]  [160/500]  eta: 0:03:31  lr: 0.000000  loss: 6.4262 (6.2245)  loss_classifier: 5.8923 (5.7537)  loss_box_reg: 0.2362 (0.2372)  loss_objectness: 0.1576 (0.1557)  loss_rpn_box_reg: 0.0554 (0.0779)  time: 0.6119  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [65]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 6.4264 (6.2334)  loss_classifier: 5.8265 (5.7597)  loss_box_reg: 0.2376 (0.2390)  loss_objectness: 0.1604 (0.1560)  loss_rpn_box_reg: 0.0654 (0.0787)  time: 0.6172  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [65]  [180/500]  eta: 0:03:18  lr: 0.000000  loss: 6.2557 (6.2229)  loss_classifier: 5.7598 (5.7473)  loss_box_reg: 0.2628 (0.2409)  loss_objectness: 0.1598 (0.1565)  loss_rpn_box_reg: 0.0790 (0.0783)  time: 0.6122  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [65]  [190/500]  eta: 0:03:12  lr: 0.000000  loss: 6.1411 (6.2209)  loss_classifier: 5.6734 (5.7487)  loss_box_reg: 0.2214 (0.2385)  loss_objectness: 0.1418 (0.1554)  loss_rpn_box_reg: 0.0790 (0.0783)  time: 0.6175  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [65]  [200/500]  eta: 0:03:06  lr: 0.000000  loss: 6.2574 (6.2287)  loss_classifier: 5.6807 (5.7567)  loss_box_reg: 0.1978 (0.2387)  loss_objectness: 0.1494 (0.1556)  loss_rpn_box_reg: 0.0639 (0.0777)  time: 0.6355  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [65]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.2713 (6.2261)  loss_classifier: 5.7463 (5.7548)  loss_box_reg: 0.2356 (0.2389)  loss_objectness: 0.1385 (0.1545)  loss_rpn_box_reg: 0.0653 (0.0780)  time: 0.6357  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [65]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.0942 (6.2246)  loss_classifier: 5.7397 (5.7536)  loss_box_reg: 0.2090 (0.2381)  loss_objectness: 0.1379 (0.1547)  loss_rpn_box_reg: 0.0713 (0.0783)  time: 0.6327  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [65]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.0429 (6.2342)  loss_classifier: 5.6341 (5.7629)  loss_box_reg: 0.2315 (0.2386)  loss_objectness: 0.1596 (0.1547)  loss_rpn_box_reg: 0.0737 (0.0780)  time: 0.6291  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [65]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.0949 (6.2320)  loss_classifier: 5.5315 (5.7609)  loss_box_reg: 0.2453 (0.2384)  loss_objectness: 0.1589 (0.1551)  loss_rpn_box_reg: 0.0737 (0.0776)  time: 0.6293  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [65]  [250/500]  eta: 0:02:35  lr: 0.000000  loss: 5.9798 (6.2262)  loss_classifier: 5.5206 (5.7562)  loss_box_reg: 0.2381 (0.2385)  loss_objectness: 0.1550 (0.1546)  loss_rpn_box_reg: 0.0599 (0.0768)  time: 0.6214  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [65]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 5.9464 (6.2235)  loss_classifier: 5.5228 (5.7545)  loss_box_reg: 0.2138 (0.2378)  loss_objectness: 0.1379 (0.1542)  loss_rpn_box_reg: 0.0599 (0.0770)  time: 0.6269  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [65]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.1275 (6.2256)  loss_classifier: 5.6351 (5.7551)  loss_box_reg: 0.2138 (0.2391)  loss_objectness: 0.1539 (0.1542)  loss_rpn_box_reg: 0.0849 (0.0772)  time: 0.6272  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [65]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.2398 (6.2260)  loss_classifier: 5.7987 (5.7558)  loss_box_reg: 0.2275 (0.2389)  loss_objectness: 0.1549 (0.1544)  loss_rpn_box_reg: 0.0691 (0.0768)  time: 0.6120  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [65]  [290/500]  eta: 0:02:10  lr: 0.000000  loss: 6.1202 (6.2183)  loss_classifier: 5.6746 (5.7486)  loss_box_reg: 0.2138 (0.2387)  loss_objectness: 0.1549 (0.1546)  loss_rpn_box_reg: 0.0618 (0.0763)  time: 0.6154  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [65]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.0635 (6.2169)  loss_classifier: 5.5195 (5.7482)  loss_box_reg: 0.2053 (0.2385)  loss_objectness: 0.1472 (0.1540)  loss_rpn_box_reg: 0.0551 (0.0762)  time: 0.6298  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [65]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.2120 (6.2170)  loss_classifier: 5.6088 (5.7464)  loss_box_reg: 0.2401 (0.2396)  loss_objectness: 0.1496 (0.1541)  loss_rpn_box_reg: 0.0729 (0.0768)  time: 0.6286  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [65]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1652 (6.2159)  loss_classifier: 5.6337 (5.7471)  loss_box_reg: 0.2423 (0.2393)  loss_objectness: 0.1448 (0.1534)  loss_rpn_box_reg: 0.0611 (0.0761)  time: 0.6290  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [65]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.4135 (6.2284)  loss_classifier: 5.9327 (5.7591)  loss_box_reg: 0.2100 (0.2387)  loss_objectness: 0.1442 (0.1541)  loss_rpn_box_reg: 0.0549 (0.0765)  time: 0.6392  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [65]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.3435 (6.2313)  loss_classifier: 5.9327 (5.7631)  loss_box_reg: 0.2150 (0.2386)  loss_objectness: 0.1398 (0.1533)  loss_rpn_box_reg: 0.0672 (0.0762)  time: 0.6243  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [65]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.2531 (6.2312)  loss_classifier: 5.8275 (5.7637)  loss_box_reg: 0.2232 (0.2383)  loss_objectness: 0.1321 (0.1531)  loss_rpn_box_reg: 0.0619 (0.0761)  time: 0.6154  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [65]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.2210 (6.2249)  loss_classifier: 5.6880 (5.7579)  loss_box_reg: 0.2113 (0.2379)  loss_objectness: 0.1405 (0.1531)  loss_rpn_box_reg: 0.0632 (0.0759)  time: 0.6424  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [65]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1714 (6.2254)  loss_classifier: 5.6490 (5.7579)  loss_box_reg: 0.2302 (0.2381)  loss_objectness: 0.1528 (0.1533)  loss_rpn_box_reg: 0.0812 (0.0761)  time: 0.6494  data: 0.1382  max mem: 10734\n",
      "Training Epoch: [65]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1123 (6.2224)  loss_classifier: 5.6838 (5.7552)  loss_box_reg: 0.2540 (0.2380)  loss_objectness: 0.1403 (0.1529)  loss_rpn_box_reg: 0.0856 (0.0763)  time: 0.6259  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [65]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1914 (6.2247)  loss_classifier: 5.7042 (5.7577)  loss_box_reg: 0.2268 (0.2378)  loss_objectness: 0.1410 (0.1531)  loss_rpn_box_reg: 0.0652 (0.0761)  time: 0.6254  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [65]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2010 (6.2212)  loss_classifier: 5.7680 (5.7556)  loss_box_reg: 0.2225 (0.2372)  loss_objectness: 0.1492 (0.1528)  loss_rpn_box_reg: 0.0570 (0.0756)  time: 0.6339  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [65]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1442 (6.2204)  loss_classifier: 5.7139 (5.7545)  loss_box_reg: 0.2225 (0.2373)  loss_objectness: 0.1498 (0.1527)  loss_rpn_box_reg: 0.0617 (0.0759)  time: 0.6309  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [65]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.0508 (6.2169)  loss_classifier: 5.6791 (5.7510)  loss_box_reg: 0.2238 (0.2370)  loss_objectness: 0.1596 (0.1528)  loss_rpn_box_reg: 0.0825 (0.0761)  time: 0.6270  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [65]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.0508 (6.2209)  loss_classifier: 5.5429 (5.7549)  loss_box_reg: 0.2394 (0.2373)  loss_objectness: 0.1416 (0.1526)  loss_rpn_box_reg: 0.0810 (0.0762)  time: 0.6329  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [65]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1628 (6.2196)  loss_classifier: 5.6928 (5.7536)  loss_box_reg: 0.2401 (0.2371)  loss_objectness: 0.1446 (0.1527)  loss_rpn_box_reg: 0.0753 (0.0762)  time: 0.6262  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [65]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1591 (6.2197)  loss_classifier: 5.7493 (5.7537)  loss_box_reg: 0.2401 (0.2375)  loss_objectness: 0.1533 (0.1525)  loss_rpn_box_reg: 0.0621 (0.0760)  time: 0.6181  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [65]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.2858 (6.2243)  loss_classifier: 5.7875 (5.7582)  loss_box_reg: 0.2607 (0.2379)  loss_objectness: 0.1390 (0.1523)  loss_rpn_box_reg: 0.0666 (0.0760)  time: 0.6209  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [65]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2853 (6.2182)  loss_classifier: 5.7482 (5.7527)  loss_box_reg: 0.2263 (0.2374)  loss_objectness: 0.1379 (0.1522)  loss_rpn_box_reg: 0.0699 (0.0759)  time: 0.6238  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [65]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 5.8425 (6.2165)  loss_classifier: 5.4184 (5.7509)  loss_box_reg: 0.2156 (0.2376)  loss_objectness: 0.1490 (0.1522)  loss_rpn_box_reg: 0.0629 (0.0758)  time: 0.6195  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [65]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 5.9872 (6.2141)  loss_classifier: 5.6115 (5.7488)  loss_box_reg: 0.2220 (0.2375)  loss_objectness: 0.1490 (0.1521)  loss_rpn_box_reg: 0.0654 (0.0757)  time: 0.6245  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [65]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0732 (6.2126)  loss_classifier: 5.6115 (5.7464)  loss_box_reg: 0.2422 (0.2380)  loss_objectness: 0.1402 (0.1523)  loss_rpn_box_reg: 0.0779 (0.0759)  time: 0.6318  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [65] Total time: 0:05:12 (0.6258 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:53  model_time: 0.7212 (0.7212)  evaluator_time: 0.0350 (0.0350)  time: 0.9112  data: 0.1440  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4381 (0.4518)  evaluator_time: 0.0340 (0.0371)  time: 0.6349  data: 0.1543  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4651 (0.4534)  evaluator_time: 0.0360 (0.0374)  time: 0.6548  data: 0.1484  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6414 s / it)\n",
      "Averaged stats: model_time: 0.4651 (0.4534)  evaluator_time: 0.0360 (0.0374)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [65]  [  0/125]  eta: 0:01:30  lr: 0.000000  loss: 6.1978 (6.1978)  loss_classifier: 5.6509 (5.6509)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1204 (0.1204)  loss_rpn_box_reg: 0.1320 (0.1320)  time: 0.7262  data: 0.2241  max mem: 10734\n",
      "Testing Epoch: [65]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9967 (6.1206)  loss_classifier: 5.4197 (5.6117)  loss_box_reg: 0.2609 (0.2887)  loss_objectness: 0.1278 (0.1309)  loss_rpn_box_reg: 0.0715 (0.0893)  time: 0.5837  data: 0.1442  max mem: 10734\n",
      "Testing Epoch: [65]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1509 (6.1549)  loss_classifier: 5.6975 (5.6501)  loss_box_reg: 0.2500 (0.2843)  loss_objectness: 0.1178 (0.1311)  loss_rpn_box_reg: 0.0745 (0.0894)  time: 0.5982  data: 0.1454  max mem: 10734\n",
      "Testing Epoch: [65] Total time: 0:01:14 (0.5961 s / it)\n",
      "Training Epoch: [66]  [  0/500]  eta: 0:07:39  lr: 0.000000  loss: 6.4579 (6.4579)  loss_classifier: 6.1001 (6.1001)  loss_box_reg: 0.1467 (0.1467)  loss_objectness: 0.1518 (0.1518)  loss_rpn_box_reg: 0.0592 (0.0592)  time: 0.9182  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [66]  [ 10/500]  eta: 0:05:16  lr: 0.000000  loss: 6.2673 (6.2579)  loss_classifier: 5.7778 (5.8015)  loss_box_reg: 0.2448 (0.2249)  loss_objectness: 0.1518 (0.1550)  loss_rpn_box_reg: 0.0767 (0.0765)  time: 0.6452  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [66]  [ 20/500]  eta: 0:05:07  lr: 0.000000  loss: 6.2858 (6.2887)  loss_classifier: 5.7879 (5.8552)  loss_box_reg: 0.2307 (0.2156)  loss_objectness: 0.1455 (0.1522)  loss_rpn_box_reg: 0.0582 (0.0657)  time: 0.6274  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [66]  [ 30/500]  eta: 0:04:57  lr: 0.000000  loss: 6.2552 (6.2459)  loss_classifier: 5.7995 (5.8092)  loss_box_reg: 0.2130 (0.2194)  loss_objectness: 0.1541 (0.1534)  loss_rpn_box_reg: 0.0582 (0.0639)  time: 0.6267  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [66]  [ 40/500]  eta: 0:04:50  lr: 0.000000  loss: 6.1234 (6.2118)  loss_classifier: 5.6154 (5.7678)  loss_box_reg: 0.2130 (0.2237)  loss_objectness: 0.1557 (0.1551)  loss_rpn_box_reg: 0.0641 (0.0653)  time: 0.6212  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [66]  [ 50/500]  eta: 0:04:44  lr: 0.000000  loss: 6.2358 (6.1968)  loss_classifier: 5.6139 (5.7490)  loss_box_reg: 0.2204 (0.2274)  loss_objectness: 0.1557 (0.1559)  loss_rpn_box_reg: 0.0627 (0.0645)  time: 0.6303  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [66]  [ 60/500]  eta: 0:04:35  lr: 0.000000  loss: 6.2578 (6.1816)  loss_classifier: 5.6620 (5.7218)  loss_box_reg: 0.2569 (0.2349)  loss_objectness: 0.1540 (0.1569)  loss_rpn_box_reg: 0.0609 (0.0680)  time: 0.6170  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [66]  [ 70/500]  eta: 0:04:30  lr: 0.000000  loss: 6.1224 (6.1589)  loss_classifier: 5.5709 (5.7020)  loss_box_reg: 0.2307 (0.2313)  loss_objectness: 0.1557 (0.1571)  loss_rpn_box_reg: 0.0815 (0.0685)  time: 0.6249  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [66]  [ 80/500]  eta: 0:04:25  lr: 0.000000  loss: 5.9006 (6.1157)  loss_classifier: 5.4426 (5.6598)  loss_box_reg: 0.2235 (0.2301)  loss_objectness: 0.1399 (0.1551)  loss_rpn_box_reg: 0.0804 (0.0707)  time: 0.6444  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [66]  [ 90/500]  eta: 0:04:18  lr: 0.000000  loss: 6.2170 (6.1506)  loss_classifier: 5.8483 (5.6976)  loss_box_reg: 0.2195 (0.2292)  loss_objectness: 0.1270 (0.1535)  loss_rpn_box_reg: 0.0799 (0.0702)  time: 0.6355  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [66]  [100/500]  eta: 0:04:12  lr: 0.000000  loss: 6.3323 (6.1626)  loss_classifier: 5.8886 (5.7115)  loss_box_reg: 0.2052 (0.2267)  loss_objectness: 0.1404 (0.1535)  loss_rpn_box_reg: 0.0659 (0.0709)  time: 0.6301  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [66]  [110/500]  eta: 0:04:05  lr: 0.000000  loss: 5.9373 (6.1469)  loss_classifier: 5.4604 (5.6921)  loss_box_reg: 0.2338 (0.2288)  loss_objectness: 0.1557 (0.1540)  loss_rpn_box_reg: 0.0768 (0.0719)  time: 0.6193  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [66]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.0946 (6.1504)  loss_classifier: 5.6801 (5.6949)  loss_box_reg: 0.2370 (0.2308)  loss_objectness: 0.1341 (0.1528)  loss_rpn_box_reg: 0.0761 (0.0719)  time: 0.6119  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [66]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 6.0946 (6.1378)  loss_classifier: 5.6897 (5.6825)  loss_box_reg: 0.2357 (0.2318)  loss_objectness: 0.1353 (0.1519)  loss_rpn_box_reg: 0.0566 (0.0717)  time: 0.6170  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [66]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.0538 (6.1435)  loss_classifier: 5.5242 (5.6848)  loss_box_reg: 0.2514 (0.2348)  loss_objectness: 0.1466 (0.1515)  loss_rpn_box_reg: 0.0705 (0.0724)  time: 0.6295  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [66]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.2756 (6.1693)  loss_classifier: 5.7461 (5.7076)  loss_box_reg: 0.2642 (0.2361)  loss_objectness: 0.1652 (0.1525)  loss_rpn_box_reg: 0.0768 (0.0731)  time: 0.6356  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [66]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.2590 (6.1573)  loss_classifier: 5.7461 (5.6972)  loss_box_reg: 0.2377 (0.2351)  loss_objectness: 0.1655 (0.1524)  loss_rpn_box_reg: 0.0731 (0.0726)  time: 0.6206  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [66]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 5.9337 (6.1533)  loss_classifier: 5.4457 (5.6894)  loss_box_reg: 0.2630 (0.2394)  loss_objectness: 0.1512 (0.1521)  loss_rpn_box_reg: 0.0612 (0.0724)  time: 0.6217  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [66]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.1815 (6.1638)  loss_classifier: 5.6840 (5.7001)  loss_box_reg: 0.2740 (0.2400)  loss_objectness: 0.1358 (0.1513)  loss_rpn_box_reg: 0.0650 (0.0724)  time: 0.6323  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [66]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.0801 (6.1624)  loss_classifier: 5.6840 (5.7006)  loss_box_reg: 0.2197 (0.2389)  loss_objectness: 0.1350 (0.1499)  loss_rpn_box_reg: 0.0674 (0.0728)  time: 0.6369  data: 0.1298  max mem: 10734\n",
      "Training Epoch: [66]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.2974 (6.1785)  loss_classifier: 5.6407 (5.7132)  loss_box_reg: 0.2462 (0.2410)  loss_objectness: 0.1383 (0.1506)  loss_rpn_box_reg: 0.0689 (0.0737)  time: 0.6316  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [66]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.5308 (6.1851)  loss_classifier: 5.9813 (5.7219)  loss_box_reg: 0.2393 (0.2394)  loss_objectness: 0.1449 (0.1506)  loss_rpn_box_reg: 0.0598 (0.0732)  time: 0.6224  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [66]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.3245 (6.1921)  loss_classifier: 5.8266 (5.7275)  loss_box_reg: 0.2099 (0.2398)  loss_objectness: 0.1449 (0.1508)  loss_rpn_box_reg: 0.0610 (0.0740)  time: 0.6224  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [66]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.0117 (6.1836)  loss_classifier: 5.5451 (5.7197)  loss_box_reg: 0.2242 (0.2392)  loss_objectness: 0.1565 (0.1504)  loss_rpn_box_reg: 0.0805 (0.0743)  time: 0.6312  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [66]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.0896 (6.1911)  loss_classifier: 5.7430 (5.7268)  loss_box_reg: 0.2242 (0.2397)  loss_objectness: 0.1565 (0.1506)  loss_rpn_box_reg: 0.0700 (0.0740)  time: 0.6237  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [66]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.2769 (6.1847)  loss_classifier: 5.7731 (5.7198)  loss_box_reg: 0.2170 (0.2400)  loss_objectness: 0.1626 (0.1513)  loss_rpn_box_reg: 0.0603 (0.0736)  time: 0.6135  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [66]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 5.9932 (6.1846)  loss_classifier: 5.5364 (5.7206)  loss_box_reg: 0.2258 (0.2390)  loss_objectness: 0.1604 (0.1513)  loss_rpn_box_reg: 0.0605 (0.0737)  time: 0.6183  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [66]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.1025 (6.1782)  loss_classifier: 5.5789 (5.7127)  loss_box_reg: 0.2498 (0.2401)  loss_objectness: 0.1438 (0.1516)  loss_rpn_box_reg: 0.0649 (0.0739)  time: 0.6152  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [66]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 5.9629 (6.1724)  loss_classifier: 5.5120 (5.7058)  loss_box_reg: 0.2499 (0.2404)  loss_objectness: 0.1503 (0.1518)  loss_rpn_box_reg: 0.0746 (0.0745)  time: 0.6221  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [66]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 5.9933 (6.1694)  loss_classifier: 5.5516 (5.7022)  loss_box_reg: 0.2455 (0.2410)  loss_objectness: 0.1478 (0.1517)  loss_rpn_box_reg: 0.0740 (0.0744)  time: 0.6183  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [66]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.1662 (6.1733)  loss_classifier: 5.7396 (5.7084)  loss_box_reg: 0.2094 (0.2400)  loss_objectness: 0.1240 (0.1508)  loss_rpn_box_reg: 0.0578 (0.0742)  time: 0.6286  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [66]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.2524 (6.1807)  loss_classifier: 5.7941 (5.7138)  loss_box_reg: 0.2119 (0.2403)  loss_objectness: 0.1380 (0.1518)  loss_rpn_box_reg: 0.0584 (0.0749)  time: 0.6336  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [66]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2184 (6.1813)  loss_classifier: 5.7508 (5.7152)  loss_box_reg: 0.2219 (0.2395)  loss_objectness: 0.1558 (0.1513)  loss_rpn_box_reg: 0.0935 (0.0753)  time: 0.6181  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [66]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.1556 (6.1838)  loss_classifier: 5.7268 (5.7170)  loss_box_reg: 0.2264 (0.2406)  loss_objectness: 0.1499 (0.1511)  loss_rpn_box_reg: 0.0650 (0.0750)  time: 0.6141  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [66]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.2877 (6.1859)  loss_classifier: 5.9500 (5.7183)  loss_box_reg: 0.2264 (0.2407)  loss_objectness: 0.1511 (0.1517)  loss_rpn_box_reg: 0.0736 (0.0752)  time: 0.6114  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [66]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.3004 (6.1875)  loss_classifier: 5.6325 (5.7186)  loss_box_reg: 0.2349 (0.2414)  loss_objectness: 0.1523 (0.1517)  loss_rpn_box_reg: 0.0887 (0.0758)  time: 0.6156  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [66]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.3004 (6.1961)  loss_classifier: 5.6325 (5.7266)  loss_box_reg: 0.2790 (0.2420)  loss_objectness: 0.1471 (0.1519)  loss_rpn_box_reg: 0.0776 (0.0757)  time: 0.6263  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [66]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1089 (6.1931)  loss_classifier: 5.5954 (5.7217)  loss_box_reg: 0.2893 (0.2431)  loss_objectness: 0.1471 (0.1520)  loss_rpn_box_reg: 0.0766 (0.0763)  time: 0.6276  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [66]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1332 (6.1955)  loss_classifier: 5.5955 (5.7247)  loss_box_reg: 0.2401 (0.2425)  loss_objectness: 0.1493 (0.1521)  loss_rpn_box_reg: 0.0736 (0.0762)  time: 0.6317  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [66]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1574 (6.1969)  loss_classifier: 5.7442 (5.7261)  loss_box_reg: 0.2401 (0.2426)  loss_objectness: 0.1507 (0.1519)  loss_rpn_box_reg: 0.0679 (0.0762)  time: 0.6233  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [66]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1572 (6.1964)  loss_classifier: 5.6790 (5.7269)  loss_box_reg: 0.2034 (0.2417)  loss_objectness: 0.1507 (0.1520)  loss_rpn_box_reg: 0.0603 (0.0759)  time: 0.6152  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [66]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.0801 (6.1930)  loss_classifier: 5.6964 (5.7234)  loss_box_reg: 0.2034 (0.2418)  loss_objectness: 0.1369 (0.1521)  loss_rpn_box_reg: 0.0632 (0.0757)  time: 0.6218  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [66]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1076 (6.1946)  loss_classifier: 5.7081 (5.7251)  loss_box_reg: 0.2273 (0.2416)  loss_objectness: 0.1341 (0.1520)  loss_rpn_box_reg: 0.0744 (0.0759)  time: 0.6252  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [66]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.3323 (6.1993)  loss_classifier: 5.8914 (5.7292)  loss_box_reg: 0.2331 (0.2420)  loss_objectness: 0.1441 (0.1521)  loss_rpn_box_reg: 0.0813 (0.0760)  time: 0.6198  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [66]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.3577 (6.1992)  loss_classifier: 5.9326 (5.7281)  loss_box_reg: 0.2465 (0.2423)  loss_objectness: 0.1522 (0.1522)  loss_rpn_box_reg: 0.0823 (0.0766)  time: 0.6107  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [66]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.2874 (6.2033)  loss_classifier: 5.7574 (5.7326)  loss_box_reg: 0.2465 (0.2422)  loss_objectness: 0.1561 (0.1521)  loss_rpn_box_reg: 0.0743 (0.0764)  time: 0.6105  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [66]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.4399 (6.2078)  loss_classifier: 5.9762 (5.7377)  loss_box_reg: 0.2222 (0.2418)  loss_objectness: 0.1567 (0.1522)  loss_rpn_box_reg: 0.0649 (0.0761)  time: 0.6136  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [66]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2420 (6.2094)  loss_classifier: 5.8842 (5.7403)  loss_box_reg: 0.2190 (0.2411)  loss_objectness: 0.1551 (0.1521)  loss_rpn_box_reg: 0.0642 (0.0759)  time: 0.6247  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [66]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2295 (6.2092)  loss_classifier: 5.8745 (5.7398)  loss_box_reg: 0.2203 (0.2411)  loss_objectness: 0.1471 (0.1522)  loss_rpn_box_reg: 0.0654 (0.0762)  time: 0.6341  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [66]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1446 (6.2070)  loss_classifier: 5.6870 (5.7381)  loss_box_reg: 0.2364 (0.2411)  loss_objectness: 0.1509 (0.1519)  loss_rpn_box_reg: 0.0654 (0.0759)  time: 0.6304  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [66]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1446 (6.2072)  loss_classifier: 5.6870 (5.7384)  loss_box_reg: 0.2334 (0.2410)  loss_objectness: 0.1471 (0.1518)  loss_rpn_box_reg: 0.0665 (0.0760)  time: 0.6212  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [66] Total time: 0:05:12 (0.6242 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:53  model_time: 0.7242 (0.7242)  evaluator_time: 0.0340 (0.0340)  time: 0.9082  data: 0.1410  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4401 (0.4506)  evaluator_time: 0.0330 (0.0350)  time: 0.6261  data: 0.1478  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4651 (0.4527)  evaluator_time: 0.0350 (0.0357)  time: 0.6560  data: 0.1487  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6409 s / it)\n",
      "Averaged stats: model_time: 0.4651 (0.4527)  evaluator_time: 0.0350 (0.0357)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [66]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1937 (6.1937)  loss_classifier: 5.6495 (5.6495)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1179 (0.1179)  loss_rpn_box_reg: 0.1318 (0.1318)  time: 0.6451  data: 0.1450  max mem: 10734\n",
      "Testing Epoch: [66]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0048 (6.1228)  loss_classifier: 5.4141 (5.6116)  loss_box_reg: 0.2609 (0.2892)  loss_objectness: 0.1319 (0.1324)  loss_rpn_box_reg: 0.0717 (0.0896)  time: 0.5836  data: 0.1457  max mem: 10734\n",
      "Testing Epoch: [66]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1690 (6.1559)  loss_classifier: 5.6834 (5.6496)  loss_box_reg: 0.2500 (0.2846)  loss_objectness: 0.1158 (0.1321)  loss_rpn_box_reg: 0.0745 (0.0896)  time: 0.5962  data: 0.1436  max mem: 10734\n",
      "Testing Epoch: [66] Total time: 0:01:14 (0.5944 s / it)\n",
      "Training Epoch: [67]  [  0/500]  eta: 0:07:34  lr: 0.000000  loss: 6.4017 (6.4017)  loss_classifier: 5.8276 (5.8276)  loss_box_reg: 0.3243 (0.3243)  loss_objectness: 0.1664 (0.1664)  loss_rpn_box_reg: 0.0834 (0.0834)  time: 0.9092  data: 0.1390  max mem: 10734\n",
      "Training Epoch: [67]  [ 10/500]  eta: 0:05:23  lr: 0.000000  loss: 6.2214 (6.3348)  loss_classifier: 5.7737 (5.8845)  loss_box_reg: 0.2396 (0.2364)  loss_objectness: 0.1421 (0.1390)  loss_rpn_box_reg: 0.0765 (0.0749)  time: 0.6599  data: 0.1313  max mem: 10734\n",
      "Training Epoch: [67]  [ 20/500]  eta: 0:05:05  lr: 0.000000  loss: 6.1528 (6.2509)  loss_classifier: 5.7513 (5.7891)  loss_box_reg: 0.2396 (0.2386)  loss_objectness: 0.1404 (0.1419)  loss_rpn_box_reg: 0.0746 (0.0813)  time: 0.6239  data: 0.1312  max mem: 10734\n",
      "Training Epoch: [67]  [ 30/500]  eta: 0:04:57  lr: 0.000000  loss: 6.1705 (6.2891)  loss_classifier: 5.6629 (5.8128)  loss_box_reg: 0.2410 (0.2436)  loss_objectness: 0.1543 (0.1485)  loss_rpn_box_reg: 0.0746 (0.0842)  time: 0.6198  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [67]  [ 40/500]  eta: 0:04:48  lr: 0.000000  loss: 6.1705 (6.2735)  loss_classifier: 5.6629 (5.7884)  loss_box_reg: 0.2652 (0.2485)  loss_objectness: 0.1693 (0.1540)  loss_rpn_box_reg: 0.0723 (0.0826)  time: 0.6153  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [67]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 6.0211 (6.2282)  loss_classifier: 5.5388 (5.7419)  loss_box_reg: 0.2679 (0.2512)  loss_objectness: 0.1693 (0.1543)  loss_rpn_box_reg: 0.0669 (0.0808)  time: 0.6208  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [67]  [ 60/500]  eta: 0:04:34  lr: 0.000000  loss: 5.9913 (6.2005)  loss_classifier: 5.4639 (5.7190)  loss_box_reg: 0.2513 (0.2476)  loss_objectness: 0.1430 (0.1528)  loss_rpn_box_reg: 0.0730 (0.0809)  time: 0.6158  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [67]  [ 70/500]  eta: 0:04:27  lr: 0.000000  loss: 6.1149 (6.2101)  loss_classifier: 5.6511 (5.7251)  loss_box_reg: 0.2289 (0.2490)  loss_objectness: 0.1539 (0.1556)  loss_rpn_box_reg: 0.0737 (0.0804)  time: 0.6017  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [67]  [ 80/500]  eta: 0:04:21  lr: 0.000000  loss: 6.2619 (6.2262)  loss_classifier: 5.7086 (5.7333)  loss_box_reg: 0.2291 (0.2538)  loss_objectness: 0.1690 (0.1564)  loss_rpn_box_reg: 0.0730 (0.0827)  time: 0.6204  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [67]  [ 90/500]  eta: 0:04:14  lr: 0.000000  loss: 6.0976 (6.1890)  loss_classifier: 5.6558 (5.7017)  loss_box_reg: 0.2222 (0.2510)  loss_objectness: 0.1501 (0.1549)  loss_rpn_box_reg: 0.0730 (0.0814)  time: 0.6212  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [67]  [100/500]  eta: 0:04:08  lr: 0.000000  loss: 5.9011 (6.1674)  loss_classifier: 5.4710 (5.6806)  loss_box_reg: 0.2068 (0.2495)  loss_objectness: 0.1475 (0.1564)  loss_rpn_box_reg: 0.0638 (0.0809)  time: 0.6206  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [67]  [110/500]  eta: 0:04:02  lr: 0.000000  loss: 5.9545 (6.1904)  loss_classifier: 5.5076 (5.7065)  loss_box_reg: 0.2164 (0.2469)  loss_objectness: 0.1475 (0.1557)  loss_rpn_box_reg: 0.0724 (0.0812)  time: 0.6294  data: 0.1406  max mem: 10734\n",
      "Training Epoch: [67]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.3513 (6.1983)  loss_classifier: 5.8339 (5.7131)  loss_box_reg: 0.2353 (0.2490)  loss_objectness: 0.1398 (0.1545)  loss_rpn_box_reg: 0.0780 (0.0817)  time: 0.6395  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [67]  [130/500]  eta: 0:03:50  lr: 0.000000  loss: 6.3513 (6.2063)  loss_classifier: 5.6840 (5.7238)  loss_box_reg: 0.2458 (0.2479)  loss_objectness: 0.1399 (0.1533)  loss_rpn_box_reg: 0.0821 (0.0813)  time: 0.6296  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [67]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 6.3611 (6.2208)  loss_classifier: 5.8770 (5.7406)  loss_box_reg: 0.2314 (0.2469)  loss_objectness: 0.1447 (0.1526)  loss_rpn_box_reg: 0.0644 (0.0807)  time: 0.6171  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [67]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.3611 (6.2357)  loss_classifier: 5.9398 (5.7539)  loss_box_reg: 0.2282 (0.2478)  loss_objectness: 0.1541 (0.1536)  loss_rpn_box_reg: 0.0595 (0.0805)  time: 0.6250  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [67]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.1941 (6.2216)  loss_classifier: 5.6306 (5.7423)  loss_box_reg: 0.2297 (0.2467)  loss_objectness: 0.1541 (0.1532)  loss_rpn_box_reg: 0.0619 (0.0794)  time: 0.6293  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [67]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 6.0265 (6.2262)  loss_classifier: 5.5371 (5.7466)  loss_box_reg: 0.2385 (0.2471)  loss_objectness: 0.1468 (0.1529)  loss_rpn_box_reg: 0.0648 (0.0796)  time: 0.6260  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [67]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.3185 (6.2443)  loss_classifier: 5.8924 (5.7668)  loss_box_reg: 0.2385 (0.2456)  loss_objectness: 0.1479 (0.1529)  loss_rpn_box_reg: 0.0689 (0.0790)  time: 0.6275  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [67]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.3185 (6.2430)  loss_classifier: 5.8338 (5.7659)  loss_box_reg: 0.2110 (0.2451)  loss_objectness: 0.1507 (0.1534)  loss_rpn_box_reg: 0.0689 (0.0786)  time: 0.6331  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [67]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.2922 (6.2530)  loss_classifier: 5.7649 (5.7796)  loss_box_reg: 0.1980 (0.2420)  loss_objectness: 0.1510 (0.1535)  loss_rpn_box_reg: 0.0656 (0.0779)  time: 0.6208  data: 0.1311  max mem: 10734\n",
      "Training Epoch: [67]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.2295 (6.2475)  loss_classifier: 5.7646 (5.7760)  loss_box_reg: 0.1968 (0.2413)  loss_objectness: 0.1496 (0.1526)  loss_rpn_box_reg: 0.0664 (0.0777)  time: 0.6221  data: 0.1311  max mem: 10734\n",
      "Training Epoch: [67]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 5.9828 (6.2394)  loss_classifier: 5.4763 (5.7652)  loss_box_reg: 0.2473 (0.2438)  loss_objectness: 0.1486 (0.1529)  loss_rpn_box_reg: 0.0695 (0.0774)  time: 0.6260  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [67]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.0091 (6.2369)  loss_classifier: 5.4319 (5.7622)  loss_box_reg: 0.2835 (0.2441)  loss_objectness: 0.1540 (0.1533)  loss_rpn_box_reg: 0.0695 (0.0772)  time: 0.6322  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [67]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.1388 (6.2382)  loss_classifier: 5.6456 (5.7629)  loss_box_reg: 0.2359 (0.2446)  loss_objectness: 0.1539 (0.1536)  loss_rpn_box_reg: 0.0641 (0.0772)  time: 0.6231  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [67]  [250/500]  eta: 0:02:35  lr: 0.000000  loss: 6.3274 (6.2438)  loss_classifier: 5.8140 (5.7672)  loss_box_reg: 0.2359 (0.2453)  loss_objectness: 0.1437 (0.1539)  loss_rpn_box_reg: 0.0801 (0.0773)  time: 0.5852  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [67]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.2239 (6.2432)  loss_classifier: 5.7191 (5.7667)  loss_box_reg: 0.2456 (0.2455)  loss_objectness: 0.1448 (0.1537)  loss_rpn_box_reg: 0.0848 (0.0773)  time: 0.5881  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [67]  [270/500]  eta: 0:02:22  lr: 0.000000  loss: 6.1874 (6.2419)  loss_classifier: 5.7041 (5.7680)  loss_box_reg: 0.2229 (0.2443)  loss_objectness: 0.1364 (0.1532)  loss_rpn_box_reg: 0.0538 (0.0765)  time: 0.6091  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [67]  [280/500]  eta: 0:02:16  lr: 0.000000  loss: 6.2195 (6.2443)  loss_classifier: 5.8359 (5.7719)  loss_box_reg: 0.1977 (0.2431)  loss_objectness: 0.1402 (0.1530)  loss_rpn_box_reg: 0.0611 (0.0764)  time: 0.6230  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [67]  [290/500]  eta: 0:02:10  lr: 0.000000  loss: 6.0305 (6.2318)  loss_classifier: 5.5976 (5.7613)  loss_box_reg: 0.1858 (0.2417)  loss_objectness: 0.1434 (0.1525)  loss_rpn_box_reg: 0.0656 (0.0762)  time: 0.6372  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [67]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.0183 (6.2253)  loss_classifier: 5.4845 (5.7540)  loss_box_reg: 0.2309 (0.2425)  loss_objectness: 0.1434 (0.1523)  loss_rpn_box_reg: 0.0705 (0.0765)  time: 0.6356  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [67]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.1128 (6.2233)  loss_classifier: 5.6351 (5.7504)  loss_box_reg: 0.2533 (0.2437)  loss_objectness: 0.1510 (0.1523)  loss_rpn_box_reg: 0.0820 (0.0768)  time: 0.6239  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [67]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2562 (6.2289)  loss_classifier: 5.6931 (5.7558)  loss_box_reg: 0.2348 (0.2432)  loss_objectness: 0.1510 (0.1524)  loss_rpn_box_reg: 0.0737 (0.0774)  time: 0.6251  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [67]  [330/500]  eta: 0:01:45  lr: 0.000000  loss: 6.3191 (6.2357)  loss_classifier: 5.8642 (5.7643)  loss_box_reg: 0.2123 (0.2422)  loss_objectness: 0.1410 (0.1522)  loss_rpn_box_reg: 0.0603 (0.0769)  time: 0.6160  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [67]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.3158 (6.2326)  loss_classifier: 5.8968 (5.7615)  loss_box_reg: 0.2319 (0.2421)  loss_objectness: 0.1427 (0.1522)  loss_rpn_box_reg: 0.0603 (0.0767)  time: 0.6069  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [67]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.0549 (6.2308)  loss_classifier: 5.6341 (5.7600)  loss_box_reg: 0.2085 (0.2413)  loss_objectness: 0.1526 (0.1526)  loss_rpn_box_reg: 0.0654 (0.0769)  time: 0.6306  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [67]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.0190 (6.2199)  loss_classifier: 5.6247 (5.7493)  loss_box_reg: 0.2189 (0.2415)  loss_objectness: 0.1526 (0.1523)  loss_rpn_box_reg: 0.0614 (0.0768)  time: 0.6298  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [67]  [370/500]  eta: 0:01:20  lr: 0.000000  loss: 6.1886 (6.2250)  loss_classifier: 5.7638 (5.7533)  loss_box_reg: 0.2545 (0.2424)  loss_objectness: 0.1481 (0.1526)  loss_rpn_box_reg: 0.0618 (0.0767)  time: 0.6193  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [67]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.1886 (6.2239)  loss_classifier: 5.7769 (5.7516)  loss_box_reg: 0.2631 (0.2425)  loss_objectness: 0.1665 (0.1530)  loss_rpn_box_reg: 0.0788 (0.0768)  time: 0.6282  data: 0.1390  max mem: 10734\n",
      "Training Epoch: [67]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1520 (6.2239)  loss_classifier: 5.7058 (5.7531)  loss_box_reg: 0.2306 (0.2418)  loss_objectness: 0.1623 (0.1528)  loss_rpn_box_reg: 0.0636 (0.0763)  time: 0.6381  data: 0.1412  max mem: 10734\n",
      "Training Epoch: [67]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.0767 (6.2186)  loss_classifier: 5.6932 (5.7471)  loss_box_reg: 0.2480 (0.2423)  loss_objectness: 0.1531 (0.1530)  loss_rpn_box_reg: 0.0579 (0.0762)  time: 0.6353  data: 0.1384  max mem: 10734\n",
      "Training Epoch: [67]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1598 (6.2191)  loss_classifier: 5.7009 (5.7478)  loss_box_reg: 0.2504 (0.2421)  loss_objectness: 0.1617 (0.1531)  loss_rpn_box_reg: 0.0653 (0.0760)  time: 0.6396  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [67]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.2398 (6.2181)  loss_classifier: 5.7451 (5.7471)  loss_box_reg: 0.2386 (0.2424)  loss_objectness: 0.1404 (0.1528)  loss_rpn_box_reg: 0.0566 (0.0758)  time: 0.6367  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [67]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1875 (6.2184)  loss_classifier: 5.7331 (5.7479)  loss_box_reg: 0.2333 (0.2420)  loss_objectness: 0.1409 (0.1529)  loss_rpn_box_reg: 0.0566 (0.0756)  time: 0.6351  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [67]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1118 (6.2197)  loss_classifier: 5.7141 (5.7491)  loss_box_reg: 0.2208 (0.2418)  loss_objectness: 0.1522 (0.1530)  loss_rpn_box_reg: 0.0590 (0.0758)  time: 0.6275  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [67]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0081 (6.2119)  loss_classifier: 5.4808 (5.7413)  loss_box_reg: 0.2500 (0.2416)  loss_objectness: 0.1351 (0.1528)  loss_rpn_box_reg: 0.0794 (0.0761)  time: 0.6208  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [67]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.0147 (6.2105)  loss_classifier: 5.5182 (5.7409)  loss_box_reg: 0.2088 (0.2409)  loss_objectness: 0.1250 (0.1524)  loss_rpn_box_reg: 0.0828 (0.0763)  time: 0.6322  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [67]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1591 (6.2132)  loss_classifier: 5.7113 (5.7437)  loss_box_reg: 0.2174 (0.2410)  loss_objectness: 0.1365 (0.1521)  loss_rpn_box_reg: 0.0758 (0.0764)  time: 0.6210  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [67]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1890 (6.2109)  loss_classifier: 5.6963 (5.7415)  loss_box_reg: 0.2220 (0.2410)  loss_objectness: 0.1482 (0.1522)  loss_rpn_box_reg: 0.0704 (0.0762)  time: 0.6232  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [67]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0822 (6.2120)  loss_classifier: 5.6331 (5.7425)  loss_box_reg: 0.2220 (0.2410)  loss_objectness: 0.1514 (0.1523)  loss_rpn_box_reg: 0.0634 (0.0761)  time: 0.6304  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [67]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0657 (6.2131)  loss_classifier: 5.6391 (5.7443)  loss_box_reg: 0.2334 (0.2405)  loss_objectness: 0.1497 (0.1522)  loss_rpn_box_reg: 0.0644 (0.0761)  time: 0.6225  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [67] Total time: 0:05:12 (0.6244 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:04  model_time: 0.8122 (0.8122)  evaluator_time: 0.0340 (0.0340)  time: 0.9962  data: 0.1410  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4391 (0.4525)  evaluator_time: 0.0340 (0.0370)  time: 0.6310  data: 0.1472  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4641 (0.4542)  evaluator_time: 0.0350 (0.0373)  time: 0.6554  data: 0.1478  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6418 s / it)\n",
      "Averaged stats: model_time: 0.4641 (0.4542)  evaluator_time: 0.0350 (0.0373)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [67]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1958 (6.1958)  loss_classifier: 5.6463 (5.6463)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1250 (0.1250)  loss_rpn_box_reg: 0.1299 (0.1299)  time: 0.6451  data: 0.1430  max mem: 10734\n",
      "Testing Epoch: [67]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9826 (6.1294)  loss_classifier: 5.4192 (5.6165)  loss_box_reg: 0.2609 (0.2897)  loss_objectness: 0.1277 (0.1327)  loss_rpn_box_reg: 0.0734 (0.0905)  time: 0.5846  data: 0.1455  max mem: 10734\n",
      "Testing Epoch: [67]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1503 (6.1622)  loss_classifier: 5.6811 (5.6544)  loss_box_reg: 0.2500 (0.2851)  loss_objectness: 0.1216 (0.1323)  loss_rpn_box_reg: 0.0745 (0.0904)  time: 0.5973  data: 0.1455  max mem: 10734\n",
      "Testing Epoch: [67] Total time: 0:01:14 (0.5952 s / it)\n",
      "Training Epoch: [68]  [  0/500]  eta: 0:06:08  lr: 0.000000  loss: 5.3476 (5.3476)  loss_classifier: 4.9781 (4.9781)  loss_box_reg: 0.1973 (0.1973)  loss_objectness: 0.1179 (0.1179)  loss_rpn_box_reg: 0.0543 (0.0543)  time: 0.7362  data: 0.1280  max mem: 10734\n",
      "Training Epoch: [68]  [ 10/500]  eta: 0:05:07  lr: 0.000000  loss: 6.1224 (6.0765)  loss_classifier: 5.6063 (5.6004)  loss_box_reg: 0.2376 (0.2396)  loss_objectness: 0.1499 (0.1508)  loss_rpn_box_reg: 0.0910 (0.0857)  time: 0.6266  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [68]  [ 20/500]  eta: 0:05:06  lr: 0.000000  loss: 6.0642 (6.0697)  loss_classifier: 5.6055 (5.6083)  loss_box_reg: 0.2237 (0.2235)  loss_objectness: 0.1600 (0.1532)  loss_rpn_box_reg: 0.0875 (0.0847)  time: 0.6337  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [68]  [ 30/500]  eta: 0:04:59  lr: 0.000000  loss: 6.0659 (6.1077)  loss_classifier: 5.5863 (5.6326)  loss_box_reg: 0.2307 (0.2387)  loss_objectness: 0.1645 (0.1541)  loss_rpn_box_reg: 0.0756 (0.0824)  time: 0.6439  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [68]  [ 40/500]  eta: 0:04:51  lr: 0.000000  loss: 6.1171 (6.1532)  loss_classifier: 5.6635 (5.6683)  loss_box_reg: 0.2693 (0.2429)  loss_objectness: 0.1645 (0.1578)  loss_rpn_box_reg: 0.0783 (0.0842)  time: 0.6300  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [68]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 6.3156 (6.1927)  loss_classifier: 5.8378 (5.7097)  loss_box_reg: 0.2387 (0.2420)  loss_objectness: 0.1523 (0.1590)  loss_rpn_box_reg: 0.0732 (0.0820)  time: 0.6128  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [68]  [ 60/500]  eta: 0:04:37  lr: 0.000000  loss: 6.2649 (6.1974)  loss_classifier: 5.8143 (5.7221)  loss_box_reg: 0.2361 (0.2405)  loss_objectness: 0.1402 (0.1547)  loss_rpn_box_reg: 0.0559 (0.0801)  time: 0.6258  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [68]  [ 70/500]  eta: 0:04:30  lr: 0.000000  loss: 6.1897 (6.2003)  loss_classifier: 5.7649 (5.7309)  loss_box_reg: 0.2274 (0.2389)  loss_objectness: 0.1308 (0.1524)  loss_rpn_box_reg: 0.0540 (0.0782)  time: 0.6336  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [68]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 6.1897 (6.1852)  loss_classifier: 5.7529 (5.7217)  loss_box_reg: 0.2174 (0.2359)  loss_objectness: 0.1322 (0.1502)  loss_rpn_box_reg: 0.0570 (0.0773)  time: 0.6111  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [68]  [ 90/500]  eta: 0:04:16  lr: 0.000000  loss: 6.2212 (6.2000)  loss_classifier: 5.7999 (5.7367)  loss_box_reg: 0.2033 (0.2350)  loss_objectness: 0.1356 (0.1508)  loss_rpn_box_reg: 0.0724 (0.0774)  time: 0.6133  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [68]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 6.1658 (6.1940)  loss_classifier: 5.7999 (5.7318)  loss_box_reg: 0.2379 (0.2366)  loss_objectness: 0.1574 (0.1509)  loss_rpn_box_reg: 0.0610 (0.0748)  time: 0.6279  data: 0.1374  max mem: 10734\n",
      "Training Epoch: [68]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 5.9076 (6.1874)  loss_classifier: 5.3828 (5.7237)  loss_box_reg: 0.2388 (0.2391)  loss_objectness: 0.1384 (0.1494)  loss_rpn_box_reg: 0.0610 (0.0752)  time: 0.6223  data: 0.1370  max mem: 10734\n",
      "Training Epoch: [68]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.1208 (6.1791)  loss_classifier: 5.6209 (5.7173)  loss_box_reg: 0.2361 (0.2391)  loss_objectness: 0.1377 (0.1485)  loss_rpn_box_reg: 0.0643 (0.0742)  time: 0.6244  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [68]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 6.1837 (6.1862)  loss_classifier: 5.7022 (5.7221)  loss_box_reg: 0.2320 (0.2407)  loss_objectness: 0.1398 (0.1495)  loss_rpn_box_reg: 0.0578 (0.0740)  time: 0.6372  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [68]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.4071 (6.2156)  loss_classifier: 5.8255 (5.7495)  loss_box_reg: 0.2590 (0.2419)  loss_objectness: 0.1520 (0.1502)  loss_rpn_box_reg: 0.0753 (0.0741)  time: 0.6225  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [68]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.3570 (6.2253)  loss_classifier: 5.8430 (5.7575)  loss_box_reg: 0.2386 (0.2428)  loss_objectness: 0.1563 (0.1510)  loss_rpn_box_reg: 0.0796 (0.0741)  time: 0.6135  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [68]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.2846 (6.2226)  loss_classifier: 5.7633 (5.7534)  loss_box_reg: 0.2506 (0.2443)  loss_objectness: 0.1431 (0.1501)  loss_rpn_box_reg: 0.0802 (0.0747)  time: 0.6294  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [68]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 5.9359 (6.2018)  loss_classifier: 5.5072 (5.7357)  loss_box_reg: 0.2128 (0.2422)  loss_objectness: 0.1383 (0.1499)  loss_rpn_box_reg: 0.0680 (0.0741)  time: 0.6346  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [68]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.2123 (6.2178)  loss_classifier: 5.7556 (5.7526)  loss_box_reg: 0.2021 (0.2411)  loss_objectness: 0.1401 (0.1497)  loss_rpn_box_reg: 0.0685 (0.0744)  time: 0.6293  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [68]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.3818 (6.2255)  loss_classifier: 5.9217 (5.7589)  loss_box_reg: 0.2412 (0.2413)  loss_objectness: 0.1653 (0.1506)  loss_rpn_box_reg: 0.0685 (0.0747)  time: 0.6235  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [68]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.3041 (6.2167)  loss_classifier: 5.7059 (5.7484)  loss_box_reg: 0.2659 (0.2423)  loss_objectness: 0.1643 (0.1511)  loss_rpn_box_reg: 0.0674 (0.0749)  time: 0.6260  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [68]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 5.9609 (6.2095)  loss_classifier: 5.4372 (5.7407)  loss_box_reg: 0.2395 (0.2424)  loss_objectness: 0.1553 (0.1512)  loss_rpn_box_reg: 0.0704 (0.0752)  time: 0.6108  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [68]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 5.9322 (6.2140)  loss_classifier: 5.3891 (5.7450)  loss_box_reg: 0.2389 (0.2430)  loss_objectness: 0.1327 (0.1508)  loss_rpn_box_reg: 0.0654 (0.0753)  time: 0.6101  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [68]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.0264 (6.2090)  loss_classifier: 5.5275 (5.7392)  loss_box_reg: 0.2284 (0.2434)  loss_objectness: 0.1450 (0.1515)  loss_rpn_box_reg: 0.0654 (0.0748)  time: 0.6361  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [68]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.3050 (6.2139)  loss_classifier: 5.8379 (5.7429)  loss_box_reg: 0.2284 (0.2431)  loss_objectness: 0.1621 (0.1524)  loss_rpn_box_reg: 0.0668 (0.0756)  time: 0.6350  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [68]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.2629 (6.2128)  loss_classifier: 5.7413 (5.7434)  loss_box_reg: 0.2287 (0.2419)  loss_objectness: 0.1621 (0.1525)  loss_rpn_box_reg: 0.0657 (0.0750)  time: 0.6304  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [68]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.1750 (6.2140)  loss_classifier: 5.6794 (5.7438)  loss_box_reg: 0.2472 (0.2422)  loss_objectness: 0.1491 (0.1525)  loss_rpn_box_reg: 0.0650 (0.0755)  time: 0.6200  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [68]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.2394 (6.2131)  loss_classifier: 5.7313 (5.7428)  loss_box_reg: 0.2524 (0.2423)  loss_objectness: 0.1491 (0.1526)  loss_rpn_box_reg: 0.0688 (0.0754)  time: 0.6162  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [68]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.0773 (6.2014)  loss_classifier: 5.5625 (5.7307)  loss_box_reg: 0.2363 (0.2425)  loss_objectness: 0.1534 (0.1527)  loss_rpn_box_reg: 0.0688 (0.0755)  time: 0.6315  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [68]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 5.9879 (6.1969)  loss_classifier: 5.4958 (5.7274)  loss_box_reg: 0.2083 (0.2411)  loss_objectness: 0.1572 (0.1526)  loss_rpn_box_reg: 0.0768 (0.0758)  time: 0.6309  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [68]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.2350 (6.1976)  loss_classifier: 5.9107 (5.7298)  loss_box_reg: 0.1999 (0.2405)  loss_objectness: 0.1340 (0.1519)  loss_rpn_box_reg: 0.0654 (0.0753)  time: 0.6445  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [68]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.3318 (6.2050)  loss_classifier: 5.9180 (5.7390)  loss_box_reg: 0.2023 (0.2392)  loss_objectness: 0.1340 (0.1520)  loss_rpn_box_reg: 0.0474 (0.0748)  time: 0.6404  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [68]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.3787 (6.2071)  loss_classifier: 5.9632 (5.7419)  loss_box_reg: 0.2139 (0.2389)  loss_objectness: 0.1426 (0.1517)  loss_rpn_box_reg: 0.0558 (0.0745)  time: 0.6303  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [68]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.1612 (6.2069)  loss_classifier: 5.7283 (5.7422)  loss_box_reg: 0.2207 (0.2385)  loss_objectness: 0.1364 (0.1514)  loss_rpn_box_reg: 0.0697 (0.0747)  time: 0.6388  data: 0.1305  max mem: 10734\n",
      "Training Epoch: [68]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 5.9637 (6.2001)  loss_classifier: 5.5041 (5.7340)  loss_box_reg: 0.2470 (0.2394)  loss_objectness: 0.1450 (0.1517)  loss_rpn_box_reg: 0.0753 (0.0749)  time: 0.6111  data: 0.1302  max mem: 10734\n",
      "Training Epoch: [68]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 5.9637 (6.1981)  loss_classifier: 5.5146 (5.7306)  loss_box_reg: 0.2401 (0.2403)  loss_objectness: 0.1627 (0.1520)  loss_rpn_box_reg: 0.0770 (0.0753)  time: 0.6013  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [68]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.4123 (6.2063)  loss_classifier: 5.9196 (5.7402)  loss_box_reg: 0.2278 (0.2393)  loss_objectness: 0.1511 (0.1516)  loss_rpn_box_reg: 0.0763 (0.0752)  time: 0.6149  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [68]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.3176 (6.2082)  loss_classifier: 5.9196 (5.7418)  loss_box_reg: 0.2095 (0.2395)  loss_objectness: 0.1429 (0.1516)  loss_rpn_box_reg: 0.0763 (0.0753)  time: 0.6172  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [68]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.1764 (6.2077)  loss_classifier: 5.6050 (5.7409)  loss_box_reg: 0.2375 (0.2397)  loss_objectness: 0.1414 (0.1518)  loss_rpn_box_reg: 0.0822 (0.0753)  time: 0.6286  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [68]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.2297 (6.2108)  loss_classifier: 5.6791 (5.7434)  loss_box_reg: 0.2315 (0.2398)  loss_objectness: 0.1520 (0.1519)  loss_rpn_box_reg: 0.0861 (0.0757)  time: 0.6244  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [68]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2322 (6.2142)  loss_classifier: 5.7056 (5.7471)  loss_box_reg: 0.2289 (0.2390)  loss_objectness: 0.1517 (0.1522)  loss_rpn_box_reg: 0.0838 (0.0759)  time: 0.6107  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [68]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1935 (6.2131)  loss_classifier: 5.6611 (5.7455)  loss_box_reg: 0.2025 (0.2391)  loss_objectness: 0.1538 (0.1525)  loss_rpn_box_reg: 0.0756 (0.0760)  time: 0.6100  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [68]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.1935 (6.2164)  loss_classifier: 5.8241 (5.7495)  loss_box_reg: 0.2180 (0.2386)  loss_objectness: 0.1676 (0.1527)  loss_rpn_box_reg: 0.0653 (0.0756)  time: 0.6289  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [68]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1713 (6.2141)  loss_classifier: 5.8171 (5.7474)  loss_box_reg: 0.2180 (0.2383)  loss_objectness: 0.1343 (0.1528)  loss_rpn_box_reg: 0.0616 (0.0756)  time: 0.6345  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [68]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 5.9865 (6.2108)  loss_classifier: 5.5967 (5.7443)  loss_box_reg: 0.2051 (0.2377)  loss_objectness: 0.1332 (0.1527)  loss_rpn_box_reg: 0.0831 (0.0760)  time: 0.6173  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [68]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0128 (6.2069)  loss_classifier: 5.5967 (5.7402)  loss_box_reg: 0.2148 (0.2379)  loss_objectness: 0.1573 (0.1527)  loss_rpn_box_reg: 0.0766 (0.0761)  time: 0.6091  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [68]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.1799 (6.2104)  loss_classifier: 5.6967 (5.7431)  loss_box_reg: 0.2344 (0.2381)  loss_objectness: 0.1600 (0.1531)  loss_rpn_box_reg: 0.0661 (0.0761)  time: 0.6178  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [68]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2933 (6.2120)  loss_classifier: 5.8106 (5.7438)  loss_box_reg: 0.2509 (0.2386)  loss_objectness: 0.1578 (0.1532)  loss_rpn_box_reg: 0.0724 (0.0764)  time: 0.6344  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [68]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1491 (6.2144)  loss_classifier: 5.7155 (5.7473)  loss_box_reg: 0.2148 (0.2379)  loss_objectness: 0.1475 (0.1528)  loss_rpn_box_reg: 0.0724 (0.0764)  time: 0.6295  data: 0.1306  max mem: 10734\n",
      "Training Epoch: [68]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1351 (6.2140)  loss_classifier: 5.7155 (5.7473)  loss_box_reg: 0.2001 (0.2376)  loss_objectness: 0.1473 (0.1529)  loss_rpn_box_reg: 0.0658 (0.0761)  time: 0.6344  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [68]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1132 (6.2145)  loss_classifier: 5.6997 (5.7486)  loss_box_reg: 0.2127 (0.2372)  loss_objectness: 0.1535 (0.1528)  loss_rpn_box_reg: 0.0564 (0.0759)  time: 0.6391  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [68] Total time: 0:05:12 (0.6253 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:03  model_time: 0.7982 (0.7982)  evaluator_time: 0.0350 (0.0350)  time: 0.9892  data: 0.1470  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4371 (0.4504)  evaluator_time: 0.0340 (0.0371)  time: 0.6275  data: 0.1478  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4661 (0.4521)  evaluator_time: 0.0360 (0.0374)  time: 0.6523  data: 0.1482  max mem: 10734\n",
      "Test: Total time: 0:01:19 (0.6396 s / it)\n",
      "Averaged stats: model_time: 0.4661 (0.4521)  evaluator_time: 0.0360 (0.0374)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.28s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [68]  [  0/125]  eta: 0:01:19  lr: 0.000000  loss: 6.1858 (6.1858)  loss_classifier: 5.6453 (5.6453)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1135 (0.1135)  loss_rpn_box_reg: 0.1324 (0.1324)  time: 0.6391  data: 0.1350  max mem: 10734\n",
      "Testing Epoch: [68]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9927 (6.1374)  loss_classifier: 5.4294 (5.6261)  loss_box_reg: 0.2609 (0.2897)  loss_objectness: 0.1284 (0.1318)  loss_rpn_box_reg: 0.0720 (0.0898)  time: 0.5832  data: 0.1447  max mem: 10734\n",
      "Testing Epoch: [68]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1578 (6.1680)  loss_classifier: 5.6791 (5.6612)  loss_box_reg: 0.2500 (0.2850)  loss_objectness: 0.1229 (0.1319)  loss_rpn_box_reg: 0.0745 (0.0899)  time: 0.5964  data: 0.1439  max mem: 10734\n",
      "Testing Epoch: [68] Total time: 0:01:14 (0.5954 s / it)\n",
      "Training Epoch: [69]  [  0/500]  eta: 0:07:23  lr: 0.000000  loss: 6.1261 (6.1261)  loss_classifier: 5.7976 (5.7976)  loss_box_reg: 0.1578 (0.1578)  loss_objectness: 0.1390 (0.1390)  loss_rpn_box_reg: 0.0317 (0.0317)  time: 0.8862  data: 0.1280  max mem: 10734\n",
      "Training Epoch: [69]  [ 10/500]  eta: 0:05:22  lr: 0.000000  loss: 6.2182 (6.1513)  loss_classifier: 5.7822 (5.7082)  loss_box_reg: 0.2161 (0.2240)  loss_objectness: 0.1390 (0.1463)  loss_rpn_box_reg: 0.0876 (0.0729)  time: 0.6583  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [69]  [ 20/500]  eta: 0:05:09  lr: 0.000000  loss: 6.2182 (6.1978)  loss_classifier: 5.7300 (5.7439)  loss_box_reg: 0.2186 (0.2333)  loss_objectness: 0.1493 (0.1497)  loss_rpn_box_reg: 0.0744 (0.0709)  time: 0.6324  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [69]  [ 30/500]  eta: 0:05:01  lr: 0.000000  loss: 6.3514 (6.3084)  loss_classifier: 5.8218 (5.8449)  loss_box_reg: 0.2215 (0.2386)  loss_objectness: 0.1548 (0.1524)  loss_rpn_box_reg: 0.0755 (0.0726)  time: 0.6312  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [69]  [ 40/500]  eta: 0:04:52  lr: 0.000000  loss: 6.2993 (6.2870)  loss_classifier: 5.8218 (5.8177)  loss_box_reg: 0.2402 (0.2377)  loss_objectness: 0.1568 (0.1566)  loss_rpn_box_reg: 0.0764 (0.0750)  time: 0.6285  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [69]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 6.1397 (6.2539)  loss_classifier: 5.6160 (5.7836)  loss_box_reg: 0.2496 (0.2404)  loss_objectness: 0.1526 (0.1541)  loss_rpn_box_reg: 0.0759 (0.0758)  time: 0.6093  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [69]  [ 60/500]  eta: 0:04:36  lr: 0.000000  loss: 6.1397 (6.2441)  loss_classifier: 5.6034 (5.7712)  loss_box_reg: 0.2260 (0.2400)  loss_objectness: 0.1560 (0.1546)  loss_rpn_box_reg: 0.0818 (0.0783)  time: 0.6113  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [69]  [ 70/500]  eta: 0:04:29  lr: 0.000000  loss: 6.1811 (6.2394)  loss_classifier: 5.6493 (5.7662)  loss_box_reg: 0.2468 (0.2435)  loss_objectness: 0.1561 (0.1523)  loss_rpn_box_reg: 0.0804 (0.0775)  time: 0.6232  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [69]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 6.2728 (6.2623)  loss_classifier: 5.9028 (5.7870)  loss_box_reg: 0.2468 (0.2446)  loss_objectness: 0.1462 (0.1519)  loss_rpn_box_reg: 0.0807 (0.0788)  time: 0.6206  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [69]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 6.1409 (6.2384)  loss_classifier: 5.7330 (5.7690)  loss_box_reg: 0.2143 (0.2431)  loss_objectness: 0.1361 (0.1500)  loss_rpn_box_reg: 0.0620 (0.0763)  time: 0.6331  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [69]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 5.9899 (6.2406)  loss_classifier: 5.5369 (5.7752)  loss_box_reg: 0.2143 (0.2409)  loss_objectness: 0.1307 (0.1481)  loss_rpn_box_reg: 0.0506 (0.0764)  time: 0.6328  data: 0.1313  max mem: 10734\n",
      "Training Epoch: [69]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 5.9008 (6.2289)  loss_classifier: 5.4636 (5.7595)  loss_box_reg: 0.2328 (0.2430)  loss_objectness: 0.1410 (0.1493)  loss_rpn_box_reg: 0.0719 (0.0770)  time: 0.6084  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [69]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 5.9446 (6.2193)  loss_classifier: 5.4546 (5.7466)  loss_box_reg: 0.2436 (0.2443)  loss_objectness: 0.1680 (0.1509)  loss_rpn_box_reg: 0.0828 (0.0774)  time: 0.6039  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [69]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.1625 (6.2258)  loss_classifier: 5.6634 (5.7524)  loss_box_reg: 0.2538 (0.2446)  loss_objectness: 0.1576 (0.1511)  loss_rpn_box_reg: 0.0779 (0.0776)  time: 0.6296  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [69]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 6.1856 (6.2316)  loss_classifier: 5.6634 (5.7573)  loss_box_reg: 0.2187 (0.2437)  loss_objectness: 0.1327 (0.1514)  loss_rpn_box_reg: 0.0908 (0.0792)  time: 0.6275  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [69]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.0660 (6.2185)  loss_classifier: 5.6041 (5.7443)  loss_box_reg: 0.2187 (0.2441)  loss_objectness: 0.1327 (0.1520)  loss_rpn_box_reg: 0.0820 (0.0780)  time: 0.6109  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [69]  [160/500]  eta: 0:03:31  lr: 0.000000  loss: 6.0993 (6.2136)  loss_classifier: 5.5724 (5.7405)  loss_box_reg: 0.2240 (0.2419)  loss_objectness: 0.1571 (0.1527)  loss_rpn_box_reg: 0.0749 (0.0785)  time: 0.6159  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [69]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 6.1132 (6.2161)  loss_classifier: 5.5897 (5.7426)  loss_box_reg: 0.2283 (0.2430)  loss_objectness: 0.1550 (0.1521)  loss_rpn_box_reg: 0.0797 (0.0785)  time: 0.6115  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [69]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.0281 (6.2088)  loss_classifier: 5.5440 (5.7353)  loss_box_reg: 0.2493 (0.2422)  loss_objectness: 0.1550 (0.1530)  loss_rpn_box_reg: 0.0660 (0.0783)  time: 0.6193  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [69]  [190/500]  eta: 0:03:12  lr: 0.000000  loss: 6.1443 (6.2131)  loss_classifier: 5.6089 (5.7385)  loss_box_reg: 0.2542 (0.2434)  loss_objectness: 0.1670 (0.1528)  loss_rpn_box_reg: 0.0660 (0.0784)  time: 0.6155  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [69]  [200/500]  eta: 0:03:06  lr: 0.000000  loss: 6.2212 (6.2093)  loss_classifier: 5.6089 (5.7320)  loss_box_reg: 0.2691 (0.2457)  loss_objectness: 0.1460 (0.1531)  loss_rpn_box_reg: 0.0710 (0.0785)  time: 0.6110  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [69]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.0677 (6.2094)  loss_classifier: 5.5814 (5.7330)  loss_box_reg: 0.2476 (0.2453)  loss_objectness: 0.1490 (0.1525)  loss_rpn_box_reg: 0.0746 (0.0786)  time: 0.6372  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [69]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.1819 (6.2103)  loss_classifier: 5.6154 (5.7328)  loss_box_reg: 0.2163 (0.2451)  loss_objectness: 0.1567 (0.1538)  loss_rpn_box_reg: 0.0748 (0.0787)  time: 0.6502  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [69]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.4199 (6.2254)  loss_classifier: 5.9845 (5.7492)  loss_box_reg: 0.2128 (0.2441)  loss_objectness: 0.1573 (0.1539)  loss_rpn_box_reg: 0.0699 (0.0782)  time: 0.6436  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [69]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.5378 (6.2373)  loss_classifier: 6.0641 (5.7616)  loss_box_reg: 0.2192 (0.2437)  loss_objectness: 0.1398 (0.1537)  loss_rpn_box_reg: 0.0624 (0.0783)  time: 0.6390  data: 0.1314  max mem: 10734\n",
      "Training Epoch: [69]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.3979 (6.2312)  loss_classifier: 5.9251 (5.7581)  loss_box_reg: 0.2192 (0.2424)  loss_objectness: 0.1343 (0.1533)  loss_rpn_box_reg: 0.0590 (0.0774)  time: 0.6329  data: 0.1303  max mem: 10734\n",
      "Training Epoch: [69]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.0742 (6.2333)  loss_classifier: 5.7229 (5.7609)  loss_box_reg: 0.2065 (0.2425)  loss_objectness: 0.1329 (0.1529)  loss_rpn_box_reg: 0.0616 (0.0770)  time: 0.6344  data: 0.1384  max mem: 10734\n",
      "Training Epoch: [69]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.2676 (6.2307)  loss_classifier: 5.7236 (5.7567)  loss_box_reg: 0.2339 (0.2431)  loss_objectness: 0.1501 (0.1533)  loss_rpn_box_reg: 0.0755 (0.0777)  time: 0.6435  data: 0.1439  max mem: 10734\n",
      "Training Epoch: [69]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.1358 (6.2178)  loss_classifier: 5.7236 (5.7466)  loss_box_reg: 0.2213 (0.2412)  loss_objectness: 0.1395 (0.1528)  loss_rpn_box_reg: 0.0738 (0.0772)  time: 0.6437  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [69]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.0431 (6.2107)  loss_classifier: 5.5611 (5.7400)  loss_box_reg: 0.2031 (0.2409)  loss_objectness: 0.1476 (0.1532)  loss_rpn_box_reg: 0.0562 (0.0767)  time: 0.6402  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [69]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.0146 (6.2088)  loss_classifier: 5.5611 (5.7387)  loss_box_reg: 0.2179 (0.2410)  loss_objectness: 0.1467 (0.1527)  loss_rpn_box_reg: 0.0601 (0.0764)  time: 0.6326  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [69]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.0331 (6.2136)  loss_classifier: 5.6157 (5.7447)  loss_box_reg: 0.2073 (0.2405)  loss_objectness: 0.1422 (0.1524)  loss_rpn_box_reg: 0.0608 (0.0760)  time: 0.6344  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [69]  [320/500]  eta: 0:01:53  lr: 0.000000  loss: 6.3553 (6.2229)  loss_classifier: 5.7416 (5.7542)  loss_box_reg: 0.2177 (0.2405)  loss_objectness: 0.1444 (0.1526)  loss_rpn_box_reg: 0.0592 (0.0756)  time: 0.6348  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [69]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.3103 (6.2241)  loss_classifier: 5.9233 (5.7565)  loss_box_reg: 0.2240 (0.2399)  loss_objectness: 0.1444 (0.1524)  loss_rpn_box_reg: 0.0586 (0.0753)  time: 0.6297  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [69]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.2599 (6.2236)  loss_classifier: 5.7977 (5.7564)  loss_box_reg: 0.2158 (0.2396)  loss_objectness: 0.1449 (0.1521)  loss_rpn_box_reg: 0.0729 (0.0755)  time: 0.6244  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [69]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.1870 (6.2193)  loss_classifier: 5.7716 (5.7515)  loss_box_reg: 0.2375 (0.2403)  loss_objectness: 0.1418 (0.1518)  loss_rpn_box_reg: 0.0778 (0.0756)  time: 0.6150  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [69]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1805 (6.2236)  loss_classifier: 5.7668 (5.7553)  loss_box_reg: 0.2255 (0.2410)  loss_objectness: 0.1527 (0.1524)  loss_rpn_box_reg: 0.0623 (0.0749)  time: 0.6176  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [69]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.3127 (6.2265)  loss_classifier: 5.8467 (5.7580)  loss_box_reg: 0.2255 (0.2412)  loss_objectness: 0.1582 (0.1523)  loss_rpn_box_reg: 0.0639 (0.0751)  time: 0.6230  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [69]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.3317 (6.2261)  loss_classifier: 5.8551 (5.7584)  loss_box_reg: 0.2298 (0.2405)  loss_objectness: 0.1367 (0.1520)  loss_rpn_box_reg: 0.0800 (0.0752)  time: 0.6168  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [69]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.2463 (6.2271)  loss_classifier: 5.8924 (5.7592)  loss_box_reg: 0.2098 (0.2404)  loss_objectness: 0.1482 (0.1524)  loss_rpn_box_reg: 0.0733 (0.0752)  time: 0.6212  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [69]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 5.9612 (6.2200)  loss_classifier: 5.4508 (5.7518)  loss_box_reg: 0.2070 (0.2405)  loss_objectness: 0.1545 (0.1525)  loss_rpn_box_reg: 0.0661 (0.0751)  time: 0.6233  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [69]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 5.9124 (6.2183)  loss_classifier: 5.3456 (5.7497)  loss_box_reg: 0.2526 (0.2408)  loss_objectness: 0.1506 (0.1524)  loss_rpn_box_reg: 0.0691 (0.0754)  time: 0.6220  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [69]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.2323 (6.2200)  loss_classifier: 5.8208 (5.7522)  loss_box_reg: 0.2323 (0.2400)  loss_objectness: 0.1515 (0.1525)  loss_rpn_box_reg: 0.0691 (0.0753)  time: 0.6229  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [69]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.3254 (6.2252)  loss_classifier: 5.8515 (5.7569)  loss_box_reg: 0.2042 (0.2402)  loss_objectness: 0.1566 (0.1525)  loss_rpn_box_reg: 0.0768 (0.0755)  time: 0.6054  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [69]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.3367 (6.2245)  loss_classifier: 5.8466 (5.7560)  loss_box_reg: 0.2337 (0.2403)  loss_objectness: 0.1507 (0.1526)  loss_rpn_box_reg: 0.0813 (0.0756)  time: 0.6068  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [69]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1869 (6.2247)  loss_classifier: 5.7239 (5.7575)  loss_box_reg: 0.2062 (0.2395)  loss_objectness: 0.1379 (0.1522)  loss_rpn_box_reg: 0.0812 (0.0756)  time: 0.6255  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [69]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.1752 (6.2208)  loss_classifier: 5.7176 (5.7534)  loss_box_reg: 0.2321 (0.2397)  loss_objectness: 0.1379 (0.1522)  loss_rpn_box_reg: 0.0674 (0.0756)  time: 0.6219  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [69]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0549 (6.2175)  loss_classifier: 5.5643 (5.7501)  loss_box_reg: 0.2414 (0.2397)  loss_objectness: 0.1459 (0.1522)  loss_rpn_box_reg: 0.0692 (0.0756)  time: 0.6235  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [69]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0250 (6.2139)  loss_classifier: 5.5223 (5.7462)  loss_box_reg: 0.2199 (0.2396)  loss_objectness: 0.1582 (0.1522)  loss_rpn_box_reg: 0.0795 (0.0760)  time: 0.6292  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [69]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0899 (6.2156)  loss_classifier: 5.6846 (5.7482)  loss_box_reg: 0.2072 (0.2390)  loss_objectness: 0.1616 (0.1525)  loss_rpn_box_reg: 0.0864 (0.0759)  time: 0.6118  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [69]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2241 (6.2153)  loss_classifier: 5.7242 (5.7488)  loss_box_reg: 0.1933 (0.2385)  loss_objectness: 0.1346 (0.1523)  loss_rpn_box_reg: 0.0608 (0.0758)  time: 0.6207  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [69] Total time: 0:05:12 (0.6254 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:51  model_time: 0.7122 (0.7122)  evaluator_time: 0.0340 (0.0340)  time: 0.8952  data: 0.1400  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4361 (0.4479)  evaluator_time: 0.0330 (0.0341)  time: 0.6310  data: 0.1529  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4661 (0.4499)  evaluator_time: 0.0350 (0.0350)  time: 0.6502  data: 0.1477  max mem: 10734\n",
      "Test: Total time: 0:01:19 (0.6371 s / it)\n",
      "Averaged stats: model_time: 0.4661 (0.4499)  evaluator_time: 0.0350 (0.0350)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [69]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.1983 (6.1983)  loss_classifier: 5.6460 (5.6460)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1255 (0.1255)  loss_rpn_box_reg: 0.1324 (0.1324)  time: 0.6491  data: 0.1500  max mem: 10734\n",
      "Testing Epoch: [69]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0075 (6.1380)  loss_classifier: 5.4341 (5.6265)  loss_box_reg: 0.2609 (0.2891)  loss_objectness: 0.1338 (0.1323)  loss_rpn_box_reg: 0.0729 (0.0901)  time: 0.5828  data: 0.1451  max mem: 10734\n",
      "Testing Epoch: [69]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1566 (6.1689)  loss_classifier: 5.6858 (5.6623)  loss_box_reg: 0.2500 (0.2846)  loss_objectness: 0.1201 (0.1319)  loss_rpn_box_reg: 0.0745 (0.0900)  time: 0.5979  data: 0.1451  max mem: 10734\n",
      "Testing Epoch: [69] Total time: 0:01:14 (0.5949 s / it)\n",
      "Training Epoch: [70]  [  0/500]  eta: 0:07:41  lr: 0.000000  loss: 6.5989 (6.5989)  loss_classifier: 6.1897 (6.1897)  loss_box_reg: 0.2075 (0.2075)  loss_objectness: 0.1516 (0.1516)  loss_rpn_box_reg: 0.0500 (0.0500)  time: 0.9222  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [70]  [ 10/500]  eta: 0:05:17  lr: 0.000000  loss: 6.5989 (6.5934)  loss_classifier: 6.1812 (6.1121)  loss_box_reg: 0.2205 (0.2316)  loss_objectness: 0.1525 (0.1722)  loss_rpn_box_reg: 0.0653 (0.0774)  time: 0.6488  data: 0.1388  max mem: 10734\n",
      "Training Epoch: [70]  [ 20/500]  eta: 0:05:04  lr: 0.000000  loss: 6.0849 (6.3831)  loss_classifier: 5.6953 (5.9440)  loss_box_reg: 0.1997 (0.2113)  loss_objectness: 0.1422 (0.1575)  loss_rpn_box_reg: 0.0616 (0.0703)  time: 0.6200  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [70]  [ 30/500]  eta: 0:04:57  lr: 0.000000  loss: 6.1489 (6.3611)  loss_classifier: 5.6477 (5.9133)  loss_box_reg: 0.2085 (0.2193)  loss_objectness: 0.1420 (0.1586)  loss_rpn_box_reg: 0.0605 (0.0699)  time: 0.6254  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [70]  [ 40/500]  eta: 0:04:51  lr: 0.000000  loss: 6.1563 (6.3155)  loss_classifier: 5.7098 (5.8648)  loss_box_reg: 0.2306 (0.2220)  loss_objectness: 0.1660 (0.1612)  loss_rpn_box_reg: 0.0605 (0.0676)  time: 0.6326  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [70]  [ 50/500]  eta: 0:04:44  lr: 0.000000  loss: 6.1985 (6.3362)  loss_classifier: 5.7156 (5.8826)  loss_box_reg: 0.2288 (0.2260)  loss_objectness: 0.1531 (0.1590)  loss_rpn_box_reg: 0.0639 (0.0686)  time: 0.6309  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [70]  [ 60/500]  eta: 0:04:36  lr: 0.000000  loss: 6.1452 (6.2937)  loss_classifier: 5.7016 (5.8417)  loss_box_reg: 0.2248 (0.2246)  loss_objectness: 0.1384 (0.1582)  loss_rpn_box_reg: 0.0647 (0.0693)  time: 0.6213  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [70]  [ 70/500]  eta: 0:04:31  lr: 0.000000  loss: 6.0538 (6.2898)  loss_classifier: 5.6123 (5.8298)  loss_box_reg: 0.2631 (0.2325)  loss_objectness: 0.1384 (0.1566)  loss_rpn_box_reg: 0.0720 (0.0709)  time: 0.6312  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [70]  [ 80/500]  eta: 0:04:24  lr: 0.000000  loss: 6.2605 (6.2849)  loss_classifier: 5.6859 (5.8208)  loss_box_reg: 0.2632 (0.2345)  loss_objectness: 0.1452 (0.1563)  loss_rpn_box_reg: 0.0720 (0.0732)  time: 0.6342  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [70]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 6.2850 (6.2967)  loss_classifier: 5.6958 (5.8244)  loss_box_reg: 0.2552 (0.2374)  loss_objectness: 0.1657 (0.1596)  loss_rpn_box_reg: 0.0786 (0.0752)  time: 0.6166  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [70]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 6.3714 (6.3034)  loss_classifier: 5.9359 (5.8292)  loss_box_reg: 0.2419 (0.2376)  loss_objectness: 0.1754 (0.1609)  loss_rpn_box_reg: 0.0867 (0.0758)  time: 0.6178  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [70]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.5154 (6.3173)  loss_classifier: 5.9786 (5.8480)  loss_box_reg: 0.2230 (0.2355)  loss_objectness: 0.1427 (0.1586)  loss_rpn_box_reg: 0.0634 (0.0752)  time: 0.6244  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [70]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.1646 (6.3101)  loss_classifier: 5.7050 (5.8417)  loss_box_reg: 0.1946 (0.2339)  loss_objectness: 0.1494 (0.1595)  loss_rpn_box_reg: 0.0623 (0.0750)  time: 0.6187  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [70]  [130/500]  eta: 0:03:50  lr: 0.000000  loss: 6.0166 (6.2849)  loss_classifier: 5.4673 (5.8186)  loss_box_reg: 0.1888 (0.2330)  loss_objectness: 0.1587 (0.1588)  loss_rpn_box_reg: 0.0645 (0.0745)  time: 0.6023  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [70]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 6.0373 (6.2805)  loss_classifier: 5.5030 (5.8162)  loss_box_reg: 0.2032 (0.2333)  loss_objectness: 0.1315 (0.1569)  loss_rpn_box_reg: 0.0630 (0.0741)  time: 0.6146  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [70]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.1721 (6.2697)  loss_classifier: 5.6392 (5.8048)  loss_box_reg: 0.2345 (0.2334)  loss_objectness: 0.1401 (0.1568)  loss_rpn_box_reg: 0.0648 (0.0746)  time: 0.6365  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [70]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.3295 (6.2798)  loss_classifier: 5.8344 (5.8129)  loss_box_reg: 0.2450 (0.2343)  loss_objectness: 0.1685 (0.1574)  loss_rpn_box_reg: 0.0780 (0.0753)  time: 0.6393  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [70]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.3891 (6.2777)  loss_classifier: 5.9196 (5.8130)  loss_box_reg: 0.2192 (0.2317)  loss_objectness: 0.1750 (0.1585)  loss_rpn_box_reg: 0.0716 (0.0745)  time: 0.6360  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [70]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.1629 (6.2740)  loss_classifier: 5.7879 (5.8087)  loss_box_reg: 0.1990 (0.2321)  loss_objectness: 0.1521 (0.1574)  loss_rpn_box_reg: 0.0761 (0.0758)  time: 0.6189  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [70]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.0736 (6.2732)  loss_classifier: 5.6795 (5.8072)  loss_box_reg: 0.2562 (0.2331)  loss_objectness: 0.1357 (0.1567)  loss_rpn_box_reg: 0.0846 (0.0762)  time: 0.6005  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [70]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.1877 (6.2668)  loss_classifier: 5.6332 (5.8002)  loss_box_reg: 0.2613 (0.2341)  loss_objectness: 0.1453 (0.1562)  loss_rpn_box_reg: 0.0629 (0.0763)  time: 0.6135  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [70]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 5.9872 (6.2597)  loss_classifier: 5.5222 (5.7946)  loss_box_reg: 0.2361 (0.2340)  loss_objectness: 0.1310 (0.1550)  loss_rpn_box_reg: 0.0620 (0.0761)  time: 0.6302  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [70]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 5.9359 (6.2510)  loss_classifier: 5.4894 (5.7858)  loss_box_reg: 0.2353 (0.2344)  loss_objectness: 0.1360 (0.1550)  loss_rpn_box_reg: 0.0590 (0.0758)  time: 0.6225  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [70]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.1779 (6.2509)  loss_classifier: 5.7161 (5.7842)  loss_box_reg: 0.2427 (0.2356)  loss_objectness: 0.1467 (0.1550)  loss_rpn_box_reg: 0.0680 (0.0762)  time: 0.6151  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [70]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.0448 (6.2407)  loss_classifier: 5.5767 (5.7739)  loss_box_reg: 0.2445 (0.2360)  loss_objectness: 0.1441 (0.1548)  loss_rpn_box_reg: 0.0708 (0.0760)  time: 0.6298  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [70]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.0448 (6.2394)  loss_classifier: 5.5767 (5.7713)  loss_box_reg: 0.2499 (0.2379)  loss_objectness: 0.1362 (0.1543)  loss_rpn_box_reg: 0.0684 (0.0760)  time: 0.6402  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [70]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.1973 (6.2351)  loss_classifier: 5.8382 (5.7685)  loss_box_reg: 0.2343 (0.2369)  loss_objectness: 0.1368 (0.1538)  loss_rpn_box_reg: 0.0608 (0.0759)  time: 0.6246  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [70]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.2895 (6.2378)  loss_classifier: 5.6894 (5.7708)  loss_box_reg: 0.2210 (0.2376)  loss_objectness: 0.1449 (0.1538)  loss_rpn_box_reg: 0.0594 (0.0756)  time: 0.6185  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [70]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.2895 (6.2395)  loss_classifier: 5.6894 (5.7724)  loss_box_reg: 0.2426 (0.2381)  loss_objectness: 0.1443 (0.1536)  loss_rpn_box_reg: 0.0623 (0.0754)  time: 0.6253  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [70]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.1348 (6.2332)  loss_classifier: 5.6554 (5.7660)  loss_box_reg: 0.2287 (0.2375)  loss_objectness: 0.1374 (0.1540)  loss_rpn_box_reg: 0.0623 (0.0757)  time: 0.6217  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [70]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.1348 (6.2323)  loss_classifier: 5.7270 (5.7656)  loss_box_reg: 0.2201 (0.2368)  loss_objectness: 0.1374 (0.1540)  loss_rpn_box_reg: 0.0764 (0.0758)  time: 0.6260  data: 0.1314  max mem: 10734\n",
      "Training Epoch: [70]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.2267 (6.2298)  loss_classifier: 5.7689 (5.7618)  loss_box_reg: 0.2343 (0.2379)  loss_objectness: 0.1615 (0.1542)  loss_rpn_box_reg: 0.0671 (0.0760)  time: 0.6403  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [70]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1505 (6.2291)  loss_classifier: 5.6630 (5.7618)  loss_box_reg: 0.2452 (0.2376)  loss_objectness: 0.1592 (0.1543)  loss_rpn_box_reg: 0.0671 (0.0754)  time: 0.6301  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [70]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.3561 (6.2320)  loss_classifier: 5.8527 (5.7643)  loss_box_reg: 0.2445 (0.2381)  loss_objectness: 0.1501 (0.1543)  loss_rpn_box_reg: 0.0608 (0.0753)  time: 0.6195  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [70]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.2589 (6.2303)  loss_classifier: 5.7876 (5.7633)  loss_box_reg: 0.2283 (0.2380)  loss_objectness: 0.1469 (0.1540)  loss_rpn_box_reg: 0.0562 (0.0750)  time: 0.6228  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [70]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.0379 (6.2243)  loss_classifier: 5.5480 (5.7568)  loss_box_reg: 0.2046 (0.2372)  loss_objectness: 0.1469 (0.1545)  loss_rpn_box_reg: 0.0700 (0.0757)  time: 0.6197  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [70]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.0521 (6.2262)  loss_classifier: 5.5745 (5.7590)  loss_box_reg: 0.2036 (0.2366)  loss_objectness: 0.1426 (0.1546)  loss_rpn_box_reg: 0.0947 (0.0760)  time: 0.6122  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [70]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1628 (6.2264)  loss_classifier: 5.6610 (5.7585)  loss_box_reg: 0.2217 (0.2374)  loss_objectness: 0.1432 (0.1545)  loss_rpn_box_reg: 0.0654 (0.0759)  time: 0.6126  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [70]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.2479 (6.2295)  loss_classifier: 5.7635 (5.7625)  loss_box_reg: 0.2438 (0.2371)  loss_objectness: 0.1501 (0.1546)  loss_rpn_box_reg: 0.0628 (0.0754)  time: 0.6289  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [70]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.2205 (6.2217)  loss_classifier: 5.7037 (5.7548)  loss_box_reg: 0.2106 (0.2369)  loss_objectness: 0.1438 (0.1544)  loss_rpn_box_reg: 0.0654 (0.0756)  time: 0.6466  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [70]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1771 (6.2218)  loss_classifier: 5.6692 (5.7547)  loss_box_reg: 0.2274 (0.2374)  loss_objectness: 0.1308 (0.1538)  loss_rpn_box_reg: 0.0798 (0.0759)  time: 0.6359  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [70]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2289 (6.2241)  loss_classifier: 5.7026 (5.7567)  loss_box_reg: 0.2281 (0.2375)  loss_objectness: 0.1483 (0.1541)  loss_rpn_box_reg: 0.0690 (0.0758)  time: 0.6238  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [70]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.2376 (6.2228)  loss_classifier: 5.6689 (5.7542)  loss_box_reg: 0.2437 (0.2383)  loss_objectness: 0.1506 (0.1541)  loss_rpn_box_reg: 0.0761 (0.0761)  time: 0.6237  data: 0.1375  max mem: 10734\n",
      "Training Epoch: [70]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.0728 (6.2227)  loss_classifier: 5.6036 (5.7544)  loss_box_reg: 0.2565 (0.2381)  loss_objectness: 0.1552 (0.1542)  loss_rpn_box_reg: 0.0745 (0.0761)  time: 0.6244  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [70]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.0895 (6.2215)  loss_classifier: 5.6488 (5.7533)  loss_box_reg: 0.2035 (0.2379)  loss_objectness: 0.1451 (0.1542)  loss_rpn_box_reg: 0.0557 (0.0761)  time: 0.6338  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [70]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0895 (6.2193)  loss_classifier: 5.6488 (5.7499)  loss_box_reg: 0.2281 (0.2382)  loss_objectness: 0.1607 (0.1547)  loss_rpn_box_reg: 0.0694 (0.0764)  time: 0.6114  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [70]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.0648 (6.2203)  loss_classifier: 5.6224 (5.7517)  loss_box_reg: 0.2135 (0.2374)  loss_objectness: 0.1629 (0.1547)  loss_rpn_box_reg: 0.0786 (0.0766)  time: 0.6005  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [70]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1365 (6.2200)  loss_classifier: 5.7345 (5.7514)  loss_box_reg: 0.2022 (0.2373)  loss_objectness: 0.1506 (0.1546)  loss_rpn_box_reg: 0.0769 (0.0766)  time: 0.6224  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [70]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0306 (6.2191)  loss_classifier: 5.5672 (5.7507)  loss_box_reg: 0.2293 (0.2375)  loss_objectness: 0.1512 (0.1547)  loss_rpn_box_reg: 0.0604 (0.0763)  time: 0.6188  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [70]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0306 (6.2169)  loss_classifier: 5.5672 (5.7496)  loss_box_reg: 0.2178 (0.2369)  loss_objectness: 0.1418 (0.1544)  loss_rpn_box_reg: 0.0604 (0.0760)  time: 0.6173  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [70]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0196 (6.2163)  loss_classifier: 5.5405 (5.7495)  loss_box_reg: 0.2133 (0.2367)  loss_objectness: 0.1329 (0.1541)  loss_rpn_box_reg: 0.0679 (0.0760)  time: 0.6334  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [70] Total time: 0:05:12 (0.6246 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:38  model_time: 0.6051 (0.6051)  evaluator_time: 0.0350 (0.0350)  time: 0.7905  data: 0.1414  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4401 (0.4493)  evaluator_time: 0.0340 (0.0349)  time: 0.6336  data: 0.1534  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4681 (0.4516)  evaluator_time: 0.0360 (0.0356)  time: 0.6606  data: 0.1541  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6406 s / it)\n",
      "Averaged stats: model_time: 0.4681 (0.4516)  evaluator_time: 0.0360 (0.0356)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [70]  [  0/125]  eta: 0:01:19  lr: 0.000000  loss: 6.1942 (6.1942)  loss_classifier: 5.6523 (5.6523)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1158 (0.1158)  loss_rpn_box_reg: 0.1316 (0.1316)  time: 0.6361  data: 0.1350  max mem: 10734\n",
      "Testing Epoch: [70]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9881 (6.1291)  loss_classifier: 5.4136 (5.6194)  loss_box_reg: 0.2609 (0.2890)  loss_objectness: 0.1287 (0.1316)  loss_rpn_box_reg: 0.0704 (0.0892)  time: 0.5869  data: 0.1470  max mem: 10734\n",
      "Testing Epoch: [70]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1726 (6.1617)  loss_classifier: 5.6916 (5.6563)  loss_box_reg: 0.2500 (0.2845)  loss_objectness: 0.1160 (0.1316)  loss_rpn_box_reg: 0.0745 (0.0894)  time: 0.5984  data: 0.1465  max mem: 10734\n",
      "Testing Epoch: [70] Total time: 0:01:14 (0.5946 s / it)\n",
      "Training Epoch: [71]  [  0/500]  eta: 0:06:13  lr: 0.000000  loss: 5.9356 (5.9356)  loss_classifier: 5.5132 (5.5132)  loss_box_reg: 0.1817 (0.1817)  loss_objectness: 0.1526 (0.1526)  loss_rpn_box_reg: 0.0881 (0.0881)  time: 0.7472  data: 0.1400  max mem: 10734\n",
      "Training Epoch: [71]  [ 10/500]  eta: 0:05:13  lr: 0.000000  loss: 6.6010 (6.4885)  loss_classifier: 6.2431 (6.0530)  loss_box_reg: 0.2120 (0.2245)  loss_objectness: 0.1390 (0.1465)  loss_rpn_box_reg: 0.0677 (0.0645)  time: 0.6401  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [71]  [ 20/500]  eta: 0:05:04  lr: 0.000000  loss: 6.3700 (6.3770)  loss_classifier: 5.9663 (5.8953)  loss_box_reg: 0.2372 (0.2476)  loss_objectness: 0.1569 (0.1568)  loss_rpn_box_reg: 0.0777 (0.0773)  time: 0.6278  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [71]  [ 30/500]  eta: 0:04:58  lr: 0.000000  loss: 6.1232 (6.3345)  loss_classifier: 5.6379 (5.8596)  loss_box_reg: 0.2372 (0.2461)  loss_objectness: 0.1588 (0.1530)  loss_rpn_box_reg: 0.0815 (0.0758)  time: 0.6322  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [71]  [ 40/500]  eta: 0:04:48  lr: 0.000000  loss: 6.2402 (6.3590)  loss_classifier: 5.8273 (5.8946)  loss_box_reg: 0.2049 (0.2357)  loss_objectness: 0.1387 (0.1527)  loss_rpn_box_reg: 0.0625 (0.0760)  time: 0.6215  data: 0.1313  max mem: 10734\n",
      "Training Epoch: [71]  [ 50/500]  eta: 0:04:41  lr: 0.000000  loss: 6.1903 (6.3019)  loss_classifier: 5.8256 (5.8406)  loss_box_reg: 0.2022 (0.2362)  loss_objectness: 0.1345 (0.1490)  loss_rpn_box_reg: 0.0693 (0.0761)  time: 0.6101  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [71]  [ 60/500]  eta: 0:04:35  lr: 0.000000  loss: 6.1769 (6.3095)  loss_classifier: 5.7828 (5.8476)  loss_box_reg: 0.2027 (0.2385)  loss_objectness: 0.1419 (0.1488)  loss_rpn_box_reg: 0.0547 (0.0746)  time: 0.6236  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [71]  [ 70/500]  eta: 0:04:29  lr: 0.000000  loss: 6.1674 (6.2796)  loss_classifier: 5.7828 (5.8235)  loss_box_reg: 0.2261 (0.2352)  loss_objectness: 0.1416 (0.1454)  loss_rpn_box_reg: 0.0625 (0.0755)  time: 0.6331  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [71]  [ 80/500]  eta: 0:04:21  lr: 0.000000  loss: 6.1417 (6.2774)  loss_classifier: 5.6742 (5.8156)  loss_box_reg: 0.2457 (0.2387)  loss_objectness: 0.1390 (0.1467)  loss_rpn_box_reg: 0.0755 (0.0764)  time: 0.6144  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [71]  [ 90/500]  eta: 0:04:15  lr: 0.000000  loss: 6.2966 (6.3012)  loss_classifier: 5.9816 (5.8378)  loss_box_reg: 0.2457 (0.2388)  loss_objectness: 0.1485 (0.1473)  loss_rpn_box_reg: 0.0877 (0.0773)  time: 0.6033  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [71]  [100/500]  eta: 0:04:09  lr: 0.000000  loss: 6.1196 (6.2711)  loss_classifier: 5.7285 (5.8092)  loss_box_reg: 0.2144 (0.2376)  loss_objectness: 0.1538 (0.1483)  loss_rpn_box_reg: 0.0634 (0.0760)  time: 0.6265  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [71]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 6.1196 (6.2695)  loss_classifier: 5.7147 (5.8078)  loss_box_reg: 0.2501 (0.2398)  loss_objectness: 0.1413 (0.1469)  loss_rpn_box_reg: 0.0578 (0.0750)  time: 0.6363  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [71]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.1537 (6.2556)  loss_classifier: 5.6977 (5.7932)  loss_box_reg: 0.2584 (0.2400)  loss_objectness: 0.1425 (0.1477)  loss_rpn_box_reg: 0.0643 (0.0747)  time: 0.6258  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [71]  [130/500]  eta: 0:03:50  lr: 0.000000  loss: 6.3113 (6.2810)  loss_classifier: 5.8223 (5.8177)  loss_box_reg: 0.2252 (0.2396)  loss_objectness: 0.1594 (0.1490)  loss_rpn_box_reg: 0.0721 (0.0746)  time: 0.6158  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [71]  [140/500]  eta: 0:03:43  lr: 0.000000  loss: 6.4821 (6.2912)  loss_classifier: 5.9412 (5.8236)  loss_box_reg: 0.2505 (0.2421)  loss_objectness: 0.1688 (0.1504)  loss_rpn_box_reg: 0.0820 (0.0751)  time: 0.6068  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [71]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.2557 (6.2704)  loss_classifier: 5.7041 (5.8025)  loss_box_reg: 0.2480 (0.2417)  loss_objectness: 0.1635 (0.1504)  loss_rpn_box_reg: 0.0751 (0.0757)  time: 0.6222  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [71]  [160/500]  eta: 0:03:31  lr: 0.000000  loss: 6.2129 (6.2705)  loss_classifier: 5.7041 (5.8019)  loss_box_reg: 0.2172 (0.2423)  loss_objectness: 0.1394 (0.1509)  loss_rpn_box_reg: 0.0751 (0.0754)  time: 0.6348  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [71]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 6.2183 (6.2668)  loss_classifier: 5.7767 (5.7988)  loss_box_reg: 0.2416 (0.2420)  loss_objectness: 0.1382 (0.1505)  loss_rpn_box_reg: 0.0692 (0.0755)  time: 0.6285  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [71]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.2072 (6.2590)  loss_classifier: 5.7471 (5.7909)  loss_box_reg: 0.2261 (0.2421)  loss_objectness: 0.1372 (0.1508)  loss_rpn_box_reg: 0.0609 (0.0752)  time: 0.6216  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [71]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.0962 (6.2436)  loss_classifier: 5.7072 (5.7763)  loss_box_reg: 0.2202 (0.2416)  loss_objectness: 0.1551 (0.1506)  loss_rpn_box_reg: 0.0642 (0.0751)  time: 0.6238  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [71]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.0136 (6.2301)  loss_classifier: 5.5654 (5.7659)  loss_box_reg: 0.2142 (0.2397)  loss_objectness: 0.1278 (0.1501)  loss_rpn_box_reg: 0.0642 (0.0745)  time: 0.6272  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [71]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.1511 (6.2367)  loss_classifier: 5.7547 (5.7715)  loss_box_reg: 0.2104 (0.2407)  loss_objectness: 0.1412 (0.1500)  loss_rpn_box_reg: 0.0718 (0.0746)  time: 0.6271  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [71]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.4085 (6.2499)  loss_classifier: 5.8747 (5.7859)  loss_box_reg: 0.2104 (0.2394)  loss_objectness: 0.1437 (0.1496)  loss_rpn_box_reg: 0.0742 (0.0750)  time: 0.6253  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [71]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.1378 (6.2439)  loss_classifier: 5.6603 (5.7796)  loss_box_reg: 0.2156 (0.2393)  loss_objectness: 0.1428 (0.1500)  loss_rpn_box_reg: 0.0668 (0.0751)  time: 0.6080  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [71]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.1378 (6.2391)  loss_classifier: 5.6603 (5.7756)  loss_box_reg: 0.2300 (0.2387)  loss_objectness: 0.1419 (0.1501)  loss_rpn_box_reg: 0.0668 (0.0747)  time: 0.6184  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [71]  [250/500]  eta: 0:02:35  lr: 0.000000  loss: 6.1847 (6.2440)  loss_classifier: 5.7016 (5.7795)  loss_box_reg: 0.2326 (0.2391)  loss_objectness: 0.1455 (0.1503)  loss_rpn_box_reg: 0.0712 (0.0751)  time: 0.6328  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [71]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.1205 (6.2363)  loss_classifier: 5.6669 (5.7711)  loss_box_reg: 0.2306 (0.2393)  loss_objectness: 0.1475 (0.1507)  loss_rpn_box_reg: 0.0758 (0.0752)  time: 0.6234  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [71]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.1205 (6.2317)  loss_classifier: 5.6591 (5.7675)  loss_box_reg: 0.2152 (0.2391)  loss_objectness: 0.1423 (0.1504)  loss_rpn_box_reg: 0.0558 (0.0747)  time: 0.6249  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [71]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.0975 (6.2267)  loss_classifier: 5.5406 (5.7606)  loss_box_reg: 0.2582 (0.2407)  loss_objectness: 0.1433 (0.1505)  loss_rpn_box_reg: 0.0561 (0.0749)  time: 0.6209  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [71]  [290/500]  eta: 0:02:10  lr: 0.000000  loss: 6.0029 (6.2226)  loss_classifier: 5.5238 (5.7559)  loss_box_reg: 0.2518 (0.2404)  loss_objectness: 0.1651 (0.1509)  loss_rpn_box_reg: 0.0789 (0.0754)  time: 0.6168  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [71]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.1202 (6.2242)  loss_classifier: 5.6165 (5.7569)  loss_box_reg: 0.2291 (0.2412)  loss_objectness: 0.1481 (0.1504)  loss_rpn_box_reg: 0.0793 (0.0756)  time: 0.6254  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [71]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.0494 (6.2204)  loss_classifier: 5.6218 (5.7535)  loss_box_reg: 0.2370 (0.2410)  loss_objectness: 0.1402 (0.1505)  loss_rpn_box_reg: 0.0750 (0.0754)  time: 0.6291  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [71]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.0405 (6.2177)  loss_classifier: 5.6180 (5.7511)  loss_box_reg: 0.2225 (0.2409)  loss_objectness: 0.1377 (0.1502)  loss_rpn_box_reg: 0.0746 (0.0755)  time: 0.6249  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [71]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.1052 (6.2196)  loss_classifier: 5.6127 (5.7521)  loss_box_reg: 0.2405 (0.2414)  loss_objectness: 0.1337 (0.1502)  loss_rpn_box_reg: 0.0799 (0.0758)  time: 0.6298  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [71]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.1106 (6.2150)  loss_classifier: 5.5680 (5.7473)  loss_box_reg: 0.2405 (0.2412)  loss_objectness: 0.1443 (0.1508)  loss_rpn_box_reg: 0.0797 (0.0757)  time: 0.6309  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [71]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.1441 (6.2177)  loss_classifier: 5.6617 (5.7500)  loss_box_reg: 0.2083 (0.2406)  loss_objectness: 0.1579 (0.1510)  loss_rpn_box_reg: 0.0705 (0.0761)  time: 0.6122  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [71]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.3127 (6.2185)  loss_classifier: 5.8932 (5.7521)  loss_box_reg: 0.2002 (0.2397)  loss_objectness: 0.1474 (0.1507)  loss_rpn_box_reg: 0.0792 (0.0759)  time: 0.6046  data: 0.1314  max mem: 10734\n",
      "Training Epoch: [71]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1486 (6.2150)  loss_classifier: 5.5548 (5.7465)  loss_box_reg: 0.2436 (0.2411)  loss_objectness: 0.1433 (0.1509)  loss_rpn_box_reg: 0.0824 (0.0765)  time: 0.6304  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [71]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.0570 (6.2126)  loss_classifier: 5.5548 (5.7444)  loss_box_reg: 0.2482 (0.2405)  loss_objectness: 0.1635 (0.1511)  loss_rpn_box_reg: 0.0909 (0.0765)  time: 0.6358  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [71]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.0497 (6.2127)  loss_classifier: 5.5118 (5.7436)  loss_box_reg: 0.2482 (0.2412)  loss_objectness: 0.1667 (0.1513)  loss_rpn_box_reg: 0.0652 (0.0766)  time: 0.6178  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [71]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2568 (6.2141)  loss_classifier: 5.7306 (5.7441)  loss_box_reg: 0.2574 (0.2413)  loss_objectness: 0.1551 (0.1516)  loss_rpn_box_reg: 0.0901 (0.0771)  time: 0.6223  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [71]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2568 (6.2109)  loss_classifier: 5.7306 (5.7415)  loss_box_reg: 0.2416 (0.2412)  loss_objectness: 0.1561 (0.1513)  loss_rpn_box_reg: 0.0754 (0.0769)  time: 0.6229  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [71]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1045 (6.2111)  loss_classifier: 5.6928 (5.7433)  loss_box_reg: 0.1982 (0.2402)  loss_objectness: 0.1521 (0.1513)  loss_rpn_box_reg: 0.0588 (0.0763)  time: 0.6198  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [71]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1393 (6.2087)  loss_classifier: 5.6712 (5.7402)  loss_box_reg: 0.2229 (0.2409)  loss_objectness: 0.1503 (0.1512)  loss_rpn_box_reg: 0.0642 (0.0763)  time: 0.6179  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [71]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.0897 (6.2082)  loss_classifier: 5.6184 (5.7396)  loss_box_reg: 0.2444 (0.2408)  loss_objectness: 0.1439 (0.1512)  loss_rpn_box_reg: 0.0775 (0.0765)  time: 0.6231  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [71]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0939 (6.2089)  loss_classifier: 5.6677 (5.7400)  loss_box_reg: 0.2271 (0.2409)  loss_objectness: 0.1423 (0.1514)  loss_rpn_box_reg: 0.0782 (0.0767)  time: 0.6215  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [71]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.1892 (6.2078)  loss_classifier: 5.6307 (5.7391)  loss_box_reg: 0.2271 (0.2405)  loss_objectness: 0.1556 (0.1515)  loss_rpn_box_reg: 0.0768 (0.0768)  time: 0.6275  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [71]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1923 (6.2116)  loss_classifier: 5.7563 (5.7427)  loss_box_reg: 0.2385 (0.2406)  loss_objectness: 0.1578 (0.1516)  loss_rpn_box_reg: 0.0588 (0.0767)  time: 0.6302  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [71]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1846 (6.2075)  loss_classifier: 5.7289 (5.7395)  loss_box_reg: 0.2341 (0.2400)  loss_objectness: 0.1376 (0.1514)  loss_rpn_box_reg: 0.0588 (0.0766)  time: 0.6266  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [71]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 5.9658 (6.2060)  loss_classifier: 5.5253 (5.7380)  loss_box_reg: 0.2249 (0.2405)  loss_objectness: 0.1276 (0.1511)  loss_rpn_box_reg: 0.0609 (0.0764)  time: 0.6335  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [71]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0216 (6.2073)  loss_classifier: 5.6698 (5.7388)  loss_box_reg: 0.2645 (0.2411)  loss_objectness: 0.1370 (0.1512)  loss_rpn_box_reg: 0.0589 (0.0762)  time: 0.6177  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [71] Total time: 0:05:11 (0.6234 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:46  model_time: 0.6712 (0.6712)  evaluator_time: 0.0340 (0.0340)  time: 0.8542  data: 0.1400  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4441 (0.4497)  evaluator_time: 0.0350 (0.0368)  time: 0.6303  data: 0.1470  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4631 (0.4516)  evaluator_time: 0.0360 (0.0372)  time: 0.6583  data: 0.1540  max mem: 10734\n",
      "Test: Total time: 0:01:19 (0.6395 s / it)\n",
      "Averaged stats: model_time: 0.4631 (0.4516)  evaluator_time: 0.0360 (0.0372)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [71]  [  0/125]  eta: 0:01:19  lr: 0.000000  loss: 6.1993 (6.1993)  loss_classifier: 5.6518 (5.6518)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1214 (0.1214)  loss_rpn_box_reg: 0.1317 (0.1317)  time: 0.6361  data: 0.1360  max mem: 10734\n",
      "Testing Epoch: [71]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0035 (6.1336)  loss_classifier: 5.4366 (5.6207)  loss_box_reg: 0.2609 (0.2901)  loss_objectness: 0.1290 (0.1327)  loss_rpn_box_reg: 0.0704 (0.0901)  time: 0.5832  data: 0.1441  max mem: 10734\n",
      "Testing Epoch: [71]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1679 (6.1653)  loss_classifier: 5.6757 (5.6572)  loss_box_reg: 0.2500 (0.2854)  loss_objectness: 0.1202 (0.1326)  loss_rpn_box_reg: 0.0745 (0.0901)  time: 0.5963  data: 0.1443  max mem: 10734\n",
      "Testing Epoch: [71] Total time: 0:01:14 (0.5936 s / it)\n",
      "Training Epoch: [72]  [  0/500]  eta: 0:06:51  lr: 0.000000  loss: 5.6430 (5.6430)  loss_classifier: 4.9473 (4.9473)  loss_box_reg: 0.4032 (0.4032)  loss_objectness: 0.1702 (0.1702)  loss_rpn_box_reg: 0.1222 (0.1222)  time: 0.8222  data: 0.1290  max mem: 10734\n",
      "Training Epoch: [72]  [ 10/500]  eta: 0:05:19  lr: 0.000000  loss: 6.3654 (6.3856)  loss_classifier: 5.8237 (5.9534)  loss_box_reg: 0.1317 (0.1907)  loss_objectness: 0.1702 (0.1625)  loss_rpn_box_reg: 0.0805 (0.0790)  time: 0.6522  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [72]  [ 20/500]  eta: 0:05:05  lr: 0.000000  loss: 6.1725 (6.2235)  loss_classifier: 5.7332 (5.7679)  loss_box_reg: 0.2170 (0.2248)  loss_objectness: 0.1454 (0.1530)  loss_rpn_box_reg: 0.0720 (0.0778)  time: 0.6272  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [72]  [ 30/500]  eta: 0:04:57  lr: 0.000000  loss: 6.0927 (6.2219)  loss_classifier: 5.6888 (5.7730)  loss_box_reg: 0.2348 (0.2240)  loss_objectness: 0.1428 (0.1496)  loss_rpn_box_reg: 0.0636 (0.0753)  time: 0.6237  data: 0.1305  max mem: 10734\n",
      "Training Epoch: [72]  [ 40/500]  eta: 0:04:51  lr: 0.000000  loss: 6.1168 (6.2271)  loss_classifier: 5.7273 (5.7714)  loss_box_reg: 0.2154 (0.2246)  loss_objectness: 0.1611 (0.1552)  loss_rpn_box_reg: 0.0716 (0.0758)  time: 0.6323  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [72]  [ 50/500]  eta: 0:04:43  lr: 0.000000  loss: 6.2657 (6.2169)  loss_classifier: 5.7576 (5.7595)  loss_box_reg: 0.2276 (0.2322)  loss_objectness: 0.1510 (0.1522)  loss_rpn_box_reg: 0.0640 (0.0730)  time: 0.6249  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [72]  [ 60/500]  eta: 0:04:37  lr: 0.000000  loss: 6.2610 (6.2366)  loss_classifier: 5.7576 (5.7740)  loss_box_reg: 0.2355 (0.2352)  loss_objectness: 0.1446 (0.1529)  loss_rpn_box_reg: 0.0640 (0.0746)  time: 0.6227  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [72]  [ 70/500]  eta: 0:04:31  lr: 0.000000  loss: 6.2610 (6.2540)  loss_classifier: 5.8025 (5.7889)  loss_box_reg: 0.2355 (0.2368)  loss_objectness: 0.1540 (0.1538)  loss_rpn_box_reg: 0.0693 (0.0745)  time: 0.6361  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [72]  [ 80/500]  eta: 0:04:24  lr: 0.000000  loss: 6.3259 (6.2821)  loss_classifier: 5.8439 (5.8205)  loss_box_reg: 0.2216 (0.2353)  loss_objectness: 0.1455 (0.1523)  loss_rpn_box_reg: 0.0640 (0.0741)  time: 0.6308  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [72]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 6.3259 (6.2785)  loss_classifier: 5.8408 (5.8148)  loss_box_reg: 0.2295 (0.2391)  loss_objectness: 0.1426 (0.1515)  loss_rpn_box_reg: 0.0586 (0.0731)  time: 0.6140  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [72]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 6.2069 (6.2731)  loss_classifier: 5.7616 (5.8113)  loss_box_reg: 0.2359 (0.2377)  loss_objectness: 0.1421 (0.1511)  loss_rpn_box_reg: 0.0592 (0.0730)  time: 0.6151  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [72]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.2200 (6.2642)  loss_classifier: 5.7616 (5.8004)  loss_box_reg: 0.2243 (0.2398)  loss_objectness: 0.1478 (0.1503)  loss_rpn_box_reg: 0.0627 (0.0736)  time: 0.6201  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [72]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.2516 (6.2447)  loss_classifier: 5.8052 (5.7828)  loss_box_reg: 0.2261 (0.2373)  loss_objectness: 0.1308 (0.1496)  loss_rpn_box_reg: 0.0747 (0.0749)  time: 0.6251  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [72]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 6.2516 (6.2434)  loss_classifier: 5.8052 (5.7815)  loss_box_reg: 0.2186 (0.2362)  loss_objectness: 0.1286 (0.1500)  loss_rpn_box_reg: 0.0717 (0.0757)  time: 0.6402  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [72]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.0930 (6.2431)  loss_classifier: 5.7273 (5.7808)  loss_box_reg: 0.2440 (0.2368)  loss_objectness: 0.1376 (0.1498)  loss_rpn_box_reg: 0.0657 (0.0757)  time: 0.6457  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [72]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 6.1014 (6.2421)  loss_classifier: 5.6591 (5.7792)  loss_box_reg: 0.2540 (0.2373)  loss_objectness: 0.1533 (0.1503)  loss_rpn_box_reg: 0.0624 (0.0753)  time: 0.6352  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [72]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.2286 (6.2471)  loss_classifier: 5.9024 (5.7875)  loss_box_reg: 0.2109 (0.2360)  loss_objectness: 0.1380 (0.1488)  loss_rpn_box_reg: 0.0624 (0.0748)  time: 0.6249  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [72]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.2907 (6.2513)  loss_classifier: 5.9071 (5.7913)  loss_box_reg: 0.2028 (0.2363)  loss_objectness: 0.1258 (0.1493)  loss_rpn_box_reg: 0.0607 (0.0744)  time: 0.6182  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [72]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.3285 (6.2517)  loss_classifier: 5.8185 (5.7921)  loss_box_reg: 0.2378 (0.2368)  loss_objectness: 0.1481 (0.1485)  loss_rpn_box_reg: 0.0607 (0.0743)  time: 0.6166  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [72]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.3747 (6.2610)  loss_classifier: 5.9745 (5.8021)  loss_box_reg: 0.2322 (0.2358)  loss_objectness: 0.1460 (0.1488)  loss_rpn_box_reg: 0.0657 (0.0744)  time: 0.6262  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [72]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.2367 (6.2544)  loss_classifier: 5.8132 (5.7941)  loss_box_reg: 0.2244 (0.2372)  loss_objectness: 0.1460 (0.1487)  loss_rpn_box_reg: 0.0713 (0.0744)  time: 0.6328  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [72]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.1340 (6.2503)  loss_classifier: 5.7526 (5.7908)  loss_box_reg: 0.2325 (0.2369)  loss_objectness: 0.1560 (0.1488)  loss_rpn_box_reg: 0.0583 (0.0738)  time: 0.6301  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [72]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.1416 (6.2470)  loss_classifier: 5.7526 (5.7868)  loss_box_reg: 0.2491 (0.2368)  loss_objectness: 0.1560 (0.1493)  loss_rpn_box_reg: 0.0559 (0.0742)  time: 0.6239  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [72]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.0580 (6.2456)  loss_classifier: 5.6770 (5.7845)  loss_box_reg: 0.2224 (0.2366)  loss_objectness: 0.1554 (0.1500)  loss_rpn_box_reg: 0.0619 (0.0746)  time: 0.6281  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [72]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.3063 (6.2475)  loss_classifier: 5.7675 (5.7879)  loss_box_reg: 0.2162 (0.2353)  loss_objectness: 0.1536 (0.1498)  loss_rpn_box_reg: 0.0656 (0.0744)  time: 0.6339  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [72]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.2683 (6.2414)  loss_classifier: 5.7316 (5.7816)  loss_box_reg: 0.2177 (0.2355)  loss_objectness: 0.1482 (0.1501)  loss_rpn_box_reg: 0.0606 (0.0743)  time: 0.6201  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [72]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.0278 (6.2361)  loss_classifier: 5.5480 (5.7763)  loss_box_reg: 0.2354 (0.2354)  loss_objectness: 0.1482 (0.1501)  loss_rpn_box_reg: 0.0635 (0.0743)  time: 0.6266  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [72]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.0081 (6.2314)  loss_classifier: 5.5337 (5.7716)  loss_box_reg: 0.2543 (0.2358)  loss_objectness: 0.1447 (0.1503)  loss_rpn_box_reg: 0.0635 (0.0737)  time: 0.6332  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [72]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.1703 (6.2371)  loss_classifier: 5.7487 (5.7770)  loss_box_reg: 0.2466 (0.2360)  loss_objectness: 0.1421 (0.1505)  loss_rpn_box_reg: 0.0625 (0.0736)  time: 0.6234  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [72]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.0701 (6.2354)  loss_classifier: 5.6468 (5.7760)  loss_box_reg: 0.2175 (0.2354)  loss_objectness: 0.1427 (0.1505)  loss_rpn_box_reg: 0.0617 (0.0735)  time: 0.6185  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [72]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.0300 (6.2312)  loss_classifier: 5.5885 (5.7718)  loss_box_reg: 0.2175 (0.2354)  loss_objectness: 0.1432 (0.1504)  loss_rpn_box_reg: 0.0585 (0.0735)  time: 0.6150  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [72]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.0271 (6.2258)  loss_classifier: 5.5533 (5.7656)  loss_box_reg: 0.2573 (0.2355)  loss_objectness: 0.1492 (0.1509)  loss_rpn_box_reg: 0.0691 (0.0739)  time: 0.6222  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [72]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1269 (6.2307)  loss_classifier: 5.5533 (5.7689)  loss_box_reg: 0.2473 (0.2362)  loss_objectness: 0.1551 (0.1512)  loss_rpn_box_reg: 0.0905 (0.0744)  time: 0.6175  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [72]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.1269 (6.2243)  loss_classifier: 5.5645 (5.7619)  loss_box_reg: 0.2605 (0.2371)  loss_objectness: 0.1523 (0.1511)  loss_rpn_box_reg: 0.0870 (0.0742)  time: 0.6129  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [72]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 5.7954 (6.2164)  loss_classifier: 5.3777 (5.7531)  loss_box_reg: 0.2556 (0.2376)  loss_objectness: 0.1492 (0.1513)  loss_rpn_box_reg: 0.0751 (0.0744)  time: 0.6188  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [72]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.2321 (6.2255)  loss_classifier: 5.8989 (5.7625)  loss_box_reg: 0.2360 (0.2370)  loss_objectness: 0.1605 (0.1516)  loss_rpn_box_reg: 0.0727 (0.0744)  time: 0.6244  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [72]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.3317 (6.2224)  loss_classifier: 5.8109 (5.7582)  loss_box_reg: 0.2384 (0.2380)  loss_objectness: 0.1514 (0.1517)  loss_rpn_box_reg: 0.0666 (0.0745)  time: 0.6157  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [72]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1546 (6.2205)  loss_classifier: 5.6468 (5.7560)  loss_box_reg: 0.2404 (0.2384)  loss_objectness: 0.1494 (0.1515)  loss_rpn_box_reg: 0.0720 (0.0746)  time: 0.6106  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [72]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.2269 (6.2233)  loss_classifier: 5.6468 (5.7583)  loss_box_reg: 0.2322 (0.2384)  loss_objectness: 0.1447 (0.1516)  loss_rpn_box_reg: 0.0800 (0.0750)  time: 0.6154  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [72]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.0822 (6.2193)  loss_classifier: 5.5548 (5.7544)  loss_box_reg: 0.2207 (0.2383)  loss_objectness: 0.1367 (0.1514)  loss_rpn_box_reg: 0.0844 (0.0751)  time: 0.6129  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [72]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.0822 (6.2207)  loss_classifier: 5.5328 (5.7550)  loss_box_reg: 0.2222 (0.2385)  loss_objectness: 0.1469 (0.1520)  loss_rpn_box_reg: 0.0807 (0.0752)  time: 0.6084  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [72]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1175 (6.2177)  loss_classifier: 5.5444 (5.7517)  loss_box_reg: 0.2463 (0.2386)  loss_objectness: 0.1528 (0.1522)  loss_rpn_box_reg: 0.0805 (0.0752)  time: 0.6002  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [72]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.0855 (6.2171)  loss_classifier: 5.5444 (5.7509)  loss_box_reg: 0.2160 (0.2387)  loss_objectness: 0.1501 (0.1523)  loss_rpn_box_reg: 0.0697 (0.0751)  time: 0.6037  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [72]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1034 (6.2188)  loss_classifier: 5.5450 (5.7514)  loss_box_reg: 0.2437 (0.2395)  loss_objectness: 0.1466 (0.1523)  loss_rpn_box_reg: 0.0719 (0.0756)  time: 0.6172  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [72]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.0576 (6.2171)  loss_classifier: 5.5450 (5.7495)  loss_box_reg: 0.2399 (0.2394)  loss_objectness: 0.1433 (0.1523)  loss_rpn_box_reg: 0.0876 (0.0759)  time: 0.6279  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [72]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0848 (6.2141)  loss_classifier: 5.6035 (5.7471)  loss_box_reg: 0.2269 (0.2391)  loss_objectness: 0.1358 (0.1520)  loss_rpn_box_reg: 0.0804 (0.0759)  time: 0.6410  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [72]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.0848 (6.2154)  loss_classifier: 5.6025 (5.7480)  loss_box_reg: 0.2389 (0.2392)  loss_objectness: 0.1451 (0.1521)  loss_rpn_box_reg: 0.0766 (0.0761)  time: 0.6312  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [72]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0370 (6.2110)  loss_classifier: 5.5924 (5.7436)  loss_box_reg: 0.2511 (0.2397)  loss_objectness: 0.1454 (0.1518)  loss_rpn_box_reg: 0.0678 (0.0759)  time: 0.6086  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [72]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 5.9948 (6.2088)  loss_classifier: 5.5552 (5.7418)  loss_box_reg: 0.2371 (0.2394)  loss_objectness: 0.1454 (0.1517)  loss_rpn_box_reg: 0.0633 (0.0759)  time: 0.6187  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [72]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.2319 (6.2112)  loss_classifier: 5.7786 (5.7435)  loss_box_reg: 0.2261 (0.2400)  loss_objectness: 0.1507 (0.1517)  loss_rpn_box_reg: 0.0722 (0.0760)  time: 0.6298  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [72]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2476 (6.2113)  loss_classifier: 5.7786 (5.7436)  loss_box_reg: 0.2261 (0.2402)  loss_objectness: 0.1445 (0.1515)  loss_rpn_box_reg: 0.0817 (0.0760)  time: 0.6344  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [72] Total time: 0:05:11 (0.6239 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:13  model_time: 0.7932 (0.7932)  evaluator_time: 0.0350 (0.0350)  time: 1.0694  data: 0.2302  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4411 (0.4525)  evaluator_time: 0.0334 (0.0360)  time: 0.6284  data: 0.1475  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4661 (0.4536)  evaluator_time: 0.0350 (0.0365)  time: 0.6509  data: 0.1478  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6419 s / it)\n",
      "Averaged stats: model_time: 0.4661 (0.4536)  evaluator_time: 0.0350 (0.0365)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [72]  [  0/125]  eta: 0:01:19  lr: 0.000000  loss: 6.1981 (6.1981)  loss_classifier: 5.6456 (5.6456)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1270 (0.1270)  loss_rpn_box_reg: 0.1310 (0.1310)  time: 0.6341  data: 0.1350  max mem: 10734\n",
      "Testing Epoch: [72]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9969 (6.1324)  loss_classifier: 5.4338 (5.6229)  loss_box_reg: 0.2609 (0.2889)  loss_objectness: 0.1318 (0.1315)  loss_rpn_box_reg: 0.0697 (0.0890)  time: 0.5824  data: 0.1441  max mem: 10734\n",
      "Testing Epoch: [72]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1715 (6.1643)  loss_classifier: 5.6921 (5.6592)  loss_box_reg: 0.2500 (0.2844)  loss_objectness: 0.1213 (0.1314)  loss_rpn_box_reg: 0.0745 (0.0893)  time: 0.5965  data: 0.1449  max mem: 10734\n",
      "Testing Epoch: [72] Total time: 0:01:14 (0.5947 s / it)\n",
      "Training Epoch: [73]  [  0/500]  eta: 0:06:37  lr: 0.000000  loss: 6.3254 (6.3254)  loss_classifier: 5.8091 (5.8091)  loss_box_reg: 0.2728 (0.2728)  loss_objectness: 0.1775 (0.1775)  loss_rpn_box_reg: 0.0660 (0.0660)  time: 0.7942  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [73]  [ 10/500]  eta: 0:05:07  lr: 0.000000  loss: 6.3254 (6.3256)  loss_classifier: 5.8091 (5.8498)  loss_box_reg: 0.2003 (0.2335)  loss_objectness: 0.1457 (0.1519)  loss_rpn_box_reg: 0.0947 (0.0904)  time: 0.6281  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [73]  [ 20/500]  eta: 0:04:58  lr: 0.000000  loss: 6.2275 (6.3246)  loss_classifier: 5.7134 (5.8671)  loss_box_reg: 0.1874 (0.2178)  loss_objectness: 0.1368 (0.1549)  loss_rpn_box_reg: 0.0738 (0.0848)  time: 0.6134  data: 0.1376  max mem: 10734\n",
      "Training Epoch: [73]  [ 30/500]  eta: 0:04:52  lr: 0.000000  loss: 6.2275 (6.2755)  loss_classifier: 5.7214 (5.8108)  loss_box_reg: 0.2280 (0.2299)  loss_objectness: 0.1292 (0.1494)  loss_rpn_box_reg: 0.0619 (0.0854)  time: 0.6201  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [73]  [ 40/500]  eta: 0:04:47  lr: 0.000000  loss: 6.3318 (6.3043)  loss_classifier: 5.8025 (5.8378)  loss_box_reg: 0.2360 (0.2323)  loss_objectness: 0.1312 (0.1495)  loss_rpn_box_reg: 0.0682 (0.0847)  time: 0.6265  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [73]  [ 50/500]  eta: 0:04:41  lr: 0.000000  loss: 6.1816 (6.2480)  loss_classifier: 5.7231 (5.7859)  loss_box_reg: 0.2199 (0.2287)  loss_objectness: 0.1416 (0.1503)  loss_rpn_box_reg: 0.0682 (0.0831)  time: 0.6279  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [73]  [ 60/500]  eta: 0:04:35  lr: 0.000000  loss: 6.0405 (6.2232)  loss_classifier: 5.5672 (5.7595)  loss_box_reg: 0.2215 (0.2306)  loss_objectness: 0.1491 (0.1511)  loss_rpn_box_reg: 0.0736 (0.0821)  time: 0.6283  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [73]  [ 70/500]  eta: 0:04:31  lr: 0.000000  loss: 6.0526 (6.2062)  loss_classifier: 5.5948 (5.7469)  loss_box_reg: 0.2313 (0.2294)  loss_objectness: 0.1475 (0.1490)  loss_rpn_box_reg: 0.0752 (0.0809)  time: 0.6454  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [73]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 6.0956 (6.2108)  loss_classifier: 5.6864 (5.7523)  loss_box_reg: 0.2260 (0.2307)  loss_objectness: 0.1343 (0.1472)  loss_rpn_box_reg: 0.0744 (0.0805)  time: 0.6346  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [73]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 6.3806 (6.2435)  loss_classifier: 5.9344 (5.7858)  loss_box_reg: 0.2243 (0.2298)  loss_objectness: 0.1384 (0.1479)  loss_rpn_box_reg: 0.0744 (0.0800)  time: 0.6153  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [73]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 6.0442 (6.2126)  loss_classifier: 5.6494 (5.7559)  loss_box_reg: 0.2229 (0.2322)  loss_objectness: 0.1387 (0.1461)  loss_rpn_box_reg: 0.0713 (0.0785)  time: 0.6173  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [73]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.0392 (6.2154)  loss_classifier: 5.6238 (5.7545)  loss_box_reg: 0.2387 (0.2339)  loss_objectness: 0.1416 (0.1482)  loss_rpn_box_reg: 0.0722 (0.0788)  time: 0.6196  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [73]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.3821 (6.2389)  loss_classifier: 5.7895 (5.7760)  loss_box_reg: 0.2456 (0.2356)  loss_objectness: 0.1528 (0.1485)  loss_rpn_box_reg: 0.0725 (0.0789)  time: 0.6230  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [73]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.3504 (6.2366)  loss_classifier: 5.7879 (5.7717)  loss_box_reg: 0.2376 (0.2361)  loss_objectness: 0.1544 (0.1498)  loss_rpn_box_reg: 0.0782 (0.0790)  time: 0.6223  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [73]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 6.2153 (6.2369)  loss_classifier: 5.6501 (5.7682)  loss_box_reg: 0.2559 (0.2395)  loss_objectness: 0.1544 (0.1508)  loss_rpn_box_reg: 0.0657 (0.0784)  time: 0.6210  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [73]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.2548 (6.2356)  loss_classifier: 5.7731 (5.7676)  loss_box_reg: 0.2517 (0.2390)  loss_objectness: 0.1495 (0.1501)  loss_rpn_box_reg: 0.0603 (0.0788)  time: 0.6187  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [73]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.1522 (6.2375)  loss_classifier: 5.7731 (5.7695)  loss_box_reg: 0.2194 (0.2393)  loss_objectness: 0.1495 (0.1503)  loss_rpn_box_reg: 0.0710 (0.0784)  time: 0.6301  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [73]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.1491 (6.2427)  loss_classifier: 5.7373 (5.7763)  loss_box_reg: 0.2191 (0.2372)  loss_objectness: 0.1527 (0.1514)  loss_rpn_box_reg: 0.0638 (0.0778)  time: 0.6386  data: 0.1381  max mem: 10734\n",
      "Training Epoch: [73]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.1045 (6.2478)  loss_classifier: 5.6175 (5.7796)  loss_box_reg: 0.2393 (0.2383)  loss_objectness: 0.1518 (0.1515)  loss_rpn_box_reg: 0.0657 (0.0784)  time: 0.6302  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [73]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.0538 (6.2442)  loss_classifier: 5.6175 (5.7778)  loss_box_reg: 0.2326 (0.2374)  loss_objectness: 0.1460 (0.1514)  loss_rpn_box_reg: 0.0722 (0.0777)  time: 0.6346  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [73]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.0404 (6.2420)  loss_classifier: 5.6383 (5.7765)  loss_box_reg: 0.2106 (0.2369)  loss_objectness: 0.1489 (0.1515)  loss_rpn_box_reg: 0.0608 (0.0772)  time: 0.6288  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [73]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.0404 (6.2444)  loss_classifier: 5.6383 (5.7790)  loss_box_reg: 0.2108 (0.2362)  loss_objectness: 0.1577 (0.1523)  loss_rpn_box_reg: 0.0689 (0.0768)  time: 0.6119  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [73]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.2757 (6.2503)  loss_classifier: 5.7724 (5.7844)  loss_box_reg: 0.2254 (0.2360)  loss_objectness: 0.1558 (0.1525)  loss_rpn_box_reg: 0.0717 (0.0773)  time: 0.6234  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [73]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.1895 (6.2396)  loss_classifier: 5.7101 (5.7727)  loss_box_reg: 0.2341 (0.2366)  loss_objectness: 0.1428 (0.1526)  loss_rpn_box_reg: 0.0666 (0.0777)  time: 0.6310  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [73]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.1605 (6.2402)  loss_classifier: 5.6748 (5.7744)  loss_box_reg: 0.2341 (0.2356)  loss_objectness: 0.1574 (0.1530)  loss_rpn_box_reg: 0.0666 (0.0771)  time: 0.6249  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [73]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.3201 (6.2420)  loss_classifier: 5.7852 (5.7750)  loss_box_reg: 0.2474 (0.2372)  loss_objectness: 0.1537 (0.1531)  loss_rpn_box_reg: 0.0605 (0.0767)  time: 0.6235  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [73]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.2532 (6.2400)  loss_classifier: 5.6969 (5.7730)  loss_box_reg: 0.2550 (0.2372)  loss_objectness: 0.1487 (0.1530)  loss_rpn_box_reg: 0.0662 (0.0768)  time: 0.6264  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [73]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.1497 (6.2345)  loss_classifier: 5.6574 (5.7666)  loss_box_reg: 0.2518 (0.2377)  loss_objectness: 0.1364 (0.1530)  loss_rpn_box_reg: 0.0814 (0.0772)  time: 0.6157  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [73]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.1497 (6.2300)  loss_classifier: 5.6709 (5.7611)  loss_box_reg: 0.2559 (0.2380)  loss_objectness: 0.1399 (0.1533)  loss_rpn_box_reg: 0.0786 (0.0776)  time: 0.6170  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [73]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.2279 (6.2361)  loss_classifier: 5.7789 (5.7699)  loss_box_reg: 0.1981 (0.2361)  loss_objectness: 0.1369 (0.1534)  loss_rpn_box_reg: 0.0593 (0.0767)  time: 0.6259  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [73]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.2469 (6.2352)  loss_classifier: 5.9131 (5.7678)  loss_box_reg: 0.2018 (0.2366)  loss_objectness: 0.1630 (0.1540)  loss_rpn_box_reg: 0.0588 (0.0768)  time: 0.6286  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [73]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.0498 (6.2340)  loss_classifier: 5.6064 (5.7672)  loss_box_reg: 0.2309 (0.2365)  loss_objectness: 0.1588 (0.1534)  loss_rpn_box_reg: 0.0773 (0.0769)  time: 0.6403  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [73]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.0901 (6.2308)  loss_classifier: 5.6660 (5.7648)  loss_box_reg: 0.2309 (0.2357)  loss_objectness: 0.1437 (0.1534)  loss_rpn_box_reg: 0.0719 (0.0769)  time: 0.6416  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [73]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.0864 (6.2260)  loss_classifier: 5.6493 (5.7602)  loss_box_reg: 0.2441 (0.2357)  loss_objectness: 0.1355 (0.1529)  loss_rpn_box_reg: 0.0762 (0.0772)  time: 0.6337  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [73]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.0864 (6.2307)  loss_classifier: 5.6796 (5.7643)  loss_box_reg: 0.2488 (0.2360)  loss_objectness: 0.1412 (0.1533)  loss_rpn_box_reg: 0.0762 (0.0771)  time: 0.6158  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [73]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.2614 (6.2340)  loss_classifier: 5.8441 (5.7672)  loss_box_reg: 0.2349 (0.2362)  loss_objectness: 0.1561 (0.1537)  loss_rpn_box_reg: 0.0590 (0.0769)  time: 0.6115  data: 0.1379  max mem: 10734\n",
      "Training Epoch: [73]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.0639 (6.2315)  loss_classifier: 5.6472 (5.7659)  loss_box_reg: 0.2208 (0.2360)  loss_objectness: 0.1396 (0.1532)  loss_rpn_box_reg: 0.0590 (0.0765)  time: 0.6231  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [73]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.0265 (6.2280)  loss_classifier: 5.6406 (5.7636)  loss_box_reg: 0.2113 (0.2353)  loss_objectness: 0.1374 (0.1527)  loss_rpn_box_reg: 0.0561 (0.0764)  time: 0.6309  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [73]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.0752 (6.2256)  loss_classifier: 5.6406 (5.7600)  loss_box_reg: 0.2225 (0.2364)  loss_objectness: 0.1347 (0.1525)  loss_rpn_box_reg: 0.0672 (0.0766)  time: 0.6292  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [73]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1408 (6.2220)  loss_classifier: 5.6655 (5.7565)  loss_box_reg: 0.2707 (0.2366)  loss_objectness: 0.1424 (0.1525)  loss_rpn_box_reg: 0.0727 (0.0765)  time: 0.6224  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [73]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1659 (6.2248)  loss_classifier: 5.8311 (5.7594)  loss_box_reg: 0.2379 (0.2363)  loss_objectness: 0.1464 (0.1528)  loss_rpn_box_reg: 0.0677 (0.0764)  time: 0.6220  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [73]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1659 (6.2232)  loss_classifier: 5.7760 (5.7583)  loss_box_reg: 0.2328 (0.2361)  loss_objectness: 0.1436 (0.1526)  loss_rpn_box_reg: 0.0660 (0.0762)  time: 0.6131  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [73]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.0717 (6.2208)  loss_classifier: 5.7075 (5.7562)  loss_box_reg: 0.2334 (0.2365)  loss_objectness: 0.1309 (0.1523)  loss_rpn_box_reg: 0.0573 (0.0758)  time: 0.6106  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [73]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2365 (6.2240)  loss_classifier: 5.7075 (5.7584)  loss_box_reg: 0.2518 (0.2369)  loss_objectness: 0.1468 (0.1528)  loss_rpn_box_reg: 0.0576 (0.0759)  time: 0.6299  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [73]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2901 (6.2242)  loss_classifier: 5.7384 (5.7582)  loss_box_reg: 0.2315 (0.2368)  loss_objectness: 0.1729 (0.1530)  loss_rpn_box_reg: 0.0622 (0.0762)  time: 0.6496  data: 0.1409  max mem: 10734\n",
      "Training Epoch: [73]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.2342 (6.2244)  loss_classifier: 5.6947 (5.7578)  loss_box_reg: 0.2315 (0.2375)  loss_objectness: 0.1566 (0.1531)  loss_rpn_box_reg: 0.0609 (0.0761)  time: 0.6408  data: 0.1405  max mem: 10734\n",
      "Training Epoch: [73]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0272 (6.2197)  loss_classifier: 5.6078 (5.7519)  loss_box_reg: 0.2794 (0.2383)  loss_objectness: 0.1567 (0.1532)  loss_rpn_box_reg: 0.0770 (0.0763)  time: 0.6091  data: 0.1370  max mem: 10734\n",
      "Training Epoch: [73]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0302 (6.2193)  loss_classifier: 5.5867 (5.7520)  loss_box_reg: 0.2498 (0.2382)  loss_objectness: 0.1572 (0.1531)  loss_rpn_box_reg: 0.0674 (0.0760)  time: 0.6063  data: 0.1370  max mem: 10734\n",
      "Training Epoch: [73]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2151 (6.2202)  loss_classifier: 5.7181 (5.7521)  loss_box_reg: 0.2468 (0.2390)  loss_objectness: 0.1458 (0.1529)  loss_rpn_box_reg: 0.0669 (0.0763)  time: 0.6248  data: 0.1377  max mem: 10734\n",
      "Training Epoch: [73]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1832 (6.2183)  loss_classifier: 5.7164 (5.7507)  loss_box_reg: 0.2337 (0.2387)  loss_objectness: 0.1383 (0.1527)  loss_rpn_box_reg: 0.0687 (0.0761)  time: 0.6302  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [73]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0286 (6.2118)  loss_classifier: 5.5773 (5.7446)  loss_box_reg: 0.2231 (0.2388)  loss_objectness: 0.1225 (0.1525)  loss_rpn_box_reg: 0.0656 (0.0759)  time: 0.6501  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [73] Total time: 0:05:13 (0.6263 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:03  model_time: 0.7962 (0.7962)  evaluator_time: 0.0350 (0.0350)  time: 0.9862  data: 0.1460  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4401 (0.4526)  evaluator_time: 0.0340 (0.0371)  time: 0.6334  data: 0.1502  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4671 (0.4537)  evaluator_time: 0.0360 (0.0374)  time: 0.6533  data: 0.1499  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6435 s / it)\n",
      "Averaged stats: model_time: 0.4671 (0.4537)  evaluator_time: 0.0360 (0.0374)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [73]  [  0/125]  eta: 0:01:23  lr: 0.000000  loss: 6.2089 (6.2089)  loss_classifier: 5.6570 (5.6570)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1243 (0.1243)  loss_rpn_box_reg: 0.1331 (0.1331)  time: 0.6692  data: 0.1460  max mem: 10734\n",
      "Testing Epoch: [73]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9950 (6.1250)  loss_classifier: 5.4222 (5.6153)  loss_box_reg: 0.2609 (0.2891)  loss_objectness: 0.1247 (0.1315)  loss_rpn_box_reg: 0.0721 (0.0890)  time: 0.5861  data: 0.1465  max mem: 10734\n",
      "Testing Epoch: [73]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1569 (6.1583)  loss_classifier: 5.6920 (5.6530)  loss_box_reg: 0.2500 (0.2846)  loss_objectness: 0.1182 (0.1315)  loss_rpn_box_reg: 0.0745 (0.0892)  time: 0.5992  data: 0.1451  max mem: 10734\n",
      "Testing Epoch: [73] Total time: 0:01:14 (0.5970 s / it)\n",
      "Training Epoch: [74]  [  0/500]  eta: 0:06:35  lr: 0.000000  loss: 6.3195 (6.3195)  loss_classifier: 5.7154 (5.7154)  loss_box_reg: 0.3601 (0.3601)  loss_objectness: 0.1509 (0.1509)  loss_rpn_box_reg: 0.0931 (0.0931)  time: 0.7912  data: 0.1460  max mem: 10734\n",
      "Training Epoch: [74]  [ 10/500]  eta: 0:05:10  lr: 0.000000  loss: 6.2477 (6.0600)  loss_classifier: 5.7154 (5.6064)  loss_box_reg: 0.2312 (0.2391)  loss_objectness: 0.1340 (0.1418)  loss_rpn_box_reg: 0.0654 (0.0728)  time: 0.6347  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [74]  [ 20/500]  eta: 0:05:00  lr: 0.000000  loss: 6.2477 (6.2704)  loss_classifier: 5.8213 (5.7830)  loss_box_reg: 0.2463 (0.2574)  loss_objectness: 0.1340 (0.1497)  loss_rpn_box_reg: 0.0704 (0.0803)  time: 0.6187  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [74]  [ 30/500]  eta: 0:04:52  lr: 0.000000  loss: 5.9166 (6.0976)  loss_classifier: 5.4951 (5.6185)  loss_box_reg: 0.2324 (0.2441)  loss_objectness: 0.1733 (0.1578)  loss_rpn_box_reg: 0.0704 (0.0772)  time: 0.6150  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [74]  [ 40/500]  eta: 0:04:42  lr: 0.000000  loss: 5.8979 (6.1459)  loss_classifier: 5.4673 (5.6634)  loss_box_reg: 0.2227 (0.2463)  loss_objectness: 0.1667 (0.1576)  loss_rpn_box_reg: 0.0673 (0.0785)  time: 0.5991  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [74]  [ 50/500]  eta: 0:04:37  lr: 0.000000  loss: 6.1322 (6.1450)  loss_classifier: 5.7648 (5.6617)  loss_box_reg: 0.2594 (0.2514)  loss_objectness: 0.1469 (0.1567)  loss_rpn_box_reg: 0.0590 (0.0752)  time: 0.6057  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [74]  [ 60/500]  eta: 0:04:32  lr: 0.000000  loss: 6.4160 (6.2292)  loss_classifier: 5.8943 (5.7487)  loss_box_reg: 0.2333 (0.2502)  loss_objectness: 0.1469 (0.1566)  loss_rpn_box_reg: 0.0625 (0.0737)  time: 0.6350  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [74]  [ 70/500]  eta: 0:04:26  lr: 0.000000  loss: 6.4252 (6.2031)  loss_classifier: 5.8863 (5.7301)  loss_box_reg: 0.2284 (0.2433)  loss_objectness: 0.1525 (0.1562)  loss_rpn_box_reg: 0.0654 (0.0735)  time: 0.6314  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [74]  [ 80/500]  eta: 0:04:19  lr: 0.000000  loss: 6.0931 (6.2340)  loss_classifier: 5.7422 (5.7644)  loss_box_reg: 0.2042 (0.2384)  loss_objectness: 0.1682 (0.1582)  loss_rpn_box_reg: 0.0555 (0.0730)  time: 0.6127  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [74]  [ 90/500]  eta: 0:04:13  lr: 0.000000  loss: 6.3969 (6.2516)  loss_classifier: 5.9314 (5.7800)  loss_box_reg: 0.2214 (0.2393)  loss_objectness: 0.1577 (0.1585)  loss_rpn_box_reg: 0.0686 (0.0739)  time: 0.6101  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [74]  [100/500]  eta: 0:04:08  lr: 0.000000  loss: 6.2129 (6.2362)  loss_classifier: 5.7791 (5.7670)  loss_box_reg: 0.2321 (0.2368)  loss_objectness: 0.1552 (0.1582)  loss_rpn_box_reg: 0.0686 (0.0743)  time: 0.6267  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [74]  [110/500]  eta: 0:04:01  lr: 0.000000  loss: 6.1172 (6.2262)  loss_classifier: 5.6377 (5.7570)  loss_box_reg: 0.2282 (0.2373)  loss_objectness: 0.1466 (0.1575)  loss_rpn_box_reg: 0.0728 (0.0744)  time: 0.6309  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [74]  [120/500]  eta: 0:03:56  lr: 0.000000  loss: 6.1496 (6.2371)  loss_classifier: 5.7075 (5.7671)  loss_box_reg: 0.2315 (0.2370)  loss_objectness: 0.1396 (0.1563)  loss_rpn_box_reg: 0.0804 (0.0768)  time: 0.6365  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [74]  [130/500]  eta: 0:03:50  lr: 0.000000  loss: 6.3716 (6.2502)  loss_classifier: 5.9553 (5.7802)  loss_box_reg: 0.2335 (0.2376)  loss_objectness: 0.1487 (0.1560)  loss_rpn_box_reg: 0.0653 (0.0763)  time: 0.6346  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [74]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 6.4113 (6.2626)  loss_classifier: 5.9764 (5.7943)  loss_box_reg: 0.2170 (0.2372)  loss_objectness: 0.1487 (0.1548)  loss_rpn_box_reg: 0.0645 (0.0763)  time: 0.6269  data: 0.1311  max mem: 10734\n",
      "Training Epoch: [74]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.3108 (6.2646)  loss_classifier: 5.9047 (5.7969)  loss_box_reg: 0.2207 (0.2370)  loss_objectness: 0.1506 (0.1550)  loss_rpn_box_reg: 0.0646 (0.0756)  time: 0.6342  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [74]  [160/500]  eta: 0:03:31  lr: 0.000000  loss: 6.0995 (6.2594)  loss_classifier: 5.6448 (5.7904)  loss_box_reg: 0.2401 (0.2379)  loss_objectness: 0.1540 (0.1552)  loss_rpn_box_reg: 0.0646 (0.0759)  time: 0.6234  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [74]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 6.0722 (6.2505)  loss_classifier: 5.5507 (5.7807)  loss_box_reg: 0.2401 (0.2380)  loss_objectness: 0.1588 (0.1557)  loss_rpn_box_reg: 0.0706 (0.0761)  time: 0.6189  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [74]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.2814 (6.2579)  loss_classifier: 5.8164 (5.7874)  loss_box_reg: 0.2318 (0.2384)  loss_objectness: 0.1506 (0.1553)  loss_rpn_box_reg: 0.0688 (0.0767)  time: 0.6264  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [74]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.2814 (6.2462)  loss_classifier: 5.8164 (5.7770)  loss_box_reg: 0.2318 (0.2385)  loss_objectness: 0.1315 (0.1542)  loss_rpn_box_reg: 0.0688 (0.0765)  time: 0.6174  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [74]  [200/500]  eta: 0:03:06  lr: 0.000000  loss: 6.1131 (6.2470)  loss_classifier: 5.5787 (5.7767)  loss_box_reg: 0.2517 (0.2393)  loss_objectness: 0.1350 (0.1542)  loss_rpn_box_reg: 0.0716 (0.0768)  time: 0.6155  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [74]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.3833 (6.2493)  loss_classifier: 5.7109 (5.7773)  loss_box_reg: 0.2517 (0.2397)  loss_objectness: 0.1529 (0.1546)  loss_rpn_box_reg: 0.0796 (0.0776)  time: 0.6152  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [74]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.1919 (6.2472)  loss_classifier: 5.7109 (5.7767)  loss_box_reg: 0.2339 (0.2394)  loss_objectness: 0.1508 (0.1543)  loss_rpn_box_reg: 0.0724 (0.0769)  time: 0.6103  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [74]  [230/500]  eta: 0:02:47  lr: 0.000000  loss: 6.0419 (6.2389)  loss_classifier: 5.5590 (5.7694)  loss_box_reg: 0.2202 (0.2384)  loss_objectness: 0.1508 (0.1544)  loss_rpn_box_reg: 0.0664 (0.0767)  time: 0.6210  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [74]  [240/500]  eta: 0:02:41  lr: 0.000000  loss: 6.0419 (6.2348)  loss_classifier: 5.6474 (5.7670)  loss_box_reg: 0.2232 (0.2383)  loss_objectness: 0.1592 (0.1535)  loss_rpn_box_reg: 0.0642 (0.0759)  time: 0.6225  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [74]  [250/500]  eta: 0:02:35  lr: 0.000000  loss: 6.1317 (6.2281)  loss_classifier: 5.7156 (5.7624)  loss_box_reg: 0.2276 (0.2378)  loss_objectness: 0.1195 (0.1528)  loss_rpn_box_reg: 0.0482 (0.0751)  time: 0.6244  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [74]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.1576 (6.2275)  loss_classifier: 5.6930 (5.7625)  loss_box_reg: 0.2184 (0.2369)  loss_objectness: 0.1368 (0.1530)  loss_rpn_box_reg: 0.0563 (0.0751)  time: 0.6249  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [74]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.0712 (6.2325)  loss_classifier: 5.6535 (5.7677)  loss_box_reg: 0.2184 (0.2367)  loss_objectness: 0.1424 (0.1530)  loss_rpn_box_reg: 0.0696 (0.0752)  time: 0.6252  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [74]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 5.9781 (6.2263)  loss_classifier: 5.6094 (5.7632)  loss_box_reg: 0.2233 (0.2363)  loss_objectness: 0.1292 (0.1521)  loss_rpn_box_reg: 0.0615 (0.0746)  time: 0.6402  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [74]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.1901 (6.2295)  loss_classifier: 5.7396 (5.7654)  loss_box_reg: 0.2456 (0.2369)  loss_objectness: 0.1343 (0.1521)  loss_rpn_box_reg: 0.0674 (0.0750)  time: 0.6516  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [74]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.1901 (6.2256)  loss_classifier: 5.7392 (5.7616)  loss_box_reg: 0.2485 (0.2365)  loss_objectness: 0.1482 (0.1523)  loss_rpn_box_reg: 0.0738 (0.0752)  time: 0.6297  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [74]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.0420 (6.2209)  loss_classifier: 5.6561 (5.7559)  loss_box_reg: 0.2216 (0.2368)  loss_objectness: 0.1655 (0.1530)  loss_rpn_box_reg: 0.0664 (0.0752)  time: 0.6216  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [74]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1428 (6.2268)  loss_classifier: 5.6564 (5.7606)  loss_box_reg: 0.2216 (0.2367)  loss_objectness: 0.1820 (0.1535)  loss_rpn_box_reg: 0.0652 (0.0759)  time: 0.6368  data: 0.1378  max mem: 10734\n",
      "Training Epoch: [74]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.3540 (6.2328)  loss_classifier: 5.8958 (5.7668)  loss_box_reg: 0.2193 (0.2367)  loss_objectness: 0.1517 (0.1532)  loss_rpn_box_reg: 0.0652 (0.0760)  time: 0.6266  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [74]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.2019 (6.2309)  loss_classifier: 5.7731 (5.7656)  loss_box_reg: 0.2222 (0.2365)  loss_objectness: 0.1424 (0.1531)  loss_rpn_box_reg: 0.0708 (0.0758)  time: 0.6198  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [74]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 5.8600 (6.2213)  loss_classifier: 5.3536 (5.7560)  loss_box_reg: 0.2326 (0.2368)  loss_objectness: 0.1393 (0.1526)  loss_rpn_box_reg: 0.0704 (0.0759)  time: 0.6232  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [74]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 5.9022 (6.2190)  loss_classifier: 5.3536 (5.7530)  loss_box_reg: 0.2276 (0.2373)  loss_objectness: 0.1401 (0.1527)  loss_rpn_box_reg: 0.0752 (0.0760)  time: 0.6319  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [74]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.2555 (6.2218)  loss_classifier: 5.7733 (5.7551)  loss_box_reg: 0.2290 (0.2375)  loss_objectness: 0.1643 (0.1528)  loss_rpn_box_reg: 0.0779 (0.0764)  time: 0.6293  data: 0.1382  max mem: 10734\n",
      "Training Epoch: [74]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.3029 (6.2256)  loss_classifier: 5.8042 (5.7579)  loss_box_reg: 0.2534 (0.2385)  loss_objectness: 0.1395 (0.1528)  loss_rpn_box_reg: 0.0864 (0.0765)  time: 0.6271  data: 0.1405  max mem: 10734\n",
      "Training Epoch: [74]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1435 (6.2194)  loss_classifier: 5.6047 (5.7522)  loss_box_reg: 0.2534 (0.2385)  loss_objectness: 0.1387 (0.1523)  loss_rpn_box_reg: 0.0775 (0.0764)  time: 0.6321  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [74]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.0383 (6.2194)  loss_classifier: 5.6047 (5.7526)  loss_box_reg: 0.2400 (0.2384)  loss_objectness: 0.1463 (0.1523)  loss_rpn_box_reg: 0.0608 (0.0761)  time: 0.6348  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [74]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.0525 (6.2193)  loss_classifier: 5.6307 (5.7518)  loss_box_reg: 0.2295 (0.2389)  loss_objectness: 0.1470 (0.1522)  loss_rpn_box_reg: 0.0680 (0.0764)  time: 0.6401  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [74]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.0485 (6.2142)  loss_classifier: 5.6161 (5.7483)  loss_box_reg: 0.2167 (0.2381)  loss_objectness: 0.1405 (0.1518)  loss_rpn_box_reg: 0.0637 (0.0760)  time: 0.6329  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [74]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1193 (6.2241)  loss_classifier: 5.7081 (5.7581)  loss_box_reg: 0.2083 (0.2382)  loss_objectness: 0.1379 (0.1519)  loss_rpn_box_reg: 0.0567 (0.0759)  time: 0.6239  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [74]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2225 (6.2186)  loss_classifier: 5.5623 (5.7520)  loss_box_reg: 0.2249 (0.2386)  loss_objectness: 0.1401 (0.1522)  loss_rpn_box_reg: 0.0660 (0.0759)  time: 0.6261  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [74]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0068 (6.2166)  loss_classifier: 5.5561 (5.7500)  loss_box_reg: 0.2368 (0.2384)  loss_objectness: 0.1401 (0.1520)  loss_rpn_box_reg: 0.0789 (0.0761)  time: 0.6175  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [74]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.1817 (6.2191)  loss_classifier: 5.6796 (5.7526)  loss_box_reg: 0.2344 (0.2386)  loss_objectness: 0.1439 (0.1520)  loss_rpn_box_reg: 0.0721 (0.0759)  time: 0.6119  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [74]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.4208 (6.2207)  loss_classifier: 5.9209 (5.7542)  loss_box_reg: 0.2314 (0.2384)  loss_objectness: 0.1539 (0.1522)  loss_rpn_box_reg: 0.0654 (0.0759)  time: 0.6269  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [74]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1492 (6.2188)  loss_classifier: 5.7095 (5.7530)  loss_box_reg: 0.2209 (0.2381)  loss_objectness: 0.1539 (0.1518)  loss_rpn_box_reg: 0.0770 (0.0759)  time: 0.6279  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [74]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.2207 (6.2217)  loss_classifier: 5.7095 (5.7550)  loss_box_reg: 0.2310 (0.2389)  loss_objectness: 0.1397 (0.1520)  loss_rpn_box_reg: 0.0767 (0.0759)  time: 0.6225  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [74]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2207 (6.2205)  loss_classifier: 5.5247 (5.7539)  loss_box_reg: 0.2581 (0.2388)  loss_objectness: 0.1560 (0.1520)  loss_rpn_box_reg: 0.0659 (0.0758)  time: 0.6221  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [74] Total time: 0:05:12 (0.6252 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:53  model_time: 0.7242 (0.7242)  evaluator_time: 0.0350 (0.0350)  time: 0.9092  data: 0.1410  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4391 (0.4519)  evaluator_time: 0.0330 (0.0339)  time: 0.6372  data: 0.1537  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4651 (0.4529)  evaluator_time: 0.0360 (0.0349)  time: 0.6496  data: 0.1475  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6411 s / it)\n",
      "Averaged stats: model_time: 0.4651 (0.4529)  evaluator_time: 0.0360 (0.0349)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [74]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.1811 (6.1811)  loss_classifier: 5.6299 (5.6299)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1234 (0.1234)  loss_rpn_box_reg: 0.1333 (0.1333)  time: 0.6551  data: 0.1430  max mem: 10734\n",
      "Testing Epoch: [74]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0187 (6.1284)  loss_classifier: 5.4234 (5.6174)  loss_box_reg: 0.2609 (0.2894)  loss_objectness: 0.1294 (0.1320)  loss_rpn_box_reg: 0.0713 (0.0895)  time: 0.5829  data: 0.1448  max mem: 10734\n",
      "Testing Epoch: [74]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1579 (6.1613)  loss_classifier: 5.6862 (5.6551)  loss_box_reg: 0.2500 (0.2848)  loss_objectness: 0.1204 (0.1317)  loss_rpn_box_reg: 0.0745 (0.0897)  time: 0.5987  data: 0.1470  max mem: 10734\n",
      "Testing Epoch: [74] Total time: 0:01:14 (0.5933 s / it)\n",
      "Training Epoch: [75]  [  0/500]  eta: 0:07:19  lr: 0.000000  loss: 5.8483 (5.8483)  loss_classifier: 5.4158 (5.4158)  loss_box_reg: 0.1921 (0.1921)  loss_objectness: 0.1566 (0.1566)  loss_rpn_box_reg: 0.0838 (0.0838)  time: 0.8782  data: 0.1310  max mem: 10734\n",
      "Training Epoch: [75]  [ 10/500]  eta: 0:05:21  lr: 0.000000  loss: 5.9620 (6.1260)  loss_classifier: 5.4958 (5.6513)  loss_box_reg: 0.2282 (0.2369)  loss_objectness: 0.1566 (0.1553)  loss_rpn_box_reg: 0.0685 (0.0825)  time: 0.6569  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [75]  [ 20/500]  eta: 0:05:09  lr: 0.000000  loss: 5.9907 (6.1893)  loss_classifier: 5.6067 (5.7179)  loss_box_reg: 0.2282 (0.2361)  loss_objectness: 0.1570 (0.1571)  loss_rpn_box_reg: 0.0658 (0.0781)  time: 0.6337  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [75]  [ 30/500]  eta: 0:04:56  lr: 0.000000  loss: 5.9907 (6.1761)  loss_classifier: 5.5155 (5.6862)  loss_box_reg: 0.2462 (0.2476)  loss_objectness: 0.1568 (0.1602)  loss_rpn_box_reg: 0.0772 (0.0821)  time: 0.6178  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [75]  [ 40/500]  eta: 0:04:51  lr: 0.000000  loss: 6.0589 (6.1959)  loss_classifier: 5.4979 (5.7046)  loss_box_reg: 0.2600 (0.2507)  loss_objectness: 0.1521 (0.1593)  loss_rpn_box_reg: 0.0847 (0.0813)  time: 0.6234  data: 0.1370  max mem: 10734\n",
      "Training Epoch: [75]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 6.0519 (6.1605)  loss_classifier: 5.6266 (5.6798)  loss_box_reg: 0.2501 (0.2458)  loss_objectness: 0.1413 (0.1566)  loss_rpn_box_reg: 0.0720 (0.0783)  time: 0.6213  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [75]  [ 60/500]  eta: 0:04:36  lr: 0.000000  loss: 6.0234 (6.1546)  loss_classifier: 5.6024 (5.6784)  loss_box_reg: 0.2449 (0.2478)  loss_objectness: 0.1273 (0.1526)  loss_rpn_box_reg: 0.0619 (0.0758)  time: 0.6185  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [75]  [ 70/500]  eta: 0:04:30  lr: 0.000000  loss: 6.0408 (6.1487)  loss_classifier: 5.6354 (5.6767)  loss_box_reg: 0.2166 (0.2452)  loss_objectness: 0.1281 (0.1519)  loss_rpn_box_reg: 0.0588 (0.0748)  time: 0.6364  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [75]  [ 80/500]  eta: 0:04:24  lr: 0.000000  loss: 6.0790 (6.1493)  loss_classifier: 5.7003 (5.6798)  loss_box_reg: 0.2103 (0.2421)  loss_objectness: 0.1466 (0.1533)  loss_rpn_box_reg: 0.0598 (0.0740)  time: 0.6354  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [75]  [ 90/500]  eta: 0:04:18  lr: 0.000000  loss: 6.0172 (6.1291)  loss_classifier: 5.5121 (5.6589)  loss_box_reg: 0.2206 (0.2432)  loss_objectness: 0.1518 (0.1539)  loss_rpn_box_reg: 0.0663 (0.0730)  time: 0.6274  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [75]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 5.8781 (6.1110)  loss_classifier: 5.3862 (5.6427)  loss_box_reg: 0.2206 (0.2413)  loss_objectness: 0.1493 (0.1537)  loss_rpn_box_reg: 0.0663 (0.0733)  time: 0.6212  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [75]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.0970 (6.1162)  loss_classifier: 5.5833 (5.6490)  loss_box_reg: 0.2178 (0.2399)  loss_objectness: 0.1301 (0.1529)  loss_rpn_box_reg: 0.0851 (0.0744)  time: 0.6178  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [75]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.2051 (6.1308)  loss_classifier: 5.7957 (5.6650)  loss_box_reg: 0.2178 (0.2381)  loss_objectness: 0.1432 (0.1529)  loss_rpn_box_reg: 0.0761 (0.0749)  time: 0.6241  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [75]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 6.2802 (6.1482)  loss_classifier: 5.8244 (5.6870)  loss_box_reg: 0.1915 (0.2355)  loss_objectness: 0.1394 (0.1514)  loss_rpn_box_reg: 0.0653 (0.0744)  time: 0.6340  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [75]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.4182 (6.1624)  loss_classifier: 5.8903 (5.7011)  loss_box_reg: 0.2168 (0.2354)  loss_objectness: 0.1448 (0.1517)  loss_rpn_box_reg: 0.0574 (0.0741)  time: 0.6211  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [75]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.2867 (6.1705)  loss_classifier: 5.8739 (5.7100)  loss_box_reg: 0.2220 (0.2345)  loss_objectness: 0.1540 (0.1524)  loss_rpn_box_reg: 0.0615 (0.0736)  time: 0.6234  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [75]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.1519 (6.1763)  loss_classifier: 5.7886 (5.7148)  loss_box_reg: 0.2018 (0.2336)  loss_objectness: 0.1602 (0.1529)  loss_rpn_box_reg: 0.0627 (0.0750)  time: 0.6330  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [75]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.3216 (6.1815)  loss_classifier: 5.8236 (5.7221)  loss_box_reg: 0.2133 (0.2329)  loss_objectness: 0.1366 (0.1520)  loss_rpn_box_reg: 0.0704 (0.0745)  time: 0.6421  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [75]  [180/500]  eta: 0:03:21  lr: 0.000000  loss: 6.3517 (6.1832)  loss_classifier: 5.8593 (5.7202)  loss_box_reg: 0.2364 (0.2355)  loss_objectness: 0.1360 (0.1520)  loss_rpn_box_reg: 0.0795 (0.0755)  time: 0.6384  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [75]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.1085 (6.1786)  loss_classifier: 5.5809 (5.7143)  loss_box_reg: 0.2440 (0.2360)  loss_objectness: 0.1440 (0.1525)  loss_rpn_box_reg: 0.0798 (0.0758)  time: 0.6215  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [75]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.0251 (6.1795)  loss_classifier: 5.5809 (5.7167)  loss_box_reg: 0.2463 (0.2364)  loss_objectness: 0.1392 (0.1515)  loss_rpn_box_reg: 0.0677 (0.0749)  time: 0.6278  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [75]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.1997 (6.1823)  loss_classifier: 5.6882 (5.7181)  loss_box_reg: 0.2484 (0.2373)  loss_objectness: 0.1284 (0.1515)  loss_rpn_box_reg: 0.0618 (0.0754)  time: 0.6201  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [75]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.3029 (6.1893)  loss_classifier: 5.7871 (5.7253)  loss_box_reg: 0.2234 (0.2372)  loss_objectness: 0.1441 (0.1515)  loss_rpn_box_reg: 0.0560 (0.0754)  time: 0.6024  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [75]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.3443 (6.1997)  loss_classifier: 5.8734 (5.7368)  loss_box_reg: 0.2233 (0.2366)  loss_objectness: 0.1515 (0.1512)  loss_rpn_box_reg: 0.0608 (0.0752)  time: 0.6086  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [75]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.3428 (6.1968)  loss_classifier: 5.9893 (5.7361)  loss_box_reg: 0.2150 (0.2352)  loss_objectness: 0.1420 (0.1508)  loss_rpn_box_reg: 0.0647 (0.0748)  time: 0.6166  data: 0.1313  max mem: 10734\n",
      "Training Epoch: [75]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.0680 (6.1936)  loss_classifier: 5.5353 (5.7326)  loss_box_reg: 0.2102 (0.2341)  loss_objectness: 0.1431 (0.1519)  loss_rpn_box_reg: 0.0731 (0.0750)  time: 0.6269  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [75]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 5.8759 (6.1845)  loss_classifier: 5.3033 (5.7229)  loss_box_reg: 0.2175 (0.2342)  loss_objectness: 0.1475 (0.1520)  loss_rpn_box_reg: 0.0763 (0.0754)  time: 0.6254  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [75]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.0947 (6.1941)  loss_classifier: 5.6414 (5.7339)  loss_box_reg: 0.2200 (0.2336)  loss_objectness: 0.1406 (0.1517)  loss_rpn_box_reg: 0.0649 (0.0749)  time: 0.6182  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [75]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.3667 (6.2015)  loss_classifier: 5.9242 (5.7423)  loss_box_reg: 0.1918 (0.2322)  loss_objectness: 0.1420 (0.1522)  loss_rpn_box_reg: 0.0703 (0.0747)  time: 0.6107  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [75]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.3208 (6.2080)  loss_classifier: 5.8857 (5.7499)  loss_box_reg: 0.1970 (0.2326)  loss_objectness: 0.1388 (0.1515)  loss_rpn_box_reg: 0.0667 (0.0741)  time: 0.6096  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [75]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.2245 (6.2087)  loss_classifier: 5.8089 (5.7491)  loss_box_reg: 0.2614 (0.2339)  loss_objectness: 0.1374 (0.1517)  loss_rpn_box_reg: 0.0664 (0.0741)  time: 0.6157  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [75]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.2399 (6.2114)  loss_classifier: 5.6241 (5.7516)  loss_box_reg: 0.2468 (0.2340)  loss_objectness: 0.1431 (0.1517)  loss_rpn_box_reg: 0.0739 (0.0741)  time: 0.6257  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [75]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2399 (6.2099)  loss_classifier: 5.6128 (5.7489)  loss_box_reg: 0.2144 (0.2349)  loss_objectness: 0.1433 (0.1517)  loss_rpn_box_reg: 0.0640 (0.0744)  time: 0.6362  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [75]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.2134 (6.2112)  loss_classifier: 5.6575 (5.7486)  loss_box_reg: 0.2545 (0.2358)  loss_objectness: 0.1412 (0.1516)  loss_rpn_box_reg: 0.0746 (0.0751)  time: 0.6207  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [75]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.1652 (6.2103)  loss_classifier: 5.6575 (5.7472)  loss_box_reg: 0.2446 (0.2364)  loss_objectness: 0.1412 (0.1518)  loss_rpn_box_reg: 0.0715 (0.0750)  time: 0.6075  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [75]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.1652 (6.2110)  loss_classifier: 5.7509 (5.7478)  loss_box_reg: 0.2348 (0.2366)  loss_objectness: 0.1472 (0.1516)  loss_rpn_box_reg: 0.0627 (0.0750)  time: 0.6083  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [75]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.2207 (6.2119)  loss_classifier: 5.7750 (5.7483)  loss_box_reg: 0.2568 (0.2375)  loss_objectness: 0.1349 (0.1512)  loss_rpn_box_reg: 0.0624 (0.0749)  time: 0.6087  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [75]  [370/500]  eta: 0:01:20  lr: 0.000000  loss: 6.0085 (6.2075)  loss_classifier: 5.5181 (5.7419)  loss_box_reg: 0.2578 (0.2387)  loss_objectness: 0.1326 (0.1514)  loss_rpn_box_reg: 0.0704 (0.0755)  time: 0.6093  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [75]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.2243 (6.2092)  loss_classifier: 5.6283 (5.7442)  loss_box_reg: 0.2397 (0.2382)  loss_objectness: 0.1292 (0.1515)  loss_rpn_box_reg: 0.0729 (0.0753)  time: 0.6147  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [75]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.2243 (6.2057)  loss_classifier: 5.7102 (5.7401)  loss_box_reg: 0.2143 (0.2387)  loss_objectness: 0.1377 (0.1516)  loss_rpn_box_reg: 0.0729 (0.0753)  time: 0.6154  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [75]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1896 (6.2071)  loss_classifier: 5.7041 (5.7412)  loss_box_reg: 0.2287 (0.2385)  loss_objectness: 0.1538 (0.1519)  loss_rpn_box_reg: 0.0772 (0.0756)  time: 0.6194  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [75]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1534 (6.2053)  loss_classifier: 5.7041 (5.7391)  loss_box_reg: 0.2461 (0.2389)  loss_objectness: 0.1537 (0.1517)  loss_rpn_box_reg: 0.0763 (0.0757)  time: 0.6399  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [75]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1316 (6.2051)  loss_classifier: 5.5634 (5.7389)  loss_box_reg: 0.2491 (0.2385)  loss_objectness: 0.1469 (0.1519)  loss_rpn_box_reg: 0.0692 (0.0759)  time: 0.6243  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [75]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1109 (6.2079)  loss_classifier: 5.5634 (5.7409)  loss_box_reg: 0.2401 (0.2385)  loss_objectness: 0.1677 (0.1525)  loss_rpn_box_reg: 0.0777 (0.0759)  time: 0.5986  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [75]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 5.9691 (6.2050)  loss_classifier: 5.4822 (5.7377)  loss_box_reg: 0.2416 (0.2385)  loss_objectness: 0.1671 (0.1527)  loss_rpn_box_reg: 0.0795 (0.0761)  time: 0.6113  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [75]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0323 (6.2050)  loss_classifier: 5.5559 (5.7375)  loss_box_reg: 0.2417 (0.2390)  loss_objectness: 0.1409 (0.1524)  loss_rpn_box_reg: 0.0805 (0.0761)  time: 0.6297  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [75]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.2322 (6.2115)  loss_classifier: 5.7614 (5.7443)  loss_box_reg: 0.2365 (0.2385)  loss_objectness: 0.1406 (0.1526)  loss_rpn_box_reg: 0.0698 (0.0761)  time: 0.6321  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [75]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2872 (6.2166)  loss_classifier: 5.9087 (5.7485)  loss_box_reg: 0.2289 (0.2390)  loss_objectness: 0.1553 (0.1527)  loss_rpn_box_reg: 0.0708 (0.0764)  time: 0.6285  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [75]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2408 (6.2211)  loss_classifier: 5.7622 (5.7528)  loss_box_reg: 0.2262 (0.2385)  loss_objectness: 0.1605 (0.1532)  loss_rpn_box_reg: 0.0764 (0.0766)  time: 0.6213  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [75]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0897 (6.2180)  loss_classifier: 5.5637 (5.7510)  loss_box_reg: 0.2127 (0.2376)  loss_objectness: 0.1617 (0.1533)  loss_rpn_box_reg: 0.0562 (0.0761)  time: 0.6240  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [75]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0939 (6.2171)  loss_classifier: 5.6180 (5.7500)  loss_box_reg: 0.2232 (0.2379)  loss_objectness: 0.1535 (0.1533)  loss_rpn_box_reg: 0.0539 (0.0759)  time: 0.6210  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [75] Total time: 0:05:11 (0.6223 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:45  model_time: 0.6611 (0.6611)  evaluator_time: 0.0340 (0.0340)  time: 0.8432  data: 0.1380  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4391 (0.4514)  evaluator_time: 0.0340 (0.0349)  time: 0.6348  data: 0.1533  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4641 (0.4529)  evaluator_time: 0.0360 (0.0356)  time: 0.6584  data: 0.1540  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6418 s / it)\n",
      "Averaged stats: model_time: 0.4641 (0.4529)  evaluator_time: 0.0360 (0.0356)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [75]  [  0/125]  eta: 0:01:22  lr: 0.000000  loss: 6.1869 (6.1869)  loss_classifier: 5.6410 (5.6410)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1198 (0.1198)  loss_rpn_box_reg: 0.1317 (0.1317)  time: 0.6621  data: 0.1400  max mem: 10734\n",
      "Testing Epoch: [75]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0012 (6.1242)  loss_classifier: 5.4204 (5.6102)  loss_box_reg: 0.2609 (0.2919)  loss_objectness: 0.1304 (0.1322)  loss_rpn_box_reg: 0.0708 (0.0900)  time: 0.5827  data: 0.1448  max mem: 10734\n",
      "Testing Epoch: [75]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1669 (6.1577)  loss_classifier: 5.6834 (5.6485)  loss_box_reg: 0.2500 (0.2868)  loss_objectness: 0.1219 (0.1324)  loss_rpn_box_reg: 0.0745 (0.0900)  time: 0.5969  data: 0.1451  max mem: 10734\n",
      "Testing Epoch: [75] Total time: 0:01:14 (0.5945 s / it)\n",
      "Training Epoch: [76]  [  0/500]  eta: 0:06:46  lr: 0.000000  loss: 6.1227 (6.1227)  loss_classifier: 5.6606 (5.6606)  loss_box_reg: 0.2301 (0.2301)  loss_objectness: 0.1897 (0.1897)  loss_rpn_box_reg: 0.0424 (0.0424)  time: 0.8132  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [76]  [ 10/500]  eta: 0:05:14  lr: 0.000000  loss: 6.1227 (6.1693)  loss_classifier: 5.6234 (5.6859)  loss_box_reg: 0.2646 (0.2553)  loss_objectness: 0.1501 (0.1528)  loss_rpn_box_reg: 0.0678 (0.0753)  time: 0.6416  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [76]  [ 20/500]  eta: 0:05:03  lr: 0.000000  loss: 6.2734 (6.3092)  loss_classifier: 5.9344 (5.8224)  loss_box_reg: 0.2403 (0.2510)  loss_objectness: 0.1470 (0.1533)  loss_rpn_box_reg: 0.0798 (0.0826)  time: 0.6227  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [76]  [ 30/500]  eta: 0:04:57  lr: 0.000000  loss: 6.3804 (6.2857)  loss_classifier: 5.9685 (5.8104)  loss_box_reg: 0.2093 (0.2398)  loss_objectness: 0.1495 (0.1563)  loss_rpn_box_reg: 0.0699 (0.0791)  time: 0.6297  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [76]  [ 40/500]  eta: 0:04:49  lr: 0.000000  loss: 6.1378 (6.2566)  loss_classifier: 5.7306 (5.7875)  loss_box_reg: 0.2080 (0.2361)  loss_objectness: 0.1464 (0.1544)  loss_rpn_box_reg: 0.0666 (0.0787)  time: 0.6273  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [76]  [ 50/500]  eta: 0:04:45  lr: 0.000000  loss: 6.2547 (6.2817)  loss_classifier: 5.7310 (5.8121)  loss_box_reg: 0.2018 (0.2370)  loss_objectness: 0.1454 (0.1533)  loss_rpn_box_reg: 0.0650 (0.0793)  time: 0.6362  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [76]  [ 60/500]  eta: 0:04:39  lr: 0.000000  loss: 6.2038 (6.2323)  loss_classifier: 5.6922 (5.7655)  loss_box_reg: 0.1875 (0.2357)  loss_objectness: 0.1501 (0.1527)  loss_rpn_box_reg: 0.0678 (0.0784)  time: 0.6451  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [76]  [ 70/500]  eta: 0:04:31  lr: 0.000000  loss: 5.9750 (6.1968)  loss_classifier: 5.5440 (5.7330)  loss_box_reg: 0.2290 (0.2368)  loss_objectness: 0.1417 (0.1500)  loss_rpn_box_reg: 0.0669 (0.0769)  time: 0.6230  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [76]  [ 80/500]  eta: 0:04:25  lr: 0.000000  loss: 6.1286 (6.2125)  loss_classifier: 5.5804 (5.7447)  loss_box_reg: 0.2463 (0.2400)  loss_objectness: 0.1512 (0.1516)  loss_rpn_box_reg: 0.0644 (0.0763)  time: 0.6235  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [76]  [ 90/500]  eta: 0:04:19  lr: 0.000000  loss: 6.1246 (6.1962)  loss_classifier: 5.5401 (5.7244)  loss_box_reg: 0.2732 (0.2428)  loss_objectness: 0.1512 (0.1524)  loss_rpn_box_reg: 0.0737 (0.0766)  time: 0.6328  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [76]  [100/500]  eta: 0:04:12  lr: 0.000000  loss: 6.1084 (6.2141)  loss_classifier: 5.6842 (5.7429)  loss_box_reg: 0.2586 (0.2429)  loss_objectness: 0.1427 (0.1527)  loss_rpn_box_reg: 0.0771 (0.0756)  time: 0.6330  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [76]  [110/500]  eta: 0:04:05  lr: 0.000000  loss: 6.1522 (6.2111)  loss_classifier: 5.7371 (5.7406)  loss_box_reg: 0.2237 (0.2438)  loss_objectness: 0.1427 (0.1522)  loss_rpn_box_reg: 0.0556 (0.0744)  time: 0.6186  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [76]  [120/500]  eta: 0:03:59  lr: 0.000000  loss: 6.1522 (6.1912)  loss_classifier: 5.7371 (5.7220)  loss_box_reg: 0.2237 (0.2435)  loss_objectness: 0.1417 (0.1519)  loss_rpn_box_reg: 0.0546 (0.0737)  time: 0.6231  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [76]  [130/500]  eta: 0:03:53  lr: 0.000000  loss: 6.2691 (6.2002)  loss_classifier: 5.7368 (5.7296)  loss_box_reg: 0.2568 (0.2438)  loss_objectness: 0.1477 (0.1520)  loss_rpn_box_reg: 0.0713 (0.0747)  time: 0.6427  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [76]  [140/500]  eta: 0:03:47  lr: 0.000000  loss: 6.1365 (6.1957)  loss_classifier: 5.6851 (5.7252)  loss_box_reg: 0.2667 (0.2453)  loss_objectness: 0.1468 (0.1510)  loss_rpn_box_reg: 0.0656 (0.0742)  time: 0.6327  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [76]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 6.2924 (6.2147)  loss_classifier: 5.9342 (5.7457)  loss_box_reg: 0.2194 (0.2436)  loss_objectness: 0.1509 (0.1517)  loss_rpn_box_reg: 0.0582 (0.0737)  time: 0.6243  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [76]  [160/500]  eta: 0:03:34  lr: 0.000000  loss: 6.0954 (6.2071)  loss_classifier: 5.6391 (5.7376)  loss_box_reg: 0.2266 (0.2448)  loss_objectness: 0.1458 (0.1512)  loss_rpn_box_reg: 0.0626 (0.0734)  time: 0.6249  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [76]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 5.9973 (6.1977)  loss_classifier: 5.4582 (5.7269)  loss_box_reg: 0.2689 (0.2457)  loss_objectness: 0.1393 (0.1515)  loss_rpn_box_reg: 0.0683 (0.0737)  time: 0.6187  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [76]  [180/500]  eta: 0:03:21  lr: 0.000000  loss: 6.0662 (6.1917)  loss_classifier: 5.4577 (5.7201)  loss_box_reg: 0.2202 (0.2454)  loss_objectness: 0.1393 (0.1517)  loss_rpn_box_reg: 0.0851 (0.0745)  time: 0.6154  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [76]  [190/500]  eta: 0:03:15  lr: 0.000000  loss: 6.0662 (6.1970)  loss_classifier: 5.6747 (5.7279)  loss_box_reg: 0.2127 (0.2442)  loss_objectness: 0.1369 (0.1514)  loss_rpn_box_reg: 0.0719 (0.0736)  time: 0.6307  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [76]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.2076 (6.2007)  loss_classifier: 5.6977 (5.7344)  loss_box_reg: 0.2127 (0.2420)  loss_objectness: 0.1335 (0.1512)  loss_rpn_box_reg: 0.0583 (0.0730)  time: 0.6251  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [76]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.0537 (6.1921)  loss_classifier: 5.6616 (5.7249)  loss_box_reg: 0.2213 (0.2416)  loss_objectness: 0.1496 (0.1518)  loss_rpn_box_reg: 0.0773 (0.0738)  time: 0.6019  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [76]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.1868 (6.1967)  loss_classifier: 5.7020 (5.7302)  loss_box_reg: 0.2276 (0.2403)  loss_objectness: 0.1496 (0.1519)  loss_rpn_box_reg: 0.0867 (0.0742)  time: 0.6114  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [76]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.0674 (6.1904)  loss_classifier: 5.6894 (5.7233)  loss_box_reg: 0.2285 (0.2403)  loss_objectness: 0.1504 (0.1524)  loss_rpn_box_reg: 0.0699 (0.0745)  time: 0.6170  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [76]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 5.9800 (6.1856)  loss_classifier: 5.5499 (5.7188)  loss_box_reg: 0.2517 (0.2400)  loss_objectness: 0.1420 (0.1517)  loss_rpn_box_reg: 0.0831 (0.0751)  time: 0.6155  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [76]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 5.9375 (6.1841)  loss_classifier: 5.5610 (5.7187)  loss_box_reg: 0.2277 (0.2395)  loss_objectness: 0.1332 (0.1509)  loss_rpn_box_reg: 0.0744 (0.0750)  time: 0.6211  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [76]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.2818 (6.1979)  loss_classifier: 5.8931 (5.7307)  loss_box_reg: 0.2277 (0.2396)  loss_objectness: 0.1440 (0.1513)  loss_rpn_box_reg: 0.0833 (0.0763)  time: 0.6213  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [76]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.2818 (6.1936)  loss_classifier: 5.8532 (5.7249)  loss_box_reg: 0.2475 (0.2412)  loss_objectness: 0.1556 (0.1513)  loss_rpn_box_reg: 0.0831 (0.0762)  time: 0.6239  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [76]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.1526 (6.1939)  loss_classifier: 5.6947 (5.7276)  loss_box_reg: 0.2397 (0.2403)  loss_objectness: 0.1393 (0.1506)  loss_rpn_box_reg: 0.0592 (0.0754)  time: 0.6173  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [76]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.1526 (6.1945)  loss_classifier: 5.6846 (5.7281)  loss_box_reg: 0.2299 (0.2400)  loss_objectness: 0.1287 (0.1508)  loss_rpn_box_reg: 0.0589 (0.0756)  time: 0.6183  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [76]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.2661 (6.1987)  loss_classifier: 5.8647 (5.7338)  loss_box_reg: 0.2205 (0.2396)  loss_objectness: 0.1270 (0.1499)  loss_rpn_box_reg: 0.0724 (0.0755)  time: 0.6348  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [76]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.3262 (6.1974)  loss_classifier: 5.8647 (5.7325)  loss_box_reg: 0.2283 (0.2401)  loss_objectness: 0.1270 (0.1497)  loss_rpn_box_reg: 0.0668 (0.0751)  time: 0.6365  data: 0.1308  max mem: 10734\n",
      "Training Epoch: [76]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1393 (6.1994)  loss_classifier: 5.7075 (5.7349)  loss_box_reg: 0.2283 (0.2397)  loss_objectness: 0.1482 (0.1496)  loss_rpn_box_reg: 0.0641 (0.0752)  time: 0.6319  data: 0.1313  max mem: 10734\n",
      "Training Epoch: [76]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.0621 (6.1969)  loss_classifier: 5.6336 (5.7310)  loss_box_reg: 0.2209 (0.2399)  loss_objectness: 0.1521 (0.1505)  loss_rpn_box_reg: 0.0758 (0.0755)  time: 0.6296  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [76]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 5.9386 (6.1930)  loss_classifier: 5.4390 (5.7271)  loss_box_reg: 0.2228 (0.2399)  loss_objectness: 0.1644 (0.1506)  loss_rpn_box_reg: 0.0616 (0.0754)  time: 0.6264  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [76]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 5.9976 (6.1868)  loss_classifier: 5.4898 (5.7209)  loss_box_reg: 0.2228 (0.2391)  loss_objectness: 0.1614 (0.1513)  loss_rpn_box_reg: 0.0642 (0.0755)  time: 0.6203  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [76]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1384 (6.1917)  loss_classifier: 5.6397 (5.7258)  loss_box_reg: 0.2076 (0.2385)  loss_objectness: 0.1614 (0.1519)  loss_rpn_box_reg: 0.0730 (0.0756)  time: 0.6119  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [76]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.3804 (6.1982)  loss_classifier: 5.9426 (5.7331)  loss_box_reg: 0.2114 (0.2379)  loss_objectness: 0.1446 (0.1517)  loss_rpn_box_reg: 0.0699 (0.0755)  time: 0.6218  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [76]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.3892 (6.2009)  loss_classifier: 5.9131 (5.7358)  loss_box_reg: 0.2183 (0.2376)  loss_objectness: 0.1446 (0.1518)  loss_rpn_box_reg: 0.0715 (0.0756)  time: 0.6274  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [76]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.3966 (6.1993)  loss_classifier: 5.9131 (5.7348)  loss_box_reg: 0.2370 (0.2378)  loss_objectness: 0.1350 (0.1514)  loss_rpn_box_reg: 0.0708 (0.0752)  time: 0.6166  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [76]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2130 (6.2008)  loss_classifier: 5.7547 (5.7369)  loss_box_reg: 0.2362 (0.2379)  loss_objectness: 0.1350 (0.1510)  loss_rpn_box_reg: 0.0524 (0.0750)  time: 0.6154  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [76]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2666 (6.2100)  loss_classifier: 5.7588 (5.7450)  loss_box_reg: 0.2314 (0.2383)  loss_objectness: 0.1442 (0.1513)  loss_rpn_box_reg: 0.0865 (0.0753)  time: 0.6178  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [76]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.5344 (6.2095)  loss_classifier: 6.0499 (5.7438)  loss_box_reg: 0.2625 (0.2391)  loss_objectness: 0.1619 (0.1514)  loss_rpn_box_reg: 0.0763 (0.0751)  time: 0.6291  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [76]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1561 (6.2072)  loss_classifier: 5.6777 (5.7418)  loss_box_reg: 0.2458 (0.2387)  loss_objectness: 0.1543 (0.1516)  loss_rpn_box_reg: 0.0671 (0.0751)  time: 0.6422  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [76]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1884 (6.2081)  loss_classifier: 5.6826 (5.7425)  loss_box_reg: 0.2224 (0.2386)  loss_objectness: 0.1603 (0.1521)  loss_rpn_box_reg: 0.0732 (0.0749)  time: 0.6275  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [76]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.3282 (6.2110)  loss_classifier: 5.8707 (5.7450)  loss_box_reg: 0.2142 (0.2383)  loss_objectness: 0.1618 (0.1524)  loss_rpn_box_reg: 0.0739 (0.0753)  time: 0.6099  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [76]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.2753 (6.2118)  loss_classifier: 5.8754 (5.7455)  loss_box_reg: 0.2109 (0.2383)  loss_objectness: 0.1634 (0.1525)  loss_rpn_box_reg: 0.0793 (0.0754)  time: 0.6161  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [76]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1896 (6.2128)  loss_classifier: 5.7320 (5.7460)  loss_box_reg: 0.2215 (0.2381)  loss_objectness: 0.1633 (0.1529)  loss_rpn_box_reg: 0.0840 (0.0758)  time: 0.6184  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [76]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1316 (6.2125)  loss_classifier: 5.7320 (5.7467)  loss_box_reg: 0.2198 (0.2375)  loss_objectness: 0.1561 (0.1527)  loss_rpn_box_reg: 0.0780 (0.0756)  time: 0.6120  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [76]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1576 (6.2127)  loss_classifier: 5.6821 (5.7460)  loss_box_reg: 0.2198 (0.2377)  loss_objectness: 0.1626 (0.1530)  loss_rpn_box_reg: 0.0780 (0.0760)  time: 0.6174  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [76]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2627 (6.2140)  loss_classifier: 5.8515 (5.7469)  loss_box_reg: 0.2232 (0.2378)  loss_objectness: 0.1706 (0.1534)  loss_rpn_box_reg: 0.0780 (0.0758)  time: 0.6304  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [76] Total time: 0:05:12 (0.6245 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:45  model_time: 0.6631 (0.6631)  evaluator_time: 0.0350 (0.0350)  time: 0.8462  data: 0.1390  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4451 (0.4514)  evaluator_time: 0.0330 (0.0361)  time: 0.6416  data: 0.1540  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4661 (0.4526)  evaluator_time: 0.0360 (0.0367)  time: 0.6506  data: 0.1480  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6410 s / it)\n",
      "Averaged stats: model_time: 0.4661 (0.4526)  evaluator_time: 0.0360 (0.0367)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.28s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [76]  [  0/125]  eta: 0:01:23  lr: 0.000000  loss: 6.2015 (6.2015)  loss_classifier: 5.6579 (5.6579)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1196 (0.1196)  loss_rpn_box_reg: 0.1294 (0.1294)  time: 0.6651  data: 0.1410  max mem: 10734\n",
      "Testing Epoch: [76]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9866 (6.1251)  loss_classifier: 5.4199 (5.6141)  loss_box_reg: 0.2609 (0.2896)  loss_objectness: 0.1278 (0.1315)  loss_rpn_box_reg: 0.0746 (0.0899)  time: 0.5865  data: 0.1471  max mem: 10734\n",
      "Testing Epoch: [76]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1478 (6.1576)  loss_classifier: 5.6894 (5.6516)  loss_box_reg: 0.2500 (0.2850)  loss_objectness: 0.1174 (0.1311)  loss_rpn_box_reg: 0.0745 (0.0899)  time: 0.6001  data: 0.1457  max mem: 10734\n",
      "Testing Epoch: [76] Total time: 0:01:14 (0.5970 s / it)\n",
      "Training Epoch: [77]  [  0/500]  eta: 0:06:22  lr: 0.000000  loss: 6.8009 (6.8009)  loss_classifier: 6.3524 (6.3524)  loss_box_reg: 0.2713 (0.2713)  loss_objectness: 0.1161 (0.1161)  loss_rpn_box_reg: 0.0611 (0.0611)  time: 0.7642  data: 0.1450  max mem: 10734\n",
      "Training Epoch: [77]  [ 10/500]  eta: 0:05:09  lr: 0.000000  loss: 6.2187 (6.2396)  loss_classifier: 5.7762 (5.8156)  loss_box_reg: 0.2165 (0.2132)  loss_objectness: 0.1357 (0.1464)  loss_rpn_box_reg: 0.0558 (0.0643)  time: 0.6316  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [77]  [ 20/500]  eta: 0:05:00  lr: 0.000000  loss: 6.1689 (6.2922)  loss_classifier: 5.7048 (5.8436)  loss_box_reg: 0.2165 (0.2265)  loss_objectness: 0.1374 (0.1447)  loss_rpn_box_reg: 0.0689 (0.0773)  time: 0.6199  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [77]  [ 30/500]  eta: 0:04:53  lr: 0.000000  loss: 6.3523 (6.3225)  loss_classifier: 5.7666 (5.8552)  loss_box_reg: 0.2348 (0.2318)  loss_objectness: 0.1444 (0.1509)  loss_rpn_box_reg: 0.0822 (0.0847)  time: 0.6195  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [77]  [ 40/500]  eta: 0:04:46  lr: 0.000000  loss: 6.3559 (6.3337)  loss_classifier: 5.8067 (5.8740)  loss_box_reg: 0.2146 (0.2256)  loss_objectness: 0.1528 (0.1504)  loss_rpn_box_reg: 0.0807 (0.0837)  time: 0.6204  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [77]  [ 50/500]  eta: 0:04:39  lr: 0.000000  loss: 6.2795 (6.3094)  loss_classifier: 5.8067 (5.8547)  loss_box_reg: 0.2054 (0.2259)  loss_objectness: 0.1411 (0.1479)  loss_rpn_box_reg: 0.0739 (0.0809)  time: 0.6146  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [77]  [ 60/500]  eta: 0:04:32  lr: 0.000000  loss: 6.2487 (6.3002)  loss_classifier: 5.7700 (5.8403)  loss_box_reg: 0.2322 (0.2296)  loss_objectness: 0.1519 (0.1495)  loss_rpn_box_reg: 0.0649 (0.0809)  time: 0.6118  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [77]  [ 70/500]  eta: 0:04:26  lr: 0.000000  loss: 6.1663 (6.2940)  loss_classifier: 5.5898 (5.8259)  loss_box_reg: 0.2484 (0.2317)  loss_objectness: 0.1620 (0.1532)  loss_rpn_box_reg: 0.0829 (0.0832)  time: 0.6150  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [77]  [ 80/500]  eta: 0:04:19  lr: 0.000000  loss: 5.9617 (6.2758)  loss_classifier: 5.5898 (5.8103)  loss_box_reg: 0.2490 (0.2329)  loss_objectness: 0.1660 (0.1508)  loss_rpn_box_reg: 0.0720 (0.0817)  time: 0.6123  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [77]  [ 90/500]  eta: 0:04:12  lr: 0.000000  loss: 6.0005 (6.2562)  loss_classifier: 5.5963 (5.7904)  loss_box_reg: 0.2372 (0.2358)  loss_objectness: 0.1404 (0.1505)  loss_rpn_box_reg: 0.0677 (0.0796)  time: 0.6097  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [77]  [100/500]  eta: 0:04:07  lr: 0.000000  loss: 6.1809 (6.2681)  loss_classifier: 5.7025 (5.8038)  loss_box_reg: 0.2259 (0.2331)  loss_objectness: 0.1523 (0.1520)  loss_rpn_box_reg: 0.0665 (0.0792)  time: 0.6262  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [77]  [110/500]  eta: 0:04:02  lr: 0.000000  loss: 6.3570 (6.2722)  loss_classifier: 5.8684 (5.8020)  loss_box_reg: 0.2465 (0.2372)  loss_objectness: 0.1511 (0.1531)  loss_rpn_box_reg: 0.0720 (0.0799)  time: 0.6376  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [77]  [120/500]  eta: 0:03:55  lr: 0.000000  loss: 6.2168 (6.2633)  loss_classifier: 5.7634 (5.7958)  loss_box_reg: 0.2638 (0.2375)  loss_objectness: 0.1419 (0.1515)  loss_rpn_box_reg: 0.0720 (0.0785)  time: 0.6275  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [77]  [130/500]  eta: 0:03:49  lr: 0.000000  loss: 6.0428 (6.2462)  loss_classifier: 5.5643 (5.7773)  loss_box_reg: 0.2222 (0.2384)  loss_objectness: 0.1357 (0.1514)  loss_rpn_box_reg: 0.0675 (0.0791)  time: 0.6239  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [77]  [140/500]  eta: 0:03:43  lr: 0.000000  loss: 6.0428 (6.2457)  loss_classifier: 5.5764 (5.7754)  loss_box_reg: 0.2512 (0.2397)  loss_objectness: 0.1445 (0.1519)  loss_rpn_box_reg: 0.0755 (0.0787)  time: 0.6258  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [77]  [150/500]  eta: 0:03:37  lr: 0.000000  loss: 6.1665 (6.2482)  loss_classifier: 5.6904 (5.7775)  loss_box_reg: 0.2546 (0.2408)  loss_objectness: 0.1445 (0.1516)  loss_rpn_box_reg: 0.0755 (0.0783)  time: 0.6239  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [77]  [160/500]  eta: 0:03:31  lr: 0.000000  loss: 6.3340 (6.2588)  loss_classifier: 5.8184 (5.7868)  loss_box_reg: 0.2680 (0.2423)  loss_objectness: 0.1360 (0.1509)  loss_rpn_box_reg: 0.0798 (0.0789)  time: 0.6228  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [77]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 6.3340 (6.2614)  loss_classifier: 5.8249 (5.7894)  loss_box_reg: 0.2484 (0.2422)  loss_objectness: 0.1512 (0.1514)  loss_rpn_box_reg: 0.0644 (0.0784)  time: 0.6292  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [77]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.1570 (6.2484)  loss_classifier: 5.6701 (5.7776)  loss_box_reg: 0.2391 (0.2416)  loss_objectness: 0.1518 (0.1510)  loss_rpn_box_reg: 0.0620 (0.0781)  time: 0.6280  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [77]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 5.9924 (6.2493)  loss_classifier: 5.6464 (5.7792)  loss_box_reg: 0.2409 (0.2411)  loss_objectness: 0.1543 (0.1510)  loss_rpn_box_reg: 0.0708 (0.0780)  time: 0.6307  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [77]  [200/500]  eta: 0:03:06  lr: 0.000000  loss: 6.0396 (6.2484)  loss_classifier: 5.5688 (5.7781)  loss_box_reg: 0.2451 (0.2412)  loss_objectness: 0.1432 (0.1504)  loss_rpn_box_reg: 0.0692 (0.0787)  time: 0.6253  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [77]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.0699 (6.2663)  loss_classifier: 5.6820 (5.7947)  loss_box_reg: 0.2451 (0.2417)  loss_objectness: 0.1487 (0.1513)  loss_rpn_box_reg: 0.0700 (0.0786)  time: 0.6229  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [77]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.0092 (6.2580)  loss_classifier: 5.6634 (5.7861)  loss_box_reg: 0.2367 (0.2423)  loss_objectness: 0.1517 (0.1511)  loss_rpn_box_reg: 0.0736 (0.0785)  time: 0.6284  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [77]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 5.9998 (6.2503)  loss_classifier: 5.4548 (5.7783)  loss_box_reg: 0.2614 (0.2428)  loss_objectness: 0.1419 (0.1505)  loss_rpn_box_reg: 0.0770 (0.0787)  time: 0.6277  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [77]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.0949 (6.2433)  loss_classifier: 5.5982 (5.7721)  loss_box_reg: 0.2423 (0.2427)  loss_objectness: 0.1307 (0.1500)  loss_rpn_box_reg: 0.0707 (0.0785)  time: 0.6358  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [77]  [250/500]  eta: 0:02:35  lr: 0.000000  loss: 6.2304 (6.2413)  loss_classifier: 5.6784 (5.7697)  loss_box_reg: 0.2209 (0.2420)  loss_objectness: 0.1299 (0.1504)  loss_rpn_box_reg: 0.0747 (0.0792)  time: 0.6262  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [77]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.1459 (6.2422)  loss_classifier: 5.6137 (5.7707)  loss_box_reg: 0.2314 (0.2421)  loss_objectness: 0.1451 (0.1508)  loss_rpn_box_reg: 0.0633 (0.0786)  time: 0.6183  data: 0.1384  max mem: 10734\n",
      "Training Epoch: [77]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.2253 (6.2431)  loss_classifier: 5.6594 (5.7732)  loss_box_reg: 0.2354 (0.2411)  loss_objectness: 0.1406 (0.1503)  loss_rpn_box_reg: 0.0633 (0.0786)  time: 0.6259  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [77]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 5.9804 (6.2313)  loss_classifier: 5.6327 (5.7622)  loss_box_reg: 0.2050 (0.2407)  loss_objectness: 0.1347 (0.1501)  loss_rpn_box_reg: 0.0687 (0.0782)  time: 0.6185  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [77]  [290/500]  eta: 0:02:10  lr: 0.000000  loss: 5.8389 (6.2208)  loss_classifier: 5.4133 (5.7517)  loss_box_reg: 0.2205 (0.2403)  loss_objectness: 0.1416 (0.1506)  loss_rpn_box_reg: 0.0687 (0.0782)  time: 0.6190  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [77]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.2667 (6.2329)  loss_classifier: 5.6904 (5.7639)  loss_box_reg: 0.2236 (0.2399)  loss_objectness: 0.1492 (0.1507)  loss_rpn_box_reg: 0.0713 (0.0784)  time: 0.6195  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [77]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.3334 (6.2291)  loss_classifier: 5.8330 (5.7605)  loss_box_reg: 0.2215 (0.2395)  loss_objectness: 0.1557 (0.1510)  loss_rpn_box_reg: 0.0647 (0.0781)  time: 0.6198  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [77]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.0023 (6.2218)  loss_classifier: 5.5213 (5.7509)  loss_box_reg: 0.2553 (0.2411)  loss_objectness: 0.1557 (0.1510)  loss_rpn_box_reg: 0.0784 (0.0788)  time: 0.6235  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [77]  [330/500]  eta: 0:01:45  lr: 0.000000  loss: 6.0771 (6.2266)  loss_classifier: 5.5288 (5.7557)  loss_box_reg: 0.2602 (0.2414)  loss_objectness: 0.1494 (0.1511)  loss_rpn_box_reg: 0.0765 (0.0784)  time: 0.6223  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [77]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.3651 (6.2313)  loss_classifier: 5.9561 (5.7601)  loss_box_reg: 0.2348 (0.2413)  loss_objectness: 0.1570 (0.1519)  loss_rpn_box_reg: 0.0640 (0.0780)  time: 0.6284  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [77]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.2885 (6.2323)  loss_classifier: 5.9093 (5.7625)  loss_box_reg: 0.2151 (0.2404)  loss_objectness: 0.1554 (0.1516)  loss_rpn_box_reg: 0.0583 (0.0778)  time: 0.6172  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [77]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.0699 (6.2307)  loss_classifier: 5.5908 (5.7620)  loss_box_reg: 0.2003 (0.2395)  loss_objectness: 0.1344 (0.1516)  loss_rpn_box_reg: 0.0583 (0.0776)  time: 0.6179  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [77]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.0268 (6.2278)  loss_classifier: 5.5859 (5.7587)  loss_box_reg: 0.2306 (0.2397)  loss_objectness: 0.1532 (0.1519)  loss_rpn_box_reg: 0.0631 (0.0774)  time: 0.6338  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [77]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.0688 (6.2255)  loss_classifier: 5.6557 (5.7572)  loss_box_reg: 0.2326 (0.2395)  loss_objectness: 0.1532 (0.1518)  loss_rpn_box_reg: 0.0587 (0.0770)  time: 0.6310  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [77]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1109 (6.2251)  loss_classifier: 5.6591 (5.7582)  loss_box_reg: 0.2086 (0.2388)  loss_objectness: 0.1394 (0.1515)  loss_rpn_box_reg: 0.0566 (0.0766)  time: 0.6291  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [77]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1461 (6.2188)  loss_classifier: 5.6288 (5.7525)  loss_box_reg: 0.2086 (0.2385)  loss_objectness: 0.1267 (0.1513)  loss_rpn_box_reg: 0.0572 (0.0764)  time: 0.6368  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [77]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.0926 (6.2163)  loss_classifier: 5.6087 (5.7512)  loss_box_reg: 0.2273 (0.2381)  loss_objectness: 0.1307 (0.1509)  loss_rpn_box_reg: 0.0582 (0.0761)  time: 0.6493  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [77]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.1297 (6.2177)  loss_classifier: 5.7058 (5.7513)  loss_box_reg: 0.2469 (0.2389)  loss_objectness: 0.1497 (0.1514)  loss_rpn_box_reg: 0.0710 (0.0761)  time: 0.6530  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [77]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1297 (6.2179)  loss_classifier: 5.4991 (5.7505)  loss_box_reg: 0.2685 (0.2401)  loss_objectness: 0.1528 (0.1512)  loss_rpn_box_reg: 0.0760 (0.0761)  time: 0.6324  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [77]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2948 (6.2209)  loss_classifier: 5.8372 (5.7528)  loss_box_reg: 0.2594 (0.2400)  loss_objectness: 0.1437 (0.1516)  loss_rpn_box_reg: 0.0665 (0.0764)  time: 0.6189  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [77]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.2789 (6.2188)  loss_classifier: 5.8003 (5.7496)  loss_box_reg: 0.2407 (0.2405)  loss_objectness: 0.1734 (0.1521)  loss_rpn_box_reg: 0.0763 (0.0766)  time: 0.6185  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [77]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0586 (6.2181)  loss_classifier: 5.5425 (5.7494)  loss_box_reg: 0.2234 (0.2403)  loss_objectness: 0.1529 (0.1519)  loss_rpn_box_reg: 0.0689 (0.0765)  time: 0.6336  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [77]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1839 (6.2163)  loss_classifier: 5.5876 (5.7476)  loss_box_reg: 0.2152 (0.2400)  loss_objectness: 0.1464 (0.1521)  loss_rpn_box_reg: 0.0729 (0.0766)  time: 0.6393  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [77]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0442 (6.2134)  loss_classifier: 5.6320 (5.7456)  loss_box_reg: 0.2308 (0.2400)  loss_objectness: 0.1385 (0.1517)  loss_rpn_box_reg: 0.0553 (0.0763)  time: 0.6323  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [77]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0442 (6.2117)  loss_classifier: 5.6486 (5.7439)  loss_box_reg: 0.2178 (0.2400)  loss_objectness: 0.1385 (0.1517)  loss_rpn_box_reg: 0.0635 (0.0761)  time: 0.6268  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [77]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1666 (6.2140)  loss_classifier: 5.7910 (5.7465)  loss_box_reg: 0.2178 (0.2400)  loss_objectness: 0.1368 (0.1515)  loss_rpn_box_reg: 0.0642 (0.0760)  time: 0.6222  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [77] Total time: 0:05:12 (0.6258 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:56  model_time: 0.7492 (0.7492)  evaluator_time: 0.0350 (0.0350)  time: 0.9342  data: 0.1410  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4411 (0.4536)  evaluator_time: 0.0340 (0.0370)  time: 0.6380  data: 0.1541  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4721 (0.4553)  evaluator_time: 0.0360 (0.0373)  time: 0.6552  data: 0.1478  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6432 s / it)\n",
      "Averaged stats: model_time: 0.4721 (0.4553)  evaluator_time: 0.0360 (0.0373)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [77]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1950 (6.1950)  loss_classifier: 5.6363 (5.6363)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1312 (0.1312)  loss_rpn_box_reg: 0.1330 (0.1330)  time: 0.6411  data: 0.1440  max mem: 10734\n",
      "Testing Epoch: [77]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0044 (6.1328)  loss_classifier: 5.4232 (5.6206)  loss_box_reg: 0.2609 (0.2904)  loss_objectness: 0.1294 (0.1324)  loss_rpn_box_reg: 0.0720 (0.0894)  time: 0.5888  data: 0.1484  max mem: 10734\n",
      "Testing Epoch: [77]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1515 (6.1633)  loss_classifier: 5.6708 (5.6561)  loss_box_reg: 0.2500 (0.2856)  loss_objectness: 0.1183 (0.1320)  loss_rpn_box_reg: 0.0745 (0.0895)  time: 0.6024  data: 0.1472  max mem: 10734\n",
      "Testing Epoch: [77] Total time: 0:01:14 (0.5979 s / it)\n",
      "Training Epoch: [78]  [  0/500]  eta: 0:07:04  lr: 0.000000  loss: 6.9167 (6.9167)  loss_classifier: 6.4145 (6.4145)  loss_box_reg: 0.2925 (0.2925)  loss_objectness: 0.1430 (0.1430)  loss_rpn_box_reg: 0.0668 (0.0668)  time: 0.8482  data: 0.1510  max mem: 10734\n",
      "Training Epoch: [78]  [ 10/500]  eta: 0:05:20  lr: 0.000000  loss: 6.2729 (6.3211)  loss_classifier: 5.8464 (5.8916)  loss_box_reg: 0.2237 (0.2249)  loss_objectness: 0.1459 (0.1417)  loss_rpn_box_reg: 0.0682 (0.0628)  time: 0.6534  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [78]  [ 20/500]  eta: 0:05:08  lr: 0.000000  loss: 6.2676 (6.2828)  loss_classifier: 5.7386 (5.8449)  loss_box_reg: 0.2122 (0.2184)  loss_objectness: 0.1454 (0.1479)  loss_rpn_box_reg: 0.0714 (0.0716)  time: 0.6326  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [78]  [ 30/500]  eta: 0:04:56  lr: 0.000000  loss: 6.0649 (6.2085)  loss_classifier: 5.5265 (5.7514)  loss_box_reg: 0.2397 (0.2304)  loss_objectness: 0.1506 (0.1532)  loss_rpn_box_reg: 0.0759 (0.0734)  time: 0.6180  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [78]  [ 40/500]  eta: 0:04:46  lr: 0.000000  loss: 6.2867 (6.2968)  loss_classifier: 5.7373 (5.8287)  loss_box_reg: 0.2419 (0.2391)  loss_objectness: 0.1406 (0.1523)  loss_rpn_box_reg: 0.0759 (0.0768)  time: 0.6033  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [78]  [ 50/500]  eta: 0:04:39  lr: 0.000000  loss: 6.3508 (6.2590)  loss_classifier: 5.8383 (5.7986)  loss_box_reg: 0.2121 (0.2325)  loss_objectness: 0.1390 (0.1526)  loss_rpn_box_reg: 0.0781 (0.0754)  time: 0.6085  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [78]  [ 60/500]  eta: 0:04:33  lr: 0.000000  loss: 5.9568 (6.2045)  loss_classifier: 5.5705 (5.7433)  loss_box_reg: 0.2189 (0.2331)  loss_objectness: 0.1419 (0.1528)  loss_rpn_box_reg: 0.0582 (0.0753)  time: 0.6147  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [78]  [ 70/500]  eta: 0:04:26  lr: 0.000000  loss: 5.9621 (6.1933)  loss_classifier: 5.6153 (5.7270)  loss_box_reg: 0.2522 (0.2371)  loss_objectness: 0.1514 (0.1535)  loss_rpn_box_reg: 0.0656 (0.0757)  time: 0.6166  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [78]  [ 80/500]  eta: 0:04:20  lr: 0.000000  loss: 6.2282 (6.2091)  loss_classifier: 5.6676 (5.7392)  loss_box_reg: 0.2449 (0.2392)  loss_objectness: 0.1520 (0.1541)  loss_rpn_box_reg: 0.0717 (0.0767)  time: 0.6149  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [78]  [ 90/500]  eta: 0:04:15  lr: 0.000000  loss: 6.2731 (6.2231)  loss_classifier: 5.8308 (5.7528)  loss_box_reg: 0.2454 (0.2413)  loss_objectness: 0.1520 (0.1538)  loss_rpn_box_reg: 0.0614 (0.0752)  time: 0.6315  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [78]  [100/500]  eta: 0:04:09  lr: 0.000000  loss: 6.1954 (6.2123)  loss_classifier: 5.7561 (5.7379)  loss_box_reg: 0.2535 (0.2429)  loss_objectness: 0.1560 (0.1548)  loss_rpn_box_reg: 0.0615 (0.0767)  time: 0.6468  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [78]  [110/500]  eta: 0:04:04  lr: 0.000000  loss: 6.2187 (6.2297)  loss_classifier: 5.7317 (5.7545)  loss_box_reg: 0.2400 (0.2430)  loss_objectness: 0.1581 (0.1556)  loss_rpn_box_reg: 0.0628 (0.0766)  time: 0.6519  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [78]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.0726 (6.2194)  loss_classifier: 5.6334 (5.7439)  loss_box_reg: 0.2120 (0.2412)  loss_objectness: 0.1602 (0.1566)  loss_rpn_box_reg: 0.0770 (0.0777)  time: 0.6409  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [78]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.0207 (6.2182)  loss_classifier: 5.5815 (5.7429)  loss_box_reg: 0.2120 (0.2419)  loss_objectness: 0.1383 (0.1551)  loss_rpn_box_reg: 0.0875 (0.0782)  time: 0.6182  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [78]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 5.9228 (6.1935)  loss_classifier: 5.3582 (5.7171)  loss_box_reg: 0.2330 (0.2429)  loss_objectness: 0.1441 (0.1550)  loss_rpn_box_reg: 0.0843 (0.0786)  time: 0.6097  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [78]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 5.9244 (6.1921)  loss_classifier: 5.3868 (5.7157)  loss_box_reg: 0.2556 (0.2428)  loss_objectness: 0.1621 (0.1554)  loss_rpn_box_reg: 0.0751 (0.0782)  time: 0.6094  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [78]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.0066 (6.1896)  loss_classifier: 5.5490 (5.7116)  loss_box_reg: 0.2425 (0.2431)  loss_objectness: 0.1488 (0.1559)  loss_rpn_box_reg: 0.0751 (0.0790)  time: 0.6228  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [78]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 5.9864 (6.1737)  loss_classifier: 5.5113 (5.6968)  loss_box_reg: 0.2422 (0.2433)  loss_objectness: 0.1488 (0.1553)  loss_rpn_box_reg: 0.0739 (0.0784)  time: 0.6179  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [78]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 5.9727 (6.1698)  loss_classifier: 5.5005 (5.6942)  loss_box_reg: 0.2422 (0.2430)  loss_objectness: 0.1505 (0.1552)  loss_rpn_box_reg: 0.0574 (0.0774)  time: 0.6111  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [78]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.1023 (6.1718)  loss_classifier: 5.6836 (5.6951)  loss_box_reg: 0.2457 (0.2429)  loss_objectness: 0.1595 (0.1557)  loss_rpn_box_reg: 0.0654 (0.0780)  time: 0.6199  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [78]  [200/500]  eta: 0:03:06  lr: 0.000000  loss: 6.2982 (6.1768)  loss_classifier: 5.8320 (5.7010)  loss_box_reg: 0.2511 (0.2430)  loss_objectness: 0.1555 (0.1558)  loss_rpn_box_reg: 0.0631 (0.0770)  time: 0.6142  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [78]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.2387 (6.1862)  loss_classifier: 5.8337 (5.7124)  loss_box_reg: 0.2414 (0.2418)  loss_objectness: 0.1332 (0.1548)  loss_rpn_box_reg: 0.0553 (0.0773)  time: 0.6202  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [78]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.2305 (6.1847)  loss_classifier: 5.7900 (5.7108)  loss_box_reg: 0.2222 (0.2414)  loss_objectness: 0.1285 (0.1549)  loss_rpn_box_reg: 0.0789 (0.0777)  time: 0.6353  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [78]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.0651 (6.1791)  loss_classifier: 5.6548 (5.7067)  loss_box_reg: 0.2077 (0.2409)  loss_objectness: 0.1443 (0.1545)  loss_rpn_box_reg: 0.0634 (0.0770)  time: 0.6309  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [78]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 5.9924 (6.1719)  loss_classifier: 5.6040 (5.6999)  loss_box_reg: 0.2204 (0.2414)  loss_objectness: 0.1413 (0.1540)  loss_rpn_box_reg: 0.0598 (0.0765)  time: 0.6275  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [78]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.1150 (6.1815)  loss_classifier: 5.6809 (5.7094)  loss_box_reg: 0.2360 (0.2414)  loss_objectness: 0.1348 (0.1537)  loss_rpn_box_reg: 0.0685 (0.0770)  time: 0.6320  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [78]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.3479 (6.1813)  loss_classifier: 5.8367 (5.7102)  loss_box_reg: 0.2345 (0.2409)  loss_objectness: 0.1435 (0.1538)  loss_rpn_box_reg: 0.0686 (0.0765)  time: 0.6305  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [78]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.2409 (6.1807)  loss_classifier: 5.7396 (5.7093)  loss_box_reg: 0.2272 (0.2403)  loss_objectness: 0.1611 (0.1540)  loss_rpn_box_reg: 0.0686 (0.0771)  time: 0.6231  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [78]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 5.9879 (6.1769)  loss_classifier: 5.4930 (5.7071)  loss_box_reg: 0.2071 (0.2401)  loss_objectness: 0.1458 (0.1531)  loss_rpn_box_reg: 0.0699 (0.0765)  time: 0.6207  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [78]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.2643 (6.1849)  loss_classifier: 5.8048 (5.7143)  loss_box_reg: 0.2007 (0.2399)  loss_objectness: 0.1459 (0.1541)  loss_rpn_box_reg: 0.0670 (0.0766)  time: 0.6231  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [78]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.2643 (6.1880)  loss_classifier: 5.8048 (5.7163)  loss_box_reg: 0.2521 (0.2410)  loss_objectness: 0.1535 (0.1540)  loss_rpn_box_reg: 0.0771 (0.0767)  time: 0.6251  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [78]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.1988 (6.1905)  loss_classifier: 5.7311 (5.7210)  loss_box_reg: 0.2164 (0.2397)  loss_objectness: 0.1393 (0.1537)  loss_rpn_box_reg: 0.0556 (0.0760)  time: 0.6221  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [78]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1524 (6.1908)  loss_classifier: 5.6831 (5.7217)  loss_box_reg: 0.2100 (0.2395)  loss_objectness: 0.1381 (0.1536)  loss_rpn_box_reg: 0.0623 (0.0760)  time: 0.6134  data: 0.1310  max mem: 10734\n",
      "Training Epoch: [78]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.1671 (6.1898)  loss_classifier: 5.6831 (5.7207)  loss_box_reg: 0.2386 (0.2401)  loss_objectness: 0.1304 (0.1531)  loss_rpn_box_reg: 0.0658 (0.0759)  time: 0.6228  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [78]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.2309 (6.1910)  loss_classifier: 5.8174 (5.7219)  loss_box_reg: 0.2387 (0.2404)  loss_objectness: 0.1403 (0.1528)  loss_rpn_box_reg: 0.0659 (0.0758)  time: 0.6385  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [78]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.1628 (6.1931)  loss_classifier: 5.7389 (5.7241)  loss_box_reg: 0.2538 (0.2406)  loss_objectness: 0.1401 (0.1526)  loss_rpn_box_reg: 0.0693 (0.0757)  time: 0.6230  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [78]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1628 (6.1971)  loss_classifier: 5.6965 (5.7285)  loss_box_reg: 0.2538 (0.2408)  loss_objectness: 0.1302 (0.1522)  loss_rpn_box_reg: 0.0664 (0.0756)  time: 0.6176  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [78]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1545 (6.1959)  loss_classifier: 5.6965 (5.7279)  loss_box_reg: 0.2359 (0.2401)  loss_objectness: 0.1302 (0.1521)  loss_rpn_box_reg: 0.0685 (0.0758)  time: 0.6328  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [78]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.0369 (6.1926)  loss_classifier: 5.4784 (5.7245)  loss_box_reg: 0.2054 (0.2402)  loss_objectness: 0.1437 (0.1520)  loss_rpn_box_reg: 0.0750 (0.0758)  time: 0.6313  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [78]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.0297 (6.1938)  loss_classifier: 5.6021 (5.7263)  loss_box_reg: 0.2189 (0.2400)  loss_objectness: 0.1468 (0.1519)  loss_rpn_box_reg: 0.0619 (0.0756)  time: 0.6424  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [78]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1545 (6.1923)  loss_classifier: 5.6773 (5.7254)  loss_box_reg: 0.2189 (0.2396)  loss_objectness: 0.1495 (0.1519)  loss_rpn_box_reg: 0.0624 (0.0754)  time: 0.6522  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [78]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2460 (6.1997)  loss_classifier: 5.8197 (5.7328)  loss_box_reg: 0.2232 (0.2393)  loss_objectness: 0.1498 (0.1519)  loss_rpn_box_reg: 0.0689 (0.0757)  time: 0.6456  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [78]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.2872 (6.2017)  loss_classifier: 5.8155 (5.7327)  loss_box_reg: 0.2642 (0.2401)  loss_objectness: 0.1658 (0.1527)  loss_rpn_box_reg: 0.0802 (0.0762)  time: 0.6277  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [78]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2070 (6.2022)  loss_classifier: 5.7004 (5.7326)  loss_box_reg: 0.2551 (0.2405)  loss_objectness: 0.1658 (0.1527)  loss_rpn_box_reg: 0.0821 (0.0764)  time: 0.6187  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [78]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1555 (6.2070)  loss_classifier: 5.7004 (5.7382)  loss_box_reg: 0.2400 (0.2403)  loss_objectness: 0.1509 (0.1525)  loss_rpn_box_reg: 0.0622 (0.0759)  time: 0.6348  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [78]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1812 (6.2094)  loss_classifier: 5.7919 (5.7406)  loss_box_reg: 0.2400 (0.2401)  loss_objectness: 0.1547 (0.1527)  loss_rpn_box_reg: 0.0539 (0.0760)  time: 0.6168  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [78]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.3078 (6.2162)  loss_classifier: 5.7941 (5.7469)  loss_box_reg: 0.2486 (0.2403)  loss_objectness: 0.1618 (0.1527)  loss_rpn_box_reg: 0.0720 (0.0763)  time: 0.6094  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [78]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.3955 (6.2156)  loss_classifier: 5.9369 (5.7469)  loss_box_reg: 0.2423 (0.2399)  loss_objectness: 0.1375 (0.1527)  loss_rpn_box_reg: 0.0790 (0.0762)  time: 0.6241  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [78]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1043 (6.2142)  loss_classifier: 5.6770 (5.7453)  loss_box_reg: 0.2214 (0.2397)  loss_objectness: 0.1551 (0.1530)  loss_rpn_box_reg: 0.0755 (0.0762)  time: 0.6266  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [78]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0536 (6.2112)  loss_classifier: 5.6099 (5.7429)  loss_box_reg: 0.2118 (0.2393)  loss_objectness: 0.1432 (0.1527)  loss_rpn_box_reg: 0.0731 (0.0763)  time: 0.6252  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [78]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 5.9755 (6.2121)  loss_classifier: 5.6057 (5.7434)  loss_box_reg: 0.2118 (0.2399)  loss_objectness: 0.1394 (0.1527)  loss_rpn_box_reg: 0.0667 (0.0761)  time: 0.6326  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [78] Total time: 0:05:12 (0.6259 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:56  model_time: 0.7442 (0.7442)  evaluator_time: 0.0340 (0.0340)  time: 0.9282  data: 0.1410  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4391 (0.4554)  evaluator_time: 0.0340 (0.0379)  time: 0.6357  data: 0.1478  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4721 (0.4562)  evaluator_time: 0.0360 (0.0381)  time: 0.6530  data: 0.1473  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6434 s / it)\n",
      "Averaged stats: model_time: 0.4721 (0.4562)  evaluator_time: 0.0360 (0.0381)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [78]  [  0/125]  eta: 0:01:19  lr: 0.000000  loss: 6.2203 (6.2203)  loss_classifier: 5.6621 (5.6621)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1292 (0.1292)  loss_rpn_box_reg: 0.1345 (0.1345)  time: 0.6381  data: 0.1370  max mem: 10734\n",
      "Testing Epoch: [78]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0048 (6.1271)  loss_classifier: 5.4454 (5.6169)  loss_box_reg: 0.2609 (0.2896)  loss_objectness: 0.1292 (0.1313)  loss_rpn_box_reg: 0.0694 (0.0893)  time: 0.5859  data: 0.1454  max mem: 10734\n",
      "Testing Epoch: [78]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1686 (6.1604)  loss_classifier: 5.6875 (5.6543)  loss_box_reg: 0.2500 (0.2849)  loss_objectness: 0.1160 (0.1317)  loss_rpn_box_reg: 0.0745 (0.0894)  time: 0.5953  data: 0.1436  max mem: 10734\n",
      "Testing Epoch: [78] Total time: 0:01:14 (0.5955 s / it)\n",
      "Training Epoch: [79]  [  0/500]  eta: 0:07:07  lr: 0.000000  loss: 5.9539 (5.9539)  loss_classifier: 5.3444 (5.3444)  loss_box_reg: 0.3379 (0.3379)  loss_objectness: 0.1930 (0.1930)  loss_rpn_box_reg: 0.0787 (0.0787)  time: 0.8552  data: 0.1370  max mem: 10734\n",
      "Training Epoch: [79]  [ 10/500]  eta: 0:05:18  lr: 0.000000  loss: 6.4432 (6.3097)  loss_classifier: 5.9200 (5.8341)  loss_box_reg: 0.2878 (0.2662)  loss_objectness: 0.1522 (0.1438)  loss_rpn_box_reg: 0.0676 (0.0656)  time: 0.6498  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [79]  [ 20/500]  eta: 0:05:08  lr: 0.000000  loss: 6.1129 (6.2282)  loss_classifier: 5.7762 (5.7559)  loss_box_reg: 0.2839 (0.2653)  loss_objectness: 0.1424 (0.1423)  loss_rpn_box_reg: 0.0636 (0.0647)  time: 0.6326  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [79]  [ 30/500]  eta: 0:05:01  lr: 0.000000  loss: 6.1926 (6.2598)  loss_classifier: 5.8271 (5.8078)  loss_box_reg: 0.2187 (0.2485)  loss_objectness: 0.1181 (0.1363)  loss_rpn_box_reg: 0.0629 (0.0672)  time: 0.6366  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [79]  [ 40/500]  eta: 0:04:52  lr: 0.000000  loss: 6.2466 (6.2449)  loss_classifier: 5.7420 (5.7720)  loss_box_reg: 0.2187 (0.2584)  loss_objectness: 0.1224 (0.1403)  loss_rpn_box_reg: 0.0691 (0.0742)  time: 0.6269  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [79]  [ 50/500]  eta: 0:04:43  lr: 0.000000  loss: 6.0054 (6.1972)  loss_classifier: 5.5194 (5.7232)  loss_box_reg: 0.2526 (0.2579)  loss_objectness: 0.1470 (0.1403)  loss_rpn_box_reg: 0.0798 (0.0758)  time: 0.6144  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [79]  [ 60/500]  eta: 0:04:37  lr: 0.000000  loss: 5.9027 (6.1831)  loss_classifier: 5.5310 (5.7089)  loss_box_reg: 0.2321 (0.2580)  loss_objectness: 0.1313 (0.1407)  loss_rpn_box_reg: 0.0714 (0.0754)  time: 0.6231  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [79]  [ 70/500]  eta: 0:04:31  lr: 0.000000  loss: 6.0685 (6.1998)  loss_classifier: 5.5703 (5.7257)  loss_box_reg: 0.2336 (0.2567)  loss_objectness: 0.1382 (0.1429)  loss_rpn_box_reg: 0.0608 (0.0746)  time: 0.6293  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [79]  [ 80/500]  eta: 0:04:25  lr: 0.000000  loss: 6.2202 (6.2121)  loss_classifier: 5.7313 (5.7369)  loss_box_reg: 0.2320 (0.2556)  loss_objectness: 0.1424 (0.1431)  loss_rpn_box_reg: 0.0733 (0.0765)  time: 0.6322  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [79]  [ 90/500]  eta: 0:04:18  lr: 0.000000  loss: 6.0880 (6.1942)  loss_classifier: 5.6531 (5.7199)  loss_box_reg: 0.2260 (0.2521)  loss_objectness: 0.1580 (0.1451)  loss_rpn_box_reg: 0.0832 (0.0771)  time: 0.6289  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [79]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 6.0395 (6.2003)  loss_classifier: 5.6333 (5.7301)  loss_box_reg: 0.2260 (0.2509)  loss_objectness: 0.1366 (0.1436)  loss_rpn_box_reg: 0.0557 (0.0756)  time: 0.6190  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [79]  [110/500]  eta: 0:04:05  lr: 0.000000  loss: 6.0336 (6.1832)  loss_classifier: 5.5971 (5.7166)  loss_box_reg: 0.2295 (0.2488)  loss_objectness: 0.1268 (0.1443)  loss_rpn_box_reg: 0.0557 (0.0735)  time: 0.6262  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [79]  [120/500]  eta: 0:03:59  lr: 0.000000  loss: 5.9185 (6.1737)  loss_classifier: 5.5035 (5.7060)  loss_box_reg: 0.2279 (0.2488)  loss_objectness: 0.1335 (0.1441)  loss_rpn_box_reg: 0.0596 (0.0748)  time: 0.6301  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [79]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 5.9362 (6.1623)  loss_classifier: 5.5233 (5.6957)  loss_box_reg: 0.2427 (0.2472)  loss_objectness: 0.1499 (0.1448)  loss_rpn_box_reg: 0.0692 (0.0747)  time: 0.6249  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [79]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 5.8352 (6.1370)  loss_classifier: 5.4525 (5.6726)  loss_box_reg: 0.2128 (0.2438)  loss_objectness: 0.1498 (0.1457)  loss_rpn_box_reg: 0.0697 (0.0748)  time: 0.6230  data: 0.1314  max mem: 10734\n",
      "Training Epoch: [79]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 5.8048 (6.1269)  loss_classifier: 5.3518 (5.6618)  loss_box_reg: 0.2093 (0.2439)  loss_objectness: 0.1423 (0.1457)  loss_rpn_box_reg: 0.0749 (0.0755)  time: 0.6333  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [79]  [160/500]  eta: 0:03:34  lr: 0.000000  loss: 6.1233 (6.1298)  loss_classifier: 5.6861 (5.6684)  loss_box_reg: 0.2093 (0.2423)  loss_objectness: 0.1328 (0.1448)  loss_rpn_box_reg: 0.0661 (0.0743)  time: 0.6425  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [79]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.2864 (6.1464)  loss_classifier: 5.7972 (5.6845)  loss_box_reg: 0.2029 (0.2413)  loss_objectness: 0.1432 (0.1457)  loss_rpn_box_reg: 0.0661 (0.0749)  time: 0.6337  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [79]  [180/500]  eta: 0:03:21  lr: 0.000000  loss: 6.2481 (6.1536)  loss_classifier: 5.7586 (5.6922)  loss_box_reg: 0.2097 (0.2403)  loss_objectness: 0.1462 (0.1459)  loss_rpn_box_reg: 0.0740 (0.0751)  time: 0.6195  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [79]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.4049 (6.1628)  loss_classifier: 5.8828 (5.6988)  loss_box_reg: 0.2329 (0.2413)  loss_objectness: 0.1539 (0.1468)  loss_rpn_box_reg: 0.0729 (0.0759)  time: 0.6159  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [79]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.2729 (6.1752)  loss_classifier: 5.8828 (5.7127)  loss_box_reg: 0.2371 (0.2397)  loss_objectness: 0.1575 (0.1475)  loss_rpn_box_reg: 0.0654 (0.0753)  time: 0.6121  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [79]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.1414 (6.1844)  loss_classifier: 5.6858 (5.7210)  loss_box_reg: 0.2222 (0.2397)  loss_objectness: 0.1597 (0.1484)  loss_rpn_box_reg: 0.0633 (0.0753)  time: 0.6194  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [79]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.1980 (6.1894)  loss_classifier: 5.6543 (5.7269)  loss_box_reg: 0.2222 (0.2389)  loss_objectness: 0.1486 (0.1483)  loss_rpn_box_reg: 0.0640 (0.0754)  time: 0.6379  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [79]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.1677 (6.1898)  loss_classifier: 5.7492 (5.7291)  loss_box_reg: 0.2155 (0.2382)  loss_objectness: 0.1396 (0.1479)  loss_rpn_box_reg: 0.0617 (0.0747)  time: 0.6369  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [79]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 5.9924 (6.1884)  loss_classifier: 5.6577 (5.7250)  loss_box_reg: 0.2447 (0.2403)  loss_objectness: 0.1426 (0.1481)  loss_rpn_box_reg: 0.0655 (0.0750)  time: 0.6315  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [79]  [250/500]  eta: 0:02:37  lr: 0.000000  loss: 6.1571 (6.1875)  loss_classifier: 5.5978 (5.7249)  loss_box_reg: 0.2731 (0.2396)  loss_objectness: 0.1404 (0.1480)  loss_rpn_box_reg: 0.0666 (0.0750)  time: 0.6355  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [79]  [260/500]  eta: 0:02:31  lr: 0.000000  loss: 6.2384 (6.1842)  loss_classifier: 5.8416 (5.7245)  loss_box_reg: 0.2051 (0.2383)  loss_objectness: 0.1358 (0.1475)  loss_rpn_box_reg: 0.0514 (0.0740)  time: 0.6481  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [79]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.2611 (6.1881)  loss_classifier: 5.8167 (5.7270)  loss_box_reg: 0.2109 (0.2393)  loss_objectness: 0.1377 (0.1479)  loss_rpn_box_reg: 0.0514 (0.0740)  time: 0.6326  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [79]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.2877 (6.1890)  loss_classifier: 5.7563 (5.7272)  loss_box_reg: 0.2560 (0.2392)  loss_objectness: 0.1495 (0.1480)  loss_rpn_box_reg: 0.0793 (0.0746)  time: 0.6232  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [79]  [290/500]  eta: 0:02:12  lr: 0.000000  loss: 6.2317 (6.1937)  loss_classifier: 5.7527 (5.7321)  loss_box_reg: 0.2295 (0.2393)  loss_objectness: 0.1430 (0.1477)  loss_rpn_box_reg: 0.0784 (0.0746)  time: 0.6269  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [79]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.2328 (6.1992)  loss_classifier: 5.7698 (5.7375)  loss_box_reg: 0.2295 (0.2389)  loss_objectness: 0.1430 (0.1481)  loss_rpn_box_reg: 0.0784 (0.0747)  time: 0.6219  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [79]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.3591 (6.2037)  loss_classifier: 5.9471 (5.7423)  loss_box_reg: 0.2290 (0.2383)  loss_objectness: 0.1421 (0.1480)  loss_rpn_box_reg: 0.0836 (0.0751)  time: 0.6139  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [79]  [320/500]  eta: 0:01:53  lr: 0.000000  loss: 6.2231 (6.2021)  loss_classifier: 5.7347 (5.7393)  loss_box_reg: 0.2290 (0.2387)  loss_objectness: 0.1542 (0.1484)  loss_rpn_box_reg: 0.0837 (0.0757)  time: 0.6156  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [79]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.0700 (6.1935)  loss_classifier: 5.6702 (5.7305)  loss_box_reg: 0.2301 (0.2389)  loss_objectness: 0.1549 (0.1485)  loss_rpn_box_reg: 0.0781 (0.0756)  time: 0.6190  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [79]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 5.8746 (6.1922)  loss_classifier: 5.4073 (5.7294)  loss_box_reg: 0.2301 (0.2389)  loss_objectness: 0.1445 (0.1485)  loss_rpn_box_reg: 0.0707 (0.0754)  time: 0.6183  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [79]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 5.9437 (6.1901)  loss_classifier: 5.4997 (5.7279)  loss_box_reg: 0.2312 (0.2382)  loss_objectness: 0.1476 (0.1486)  loss_rpn_box_reg: 0.0685 (0.0754)  time: 0.6355  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [79]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1710 (6.1938)  loss_classifier: 5.7169 (5.7313)  loss_box_reg: 0.2168 (0.2379)  loss_objectness: 0.1547 (0.1491)  loss_rpn_box_reg: 0.0650 (0.0755)  time: 0.6226  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [79]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.3055 (6.1985)  loss_classifier: 5.8088 (5.7364)  loss_box_reg: 0.2168 (0.2375)  loss_objectness: 0.1544 (0.1493)  loss_rpn_box_reg: 0.0649 (0.0753)  time: 0.6084  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [79]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.3186 (6.2007)  loss_classifier: 5.9044 (5.7389)  loss_box_reg: 0.2238 (0.2373)  loss_objectness: 0.1442 (0.1490)  loss_rpn_box_reg: 0.0649 (0.0755)  time: 0.6254  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [79]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.2711 (6.1991)  loss_classifier: 5.7613 (5.7370)  loss_box_reg: 0.2295 (0.2376)  loss_objectness: 0.1458 (0.1491)  loss_rpn_box_reg: 0.0642 (0.0754)  time: 0.6232  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [79]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 5.9735 (6.1942)  loss_classifier: 5.5056 (5.7321)  loss_box_reg: 0.2339 (0.2374)  loss_objectness: 0.1459 (0.1492)  loss_rpn_box_reg: 0.0717 (0.0755)  time: 0.6079  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [79]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2169 (6.2004)  loss_classifier: 5.7727 (5.7384)  loss_box_reg: 0.2261 (0.2374)  loss_objectness: 0.1485 (0.1493)  loss_rpn_box_reg: 0.0681 (0.0752)  time: 0.6216  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [79]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.5808 (6.2070)  loss_classifier: 6.1601 (5.7443)  loss_box_reg: 0.2194 (0.2377)  loss_objectness: 0.1467 (0.1493)  loss_rpn_box_reg: 0.0681 (0.0757)  time: 0.6323  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [79]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2465 (6.2065)  loss_classifier: 5.7137 (5.7428)  loss_box_reg: 0.2304 (0.2383)  loss_objectness: 0.1467 (0.1496)  loss_rpn_box_reg: 0.0841 (0.0758)  time: 0.6241  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [79]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2285 (6.2102)  loss_classifier: 5.7184 (5.7461)  loss_box_reg: 0.2488 (0.2383)  loss_objectness: 0.1554 (0.1498)  loss_rpn_box_reg: 0.0781 (0.0760)  time: 0.6089  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [79]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1732 (6.2058)  loss_classifier: 5.6587 (5.7405)  loss_box_reg: 0.2545 (0.2389)  loss_objectness: 0.1492 (0.1498)  loss_rpn_box_reg: 0.0919 (0.0766)  time: 0.6021  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [79]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.1331 (6.2065)  loss_classifier: 5.6341 (5.7413)  loss_box_reg: 0.2548 (0.2388)  loss_objectness: 0.1480 (0.1501)  loss_rpn_box_reg: 0.0760 (0.0763)  time: 0.6189  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [79]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1823 (6.2098)  loss_classifier: 5.7312 (5.7441)  loss_box_reg: 0.2404 (0.2395)  loss_objectness: 0.1524 (0.1501)  loss_rpn_box_reg: 0.0581 (0.0762)  time: 0.6418  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [79]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2506 (6.2111)  loss_classifier: 5.8475 (5.7450)  loss_box_reg: 0.2413 (0.2397)  loss_objectness: 0.1458 (0.1502)  loss_rpn_box_reg: 0.0579 (0.0762)  time: 0.6395  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [79]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1418 (6.2123)  loss_classifier: 5.7192 (5.7459)  loss_box_reg: 0.2413 (0.2396)  loss_objectness: 0.1437 (0.1505)  loss_rpn_box_reg: 0.0667 (0.0762)  time: 0.6239  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [79]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 5.9039 (6.2097)  loss_classifier: 5.4891 (5.7432)  loss_box_reg: 0.2773 (0.2403)  loss_objectness: 0.1427 (0.1503)  loss_rpn_box_reg: 0.0693 (0.0760)  time: 0.6081  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [79] Total time: 0:05:12 (0.6255 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:54  model_time: 0.7292 (0.7292)  evaluator_time: 0.0350 (0.0350)  time: 0.9172  data: 0.1440  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4391 (0.4534)  evaluator_time: 0.0340 (0.0352)  time: 0.6339  data: 0.1486  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4661 (0.4548)  evaluator_time: 0.0350 (0.0359)  time: 0.6549  data: 0.1479  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6434 s / it)\n",
      "Averaged stats: model_time: 0.4661 (0.4548)  evaluator_time: 0.0350 (0.0359)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [79]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1958 (6.1958)  loss_classifier: 5.6417 (5.6417)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1252 (0.1252)  loss_rpn_box_reg: 0.1344 (0.1344)  time: 0.6461  data: 0.1410  max mem: 10734\n",
      "Testing Epoch: [79]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9945 (6.1272)  loss_classifier: 5.4324 (5.6176)  loss_box_reg: 0.2609 (0.2894)  loss_objectness: 0.1281 (0.1311)  loss_rpn_box_reg: 0.0740 (0.0891)  time: 0.5858  data: 0.1448  max mem: 10734\n",
      "Testing Epoch: [79]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1658 (6.1607)  loss_classifier: 5.6834 (5.6552)  loss_box_reg: 0.2500 (0.2848)  loss_objectness: 0.1217 (0.1313)  loss_rpn_box_reg: 0.0745 (0.0893)  time: 0.5989  data: 0.1456  max mem: 10734\n",
      "Testing Epoch: [79] Total time: 0:01:14 (0.5949 s / it)\n",
      "Training Epoch: [80]  [  0/500]  eta: 0:07:03  lr: 0.000000  loss: 6.2492 (6.2492)  loss_classifier: 5.8256 (5.8256)  loss_box_reg: 0.1675 (0.1675)  loss_objectness: 0.1894 (0.1894)  loss_rpn_box_reg: 0.0667 (0.0667)  time: 0.8462  data: 0.1440  max mem: 10734\n",
      "Training Epoch: [80]  [ 10/500]  eta: 0:05:13  lr: 0.000000  loss: 6.3657 (6.1964)  loss_classifier: 5.8256 (5.7335)  loss_box_reg: 0.2142 (0.2318)  loss_objectness: 0.1402 (0.1472)  loss_rpn_box_reg: 0.0667 (0.0840)  time: 0.6393  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [80]  [ 20/500]  eta: 0:04:58  lr: 0.000000  loss: 6.1830 (6.2196)  loss_classifier: 5.6883 (5.7285)  loss_box_reg: 0.2395 (0.2471)  loss_objectness: 0.1489 (0.1564)  loss_rpn_box_reg: 0.0721 (0.0875)  time: 0.6109  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [80]  [ 30/500]  eta: 0:04:54  lr: 0.000000  loss: 6.1119 (6.1440)  loss_classifier: 5.6599 (5.6598)  loss_box_reg: 0.2342 (0.2464)  loss_objectness: 0.1419 (0.1504)  loss_rpn_box_reg: 0.0853 (0.0875)  time: 0.6210  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [80]  [ 40/500]  eta: 0:04:48  lr: 0.000000  loss: 6.0710 (6.1068)  loss_classifier: 5.6180 (5.6204)  loss_box_reg: 0.2342 (0.2493)  loss_objectness: 0.1419 (0.1507)  loss_rpn_box_reg: 0.0786 (0.0864)  time: 0.6340  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [80]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 5.9138 (6.0731)  loss_classifier: 5.4679 (5.6004)  loss_box_reg: 0.2310 (0.2407)  loss_objectness: 0.1481 (0.1495)  loss_rpn_box_reg: 0.0703 (0.0825)  time: 0.6286  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [80]  [ 60/500]  eta: 0:04:36  lr: 0.000000  loss: 6.2325 (6.1178)  loss_classifier: 5.8304 (5.6467)  loss_box_reg: 0.2128 (0.2379)  loss_objectness: 0.1536 (0.1516)  loss_rpn_box_reg: 0.0680 (0.0815)  time: 0.6286  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [80]  [ 70/500]  eta: 0:04:29  lr: 0.000000  loss: 6.3780 (6.1404)  loss_classifier: 5.8414 (5.6700)  loss_box_reg: 0.2135 (0.2375)  loss_objectness: 0.1595 (0.1525)  loss_rpn_box_reg: 0.0724 (0.0804)  time: 0.6216  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [80]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 6.0850 (6.1183)  loss_classifier: 5.7170 (5.6475)  loss_box_reg: 0.2348 (0.2378)  loss_objectness: 0.1502 (0.1527)  loss_rpn_box_reg: 0.0725 (0.0803)  time: 0.6234  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [80]  [ 90/500]  eta: 0:04:17  lr: 0.000000  loss: 5.8605 (6.0780)  loss_classifier: 5.3975 (5.6137)  loss_box_reg: 0.2321 (0.2353)  loss_objectness: 0.1397 (0.1512)  loss_rpn_box_reg: 0.0587 (0.0778)  time: 0.6314  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [80]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 5.8693 (6.0909)  loss_classifier: 5.3975 (5.6241)  loss_box_reg: 0.2469 (0.2373)  loss_objectness: 0.1397 (0.1525)  loss_rpn_box_reg: 0.0587 (0.0770)  time: 0.6265  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [80]  [110/500]  eta: 0:04:05  lr: 0.000000  loss: 6.0682 (6.1111)  loss_classifier: 5.6019 (5.6449)  loss_box_reg: 0.2480 (0.2372)  loss_objectness: 0.1377 (0.1518)  loss_rpn_box_reg: 0.0664 (0.0772)  time: 0.6342  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [80]  [120/500]  eta: 0:03:58  lr: 0.000000  loss: 6.2024 (6.1106)  loss_classifier: 5.6854 (5.6428)  loss_box_reg: 0.2288 (0.2390)  loss_objectness: 0.1363 (0.1517)  loss_rpn_box_reg: 0.0729 (0.0772)  time: 0.6288  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [80]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 6.1891 (6.1191)  loss_classifier: 5.6854 (5.6450)  loss_box_reg: 0.2613 (0.2425)  loss_objectness: 0.1654 (0.1543)  loss_rpn_box_reg: 0.0765 (0.0774)  time: 0.6099  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [80]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.1831 (6.1196)  loss_classifier: 5.6650 (5.6454)  loss_box_reg: 0.2613 (0.2428)  loss_objectness: 0.1670 (0.1544)  loss_rpn_box_reg: 0.0711 (0.0770)  time: 0.6119  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [80]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.0211 (6.1160)  loss_classifier: 5.5370 (5.6421)  loss_box_reg: 0.2549 (0.2435)  loss_objectness: 0.1450 (0.1535)  loss_rpn_box_reg: 0.0658 (0.0770)  time: 0.6251  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [80]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 5.9315 (6.1279)  loss_classifier: 5.4358 (5.6533)  loss_box_reg: 0.2432 (0.2426)  loss_objectness: 0.1455 (0.1543)  loss_rpn_box_reg: 0.0833 (0.0776)  time: 0.6367  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [80]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 5.9801 (6.1347)  loss_classifier: 5.5472 (5.6616)  loss_box_reg: 0.2344 (0.2430)  loss_objectness: 0.1465 (0.1538)  loss_rpn_box_reg: 0.0674 (0.0764)  time: 0.6288  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [80]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.3144 (6.1486)  loss_classifier: 5.7824 (5.6777)  loss_box_reg: 0.2174 (0.2415)  loss_objectness: 0.1554 (0.1545)  loss_rpn_box_reg: 0.0545 (0.0749)  time: 0.6178  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [80]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.3442 (6.1540)  loss_classifier: 5.9564 (5.6844)  loss_box_reg: 0.2190 (0.2409)  loss_objectness: 0.1532 (0.1543)  loss_rpn_box_reg: 0.0549 (0.0744)  time: 0.6153  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [80]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.2214 (6.1569)  loss_classifier: 5.7420 (5.6878)  loss_box_reg: 0.2262 (0.2406)  loss_objectness: 0.1488 (0.1537)  loss_rpn_box_reg: 0.0611 (0.0749)  time: 0.6171  data: 0.1304  max mem: 10734\n",
      "Training Epoch: [80]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.2214 (6.1688)  loss_classifier: 5.7771 (5.7018)  loss_box_reg: 0.2086 (0.2388)  loss_objectness: 0.1458 (0.1537)  loss_rpn_box_reg: 0.0583 (0.0745)  time: 0.6344  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [80]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.3047 (6.1774)  loss_classifier: 5.7771 (5.7087)  loss_box_reg: 0.2353 (0.2395)  loss_objectness: 0.1486 (0.1539)  loss_rpn_box_reg: 0.0848 (0.0753)  time: 0.6364  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [80]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.1483 (6.1707)  loss_classifier: 5.7500 (5.7020)  loss_box_reg: 0.2553 (0.2395)  loss_objectness: 0.1531 (0.1533)  loss_rpn_box_reg: 0.0862 (0.0758)  time: 0.6310  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [80]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 5.9225 (6.1599)  loss_classifier: 5.4829 (5.6899)  loss_box_reg: 0.2553 (0.2409)  loss_objectness: 0.1472 (0.1534)  loss_rpn_box_reg: 0.0689 (0.0757)  time: 0.6239  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [80]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.1140 (6.1750)  loss_classifier: 5.6242 (5.7039)  loss_box_reg: 0.2439 (0.2410)  loss_objectness: 0.1494 (0.1534)  loss_rpn_box_reg: 0.0802 (0.0766)  time: 0.6287  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [80]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.4711 (6.1921)  loss_classifier: 5.9686 (5.7205)  loss_box_reg: 0.2344 (0.2413)  loss_objectness: 0.1498 (0.1537)  loss_rpn_box_reg: 0.0804 (0.0766)  time: 0.6399  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [80]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.1544 (6.1878)  loss_classifier: 5.6894 (5.7183)  loss_box_reg: 0.2266 (0.2404)  loss_objectness: 0.1417 (0.1532)  loss_rpn_box_reg: 0.0683 (0.0760)  time: 0.6316  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [80]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 6.0575 (6.1904)  loss_classifier: 5.6663 (5.7226)  loss_box_reg: 0.2034 (0.2396)  loss_objectness: 0.1301 (0.1525)  loss_rpn_box_reg: 0.0611 (0.0756)  time: 0.6463  data: 0.1317  max mem: 10734\n",
      "Training Epoch: [80]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.3017 (6.1968)  loss_classifier: 5.8209 (5.7276)  loss_box_reg: 0.2473 (0.2404)  loss_objectness: 0.1491 (0.1530)  loss_rpn_box_reg: 0.0722 (0.0758)  time: 0.6343  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [80]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 5.8478 (6.1888)  loss_classifier: 5.4785 (5.7207)  loss_box_reg: 0.2473 (0.2393)  loss_objectness: 0.1611 (0.1534)  loss_rpn_box_reg: 0.0663 (0.0755)  time: 0.6174  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [80]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 5.9551 (6.1892)  loss_classifier: 5.5646 (5.7211)  loss_box_reg: 0.2408 (0.2392)  loss_objectness: 0.1439 (0.1533)  loss_rpn_box_reg: 0.0650 (0.0756)  time: 0.6207  data: 0.1313  max mem: 10734\n",
      "Training Epoch: [80]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.0586 (6.1858)  loss_classifier: 5.7171 (5.7183)  loss_box_reg: 0.2490 (0.2393)  loss_objectness: 0.1383 (0.1526)  loss_rpn_box_reg: 0.0714 (0.0755)  time: 0.6186  data: 0.1306  max mem: 10734\n",
      "Training Epoch: [80]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.2029 (6.1870)  loss_classifier: 5.6546 (5.7195)  loss_box_reg: 0.2500 (0.2396)  loss_objectness: 0.1340 (0.1525)  loss_rpn_box_reg: 0.0759 (0.0755)  time: 0.6312  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [80]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.2770 (6.1892)  loss_classifier: 5.6902 (5.7210)  loss_box_reg: 0.2365 (0.2396)  loss_objectness: 0.1504 (0.1532)  loss_rpn_box_reg: 0.0759 (0.0754)  time: 0.6304  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [80]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.1368 (6.1925)  loss_classifier: 5.6902 (5.7242)  loss_box_reg: 0.2194 (0.2396)  loss_objectness: 0.1509 (0.1529)  loss_rpn_box_reg: 0.0834 (0.0758)  time: 0.6239  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [80]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1105 (6.1951)  loss_classifier: 5.6556 (5.7253)  loss_box_reg: 0.2477 (0.2410)  loss_objectness: 0.1513 (0.1531)  loss_rpn_box_reg: 0.0808 (0.0758)  time: 0.6211  data: 0.1382  max mem: 10734\n",
      "Training Epoch: [80]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.2597 (6.1951)  loss_classifier: 5.7520 (5.7255)  loss_box_reg: 0.2483 (0.2407)  loss_objectness: 0.1625 (0.1532)  loss_rpn_box_reg: 0.0662 (0.0758)  time: 0.6289  data: 0.1388  max mem: 10734\n",
      "Training Epoch: [80]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.3680 (6.2027)  loss_classifier: 5.8992 (5.7321)  loss_box_reg: 0.2483 (0.2407)  loss_objectness: 0.1604 (0.1540)  loss_rpn_box_reg: 0.0677 (0.0759)  time: 0.6361  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [80]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 6.3715 (6.2036)  loss_classifier: 5.8992 (5.7339)  loss_box_reg: 0.2263 (0.2403)  loss_objectness: 0.1420 (0.1537)  loss_rpn_box_reg: 0.0676 (0.0757)  time: 0.6353  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [80]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.0899 (6.2029)  loss_classifier: 5.6779 (5.7338)  loss_box_reg: 0.2098 (0.2397)  loss_objectness: 0.1415 (0.1537)  loss_rpn_box_reg: 0.0676 (0.0757)  time: 0.6354  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [80]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1907 (6.2063)  loss_classifier: 5.7535 (5.7367)  loss_box_reg: 0.2143 (0.2400)  loss_objectness: 0.1362 (0.1536)  loss_rpn_box_reg: 0.0789 (0.0759)  time: 0.6297  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [80]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.2166 (6.2070)  loss_classifier: 5.7031 (5.7366)  loss_box_reg: 0.2464 (0.2404)  loss_objectness: 0.1476 (0.1537)  loss_rpn_box_reg: 0.0789 (0.0762)  time: 0.6242  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [80]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.3003 (6.2115)  loss_classifier: 5.7566 (5.7409)  loss_box_reg: 0.2464 (0.2404)  loss_objectness: 0.1668 (0.1541)  loss_rpn_box_reg: 0.0781 (0.0762)  time: 0.6214  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [80]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.4119 (6.2182)  loss_classifier: 5.9097 (5.7483)  loss_box_reg: 0.2292 (0.2399)  loss_objectness: 0.1440 (0.1538)  loss_rpn_box_reg: 0.0781 (0.0761)  time: 0.6105  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [80]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1540 (6.2146)  loss_classifier: 5.6649 (5.7455)  loss_box_reg: 0.1927 (0.2398)  loss_objectness: 0.1329 (0.1532)  loss_rpn_box_reg: 0.0648 (0.0760)  time: 0.6276  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [80]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0115 (6.2168)  loss_classifier: 5.6593 (5.7487)  loss_box_reg: 0.1922 (0.2392)  loss_objectness: 0.1259 (0.1531)  loss_rpn_box_reg: 0.0542 (0.0759)  time: 0.6488  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [80]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2275 (6.2147)  loss_classifier: 5.7917 (5.7471)  loss_box_reg: 0.2206 (0.2392)  loss_objectness: 0.1357 (0.1528)  loss_rpn_box_reg: 0.0633 (0.0756)  time: 0.6208  data: 0.1299  max mem: 10734\n",
      "Training Epoch: [80]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2540 (6.2156)  loss_classifier: 5.7917 (5.7485)  loss_box_reg: 0.2327 (0.2390)  loss_objectness: 0.1395 (0.1525)  loss_rpn_box_reg: 0.0636 (0.0756)  time: 0.6122  data: 0.1310  max mem: 10734\n",
      "Training Epoch: [80]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.2335 (6.2144)  loss_classifier: 5.8276 (5.7473)  loss_box_reg: 0.2327 (0.2388)  loss_objectness: 0.1367 (0.1523)  loss_rpn_box_reg: 0.0577 (0.0760)  time: 0.6262  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [80]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0734 (6.2134)  loss_classifier: 5.6292 (5.7467)  loss_box_reg: 0.2288 (0.2385)  loss_objectness: 0.1504 (0.1523)  loss_rpn_box_reg: 0.0577 (0.0759)  time: 0.6192  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [80] Total time: 0:05:13 (0.6268 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:39  model_time: 0.6071 (0.6071)  evaluator_time: 0.0350 (0.0350)  time: 0.7952  data: 0.1430  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4431 (0.4500)  evaluator_time: 0.0340 (0.0363)  time: 0.6327  data: 0.1484  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4791 (0.4526)  evaluator_time: 0.0360 (0.0378)  time: 0.6588  data: 0.1421  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6411 s / it)\n",
      "Averaged stats: model_time: 0.4791 (0.4526)  evaluator_time: 0.0360 (0.0378)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [80]  [  0/125]  eta: 0:01:21  lr: 0.000000  loss: 6.1938 (6.1938)  loss_classifier: 5.6481 (5.6481)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1216 (0.1216)  loss_rpn_box_reg: 0.1296 (0.1296)  time: 0.6481  data: 0.1490  max mem: 10734\n",
      "Testing Epoch: [80]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9821 (6.1282)  loss_classifier: 5.4392 (5.6189)  loss_box_reg: 0.2609 (0.2891)  loss_objectness: 0.1305 (0.1307)  loss_rpn_box_reg: 0.0707 (0.0895)  time: 0.5898  data: 0.1491  max mem: 10734\n",
      "Testing Epoch: [80]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1519 (6.1607)  loss_classifier: 5.6914 (5.6556)  loss_box_reg: 0.2500 (0.2846)  loss_objectness: 0.1180 (0.1308)  loss_rpn_box_reg: 0.0745 (0.0897)  time: 0.6011  data: 0.1476  max mem: 10734\n",
      "Testing Epoch: [80] Total time: 0:01:14 (0.5972 s / it)\n",
      "Training Epoch: [81]  [  0/500]  eta: 0:07:33  lr: 0.000000  loss: 6.9613 (6.9613)  loss_classifier: 6.4721 (6.4721)  loss_box_reg: 0.2294 (0.2294)  loss_objectness: 0.1469 (0.1469)  loss_rpn_box_reg: 0.1130 (0.1130)  time: 0.9072  data: 0.1270  max mem: 10734\n",
      "Training Epoch: [81]  [ 10/500]  eta: 0:05:10  lr: 0.000000  loss: 6.5462 (6.4318)  loss_classifier: 6.0861 (5.9343)  loss_box_reg: 0.2515 (0.2549)  loss_objectness: 0.1681 (0.1630)  loss_rpn_box_reg: 0.0900 (0.0796)  time: 0.6333  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [81]  [ 20/500]  eta: 0:05:02  lr: 0.000000  loss: 6.1551 (6.2686)  loss_classifier: 5.7017 (5.7804)  loss_box_reg: 0.2546 (0.2529)  loss_objectness: 0.1534 (0.1610)  loss_rpn_box_reg: 0.0660 (0.0743)  time: 0.6156  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [81]  [ 30/500]  eta: 0:04:55  lr: 0.000000  loss: 6.1287 (6.2820)  loss_classifier: 5.7017 (5.7966)  loss_box_reg: 0.2546 (0.2520)  loss_objectness: 0.1487 (0.1588)  loss_rpn_box_reg: 0.0617 (0.0746)  time: 0.6277  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [81]  [ 40/500]  eta: 0:04:48  lr: 0.000000  loss: 5.9273 (6.1449)  loss_classifier: 5.4996 (5.6676)  loss_box_reg: 0.2369 (0.2464)  loss_objectness: 0.1631 (0.1590)  loss_rpn_box_reg: 0.0717 (0.0718)  time: 0.6239  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [81]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 5.8464 (6.1277)  loss_classifier: 5.4549 (5.6628)  loss_box_reg: 0.2141 (0.2400)  loss_objectness: 0.1453 (0.1549)  loss_rpn_box_reg: 0.0637 (0.0699)  time: 0.6235  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [81]  [ 60/500]  eta: 0:04:35  lr: 0.000000  loss: 6.1891 (6.1514)  loss_classifier: 5.6616 (5.6815)  loss_box_reg: 0.2170 (0.2403)  loss_objectness: 0.1431 (0.1586)  loss_rpn_box_reg: 0.0700 (0.0710)  time: 0.6217  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [81]  [ 70/500]  eta: 0:04:29  lr: 0.000000  loss: 6.2684 (6.1733)  loss_classifier: 5.8925 (5.7043)  loss_box_reg: 0.2428 (0.2417)  loss_objectness: 0.1605 (0.1557)  loss_rpn_box_reg: 0.0781 (0.0716)  time: 0.6278  data: 0.1374  max mem: 10734\n",
      "Training Epoch: [81]  [ 80/500]  eta: 0:04:24  lr: 0.000000  loss: 6.2806 (6.1894)  loss_classifier: 5.9002 (5.7246)  loss_box_reg: 0.2263 (0.2390)  loss_objectness: 0.1251 (0.1526)  loss_rpn_box_reg: 0.0796 (0.0732)  time: 0.6429  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [81]  [ 90/500]  eta: 0:04:18  lr: 0.000000  loss: 6.2779 (6.2012)  loss_classifier: 5.8952 (5.7370)  loss_box_reg: 0.2173 (0.2385)  loss_objectness: 0.1325 (0.1527)  loss_rpn_box_reg: 0.0620 (0.0729)  time: 0.6383  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [81]  [100/500]  eta: 0:04:11  lr: 0.000000  loss: 6.1970 (6.1899)  loss_classifier: 5.6932 (5.7236)  loss_box_reg: 0.2318 (0.2402)  loss_objectness: 0.1490 (0.1511)  loss_rpn_box_reg: 0.0852 (0.0750)  time: 0.6196  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [81]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 6.2483 (6.2041)  loss_classifier: 5.7616 (5.7412)  loss_box_reg: 0.2218 (0.2381)  loss_objectness: 0.1401 (0.1508)  loss_rpn_box_reg: 0.0726 (0.0739)  time: 0.6032  data: 0.1314  max mem: 10734\n",
      "Training Epoch: [81]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.1415 (6.1863)  loss_classifier: 5.6867 (5.7216)  loss_box_reg: 0.2326 (0.2402)  loss_objectness: 0.1464 (0.1503)  loss_rpn_box_reg: 0.0661 (0.0742)  time: 0.6125  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [81]  [130/500]  eta: 0:03:51  lr: 0.000000  loss: 5.9858 (6.1832)  loss_classifier: 5.5168 (5.7148)  loss_box_reg: 0.2434 (0.2420)  loss_objectness: 0.1502 (0.1512)  loss_rpn_box_reg: 0.0796 (0.0751)  time: 0.6251  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [81]  [140/500]  eta: 0:03:45  lr: 0.000000  loss: 6.0254 (6.1692)  loss_classifier: 5.4696 (5.7007)  loss_box_reg: 0.2264 (0.2427)  loss_objectness: 0.1502 (0.1513)  loss_rpn_box_reg: 0.0729 (0.0745)  time: 0.6268  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [81]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 6.0671 (6.1753)  loss_classifier: 5.5933 (5.7063)  loss_box_reg: 0.2264 (0.2419)  loss_objectness: 0.1418 (0.1524)  loss_rpn_box_reg: 0.0604 (0.0747)  time: 0.6255  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [81]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.0671 (6.1838)  loss_classifier: 5.5933 (5.7142)  loss_box_reg: 0.2455 (0.2424)  loss_objectness: 0.1432 (0.1526)  loss_rpn_box_reg: 0.0682 (0.0745)  time: 0.6214  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [81]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 5.9837 (6.1856)  loss_classifier: 5.5242 (5.7192)  loss_box_reg: 0.2125 (0.2394)  loss_objectness: 0.1427 (0.1527)  loss_rpn_box_reg: 0.0682 (0.0743)  time: 0.6160  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [81]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.2736 (6.1872)  loss_classifier: 5.8079 (5.7231)  loss_box_reg: 0.2024 (0.2386)  loss_objectness: 0.1298 (0.1516)  loss_rpn_box_reg: 0.0629 (0.0740)  time: 0.6235  data: 0.1310  max mem: 10734\n",
      "Training Epoch: [81]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.2468 (6.2066)  loss_classifier: 5.8079 (5.7420)  loss_box_reg: 0.2247 (0.2383)  loss_objectness: 0.1328 (0.1522)  loss_rpn_box_reg: 0.0608 (0.0741)  time: 0.6242  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [81]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.2027 (6.2016)  loss_classifier: 5.7607 (5.7362)  loss_box_reg: 0.2486 (0.2393)  loss_objectness: 0.1543 (0.1523)  loss_rpn_box_reg: 0.0608 (0.0737)  time: 0.6271  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [81]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.1307 (6.1896)  loss_classifier: 5.6971 (5.7259)  loss_box_reg: 0.2161 (0.2382)  loss_objectness: 0.1446 (0.1520)  loss_rpn_box_reg: 0.0651 (0.0736)  time: 0.6310  data: 0.1321  max mem: 10734\n",
      "Training Epoch: [81]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.1307 (6.1921)  loss_classifier: 5.6946 (5.7266)  loss_box_reg: 0.2127 (0.2384)  loss_objectness: 0.1561 (0.1527)  loss_rpn_box_reg: 0.0682 (0.0744)  time: 0.6253  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [81]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.2030 (6.1927)  loss_classifier: 5.7303 (5.7259)  loss_box_reg: 0.2236 (0.2387)  loss_objectness: 0.1609 (0.1532)  loss_rpn_box_reg: 0.0787 (0.0748)  time: 0.6200  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [81]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.2745 (6.2039)  loss_classifier: 5.7610 (5.7387)  loss_box_reg: 0.2268 (0.2380)  loss_objectness: 0.1443 (0.1523)  loss_rpn_box_reg: 0.0716 (0.0749)  time: 0.6132  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [81]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.2836 (6.2110)  loss_classifier: 5.8780 (5.7463)  loss_box_reg: 0.2176 (0.2376)  loss_objectness: 0.1480 (0.1523)  loss_rpn_box_reg: 0.0661 (0.0747)  time: 0.6212  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [81]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.2211 (6.2131)  loss_classifier: 5.7271 (5.7491)  loss_box_reg: 0.2099 (0.2365)  loss_objectness: 0.1517 (0.1526)  loss_rpn_box_reg: 0.0717 (0.0749)  time: 0.6345  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [81]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.1603 (6.2120)  loss_classifier: 5.7059 (5.7480)  loss_box_reg: 0.2092 (0.2364)  loss_objectness: 0.1560 (0.1529)  loss_rpn_box_reg: 0.0717 (0.0747)  time: 0.6384  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [81]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.2542 (6.2113)  loss_classifier: 5.6875 (5.7458)  loss_box_reg: 0.2240 (0.2361)  loss_objectness: 0.1610 (0.1534)  loss_rpn_box_reg: 0.0789 (0.0760)  time: 0.6302  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [81]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.1018 (6.2023)  loss_classifier: 5.6001 (5.7361)  loss_box_reg: 0.2516 (0.2366)  loss_objectness: 0.1610 (0.1535)  loss_rpn_box_reg: 0.0820 (0.0760)  time: 0.6236  data: 0.1380  max mem: 10734\n",
      "Training Epoch: [81]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.2261 (6.2060)  loss_classifier: 5.6568 (5.7385)  loss_box_reg: 0.2477 (0.2370)  loss_objectness: 0.1706 (0.1544)  loss_rpn_box_reg: 0.0776 (0.0761)  time: 0.6136  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [81]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.2852 (6.2078)  loss_classifier: 5.8998 (5.7409)  loss_box_reg: 0.2176 (0.2366)  loss_objectness: 0.1550 (0.1543)  loss_rpn_box_reg: 0.0801 (0.0760)  time: 0.6107  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [81]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2999 (6.2138)  loss_classifier: 5.7864 (5.7469)  loss_box_reg: 0.2109 (0.2361)  loss_objectness: 0.1550 (0.1545)  loss_rpn_box_reg: 0.0815 (0.0762)  time: 0.6259  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [81]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.2999 (6.2140)  loss_classifier: 5.7864 (5.7460)  loss_box_reg: 0.2288 (0.2369)  loss_objectness: 0.1579 (0.1546)  loss_rpn_box_reg: 0.0765 (0.0766)  time: 0.6274  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [81]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.2436 (6.2172)  loss_classifier: 5.7616 (5.7495)  loss_box_reg: 0.2405 (0.2368)  loss_objectness: 0.1408 (0.1542)  loss_rpn_box_reg: 0.0782 (0.0766)  time: 0.6269  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [81]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.1983 (6.2161)  loss_classifier: 5.6748 (5.7491)  loss_box_reg: 0.2287 (0.2369)  loss_objectness: 0.1335 (0.1536)  loss_rpn_box_reg: 0.0746 (0.0766)  time: 0.6304  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [81]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.4444 (6.2251)  loss_classifier: 6.0470 (5.7595)  loss_box_reg: 0.2200 (0.2362)  loss_objectness: 0.1318 (0.1532)  loss_rpn_box_reg: 0.0577 (0.0762)  time: 0.6377  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [81]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.2683 (6.2230)  loss_classifier: 5.6825 (5.7577)  loss_box_reg: 0.2288 (0.2367)  loss_objectness: 0.1380 (0.1527)  loss_rpn_box_reg: 0.0533 (0.0758)  time: 0.6427  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [81]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.0034 (6.2190)  loss_classifier: 5.5909 (5.7534)  loss_box_reg: 0.2466 (0.2372)  loss_objectness: 0.1416 (0.1528)  loss_rpn_box_reg: 0.0571 (0.0756)  time: 0.6311  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [81]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.0034 (6.2177)  loss_classifier: 5.5854 (5.7515)  loss_box_reg: 0.2424 (0.2373)  loss_objectness: 0.1568 (0.1532)  loss_rpn_box_reg: 0.0571 (0.0758)  time: 0.6226  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [81]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.0189 (6.2152)  loss_classifier: 5.5910 (5.7494)  loss_box_reg: 0.2224 (0.2370)  loss_objectness: 0.1563 (0.1533)  loss_rpn_box_reg: 0.0556 (0.0755)  time: 0.6186  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [81]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.2168 (6.2150)  loss_classifier: 5.6784 (5.7484)  loss_box_reg: 0.2523 (0.2379)  loss_objectness: 0.1542 (0.1535)  loss_rpn_box_reg: 0.0556 (0.0753)  time: 0.6142  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [81]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.2001 (6.2166)  loss_classifier: 5.6647 (5.7505)  loss_box_reg: 0.2406 (0.2373)  loss_objectness: 0.1450 (0.1533)  loss_rpn_box_reg: 0.0714 (0.0755)  time: 0.6171  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [81]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2027 (6.2223)  loss_classifier: 5.7249 (5.7568)  loss_box_reg: 0.2200 (0.2369)  loss_objectness: 0.1562 (0.1534)  loss_rpn_box_reg: 0.0685 (0.0752)  time: 0.6319  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [81]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2214 (6.2189)  loss_classifier: 5.8040 (5.7544)  loss_box_reg: 0.2191 (0.2364)  loss_objectness: 0.1413 (0.1527)  loss_rpn_box_reg: 0.0678 (0.0754)  time: 0.6361  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [81]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1404 (6.2165)  loss_classifier: 5.6740 (5.7521)  loss_box_reg: 0.2191 (0.2364)  loss_objectness: 0.1319 (0.1526)  loss_rpn_box_reg: 0.0694 (0.0754)  time: 0.6256  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [81]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0386 (6.2115)  loss_classifier: 5.6048 (5.7476)  loss_box_reg: 0.2143 (0.2361)  loss_objectness: 0.1388 (0.1524)  loss_rpn_box_reg: 0.0694 (0.0754)  time: 0.6330  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [81]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 5.9636 (6.2085)  loss_classifier: 5.5066 (5.7445)  loss_box_reg: 0.2311 (0.2361)  loss_objectness: 0.1397 (0.1524)  loss_rpn_box_reg: 0.0806 (0.0755)  time: 0.6428  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [81]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1701 (6.2132)  loss_classifier: 5.7496 (5.7491)  loss_box_reg: 0.2324 (0.2359)  loss_objectness: 0.1413 (0.1525)  loss_rpn_box_reg: 0.0806 (0.0757)  time: 0.6316  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [81]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1961 (6.2123)  loss_classifier: 5.7647 (5.7474)  loss_box_reg: 0.2340 (0.2363)  loss_objectness: 0.1616 (0.1529)  loss_rpn_box_reg: 0.0758 (0.0758)  time: 0.6286  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [81]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1701 (6.2092)  loss_classifier: 5.7291 (5.7439)  loss_box_reg: 0.2437 (0.2367)  loss_objectness: 0.1540 (0.1527)  loss_rpn_box_reg: 0.0758 (0.0759)  time: 0.6288  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [81] Total time: 0:05:13 (0.6263 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:46  model_time: 0.6641 (0.6641)  evaluator_time: 0.0350 (0.0350)  time: 0.8532  data: 0.1450  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4491 (0.4526)  evaluator_time: 0.0340 (0.0369)  time: 0.6394  data: 0.1541  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4771 (0.4548)  evaluator_time: 0.0360 (0.0374)  time: 0.6653  data: 0.1537  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6431 s / it)\n",
      "Averaged stats: model_time: 0.4771 (0.4548)  evaluator_time: 0.0360 (0.0374)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.28s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [81]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1925 (6.1925)  loss_classifier: 5.6474 (5.6474)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1187 (0.1187)  loss_rpn_box_reg: 0.1318 (0.1318)  time: 0.6431  data: 0.1400  max mem: 10734\n",
      "Testing Epoch: [81]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9874 (6.1292)  loss_classifier: 5.4449 (5.6174)  loss_box_reg: 0.2609 (0.2906)  loss_objectness: 0.1318 (0.1313)  loss_rpn_box_reg: 0.0716 (0.0899)  time: 0.5877  data: 0.1468  max mem: 10734\n",
      "Testing Epoch: [81]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1698 (6.1622)  loss_classifier: 5.7006 (5.6550)  loss_box_reg: 0.2500 (0.2858)  loss_objectness: 0.1186 (0.1315)  loss_rpn_box_reg: 0.0745 (0.0899)  time: 0.5973  data: 0.1433  max mem: 10734\n",
      "Testing Epoch: [81] Total time: 0:01:14 (0.5973 s / it)\n",
      "Training Epoch: [82]  [  0/500]  eta: 0:06:49  lr: 0.000000  loss: 6.0611 (6.0611)  loss_classifier: 5.5188 (5.5188)  loss_box_reg: 0.2845 (0.2845)  loss_objectness: 0.1871 (0.1871)  loss_rpn_box_reg: 0.0706 (0.0706)  time: 0.8182  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [82]  [ 10/500]  eta: 0:05:21  lr: 0.000000  loss: 6.2230 (6.3394)  loss_classifier: 5.8009 (5.8804)  loss_box_reg: 0.2352 (0.2346)  loss_objectness: 0.1728 (0.1567)  loss_rpn_box_reg: 0.0657 (0.0678)  time: 0.6555  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [82]  [ 20/500]  eta: 0:05:06  lr: 0.000000  loss: 6.2820 (6.2912)  loss_classifier: 5.8009 (5.8350)  loss_box_reg: 0.2214 (0.2370)  loss_objectness: 0.1577 (0.1532)  loss_rpn_box_reg: 0.0621 (0.0661)  time: 0.6291  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [82]  [ 30/500]  eta: 0:04:57  lr: 0.000000  loss: 6.2872 (6.2829)  loss_classifier: 5.7777 (5.8054)  loss_box_reg: 0.2450 (0.2437)  loss_objectness: 0.1650 (0.1613)  loss_rpn_box_reg: 0.0664 (0.0725)  time: 0.6221  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [82]  [ 40/500]  eta: 0:04:51  lr: 0.000000  loss: 6.2746 (6.2386)  loss_classifier: 5.7777 (5.7749)  loss_box_reg: 0.2126 (0.2322)  loss_objectness: 0.1604 (0.1570)  loss_rpn_box_reg: 0.0881 (0.0744)  time: 0.6276  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [82]  [ 50/500]  eta: 0:04:43  lr: 0.000000  loss: 6.1939 (6.2398)  loss_classifier: 5.6124 (5.7750)  loss_box_reg: 0.2064 (0.2333)  loss_objectness: 0.1496 (0.1568)  loss_rpn_box_reg: 0.0807 (0.0747)  time: 0.6220  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [82]  [ 60/500]  eta: 0:04:35  lr: 0.000000  loss: 6.2398 (6.2420)  loss_classifier: 5.6124 (5.7763)  loss_box_reg: 0.2172 (0.2335)  loss_objectness: 0.1403 (0.1563)  loss_rpn_box_reg: 0.0666 (0.0760)  time: 0.6155  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [82]  [ 70/500]  eta: 0:04:30  lr: 0.000000  loss: 6.2576 (6.2380)  loss_classifier: 5.7851 (5.7775)  loss_box_reg: 0.2160 (0.2321)  loss_objectness: 0.1312 (0.1531)  loss_rpn_box_reg: 0.0653 (0.0753)  time: 0.6287  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [82]  [ 80/500]  eta: 0:04:22  lr: 0.000000  loss: 6.2576 (6.2380)  loss_classifier: 5.7959 (5.7716)  loss_box_reg: 0.2347 (0.2348)  loss_objectness: 0.1385 (0.1577)  loss_rpn_box_reg: 0.0577 (0.0739)  time: 0.6179  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [82]  [ 90/500]  eta: 0:04:16  lr: 0.000000  loss: 6.2740 (6.2425)  loss_classifier: 5.7766 (5.7781)  loss_box_reg: 0.2417 (0.2351)  loss_objectness: 0.1703 (0.1565)  loss_rpn_box_reg: 0.0578 (0.0727)  time: 0.6154  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [82]  [100/500]  eta: 0:04:10  lr: 0.000000  loss: 6.2707 (6.2415)  loss_classifier: 5.7384 (5.7708)  loss_box_reg: 0.2654 (0.2417)  loss_objectness: 0.1474 (0.1556)  loss_rpn_box_reg: 0.0611 (0.0733)  time: 0.6343  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [82]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 6.1989 (6.2508)  loss_classifier: 5.7384 (5.7839)  loss_box_reg: 0.2476 (0.2399)  loss_objectness: 0.1395 (0.1545)  loss_rpn_box_reg: 0.0659 (0.0725)  time: 0.6213  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [82]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.1014 (6.2424)  loss_classifier: 5.7223 (5.7767)  loss_box_reg: 0.2121 (0.2392)  loss_objectness: 0.1395 (0.1545)  loss_rpn_box_reg: 0.0526 (0.0719)  time: 0.6217  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [82]  [130/500]  eta: 0:03:52  lr: 0.000000  loss: 6.1418 (6.2465)  loss_classifier: 5.6535 (5.7812)  loss_box_reg: 0.2075 (0.2395)  loss_objectness: 0.1414 (0.1537)  loss_rpn_box_reg: 0.0688 (0.0722)  time: 0.6449  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [82]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.1418 (6.2373)  loss_classifier: 5.6231 (5.7718)  loss_box_reg: 0.2217 (0.2390)  loss_objectness: 0.1505 (0.1543)  loss_rpn_box_reg: 0.0700 (0.0723)  time: 0.6484  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [82]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.0158 (6.2296)  loss_classifier: 5.6113 (5.7644)  loss_box_reg: 0.2206 (0.2379)  loss_objectness: 0.1523 (0.1542)  loss_rpn_box_reg: 0.0700 (0.0731)  time: 0.6305  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [82]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.1275 (6.2214)  loss_classifier: 5.6113 (5.7562)  loss_box_reg: 0.2239 (0.2371)  loss_objectness: 0.1503 (0.1541)  loss_rpn_box_reg: 0.0681 (0.0741)  time: 0.6171  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [82]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.1275 (6.2160)  loss_classifier: 5.5831 (5.7494)  loss_box_reg: 0.2293 (0.2385)  loss_objectness: 0.1387 (0.1534)  loss_rpn_box_reg: 0.0780 (0.0747)  time: 0.6203  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [82]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.0526 (6.2117)  loss_classifier: 5.5519 (5.7407)  loss_box_reg: 0.2465 (0.2421)  loss_objectness: 0.1353 (0.1532)  loss_rpn_box_reg: 0.0854 (0.0758)  time: 0.6173  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [82]  [190/500]  eta: 0:03:14  lr: 0.000000  loss: 6.0789 (6.2107)  loss_classifier: 5.5694 (5.7394)  loss_box_reg: 0.2465 (0.2422)  loss_objectness: 0.1412 (0.1530)  loss_rpn_box_reg: 0.0854 (0.0761)  time: 0.6288  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [82]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.1778 (6.2133)  loss_classifier: 5.7668 (5.7396)  loss_box_reg: 0.2559 (0.2432)  loss_objectness: 0.1539 (0.1538)  loss_rpn_box_reg: 0.0820 (0.0768)  time: 0.6482  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [82]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.1773 (6.2157)  loss_classifier: 5.7977 (5.7447)  loss_box_reg: 0.2169 (0.2418)  loss_objectness: 0.1500 (0.1527)  loss_rpn_box_reg: 0.0784 (0.0764)  time: 0.6356  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [82]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.1773 (6.2156)  loss_classifier: 5.7447 (5.7457)  loss_box_reg: 0.2041 (0.2407)  loss_objectness: 0.1488 (0.1532)  loss_rpn_box_reg: 0.0620 (0.0760)  time: 0.6172  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [82]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.3073 (6.2213)  loss_classifier: 5.8532 (5.7502)  loss_box_reg: 0.2341 (0.2420)  loss_objectness: 0.1658 (0.1534)  loss_rpn_box_reg: 0.0664 (0.0757)  time: 0.6260  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [82]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.2282 (6.2199)  loss_classifier: 5.7510 (5.7489)  loss_box_reg: 0.2438 (0.2413)  loss_objectness: 0.1658 (0.1534)  loss_rpn_box_reg: 0.0777 (0.0763)  time: 0.6258  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [82]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.0049 (6.2116)  loss_classifier: 5.5168 (5.7385)  loss_box_reg: 0.2359 (0.2423)  loss_objectness: 0.1595 (0.1542)  loss_rpn_box_reg: 0.0787 (0.0765)  time: 0.6162  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [82]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 5.9445 (6.2124)  loss_classifier: 5.5027 (5.7395)  loss_box_reg: 0.2492 (0.2421)  loss_objectness: 0.1595 (0.1544)  loss_rpn_box_reg: 0.0726 (0.0764)  time: 0.6312  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [82]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 5.9763 (6.2061)  loss_classifier: 5.5347 (5.7326)  loss_box_reg: 0.2384 (0.2421)  loss_objectness: 0.1708 (0.1552)  loss_rpn_box_reg: 0.0684 (0.0761)  time: 0.6293  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [82]  [280/500]  eta: 0:02:18  lr: 0.000000  loss: 5.9763 (6.2076)  loss_classifier: 5.5347 (5.7335)  loss_box_reg: 0.2604 (0.2431)  loss_objectness: 0.1487 (0.1545)  loss_rpn_box_reg: 0.0684 (0.0765)  time: 0.6248  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [82]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.0785 (6.2042)  loss_classifier: 5.5593 (5.7305)  loss_box_reg: 0.2334 (0.2423)  loss_objectness: 0.1263 (0.1547)  loss_rpn_box_reg: 0.0761 (0.0767)  time: 0.6286  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [82]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.1351 (6.2070)  loss_classifier: 5.6083 (5.7335)  loss_box_reg: 0.2044 (0.2423)  loss_objectness: 0.1400 (0.1546)  loss_rpn_box_reg: 0.0761 (0.0766)  time: 0.6304  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [82]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.3133 (6.2101)  loss_classifier: 5.7408 (5.7369)  loss_box_reg: 0.2523 (0.2424)  loss_objectness: 0.1400 (0.1542)  loss_rpn_box_reg: 0.0750 (0.0766)  time: 0.6361  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [82]  [320/500]  eta: 0:01:53  lr: 0.000000  loss: 6.2814 (6.2090)  loss_classifier: 5.7958 (5.7375)  loss_box_reg: 0.2126 (0.2412)  loss_objectness: 0.1359 (0.1540)  loss_rpn_box_reg: 0.0750 (0.0763)  time: 0.6324  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [82]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.1277 (6.2047)  loss_classifier: 5.7685 (5.7335)  loss_box_reg: 0.2277 (0.2415)  loss_objectness: 0.1342 (0.1534)  loss_rpn_box_reg: 0.0572 (0.0762)  time: 0.6143  data: 0.1310  max mem: 10734\n",
      "Training Epoch: [82]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.1541 (6.2044)  loss_classifier: 5.7326 (5.7340)  loss_box_reg: 0.2386 (0.2412)  loss_objectness: 0.1342 (0.1536)  loss_rpn_box_reg: 0.0561 (0.0756)  time: 0.6099  data: 0.1300  max mem: 10734\n",
      "Training Epoch: [82]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.1341 (6.2017)  loss_classifier: 5.6360 (5.7298)  loss_box_reg: 0.2517 (0.2419)  loss_objectness: 0.1669 (0.1541)  loss_rpn_box_reg: 0.0613 (0.0759)  time: 0.6042  data: 0.1309  max mem: 10734\n",
      "Training Epoch: [82]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.0046 (6.1966)  loss_classifier: 5.4918 (5.7253)  loss_box_reg: 0.2430 (0.2418)  loss_objectness: 0.1445 (0.1536)  loss_rpn_box_reg: 0.0755 (0.0758)  time: 0.6022  data: 0.1314  max mem: 10734\n",
      "Training Epoch: [82]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.0207 (6.1963)  loss_classifier: 5.5627 (5.7260)  loss_box_reg: 0.2197 (0.2413)  loss_objectness: 0.1433 (0.1534)  loss_rpn_box_reg: 0.0630 (0.0756)  time: 0.6164  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [82]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.0330 (6.1984)  loss_classifier: 5.5704 (5.7275)  loss_box_reg: 0.2338 (0.2420)  loss_objectness: 0.1513 (0.1533)  loss_rpn_box_reg: 0.0630 (0.0756)  time: 0.6100  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [82]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1843 (6.1974)  loss_classifier: 5.7090 (5.7259)  loss_box_reg: 0.2500 (0.2420)  loss_objectness: 0.1509 (0.1536)  loss_rpn_box_reg: 0.0637 (0.0760)  time: 0.6196  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [82]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1890 (6.1925)  loss_classifier: 5.6972 (5.7211)  loss_box_reg: 0.2510 (0.2418)  loss_objectness: 0.1509 (0.1537)  loss_rpn_box_reg: 0.0714 (0.0759)  time: 0.6207  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [82]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 5.9423 (6.1892)  loss_classifier: 5.5689 (5.7187)  loss_box_reg: 0.2406 (0.2407)  loss_objectness: 0.1445 (0.1537)  loss_rpn_box_reg: 0.0671 (0.0761)  time: 0.6108  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [82]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 5.9796 (6.1845)  loss_classifier: 5.5689 (5.7140)  loss_box_reg: 0.2112 (0.2404)  loss_objectness: 0.1477 (0.1540)  loss_rpn_box_reg: 0.0652 (0.0761)  time: 0.6175  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [82]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.1642 (6.1846)  loss_classifier: 5.6419 (5.7142)  loss_box_reg: 0.2267 (0.2404)  loss_objectness: 0.1713 (0.1540)  loss_rpn_box_reg: 0.0698 (0.0761)  time: 0.6103  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [82]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.3731 (6.1964)  loss_classifier: 5.9761 (5.7254)  loss_box_reg: 0.2348 (0.2410)  loss_objectness: 0.1682 (0.1542)  loss_rpn_box_reg: 0.0709 (0.0759)  time: 0.6171  data: 0.1369  max mem: 10734\n",
      "Training Epoch: [82]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.4507 (6.2068)  loss_classifier: 6.0333 (5.7361)  loss_box_reg: 0.2355 (0.2407)  loss_objectness: 0.1682 (0.1542)  loss_rpn_box_reg: 0.0691 (0.0758)  time: 0.6217  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [82]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.3715 (6.2081)  loss_classifier: 5.9128 (5.7371)  loss_box_reg: 0.2404 (0.2409)  loss_objectness: 0.1573 (0.1543)  loss_rpn_box_reg: 0.0758 (0.0758)  time: 0.6184  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [82]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.2080 (6.2080)  loss_classifier: 5.7283 (5.7381)  loss_box_reg: 0.2291 (0.2402)  loss_objectness: 0.1481 (0.1540)  loss_rpn_box_reg: 0.0636 (0.0756)  time: 0.6127  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [82]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1881 (6.2079)  loss_classifier: 5.7283 (5.7389)  loss_box_reg: 0.2095 (0.2399)  loss_objectness: 0.1280 (0.1536)  loss_rpn_box_reg: 0.0636 (0.0755)  time: 0.6075  data: 0.1315  max mem: 10734\n",
      "Training Epoch: [82]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.2312 (6.2088)  loss_classifier: 5.7888 (5.7402)  loss_box_reg: 0.2224 (0.2397)  loss_objectness: 0.1391 (0.1534)  loss_rpn_box_reg: 0.0795 (0.0755)  time: 0.6276  data: 0.1311  max mem: 10734\n",
      "Training Epoch: [82]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1098 (6.2074)  loss_classifier: 5.6722 (5.7390)  loss_box_reg: 0.2171 (0.2393)  loss_objectness: 0.1415 (0.1532)  loss_rpn_box_reg: 0.0826 (0.0758)  time: 0.6340  data: 0.1306  max mem: 10734\n",
      "Training Epoch: [82] Total time: 0:05:11 (0.6236 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:56  model_time: 0.7502 (0.7502)  evaluator_time: 0.0340 (0.0340)  time: 0.9352  data: 0.1410  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4481 (0.4541)  evaluator_time: 0.0340 (0.0341)  time: 0.6410  data: 0.1546  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4741 (0.4559)  evaluator_time: 0.0360 (0.0361)  time: 0.6647  data: 0.1482  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6446 s / it)\n",
      "Averaged stats: model_time: 0.4741 (0.4559)  evaluator_time: 0.0360 (0.0361)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [82]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1812 (6.1812)  loss_classifier: 5.6480 (5.6480)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1072 (0.1072)  loss_rpn_box_reg: 0.1314 (0.1314)  time: 0.6401  data: 0.1380  max mem: 10734\n",
      "Testing Epoch: [82]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0077 (6.1389)  loss_classifier: 5.4221 (5.6287)  loss_box_reg: 0.2609 (0.2888)  loss_objectness: 0.1277 (0.1322)  loss_rpn_box_reg: 0.0713 (0.0892)  time: 0.5884  data: 0.1472  max mem: 10734\n",
      "Testing Epoch: [82]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1586 (6.1697)  loss_classifier: 5.6739 (5.6639)  loss_box_reg: 0.2500 (0.2844)  loss_objectness: 0.1195 (0.1322)  loss_rpn_box_reg: 0.0745 (0.0894)  time: 0.6011  data: 0.1463  max mem: 10734\n",
      "Testing Epoch: [82] Total time: 0:01:14 (0.5972 s / it)\n",
      "Training Epoch: [83]  [  0/500]  eta: 0:06:31  lr: 0.000000  loss: 6.6049 (6.6049)  loss_classifier: 6.0147 (6.0147)  loss_box_reg: 0.2465 (0.2465)  loss_objectness: 0.1909 (0.1909)  loss_rpn_box_reg: 0.1528 (0.1528)  time: 0.7832  data: 0.1290  max mem: 10734\n",
      "Training Epoch: [83]  [ 10/500]  eta: 0:05:02  lr: 0.000000  loss: 6.1837 (6.1881)  loss_classifier: 5.6096 (5.6804)  loss_box_reg: 0.2540 (0.2612)  loss_objectness: 0.1566 (0.1657)  loss_rpn_box_reg: 0.0762 (0.0809)  time: 0.6180  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [83]  [ 20/500]  eta: 0:04:52  lr: 0.000000  loss: 6.1571 (6.2342)  loss_classifier: 5.7305 (5.7287)  loss_box_reg: 0.2546 (0.2625)  loss_objectness: 0.1489 (0.1610)  loss_rpn_box_reg: 0.0800 (0.0820)  time: 0.6007  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [83]  [ 30/500]  eta: 0:04:50  lr: 0.000000  loss: 6.2225 (6.2887)  loss_classifier: 5.7596 (5.7820)  loss_box_reg: 0.2629 (0.2667)  loss_objectness: 0.1447 (0.1604)  loss_rpn_box_reg: 0.0823 (0.0797)  time: 0.6185  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [83]  [ 40/500]  eta: 0:04:43  lr: 0.000000  loss: 6.2326 (6.2581)  loss_classifier: 5.7213 (5.7605)  loss_box_reg: 0.2629 (0.2601)  loss_objectness: 0.1447 (0.1582)  loss_rpn_box_reg: 0.0760 (0.0792)  time: 0.6236  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [83]  [ 50/500]  eta: 0:04:39  lr: 0.000000  loss: 6.1045 (6.2478)  loss_classifier: 5.6687 (5.7647)  loss_box_reg: 0.2234 (0.2508)  loss_objectness: 0.1330 (0.1534)  loss_rpn_box_reg: 0.0820 (0.0790)  time: 0.6229  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [83]  [ 60/500]  eta: 0:04:31  lr: 0.000000  loss: 6.1045 (6.2142)  loss_classifier: 5.6177 (5.7279)  loss_box_reg: 0.2442 (0.2542)  loss_objectness: 0.1398 (0.1532)  loss_rpn_box_reg: 0.0818 (0.0789)  time: 0.6196  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [83]  [ 70/500]  eta: 0:04:25  lr: 0.000000  loss: 6.0903 (6.1843)  loss_classifier: 5.6177 (5.7026)  loss_box_reg: 0.2628 (0.2532)  loss_objectness: 0.1460 (0.1525)  loss_rpn_box_reg: 0.0662 (0.0760)  time: 0.6092  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [83]  [ 80/500]  eta: 0:04:19  lr: 0.000000  loss: 6.1107 (6.2080)  loss_classifier: 5.7410 (5.7336)  loss_box_reg: 0.2022 (0.2467)  loss_objectness: 0.1508 (0.1531)  loss_rpn_box_reg: 0.0547 (0.0746)  time: 0.6209  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [83]  [ 90/500]  eta: 0:04:13  lr: 0.000000  loss: 6.2183 (6.2146)  loss_classifier: 5.7407 (5.7406)  loss_box_reg: 0.2022 (0.2453)  loss_objectness: 0.1567 (0.1552)  loss_rpn_box_reg: 0.0548 (0.0735)  time: 0.6276  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [83]  [100/500]  eta: 0:04:08  lr: 0.000000  loss: 5.9607 (6.1802)  loss_classifier: 5.5728 (5.7127)  loss_box_reg: 0.2068 (0.2422)  loss_objectness: 0.1473 (0.1534)  loss_rpn_box_reg: 0.0538 (0.0719)  time: 0.6281  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [83]  [110/500]  eta: 0:04:01  lr: 0.000000  loss: 5.8862 (6.1693)  loss_classifier: 5.4762 (5.6998)  loss_box_reg: 0.2242 (0.2415)  loss_objectness: 0.1462 (0.1541)  loss_rpn_box_reg: 0.0723 (0.0739)  time: 0.6165  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [83]  [120/500]  eta: 0:03:55  lr: 0.000000  loss: 5.9898 (6.1615)  loss_classifier: 5.4882 (5.6914)  loss_box_reg: 0.2485 (0.2433)  loss_objectness: 0.1467 (0.1534)  loss_rpn_box_reg: 0.0753 (0.0735)  time: 0.6145  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [83]  [130/500]  eta: 0:03:48  lr: 0.000000  loss: 5.9898 (6.1502)  loss_classifier: 5.4982 (5.6791)  loss_box_reg: 0.2530 (0.2431)  loss_objectness: 0.1410 (0.1538)  loss_rpn_box_reg: 0.0684 (0.0742)  time: 0.6095  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [83]  [140/500]  eta: 0:03:42  lr: 0.000000  loss: 6.0700 (6.1681)  loss_classifier: 5.5700 (5.6971)  loss_box_reg: 0.2504 (0.2426)  loss_objectness: 0.1478 (0.1537)  loss_rpn_box_reg: 0.0722 (0.0748)  time: 0.6044  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [83]  [150/500]  eta: 0:03:36  lr: 0.000000  loss: 6.3132 (6.1692)  loss_classifier: 5.8150 (5.6976)  loss_box_reg: 0.2494 (0.2435)  loss_objectness: 0.1506 (0.1533)  loss_rpn_box_reg: 0.0663 (0.0748)  time: 0.6190  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [83]  [160/500]  eta: 0:03:30  lr: 0.000000  loss: 6.1913 (6.1786)  loss_classifier: 5.8091 (5.7075)  loss_box_reg: 0.2320 (0.2434)  loss_objectness: 0.1467 (0.1529)  loss_rpn_box_reg: 0.0663 (0.0748)  time: 0.6305  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [83]  [170/500]  eta: 0:03:24  lr: 0.000000  loss: 6.1913 (6.1715)  loss_classifier: 5.5786 (5.6987)  loss_box_reg: 0.2583 (0.2457)  loss_objectness: 0.1315 (0.1521)  loss_rpn_box_reg: 0.0702 (0.0750)  time: 0.6283  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [83]  [180/500]  eta: 0:03:17  lr: 0.000000  loss: 6.0197 (6.1699)  loss_classifier: 5.5320 (5.6976)  loss_box_reg: 0.2659 (0.2459)  loss_objectness: 0.1342 (0.1516)  loss_rpn_box_reg: 0.0614 (0.0749)  time: 0.6026  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [83]  [190/500]  eta: 0:03:11  lr: 0.000000  loss: 6.1373 (6.1776)  loss_classifier: 5.7201 (5.7075)  loss_box_reg: 0.2478 (0.2438)  loss_objectness: 0.1507 (0.1518)  loss_rpn_box_reg: 0.0568 (0.0745)  time: 0.6117  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [83]  [200/500]  eta: 0:03:05  lr: 0.000000  loss: 6.2400 (6.1814)  loss_classifier: 5.8530 (5.7112)  loss_box_reg: 0.2123 (0.2431)  loss_objectness: 0.1497 (0.1524)  loss_rpn_box_reg: 0.0750 (0.0747)  time: 0.6262  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [83]  [210/500]  eta: 0:02:59  lr: 0.000000  loss: 6.3192 (6.1946)  loss_classifier: 5.8682 (5.7269)  loss_box_reg: 0.2058 (0.2417)  loss_objectness: 0.1475 (0.1519)  loss_rpn_box_reg: 0.0808 (0.0741)  time: 0.6233  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [83]  [220/500]  eta: 0:02:53  lr: 0.000000  loss: 6.2168 (6.1913)  loss_classifier: 5.8491 (5.7241)  loss_box_reg: 0.2178 (0.2412)  loss_objectness: 0.1517 (0.1520)  loss_rpn_box_reg: 0.0650 (0.0739)  time: 0.6331  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [83]  [230/500]  eta: 0:02:47  lr: 0.000000  loss: 6.0860 (6.1867)  loss_classifier: 5.5236 (5.7199)  loss_box_reg: 0.2506 (0.2411)  loss_objectness: 0.1521 (0.1523)  loss_rpn_box_reg: 0.0650 (0.0735)  time: 0.6292  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [83]  [240/500]  eta: 0:02:41  lr: 0.000000  loss: 6.4506 (6.2014)  loss_classifier: 5.8256 (5.7320)  loss_box_reg: 0.2478 (0.2432)  loss_objectness: 0.1446 (0.1519)  loss_rpn_box_reg: 0.0760 (0.0742)  time: 0.6230  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [83]  [250/500]  eta: 0:02:34  lr: 0.000000  loss: 6.4104 (6.2021)  loss_classifier: 5.8935 (5.7319)  loss_box_reg: 0.2430 (0.2440)  loss_objectness: 0.1437 (0.1518)  loss_rpn_box_reg: 0.0765 (0.0744)  time: 0.6084  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [83]  [260/500]  eta: 0:02:28  lr: 0.000000  loss: 6.1228 (6.1952)  loss_classifier: 5.6526 (5.7250)  loss_box_reg: 0.2404 (0.2436)  loss_objectness: 0.1437 (0.1517)  loss_rpn_box_reg: 0.0738 (0.0748)  time: 0.5991  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [83]  [270/500]  eta: 0:02:22  lr: 0.000000  loss: 6.0465 (6.2000)  loss_classifier: 5.6236 (5.7299)  loss_box_reg: 0.2272 (0.2434)  loss_objectness: 0.1441 (0.1517)  loss_rpn_box_reg: 0.0709 (0.0751)  time: 0.6093  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [83]  [280/500]  eta: 0:02:16  lr: 0.000000  loss: 6.2659 (6.2100)  loss_classifier: 5.6941 (5.7417)  loss_box_reg: 0.2213 (0.2420)  loss_objectness: 0.1469 (0.1517)  loss_rpn_box_reg: 0.0571 (0.0746)  time: 0.6347  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [83]  [290/500]  eta: 0:02:10  lr: 0.000000  loss: 6.1746 (6.2053)  loss_classifier: 5.6941 (5.7366)  loss_box_reg: 0.2202 (0.2422)  loss_objectness: 0.1506 (0.1521)  loss_rpn_box_reg: 0.0614 (0.0744)  time: 0.6346  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [83]  [300/500]  eta: 0:02:03  lr: 0.000000  loss: 6.1929 (6.2134)  loss_classifier: 5.7764 (5.7447)  loss_box_reg: 0.2286 (0.2421)  loss_objectness: 0.1587 (0.1522)  loss_rpn_box_reg: 0.0659 (0.0744)  time: 0.6234  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [83]  [310/500]  eta: 0:01:57  lr: 0.000000  loss: 6.4888 (6.2212)  loss_classifier: 6.0253 (5.7531)  loss_box_reg: 0.2084 (0.2411)  loss_objectness: 0.1553 (0.1528)  loss_rpn_box_reg: 0.0636 (0.0743)  time: 0.6354  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [83]  [320/500]  eta: 0:01:51  lr: 0.000000  loss: 6.2583 (6.2149)  loss_classifier: 5.9351 (5.7475)  loss_box_reg: 0.2040 (0.2402)  loss_objectness: 0.1553 (0.1529)  loss_rpn_box_reg: 0.0734 (0.0745)  time: 0.6204  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [83]  [330/500]  eta: 0:01:45  lr: 0.000000  loss: 6.0117 (6.2151)  loss_classifier: 5.5664 (5.7478)  loss_box_reg: 0.2157 (0.2396)  loss_objectness: 0.1554 (0.1531)  loss_rpn_box_reg: 0.0751 (0.0746)  time: 0.6054  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [83]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.0950 (6.2108)  loss_classifier: 5.6405 (5.7444)  loss_box_reg: 0.2202 (0.2392)  loss_objectness: 0.1555 (0.1530)  loss_rpn_box_reg: 0.0649 (0.0743)  time: 0.6177  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [83]  [350/500]  eta: 0:01:32  lr: 0.000000  loss: 6.0517 (6.2075)  loss_classifier: 5.6206 (5.7411)  loss_box_reg: 0.2214 (0.2389)  loss_objectness: 0.1480 (0.1530)  loss_rpn_box_reg: 0.0607 (0.0745)  time: 0.6213  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [83]  [360/500]  eta: 0:01:26  lr: 0.000000  loss: 6.0374 (6.2052)  loss_classifier: 5.5790 (5.7371)  loss_box_reg: 0.2382 (0.2404)  loss_objectness: 0.1504 (0.1530)  loss_rpn_box_reg: 0.0815 (0.0747)  time: 0.6279  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [83]  [370/500]  eta: 0:01:20  lr: 0.000000  loss: 6.0374 (6.2052)  loss_classifier: 5.5806 (5.7376)  loss_box_reg: 0.2382 (0.2403)  loss_objectness: 0.1481 (0.1528)  loss_rpn_box_reg: 0.0691 (0.0745)  time: 0.6396  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [83]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.1719 (6.2051)  loss_classifier: 5.6476 (5.7386)  loss_box_reg: 0.2144 (0.2398)  loss_objectness: 0.1383 (0.1524)  loss_rpn_box_reg: 0.0652 (0.0743)  time: 0.6335  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [83]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.0758 (6.2007)  loss_classifier: 5.6476 (5.7346)  loss_box_reg: 0.2185 (0.2396)  loss_objectness: 0.1420 (0.1523)  loss_rpn_box_reg: 0.0685 (0.0742)  time: 0.6231  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [83]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1037 (6.2007)  loss_classifier: 5.6954 (5.7342)  loss_box_reg: 0.2370 (0.2399)  loss_objectness: 0.1451 (0.1523)  loss_rpn_box_reg: 0.0704 (0.0744)  time: 0.6287  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [83]  [410/500]  eta: 0:00:55  lr: 0.000000  loss: 6.1670 (6.2002)  loss_classifier: 5.6692 (5.7331)  loss_box_reg: 0.2370 (0.2403)  loss_objectness: 0.1454 (0.1521)  loss_rpn_box_reg: 0.0704 (0.0747)  time: 0.6418  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [83]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.2323 (6.2043)  loss_classifier: 5.6997 (5.7368)  loss_box_reg: 0.2440 (0.2404)  loss_objectness: 0.1607 (0.1525)  loss_rpn_box_reg: 0.0700 (0.0747)  time: 0.6268  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [83]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2757 (6.2068)  loss_classifier: 5.7843 (5.7384)  loss_box_reg: 0.2518 (0.2410)  loss_objectness: 0.1725 (0.1525)  loss_rpn_box_reg: 0.0721 (0.0749)  time: 0.6080  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [83]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.3549 (6.2098)  loss_classifier: 5.8520 (5.7411)  loss_box_reg: 0.2312 (0.2408)  loss_objectness: 0.1668 (0.1527)  loss_rpn_box_reg: 0.0761 (0.0752)  time: 0.6191  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [83]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.2586 (6.2070)  loss_classifier: 5.8428 (5.7389)  loss_box_reg: 0.2174 (0.2402)  loss_objectness: 0.1668 (0.1530)  loss_rpn_box_reg: 0.0725 (0.0750)  time: 0.6244  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [83]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.2145 (6.2108)  loss_classifier: 5.7630 (5.7425)  loss_box_reg: 0.2183 (0.2402)  loss_objectness: 0.1478 (0.1529)  loss_rpn_box_reg: 0.0714 (0.0753)  time: 0.6087  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [83]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.3552 (6.2136)  loss_classifier: 5.9022 (5.7447)  loss_box_reg: 0.2301 (0.2402)  loss_objectness: 0.1424 (0.1530)  loss_rpn_box_reg: 0.0770 (0.0757)  time: 0.6301  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [83]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.3508 (6.2182)  loss_classifier: 5.8419 (5.7491)  loss_box_reg: 0.2461 (0.2405)  loss_objectness: 0.1402 (0.1528)  loss_rpn_box_reg: 0.0770 (0.0758)  time: 0.6417  data: 0.1378  max mem: 10734\n",
      "Training Epoch: [83]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.2088 (6.2139)  loss_classifier: 5.6960 (5.7442)  loss_box_reg: 0.2716 (0.2411)  loss_objectness: 0.1402 (0.1526)  loss_rpn_box_reg: 0.0743 (0.0760)  time: 0.6210  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [83]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0119 (6.2141)  loss_classifier: 5.5504 (5.7445)  loss_box_reg: 0.2280 (0.2409)  loss_objectness: 0.1545 (0.1528)  loss_rpn_box_reg: 0.0708 (0.0759)  time: 0.6407  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [83] Total time: 0:05:11 (0.6224 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:55  model_time: 0.7342 (0.7342)  evaluator_time: 0.0350 (0.0350)  time: 0.9212  data: 0.1430  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4481 (0.4527)  evaluator_time: 0.0330 (0.0348)  time: 0.6378  data: 0.1543  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4731 (0.4543)  evaluator_time: 0.0360 (0.0356)  time: 0.6545  data: 0.1474  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6421 s / it)\n",
      "Averaged stats: model_time: 0.4731 (0.4543)  evaluator_time: 0.0360 (0.0356)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [83]  [  0/125]  eta: 0:01:29  lr: 0.000000  loss: 6.1984 (6.1984)  loss_classifier: 5.6548 (5.6548)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1196 (0.1196)  loss_rpn_box_reg: 0.1295 (0.1295)  time: 0.7192  data: 0.2210  max mem: 10734\n",
      "Testing Epoch: [83]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0198 (6.1366)  loss_classifier: 5.4370 (5.6251)  loss_box_reg: 0.2609 (0.2896)  loss_objectness: 0.1301 (0.1322)  loss_rpn_box_reg: 0.0723 (0.0897)  time: 0.5852  data: 0.1452  max mem: 10734\n",
      "Testing Epoch: [83]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1684 (6.1686)  loss_classifier: 5.6849 (5.6616)  loss_box_reg: 0.2500 (0.2850)  loss_objectness: 0.1223 (0.1323)  loss_rpn_box_reg: 0.0745 (0.0898)  time: 0.6014  data: 0.1469  max mem: 10734\n",
      "Testing Epoch: [83] Total time: 0:01:14 (0.5968 s / it)\n",
      "Training Epoch: [84]  [  0/500]  eta: 0:07:03  lr: 0.000000  loss: 5.7508 (5.7508)  loss_classifier: 5.2590 (5.2590)  loss_box_reg: 0.2648 (0.2648)  loss_objectness: 0.1640 (0.1640)  loss_rpn_box_reg: 0.0630 (0.0630)  time: 0.8462  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [84]  [ 10/500]  eta: 0:05:10  lr: 0.000000  loss: 6.1876 (6.2350)  loss_classifier: 5.6511 (5.7264)  loss_box_reg: 0.2519 (0.2580)  loss_objectness: 0.1596 (0.1567)  loss_rpn_box_reg: 0.0806 (0.0940)  time: 0.6335  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [84]  [ 20/500]  eta: 0:05:02  lr: 0.000000  loss: 6.1018 (6.2549)  loss_classifier: 5.6075 (5.7662)  loss_box_reg: 0.2414 (0.2499)  loss_objectness: 0.1596 (0.1557)  loss_rpn_box_reg: 0.0806 (0.0830)  time: 0.6192  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [84]  [ 30/500]  eta: 0:04:57  lr: 0.000000  loss: 6.1018 (6.2472)  loss_classifier: 5.5895 (5.7614)  loss_box_reg: 0.2218 (0.2470)  loss_objectness: 0.1618 (0.1538)  loss_rpn_box_reg: 0.0856 (0.0850)  time: 0.6317  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [84]  [ 40/500]  eta: 0:04:49  lr: 0.000000  loss: 6.1425 (6.2330)  loss_classifier: 5.7182 (5.7646)  loss_box_reg: 0.1931 (0.2398)  loss_objectness: 0.1400 (0.1509)  loss_rpn_box_reg: 0.0655 (0.0776)  time: 0.6292  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [84]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 6.2586 (6.2680)  loss_classifier: 5.8731 (5.8060)  loss_box_reg: 0.2035 (0.2358)  loss_objectness: 0.1400 (0.1504)  loss_rpn_box_reg: 0.0578 (0.0758)  time: 0.6196  data: 0.1297  max mem: 10734\n",
      "Training Epoch: [84]  [ 60/500]  eta: 0:04:35  lr: 0.000000  loss: 6.2233 (6.2356)  loss_classifier: 5.6638 (5.7723)  loss_box_reg: 0.2199 (0.2367)  loss_objectness: 0.1394 (0.1478)  loss_rpn_box_reg: 0.0823 (0.0789)  time: 0.6164  data: 0.1300  max mem: 10734\n",
      "Training Epoch: [84]  [ 70/500]  eta: 0:04:28  lr: 0.000000  loss: 6.1590 (6.2240)  loss_classifier: 5.6638 (5.7670)  loss_box_reg: 0.2199 (0.2346)  loss_objectness: 0.1394 (0.1474)  loss_rpn_box_reg: 0.0630 (0.0750)  time: 0.6168  data: 0.1319  max mem: 10734\n",
      "Training Epoch: [84]  [ 80/500]  eta: 0:04:21  lr: 0.000000  loss: 6.1858 (6.2176)  loss_classifier: 5.7265 (5.7559)  loss_box_reg: 0.2323 (0.2352)  loss_objectness: 0.1619 (0.1500)  loss_rpn_box_reg: 0.0646 (0.0765)  time: 0.6179  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [84]  [ 90/500]  eta: 0:04:15  lr: 0.000000  loss: 6.3609 (6.2144)  loss_classifier: 5.8002 (5.7490)  loss_box_reg: 0.2557 (0.2398)  loss_objectness: 0.1572 (0.1492)  loss_rpn_box_reg: 0.0733 (0.0765)  time: 0.6200  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [84]  [100/500]  eta: 0:04:08  lr: 0.000000  loss: 6.3564 (6.2117)  loss_classifier: 5.8653 (5.7486)  loss_box_reg: 0.2264 (0.2369)  loss_objectness: 0.1432 (0.1493)  loss_rpn_box_reg: 0.0592 (0.0770)  time: 0.6177  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [84]  [110/500]  eta: 0:04:02  lr: 0.000000  loss: 6.2496 (6.2091)  loss_classifier: 5.7193 (5.7426)  loss_box_reg: 0.2264 (0.2379)  loss_objectness: 0.1671 (0.1515)  loss_rpn_box_reg: 0.0740 (0.0771)  time: 0.6156  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [84]  [120/500]  eta: 0:03:57  lr: 0.000000  loss: 6.0732 (6.2061)  loss_classifier: 5.5703 (5.7401)  loss_box_reg: 0.2364 (0.2369)  loss_objectness: 0.1610 (0.1521)  loss_rpn_box_reg: 0.0740 (0.0770)  time: 0.6307  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [84]  [130/500]  eta: 0:03:50  lr: 0.000000  loss: 5.9824 (6.1878)  loss_classifier: 5.5652 (5.7209)  loss_box_reg: 0.2220 (0.2368)  loss_objectness: 0.1518 (0.1522)  loss_rpn_box_reg: 0.0752 (0.0779)  time: 0.6248  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [84]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 5.8994 (6.1744)  loss_classifier: 5.4773 (5.7081)  loss_box_reg: 0.2162 (0.2361)  loss_objectness: 0.1466 (0.1517)  loss_rpn_box_reg: 0.0776 (0.0785)  time: 0.6141  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [84]  [150/500]  eta: 0:03:38  lr: 0.000000  loss: 5.9628 (6.1795)  loss_classifier: 5.5039 (5.7134)  loss_box_reg: 0.1976 (0.2364)  loss_objectness: 0.1402 (0.1510)  loss_rpn_box_reg: 0.0726 (0.0787)  time: 0.6268  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [84]  [160/500]  eta: 0:03:32  lr: 0.000000  loss: 6.2205 (6.1799)  loss_classifier: 5.7517 (5.7151)  loss_box_reg: 0.2146 (0.2376)  loss_objectness: 0.1349 (0.1501)  loss_rpn_box_reg: 0.0632 (0.0772)  time: 0.6370  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [84]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 6.2205 (6.1798)  loss_classifier: 5.7550 (5.7147)  loss_box_reg: 0.2246 (0.2372)  loss_objectness: 0.1433 (0.1502)  loss_rpn_box_reg: 0.0534 (0.0778)  time: 0.6104  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [84]  [180/500]  eta: 0:03:18  lr: 0.000000  loss: 6.0621 (6.1710)  loss_classifier: 5.4749 (5.7042)  loss_box_reg: 0.2246 (0.2379)  loss_objectness: 0.1548 (0.1508)  loss_rpn_box_reg: 0.0800 (0.0780)  time: 0.6011  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [84]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.0213 (6.1820)  loss_classifier: 5.5167 (5.7136)  loss_box_reg: 0.2580 (0.2402)  loss_objectness: 0.1464 (0.1505)  loss_rpn_box_reg: 0.0708 (0.0777)  time: 0.6317  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [84]  [200/500]  eta: 0:03:06  lr: 0.000000  loss: 6.1374 (6.1727)  loss_classifier: 5.7193 (5.7033)  loss_box_reg: 0.2836 (0.2410)  loss_objectness: 0.1499 (0.1511)  loss_rpn_box_reg: 0.0612 (0.0772)  time: 0.6276  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [84]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.1374 (6.1822)  loss_classifier: 5.7340 (5.7127)  loss_box_reg: 0.2483 (0.2409)  loss_objectness: 0.1528 (0.1516)  loss_rpn_box_reg: 0.0664 (0.0771)  time: 0.6194  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [84]  [220/500]  eta: 0:02:53  lr: 0.000000  loss: 6.3578 (6.1906)  loss_classifier: 5.8422 (5.7204)  loss_box_reg: 0.2483 (0.2418)  loss_objectness: 0.1482 (0.1517)  loss_rpn_box_reg: 0.0615 (0.0767)  time: 0.6131  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [84]  [230/500]  eta: 0:02:47  lr: 0.000000  loss: 6.3578 (6.1911)  loss_classifier: 5.7708 (5.7196)  loss_box_reg: 0.2795 (0.2428)  loss_objectness: 0.1495 (0.1519)  loss_rpn_box_reg: 0.0627 (0.0768)  time: 0.6073  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [84]  [240/500]  eta: 0:02:41  lr: 0.000000  loss: 6.1073 (6.1898)  loss_classifier: 5.6763 (5.7192)  loss_box_reg: 0.2273 (0.2421)  loss_objectness: 0.1526 (0.1520)  loss_rpn_box_reg: 0.0735 (0.0765)  time: 0.6150  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [84]  [250/500]  eta: 0:02:35  lr: 0.000000  loss: 6.0571 (6.1880)  loss_classifier: 5.6296 (5.7185)  loss_box_reg: 0.2002 (0.2410)  loss_objectness: 0.1468 (0.1519)  loss_rpn_box_reg: 0.0700 (0.0767)  time: 0.6361  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [84]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.0947 (6.1901)  loss_classifier: 5.6296 (5.7210)  loss_box_reg: 0.2328 (0.2408)  loss_objectness: 0.1468 (0.1517)  loss_rpn_box_reg: 0.0687 (0.0766)  time: 0.6340  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [84]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.0947 (6.1852)  loss_classifier: 5.7193 (5.7149)  loss_box_reg: 0.2328 (0.2412)  loss_objectness: 0.1676 (0.1522)  loss_rpn_box_reg: 0.0800 (0.0769)  time: 0.6157  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [84]  [280/500]  eta: 0:02:16  lr: 0.000000  loss: 6.0640 (6.1849)  loss_classifier: 5.5617 (5.7154)  loss_box_reg: 0.2213 (0.2405)  loss_objectness: 0.1505 (0.1522)  loss_rpn_box_reg: 0.0720 (0.0768)  time: 0.6225  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [84]  [290/500]  eta: 0:02:10  lr: 0.000000  loss: 6.0623 (6.1821)  loss_classifier: 5.7090 (5.7133)  loss_box_reg: 0.2213 (0.2402)  loss_objectness: 0.1474 (0.1519)  loss_rpn_box_reg: 0.0701 (0.0767)  time: 0.6227  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [84]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.2396 (6.1899)  loss_classifier: 5.7881 (5.7207)  loss_box_reg: 0.2483 (0.2404)  loss_objectness: 0.1467 (0.1522)  loss_rpn_box_reg: 0.0701 (0.0766)  time: 0.6116  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [84]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.2388 (6.1923)  loss_classifier: 5.7848 (5.7218)  loss_box_reg: 0.2483 (0.2407)  loss_objectness: 0.1608 (0.1529)  loss_rpn_box_reg: 0.0674 (0.0769)  time: 0.6111  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [84]  [320/500]  eta: 0:01:51  lr: 0.000000  loss: 6.1336 (6.1944)  loss_classifier: 5.7477 (5.7249)  loss_box_reg: 0.2443 (0.2402)  loss_objectness: 0.1413 (0.1522)  loss_rpn_box_reg: 0.0674 (0.0772)  time: 0.6282  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [84]  [330/500]  eta: 0:01:45  lr: 0.000000  loss: 6.4122 (6.2049)  loss_classifier: 6.0144 (5.7346)  loss_box_reg: 0.2443 (0.2402)  loss_objectness: 0.1445 (0.1532)  loss_rpn_box_reg: 0.0695 (0.0770)  time: 0.6260  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [84]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.2676 (6.2024)  loss_classifier: 5.8087 (5.7327)  loss_box_reg: 0.2279 (0.2395)  loss_objectness: 0.1657 (0.1530)  loss_rpn_box_reg: 0.0774 (0.0772)  time: 0.6187  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [84]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.0152 (6.1977)  loss_classifier: 5.6101 (5.7281)  loss_box_reg: 0.2280 (0.2405)  loss_objectness: 0.1294 (0.1522)  loss_rpn_box_reg: 0.0791 (0.0770)  time: 0.6246  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [84]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1028 (6.1915)  loss_classifier: 5.6101 (5.7232)  loss_box_reg: 0.2417 (0.2397)  loss_objectness: 0.1317 (0.1522)  loss_rpn_box_reg: 0.0553 (0.0764)  time: 0.6292  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [84]  [370/500]  eta: 0:01:20  lr: 0.000000  loss: 6.1290 (6.1934)  loss_classifier: 5.6313 (5.7254)  loss_box_reg: 0.2030 (0.2389)  loss_objectness: 0.1632 (0.1527)  loss_rpn_box_reg: 0.0586 (0.0764)  time: 0.6248  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [84]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.3520 (6.1986)  loss_classifier: 5.8691 (5.7296)  loss_box_reg: 0.2179 (0.2403)  loss_objectness: 0.1507 (0.1525)  loss_rpn_box_reg: 0.0680 (0.0762)  time: 0.6164  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [84]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.3897 (6.2035)  loss_classifier: 5.8884 (5.7356)  loss_box_reg: 0.2679 (0.2399)  loss_objectness: 0.1406 (0.1522)  loss_rpn_box_reg: 0.0578 (0.0757)  time: 0.6297  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [84]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.3744 (6.2084)  loss_classifier: 5.8732 (5.7392)  loss_box_reg: 0.2435 (0.2411)  loss_objectness: 0.1406 (0.1522)  loss_rpn_box_reg: 0.0638 (0.0759)  time: 0.6282  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [84]  [410/500]  eta: 0:00:55  lr: 0.000000  loss: 6.2158 (6.2120)  loss_classifier: 5.7835 (5.7429)  loss_box_reg: 0.2686 (0.2409)  loss_objectness: 0.1492 (0.1521)  loss_rpn_box_reg: 0.0752 (0.0761)  time: 0.6159  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [84]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.1484 (6.2156)  loss_classifier: 5.7366 (5.7449)  loss_box_reg: 0.2560 (0.2416)  loss_objectness: 0.1636 (0.1527)  loss_rpn_box_reg: 0.0933 (0.0764)  time: 0.6167  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [84]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 5.9916 (6.2086)  loss_classifier: 5.5329 (5.7371)  loss_box_reg: 0.2622 (0.2420)  loss_objectness: 0.1650 (0.1530)  loss_rpn_box_reg: 0.0911 (0.0766)  time: 0.6138  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [84]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 5.9916 (6.2060)  loss_classifier: 5.4972 (5.7349)  loss_box_reg: 0.2529 (0.2416)  loss_objectness: 0.1559 (0.1529)  loss_rpn_box_reg: 0.0845 (0.0766)  time: 0.6252  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [84]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1128 (6.2055)  loss_classifier: 5.6749 (5.7345)  loss_box_reg: 0.2199 (0.2412)  loss_objectness: 0.1559 (0.1532)  loss_rpn_box_reg: 0.0815 (0.0767)  time: 0.6432  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [84]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 6.3434 (6.2105)  loss_classifier: 5.8655 (5.7395)  loss_box_reg: 0.2235 (0.2410)  loss_objectness: 0.1628 (0.1533)  loss_rpn_box_reg: 0.0735 (0.0766)  time: 0.6379  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [84]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1633 (6.2116)  loss_classifier: 5.7088 (5.7405)  loss_box_reg: 0.2235 (0.2413)  loss_objectness: 0.1589 (0.1534)  loss_rpn_box_reg: 0.0629 (0.0765)  time: 0.6296  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [84]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1500 (6.2151)  loss_classifier: 5.7045 (5.7441)  loss_box_reg: 0.2358 (0.2411)  loss_objectness: 0.1489 (0.1535)  loss_rpn_box_reg: 0.0648 (0.0764)  time: 0.6282  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [84]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.2536 (6.2121)  loss_classifier: 5.7875 (5.7413)  loss_box_reg: 0.2333 (0.2407)  loss_objectness: 0.1522 (0.1536)  loss_rpn_box_reg: 0.0714 (0.0765)  time: 0.6198  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [84]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1332 (6.2118)  loss_classifier: 5.7260 (5.7425)  loss_box_reg: 0.2169 (0.2399)  loss_objectness: 0.1522 (0.1533)  loss_rpn_box_reg: 0.0588 (0.0762)  time: 0.6300  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [84] Total time: 0:05:11 (0.6232 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:49  model_time: 0.6872 (0.6872)  evaluator_time: 0.0350 (0.0350)  time: 0.8732  data: 0.1420  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4441 (0.4552)  evaluator_time: 0.0340 (0.0361)  time: 0.6337  data: 0.1484  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4701 (0.4564)  evaluator_time: 0.0360 (0.0366)  time: 0.6568  data: 0.1488  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6451 s / it)\n",
      "Averaged stats: model_time: 0.4701 (0.4564)  evaluator_time: 0.0360 (0.0366)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [84]  [  0/125]  eta: 0:01:22  lr: 0.000000  loss: 6.1961 (6.1961)  loss_classifier: 5.6386 (5.6386)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1312 (0.1312)  loss_rpn_box_reg: 0.1318 (0.1318)  time: 0.6571  data: 0.1500  max mem: 10734\n",
      "Testing Epoch: [84]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0256 (6.1404)  loss_classifier: 5.4361 (5.6279)  loss_box_reg: 0.2609 (0.2907)  loss_objectness: 0.1326 (0.1321)  loss_rpn_box_reg: 0.0714 (0.0897)  time: 0.5854  data: 0.1470  max mem: 10734\n",
      "Testing Epoch: [84]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1520 (6.1694)  loss_classifier: 5.6857 (5.6619)  loss_box_reg: 0.2500 (0.2859)  loss_objectness: 0.1173 (0.1318)  loss_rpn_box_reg: 0.0745 (0.0897)  time: 0.5979  data: 0.1455  max mem: 10734\n",
      "Testing Epoch: [84] Total time: 0:01:14 (0.5951 s / it)\n",
      "Training Epoch: [85]  [  0/500]  eta: 0:07:24  lr: 0.000000  loss: 5.8522 (5.8522)  loss_classifier: 5.4011 (5.4011)  loss_box_reg: 0.2093 (0.2093)  loss_objectness: 0.1733 (0.1733)  loss_rpn_box_reg: 0.0685 (0.0685)  time: 0.8882  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [85]  [ 10/500]  eta: 0:05:12  lr: 0.000000  loss: 6.1498 (6.2382)  loss_classifier: 5.7144 (5.7794)  loss_box_reg: 0.2233 (0.2289)  loss_objectness: 0.1516 (0.1554)  loss_rpn_box_reg: 0.0690 (0.0745)  time: 0.6370  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [85]  [ 20/500]  eta: 0:05:03  lr: 0.000000  loss: 6.2261 (6.1923)  loss_classifier: 5.7479 (5.7468)  loss_box_reg: 0.2233 (0.2231)  loss_objectness: 0.1499 (0.1532)  loss_rpn_box_reg: 0.0658 (0.0692)  time: 0.6195  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [85]  [ 30/500]  eta: 0:04:55  lr: 0.000000  loss: 6.2677 (6.2845)  loss_classifier: 5.8590 (5.8443)  loss_box_reg: 0.1978 (0.2171)  loss_objectness: 0.1438 (0.1544)  loss_rpn_box_reg: 0.0583 (0.0688)  time: 0.6258  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [85]  [ 40/500]  eta: 0:04:48  lr: 0.000000  loss: 6.3334 (6.2673)  loss_classifier: 5.9225 (5.8217)  loss_box_reg: 0.2172 (0.2250)  loss_objectness: 0.1438 (0.1536)  loss_rpn_box_reg: 0.0588 (0.0669)  time: 0.6210  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [85]  [ 50/500]  eta: 0:04:42  lr: 0.000000  loss: 6.1012 (6.2437)  loss_classifier: 5.6630 (5.7961)  loss_box_reg: 0.2359 (0.2285)  loss_objectness: 0.1456 (0.1533)  loss_rpn_box_reg: 0.0601 (0.0659)  time: 0.6237  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [85]  [ 60/500]  eta: 0:04:35  lr: 0.000000  loss: 6.2435 (6.2878)  loss_classifier: 5.8054 (5.8279)  loss_box_reg: 0.2438 (0.2331)  loss_objectness: 0.1560 (0.1573)  loss_rpn_box_reg: 0.0687 (0.0694)  time: 0.6241  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [85]  [ 70/500]  eta: 0:04:28  lr: 0.000000  loss: 6.1864 (6.2536)  loss_classifier: 5.7867 (5.7971)  loss_box_reg: 0.2345 (0.2326)  loss_objectness: 0.1372 (0.1557)  loss_rpn_box_reg: 0.0700 (0.0683)  time: 0.6200  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [85]  [ 80/500]  eta: 0:04:22  lr: 0.000000  loss: 6.0449 (6.2208)  loss_classifier: 5.5632 (5.7626)  loss_box_reg: 0.2313 (0.2341)  loss_objectness: 0.1404 (0.1547)  loss_rpn_box_reg: 0.0700 (0.0694)  time: 0.6234  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [85]  [ 90/500]  eta: 0:04:15  lr: 0.000000  loss: 6.1831 (6.2418)  loss_classifier: 5.7007 (5.7840)  loss_box_reg: 0.2313 (0.2322)  loss_objectness: 0.1451 (0.1549)  loss_rpn_box_reg: 0.0736 (0.0707)  time: 0.6204  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [85]  [100/500]  eta: 0:04:09  lr: 0.000000  loss: 6.2225 (6.2391)  loss_classifier: 5.8520 (5.7830)  loss_box_reg: 0.2058 (0.2302)  loss_objectness: 0.1508 (0.1546)  loss_rpn_box_reg: 0.0776 (0.0714)  time: 0.6186  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [85]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 6.2979 (6.2671)  loss_classifier: 5.8538 (5.8111)  loss_box_reg: 0.2058 (0.2302)  loss_objectness: 0.1533 (0.1546)  loss_rpn_box_reg: 0.0703 (0.0712)  time: 0.6190  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [85]  [120/500]  eta: 0:03:56  lr: 0.000000  loss: 6.2589 (6.2375)  loss_classifier: 5.7908 (5.7805)  loss_box_reg: 0.2275 (0.2310)  loss_objectness: 0.1569 (0.1540)  loss_rpn_box_reg: 0.0666 (0.0720)  time: 0.6130  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [85]  [130/500]  eta: 0:03:50  lr: 0.000000  loss: 6.0786 (6.2421)  loss_classifier: 5.6615 (5.7848)  loss_box_reg: 0.2235 (0.2309)  loss_objectness: 0.1562 (0.1540)  loss_rpn_box_reg: 0.0656 (0.0724)  time: 0.6225  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [85]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 6.0902 (6.2371)  loss_classifier: 5.7187 (5.7781)  loss_box_reg: 0.2334 (0.2324)  loss_objectness: 0.1553 (0.1539)  loss_rpn_box_reg: 0.0611 (0.0728)  time: 0.6367  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [85]  [150/500]  eta: 0:03:37  lr: 0.000000  loss: 6.2599 (6.2448)  loss_classifier: 5.7937 (5.7812)  loss_box_reg: 0.2394 (0.2341)  loss_objectness: 0.1577 (0.1550)  loss_rpn_box_reg: 0.0844 (0.0746)  time: 0.6145  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [85]  [160/500]  eta: 0:03:31  lr: 0.000000  loss: 6.3807 (6.2451)  loss_classifier: 5.8709 (5.7803)  loss_box_reg: 0.2394 (0.2335)  loss_objectness: 0.1617 (0.1555)  loss_rpn_box_reg: 0.0889 (0.0758)  time: 0.5995  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [85]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 6.2736 (6.2496)  loss_classifier: 5.8948 (5.7863)  loss_box_reg: 0.2088 (0.2327)  loss_objectness: 0.1554 (0.1554)  loss_rpn_box_reg: 0.0807 (0.0753)  time: 0.6175  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [85]  [180/500]  eta: 0:03:18  lr: 0.000000  loss: 6.2736 (6.2539)  loss_classifier: 5.8688 (5.7915)  loss_box_reg: 0.2004 (0.2331)  loss_objectness: 0.1449 (0.1549)  loss_rpn_box_reg: 0.0512 (0.0744)  time: 0.6251  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [85]  [190/500]  eta: 0:03:12  lr: 0.000000  loss: 6.3586 (6.2577)  loss_classifier: 5.8688 (5.7934)  loss_box_reg: 0.2216 (0.2348)  loss_objectness: 0.1472 (0.1553)  loss_rpn_box_reg: 0.0586 (0.0742)  time: 0.6177  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [85]  [200/500]  eta: 0:03:06  lr: 0.000000  loss: 6.2707 (6.2546)  loss_classifier: 5.7675 (5.7884)  loss_box_reg: 0.2559 (0.2345)  loss_objectness: 0.1609 (0.1563)  loss_rpn_box_reg: 0.0766 (0.0754)  time: 0.6154  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [85]  [210/500]  eta: 0:02:59  lr: 0.000000  loss: 6.2202 (6.2553)  loss_classifier: 5.6828 (5.7882)  loss_box_reg: 0.2559 (0.2354)  loss_objectness: 0.1594 (0.1565)  loss_rpn_box_reg: 0.0760 (0.0752)  time: 0.6112  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [85]  [220/500]  eta: 0:02:53  lr: 0.000000  loss: 6.1694 (6.2478)  loss_classifier: 5.6828 (5.7801)  loss_box_reg: 0.2566 (0.2359)  loss_objectness: 0.1481 (0.1564)  loss_rpn_box_reg: 0.0683 (0.0754)  time: 0.6150  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [85]  [230/500]  eta: 0:02:47  lr: 0.000000  loss: 6.1683 (6.2467)  loss_classifier: 5.6915 (5.7805)  loss_box_reg: 0.2215 (0.2352)  loss_objectness: 0.1429 (0.1558)  loss_rpn_box_reg: 0.0685 (0.0752)  time: 0.6320  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [85]  [240/500]  eta: 0:02:41  lr: 0.000000  loss: 6.1683 (6.2454)  loss_classifier: 5.7142 (5.7790)  loss_box_reg: 0.2308 (0.2359)  loss_objectness: 0.1354 (0.1553)  loss_rpn_box_reg: 0.0547 (0.0752)  time: 0.6301  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [85]  [250/500]  eta: 0:02:35  lr: 0.000000  loss: 6.1909 (6.2417)  loss_classifier: 5.5843 (5.7722)  loss_box_reg: 0.2727 (0.2380)  loss_objectness: 0.1660 (0.1557)  loss_rpn_box_reg: 0.0731 (0.0758)  time: 0.6238  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [85]  [260/500]  eta: 0:02:28  lr: 0.000000  loss: 6.2998 (6.2451)  loss_classifier: 5.7906 (5.7746)  loss_box_reg: 0.2835 (0.2387)  loss_objectness: 0.1675 (0.1560)  loss_rpn_box_reg: 0.0778 (0.0758)  time: 0.6153  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [85]  [270/500]  eta: 0:02:22  lr: 0.000000  loss: 6.1312 (6.2360)  loss_classifier: 5.7068 (5.7645)  loss_box_reg: 0.2655 (0.2398)  loss_objectness: 0.1599 (0.1560)  loss_rpn_box_reg: 0.0692 (0.0757)  time: 0.6197  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [85]  [280/500]  eta: 0:02:16  lr: 0.000000  loss: 5.9810 (6.2354)  loss_classifier: 5.5527 (5.7639)  loss_box_reg: 0.2492 (0.2401)  loss_objectness: 0.1547 (0.1556)  loss_rpn_box_reg: 0.0688 (0.0757)  time: 0.6316  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [85]  [290/500]  eta: 0:02:10  lr: 0.000000  loss: 5.9639 (6.2304)  loss_classifier: 5.5425 (5.7581)  loss_box_reg: 0.2492 (0.2408)  loss_objectness: 0.1500 (0.1555)  loss_rpn_box_reg: 0.0689 (0.0760)  time: 0.6297  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [85]  [300/500]  eta: 0:02:04  lr: 0.000000  loss: 6.0564 (6.2300)  loss_classifier: 5.5425 (5.7577)  loss_box_reg: 0.2508 (0.2407)  loss_objectness: 0.1582 (0.1555)  loss_rpn_box_reg: 0.0737 (0.0761)  time: 0.6358  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [85]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.3851 (6.2322)  loss_classifier: 5.8087 (5.7605)  loss_box_reg: 0.2238 (0.2402)  loss_objectness: 0.1589 (0.1555)  loss_rpn_box_reg: 0.0737 (0.0760)  time: 0.6368  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [85]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2393 (6.2351)  loss_classifier: 5.7384 (5.7642)  loss_box_reg: 0.1988 (0.2394)  loss_objectness: 0.1544 (0.1554)  loss_rpn_box_reg: 0.0702 (0.0761)  time: 0.6349  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [85]  [330/500]  eta: 0:01:45  lr: 0.000000  loss: 6.1173 (6.2331)  loss_classifier: 5.6548 (5.7629)  loss_box_reg: 0.2058 (0.2392)  loss_objectness: 0.1321 (0.1546)  loss_rpn_box_reg: 0.0880 (0.0764)  time: 0.6338  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [85]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.0344 (6.2255)  loss_classifier: 5.6317 (5.7563)  loss_box_reg: 0.2323 (0.2390)  loss_objectness: 0.1174 (0.1541)  loss_rpn_box_reg: 0.0732 (0.0761)  time: 0.6147  data: 0.1316  max mem: 10734\n",
      "Training Epoch: [85]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.1231 (6.2278)  loss_classifier: 5.6356 (5.7593)  loss_box_reg: 0.1917 (0.2382)  loss_objectness: 0.1480 (0.1543)  loss_rpn_box_reg: 0.0673 (0.0760)  time: 0.6144  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [85]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1231 (6.2293)  loss_classifier: 5.7351 (5.7604)  loss_box_reg: 0.2075 (0.2386)  loss_objectness: 0.1567 (0.1545)  loss_rpn_box_reg: 0.0707 (0.0759)  time: 0.6260  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [85]  [370/500]  eta: 0:01:20  lr: 0.000000  loss: 6.0727 (6.2263)  loss_classifier: 5.5795 (5.7573)  loss_box_reg: 0.2706 (0.2393)  loss_objectness: 0.1467 (0.1543)  loss_rpn_box_reg: 0.0605 (0.0754)  time: 0.6236  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [85]  [380/500]  eta: 0:01:14  lr: 0.000000  loss: 6.2519 (6.2271)  loss_classifier: 5.7837 (5.7599)  loss_box_reg: 0.2487 (0.2385)  loss_objectness: 0.1328 (0.1533)  loss_rpn_box_reg: 0.0555 (0.0754)  time: 0.6295  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [85]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.1575 (6.2245)  loss_classifier: 5.6458 (5.7572)  loss_box_reg: 0.2188 (0.2394)  loss_objectness: 0.1307 (0.1529)  loss_rpn_box_reg: 0.0665 (0.0751)  time: 0.6288  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [85]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.0976 (6.2207)  loss_classifier: 5.5882 (5.7543)  loss_box_reg: 0.2433 (0.2391)  loss_objectness: 0.1307 (0.1525)  loss_rpn_box_reg: 0.0598 (0.0748)  time: 0.6378  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [85]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1637 (6.2223)  loss_classifier: 5.6165 (5.7545)  loss_box_reg: 0.2420 (0.2396)  loss_objectness: 0.1509 (0.1528)  loss_rpn_box_reg: 0.0643 (0.0754)  time: 0.6393  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [85]  [420/500]  eta: 0:00:49  lr: 0.000000  loss: 6.2870 (6.2262)  loss_classifier: 5.7770 (5.7593)  loss_box_reg: 0.2376 (0.2390)  loss_objectness: 0.1637 (0.1530)  loss_rpn_box_reg: 0.0607 (0.0749)  time: 0.6235  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [85]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.2870 (6.2234)  loss_classifier: 5.7913 (5.7568)  loss_box_reg: 0.2368 (0.2395)  loss_objectness: 0.1319 (0.1524)  loss_rpn_box_reg: 0.0590 (0.0747)  time: 0.6163  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [85]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.2537 (6.2237)  loss_classifier: 5.8631 (5.7572)  loss_box_reg: 0.2447 (0.2395)  loss_objectness: 0.1238 (0.1521)  loss_rpn_box_reg: 0.0739 (0.0749)  time: 0.6231  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [85]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 5.9505 (6.2195)  loss_classifier: 5.5491 (5.7532)  loss_box_reg: 0.2462 (0.2392)  loss_objectness: 0.1331 (0.1522)  loss_rpn_box_reg: 0.0738 (0.0750)  time: 0.6206  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [85]  [460/500]  eta: 0:00:24  lr: 0.000000  loss: 5.8890 (6.2156)  loss_classifier: 5.4706 (5.7489)  loss_box_reg: 0.2164 (0.2390)  loss_objectness: 0.1407 (0.1522)  loss_rpn_box_reg: 0.0654 (0.0755)  time: 0.6048  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [85]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1840 (6.2201)  loss_classifier: 5.6771 (5.7529)  loss_box_reg: 0.2341 (0.2390)  loss_objectness: 0.1450 (0.1525)  loss_rpn_box_reg: 0.0790 (0.0757)  time: 0.6103  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [85]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.1840 (6.2153)  loss_classifier: 5.7769 (5.7471)  loss_box_reg: 0.2458 (0.2397)  loss_objectness: 0.1590 (0.1525)  loss_rpn_box_reg: 0.0796 (0.0760)  time: 0.6127  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [85]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0085 (6.2156)  loss_classifier: 5.6188 (5.7482)  loss_box_reg: 0.2278 (0.2393)  loss_objectness: 0.1451 (0.1524)  loss_rpn_box_reg: 0.0652 (0.0757)  time: 0.6084  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [85]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2399 (6.2165)  loss_classifier: 5.7741 (5.7491)  loss_box_reg: 0.2158 (0.2394)  loss_objectness: 0.1448 (0.1523)  loss_rpn_box_reg: 0.0557 (0.0757)  time: 0.6122  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [85] Total time: 0:05:11 (0.6225 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:02:15  model_time: 0.8072 (0.8072)  evaluator_time: 0.0350 (0.0350)  time: 1.0852  data: 0.2331  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4421 (0.4523)  evaluator_time: 0.0340 (0.0350)  time: 0.6337  data: 0.1482  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4711 (0.4542)  evaluator_time: 0.0360 (0.0358)  time: 0.6568  data: 0.1482  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6430 s / it)\n",
      "Averaged stats: model_time: 0.4711 (0.4542)  evaluator_time: 0.0360 (0.0358)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [85]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1728 (6.1728)  loss_classifier: 5.6305 (5.6305)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1162 (0.1162)  loss_rpn_box_reg: 0.1316 (0.1316)  time: 0.6441  data: 0.1450  max mem: 10734\n",
      "Testing Epoch: [85]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0115 (6.1310)  loss_classifier: 5.4209 (5.6223)  loss_box_reg: 0.2609 (0.2882)  loss_objectness: 0.1295 (0.1310)  loss_rpn_box_reg: 0.0702 (0.0896)  time: 0.5841  data: 0.1445  max mem: 10734\n",
      "Testing Epoch: [85]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1554 (6.1627)  loss_classifier: 5.6999 (5.6580)  loss_box_reg: 0.2500 (0.2838)  loss_objectness: 0.1221 (0.1312)  loss_rpn_box_reg: 0.0745 (0.0897)  time: 0.6004  data: 0.1463  max mem: 10734\n",
      "Testing Epoch: [85] Total time: 0:01:14 (0.5952 s / it)\n",
      "Training Epoch: [86]  [  0/500]  eta: 0:06:25  lr: 0.000000  loss: 6.6021 (6.6021)  loss_classifier: 6.2051 (6.2051)  loss_box_reg: 0.1777 (0.1777)  loss_objectness: 0.1381 (0.1381)  loss_rpn_box_reg: 0.0812 (0.0812)  time: 0.7712  data: 0.1390  max mem: 10734\n",
      "Training Epoch: [86]  [ 10/500]  eta: 0:05:12  lr: 0.000000  loss: 6.7374 (6.7301)  loss_classifier: 6.3082 (6.2719)  loss_box_reg: 0.2119 (0.2136)  loss_objectness: 0.1684 (0.1593)  loss_rpn_box_reg: 0.0857 (0.0853)  time: 0.6380  data: 0.1368  max mem: 10734\n",
      "Training Epoch: [86]  [ 20/500]  eta: 0:05:08  lr: 0.000000  loss: 6.4919 (6.6107)  loss_classifier: 6.0716 (6.1708)  loss_box_reg: 0.2166 (0.2241)  loss_objectness: 0.1353 (0.1425)  loss_rpn_box_reg: 0.0627 (0.0733)  time: 0.6368  data: 0.1380  max mem: 10734\n",
      "Training Epoch: [86]  [ 30/500]  eta: 0:05:00  lr: 0.000000  loss: 6.2131 (6.4515)  loss_classifier: 5.7851 (6.0021)  loss_box_reg: 0.2170 (0.2262)  loss_objectness: 0.1314 (0.1460)  loss_rpn_box_reg: 0.0594 (0.0772)  time: 0.6397  data: 0.1379  max mem: 10734\n",
      "Training Epoch: [86]  [ 40/500]  eta: 0:04:53  lr: 0.000000  loss: 6.1733 (6.3942)  loss_classifier: 5.7165 (5.9377)  loss_box_reg: 0.2170 (0.2293)  loss_objectness: 0.1516 (0.1501)  loss_rpn_box_reg: 0.0648 (0.0770)  time: 0.6337  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [86]  [ 50/500]  eta: 0:04:44  lr: 0.000000  loss: 6.4149 (6.4280)  loss_classifier: 5.8737 (5.9628)  loss_box_reg: 0.2297 (0.2320)  loss_objectness: 0.1587 (0.1517)  loss_rpn_box_reg: 0.0825 (0.0815)  time: 0.6217  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [86]  [ 60/500]  eta: 0:04:38  lr: 0.000000  loss: 6.3179 (6.3843)  loss_classifier: 5.8400 (5.9188)  loss_box_reg: 0.2466 (0.2352)  loss_objectness: 0.1570 (0.1504)  loss_rpn_box_reg: 0.0873 (0.0798)  time: 0.6191  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [86]  [ 70/500]  eta: 0:04:31  lr: 0.000000  loss: 6.0877 (6.3306)  loss_classifier: 5.5956 (5.8705)  loss_box_reg: 0.2207 (0.2314)  loss_objectness: 0.1485 (0.1505)  loss_rpn_box_reg: 0.0649 (0.0783)  time: 0.6312  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [86]  [ 80/500]  eta: 0:04:25  lr: 0.000000  loss: 6.0431 (6.3033)  loss_classifier: 5.5956 (5.8439)  loss_box_reg: 0.2063 (0.2328)  loss_objectness: 0.1485 (0.1508)  loss_rpn_box_reg: 0.0635 (0.0758)  time: 0.6321  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [86]  [ 90/500]  eta: 0:04:18  lr: 0.000000  loss: 6.0428 (6.2877)  loss_classifier: 5.5785 (5.8268)  loss_box_reg: 0.2338 (0.2332)  loss_objectness: 0.1596 (0.1529)  loss_rpn_box_reg: 0.0633 (0.0748)  time: 0.6275  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [86]  [100/500]  eta: 0:04:12  lr: 0.000000  loss: 6.2293 (6.2966)  loss_classifier: 5.7464 (5.8387)  loss_box_reg: 0.2203 (0.2312)  loss_objectness: 0.1467 (0.1534)  loss_rpn_box_reg: 0.0628 (0.0733)  time: 0.6301  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [86]  [110/500]  eta: 0:04:05  lr: 0.000000  loss: 6.2293 (6.2800)  loss_classifier: 5.7705 (5.8239)  loss_box_reg: 0.1978 (0.2298)  loss_objectness: 0.1375 (0.1520)  loss_rpn_box_reg: 0.0619 (0.0743)  time: 0.6271  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [86]  [120/500]  eta: 0:03:59  lr: 0.000000  loss: 6.0559 (6.2664)  loss_classifier: 5.5368 (5.8066)  loss_box_reg: 0.2372 (0.2334)  loss_objectness: 0.1416 (0.1521)  loss_rpn_box_reg: 0.0667 (0.0743)  time: 0.6190  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [86]  [130/500]  eta: 0:03:53  lr: 0.000000  loss: 6.2532 (6.2817)  loss_classifier: 5.9000 (5.8245)  loss_box_reg: 0.2207 (0.2312)  loss_objectness: 0.1452 (0.1521)  loss_rpn_box_reg: 0.0584 (0.0739)  time: 0.6308  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [86]  [140/500]  eta: 0:03:46  lr: 0.000000  loss: 6.2119 (6.2616)  loss_classifier: 5.7133 (5.7987)  loss_box_reg: 0.2207 (0.2343)  loss_objectness: 0.1525 (0.1531)  loss_rpn_box_reg: 0.0751 (0.0755)  time: 0.6241  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [86]  [150/500]  eta: 0:03:39  lr: 0.000000  loss: 6.0953 (6.2736)  loss_classifier: 5.6691 (5.8143)  loss_box_reg: 0.2283 (0.2320)  loss_objectness: 0.1521 (0.1524)  loss_rpn_box_reg: 0.0731 (0.0749)  time: 0.6088  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [86]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.2243 (6.2724)  loss_classifier: 5.6805 (5.8118)  loss_box_reg: 0.2162 (0.2331)  loss_objectness: 0.1418 (0.1520)  loss_rpn_box_reg: 0.0745 (0.0754)  time: 0.6189  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [86]  [170/500]  eta: 0:03:26  lr: 0.000000  loss: 6.1571 (6.2639)  loss_classifier: 5.6697 (5.8030)  loss_box_reg: 0.2094 (0.2332)  loss_objectness: 0.1446 (0.1523)  loss_rpn_box_reg: 0.0745 (0.0754)  time: 0.6205  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [86]  [180/500]  eta: 0:03:20  lr: 0.000000  loss: 6.1320 (6.2619)  loss_classifier: 5.6825 (5.8009)  loss_box_reg: 0.2023 (0.2330)  loss_objectness: 0.1446 (0.1522)  loss_rpn_box_reg: 0.0676 (0.0758)  time: 0.6045  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [86]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.0132 (6.2428)  loss_classifier: 5.6216 (5.7788)  loss_box_reg: 0.2155 (0.2343)  loss_objectness: 0.1587 (0.1528)  loss_rpn_box_reg: 0.0832 (0.0769)  time: 0.6065  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [86]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.0755 (6.2463)  loss_classifier: 5.6689 (5.7821)  loss_box_reg: 0.2374 (0.2351)  loss_objectness: 0.1539 (0.1520)  loss_rpn_box_reg: 0.0872 (0.0771)  time: 0.6201  data: 0.1328  max mem: 10734\n",
      "Training Epoch: [86]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.0428 (6.2328)  loss_classifier: 5.6882 (5.7708)  loss_box_reg: 0.2336 (0.2343)  loss_objectness: 0.1252 (0.1514)  loss_rpn_box_reg: 0.0636 (0.0764)  time: 0.6265  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [86]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.0497 (6.2384)  loss_classifier: 5.6543 (5.7762)  loss_box_reg: 0.2451 (0.2350)  loss_objectness: 0.1419 (0.1513)  loss_rpn_box_reg: 0.0558 (0.0760)  time: 0.6408  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [86]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.1947 (6.2397)  loss_classifier: 5.7282 (5.7786)  loss_box_reg: 0.2499 (0.2348)  loss_objectness: 0.1378 (0.1506)  loss_rpn_box_reg: 0.0629 (0.0757)  time: 0.6361  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [86]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.1947 (6.2396)  loss_classifier: 5.6791 (5.7781)  loss_box_reg: 0.2143 (0.2348)  loss_objectness: 0.1450 (0.1513)  loss_rpn_box_reg: 0.0644 (0.0755)  time: 0.6310  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [86]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.0269 (6.2376)  loss_classifier: 5.5867 (5.7750)  loss_box_reg: 0.2229 (0.2350)  loss_objectness: 0.1514 (0.1516)  loss_rpn_box_reg: 0.0735 (0.0760)  time: 0.6286  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [86]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 5.9784 (6.2276)  loss_classifier: 5.5354 (5.7638)  loss_box_reg: 0.2346 (0.2356)  loss_objectness: 0.1641 (0.1523)  loss_rpn_box_reg: 0.0722 (0.0760)  time: 0.6166  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [86]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.0282 (6.2244)  loss_classifier: 5.5653 (5.7620)  loss_box_reg: 0.2346 (0.2348)  loss_objectness: 0.1656 (0.1524)  loss_rpn_box_reg: 0.0606 (0.0752)  time: 0.6211  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [86]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.1725 (6.2253)  loss_classifier: 5.6964 (5.7624)  loss_box_reg: 0.2377 (0.2359)  loss_objectness: 0.1457 (0.1523)  loss_rpn_box_reg: 0.0556 (0.0748)  time: 0.6330  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [86]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.2911 (6.2285)  loss_classifier: 5.8503 (5.7638)  loss_box_reg: 0.2614 (0.2363)  loss_objectness: 0.1406 (0.1527)  loss_rpn_box_reg: 0.0622 (0.0756)  time: 0.6300  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [86]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.2866 (6.2285)  loss_classifier: 5.7710 (5.7646)  loss_box_reg: 0.2157 (0.2358)  loss_objectness: 0.1469 (0.1525)  loss_rpn_box_reg: 0.0644 (0.0755)  time: 0.6215  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [86]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.1441 (6.2287)  loss_classifier: 5.7710 (5.7654)  loss_box_reg: 0.2277 (0.2356)  loss_objectness: 0.1362 (0.1520)  loss_rpn_box_reg: 0.0703 (0.0756)  time: 0.6253  data: 0.1336  max mem: 10734\n",
      "Training Epoch: [86]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.1287 (6.2249)  loss_classifier: 5.6890 (5.7614)  loss_box_reg: 0.2277 (0.2352)  loss_objectness: 0.1446 (0.1523)  loss_rpn_box_reg: 0.0754 (0.0760)  time: 0.6224  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [86]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.0632 (6.2250)  loss_classifier: 5.5931 (5.7612)  loss_box_reg: 0.2206 (0.2353)  loss_objectness: 0.1554 (0.1526)  loss_rpn_box_reg: 0.0729 (0.0759)  time: 0.6217  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [86]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.2209 (6.2302)  loss_classifier: 5.7743 (5.7662)  loss_box_reg: 0.2240 (0.2353)  loss_objectness: 0.1622 (0.1530)  loss_rpn_box_reg: 0.0631 (0.0757)  time: 0.6364  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [86]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.2209 (6.2284)  loss_classifier: 5.7474 (5.7634)  loss_box_reg: 0.2539 (0.2355)  loss_objectness: 0.1712 (0.1534)  loss_rpn_box_reg: 0.0763 (0.0761)  time: 0.6445  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [86]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1509 (6.2277)  loss_classifier: 5.7227 (5.7629)  loss_box_reg: 0.2424 (0.2351)  loss_objectness: 0.1652 (0.1534)  loss_rpn_box_reg: 0.0797 (0.0764)  time: 0.6332  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [86]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.1439 (6.2272)  loss_classifier: 5.7118 (5.7613)  loss_box_reg: 0.2407 (0.2360)  loss_objectness: 0.1578 (0.1537)  loss_rpn_box_reg: 0.0637 (0.0763)  time: 0.6140  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [86]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.2855 (6.2275)  loss_classifier: 5.8312 (5.7614)  loss_box_reg: 0.2574 (0.2360)  loss_objectness: 0.1599 (0.1537)  loss_rpn_box_reg: 0.0637 (0.0763)  time: 0.6155  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [86]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 6.1693 (6.2214)  loss_classifier: 5.6080 (5.7535)  loss_box_reg: 0.2593 (0.2372)  loss_objectness: 0.1599 (0.1539)  loss_rpn_box_reg: 0.0764 (0.0767)  time: 0.6802  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [86]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.0991 (6.2207)  loss_classifier: 5.5248 (5.7524)  loss_box_reg: 0.2402 (0.2378)  loss_objectness: 0.1577 (0.1540)  loss_rpn_box_reg: 0.0803 (0.0766)  time: 0.6757  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [86]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 5.9775 (6.2130)  loss_classifier: 5.4453 (5.7441)  loss_box_reg: 0.2316 (0.2382)  loss_objectness: 0.1503 (0.1541)  loss_rpn_box_reg: 0.0733 (0.0764)  time: 0.6211  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [86]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 5.9060 (6.2137)  loss_classifier: 5.4453 (5.7451)  loss_box_reg: 0.2316 (0.2385)  loss_objectness: 0.1450 (0.1540)  loss_rpn_box_reg: 0.0667 (0.0761)  time: 0.6275  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [86]  [430/500]  eta: 0:00:44  lr: 0.000000  loss: 6.1059 (6.2145)  loss_classifier: 5.6489 (5.7464)  loss_box_reg: 0.2156 (0.2386)  loss_objectness: 0.1413 (0.1537)  loss_rpn_box_reg: 0.0567 (0.0758)  time: 0.6443  data: 0.1367  max mem: 10734\n",
      "Training Epoch: [86]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.1930 (6.2121)  loss_classifier: 5.6226 (5.7440)  loss_box_reg: 0.2399 (0.2387)  loss_objectness: 0.1319 (0.1533)  loss_rpn_box_reg: 0.0600 (0.0760)  time: 0.6340  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [86]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1405 (6.2100)  loss_classifier: 5.5680 (5.7419)  loss_box_reg: 0.2072 (0.2385)  loss_objectness: 0.1330 (0.1535)  loss_rpn_box_reg: 0.0917 (0.0761)  time: 0.6186  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [86]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.1405 (6.2124)  loss_classifier: 5.6878 (5.7445)  loss_box_reg: 0.1990 (0.2386)  loss_objectness: 0.1561 (0.1535)  loss_rpn_box_reg: 0.0665 (0.0759)  time: 0.6301  data: 0.1388  max mem: 10734\n",
      "Training Epoch: [86]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.1023 (6.2091)  loss_classifier: 5.6457 (5.7410)  loss_box_reg: 0.2264 (0.2386)  loss_objectness: 0.1380 (0.1534)  loss_rpn_box_reg: 0.0630 (0.0761)  time: 0.6270  data: 0.1380  max mem: 10734\n",
      "Training Epoch: [86]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.0553 (6.2089)  loss_classifier: 5.6320 (5.7407)  loss_box_reg: 0.2291 (0.2387)  loss_objectness: 0.1322 (0.1535)  loss_rpn_box_reg: 0.0630 (0.0760)  time: 0.6317  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [86]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.1106 (6.2089)  loss_classifier: 5.6623 (5.7410)  loss_box_reg: 0.2290 (0.2384)  loss_objectness: 0.1310 (0.1533)  loss_rpn_box_reg: 0.0791 (0.0762)  time: 0.6370  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [86]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.1804 (6.2088)  loss_classifier: 5.6625 (5.7409)  loss_box_reg: 0.2290 (0.2384)  loss_objectness: 0.1495 (0.1535)  loss_rpn_box_reg: 0.0786 (0.0760)  time: 0.6219  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [86] Total time: 0:05:14 (0.6289 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:59  model_time: 0.6792 (0.6792)  evaluator_time: 0.0350 (0.0350)  time: 0.9547  data: 0.2295  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4361 (0.4527)  evaluator_time: 0.0340 (0.0380)  time: 0.6365  data: 0.1536  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4691 (0.4540)  evaluator_time: 0.0360 (0.0382)  time: 0.6603  data: 0.1546  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6422 s / it)\n",
      "Averaged stats: model_time: 0.4691 (0.4540)  evaluator_time: 0.0360 (0.0382)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [86]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1969 (6.1969)  loss_classifier: 5.6536 (5.6536)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1178 (0.1178)  loss_rpn_box_reg: 0.1311 (0.1311)  time: 0.6451  data: 0.1470  max mem: 10734\n",
      "Testing Epoch: [86]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0142 (6.1216)  loss_classifier: 5.4277 (5.6093)  loss_box_reg: 0.2609 (0.2905)  loss_objectness: 0.1304 (0.1317)  loss_rpn_box_reg: 0.0718 (0.0902)  time: 0.5867  data: 0.1472  max mem: 10734\n",
      "Testing Epoch: [86]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1596 (6.1558)  loss_classifier: 5.6755 (5.6480)  loss_box_reg: 0.2500 (0.2857)  loss_objectness: 0.1201 (0.1320)  loss_rpn_box_reg: 0.0745 (0.0902)  time: 0.5986  data: 0.1463  max mem: 10734\n",
      "Testing Epoch: [86] Total time: 0:01:14 (0.5937 s / it)\n",
      "Training Epoch: [87]  [  0/500]  eta: 0:07:11  lr: 0.000000  loss: 5.9164 (5.9164)  loss_classifier: 5.4261 (5.4261)  loss_box_reg: 0.2775 (0.2775)  loss_objectness: 0.1570 (0.1570)  loss_rpn_box_reg: 0.0557 (0.0557)  time: 0.8622  data: 0.1520  max mem: 10734\n",
      "Training Epoch: [87]  [ 10/500]  eta: 0:05:07  lr: 0.000000  loss: 6.0308 (5.9821)  loss_classifier: 5.5327 (5.4641)  loss_box_reg: 0.2416 (0.2326)  loss_objectness: 0.1812 (0.1896)  loss_rpn_box_reg: 0.0920 (0.0957)  time: 0.6285  data: 0.1378  max mem: 10734\n",
      "Training Epoch: [87]  [ 20/500]  eta: 0:04:56  lr: 0.000000  loss: 6.0414 (6.0766)  loss_classifier: 5.5327 (5.5968)  loss_box_reg: 0.2294 (0.2355)  loss_objectness: 0.1539 (0.1658)  loss_rpn_box_reg: 0.0786 (0.0785)  time: 0.6056  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [87]  [ 30/500]  eta: 0:04:52  lr: 0.000000  loss: 6.1194 (6.1356)  loss_classifier: 5.6299 (5.6509)  loss_box_reg: 0.2206 (0.2419)  loss_objectness: 0.1419 (0.1662)  loss_rpn_box_reg: 0.0568 (0.0766)  time: 0.6193  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [87]  [ 40/500]  eta: 0:04:46  lr: 0.000000  loss: 6.1323 (6.1647)  loss_classifier: 5.6299 (5.6767)  loss_box_reg: 0.2380 (0.2414)  loss_objectness: 0.1529 (0.1660)  loss_rpn_box_reg: 0.0793 (0.0806)  time: 0.6259  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [87]  [ 50/500]  eta: 0:04:40  lr: 0.000000  loss: 6.2677 (6.2122)  loss_classifier: 5.7985 (5.7271)  loss_box_reg: 0.2268 (0.2410)  loss_objectness: 0.1529 (0.1644)  loss_rpn_box_reg: 0.0719 (0.0797)  time: 0.6244  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [87]  [ 60/500]  eta: 0:04:35  lr: 0.000000  loss: 6.3303 (6.2231)  loss_classifier: 5.8577 (5.7374)  loss_box_reg: 0.2225 (0.2437)  loss_objectness: 0.1519 (0.1643)  loss_rpn_box_reg: 0.0653 (0.0777)  time: 0.6368  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [87]  [ 70/500]  eta: 0:04:28  lr: 0.000000  loss: 6.2344 (6.2266)  loss_classifier: 5.8264 (5.7555)  loss_box_reg: 0.1884 (0.2341)  loss_objectness: 0.1547 (0.1623)  loss_rpn_box_reg: 0.0497 (0.0747)  time: 0.6282  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [87]  [ 80/500]  eta: 0:04:21  lr: 0.000000  loss: 6.1118 (6.1880)  loss_classifier: 5.5721 (5.7175)  loss_box_reg: 0.1889 (0.2333)  loss_objectness: 0.1547 (0.1614)  loss_rpn_box_reg: 0.0558 (0.0757)  time: 0.6060  data: 0.1308  max mem: 10734\n",
      "Training Epoch: [87]  [ 90/500]  eta: 0:04:15  lr: 0.000000  loss: 6.0051 (6.1876)  loss_classifier: 5.5592 (5.7175)  loss_box_reg: 0.2484 (0.2340)  loss_objectness: 0.1536 (0.1607)  loss_rpn_box_reg: 0.0722 (0.0755)  time: 0.6146  data: 0.1314  max mem: 10734\n",
      "Training Epoch: [87]  [100/500]  eta: 0:04:09  lr: 0.000000  loss: 6.2404 (6.2004)  loss_classifier: 5.7373 (5.7270)  loss_box_reg: 0.2284 (0.2371)  loss_objectness: 0.1487 (0.1604)  loss_rpn_box_reg: 0.0673 (0.0759)  time: 0.6313  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [87]  [110/500]  eta: 0:04:03  lr: 0.000000  loss: 6.2404 (6.1860)  loss_classifier: 5.7421 (5.7176)  loss_box_reg: 0.2181 (0.2339)  loss_objectness: 0.1448 (0.1585)  loss_rpn_box_reg: 0.0714 (0.0760)  time: 0.6271  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [87]  [120/500]  eta: 0:03:56  lr: 0.000000  loss: 6.2736 (6.2078)  loss_classifier: 5.8321 (5.7412)  loss_box_reg: 0.1915 (0.2317)  loss_objectness: 0.1409 (0.1577)  loss_rpn_box_reg: 0.0799 (0.0772)  time: 0.6143  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [87]  [130/500]  eta: 0:03:49  lr: 0.000000  loss: 5.9567 (6.1769)  loss_classifier: 5.4528 (5.7081)  loss_box_reg: 0.2219 (0.2334)  loss_objectness: 0.1447 (0.1579)  loss_rpn_box_reg: 0.0915 (0.0775)  time: 0.6052  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [87]  [140/500]  eta: 0:03:43  lr: 0.000000  loss: 5.9567 (6.1778)  loss_classifier: 5.5056 (5.7091)  loss_box_reg: 0.2442 (0.2335)  loss_objectness: 0.1583 (0.1579)  loss_rpn_box_reg: 0.0718 (0.0773)  time: 0.6048  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [87]  [150/500]  eta: 0:03:36  lr: 0.000000  loss: 6.3539 (6.1876)  loss_classifier: 5.8325 (5.7198)  loss_box_reg: 0.2339 (0.2330)  loss_objectness: 0.1617 (0.1580)  loss_rpn_box_reg: 0.0633 (0.0769)  time: 0.6116  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [87]  [160/500]  eta: 0:03:31  lr: 0.000000  loss: 6.3539 (6.1888)  loss_classifier: 5.8521 (5.7208)  loss_box_reg: 0.2143 (0.2332)  loss_objectness: 0.1536 (0.1579)  loss_rpn_box_reg: 0.0633 (0.0770)  time: 0.6311  data: 0.1361  max mem: 10734\n",
      "Training Epoch: [87]  [170/500]  eta: 0:03:24  lr: 0.000000  loss: 6.0632 (6.1813)  loss_classifier: 5.6203 (5.7141)  loss_box_reg: 0.2212 (0.2341)  loss_objectness: 0.1315 (0.1566)  loss_rpn_box_reg: 0.0710 (0.0766)  time: 0.6327  data: 0.1335  max mem: 10734\n",
      "Training Epoch: [87]  [180/500]  eta: 0:03:18  lr: 0.000000  loss: 6.0333 (6.1760)  loss_classifier: 5.6211 (5.7109)  loss_box_reg: 0.2190 (0.2336)  loss_objectness: 0.1286 (0.1558)  loss_rpn_box_reg: 0.0550 (0.0757)  time: 0.6248  data: 0.1294  max mem: 10734\n",
      "Training Epoch: [87]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.1603 (6.1875)  loss_classifier: 5.6991 (5.7230)  loss_box_reg: 0.2279 (0.2334)  loss_objectness: 0.1369 (0.1554)  loss_rpn_box_reg: 0.0561 (0.0757)  time: 0.6370  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [87]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.3213 (6.1965)  loss_classifier: 5.8946 (5.7316)  loss_box_reg: 0.2566 (0.2341)  loss_objectness: 0.1406 (0.1553)  loss_rpn_box_reg: 0.0755 (0.0756)  time: 0.6414  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [87]  [210/500]  eta: 0:03:00  lr: 0.000000  loss: 6.2393 (6.1983)  loss_classifier: 5.7328 (5.7329)  loss_box_reg: 0.2367 (0.2341)  loss_objectness: 0.1421 (0.1552)  loss_rpn_box_reg: 0.0807 (0.0761)  time: 0.6306  data: 0.1313  max mem: 10734\n",
      "Training Epoch: [87]  [220/500]  eta: 0:02:54  lr: 0.000000  loss: 6.2174 (6.2004)  loss_classifier: 5.7328 (5.7364)  loss_box_reg: 0.2139 (0.2334)  loss_objectness: 0.1382 (0.1547)  loss_rpn_box_reg: 0.0769 (0.0759)  time: 0.6348  data: 0.1310  max mem: 10734\n",
      "Training Epoch: [87]  [230/500]  eta: 0:02:48  lr: 0.000000  loss: 6.1465 (6.2079)  loss_classifier: 5.7531 (5.7433)  loss_box_reg: 0.2139 (0.2342)  loss_objectness: 0.1410 (0.1548)  loss_rpn_box_reg: 0.0650 (0.0755)  time: 0.6411  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [87]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.1823 (6.2099)  loss_classifier: 5.8144 (5.7471)  loss_box_reg: 0.2286 (0.2340)  loss_objectness: 0.1329 (0.1537)  loss_rpn_box_reg: 0.0610 (0.0751)  time: 0.6245  data: 0.1353  max mem: 10734\n",
      "Training Epoch: [87]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.0388 (6.2027)  loss_classifier: 5.6831 (5.7399)  loss_box_reg: 0.2221 (0.2336)  loss_objectness: 0.1326 (0.1540)  loss_rpn_box_reg: 0.0638 (0.0753)  time: 0.6185  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [87]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 5.8690 (6.1961)  loss_classifier: 5.5196 (5.7311)  loss_box_reg: 0.2362 (0.2352)  loss_objectness: 0.1441 (0.1544)  loss_rpn_box_reg: 0.0757 (0.0754)  time: 0.6340  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [87]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 5.8546 (6.1961)  loss_classifier: 5.5196 (5.7281)  loss_box_reg: 0.2600 (0.2368)  loss_objectness: 0.1761 (0.1551)  loss_rpn_box_reg: 0.0778 (0.0761)  time: 0.6233  data: 0.1372  max mem: 10734\n",
      "Training Epoch: [87]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.2648 (6.2038)  loss_classifier: 5.6321 (5.7347)  loss_box_reg: 0.2649 (0.2377)  loss_objectness: 0.1661 (0.1551)  loss_rpn_box_reg: 0.0690 (0.0763)  time: 0.6225  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [87]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.3908 (6.2115)  loss_classifier: 5.9576 (5.7431)  loss_box_reg: 0.2223 (0.2371)  loss_objectness: 0.1529 (0.1549)  loss_rpn_box_reg: 0.0721 (0.0764)  time: 0.6382  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [87]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.2058 (6.2112)  loss_classifier: 5.7790 (5.7415)  loss_box_reg: 0.2061 (0.2372)  loss_objectness: 0.1535 (0.1552)  loss_rpn_box_reg: 0.0801 (0.0773)  time: 0.6309  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [87]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 6.1472 (6.2088)  loss_classifier: 5.6553 (5.7388)  loss_box_reg: 0.2572 (0.2381)  loss_objectness: 0.1409 (0.1548)  loss_rpn_box_reg: 0.0777 (0.0771)  time: 0.6284  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [87]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2284 (6.2103)  loss_classifier: 5.7043 (5.7389)  loss_box_reg: 0.2554 (0.2390)  loss_objectness: 0.1409 (0.1550)  loss_rpn_box_reg: 0.0744 (0.0775)  time: 0.6279  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [87]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.2691 (6.2106)  loss_classifier: 5.8674 (5.7414)  loss_box_reg: 0.2186 (0.2383)  loss_objectness: 0.1319 (0.1541)  loss_rpn_box_reg: 0.0607 (0.0768)  time: 0.6235  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [87]  [340/500]  eta: 0:01:39  lr: 0.000000  loss: 6.2360 (6.2089)  loss_classifier: 5.7881 (5.7398)  loss_box_reg: 0.2186 (0.2384)  loss_objectness: 0.1304 (0.1541)  loss_rpn_box_reg: 0.0649 (0.0765)  time: 0.6129  data: 0.1320  max mem: 10734\n",
      "Training Epoch: [87]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.2168 (6.2102)  loss_classifier: 5.7035 (5.7406)  loss_box_reg: 0.2345 (0.2384)  loss_objectness: 0.1564 (0.1548)  loss_rpn_box_reg: 0.0679 (0.0764)  time: 0.6191  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [87]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 5.8893 (6.2038)  loss_classifier: 5.4800 (5.7338)  loss_box_reg: 0.2447 (0.2391)  loss_objectness: 0.1512 (0.1543)  loss_rpn_box_reg: 0.0711 (0.0765)  time: 0.6322  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [87]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 5.9706 (6.2078)  loss_classifier: 5.4580 (5.7370)  loss_box_reg: 0.2455 (0.2395)  loss_objectness: 0.1422 (0.1546)  loss_rpn_box_reg: 0.0795 (0.0768)  time: 0.6324  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [87]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.0815 (6.2014)  loss_classifier: 5.6200 (5.7301)  loss_box_reg: 0.2536 (0.2403)  loss_objectness: 0.1491 (0.1543)  loss_rpn_box_reg: 0.0666 (0.0766)  time: 0.6336  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [87]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.0815 (6.2024)  loss_classifier: 5.6203 (5.7319)  loss_box_reg: 0.2557 (0.2402)  loss_objectness: 0.1388 (0.1541)  loss_rpn_box_reg: 0.0563 (0.0763)  time: 0.6356  data: 0.1326  max mem: 10734\n",
      "Training Epoch: [87]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2945 (6.2080)  loss_classifier: 5.8727 (5.7388)  loss_box_reg: 0.1961 (0.2391)  loss_objectness: 0.1480 (0.1541)  loss_rpn_box_reg: 0.0549 (0.0759)  time: 0.6383  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [87]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.3191 (6.2061)  loss_classifier: 5.8389 (5.7382)  loss_box_reg: 0.1947 (0.2384)  loss_objectness: 0.1348 (0.1535)  loss_rpn_box_reg: 0.0565 (0.0760)  time: 0.6366  data: 0.1322  max mem: 10734\n",
      "Training Epoch: [87]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 5.9777 (6.2039)  loss_classifier: 5.5380 (5.7375)  loss_box_reg: 0.1873 (0.2372)  loss_objectness: 0.1348 (0.1535)  loss_rpn_box_reg: 0.0508 (0.0757)  time: 0.6188  data: 0.1303  max mem: 10734\n",
      "Training Epoch: [87]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.0281 (6.2015)  loss_classifier: 5.5746 (5.7348)  loss_box_reg: 0.2355 (0.2378)  loss_objectness: 0.1425 (0.1531)  loss_rpn_box_reg: 0.0723 (0.0758)  time: 0.6202  data: 0.1327  max mem: 10734\n",
      "Training Epoch: [87]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.0281 (6.2007)  loss_classifier: 5.5616 (5.7334)  loss_box_reg: 0.2574 (0.2384)  loss_objectness: 0.1425 (0.1533)  loss_rpn_box_reg: 0.0710 (0.0756)  time: 0.6240  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [87]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1625 (6.2032)  loss_classifier: 5.6664 (5.7350)  loss_box_reg: 0.2582 (0.2391)  loss_objectness: 0.1619 (0.1533)  loss_rpn_box_reg: 0.0710 (0.0758)  time: 0.6198  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [87]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.1848 (6.2055)  loss_classifier: 5.7450 (5.7373)  loss_box_reg: 0.2465 (0.2389)  loss_objectness: 0.1522 (0.1534)  loss_rpn_box_reg: 0.0801 (0.0758)  time: 0.6112  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [87]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.4790 (6.2110)  loss_classifier: 5.9060 (5.7431)  loss_box_reg: 0.2039 (0.2386)  loss_objectness: 0.1491 (0.1534)  loss_rpn_box_reg: 0.0694 (0.0758)  time: 0.6066  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [87]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 6.2740 (6.2109)  loss_classifier: 5.8824 (5.7436)  loss_box_reg: 0.1824 (0.2378)  loss_objectness: 0.1528 (0.1535)  loss_rpn_box_reg: 0.0726 (0.0759)  time: 0.6209  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [87]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 6.0282 (6.2093)  loss_classifier: 5.5588 (5.7421)  loss_box_reg: 0.2015 (0.2378)  loss_objectness: 0.1547 (0.1536)  loss_rpn_box_reg: 0.0641 (0.0758)  time: 0.6190  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [87]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.0888 (6.2117)  loss_classifier: 5.6196 (5.7441)  loss_box_reg: 0.2198 (0.2380)  loss_objectness: 0.1547 (0.1537)  loss_rpn_box_reg: 0.0616 (0.0760)  time: 0.5998  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [87] Total time: 0:05:12 (0.6242 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:44  model_time: 0.6481 (0.6481)  evaluator_time: 0.0340 (0.0340)  time: 0.8372  data: 0.1450  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:15  model_time: 0.4441 (0.4523)  evaluator_time: 0.0340 (0.0342)  time: 0.6360  data: 0.1536  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4701 (0.4544)  evaluator_time: 0.0360 (0.0351)  time: 0.6582  data: 0.1488  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6429 s / it)\n",
      "Averaged stats: model_time: 0.4701 (0.4544)  evaluator_time: 0.0360 (0.0351)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.27s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [87]  [  0/125]  eta: 0:01:19  lr: 0.000000  loss: 6.2013 (6.2013)  loss_classifier: 5.6560 (5.6560)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1189 (0.1189)  loss_rpn_box_reg: 0.1319 (0.1319)  time: 0.6381  data: 0.1380  max mem: 10734\n",
      "Testing Epoch: [87]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 5.9946 (6.1309)  loss_classifier: 5.4084 (5.6219)  loss_box_reg: 0.2609 (0.2890)  loss_objectness: 0.1281 (0.1310)  loss_rpn_box_reg: 0.0709 (0.0889)  time: 0.5854  data: 0.1460  max mem: 10734\n",
      "Testing Epoch: [87]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1619 (6.1631)  loss_classifier: 5.6918 (5.6580)  loss_box_reg: 0.2500 (0.2845)  loss_objectness: 0.1188 (0.1314)  loss_rpn_box_reg: 0.0745 (0.0892)  time: 0.5997  data: 0.1460  max mem: 10734\n",
      "Testing Epoch: [87] Total time: 0:01:14 (0.5970 s / it)\n",
      "Training Epoch: [88]  [  0/500]  eta: 0:06:50  lr: 0.000000  loss: 6.7138 (6.7138)  loss_classifier: 6.2577 (6.2577)  loss_box_reg: 0.2547 (0.2547)  loss_objectness: 0.1160 (0.1160)  loss_rpn_box_reg: 0.0854 (0.0854)  time: 0.8212  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [88]  [ 10/500]  eta: 0:05:22  lr: 0.000000  loss: 6.2965 (6.3586)  loss_classifier: 5.7856 (5.8633)  loss_box_reg: 0.2387 (0.2462)  loss_objectness: 0.1545 (0.1514)  loss_rpn_box_reg: 0.0854 (0.0977)  time: 0.6590  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [88]  [ 20/500]  eta: 0:05:07  lr: 0.000000  loss: 6.2387 (6.2143)  loss_classifier: 5.7126 (5.7242)  loss_box_reg: 0.2433 (0.2506)  loss_objectness: 0.1477 (0.1487)  loss_rpn_box_reg: 0.0834 (0.0908)  time: 0.6320  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [88]  [ 30/500]  eta: 0:05:00  lr: 0.000000  loss: 6.1158 (6.2573)  loss_classifier: 5.6543 (5.7778)  loss_box_reg: 0.2504 (0.2502)  loss_objectness: 0.1420 (0.1466)  loss_rpn_box_reg: 0.0585 (0.0826)  time: 0.6276  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [88]  [ 40/500]  eta: 0:04:52  lr: 0.000000  loss: 6.1158 (6.2385)  loss_classifier: 5.6543 (5.7579)  loss_box_reg: 0.2498 (0.2509)  loss_objectness: 0.1467 (0.1503)  loss_rpn_box_reg: 0.0569 (0.0794)  time: 0.6312  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [88]  [ 50/500]  eta: 0:04:45  lr: 0.000000  loss: 6.0938 (6.1768)  loss_classifier: 5.5764 (5.6937)  loss_box_reg: 0.2455 (0.2534)  loss_objectness: 0.1469 (0.1474)  loss_rpn_box_reg: 0.0640 (0.0823)  time: 0.6267  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [88]  [ 60/500]  eta: 0:04:39  lr: 0.000000  loss: 6.1014 (6.2026)  loss_classifier: 5.6062 (5.7251)  loss_box_reg: 0.2139 (0.2463)  loss_objectness: 0.1354 (0.1487)  loss_rpn_box_reg: 0.0831 (0.0825)  time: 0.6353  data: 0.1337  max mem: 10734\n",
      "Training Epoch: [88]  [ 70/500]  eta: 0:04:33  lr: 0.000000  loss: 6.1615 (6.1834)  loss_classifier: 5.6623 (5.7094)  loss_box_reg: 0.2046 (0.2405)  loss_objectness: 0.1426 (0.1513)  loss_rpn_box_reg: 0.0757 (0.0823)  time: 0.6414  data: 0.1351  max mem: 10734\n",
      "Training Epoch: [88]  [ 80/500]  eta: 0:04:26  lr: 0.000000  loss: 6.1573 (6.1624)  loss_classifier: 5.6623 (5.6943)  loss_box_reg: 0.2153 (0.2388)  loss_objectness: 0.1426 (0.1501)  loss_rpn_box_reg: 0.0699 (0.0792)  time: 0.6321  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [88]  [ 90/500]  eta: 0:04:20  lr: 0.000000  loss: 6.2362 (6.1775)  loss_classifier: 5.7412 (5.7123)  loss_box_reg: 0.2322 (0.2380)  loss_objectness: 0.1385 (0.1494)  loss_rpn_box_reg: 0.0588 (0.0778)  time: 0.6336  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [88]  [100/500]  eta: 0:04:13  lr: 0.000000  loss: 6.4092 (6.1980)  loss_classifier: 5.9739 (5.7350)  loss_box_reg: 0.2260 (0.2371)  loss_objectness: 0.1385 (0.1493)  loss_rpn_box_reg: 0.0634 (0.0765)  time: 0.6334  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [88]  [110/500]  eta: 0:04:06  lr: 0.000000  loss: 6.1766 (6.1924)  loss_classifier: 5.6667 (5.7283)  loss_box_reg: 0.2260 (0.2390)  loss_objectness: 0.1345 (0.1494)  loss_rpn_box_reg: 0.0668 (0.0757)  time: 0.6223  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [88]  [120/500]  eta: 0:04:00  lr: 0.000000  loss: 6.0031 (6.1795)  loss_classifier: 5.4588 (5.7170)  loss_box_reg: 0.2568 (0.2389)  loss_objectness: 0.1412 (0.1493)  loss_rpn_box_reg: 0.0535 (0.0742)  time: 0.6224  data: 0.1365  max mem: 10734\n",
      "Training Epoch: [88]  [130/500]  eta: 0:03:54  lr: 0.000000  loss: 6.2239 (6.1952)  loss_classifier: 5.7950 (5.7311)  loss_box_reg: 0.2303 (0.2389)  loss_objectness: 0.1608 (0.1504)  loss_rpn_box_reg: 0.0642 (0.0748)  time: 0.6331  data: 0.1374  max mem: 10734\n",
      "Training Epoch: [88]  [140/500]  eta: 0:03:47  lr: 0.000000  loss: 6.3889 (6.2077)  loss_classifier: 5.9716 (5.7436)  loss_box_reg: 0.2303 (0.2388)  loss_objectness: 0.1440 (0.1500)  loss_rpn_box_reg: 0.0725 (0.0754)  time: 0.6204  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [88]  [150/500]  eta: 0:03:40  lr: 0.000000  loss: 6.1645 (6.1971)  loss_classifier: 5.6576 (5.7329)  loss_box_reg: 0.2466 (0.2386)  loss_objectness: 0.1415 (0.1502)  loss_rpn_box_reg: 0.0747 (0.0754)  time: 0.6006  data: 0.1306  max mem: 10734\n",
      "Training Epoch: [88]  [160/500]  eta: 0:03:33  lr: 0.000000  loss: 6.0420 (6.1977)  loss_classifier: 5.5673 (5.7353)  loss_box_reg: 0.2242 (0.2374)  loss_objectness: 0.1408 (0.1499)  loss_rpn_box_reg: 0.0678 (0.0751)  time: 0.6147  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [88]  [170/500]  eta: 0:03:27  lr: 0.000000  loss: 6.1638 (6.1922)  loss_classifier: 5.6521 (5.7255)  loss_box_reg: 0.2244 (0.2395)  loss_objectness: 0.1483 (0.1513)  loss_rpn_box_reg: 0.0757 (0.0759)  time: 0.6256  data: 0.1376  max mem: 10734\n",
      "Training Epoch: [88]  [180/500]  eta: 0:03:21  lr: 0.000000  loss: 6.1773 (6.1954)  loss_classifier: 5.5607 (5.7269)  loss_box_reg: 0.2756 (0.2409)  loss_objectness: 0.1546 (0.1520)  loss_rpn_box_reg: 0.0800 (0.0757)  time: 0.6283  data: 0.1366  max mem: 10734\n",
      "Training Epoch: [88]  [190/500]  eta: 0:03:15  lr: 0.000000  loss: 6.3793 (6.2099)  loss_classifier: 5.9270 (5.7418)  loss_box_reg: 0.2733 (0.2411)  loss_objectness: 0.1474 (0.1518)  loss_rpn_box_reg: 0.0577 (0.0751)  time: 0.6368  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [88]  [200/500]  eta: 0:03:08  lr: 0.000000  loss: 6.3494 (6.2144)  loss_classifier: 5.9320 (5.7487)  loss_box_reg: 0.2226 (0.2402)  loss_objectness: 0.1453 (0.1514)  loss_rpn_box_reg: 0.0565 (0.0741)  time: 0.6357  data: 0.1325  max mem: 10734\n",
      "Training Epoch: [88]  [210/500]  eta: 0:03:02  lr: 0.000000  loss: 6.1891 (6.2069)  loss_classifier: 5.6791 (5.7430)  loss_box_reg: 0.2226 (0.2389)  loss_objectness: 0.1385 (0.1510)  loss_rpn_box_reg: 0.0565 (0.0741)  time: 0.6270  data: 0.1312  max mem: 10734\n",
      "Training Epoch: [88]  [220/500]  eta: 0:02:56  lr: 0.000000  loss: 6.2842 (6.2018)  loss_classifier: 5.8258 (5.7363)  loss_box_reg: 0.2239 (0.2383)  loss_objectness: 0.1557 (0.1516)  loss_rpn_box_reg: 0.0811 (0.0756)  time: 0.6196  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [88]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.2937 (6.2055)  loss_classifier: 5.7917 (5.7368)  loss_box_reg: 0.2516 (0.2406)  loss_objectness: 0.1579 (0.1521)  loss_rpn_box_reg: 0.0855 (0.0761)  time: 0.6242  data: 0.1357  max mem: 10734\n",
      "Training Epoch: [88]  [240/500]  eta: 0:02:43  lr: 0.000000  loss: 6.2974 (6.2101)  loss_classifier: 5.7993 (5.7419)  loss_box_reg: 0.2639 (0.2405)  loss_objectness: 0.1480 (0.1523)  loss_rpn_box_reg: 0.0752 (0.0754)  time: 0.6293  data: 0.1374  max mem: 10734\n",
      "Training Epoch: [88]  [250/500]  eta: 0:02:37  lr: 0.000000  loss: 6.3289 (6.2174)  loss_classifier: 5.9343 (5.7483)  loss_box_reg: 0.2369 (0.2411)  loss_objectness: 0.1661 (0.1527)  loss_rpn_box_reg: 0.0595 (0.0752)  time: 0.6256  data: 0.1373  max mem: 10734\n",
      "Training Epoch: [88]  [260/500]  eta: 0:02:30  lr: 0.000000  loss: 6.3014 (6.2221)  loss_classifier: 5.8510 (5.7533)  loss_box_reg: 0.2351 (0.2407)  loss_objectness: 0.1612 (0.1531)  loss_rpn_box_reg: 0.0656 (0.0750)  time: 0.6110  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [88]  [270/500]  eta: 0:02:24  lr: 0.000000  loss: 6.3451 (6.2294)  loss_classifier: 5.8619 (5.7592)  loss_box_reg: 0.2351 (0.2418)  loss_objectness: 0.1579 (0.1532)  loss_rpn_box_reg: 0.0657 (0.0752)  time: 0.6127  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [88]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 6.2674 (6.2277)  loss_classifier: 5.7295 (5.7580)  loss_box_reg: 0.2350 (0.2413)  loss_objectness: 0.1529 (0.1532)  loss_rpn_box_reg: 0.0657 (0.0751)  time: 0.6237  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [88]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.0762 (6.2258)  loss_classifier: 5.6990 (5.7568)  loss_box_reg: 0.2317 (0.2409)  loss_objectness: 0.1376 (0.1527)  loss_rpn_box_reg: 0.0723 (0.0754)  time: 0.6272  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [88]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.0894 (6.2250)  loss_classifier: 5.7244 (5.7565)  loss_box_reg: 0.2317 (0.2402)  loss_objectness: 0.1459 (0.1527)  loss_rpn_box_reg: 0.0781 (0.0756)  time: 0.6408  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [88]  [310/500]  eta: 0:01:59  lr: 0.000000  loss: 6.2710 (6.2297)  loss_classifier: 5.7720 (5.7612)  loss_box_reg: 0.2400 (0.2404)  loss_objectness: 0.1484 (0.1524)  loss_rpn_box_reg: 0.0741 (0.0757)  time: 0.6406  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [88]  [320/500]  eta: 0:01:53  lr: 0.000000  loss: 6.2595 (6.2263)  loss_classifier: 5.7309 (5.7599)  loss_box_reg: 0.2218 (0.2395)  loss_objectness: 0.1399 (0.1519)  loss_rpn_box_reg: 0.0659 (0.0750)  time: 0.6402  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [88]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 5.9365 (6.2208)  loss_classifier: 5.4985 (5.7532)  loss_box_reg: 0.2412 (0.2401)  loss_objectness: 0.1372 (0.1523)  loss_rpn_box_reg: 0.0609 (0.0752)  time: 0.6391  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [88]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 5.9391 (6.2162)  loss_classifier: 5.4348 (5.7495)  loss_box_reg: 0.2350 (0.2392)  loss_objectness: 0.1659 (0.1524)  loss_rpn_box_reg: 0.0672 (0.0750)  time: 0.6338  data: 0.1364  max mem: 10734\n",
      "Training Epoch: [88]  [350/500]  eta: 0:01:34  lr: 0.000000  loss: 6.0873 (6.2157)  loss_classifier: 5.6844 (5.7507)  loss_box_reg: 0.2239 (0.2387)  loss_objectness: 0.1559 (0.1518)  loss_rpn_box_reg: 0.0503 (0.0745)  time: 0.6278  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [88]  [360/500]  eta: 0:01:28  lr: 0.000000  loss: 6.2238 (6.2217)  loss_classifier: 5.7618 (5.7574)  loss_box_reg: 0.2178 (0.2380)  loss_objectness: 0.1342 (0.1517)  loss_rpn_box_reg: 0.0610 (0.0746)  time: 0.6247  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [88]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.3892 (6.2231)  loss_classifier: 5.8610 (5.7570)  loss_box_reg: 0.2173 (0.2385)  loss_objectness: 0.1578 (0.1524)  loss_rpn_box_reg: 0.0841 (0.0753)  time: 0.6177  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [88]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.2638 (6.2295)  loss_classifier: 5.8619 (5.7642)  loss_box_reg: 0.2119 (0.2374)  loss_objectness: 0.1606 (0.1526)  loss_rpn_box_reg: 0.0829 (0.0753)  time: 0.5985  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [88]  [390/500]  eta: 0:01:08  lr: 0.000000  loss: 6.2638 (6.2305)  loss_classifier: 5.8927 (5.7656)  loss_box_reg: 0.2098 (0.2369)  loss_objectness: 0.1566 (0.1526)  loss_rpn_box_reg: 0.0650 (0.0754)  time: 0.6072  data: 0.1332  max mem: 10734\n",
      "Training Epoch: [88]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.1349 (6.2267)  loss_classifier: 5.7235 (5.7628)  loss_box_reg: 0.2074 (0.2363)  loss_objectness: 0.1493 (0.1525)  loss_rpn_box_reg: 0.0650 (0.0750)  time: 0.6285  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [88]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.0743 (6.2255)  loss_classifier: 5.6497 (5.7604)  loss_box_reg: 0.2119 (0.2364)  loss_objectness: 0.1656 (0.1535)  loss_rpn_box_reg: 0.0639 (0.0752)  time: 0.6242  data: 0.1371  max mem: 10734\n",
      "Training Epoch: [88]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.1484 (6.2284)  loss_classifier: 5.5952 (5.7625)  loss_box_reg: 0.2370 (0.2368)  loss_objectness: 0.1742 (0.1536)  loss_rpn_box_reg: 0.0809 (0.0754)  time: 0.6217  data: 0.1388  max mem: 10734\n",
      "Training Epoch: [88]  [430/500]  eta: 0:00:43  lr: 0.000000  loss: 6.0946 (6.2283)  loss_classifier: 5.6476 (5.7634)  loss_box_reg: 0.2370 (0.2360)  loss_objectness: 0.1445 (0.1533)  loss_rpn_box_reg: 0.0809 (0.0756)  time: 0.6252  data: 0.1363  max mem: 10734\n",
      "Training Epoch: [88]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.0946 (6.2280)  loss_classifier: 5.6508 (5.7629)  loss_box_reg: 0.2011 (0.2361)  loss_objectness: 0.1369 (0.1534)  loss_rpn_box_reg: 0.0792 (0.0755)  time: 0.6191  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [88]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.1790 (6.2266)  loss_classifier: 5.6396 (5.7601)  loss_box_reg: 0.2715 (0.2373)  loss_objectness: 0.1640 (0.1537)  loss_rpn_box_reg: 0.0687 (0.0755)  time: 0.6221  data: 0.1360  max mem: 10734\n",
      "Training Epoch: [88]  [460/500]  eta: 0:00:25  lr: 0.000000  loss: 6.0421 (6.2228)  loss_classifier: 5.5840 (5.7561)  loss_box_reg: 0.2860 (0.2377)  loss_objectness: 0.1560 (0.1534)  loss_rpn_box_reg: 0.0699 (0.0757)  time: 0.6287  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [88]  [470/500]  eta: 0:00:18  lr: 0.000000  loss: 6.0161 (6.2201)  loss_classifier: 5.5427 (5.7529)  loss_box_reg: 0.2342 (0.2377)  loss_objectness: 0.1522 (0.1536)  loss_rpn_box_reg: 0.0774 (0.0760)  time: 0.6213  data: 0.1345  max mem: 10734\n",
      "Training Epoch: [88]  [480/500]  eta: 0:00:12  lr: 0.000000  loss: 5.9511 (6.2157)  loss_classifier: 5.5086 (5.7494)  loss_box_reg: 0.2187 (0.2371)  loss_objectness: 0.1588 (0.1536)  loss_rpn_box_reg: 0.0632 (0.0757)  time: 0.6278  data: 0.1348  max mem: 10734\n",
      "Training Epoch: [88]  [490/500]  eta: 0:00:06  lr: 0.000000  loss: 5.9975 (6.2159)  loss_classifier: 5.5407 (5.7497)  loss_box_reg: 0.2187 (0.2367)  loss_objectness: 0.1553 (0.1536)  loss_rpn_box_reg: 0.0652 (0.0759)  time: 0.6259  data: 0.1329  max mem: 10734\n",
      "Training Epoch: [88]  [499/500]  eta: 0:00:00  lr: 0.000000  loss: 6.2628 (6.2176)  loss_classifier: 5.7940 (5.7515)  loss_box_reg: 0.2040 (0.2365)  loss_objectness: 0.1410 (0.1535)  loss_rpn_box_reg: 0.0736 (0.0760)  time: 0.6236  data: 0.1341  max mem: 10734\n",
      "Training Epoch: [88] Total time: 0:05:13 (0.6267 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/125]  eta: 0:01:52  model_time: 0.7152 (0.7152)  evaluator_time: 0.0350 (0.0350)  time: 0.9022  data: 0.1420  max mem: 10734\n",
      "Test:  [100/125]  eta: 0:00:16  model_time: 0.4451 (0.4541)  evaluator_time: 0.0340 (0.0380)  time: 0.6304  data: 0.1480  max mem: 10734\n",
      "Test:  [124/125]  eta: 0:00:00  model_time: 0.4761 (0.4560)  evaluator_time: 0.0350 (0.0382)  time: 0.6653  data: 0.1550  max mem: 10734\n",
      "Test: Total time: 0:01:20 (0.6452 s / it)\n",
      "Averaged stats: model_time: 0.4761 (0.4560)  evaluator_time: 0.0350 (0.0382)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.28s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [88]  [  0/125]  eta: 0:01:20  lr: 0.000000  loss: 6.1889 (6.1889)  loss_classifier: 5.6395 (5.6395)  loss_box_reg: 0.2945 (0.2945)  loss_objectness: 0.1224 (0.1224)  loss_rpn_box_reg: 0.1325 (0.1325)  time: 0.6441  data: 0.1440  max mem: 10734\n",
      "Testing Epoch: [88]  [100/125]  eta: 0:00:14  lr: 0.000000  loss: 6.0006 (6.1319)  loss_classifier: 5.4268 (5.6232)  loss_box_reg: 0.2609 (0.2882)  loss_objectness: 0.1290 (0.1315)  loss_rpn_box_reg: 0.0728 (0.0890)  time: 0.5894  data: 0.1466  max mem: 10734\n",
      "Testing Epoch: [88]  [124/125]  eta: 0:00:00  lr: 0.000000  loss: 6.1677 (6.1635)  loss_classifier: 5.6887 (5.6590)  loss_box_reg: 0.2500 (0.2839)  loss_objectness: 0.1176 (0.1314)  loss_rpn_box_reg: 0.0745 (0.0892)  time: 0.5987  data: 0.1460  max mem: 10734\n",
      "Testing Epoch: [88] Total time: 0:01:14 (0.5982 s / it)\n",
      "Training Epoch: [89]  [  0/500]  eta: 0:07:10  lr: 0.000000  loss: 7.0160 (7.0160)  loss_classifier: 6.4922 (6.4922)  loss_box_reg: 0.2820 (0.2820)  loss_objectness: 0.1442 (0.1442)  loss_rpn_box_reg: 0.0976 (0.0976)  time: 0.8612  data: 0.1400  max mem: 10734\n",
      "Training Epoch: [89]  [ 10/500]  eta: 0:05:19  lr: 0.000000  loss: 6.2145 (6.2927)  loss_classifier: 5.7510 (5.7834)  loss_box_reg: 0.2820 (0.2642)  loss_objectness: 0.1634 (0.1624)  loss_rpn_box_reg: 0.0678 (0.0827)  time: 0.6524  data: 0.1387  max mem: 10734\n",
      "Training Epoch: [89]  [ 20/500]  eta: 0:05:03  lr: 0.000000  loss: 6.1580 (6.2784)  loss_classifier: 5.6182 (5.7892)  loss_box_reg: 0.2436 (0.2505)  loss_objectness: 0.1610 (0.1568)  loss_rpn_box_reg: 0.0708 (0.0820)  time: 0.6219  data: 0.1370  max mem: 10734\n",
      "Training Epoch: [89]  [ 30/500]  eta: 0:04:57  lr: 0.000000  loss: 6.2848 (6.2806)  loss_classifier: 5.7739 (5.7991)  loss_box_reg: 0.2332 (0.2459)  loss_objectness: 0.1586 (0.1580)  loss_rpn_box_reg: 0.0708 (0.0776)  time: 0.6220  data: 0.1358  max mem: 10734\n",
      "Training Epoch: [89]  [ 40/500]  eta: 0:04:48  lr: 0.000000  loss: 6.2068 (6.2397)  loss_classifier: 5.7739 (5.7704)  loss_box_reg: 0.2252 (0.2373)  loss_objectness: 0.1477 (0.1548)  loss_rpn_box_reg: 0.0590 (0.0772)  time: 0.6188  data: 0.1333  max mem: 10734\n",
      "Training Epoch: [89]  [ 50/500]  eta: 0:04:41  lr: 0.000000  loss: 6.2068 (6.2581)  loss_classifier: 5.6801 (5.7975)  loss_box_reg: 0.2092 (0.2344)  loss_objectness: 0.1335 (0.1513)  loss_rpn_box_reg: 0.0597 (0.0749)  time: 0.6130  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [89]  [ 60/500]  eta: 0:04:36  lr: 0.000000  loss: 6.3253 (6.2665)  loss_classifier: 5.8671 (5.8150)  loss_box_reg: 0.2089 (0.2294)  loss_objectness: 0.1338 (0.1482)  loss_rpn_box_reg: 0.0592 (0.0738)  time: 0.6300  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [89]  [ 70/500]  eta: 0:04:30  lr: 0.000000  loss: 6.2930 (6.2472)  loss_classifier: 5.7704 (5.7933)  loss_box_reg: 0.1854 (0.2299)  loss_objectness: 0.1338 (0.1493)  loss_rpn_box_reg: 0.0603 (0.0746)  time: 0.6382  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [89]  [ 80/500]  eta: 0:04:23  lr: 0.000000  loss: 6.3037 (6.2620)  loss_classifier: 5.8714 (5.8075)  loss_box_reg: 0.2261 (0.2303)  loss_objectness: 0.1518 (0.1501)  loss_rpn_box_reg: 0.0693 (0.0742)  time: 0.6238  data: 0.1331  max mem: 10734\n",
      "Training Epoch: [89]  [ 90/500]  eta: 0:04:16  lr: 0.000000  loss: 6.3057 (6.2550)  loss_classifier: 5.9070 (5.7950)  loss_box_reg: 0.2399 (0.2344)  loss_objectness: 0.1570 (0.1510)  loss_rpn_box_reg: 0.0693 (0.0747)  time: 0.6146  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [89]  [100/500]  eta: 0:04:09  lr: 0.000000  loss: 6.1600 (6.2524)  loss_classifier: 5.6667 (5.7899)  loss_box_reg: 0.2441 (0.2359)  loss_objectness: 0.1545 (0.1514)  loss_rpn_box_reg: 0.0686 (0.0752)  time: 0.6096  data: 0.1356  max mem: 10734\n",
      "Training Epoch: [89]  [110/500]  eta: 0:04:02  lr: 0.000000  loss: 6.2602 (6.2537)  loss_classifier: 5.8547 (5.7931)  loss_box_reg: 0.2183 (0.2350)  loss_objectness: 0.1406 (0.1506)  loss_rpn_box_reg: 0.0715 (0.0750)  time: 0.6027  data: 0.1324  max mem: 10734\n",
      "Training Epoch: [89]  [120/500]  eta: 0:03:55  lr: 0.000000  loss: 6.2602 (6.2531)  loss_classifier: 5.8503 (5.7896)  loss_box_reg: 0.2256 (0.2372)  loss_objectness: 0.1450 (0.1518)  loss_rpn_box_reg: 0.0651 (0.0745)  time: 0.6051  data: 0.1334  max mem: 10734\n",
      "Training Epoch: [89]  [130/500]  eta: 0:03:50  lr: 0.000000  loss: 6.1590 (6.2555)  loss_classifier: 5.6710 (5.7958)  loss_box_reg: 0.2261 (0.2359)  loss_objectness: 0.1373 (0.1504)  loss_rpn_box_reg: 0.0596 (0.0733)  time: 0.6249  data: 0.1384  max mem: 10734\n",
      "Training Epoch: [89]  [140/500]  eta: 0:03:44  lr: 0.000000  loss: 6.2365 (6.2493)  loss_classifier: 5.6710 (5.7885)  loss_box_reg: 0.2181 (0.2360)  loss_objectness: 0.1374 (0.1509)  loss_rpn_box_reg: 0.0596 (0.0738)  time: 0.6379  data: 0.1416  max mem: 10734\n",
      "Training Epoch: [89]  [150/500]  eta: 0:03:37  lr: 0.000000  loss: 6.2500 (6.2585)  loss_classifier: 5.7397 (5.7958)  loss_box_reg: 0.2254 (0.2376)  loss_objectness: 0.1484 (0.1511)  loss_rpn_box_reg: 0.0627 (0.0740)  time: 0.6242  data: 0.1390  max mem: 10734\n",
      "Training Epoch: [89]  [160/500]  eta: 0:03:31  lr: 0.000000  loss: 6.3036 (6.2630)  loss_classifier: 5.7685 (5.7995)  loss_box_reg: 0.2646 (0.2398)  loss_objectness: 0.1458 (0.1498)  loss_rpn_box_reg: 0.0627 (0.0739)  time: 0.6256  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [89]  [170/500]  eta: 0:03:25  lr: 0.000000  loss: 6.3183 (6.2624)  loss_classifier: 5.8581 (5.7986)  loss_box_reg: 0.2319 (0.2384)  loss_objectness: 0.1444 (0.1506)  loss_rpn_box_reg: 0.0687 (0.0749)  time: 0.6337  data: 0.1355  max mem: 10734\n",
      "Training Epoch: [89]  [180/500]  eta: 0:03:19  lr: 0.000000  loss: 6.2542 (6.2692)  loss_classifier: 5.7544 (5.8053)  loss_box_reg: 0.2162 (0.2389)  loss_objectness: 0.1442 (0.1499)  loss_rpn_box_reg: 0.0762 (0.0751)  time: 0.6316  data: 0.1352  max mem: 10734\n",
      "Training Epoch: [89]  [190/500]  eta: 0:03:13  lr: 0.000000  loss: 6.1837 (6.2635)  loss_classifier: 5.7301 (5.7994)  loss_box_reg: 0.2145 (0.2380)  loss_objectness: 0.1438 (0.1503)  loss_rpn_box_reg: 0.0783 (0.0758)  time: 0.6384  data: 0.1347  max mem: 10734\n",
      "Training Epoch: [89]  [200/500]  eta: 0:03:07  lr: 0.000000  loss: 6.0628 (6.2508)  loss_classifier: 5.5757 (5.7864)  loss_box_reg: 0.2093 (0.2385)  loss_objectness: 0.1438 (0.1500)  loss_rpn_box_reg: 0.0783 (0.0760)  time: 0.6421  data: 0.1344  max mem: 10734\n",
      "Training Epoch: [89]  [210/500]  eta: 0:03:01  lr: 0.000000  loss: 6.1354 (6.2467)  loss_classifier: 5.5869 (5.7808)  loss_box_reg: 0.2468 (0.2396)  loss_objectness: 0.1507 (0.1503)  loss_rpn_box_reg: 0.0668 (0.0760)  time: 0.6346  data: 0.1330  max mem: 10734\n",
      "Training Epoch: [89]  [220/500]  eta: 0:02:55  lr: 0.000000  loss: 6.1622 (6.2458)  loss_classifier: 5.7358 (5.7797)  loss_box_reg: 0.2536 (0.2408)  loss_objectness: 0.1495 (0.1497)  loss_rpn_box_reg: 0.0574 (0.0756)  time: 0.6307  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [89]  [230/500]  eta: 0:02:49  lr: 0.000000  loss: 6.4247 (6.2541)  loss_classifier: 5.9859 (5.7883)  loss_box_reg: 0.2536 (0.2403)  loss_objectness: 0.1447 (0.1501)  loss_rpn_box_reg: 0.0581 (0.0754)  time: 0.6315  data: 0.1354  max mem: 10734\n",
      "Training Epoch: [89]  [240/500]  eta: 0:02:42  lr: 0.000000  loss: 6.2641 (6.2479)  loss_classifier: 5.8074 (5.7819)  loss_box_reg: 0.2197 (0.2403)  loss_objectness: 0.1671 (0.1503)  loss_rpn_box_reg: 0.0671 (0.0753)  time: 0.6144  data: 0.1342  max mem: 10734\n",
      "Training Epoch: [89]  [250/500]  eta: 0:02:36  lr: 0.000000  loss: 6.1279 (6.2410)  loss_classifier: 5.6255 (5.7760)  loss_box_reg: 0.2281 (0.2393)  loss_objectness: 0.1429 (0.1506)  loss_rpn_box_reg: 0.0713 (0.0752)  time: 0.6029  data: 0.1318  max mem: 10734\n",
      "Training Epoch: [89]  [260/500]  eta: 0:02:29  lr: 0.000000  loss: 6.2059 (6.2448)  loss_classifier: 5.7161 (5.7776)  loss_box_reg: 0.2281 (0.2401)  loss_objectness: 0.1399 (0.1511)  loss_rpn_box_reg: 0.0781 (0.0760)  time: 0.6095  data: 0.1323  max mem: 10734\n",
      "Training Epoch: [89]  [270/500]  eta: 0:02:23  lr: 0.000000  loss: 6.1500 (6.2382)  loss_classifier: 5.6143 (5.7702)  loss_box_reg: 0.2350 (0.2402)  loss_objectness: 0.1411 (0.1511)  loss_rpn_box_reg: 0.0912 (0.0767)  time: 0.6169  data: 0.1349  max mem: 10734\n",
      "Training Epoch: [89]  [280/500]  eta: 0:02:17  lr: 0.000000  loss: 5.9559 (6.2304)  loss_classifier: 5.4290 (5.7612)  loss_box_reg: 0.2322 (0.2407)  loss_objectness: 0.1456 (0.1516)  loss_rpn_box_reg: 0.0793 (0.0768)  time: 0.6326  data: 0.1359  max mem: 10734\n",
      "Training Epoch: [89]  [290/500]  eta: 0:02:11  lr: 0.000000  loss: 6.0362 (6.2290)  loss_classifier: 5.5197 (5.7584)  loss_box_reg: 0.2506 (0.2419)  loss_objectness: 0.1557 (0.1517)  loss_rpn_box_reg: 0.0728 (0.0770)  time: 0.6359  data: 0.1362  max mem: 10734\n",
      "Training Epoch: [89]  [300/500]  eta: 0:02:05  lr: 0.000000  loss: 6.0362 (6.2240)  loss_classifier: 5.6268 (5.7531)  loss_box_reg: 0.2634 (0.2426)  loss_objectness: 0.1468 (0.1514)  loss_rpn_box_reg: 0.0728 (0.0769)  time: 0.6309  data: 0.1346  max mem: 10734\n",
      "Training Epoch: [89]  [310/500]  eta: 0:01:58  lr: 0.000000  loss: 5.9909 (6.2223)  loss_classifier: 5.6268 (5.7508)  loss_box_reg: 0.2239 (0.2427)  loss_objectness: 0.1360 (0.1512)  loss_rpn_box_reg: 0.0792 (0.0775)  time: 0.6253  data: 0.1338  max mem: 10734\n",
      "Training Epoch: [89]  [320/500]  eta: 0:01:52  lr: 0.000000  loss: 6.2234 (6.2205)  loss_classifier: 5.6728 (5.7501)  loss_box_reg: 0.2099 (0.2417)  loss_objectness: 0.1379 (0.1513)  loss_rpn_box_reg: 0.0758 (0.0775)  time: 0.6212  data: 0.1339  max mem: 10734\n",
      "Training Epoch: [89]  [330/500]  eta: 0:01:46  lr: 0.000000  loss: 6.1587 (6.2244)  loss_classifier: 5.7550 (5.7547)  loss_box_reg: 0.2265 (0.2418)  loss_objectness: 0.1379 (0.1512)  loss_rpn_box_reg: 0.0629 (0.0767)  time: 0.6239  data: 0.1340  max mem: 10734\n",
      "Training Epoch: [89]  [340/500]  eta: 0:01:40  lr: 0.000000  loss: 6.3022 (6.2282)  loss_classifier: 5.8934 (5.7576)  loss_box_reg: 0.2436 (0.2424)  loss_objectness: 0.1438 (0.1512)  loss_rpn_box_reg: 0.0614 (0.0770)  time: 0.6350  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [89]  [350/500]  eta: 0:01:33  lr: 0.000000  loss: 6.1715 (6.2286)  loss_classifier: 5.7459 (5.7583)  loss_box_reg: 0.2421 (0.2424)  loss_objectness: 0.1399 (0.1509)  loss_rpn_box_reg: 0.0741 (0.0771)  time: 0.6356  data: 0.1343  max mem: 10734\n",
      "Training Epoch: [89]  [360/500]  eta: 0:01:27  lr: 0.000000  loss: 6.1179 (6.2278)  loss_classifier: 5.5964 (5.7576)  loss_box_reg: 0.2236 (0.2417)  loss_objectness: 0.1459 (0.1516)  loss_rpn_box_reg: 0.0728 (0.0769)  time: 0.6569  data: 0.1490  max mem: 10734\n",
      "Training Epoch: [89]  [370/500]  eta: 0:01:21  lr: 0.000000  loss: 6.4277 (6.2292)  loss_classifier: 5.8150 (5.7583)  loss_box_reg: 0.2181 (0.2417)  loss_objectness: 0.1639 (0.1519)  loss_rpn_box_reg: 0.0728 (0.0773)  time: 0.6684  data: 0.1538  max mem: 10734\n",
      "Training Epoch: [89]  [380/500]  eta: 0:01:15  lr: 0.000000  loss: 6.2210 (6.2248)  loss_classifier: 5.5409 (5.7533)  loss_box_reg: 0.2424 (0.2416)  loss_objectness: 0.1546 (0.1519)  loss_rpn_box_reg: 0.0914 (0.0779)  time: 0.6447  data: 0.1379  max mem: 10734\n",
      "Training Epoch: [89]  [390/500]  eta: 0:01:09  lr: 0.000000  loss: 6.2025 (6.2229)  loss_classifier: 5.5850 (5.7518)  loss_box_reg: 0.2424 (0.2413)  loss_objectness: 0.1456 (0.1521)  loss_rpn_box_reg: 0.0790 (0.0777)  time: 0.6390  data: 0.1350  max mem: 10734\n",
      "Training Epoch: [89]  [400/500]  eta: 0:01:02  lr: 0.000000  loss: 6.2478 (6.2269)  loss_classifier: 5.8306 (5.7574)  loss_box_reg: 0.2278 (0.2409)  loss_objectness: 0.1407 (0.1515)  loss_rpn_box_reg: 0.0509 (0.0771)  time: 0.6606  data: 0.1432  max mem: 10734\n",
      "Training Epoch: [89]  [410/500]  eta: 0:00:56  lr: 0.000000  loss: 6.1688 (6.2269)  loss_classifier: 5.6645 (5.7572)  loss_box_reg: 0.2443 (0.2415)  loss_objectness: 0.1293 (0.1513)  loss_rpn_box_reg: 0.0518 (0.0768)  time: 0.6642  data: 0.1472  max mem: 10734\n",
      "Training Epoch: [89]  [420/500]  eta: 0:00:50  lr: 0.000000  loss: 6.1688 (6.2286)  loss_classifier: 5.6645 (5.7597)  loss_box_reg: 0.2324 (0.2406)  loss_objectness: 0.1454 (0.1514)  loss_rpn_box_reg: 0.0698 (0.0768)  time: 0.6481  data: 0.1447  max mem: 10734\n",
      "Training Epoch: [89]  [430/500]  eta: 0:00:44  lr: 0.000000  loss: 6.1728 (6.2240)  loss_classifier: 5.7714 (5.7555)  loss_box_reg: 0.2324 (0.2406)  loss_objectness: 0.1570 (0.1515)  loss_rpn_box_reg: 0.0672 (0.0764)  time: 0.6563  data: 0.1475  max mem: 10734\n",
      "Training Epoch: [89]  [440/500]  eta: 0:00:37  lr: 0.000000  loss: 6.0280 (6.2217)  loss_classifier: 5.6748 (5.7546)  loss_box_reg: 0.2212 (0.2397)  loss_objectness: 0.1324 (0.1510)  loss_rpn_box_reg: 0.0589 (0.0764)  time: 0.6548  data: 0.1475  max mem: 10734\n",
      "Training Epoch: [89]  [450/500]  eta: 0:00:31  lr: 0.000000  loss: 6.0280 (6.2182)  loss_classifier: 5.5571 (5.7505)  loss_box_reg: 0.2172 (0.2400)  loss_objectness: 0.1274 (0.1512)  loss_rpn_box_reg: 0.0677 (0.0765)  time: 0.6602  data: 0.1454  max mem: 10734\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m     train_model(model, evaluation_dataset, evaluation_dataset, num_epochs\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mNUM_EPOCHS, MODEL_TYPE\u001B[38;5;241m=\u001B[39mMODEL_TYPE, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 24\u001B[0m     \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevaluation_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNUM_EPOCHS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMODEL_TYPE\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMODEL_TYPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Data_drive\\Github\\TORCH_CLIP_FRCNN_Trainable\\engine.py:172\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_dataset, validation_dataset, num_epochs, MODEL_TYPE, batch_size)\u001B[0m\n\u001B[0;32m    168\u001B[0m scaler \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mGradScaler()\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m    171\u001B[0m     \u001B[38;5;66;03m# train for one epoch, printing every 10 iterations\u001B[39;00m\n\u001B[1;32m--> 172\u001B[0m     training_metrics \u001B[38;5;241m=\u001B[39m train_one_epoch(model, optimizer, train_data_loader, config\u001B[38;5;241m.\u001B[39mDEVICE, epoch, print_freq\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, scaler\u001B[38;5;241m=\u001B[39mscaler)\n\u001B[0;32m    174\u001B[0m     \u001B[38;5;66;03m# if MODEL_TYPE == 'CLIP-FRCNN':  # check that we dont change the weights from the backbone\u001B[39;00m\n\u001B[0;32m    175\u001B[0m     \u001B[38;5;66;03m#     weight_tester.test(model)\u001B[39;00m\n\u001B[0;32m    176\u001B[0m \n\u001B[0;32m    177\u001B[0m     \u001B[38;5;66;03m# evaluate on the test dataset\u001B[39;00m\n\u001B[0;32m    178\u001B[0m     evaluate(model, valid_data_loader, device\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mDEVICE)\n",
      "File \u001B[1;32mC:\\Data_drive\\Github\\TORCH_CLIP_FRCNN_Trainable\\engine.py:38\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[1;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler, training)\u001B[0m\n\u001B[0;32m     36\u001B[0m targets \u001B[38;5;241m=\u001B[39m [{k: v\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m t\u001B[38;5;241m.\u001B[39mitems()} \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m targets]\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast(enabled\u001B[38;5;241m=\u001B[39mscaler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m---> 38\u001B[0m     loss_dict \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     39\u001B[0m     losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(loss \u001B[38;5;28;01mfor\u001B[39;00m loss \u001B[38;5;129;01min\u001B[39;00m loss_dict\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# reduce losses over all GPUs for logging purposes\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py:97\u001B[0m, in \u001B[0;36mGeneralizedRCNN.forward\u001B[1;34m(self, images, targets)\u001B[0m\n\u001B[0;32m     95\u001B[0m     features \u001B[38;5;241m=\u001B[39m OrderedDict([(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m'\u001B[39m, features)])\n\u001B[0;32m     96\u001B[0m proposals, proposal_losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrpn(images, features, targets)\n\u001B[1;32m---> 97\u001B[0m detections, detector_losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroi_heads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproposals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimages\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage_sizes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     98\u001B[0m detections \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform\u001B[38;5;241m.\u001B[39mpostprocess(detections, images\u001B[38;5;241m.\u001B[39mimage_sizes, original_image_sizes)\n\u001B[0;32m    100\u001B[0m losses \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torchvision\\models\\detection\\roi_heads.py:760\u001B[0m, in \u001B[0;36mRoIHeads.forward\u001B[1;34m(self, features, proposals, image_shapes, targets)\u001B[0m\n\u001B[0;32m    758\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining:\n\u001B[0;32m    759\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m regression_targets \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 760\u001B[0m     loss_classifier, loss_box_reg \u001B[38;5;241m=\u001B[39m \u001B[43mfastrcnn_loss\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    761\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_logits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbox_regression\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mregression_targets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    762\u001B[0m     losses \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    763\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss_classifier\u001B[39m\u001B[38;5;124m\"\u001B[39m: loss_classifier,\n\u001B[0;32m    764\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss_box_reg\u001B[39m\u001B[38;5;124m\"\u001B[39m: loss_box_reg\n\u001B[0;32m    765\u001B[0m     }\n\u001B[0;32m    766\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torchvision\\models\\detection\\roi_heads.py:40\u001B[0m, in \u001B[0;36mfastrcnn_loss\u001B[1;34m(class_logits, box_regression, labels, regression_targets)\u001B[0m\n\u001B[0;32m     35\u001B[0m classification_loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mcross_entropy(class_logits, labels)\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# get indices that correspond to the regression targets for\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# the corresponding ground truth labels, to be used with\u001B[39;00m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# advanced indexing\u001B[39;00m\n\u001B[1;32m---> 40\u001B[0m sampled_pos_inds_subset \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     41\u001B[0m labels_pos \u001B[38;5;241m=\u001B[39m labels[sampled_pos_inds_subset]\n\u001B[0;32m     42\u001B[0m N, num_classes \u001B[38;5;241m=\u001B[39m class_logits\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "MODEL_TYPE='CLIP-FRCNN'\n",
    "# CLIP-Backbone-FRCNN creates a FRCNN using CLIP features as the model backbone\n",
    "# CLIP-FRCNN creates a FRCNN using CLIP features as the model backbone, and embeds the rois using CLIP's embedding\n",
    "# Fully custom vanilla uses a pre-trained resnet50 backbone, and generates new anchor generator and roi pooling\n",
    "# Custom-Vanilla uses the pre-trained FRCNN from pytorch and replaces the roi heads only\n",
    "#\n",
    "import clip\n",
    "text_tokens = clip.tokenize([\"This is \" + desc for desc in item_list]).cuda()\n",
    "\n",
    "model = create_model(MODEL_TYPE, text_tokens)\n",
    "test = False\n",
    "#\n",
    "#\n",
    "# for i in range(1):\n",
    "#     test_image = [torch.rand(3, 224, 224).cuda()]\n",
    "#     model.eval()\n",
    "#     out = model(test_image)\n",
    "#     print(out[0]['labels'].shape)\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "if test:\n",
    "    train_model(model, evaluation_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=8)\n",
    "else:\n",
    "    train_model(model, train_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_TYPE='CLIP-Backbone-FRCNN'\n",
    "\n",
    "model = create_model(MODEL_TYPE, classes=item_list)\n",
    "test = False\n",
    "\n",
    "if test:\n",
    "    train_model(model, evaluation_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=2)\n",
    "else:\n",
    "    train_model(model, train_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "acbb3df601244291b8b2fb9ea1137573",
      "32b6ec3046e64d04b4134553dc434fe0",
      "d8c6a316609d4ca5bfee139b93177ef5",
      "a1645bdfb02b42fba268f7000f183639",
      "4a4788a4fd6841788b20cfbf54a3d10b",
      "5d836b94d13e459d82429606496e4d4f",
      "a410071b34034a91aeda7ef1114969c2",
      "c063e7d90f6a4027b53d1b70c8c07742"
     ]
    },
    "id": "bHa6KRbEWuxz",
    "outputId": "3b4ebd0b-aa69-4a4d-b73c-b8cf24d8b461"
   },
   "outputs": [],
   "source": [
    "#train a custom vanilla model so that we can compare and make sure the CLIP FRCNN is comparable\n",
    "# Fully-Custom-Vanilla is most appropriate as it generates the model in a similar fashion\n",
    "MODEL_TYPE = 'Fully-Custom-Vanilla'\n",
    "\n",
    "vanilla_model = create_model(MODEL_TYPE, classes=item_list)\n",
    "train_model(vanilla_model, train_dataset, evaluation_dataset, num_epochs=10, MODEL_TYPE=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj3vLT1eXFnk"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkzG1i3AW1O7",
    "outputId": "ec7971c3-66ef-4a57-e710-248cb53dee8e"
   },
   "outputs": [],
   "source": [
    "add_detections(model, evaluation_dataset, fo_dataset, field_name=\"predictions\")\n",
    "\n",
    "results = fo.evaluate_detections(\n",
    "    test_view,\n",
    "    \"predictions\",\n",
    "    classes=item_list,\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uYdXrhgYdJ_",
    "outputId": "2eb792e9-342f-4dc8-f6c0-e1503d8bf193"
   },
   "outputs": [],
   "source": [
    "results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcJBOM76aJPR",
    "outputId": "ac452527-7608-4e8d-f57e-18a0470acd30"
   },
   "outputs": [],
   "source": [
    "results.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nddFfGSnXo7i"
   },
   "source": [
    "By default, objects are only matched with other objects of the same class. In order to get an interesting confusion matrix, we need to match interclass objects by setting `classwise=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_53aCMna2Vt",
    "outputId": "4db71f31-73e3-4036-f623-efd8e2ac85bf"
   },
   "outputs": [],
   "source": [
    "results_interclass = fo.evaluate_detections(\n",
    "    test_view, \n",
    "    \"predictions\", \n",
    "    classes=item_list,\n",
    "    compute_mAP=True, \n",
    "    classwise=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot = results.plot_pr_curves(classes=item_list)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "Nbqf-NuAZ7Ps",
    "outputId": "571cd947-c94a-4b9a-ed93-2330fbddea7e"
   },
   "outputs": [],
   "source": [
    "results_interclass.plot_confusion_matrix(classes=item_list, include_other=False, include_missing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElSV7tTbYKLr"
   },
   "source": [
    "The [detection evaluation](https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#detections) also added the attributes `eval_fp`, `eval_tp`, and `eval_fn` to every predicted detection indicating if it is a false positive, true positive, or false negative. \n",
    "Let's create a view to find the worst samples by sorting by `eval_fp` using the [FiftyOne App](https://voxel51.com/docs/fiftyone/user_guide/app.html) to visualize the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786,
     "resources": {
      "https://localhost:5151/polling?sessionId=de0b710e-15f8-4c57-ba46-ae7955f716b1": {
       "data": "eyJtZXNzYWdlcyI6IFtdfQ==",
       "headers": [
        [
         "access-control-allow-headers",
         "x-requested-with"
        ],
        [
         "content-type",
         "text/html; charset=UTF-8"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "Pm4Z52rd8AC1",
    "outputId": "62d39076-7ef3-4fe3-95ae-500d0f8f8a3f"
   },
   "outputs": [],
   "source": [
    "session.view = test_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786,
     "resources": {
      "https://localhost:5151/polling?sessionId=ebbc318d-3578-4fb1-9ae7-68596117572b": {
       "data": "eyJtZXNzYWdlcyI6IFtdfQ==",
       "headers": [
        [
         "access-control-allow-headers",
         "x-requested-with"
        ],
        [
         "content-type",
         "text/html; charset=UTF-8"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "njLG0l5K-ucV",
    "outputId": "bda6f02d-d8fe-49be-d212-31e0e70779e3"
   },
   "outputs": [],
   "source": [
    "session.view = test_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReXDVFgLZLtf"
   },
   "source": [
    "It would be best to get this [data reannotated to fix these mistakes](https://towardsdatascience.com/managing-annotation-mistakes-with-fiftyone-and-labelbox-fc6e87b51102), but in the meantime, we can easily remedy this by simply creating a new view that remaps the labels `car`, `truck`, and `bus` all to `vehicle` and then retraining the model with that. This is only possible because we are backing our data in FiftyOne and loading views into PyTorch as needed. Without FiftyOne, the PyTorch dataset class or the underlying data would need to be changed to remap these classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# map labels to single vehicle class\n",
    "vehicle_list = ['car', 'bus', 'truck']\n",
    "vehicles_map = {c: \"vehicle\" for c in vehicle_list}\n",
    "\n",
    "train_map_view = train_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "test_map_view = test_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "torch_map_dataset = FiftyOneTorchDataset(train_map_view, train_transforms)\n",
    "torch_map_dataset_test = FiftyOneTorchDataset(test_map_view, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynRCHQv8XB_v"
   },
   "outputs": [],
   "source": [
    "# Only 2 classes (background and vehicle)\n",
    "MODEL_TYPE = 'Vanilla-FRCNN'\n",
    "vehicle_model = create_model(MODEL_TYPE, num_classes=(len(vehicles_map)+1))\n",
    "train_model(vehicle_model, torch_map_dataset, torch_map_dataset_test, num_epochs=2, MODEL_TYPE=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-mrVOl4XFbp",
    "outputId": "6d8bec76-ebe8-4a36-959a-52bb1aab8498"
   },
   "outputs": [],
   "source": [
    "add_detections(vehicle_model, torch_map_dataset_test, test_map_view, field_name=\"vehicle_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfd3xvhaXhl_",
    "outputId": "d9c4a2fe-538a-4979-c3f8-f5ede0c98aa1"
   },
   "outputs": [],
   "source": [
    "vehicle_results = fo.evaluate_detections(\n",
    "    test_map_view, \n",
    "    \"vehicle_predictions\", \n",
    "    classes=[\"vehicle\"], \n",
    "    eval_key=\"vehicle_eval\", \n",
    "    compute_mAP=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFvddH3rk0NR",
    "outputId": "59572ba2-f9ad-4dd2-e9ac-90877190ff99"
   },
   "outputs": [],
   "source": [
    "vehicle_results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwbhq18sk1PL",
    "outputId": "d6985867-5049-4678-cc88-d5041a0079ed"
   },
   "outputs": [],
   "source": [
    "vehicle_results.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJMAkJbWZ_u1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Due to our ability to easily visualize and manage our dataset with FiftyOne, we were able to spot and take action on a dataset issue that would otherwise have gone unnoticed if we only concerned ourselves with dataset-wide evaluation metrics and fixed dataset representations. Through these efforts, we managed to increase the mAP of the model to 43%.\n",
    "\n",
    "Even though this example workflow may not work in all situations, this kind of class-merging strategy can be effective in cases where more fine-grained discrimination is not called for."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "fiftyone_pytorch_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "torch-frcnn",
   "language": "python",
   "display_name": "torch-frcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "32b6ec3046e64d04b4134553dc434fe0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a4788a4fd6841788b20cfbf54a3d10b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5d836b94d13e459d82429606496e4d4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1645bdfb02b42fba268f7000f183639": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c063e7d90f6a4027b53d1b70c8c07742",
      "placeholder": "​",
      "style": "IPY_MODEL_a410071b34034a91aeda7ef1114969c2",
      "value": " 160M/160M [01:05&lt;00:00, 2.55MB/s]"
     }
    },
    "a410071b34034a91aeda7ef1114969c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acbb3df601244291b8b2fb9ea1137573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8c6a316609d4ca5bfee139b93177ef5",
       "IPY_MODEL_a1645bdfb02b42fba268f7000f183639"
      ],
      "layout": "IPY_MODEL_32b6ec3046e64d04b4134553dc434fe0"
     }
    },
    "c063e7d90f6a4027b53d1b70c8c07742": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8c6a316609d4ca5bfee139b93177ef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d836b94d13e459d82429606496e4d4f",
      "max": 167502836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a4788a4fd6841788b20cfbf54a3d10b",
      "value": 167502836
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}