{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Code for using FiftyOne to train a Faster RCNN on COCO data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x2022830d8d0>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import torchvision.models.detection.roi_heads\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "from dataset import FiftyOneTorchDataset, get_transforms\n",
    "from model import create_model\n",
    "from utils import add_detections\n",
    "\n",
    "from engine import train_model\n",
    "import config\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load full dataset from model zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5crNDNsRWdPT",
    "outputId": "4f3ff734-ca0a-4312-a811-7f84db514fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to 'C:\\Users\\blain\\fiftyone\\coco-2017\\validation' if necessary\n",
      "Found annotations at 'C:\\Users\\blain\\fiftyone\\coco-2017\\raw\\instances_val2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading 'coco-2017' split 'validation'\n",
      " 100% |███████████████| 5000/5000 [15.4s elapsed, 0s remaining, 350.3 samples/s]      \n",
      "Dataset 'coco-2017-validation' created\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x20262192280>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"800\"\n            src=\"http://localhost:5151/?notebook=true&handleId=557d214b-5786-4947-8c64-ebb4905c625d\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lodad in the dataset from the FiftyOne model Zoo\n",
    "fo_dataset = foz.load_zoo_dataset(\"coco-2017\", \"validation\")\n",
    "\n",
    "#needed to calculate image height and width\n",
    "fo_dataset.compute_metadata()\n",
    "\n",
    "session = fo.launch_app(fo_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqU6Ckq4WKHK"
   },
   "source": [
    "For example, cluttered images make it difficult for models to localize objects. We can use FiftyOne to create a view containing only samples with more than, say, 10 objects. You can perform the same operations on views as datasets, so we can create an instance of our PyTorch dataset from this view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kLACOukJFUxd"
   },
   "outputs": [],
   "source": [
    "#if we want to see images with more than 10 items, we can\n",
    "# busy_view = fo_dataset.match(F(\"ground_truth.detections\").length() > 10)\n",
    "# busy_torch_dataset = FiftyOneTorchDataset(busy_view)\n",
    "# session.view = busy_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKsE_7TOWXBE"
   },
   "source": [
    "### Create training and testing views (and corresponding PyTorch datasets) that only contain some items from the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TELK0NWmWrMT",
    "outputId": "8bf582cf-e483-4643-8f6b-7c664a2d6c5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning on 4000 samples\n",
      "Testing on 1000 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x202636aed90>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"800\"\n            src=\"http://localhost:5151/?notebook=true&handleId=67b55bf2-392b-4e7f-a95f-7287dc6b6e20\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subset = False\n",
    "\n",
    "train_transforms, test_transforms = get_transforms()\n",
    "\n",
    "if subset:\n",
    "    # to filter certain items from the dataset we can\n",
    "    item_list = [\"dog\", 'airplane']\n",
    "    #item_list = ['airplane', 'cat']\n",
    "    item_view = fo_dataset.filter_labels(\"ground_truth\",\n",
    "            F(\"label\").is_in(item_list))\n",
    "\n",
    "    #session.view = item_view\n",
    "\n",
    "    # split the dataset in train and test set\n",
    "    train_view = item_view.take((len(item_view) * config.TRAIN_TEST_SPLIT), seed=51)\n",
    "    test_view = item_view.exclude([s.id for s in train_view])\n",
    "\n",
    "else:\n",
    "    train_view = fo_dataset.take(len(fo_dataset) * config.TRAIN_TEST_SPLIT)\n",
    "    test_view = fo_dataset.exclude([s.id for s in train_view])\n",
    "    item_list = fo_dataset.distinct(\"ground_truth.detections.label\")\n",
    "\n",
    "print(f'Traning on {len(train_view)} samples')\n",
    "print(f'Testing on {len(test_view)} samples')\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "train_dataset = FiftyOneTorchDataset(train_view, train_transforms,\n",
    "        classes=item_list)\n",
    "evaluation_dataset = FiftyOneTorchDataset(test_view, test_transforms,\n",
    "        classes=item_list)\n",
    "\n",
    "session.view = train_view\n",
    "\n",
    "#this is needed for later use, but not for creating the dataset\n",
    "if item_list[0] != 'background':\n",
    "     item_list.insert(0,'background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# # map labels to single vehicle class\n",
    "# vehicle_list = ['car', 'bus', 'truck']\n",
    "# vehicles_map = {c: \"vehicle\" for c in vehicle_list}\n",
    "#\n",
    "# train_map_view = train_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "# test_map_view = test_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "#\n",
    "# # use our dataset and defined transformations\n",
    "# torch_map_dataset = FiftyOneTorchDataset(train_map_view, train_transforms)\n",
    "# torch_map_dataset_test = FiftyOneTorchDataset(test_map_view, test_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5je6lVBWz5r"
   },
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpn score thresh: 0.0\n",
      "Using device cuda\n",
      "Loaded model epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blain\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: [22]  [  0/250]  eta: 0:07:57  lr: 0.000300  loss: 0.1458 (0.1458)  loss_objectness: 0.0791 (0.0791)  loss_rpn_box_reg: 0.0668 (0.0668)  time: 1.9110  data: 0.5583  max mem: 3988\n",
      "Training Epoch: [22]  [ 10/250]  eta: 0:03:13  lr: 0.000300  loss: 0.1427 (0.1353)  loss_objectness: 0.0739 (0.0702)  loss_rpn_box_reg: 0.0668 (0.0651)  time: 0.8043  data: 0.3295  max mem: 4551\n",
      "Training Epoch: [22]  [ 20/250]  eta: 0:02:55  lr: 0.000300  loss: 0.1444 (0.1423)  loss_objectness: 0.0739 (0.0760)  loss_rpn_box_reg: 0.0658 (0.0663)  time: 0.7056  data: 0.3022  max mem: 4883\n",
      "Training Epoch: [22]  [ 30/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1450 (0.1454)  loss_objectness: 0.0733 (0.0748)  loss_rpn_box_reg: 0.0658 (0.0707)  time: 0.7198  data: 0.3025  max mem: 4883\n",
      "Training Epoch: [22]  [ 40/250]  eta: 0:02:33  lr: 0.000300  loss: 0.1546 (0.1479)  loss_objectness: 0.0707 (0.0744)  loss_rpn_box_reg: 0.0790 (0.0735)  time: 0.6996  data: 0.3047  max mem: 4883\n",
      "Training Epoch: [22]  [ 50/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1395 (0.1469)  loss_objectness: 0.0726 (0.0750)  loss_rpn_box_reg: 0.0698 (0.0719)  time: 0.6945  data: 0.2999  max mem: 4890\n",
      "Training Epoch: [22]  [ 60/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1395 (0.1469)  loss_objectness: 0.0683 (0.0742)  loss_rpn_box_reg: 0.0697 (0.0727)  time: 0.6878  data: 0.2952  max mem: 4890\n",
      "Training Epoch: [22]  [ 70/250]  eta: 0:02:08  lr: 0.000300  loss: 0.1436 (0.1469)  loss_objectness: 0.0683 (0.0743)  loss_rpn_box_reg: 0.0769 (0.0726)  time: 0.6768  data: 0.2960  max mem: 4890\n",
      "Training Epoch: [22]  [ 80/250]  eta: 0:02:01  lr: 0.000300  loss: 0.1499 (0.1469)  loss_objectness: 0.0730 (0.0755)  loss_rpn_box_reg: 0.0682 (0.0714)  time: 0.6989  data: 0.3018  max mem: 4890\n",
      "Training Epoch: [22]  [ 90/250]  eta: 0:01:53  lr: 0.000300  loss: 0.1521 (0.1462)  loss_objectness: 0.0715 (0.0746)  loss_rpn_box_reg: 0.0657 (0.0717)  time: 0.7078  data: 0.2994  max mem: 4890\n",
      "Training Epoch: [22]  [100/250]  eta: 0:01:46  lr: 0.000300  loss: 0.1539 (0.1480)  loss_objectness: 0.0715 (0.0749)  loss_rpn_box_reg: 0.0736 (0.0731)  time: 0.7101  data: 0.2979  max mem: 4890\n",
      "Training Epoch: [22]  [110/250]  eta: 0:01:39  lr: 0.000300  loss: 0.1682 (0.1500)  loss_objectness: 0.0819 (0.0766)  loss_rpn_box_reg: 0.0767 (0.0734)  time: 0.7035  data: 0.3002  max mem: 4890\n",
      "Training Epoch: [22]  [120/250]  eta: 0:01:32  lr: 0.000300  loss: 0.1621 (0.1519)  loss_objectness: 0.0798 (0.0768)  loss_rpn_box_reg: 0.0758 (0.0751)  time: 0.7081  data: 0.2986  max mem: 4890\n",
      "Training Epoch: [22]  [130/250]  eta: 0:01:25  lr: 0.000300  loss: 0.1523 (0.1516)  loss_objectness: 0.0770 (0.0770)  loss_rpn_box_reg: 0.0724 (0.0746)  time: 0.7006  data: 0.2993  max mem: 4890\n",
      "Training Epoch: [22]  [140/250]  eta: 0:01:17  lr: 0.000300  loss: 0.1373 (0.1500)  loss_objectness: 0.0743 (0.0763)  loss_rpn_box_reg: 0.0629 (0.0736)  time: 0.6831  data: 0.3015  max mem: 4890\n",
      "Training Epoch: [22]  [150/250]  eta: 0:01:10  lr: 0.000300  loss: 0.1552 (0.1510)  loss_objectness: 0.0724 (0.0769)  loss_rpn_box_reg: 0.0731 (0.0742)  time: 0.6922  data: 0.2984  max mem: 4890\n",
      "Training Epoch: [22]  [160/250]  eta: 0:01:03  lr: 0.000300  loss: 0.1558 (0.1507)  loss_objectness: 0.0834 (0.0769)  loss_rpn_box_reg: 0.0709 (0.0738)  time: 0.6841  data: 0.2960  max mem: 4890\n",
      "Training Epoch: [22]  [170/250]  eta: 0:00:56  lr: 0.000300  loss: 0.1583 (0.1512)  loss_objectness: 0.0853 (0.0778)  loss_rpn_box_reg: 0.0592 (0.0734)  time: 0.6714  data: 0.3006  max mem: 4890\n",
      "Training Epoch: [22]  [180/250]  eta: 0:00:49  lr: 0.000300  loss: 0.1606 (0.1516)  loss_objectness: 0.0853 (0.0783)  loss_rpn_box_reg: 0.0704 (0.0733)  time: 0.6903  data: 0.3155  max mem: 4890\n",
      "Training Epoch: [22]  [190/250]  eta: 0:00:42  lr: 0.000300  loss: 0.1606 (0.1522)  loss_objectness: 0.0808 (0.0786)  loss_rpn_box_reg: 0.0712 (0.0735)  time: 0.7082  data: 0.3132  max mem: 4890\n",
      "Training Epoch: [22]  [200/250]  eta: 0:00:35  lr: 0.000300  loss: 0.1620 (0.1526)  loss_objectness: 0.0817 (0.0792)  loss_rpn_box_reg: 0.0646 (0.0734)  time: 0.6912  data: 0.2975  max mem: 4890\n",
      "Training Epoch: [22]  [210/250]  eta: 0:00:28  lr: 0.000300  loss: 0.1398 (0.1519)  loss_objectness: 0.0847 (0.0793)  loss_rpn_box_reg: 0.0600 (0.0726)  time: 0.6783  data: 0.2971  max mem: 4890\n",
      "Training Epoch: [22]  [220/250]  eta: 0:00:21  lr: 0.000300  loss: 0.1495 (0.1524)  loss_objectness: 0.0826 (0.0795)  loss_rpn_box_reg: 0.0675 (0.0729)  time: 0.6955  data: 0.2998  max mem: 4890\n",
      "Training Epoch: [22]  [230/250]  eta: 0:00:14  lr: 0.000300  loss: 0.1579 (0.1524)  loss_objectness: 0.0765 (0.0794)  loss_rpn_box_reg: 0.0821 (0.0731)  time: 0.6916  data: 0.2972  max mem: 4890\n",
      "Training Epoch: [22]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1579 (0.1531)  loss_objectness: 0.0726 (0.0794)  loss_rpn_box_reg: 0.0822 (0.0738)  time: 0.6759  data: 0.2953  max mem: 4890\n",
      "Training Epoch: [22]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1614 (0.1534)  loss_objectness: 0.0719 (0.0795)  loss_rpn_box_reg: 0.0819 (0.0739)  time: 0.6888  data: 0.2981  max mem: 4890\n",
      "Training Epoch: [22] Total time: 0:02:54 (0.6992 s / it)\n",
      "Testing Epoch: [22]  [ 0/62]  eta: 0:00:45  lr: 0.000300  loss: 0.1334 (0.1334)  loss_objectness: 0.0444 (0.0444)  loss_rpn_box_reg: 0.0890 (0.0890)  time: 0.7292  data: 0.4051  max mem: 4890\n",
      "Testing Epoch: [22]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1225 (0.1308)  loss_objectness: 0.0551 (0.0559)  loss_rpn_box_reg: 0.0675 (0.0749)  time: 0.6319  data: 0.3124  max mem: 5067\n",
      "Testing Epoch: [22] Total time: 0:00:39 (0.6410 s / it)\n",
      "Saving epoch 22 - Evaluation Loss 0.13051050901412964\n",
      "Training Epoch: [23]  [  0/250]  eta: 0:03:26  lr: 0.000300  loss: 0.1482 (0.1482)  loss_objectness: 0.0917 (0.0917)  loss_rpn_box_reg: 0.0565 (0.0565)  time: 0.8252  data: 0.3051  max mem: 5067\n",
      "Training Epoch: [23]  [ 10/250]  eta: 0:02:50  lr: 0.000300  loss: 0.1546 (0.1639)  loss_objectness: 0.0880 (0.0834)  loss_rpn_box_reg: 0.0787 (0.0805)  time: 0.7096  data: 0.2904  max mem: 5067\n",
      "Training Epoch: [23]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1519 (0.1556)  loss_objectness: 0.0872 (0.0846)  loss_rpn_box_reg: 0.0621 (0.0710)  time: 0.6924  data: 0.2911  max mem: 5067\n",
      "Training Epoch: [23]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1448 (0.1522)  loss_objectness: 0.0743 (0.0801)  loss_rpn_box_reg: 0.0634 (0.0721)  time: 0.6754  data: 0.2911  max mem: 5067\n",
      "Training Epoch: [23]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1313 (0.1467)  loss_objectness: 0.0720 (0.0774)  loss_rpn_box_reg: 0.0634 (0.0694)  time: 0.6742  data: 0.2896  max mem: 5067\n",
      "Training Epoch: [23]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1313 (0.1463)  loss_objectness: 0.0628 (0.0761)  loss_rpn_box_reg: 0.0608 (0.0702)  time: 0.6875  data: 0.2878  max mem: 5067\n",
      "Training Epoch: [23]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1515 (0.1480)  loss_objectness: 0.0725 (0.0762)  loss_rpn_box_reg: 0.0708 (0.0718)  time: 0.6883  data: 0.2892  max mem: 5067\n",
      "Training Epoch: [23]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1515 (0.1485)  loss_objectness: 0.0771 (0.0773)  loss_rpn_box_reg: 0.0748 (0.0712)  time: 0.6744  data: 0.2917  max mem: 5067\n",
      "Training Epoch: [23]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1571 (0.1493)  loss_objectness: 0.0813 (0.0780)  loss_rpn_box_reg: 0.0663 (0.0713)  time: 0.6809  data: 0.2923  max mem: 5067\n",
      "Training Epoch: [23]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1598 (0.1513)  loss_objectness: 0.0821 (0.0787)  loss_rpn_box_reg: 0.0747 (0.0726)  time: 0.6888  data: 0.2910  max mem: 5067\n",
      "Training Epoch: [23]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1566 (0.1510)  loss_objectness: 0.0788 (0.0788)  loss_rpn_box_reg: 0.0741 (0.0723)  time: 0.6852  data: 0.2870  max mem: 5067\n",
      "Training Epoch: [23]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1472 (0.1511)  loss_objectness: 0.0757 (0.0793)  loss_rpn_box_reg: 0.0691 (0.0718)  time: 0.6915  data: 0.2901  max mem: 5067\n",
      "Training Epoch: [23]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1490 (0.1517)  loss_objectness: 0.0754 (0.0789)  loss_rpn_box_reg: 0.0766 (0.0728)  time: 0.6954  data: 0.2933  max mem: 5067\n",
      "Training Epoch: [23]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1490 (0.1521)  loss_objectness: 0.0742 (0.0781)  loss_rpn_box_reg: 0.0860 (0.0740)  time: 0.6888  data: 0.2905  max mem: 5067\n",
      "Training Epoch: [23]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1387 (0.1510)  loss_objectness: 0.0723 (0.0780)  loss_rpn_box_reg: 0.0546 (0.0730)  time: 0.6804  data: 0.2894  max mem: 5067\n",
      "Training Epoch: [23]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1428 (0.1520)  loss_objectness: 0.0781 (0.0786)  loss_rpn_box_reg: 0.0647 (0.0734)  time: 0.6776  data: 0.2899  max mem: 5067\n",
      "Training Epoch: [23]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1332 (0.1508)  loss_objectness: 0.0734 (0.0780)  loss_rpn_box_reg: 0.0656 (0.0728)  time: 0.6772  data: 0.2879  max mem: 5067\n",
      "Training Epoch: [23]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1276 (0.1503)  loss_objectness: 0.0719 (0.0778)  loss_rpn_box_reg: 0.0644 (0.0725)  time: 0.6768  data: 0.2882  max mem: 5067\n",
      "Training Epoch: [23]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1499 (0.1504)  loss_objectness: 0.0719 (0.0777)  loss_rpn_box_reg: 0.0726 (0.0726)  time: 0.6829  data: 0.2896  max mem: 5067\n",
      "Training Epoch: [23]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1576 (0.1511)  loss_objectness: 0.0822 (0.0784)  loss_rpn_box_reg: 0.0726 (0.0727)  time: 0.6943  data: 0.2879  max mem: 5067\n",
      "Training Epoch: [23]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1299 (0.1505)  loss_objectness: 0.0868 (0.0786)  loss_rpn_box_reg: 0.0500 (0.0719)  time: 0.6863  data: 0.2891  max mem: 5067\n",
      "Training Epoch: [23]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1299 (0.1510)  loss_objectness: 0.0773 (0.0783)  loss_rpn_box_reg: 0.0655 (0.0727)  time: 0.6703  data: 0.2884  max mem: 5067\n",
      "Training Epoch: [23]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1659 (0.1517)  loss_objectness: 0.0773 (0.0787)  loss_rpn_box_reg: 0.0840 (0.0730)  time: 0.6942  data: 0.2874  max mem: 5067\n",
      "Training Epoch: [23]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1587 (0.1516)  loss_objectness: 0.0802 (0.0788)  loss_rpn_box_reg: 0.0778 (0.0728)  time: 0.7118  data: 0.2905  max mem: 5067\n",
      "Training Epoch: [23]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1483 (0.1517)  loss_objectness: 0.0750 (0.0786)  loss_rpn_box_reg: 0.0796 (0.0731)  time: 0.6852  data: 0.2883  max mem: 5067\n",
      "Training Epoch: [23]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1463 (0.1517)  loss_objectness: 0.0733 (0.0785)  loss_rpn_box_reg: 0.0670 (0.0733)  time: 0.6845  data: 0.2874  max mem: 5067\n",
      "Training Epoch: [23] Total time: 0:02:51 (0.6864 s / it)\n",
      "Testing Epoch: [23]  [ 0/62]  eta: 0:00:40  lr: 0.000300  loss: 0.1288 (0.1288)  loss_objectness: 0.0428 (0.0428)  loss_rpn_box_reg: 0.0860 (0.0860)  time: 0.6481  data: 0.2871  max mem: 5067\n",
      "Testing Epoch: [23]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1222 (0.1276)  loss_objectness: 0.0500 (0.0536)  loss_rpn_box_reg: 0.0635 (0.0740)  time: 0.6216  data: 0.3013  max mem: 5067\n",
      "Testing Epoch: [23] Total time: 0:00:39 (0.6348 s / it)\n",
      "Saving epoch 23 - Evaluation Loss 0.12385442107915878\n",
      "Training Epoch: [24]  [  0/250]  eta: 0:03:34  lr: 0.000300  loss: 0.1367 (0.1367)  loss_objectness: 0.0734 (0.0734)  loss_rpn_box_reg: 0.0633 (0.0633)  time: 0.8582  data: 0.2951  max mem: 5067\n",
      "Training Epoch: [24]  [ 10/250]  eta: 0:02:48  lr: 0.000300  loss: 0.1416 (0.1372)  loss_objectness: 0.0750 (0.0769)  loss_rpn_box_reg: 0.0633 (0.0602)  time: 0.7020  data: 0.2839  max mem: 5067\n",
      "Training Epoch: [24]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1442 (0.1432)  loss_objectness: 0.0712 (0.0743)  loss_rpn_box_reg: 0.0730 (0.0689)  time: 0.6777  data: 0.2832  max mem: 5067\n",
      "Training Epoch: [24]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1412 (0.1448)  loss_objectness: 0.0724 (0.0748)  loss_rpn_box_reg: 0.0835 (0.0700)  time: 0.6719  data: 0.2856  max mem: 5067\n",
      "Training Epoch: [24]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1412 (0.1456)  loss_objectness: 0.0729 (0.0741)  loss_rpn_box_reg: 0.0765 (0.0715)  time: 0.6826  data: 0.2884  max mem: 5067\n",
      "Training Epoch: [24]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1454 (0.1472)  loss_objectness: 0.0769 (0.0750)  loss_rpn_box_reg: 0.0708 (0.0721)  time: 0.6863  data: 0.2912  max mem: 5067\n",
      "Training Epoch: [24]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1623 (0.1529)  loss_objectness: 0.0822 (0.0772)  loss_rpn_box_reg: 0.0801 (0.0757)  time: 0.6822  data: 0.2951  max mem: 5067\n",
      "Training Epoch: [24]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1623 (0.1536)  loss_objectness: 0.0772 (0.0774)  loss_rpn_box_reg: 0.0837 (0.0762)  time: 0.6910  data: 0.2928  max mem: 5067\n",
      "Training Epoch: [24]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1422 (0.1531)  loss_objectness: 0.0731 (0.0769)  loss_rpn_box_reg: 0.0728 (0.0762)  time: 0.6941  data: 0.2897  max mem: 5067\n",
      "Training Epoch: [24]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1481 (0.1538)  loss_objectness: 0.0789 (0.0778)  loss_rpn_box_reg: 0.0681 (0.0759)  time: 0.6698  data: 0.2905  max mem: 5067\n",
      "Training Epoch: [24]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1365 (0.1521)  loss_objectness: 0.0712 (0.0776)  loss_rpn_box_reg: 0.0658 (0.0745)  time: 0.6541  data: 0.2890  max mem: 5067\n",
      "Training Epoch: [24]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1364 (0.1516)  loss_objectness: 0.0673 (0.0776)  loss_rpn_box_reg: 0.0658 (0.0740)  time: 0.6684  data: 0.2897  max mem: 5067\n",
      "Training Epoch: [24]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1463 (0.1513)  loss_objectness: 0.0759 (0.0775)  loss_rpn_box_reg: 0.0662 (0.0738)  time: 0.6851  data: 0.2908  max mem: 5067\n",
      "Training Epoch: [24]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1539 (0.1520)  loss_objectness: 0.0759 (0.0777)  loss_rpn_box_reg: 0.0695 (0.0743)  time: 0.6802  data: 0.2897  max mem: 5067\n",
      "Training Epoch: [24]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1474 (0.1516)  loss_objectness: 0.0715 (0.0778)  loss_rpn_box_reg: 0.0695 (0.0738)  time: 0.6774  data: 0.2858  max mem: 5067\n",
      "Training Epoch: [24]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1431 (0.1519)  loss_objectness: 0.0731 (0.0780)  loss_rpn_box_reg: 0.0711 (0.0739)  time: 0.6884  data: 0.2873  max mem: 5067\n",
      "Training Epoch: [24]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1474 (0.1520)  loss_objectness: 0.0774 (0.0782)  loss_rpn_box_reg: 0.0756 (0.0738)  time: 0.6931  data: 0.2902  max mem: 5067\n",
      "Training Epoch: [24]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1512 (0.1521)  loss_objectness: 0.0828 (0.0786)  loss_rpn_box_reg: 0.0725 (0.0735)  time: 0.6728  data: 0.2848  max mem: 5067\n",
      "Training Epoch: [24]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1512 (0.1519)  loss_objectness: 0.0755 (0.0785)  loss_rpn_box_reg: 0.0639 (0.0734)  time: 0.6667  data: 0.2869  max mem: 5067\n",
      "Training Epoch: [24]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1424 (0.1521)  loss_objectness: 0.0755 (0.0789)  loss_rpn_box_reg: 0.0719 (0.0733)  time: 0.6754  data: 0.2897  max mem: 5067\n",
      "Training Epoch: [24]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1468 (0.1521)  loss_objectness: 0.0820 (0.0792)  loss_rpn_box_reg: 0.0666 (0.0729)  time: 0.6825  data: 0.2902  max mem: 5067\n",
      "Training Epoch: [24]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1417 (0.1511)  loss_objectness: 0.0734 (0.0790)  loss_rpn_box_reg: 0.0571 (0.0721)  time: 0.6798  data: 0.2946  max mem: 5067\n",
      "Training Epoch: [24]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1417 (0.1516)  loss_objectness: 0.0767 (0.0792)  loss_rpn_box_reg: 0.0552 (0.0724)  time: 0.6787  data: 0.2941  max mem: 5067\n",
      "Training Epoch: [24]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1490 (0.1520)  loss_objectness: 0.0767 (0.0791)  loss_rpn_box_reg: 0.0694 (0.0729)  time: 0.6938  data: 0.2925  max mem: 5067\n",
      "Training Epoch: [24]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1579 (0.1524)  loss_objectness: 0.0774 (0.0793)  loss_rpn_box_reg: 0.0759 (0.0730)  time: 0.6843  data: 0.2907  max mem: 5067\n",
      "Training Epoch: [24]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1642 (0.1527)  loss_objectness: 0.0855 (0.0795)  loss_rpn_box_reg: 0.0738 (0.0732)  time: 0.6881  data: 0.2927  max mem: 5067\n",
      "Training Epoch: [24] Total time: 0:02:50 (0.6816 s / it)\n",
      "Testing Epoch: [24]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1311 (0.1311)  loss_objectness: 0.0431 (0.0431)  loss_rpn_box_reg: 0.0881 (0.0881)  time: 0.7102  data: 0.3791  max mem: 5067\n",
      "Testing Epoch: [24]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1254 (0.1349)  loss_objectness: 0.0528 (0.0560)  loss_rpn_box_reg: 0.0728 (0.0789)  time: 0.6293  data: 0.3077  max mem: 5067\n",
      "Testing Epoch: [24] Total time: 0:00:39 (0.6326 s / it)\n",
      "Training Epoch: [25]  [  0/250]  eta: 0:03:04  lr: 0.000300  loss: 0.1601 (0.1601)  loss_objectness: 0.0634 (0.0634)  loss_rpn_box_reg: 0.0967 (0.0967)  time: 0.7372  data: 0.2781  max mem: 5067\n",
      "Training Epoch: [25]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1363 (0.1469)  loss_objectness: 0.0662 (0.0699)  loss_rpn_box_reg: 0.0691 (0.0770)  time: 0.6979  data: 0.2890  max mem: 5067\n",
      "Training Epoch: [25]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1311 (0.1425)  loss_objectness: 0.0662 (0.0677)  loss_rpn_box_reg: 0.0652 (0.0749)  time: 0.6828  data: 0.2892  max mem: 5067\n",
      "Training Epoch: [25]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1311 (0.1434)  loss_objectness: 0.0724 (0.0714)  loss_rpn_box_reg: 0.0595 (0.0720)  time: 0.6697  data: 0.2868  max mem: 5067\n",
      "Training Epoch: [25]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1476 (0.1485)  loss_objectness: 0.0798 (0.0742)  loss_rpn_box_reg: 0.0679 (0.0743)  time: 0.6848  data: 0.2884  max mem: 5067\n",
      "Training Epoch: [25]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1510 (0.1490)  loss_objectness: 0.0846 (0.0753)  loss_rpn_box_reg: 0.0713 (0.0736)  time: 0.6884  data: 0.2925  max mem: 5067\n",
      "Training Epoch: [25]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1467 (0.1476)  loss_objectness: 0.0846 (0.0760)  loss_rpn_box_reg: 0.0591 (0.0715)  time: 0.6761  data: 0.2923  max mem: 5067\n",
      "Training Epoch: [25]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1354 (0.1461)  loss_objectness: 0.0792 (0.0754)  loss_rpn_box_reg: 0.0562 (0.0707)  time: 0.6789  data: 0.2918  max mem: 5067\n",
      "Training Epoch: [25]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1414 (0.1473)  loss_objectness: 0.0703 (0.0756)  loss_rpn_box_reg: 0.0711 (0.0717)  time: 0.6879  data: 0.2895  max mem: 5067\n",
      "Training Epoch: [25]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1439 (0.1463)  loss_objectness: 0.0757 (0.0756)  loss_rpn_box_reg: 0.0688 (0.0707)  time: 0.6906  data: 0.2886  max mem: 5067\n",
      "Training Epoch: [25]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1365 (0.1458)  loss_objectness: 0.0756 (0.0755)  loss_rpn_box_reg: 0.0661 (0.0702)  time: 0.6843  data: 0.2908  max mem: 5067\n",
      "Training Epoch: [25]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1491 (0.1471)  loss_objectness: 0.0695 (0.0759)  loss_rpn_box_reg: 0.0693 (0.0712)  time: 0.6963  data: 0.2949  max mem: 5067\n",
      "Training Epoch: [25]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1583 (0.1475)  loss_objectness: 0.0753 (0.0769)  loss_rpn_box_reg: 0.0719 (0.0707)  time: 0.7026  data: 0.2979  max mem: 5067\n",
      "Training Epoch: [25]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1596 (0.1489)  loss_objectness: 0.0906 (0.0780)  loss_rpn_box_reg: 0.0639 (0.0709)  time: 0.6816  data: 0.2931  max mem: 5067\n",
      "Training Epoch: [25]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1594 (0.1483)  loss_objectness: 0.0774 (0.0773)  loss_rpn_box_reg: 0.0676 (0.0710)  time: 0.6672  data: 0.2893  max mem: 5067\n",
      "Training Epoch: [25]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1571 (0.1492)  loss_objectness: 0.0726 (0.0775)  loss_rpn_box_reg: 0.0773 (0.0717)  time: 0.6798  data: 0.2918  max mem: 5067\n",
      "Training Epoch: [25]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1469 (0.1486)  loss_objectness: 0.0698 (0.0769)  loss_rpn_box_reg: 0.0754 (0.0716)  time: 0.6854  data: 0.2912  max mem: 5067\n",
      "Training Epoch: [25]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1535 (0.1496)  loss_objectness: 0.0682 (0.0772)  loss_rpn_box_reg: 0.0672 (0.0724)  time: 0.6768  data: 0.2898  max mem: 5067\n",
      "Training Epoch: [25]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1584 (0.1495)  loss_objectness: 0.0751 (0.0771)  loss_rpn_box_reg: 0.0692 (0.0724)  time: 0.6792  data: 0.2906  max mem: 5067\n",
      "Training Epoch: [25]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1548 (0.1500)  loss_objectness: 0.0749 (0.0772)  loss_rpn_box_reg: 0.0692 (0.0728)  time: 0.6784  data: 0.2894  max mem: 5067\n",
      "Training Epoch: [25]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1538 (0.1497)  loss_objectness: 0.0749 (0.0773)  loss_rpn_box_reg: 0.0644 (0.0724)  time: 0.6659  data: 0.2902  max mem: 5067\n",
      "Training Epoch: [25]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1510 (0.1501)  loss_objectness: 0.0817 (0.0776)  loss_rpn_box_reg: 0.0636 (0.0725)  time: 0.6656  data: 0.2901  max mem: 5067\n",
      "Training Epoch: [25]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1510 (0.1502)  loss_objectness: 0.0809 (0.0777)  loss_rpn_box_reg: 0.0606 (0.0725)  time: 0.6859  data: 0.2894  max mem: 5067\n",
      "Training Epoch: [25]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1525 (0.1503)  loss_objectness: 0.0766 (0.0778)  loss_rpn_box_reg: 0.0644 (0.0724)  time: 0.7005  data: 0.2933  max mem: 5067\n",
      "Training Epoch: [25]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1412 (0.1498)  loss_objectness: 0.0766 (0.0781)  loss_rpn_box_reg: 0.0615 (0.0717)  time: 0.6954  data: 0.2902  max mem: 5067\n",
      "Training Epoch: [25]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1570 (0.1509)  loss_objectness: 0.0814 (0.0782)  loss_rpn_box_reg: 0.0635 (0.0726)  time: 0.6977  data: 0.2887  max mem: 5067\n",
      "Training Epoch: [25] Total time: 0:02:51 (0.6841 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:04  model_time: 0.5991 (0.5991)  evaluator_time: 0.0440 (0.0440)  time: 1.0352  data: 0.3771  max mem: 5067\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3561 (0.3550)  evaluator_time: 0.0520 (0.0585)  time: 0.7154  data: 0.2984  max mem: 5067\n",
      "Test: Total time: 0:00:44 (0.7220 s / it)\n",
      "Averaged stats: model_time: 0.3561 (0.3550)  evaluator_time: 0.0520 (0.0585)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.86s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.037\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.145\n",
      "Testing Epoch: [25]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1341 (0.1341)  loss_objectness: 0.0490 (0.0490)  loss_rpn_box_reg: 0.0851 (0.0851)  time: 0.6171  data: 0.2881  max mem: 5067\n",
      "Testing Epoch: [25]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1282 (0.1366)  loss_objectness: 0.0588 (0.0602)  loss_rpn_box_reg: 0.0683 (0.0764)  time: 0.6280  data: 0.3039  max mem: 5067\n",
      "Testing Epoch: [25] Total time: 0:00:39 (0.6342 s / it)\n",
      "Training Epoch: [26]  [  0/250]  eta: 0:03:11  lr: 0.000300  loss: 0.1326 (0.1326)  loss_objectness: 0.0922 (0.0922)  loss_rpn_box_reg: 0.0404 (0.0404)  time: 0.7672  data: 0.3111  max mem: 5067\n",
      "Training Epoch: [26]  [ 10/250]  eta: 0:02:48  lr: 0.000300  loss: 0.1497 (0.1514)  loss_objectness: 0.0774 (0.0806)  loss_rpn_box_reg: 0.0625 (0.0708)  time: 0.7027  data: 0.3008  max mem: 5067\n",
      "Training Epoch: [26]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1260 (0.1373)  loss_objectness: 0.0742 (0.0764)  loss_rpn_box_reg: 0.0527 (0.0609)  time: 0.6963  data: 0.2923  max mem: 5067\n",
      "Training Epoch: [26]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1241 (0.1450)  loss_objectness: 0.0753 (0.0795)  loss_rpn_box_reg: 0.0509 (0.0655)  time: 0.6907  data: 0.2871  max mem: 5067\n",
      "Training Epoch: [26]  [ 40/250]  eta: 0:02:26  lr: 0.000300  loss: 0.1567 (0.1458)  loss_objectness: 0.0786 (0.0787)  loss_rpn_box_reg: 0.0783 (0.0671)  time: 0.6998  data: 0.2921  max mem: 5067\n",
      "Training Epoch: [26]  [ 50/250]  eta: 0:02:19  lr: 0.000300  loss: 0.1372 (0.1461)  loss_objectness: 0.0687 (0.0769)  loss_rpn_box_reg: 0.0724 (0.0692)  time: 0.6959  data: 0.2911  max mem: 5067\n",
      "Training Epoch: [26]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1370 (0.1460)  loss_objectness: 0.0680 (0.0764)  loss_rpn_box_reg: 0.0726 (0.0696)  time: 0.6829  data: 0.2878  max mem: 5067\n",
      "Training Epoch: [26]  [ 70/250]  eta: 0:02:05  lr: 0.000300  loss: 0.1355 (0.1441)  loss_objectness: 0.0714 (0.0760)  loss_rpn_box_reg: 0.0633 (0.0681)  time: 0.6941  data: 0.2903  max mem: 5067\n",
      "Training Epoch: [26]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1370 (0.1455)  loss_objectness: 0.0751 (0.0763)  loss_rpn_box_reg: 0.0633 (0.0692)  time: 0.6883  data: 0.2893  max mem: 5067\n",
      "Training Epoch: [26]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1544 (0.1474)  loss_objectness: 0.0815 (0.0779)  loss_rpn_box_reg: 0.0737 (0.0695)  time: 0.6733  data: 0.2904  max mem: 5067\n",
      "Training Epoch: [26]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1624 (0.1482)  loss_objectness: 0.0821 (0.0781)  loss_rpn_box_reg: 0.0686 (0.0701)  time: 0.6743  data: 0.2922  max mem: 5067\n",
      "Training Epoch: [26]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1393 (0.1478)  loss_objectness: 0.0740 (0.0779)  loss_rpn_box_reg: 0.0665 (0.0699)  time: 0.6880  data: 0.2904  max mem: 5067\n",
      "Training Epoch: [26]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1454 (0.1482)  loss_objectness: 0.0750 (0.0778)  loss_rpn_box_reg: 0.0677 (0.0704)  time: 0.7059  data: 0.2978  max mem: 5067\n",
      "Training Epoch: [26]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1513 (0.1488)  loss_objectness: 0.0761 (0.0779)  loss_rpn_box_reg: 0.0679 (0.0709)  time: 0.6893  data: 0.2993  max mem: 5067\n",
      "Training Epoch: [26]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1386 (0.1486)  loss_objectness: 0.0818 (0.0782)  loss_rpn_box_reg: 0.0565 (0.0705)  time: 0.6827  data: 0.2946  max mem: 5067\n",
      "Training Epoch: [26]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1352 (0.1489)  loss_objectness: 0.0732 (0.0778)  loss_rpn_box_reg: 0.0691 (0.0711)  time: 0.6817  data: 0.2943  max mem: 5067\n",
      "Training Epoch: [26]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1349 (0.1481)  loss_objectness: 0.0661 (0.0777)  loss_rpn_box_reg: 0.0685 (0.0704)  time: 0.6658  data: 0.2931  max mem: 5067\n",
      "Training Epoch: [26]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1349 (0.1475)  loss_objectness: 0.0720 (0.0775)  loss_rpn_box_reg: 0.0565 (0.0700)  time: 0.6791  data: 0.2919  max mem: 5067\n",
      "Training Epoch: [26]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1376 (0.1472)  loss_objectness: 0.0702 (0.0773)  loss_rpn_box_reg: 0.0643 (0.0699)  time: 0.6962  data: 0.2944  max mem: 5067\n",
      "Training Epoch: [26]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1432 (0.1480)  loss_objectness: 0.0821 (0.0777)  loss_rpn_box_reg: 0.0667 (0.0703)  time: 0.6984  data: 0.2934  max mem: 5067\n",
      "Training Epoch: [26]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1626 (0.1488)  loss_objectness: 0.0897 (0.0784)  loss_rpn_box_reg: 0.0678 (0.0704)  time: 0.6972  data: 0.2898  max mem: 5067\n",
      "Training Epoch: [26]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1626 (0.1498)  loss_objectness: 0.0843 (0.0786)  loss_rpn_box_reg: 0.0678 (0.0712)  time: 0.6966  data: 0.2916  max mem: 5067\n",
      "Training Epoch: [26]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1542 (0.1502)  loss_objectness: 0.0737 (0.0782)  loss_rpn_box_reg: 0.0939 (0.0720)  time: 0.6861  data: 0.2935  max mem: 5067\n",
      "Training Epoch: [26]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1489 (0.1501)  loss_objectness: 0.0765 (0.0783)  loss_rpn_box_reg: 0.0724 (0.0718)  time: 0.6762  data: 0.2936  max mem: 5067\n",
      "Training Epoch: [26]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1475 (0.1501)  loss_objectness: 0.0776 (0.0785)  loss_rpn_box_reg: 0.0680 (0.0716)  time: 0.6845  data: 0.2919  max mem: 5067\n",
      "Training Epoch: [26]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1475 (0.1505)  loss_objectness: 0.0754 (0.0784)  loss_rpn_box_reg: 0.0720 (0.0722)  time: 0.7075  data: 0.2929  max mem: 5067\n",
      "Training Epoch: [26] Total time: 0:02:52 (0.6899 s / it)\n",
      "Testing Epoch: [26]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1317 (0.1317)  loss_objectness: 0.0460 (0.0460)  loss_rpn_box_reg: 0.0857 (0.0857)  time: 0.7112  data: 0.3841  max mem: 5067\n",
      "Testing Epoch: [26]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1218 (0.1343)  loss_objectness: 0.0549 (0.0562)  loss_rpn_box_reg: 0.0656 (0.0781)  time: 0.6365  data: 0.3107  max mem: 5067\n",
      "Testing Epoch: [26] Total time: 0:00:39 (0.6363 s / it)\n",
      "Training Epoch: [27]  [  0/250]  eta: 0:03:01  lr: 0.000300  loss: 0.1539 (0.1539)  loss_objectness: 0.0976 (0.0976)  loss_rpn_box_reg: 0.0563 (0.0563)  time: 0.7272  data: 0.3101  max mem: 5067\n",
      "Training Epoch: [27]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1328 (0.1369)  loss_objectness: 0.0701 (0.0730)  loss_rpn_box_reg: 0.0563 (0.0638)  time: 0.6959  data: 0.2969  max mem: 5067\n",
      "Training Epoch: [27]  [ 20/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1279 (0.1384)  loss_objectness: 0.0665 (0.0707)  loss_rpn_box_reg: 0.0630 (0.0677)  time: 0.6996  data: 0.2925  max mem: 5067\n",
      "Training Epoch: [27]  [ 30/250]  eta: 0:02:33  lr: 0.000300  loss: 0.1493 (0.1420)  loss_objectness: 0.0676 (0.0720)  loss_rpn_box_reg: 0.0724 (0.0701)  time: 0.6962  data: 0.2911  max mem: 5067\n",
      "Training Epoch: [27]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1434 (0.1415)  loss_objectness: 0.0688 (0.0719)  loss_rpn_box_reg: 0.0669 (0.0696)  time: 0.6683  data: 0.2909  max mem: 5067\n",
      "Training Epoch: [27]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1331 (0.1428)  loss_objectness: 0.0658 (0.0724)  loss_rpn_box_reg: 0.0716 (0.0704)  time: 0.6664  data: 0.2872  max mem: 5067\n",
      "Training Epoch: [27]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1349 (0.1433)  loss_objectness: 0.0677 (0.0719)  loss_rpn_box_reg: 0.0722 (0.0714)  time: 0.6913  data: 0.2896  max mem: 5067\n",
      "Training Epoch: [27]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1412 (0.1434)  loss_objectness: 0.0696 (0.0720)  loss_rpn_box_reg: 0.0713 (0.0714)  time: 0.6947  data: 0.2905  max mem: 5067\n",
      "Training Epoch: [27]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1549 (0.1450)  loss_objectness: 0.0812 (0.0737)  loss_rpn_box_reg: 0.0671 (0.0713)  time: 0.6937  data: 0.2925  max mem: 5067\n",
      "Training Epoch: [27]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1582 (0.1455)  loss_objectness: 0.0803 (0.0747)  loss_rpn_box_reg: 0.0666 (0.0708)  time: 0.7005  data: 0.2934  max mem: 5067\n",
      "Training Epoch: [27]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1449 (0.1456)  loss_objectness: 0.0803 (0.0752)  loss_rpn_box_reg: 0.0668 (0.0704)  time: 0.7037  data: 0.2887  max mem: 5067\n",
      "Training Epoch: [27]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1449 (0.1451)  loss_objectness: 0.0768 (0.0750)  loss_rpn_box_reg: 0.0680 (0.0701)  time: 0.7013  data: 0.2913  max mem: 5067\n",
      "Training Epoch: [27]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1396 (0.1448)  loss_objectness: 0.0738 (0.0751)  loss_rpn_box_reg: 0.0674 (0.0697)  time: 0.6870  data: 0.2957  max mem: 5067\n",
      "Training Epoch: [27]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1590 (0.1461)  loss_objectness: 0.0738 (0.0756)  loss_rpn_box_reg: 0.0706 (0.0705)  time: 0.6845  data: 0.2977  max mem: 5067\n",
      "Training Epoch: [27]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1512 (0.1457)  loss_objectness: 0.0750 (0.0755)  loss_rpn_box_reg: 0.0661 (0.0703)  time: 0.6870  data: 0.2940  max mem: 5067\n",
      "Training Epoch: [27]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1421 (0.1459)  loss_objectness: 0.0749 (0.0756)  loss_rpn_box_reg: 0.0649 (0.0703)  time: 0.6851  data: 0.2907  max mem: 5067\n",
      "Training Epoch: [27]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1373 (0.1453)  loss_objectness: 0.0746 (0.0754)  loss_rpn_box_reg: 0.0640 (0.0699)  time: 0.6875  data: 0.2918  max mem: 5067\n",
      "Training Epoch: [27]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1346 (0.1453)  loss_objectness: 0.0735 (0.0753)  loss_rpn_box_reg: 0.0656 (0.0700)  time: 0.7020  data: 0.2893  max mem: 5067\n",
      "Training Epoch: [27]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1392 (0.1458)  loss_objectness: 0.0700 (0.0750)  loss_rpn_box_reg: 0.0719 (0.0708)  time: 0.6969  data: 0.2893  max mem: 5067\n",
      "Training Epoch: [27]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1464 (0.1459)  loss_objectness: 0.0690 (0.0749)  loss_rpn_box_reg: 0.0735 (0.0710)  time: 0.6773  data: 0.2923  max mem: 5067\n",
      "Training Epoch: [27]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1618 (0.1471)  loss_objectness: 0.0748 (0.0753)  loss_rpn_box_reg: 0.0819 (0.0718)  time: 0.6791  data: 0.2938  max mem: 5067\n",
      "Training Epoch: [27]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1624 (0.1476)  loss_objectness: 0.0803 (0.0758)  loss_rpn_box_reg: 0.0775 (0.0718)  time: 0.6786  data: 0.2931  max mem: 5067\n",
      "Training Epoch: [27]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1563 (0.1478)  loss_objectness: 0.0870 (0.0760)  loss_rpn_box_reg: 0.0664 (0.0717)  time: 0.6749  data: 0.2936  max mem: 5067\n",
      "Training Epoch: [27]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1464 (0.1478)  loss_objectness: 0.0813 (0.0760)  loss_rpn_box_reg: 0.0664 (0.0717)  time: 0.6755  data: 0.2964  max mem: 5067\n",
      "Training Epoch: [27]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1525 (0.1485)  loss_objectness: 0.0813 (0.0765)  loss_rpn_box_reg: 0.0663 (0.0720)  time: 0.6862  data: 0.2920  max mem: 5067\n",
      "Training Epoch: [27]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1525 (0.1484)  loss_objectness: 0.0783 (0.0764)  loss_rpn_box_reg: 0.0664 (0.0720)  time: 0.6801  data: 0.2899  max mem: 5067\n",
      "Training Epoch: [27] Total time: 0:02:51 (0.6871 s / it)\n",
      "Testing Epoch: [27]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1396 (0.1396)  loss_objectness: 0.0485 (0.0485)  loss_rpn_box_reg: 0.0911 (0.0911)  time: 0.6191  data: 0.2951  max mem: 5067\n",
      "Testing Epoch: [27]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1266 (0.1393)  loss_objectness: 0.0547 (0.0587)  loss_rpn_box_reg: 0.0737 (0.0806)  time: 0.6374  data: 0.3099  max mem: 5067\n",
      "Testing Epoch: [27] Total time: 0:00:39 (0.6348 s / it)\n",
      "Training Epoch: [28]  [  0/250]  eta: 0:02:48  lr: 0.000300  loss: 0.1412 (0.1412)  loss_objectness: 0.0737 (0.0737)  loss_rpn_box_reg: 0.0675 (0.0675)  time: 0.6732  data: 0.2981  max mem: 5067\n",
      "Training Epoch: [28]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1412 (0.1503)  loss_objectness: 0.0778 (0.0793)  loss_rpn_box_reg: 0.0712 (0.0710)  time: 0.6712  data: 0.2940  max mem: 5067\n",
      "Training Epoch: [28]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1382 (0.1488)  loss_objectness: 0.0778 (0.0784)  loss_rpn_box_reg: 0.0712 (0.0704)  time: 0.6913  data: 0.2946  max mem: 5067\n",
      "Training Epoch: [28]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1428 (0.1474)  loss_objectness: 0.0731 (0.0762)  loss_rpn_box_reg: 0.0734 (0.0712)  time: 0.6995  data: 0.2972  max mem: 5067\n",
      "Training Epoch: [28]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1528 (0.1526)  loss_objectness: 0.0778 (0.0784)  loss_rpn_box_reg: 0.0769 (0.0743)  time: 0.6934  data: 0.2981  max mem: 5067\n",
      "Training Epoch: [28]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1339 (0.1476)  loss_objectness: 0.0754 (0.0766)  loss_rpn_box_reg: 0.0705 (0.0710)  time: 0.6746  data: 0.2870  max mem: 5067\n",
      "Training Epoch: [28]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1221 (0.1450)  loss_objectness: 0.0656 (0.0757)  loss_rpn_box_reg: 0.0515 (0.0694)  time: 0.6630  data: 0.2858  max mem: 5067\n",
      "Training Epoch: [28]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1428 (0.1469)  loss_objectness: 0.0792 (0.0770)  loss_rpn_box_reg: 0.0611 (0.0699)  time: 0.6777  data: 0.2937  max mem: 5067\n",
      "Training Epoch: [28]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1528 (0.1477)  loss_objectness: 0.0846 (0.0775)  loss_rpn_box_reg: 0.0677 (0.0701)  time: 0.6817  data: 0.2928  max mem: 5067\n",
      "Training Epoch: [28]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1473 (0.1485)  loss_objectness: 0.0754 (0.0771)  loss_rpn_box_reg: 0.0789 (0.0714)  time: 0.6866  data: 0.2915  max mem: 5067\n",
      "Training Epoch: [28]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1407 (0.1481)  loss_objectness: 0.0712 (0.0772)  loss_rpn_box_reg: 0.0730 (0.0709)  time: 0.6865  data: 0.2874  max mem: 5067\n",
      "Training Epoch: [28]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1407 (0.1493)  loss_objectness: 0.0780 (0.0778)  loss_rpn_box_reg: 0.0623 (0.0715)  time: 0.6982  data: 0.2921  max mem: 5067\n",
      "Training Epoch: [28]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1472 (0.1498)  loss_objectness: 0.0782 (0.0787)  loss_rpn_box_reg: 0.0621 (0.0711)  time: 0.6754  data: 0.2964  max mem: 5067\n",
      "Training Epoch: [28]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1559 (0.1516)  loss_objectness: 0.0875 (0.0793)  loss_rpn_box_reg: 0.0736 (0.0723)  time: 0.6634  data: 0.2935  max mem: 5067\n",
      "Training Epoch: [28]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1393 (0.1502)  loss_objectness: 0.0765 (0.0786)  loss_rpn_box_reg: 0.0636 (0.0715)  time: 0.6821  data: 0.2912  max mem: 5067\n",
      "Training Epoch: [28]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1256 (0.1487)  loss_objectness: 0.0718 (0.0782)  loss_rpn_box_reg: 0.0506 (0.0705)  time: 0.6668  data: 0.2913  max mem: 5067\n",
      "Training Epoch: [28]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1390 (0.1486)  loss_objectness: 0.0747 (0.0781)  loss_rpn_box_reg: 0.0558 (0.0705)  time: 0.6756  data: 0.2900  max mem: 5067\n",
      "Training Epoch: [28]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1466 (0.1485)  loss_objectness: 0.0769 (0.0783)  loss_rpn_box_reg: 0.0685 (0.0703)  time: 0.6953  data: 0.2892  max mem: 5067\n",
      "Training Epoch: [28]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1432 (0.1486)  loss_objectness: 0.0690 (0.0775)  loss_rpn_box_reg: 0.0733 (0.0710)  time: 0.6957  data: 0.2912  max mem: 5067\n",
      "Training Epoch: [28]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1383 (0.1482)  loss_objectness: 0.0650 (0.0769)  loss_rpn_box_reg: 0.0694 (0.0713)  time: 0.6839  data: 0.2907  max mem: 5067\n",
      "Training Epoch: [28]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1343 (0.1480)  loss_objectness: 0.0671 (0.0768)  loss_rpn_box_reg: 0.0667 (0.0711)  time: 0.6959  data: 0.2936  max mem: 5067\n",
      "Training Epoch: [28]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1453 (0.1491)  loss_objectness: 0.0837 (0.0776)  loss_rpn_box_reg: 0.0720 (0.0716)  time: 0.6984  data: 0.2941  max mem: 5067\n",
      "Training Epoch: [28]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1631 (0.1494)  loss_objectness: 0.0798 (0.0775)  loss_rpn_box_reg: 0.0852 (0.0718)  time: 0.6737  data: 0.2911  max mem: 5067\n",
      "Training Epoch: [28]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1491 (0.1495)  loss_objectness: 0.0735 (0.0777)  loss_rpn_box_reg: 0.0803 (0.0719)  time: 0.6894  data: 0.2930  max mem: 5067\n",
      "Training Epoch: [28]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1527 (0.1499)  loss_objectness: 0.0793 (0.0779)  loss_rpn_box_reg: 0.0708 (0.0720)  time: 0.7045  data: 0.2941  max mem: 5067\n",
      "Training Epoch: [28]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1691 (0.1504)  loss_objectness: 0.0796 (0.0782)  loss_rpn_box_reg: 0.0775 (0.0722)  time: 0.6959  data: 0.2928  max mem: 5067\n",
      "Training Epoch: [28] Total time: 0:02:51 (0.6850 s / it)\n",
      "Testing Epoch: [28]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1353 (0.1353)  loss_objectness: 0.0501 (0.0501)  loss_rpn_box_reg: 0.0852 (0.0852)  time: 0.6141  data: 0.2801  max mem: 5067\n",
      "Testing Epoch: [28]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1372 (0.1409)  loss_objectness: 0.0585 (0.0614)  loss_rpn_box_reg: 0.0721 (0.0795)  time: 0.6382  data: 0.3115  max mem: 5067\n",
      "Testing Epoch: [28] Total time: 0:00:39 (0.6365 s / it)\n",
      "Training Epoch: [29]  [  0/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1225 (0.1225)  loss_objectness: 0.0839 (0.0839)  loss_rpn_box_reg: 0.0386 (0.0386)  time: 0.6191  data: 0.3001  max mem: 5067\n",
      "Training Epoch: [29]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1283 (0.1367)  loss_objectness: 0.0787 (0.0791)  loss_rpn_box_reg: 0.0523 (0.0575)  time: 0.6740  data: 0.2947  max mem: 5067\n",
      "Training Epoch: [29]  [ 20/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1283 (0.1377)  loss_objectness: 0.0666 (0.0744)  loss_rpn_box_reg: 0.0562 (0.0633)  time: 0.6806  data: 0.2928  max mem: 5067\n",
      "Training Epoch: [29]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1450 (0.1435)  loss_objectness: 0.0668 (0.0745)  loss_rpn_box_reg: 0.0790 (0.0690)  time: 0.6814  data: 0.2931  max mem: 5067\n",
      "Training Epoch: [29]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1582 (0.1483)  loss_objectness: 0.0679 (0.0762)  loss_rpn_box_reg: 0.0825 (0.0720)  time: 0.6832  data: 0.2932  max mem: 5067\n",
      "Training Epoch: [29]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1582 (0.1520)  loss_objectness: 0.0728 (0.0779)  loss_rpn_box_reg: 0.0838 (0.0741)  time: 0.6807  data: 0.2939  max mem: 5067\n",
      "Training Epoch: [29]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1580 (0.1507)  loss_objectness: 0.0774 (0.0786)  loss_rpn_box_reg: 0.0752 (0.0721)  time: 0.7073  data: 0.2951  max mem: 5067\n",
      "Training Epoch: [29]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1271 (0.1481)  loss_objectness: 0.0762 (0.0779)  loss_rpn_box_reg: 0.0528 (0.0702)  time: 0.7144  data: 0.2998  max mem: 5067\n",
      "Training Epoch: [29]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1400 (0.1489)  loss_objectness: 0.0720 (0.0780)  loss_rpn_box_reg: 0.0682 (0.0710)  time: 0.6861  data: 0.2994  max mem: 5067\n",
      "Training Epoch: [29]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1494 (0.1491)  loss_objectness: 0.0738 (0.0782)  loss_rpn_box_reg: 0.0698 (0.0709)  time: 0.6840  data: 0.2941  max mem: 5067\n",
      "Training Epoch: [29]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1447 (0.1489)  loss_objectness: 0.0811 (0.0790)  loss_rpn_box_reg: 0.0622 (0.0699)  time: 0.6758  data: 0.2926  max mem: 5067\n",
      "Training Epoch: [29]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1451 (0.1490)  loss_objectness: 0.0767 (0.0789)  loss_rpn_box_reg: 0.0660 (0.0700)  time: 0.6662  data: 0.2928  max mem: 5067\n",
      "Training Epoch: [29]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1409 (0.1478)  loss_objectness: 0.0665 (0.0777)  loss_rpn_box_reg: 0.0678 (0.0701)  time: 0.6764  data: 0.2941  max mem: 5067\n",
      "Training Epoch: [29]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1425 (0.1490)  loss_objectness: 0.0682 (0.0788)  loss_rpn_box_reg: 0.0697 (0.0702)  time: 0.6842  data: 0.2955  max mem: 5067\n",
      "Training Epoch: [29]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1651 (0.1500)  loss_objectness: 0.0866 (0.0792)  loss_rpn_box_reg: 0.0718 (0.0708)  time: 0.6743  data: 0.2954  max mem: 5067\n",
      "Training Epoch: [29]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1572 (0.1500)  loss_objectness: 0.0844 (0.0791)  loss_rpn_box_reg: 0.0711 (0.0709)  time: 0.6776  data: 0.2935  max mem: 5067\n",
      "Training Epoch: [29]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1523 (0.1493)  loss_objectness: 0.0765 (0.0785)  loss_rpn_box_reg: 0.0699 (0.0708)  time: 0.6900  data: 0.2919  max mem: 5067\n",
      "Training Epoch: [29]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1377 (0.1489)  loss_objectness: 0.0675 (0.0782)  loss_rpn_box_reg: 0.0701 (0.0707)  time: 0.6926  data: 0.2919  max mem: 5067\n",
      "Training Epoch: [29]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1377 (0.1488)  loss_objectness: 0.0758 (0.0782)  loss_rpn_box_reg: 0.0695 (0.0706)  time: 0.6969  data: 0.2917  max mem: 5067\n",
      "Training Epoch: [29]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1541 (0.1496)  loss_objectness: 0.0829 (0.0783)  loss_rpn_box_reg: 0.0695 (0.0713)  time: 0.7027  data: 0.2919  max mem: 5067\n",
      "Training Epoch: [29]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1633 (0.1507)  loss_objectness: 0.0834 (0.0788)  loss_rpn_box_reg: 0.0757 (0.0719)  time: 0.6972  data: 0.2927  max mem: 5067\n",
      "Training Epoch: [29]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1649 (0.1512)  loss_objectness: 0.0816 (0.0789)  loss_rpn_box_reg: 0.0768 (0.0723)  time: 0.6828  data: 0.2902  max mem: 5067\n",
      "Training Epoch: [29]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1348 (0.1507)  loss_objectness: 0.0692 (0.0786)  loss_rpn_box_reg: 0.0694 (0.0721)  time: 0.6747  data: 0.2886  max mem: 5067\n",
      "Training Epoch: [29]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1348 (0.1509)  loss_objectness: 0.0691 (0.0787)  loss_rpn_box_reg: 0.0694 (0.0722)  time: 0.6689  data: 0.2887  max mem: 5067\n",
      "Training Epoch: [29]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1502 (0.1510)  loss_objectness: 0.0791 (0.0790)  loss_rpn_box_reg: 0.0729 (0.0720)  time: 0.6854  data: 0.2951  max mem: 5067\n",
      "Training Epoch: [29]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1418 (0.1508)  loss_objectness: 0.0791 (0.0788)  loss_rpn_box_reg: 0.0741 (0.0720)  time: 0.6827  data: 0.2962  max mem: 5067\n",
      "Training Epoch: [29] Total time: 0:02:51 (0.6845 s / it)\n",
      "Testing Epoch: [29]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1317 (0.1317)  loss_objectness: 0.0429 (0.0429)  loss_rpn_box_reg: 0.0889 (0.0889)  time: 0.7172  data: 0.3931  max mem: 5067\n",
      "Testing Epoch: [29]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1308 (0.1393)  loss_objectness: 0.0565 (0.0585)  loss_rpn_box_reg: 0.0735 (0.0808)  time: 0.6385  data: 0.3110  max mem: 5067\n",
      "Testing Epoch: [29] Total time: 0:00:39 (0.6391 s / it)\n",
      "Training Epoch: [30]  [  0/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1562 (0.1562)  loss_objectness: 0.0931 (0.0931)  loss_rpn_box_reg: 0.0632 (0.0632)  time: 0.6191  data: 0.2931  max mem: 5067\n",
      "Training Epoch: [30]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1462 (0.1529)  loss_objectness: 0.0695 (0.0736)  loss_rpn_box_reg: 0.0795 (0.0793)  time: 0.6827  data: 0.2952  max mem: 5067\n",
      "Training Epoch: [30]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1390 (0.1503)  loss_objectness: 0.0695 (0.0750)  loss_rpn_box_reg: 0.0723 (0.0752)  time: 0.6930  data: 0.2938  max mem: 5067\n",
      "Training Epoch: [30]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1500 (0.1501)  loss_objectness: 0.0695 (0.0747)  loss_rpn_box_reg: 0.0758 (0.0753)  time: 0.6839  data: 0.2920  max mem: 5067\n",
      "Training Epoch: [30]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1500 (0.1488)  loss_objectness: 0.0649 (0.0731)  loss_rpn_box_reg: 0.0758 (0.0758)  time: 0.6781  data: 0.2913  max mem: 5067\n",
      "Training Epoch: [30]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1395 (0.1485)  loss_objectness: 0.0706 (0.0738)  loss_rpn_box_reg: 0.0649 (0.0747)  time: 0.6812  data: 0.2881  max mem: 5067\n",
      "Training Epoch: [30]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1413 (0.1482)  loss_objectness: 0.0762 (0.0743)  loss_rpn_box_reg: 0.0572 (0.0739)  time: 0.6905  data: 0.2896  max mem: 5067\n",
      "Training Epoch: [30]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1422 (0.1484)  loss_objectness: 0.0742 (0.0747)  loss_rpn_box_reg: 0.0629 (0.0737)  time: 0.6984  data: 0.2919  max mem: 5067\n",
      "Training Epoch: [30]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1483 (0.1499)  loss_objectness: 0.0753 (0.0758)  loss_rpn_box_reg: 0.0693 (0.0741)  time: 0.6716  data: 0.2941  max mem: 5067\n",
      "Training Epoch: [30]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1523 (0.1502)  loss_objectness: 0.0753 (0.0757)  loss_rpn_box_reg: 0.0775 (0.0745)  time: 0.6820  data: 0.2995  max mem: 5067\n",
      "Training Epoch: [30]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1488 (0.1491)  loss_objectness: 0.0755 (0.0756)  loss_rpn_box_reg: 0.0722 (0.0736)  time: 0.7229  data: 0.3063  max mem: 5067\n",
      "Training Epoch: [30]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1346 (0.1480)  loss_objectness: 0.0758 (0.0756)  loss_rpn_box_reg: 0.0599 (0.0723)  time: 0.7078  data: 0.3030  max mem: 5067\n",
      "Training Epoch: [30]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1405 (0.1476)  loss_objectness: 0.0758 (0.0760)  loss_rpn_box_reg: 0.0627 (0.0715)  time: 0.6900  data: 0.2938  max mem: 5067\n",
      "Training Epoch: [30]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1456 (0.1471)  loss_objectness: 0.0739 (0.0757)  loss_rpn_box_reg: 0.0656 (0.0714)  time: 0.6952  data: 0.2917  max mem: 5067\n",
      "Training Epoch: [30]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1456 (0.1477)  loss_objectness: 0.0749 (0.0763)  loss_rpn_box_reg: 0.0656 (0.0714)  time: 0.6871  data: 0.2916  max mem: 5067\n",
      "Training Epoch: [30]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1353 (0.1470)  loss_objectness: 0.0757 (0.0761)  loss_rpn_box_reg: 0.0610 (0.0709)  time: 0.6800  data: 0.2899  max mem: 5067\n",
      "Training Epoch: [30]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1239 (0.1468)  loss_objectness: 0.0691 (0.0762)  loss_rpn_box_reg: 0.0613 (0.0707)  time: 0.6808  data: 0.2916  max mem: 5067\n",
      "Training Epoch: [30]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1370 (0.1472)  loss_objectness: 0.0743 (0.0766)  loss_rpn_box_reg: 0.0701 (0.0706)  time: 0.6850  data: 0.2966  max mem: 5067\n",
      "Training Epoch: [30]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1461 (0.1474)  loss_objectness: 0.0689 (0.0764)  loss_rpn_box_reg: 0.0698 (0.0710)  time: 0.6806  data: 0.2947  max mem: 5067\n",
      "Training Epoch: [30]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1404 (0.1479)  loss_objectness: 0.0702 (0.0767)  loss_rpn_box_reg: 0.0645 (0.0712)  time: 0.6874  data: 0.2949  max mem: 5067\n",
      "Training Epoch: [30]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1488 (0.1478)  loss_objectness: 0.0740 (0.0766)  loss_rpn_box_reg: 0.0672 (0.0712)  time: 0.7067  data: 0.2953  max mem: 5067\n",
      "Training Epoch: [30]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1529 (0.1485)  loss_objectness: 0.0771 (0.0768)  loss_rpn_box_reg: 0.0734 (0.0717)  time: 0.7017  data: 0.2957  max mem: 5067\n",
      "Training Epoch: [30]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1415 (0.1482)  loss_objectness: 0.0759 (0.0768)  loss_rpn_box_reg: 0.0672 (0.0715)  time: 0.6761  data: 0.2939  max mem: 5067\n",
      "Training Epoch: [30]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1396 (0.1484)  loss_objectness: 0.0700 (0.0768)  loss_rpn_box_reg: 0.0672 (0.0716)  time: 0.6876  data: 0.2888  max mem: 5067\n",
      "Training Epoch: [30]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1445 (0.1482)  loss_objectness: 0.0702 (0.0767)  loss_rpn_box_reg: 0.0685 (0.0715)  time: 0.6972  data: 0.2903  max mem: 5067\n",
      "Training Epoch: [30]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1523 (0.1487)  loss_objectness: 0.0715 (0.0767)  loss_rpn_box_reg: 0.0808 (0.0719)  time: 0.6819  data: 0.2932  max mem: 5067\n",
      "Training Epoch: [30] Total time: 0:02:52 (0.6893 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:00:59  model_time: 0.5281 (0.5281)  evaluator_time: 0.0470 (0.0470)  time: 0.9612  data: 0.3701  max mem: 5067\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3591 (0.3655)  evaluator_time: 0.0590 (0.0682)  time: 0.7394  data: 0.3059  max mem: 5067\n",
      "Test: Total time: 0:00:45 (0.7415 s / it)\n",
      "Averaged stats: model_time: 0.3591 (0.3655)  evaluator_time: 0.0590 (0.0682)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.95s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.099\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.023\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.158\n",
      "Testing Epoch: [30]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1372 (0.1372)  loss_objectness: 0.0490 (0.0490)  loss_rpn_box_reg: 0.0882 (0.0882)  time: 0.6121  data: 0.2861  max mem: 5067\n",
      "Testing Epoch: [30]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1271 (0.1385)  loss_objectness: 0.0560 (0.0598)  loss_rpn_box_reg: 0.0712 (0.0788)  time: 0.6325  data: 0.3137  max mem: 5067\n",
      "Testing Epoch: [30] Total time: 0:00:39 (0.6349 s / it)\n",
      "Training Epoch: [31]  [  0/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1560 (0.1560)  loss_objectness: 0.1022 (0.1022)  loss_rpn_box_reg: 0.0538 (0.0538)  time: 0.6712  data: 0.2941  max mem: 5067\n",
      "Training Epoch: [31]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1349 (0.1358)  loss_objectness: 0.0766 (0.0722)  loss_rpn_box_reg: 0.0699 (0.0636)  time: 0.6962  data: 0.2908  max mem: 5067\n",
      "Training Epoch: [31]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1332 (0.1400)  loss_objectness: 0.0723 (0.0735)  loss_rpn_box_reg: 0.0702 (0.0665)  time: 0.6943  data: 0.2927  max mem: 5067\n",
      "Training Epoch: [31]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1370 (0.1436)  loss_objectness: 0.0762 (0.0767)  loss_rpn_box_reg: 0.0673 (0.0669)  time: 0.6832  data: 0.2927  max mem: 5067\n",
      "Training Epoch: [31]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1440 (0.1432)  loss_objectness: 0.0777 (0.0761)  loss_rpn_box_reg: 0.0624 (0.0671)  time: 0.6755  data: 0.2912  max mem: 5067\n",
      "Training Epoch: [31]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1467 (0.1453)  loss_objectness: 0.0768 (0.0764)  loss_rpn_box_reg: 0.0629 (0.0689)  time: 0.6789  data: 0.2941  max mem: 5067\n",
      "Training Epoch: [31]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1456 (0.1449)  loss_objectness: 0.0784 (0.0765)  loss_rpn_box_reg: 0.0635 (0.0684)  time: 0.6810  data: 0.2923  max mem: 5067\n",
      "Training Epoch: [31]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1348 (0.1432)  loss_objectness: 0.0737 (0.0752)  loss_rpn_box_reg: 0.0589 (0.0680)  time: 0.6808  data: 0.2873  max mem: 5067\n",
      "Training Epoch: [31]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1441 (0.1444)  loss_objectness: 0.0737 (0.0757)  loss_rpn_box_reg: 0.0707 (0.0687)  time: 0.6909  data: 0.2897  max mem: 5067\n",
      "Training Epoch: [31]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1520 (0.1445)  loss_objectness: 0.0807 (0.0762)  loss_rpn_box_reg: 0.0755 (0.0683)  time: 0.6955  data: 0.2937  max mem: 5067\n",
      "Training Epoch: [31]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1444 (0.1448)  loss_objectness: 0.0800 (0.0771)  loss_rpn_box_reg: 0.0612 (0.0676)  time: 0.6902  data: 0.2939  max mem: 5067\n",
      "Training Epoch: [31]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1467 (0.1459)  loss_objectness: 0.0746 (0.0769)  loss_rpn_box_reg: 0.0716 (0.0690)  time: 0.6836  data: 0.2929  max mem: 5067\n",
      "Training Epoch: [31]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1476 (0.1459)  loss_objectness: 0.0742 (0.0766)  loss_rpn_box_reg: 0.0734 (0.0693)  time: 0.6844  data: 0.2966  max mem: 5067\n",
      "Training Epoch: [31]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1476 (0.1460)  loss_objectness: 0.0749 (0.0767)  loss_rpn_box_reg: 0.0676 (0.0693)  time: 0.7004  data: 0.3058  max mem: 5067\n",
      "Training Epoch: [31]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1553 (0.1476)  loss_objectness: 0.0687 (0.0771)  loss_rpn_box_reg: 0.0823 (0.0705)  time: 0.7041  data: 0.3091  max mem: 5067\n",
      "Training Epoch: [31]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1533 (0.1479)  loss_objectness: 0.0802 (0.0777)  loss_rpn_box_reg: 0.0731 (0.0702)  time: 0.6975  data: 0.3049  max mem: 5067\n",
      "Training Epoch: [31]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1533 (0.1495)  loss_objectness: 0.0841 (0.0784)  loss_rpn_box_reg: 0.0710 (0.0711)  time: 0.7001  data: 0.3036  max mem: 5067\n",
      "Training Epoch: [31]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1364 (0.1480)  loss_objectness: 0.0749 (0.0779)  loss_rpn_box_reg: 0.0632 (0.0701)  time: 0.7108  data: 0.3033  max mem: 5067\n",
      "Training Epoch: [31]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1290 (0.1479)  loss_objectness: 0.0651 (0.0776)  loss_rpn_box_reg: 0.0600 (0.0703)  time: 0.7114  data: 0.3025  max mem: 5067\n",
      "Training Epoch: [31]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1444 (0.1484)  loss_objectness: 0.0709 (0.0778)  loss_rpn_box_reg: 0.0757 (0.0706)  time: 0.7022  data: 0.3039  max mem: 5067\n",
      "Training Epoch: [31]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1646 (0.1489)  loss_objectness: 0.0734 (0.0778)  loss_rpn_box_reg: 0.0757 (0.0710)  time: 0.7033  data: 0.3060  max mem: 5067\n",
      "Training Epoch: [31]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1587 (0.1491)  loss_objectness: 0.0755 (0.0777)  loss_rpn_box_reg: 0.0801 (0.0714)  time: 0.6968  data: 0.3040  max mem: 5067\n",
      "Training Epoch: [31]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1482 (0.1490)  loss_objectness: 0.0780 (0.0777)  loss_rpn_box_reg: 0.0796 (0.0713)  time: 0.6961  data: 0.3046  max mem: 5067\n",
      "Training Epoch: [31]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1482 (0.1494)  loss_objectness: 0.0794 (0.0780)  loss_rpn_box_reg: 0.0714 (0.0714)  time: 0.7042  data: 0.3105  max mem: 5067\n",
      "Training Epoch: [31]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1430 (0.1492)  loss_objectness: 0.0750 (0.0778)  loss_rpn_box_reg: 0.0715 (0.0714)  time: 0.7041  data: 0.3076  max mem: 5067\n",
      "Training Epoch: [31]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1423 (0.1494)  loss_objectness: 0.0742 (0.0780)  loss_rpn_box_reg: 0.0717 (0.0714)  time: 0.6931  data: 0.3035  max mem: 5067\n",
      "Training Epoch: [31] Total time: 0:02:53 (0.6941 s / it)\n",
      "Testing Epoch: [31]  [ 0/62]  eta: 0:00:40  lr: 0.000300  loss: 0.1303 (0.1303)  loss_objectness: 0.0436 (0.0436)  loss_rpn_box_reg: 0.0867 (0.0867)  time: 0.6541  data: 0.2961  max mem: 5067\n",
      "Testing Epoch: [31]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1278 (0.1349)  loss_objectness: 0.0536 (0.0566)  loss_rpn_box_reg: 0.0723 (0.0783)  time: 0.6326  data: 0.3081  max mem: 5067\n",
      "Testing Epoch: [31] Total time: 0:00:40 (0.6460 s / it)\n",
      "Training Epoch: [32]  [  0/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1445 (0.1445)  loss_objectness: 0.0929 (0.0929)  loss_rpn_box_reg: 0.0516 (0.0516)  time: 0.6531  data: 0.2991  max mem: 5067\n",
      "Training Epoch: [32]  [ 10/250]  eta: 0:02:50  lr: 0.000300  loss: 0.1200 (0.1194)  loss_objectness: 0.0695 (0.0704)  loss_rpn_box_reg: 0.0516 (0.0490)  time: 0.7097  data: 0.2926  max mem: 5067\n",
      "Training Epoch: [32]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1328 (0.1392)  loss_objectness: 0.0695 (0.0737)  loss_rpn_box_reg: 0.0555 (0.0656)  time: 0.6957  data: 0.2939  max mem: 5067\n",
      "Training Epoch: [32]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1502 (0.1420)  loss_objectness: 0.0737 (0.0728)  loss_rpn_box_reg: 0.0795 (0.0692)  time: 0.6820  data: 0.2941  max mem: 5067\n",
      "Training Epoch: [32]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1463 (0.1429)  loss_objectness: 0.0699 (0.0713)  loss_rpn_box_reg: 0.0779 (0.0716)  time: 0.6797  data: 0.2942  max mem: 5067\n",
      "Training Epoch: [32]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1318 (0.1411)  loss_objectness: 0.0724 (0.0717)  loss_rpn_box_reg: 0.0616 (0.0694)  time: 0.6853  data: 0.2982  max mem: 5067\n",
      "Training Epoch: [32]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1315 (0.1415)  loss_objectness: 0.0724 (0.0720)  loss_rpn_box_reg: 0.0597 (0.0694)  time: 0.6984  data: 0.2989  max mem: 5067\n",
      "Training Epoch: [32]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1361 (0.1426)  loss_objectness: 0.0722 (0.0730)  loss_rpn_box_reg: 0.0690 (0.0695)  time: 0.6983  data: 0.2959  max mem: 5067\n",
      "Training Epoch: [32]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1471 (0.1428)  loss_objectness: 0.0748 (0.0734)  loss_rpn_box_reg: 0.0733 (0.0694)  time: 0.6796  data: 0.2936  max mem: 5067\n",
      "Training Epoch: [32]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1520 (0.1440)  loss_objectness: 0.0748 (0.0744)  loss_rpn_box_reg: 0.0633 (0.0696)  time: 0.6718  data: 0.2942  max mem: 5067\n",
      "Training Epoch: [32]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1526 (0.1452)  loss_objectness: 0.0786 (0.0751)  loss_rpn_box_reg: 0.0735 (0.0701)  time: 0.6811  data: 0.2959  max mem: 5067\n",
      "Training Epoch: [32]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1535 (0.1460)  loss_objectness: 0.0812 (0.0757)  loss_rpn_box_reg: 0.0736 (0.0703)  time: 0.6757  data: 0.2933  max mem: 5067\n",
      "Training Epoch: [32]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1484 (0.1458)  loss_objectness: 0.0755 (0.0759)  loss_rpn_box_reg: 0.0670 (0.0699)  time: 0.6769  data: 0.2927  max mem: 5067\n",
      "Training Epoch: [32]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1402 (0.1453)  loss_objectness: 0.0678 (0.0753)  loss_rpn_box_reg: 0.0612 (0.0700)  time: 0.6933  data: 0.2955  max mem: 5067\n",
      "Training Epoch: [32]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1328 (0.1450)  loss_objectness: 0.0648 (0.0745)  loss_rpn_box_reg: 0.0612 (0.0705)  time: 0.7046  data: 0.2921  max mem: 5067\n",
      "Training Epoch: [32]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1603 (0.1470)  loss_objectness: 0.0695 (0.0750)  loss_rpn_box_reg: 0.0856 (0.0720)  time: 0.6949  data: 0.2931  max mem: 5067\n",
      "Training Epoch: [32]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1498 (0.1460)  loss_objectness: 0.0784 (0.0747)  loss_rpn_box_reg: 0.0808 (0.0712)  time: 0.6840  data: 0.2945  max mem: 5067\n",
      "Training Epoch: [32]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1429 (0.1472)  loss_objectness: 0.0784 (0.0752)  loss_rpn_box_reg: 0.0684 (0.0720)  time: 0.6874  data: 0.2929  max mem: 5067\n",
      "Training Epoch: [32]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1555 (0.1474)  loss_objectness: 0.0782 (0.0753)  loss_rpn_box_reg: 0.0754 (0.0722)  time: 0.6840  data: 0.2909  max mem: 5067\n",
      "Training Epoch: [32]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1522 (0.1476)  loss_objectness: 0.0782 (0.0757)  loss_rpn_box_reg: 0.0667 (0.0719)  time: 0.6775  data: 0.2902  max mem: 5067\n",
      "Training Epoch: [32]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1560 (0.1481)  loss_objectness: 0.0863 (0.0761)  loss_rpn_box_reg: 0.0667 (0.0720)  time: 0.6806  data: 0.2936  max mem: 5067\n",
      "Training Epoch: [32]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1472 (0.1473)  loss_objectness: 0.0648 (0.0757)  loss_rpn_box_reg: 0.0655 (0.0716)  time: 0.6987  data: 0.2921  max mem: 5067\n",
      "Training Epoch: [32]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1472 (0.1477)  loss_objectness: 0.0764 (0.0759)  loss_rpn_box_reg: 0.0612 (0.0717)  time: 0.7026  data: 0.2890  max mem: 5067\n",
      "Training Epoch: [32]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1589 (0.1475)  loss_objectness: 0.0783 (0.0760)  loss_rpn_box_reg: 0.0718 (0.0715)  time: 0.6885  data: 0.2917  max mem: 5067\n",
      "Training Epoch: [32]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1457 (0.1475)  loss_objectness: 0.0738 (0.0760)  loss_rpn_box_reg: 0.0679 (0.0715)  time: 0.6865  data: 0.2951  max mem: 5067\n",
      "Training Epoch: [32]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1410 (0.1475)  loss_objectness: 0.0718 (0.0759)  loss_rpn_box_reg: 0.0718 (0.0716)  time: 0.7010  data: 0.2961  max mem: 5067\n",
      "Training Epoch: [32] Total time: 0:02:52 (0.6887 s / it)\n",
      "Testing Epoch: [32]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1319 (0.1319)  loss_objectness: 0.0474 (0.0474)  loss_rpn_box_reg: 0.0845 (0.0845)  time: 0.7222  data: 0.3911  max mem: 5067\n",
      "Testing Epoch: [32]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1282 (0.1351)  loss_objectness: 0.0516 (0.0569)  loss_rpn_box_reg: 0.0682 (0.0783)  time: 0.6342  data: 0.3089  max mem: 5067\n",
      "Testing Epoch: [32] Total time: 0:00:39 (0.6354 s / it)\n",
      "Training Epoch: [33]  [  0/250]  eta: 0:03:07  lr: 0.000300  loss: 0.1510 (0.1510)  loss_objectness: 0.0698 (0.0698)  loss_rpn_box_reg: 0.0811 (0.0811)  time: 0.7482  data: 0.3121  max mem: 5067\n",
      "Training Epoch: [33]  [ 10/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1335 (0.1398)  loss_objectness: 0.0724 (0.0721)  loss_rpn_box_reg: 0.0630 (0.0677)  time: 0.6891  data: 0.2930  max mem: 5067\n",
      "Training Epoch: [33]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1274 (0.1387)  loss_objectness: 0.0730 (0.0739)  loss_rpn_box_reg: 0.0560 (0.0647)  time: 0.6863  data: 0.2935  max mem: 5067\n",
      "Training Epoch: [33]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1313 (0.1404)  loss_objectness: 0.0730 (0.0737)  loss_rpn_box_reg: 0.0569 (0.0667)  time: 0.6955  data: 0.2946  max mem: 5067\n",
      "Training Epoch: [33]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1492 (0.1447)  loss_objectness: 0.0760 (0.0771)  loss_rpn_box_reg: 0.0642 (0.0676)  time: 0.6941  data: 0.2953  max mem: 5067\n",
      "Training Epoch: [33]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1487 (0.1456)  loss_objectness: 0.0814 (0.0774)  loss_rpn_box_reg: 0.0642 (0.0682)  time: 0.6776  data: 0.2942  max mem: 5067\n",
      "Training Epoch: [33]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1359 (0.1446)  loss_objectness: 0.0768 (0.0762)  loss_rpn_box_reg: 0.0639 (0.0684)  time: 0.6804  data: 0.2891  max mem: 5067\n",
      "Training Epoch: [33]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1543 (0.1468)  loss_objectness: 0.0767 (0.0772)  loss_rpn_box_reg: 0.0656 (0.0696)  time: 0.7051  data: 0.2928  max mem: 5067\n",
      "Training Epoch: [33]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1655 (0.1476)  loss_objectness: 0.0752 (0.0767)  loss_rpn_box_reg: 0.0745 (0.0709)  time: 0.7030  data: 0.2948  max mem: 5067\n",
      "Training Epoch: [33]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1386 (0.1466)  loss_objectness: 0.0678 (0.0755)  loss_rpn_box_reg: 0.0661 (0.0711)  time: 0.6836  data: 0.2903  max mem: 5067\n",
      "Training Epoch: [33]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1386 (0.1470)  loss_objectness: 0.0678 (0.0760)  loss_rpn_box_reg: 0.0631 (0.0710)  time: 0.6838  data: 0.2929  max mem: 5067\n",
      "Training Epoch: [33]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1503 (0.1480)  loss_objectness: 0.0813 (0.0768)  loss_rpn_box_reg: 0.0815 (0.0711)  time: 0.6824  data: 0.2954  max mem: 5067\n",
      "Training Epoch: [33]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1503 (0.1475)  loss_objectness: 0.0848 (0.0774)  loss_rpn_box_reg: 0.0686 (0.0702)  time: 0.6787  data: 0.2940  max mem: 5067\n",
      "Training Epoch: [33]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1446 (0.1482)  loss_objectness: 0.0847 (0.0781)  loss_rpn_box_reg: 0.0656 (0.0701)  time: 0.6808  data: 0.2928  max mem: 5067\n",
      "Training Epoch: [33]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1463 (0.1485)  loss_objectness: 0.0744 (0.0774)  loss_rpn_box_reg: 0.0763 (0.0711)  time: 0.6876  data: 0.2913  max mem: 5067\n",
      "Training Epoch: [33]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1492 (0.1490)  loss_objectness: 0.0811 (0.0780)  loss_rpn_box_reg: 0.0763 (0.0710)  time: 0.6917  data: 0.2964  max mem: 5067\n",
      "Training Epoch: [33]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1475 (0.1488)  loss_objectness: 0.0834 (0.0778)  loss_rpn_box_reg: 0.0648 (0.0710)  time: 0.6737  data: 0.2962  max mem: 5067\n",
      "Training Epoch: [33]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1441 (0.1485)  loss_objectness: 0.0631 (0.0773)  loss_rpn_box_reg: 0.0699 (0.0712)  time: 0.6836  data: 0.2931  max mem: 5067\n",
      "Training Epoch: [33]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1433 (0.1478)  loss_objectness: 0.0631 (0.0769)  loss_rpn_box_reg: 0.0695 (0.0709)  time: 0.6950  data: 0.2957  max mem: 5067\n",
      "Training Epoch: [33]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1386 (0.1480)  loss_objectness: 0.0756 (0.0773)  loss_rpn_box_reg: 0.0668 (0.0707)  time: 0.6847  data: 0.2946  max mem: 5067\n",
      "Training Epoch: [33]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1386 (0.1478)  loss_objectness: 0.0737 (0.0772)  loss_rpn_box_reg: 0.0679 (0.0706)  time: 0.6856  data: 0.2942  max mem: 5067\n",
      "Training Epoch: [33]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1392 (0.1482)  loss_objectness: 0.0784 (0.0773)  loss_rpn_box_reg: 0.0693 (0.0709)  time: 0.6986  data: 0.2960  max mem: 5067\n",
      "Training Epoch: [33]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1417 (0.1477)  loss_objectness: 0.0786 (0.0772)  loss_rpn_box_reg: 0.0600 (0.0705)  time: 0.6942  data: 0.2937  max mem: 5067\n",
      "Training Epoch: [33]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1432 (0.1484)  loss_objectness: 0.0739 (0.0771)  loss_rpn_box_reg: 0.0682 (0.0713)  time: 0.6840  data: 0.2913  max mem: 5067\n",
      "Training Epoch: [33]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1612 (0.1486)  loss_objectness: 0.0743 (0.0774)  loss_rpn_box_reg: 0.0727 (0.0712)  time: 0.6978  data: 0.2927  max mem: 5067\n",
      "Training Epoch: [33]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1528 (0.1489)  loss_objectness: 0.0823 (0.0776)  loss_rpn_box_reg: 0.0712 (0.0713)  time: 0.6915  data: 0.2916  max mem: 5067\n",
      "Training Epoch: [33] Total time: 0:02:52 (0.6884 s / it)\n",
      "Testing Epoch: [33]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1328 (0.1328)  loss_objectness: 0.0463 (0.0463)  loss_rpn_box_reg: 0.0866 (0.0866)  time: 0.6141  data: 0.2891  max mem: 5067\n",
      "Testing Epoch: [33]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1362 (0.1400)  loss_objectness: 0.0592 (0.0610)  loss_rpn_box_reg: 0.0719 (0.0790)  time: 0.6393  data: 0.3117  max mem: 5067\n",
      "Testing Epoch: [33] Total time: 0:00:39 (0.6391 s / it)\n",
      "Training Epoch: [34]  [  0/250]  eta: 0:02:50  lr: 0.000300  loss: 0.1210 (0.1210)  loss_objectness: 0.0951 (0.0951)  loss_rpn_box_reg: 0.0260 (0.0260)  time: 0.6802  data: 0.2961  max mem: 5067\n",
      "Training Epoch: [34]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1376 (0.1416)  loss_objectness: 0.0685 (0.0736)  loss_rpn_box_reg: 0.0684 (0.0680)  time: 0.6974  data: 0.3031  max mem: 5067\n",
      "Training Epoch: [34]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1362 (0.1377)  loss_objectness: 0.0680 (0.0716)  loss_rpn_box_reg: 0.0684 (0.0661)  time: 0.6855  data: 0.2959  max mem: 5067\n",
      "Training Epoch: [34]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1394 (0.1428)  loss_objectness: 0.0719 (0.0728)  loss_rpn_box_reg: 0.0710 (0.0700)  time: 0.6922  data: 0.2916  max mem: 5067\n",
      "Training Epoch: [34]  [ 40/250]  eta: 0:02:26  lr: 0.000300  loss: 0.1389 (0.1405)  loss_objectness: 0.0721 (0.0726)  loss_rpn_box_reg: 0.0622 (0.0679)  time: 0.7076  data: 0.2972  max mem: 5067\n",
      "Training Epoch: [34]  [ 50/250]  eta: 0:02:19  lr: 0.000300  loss: 0.1446 (0.1445)  loss_objectness: 0.0719 (0.0726)  loss_rpn_box_reg: 0.0664 (0.0719)  time: 0.7046  data: 0.2978  max mem: 5067\n",
      "Training Epoch: [34]  [ 60/250]  eta: 0:02:12  lr: 0.000300  loss: 0.1554 (0.1470)  loss_objectness: 0.0706 (0.0738)  loss_rpn_box_reg: 0.0784 (0.0732)  time: 0.6968  data: 0.2967  max mem: 5067\n",
      "Training Epoch: [34]  [ 70/250]  eta: 0:02:05  lr: 0.000300  loss: 0.1554 (0.1464)  loss_objectness: 0.0694 (0.0735)  loss_rpn_box_reg: 0.0702 (0.0729)  time: 0.6873  data: 0.2941  max mem: 5067\n",
      "Training Epoch: [34]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1447 (0.1452)  loss_objectness: 0.0699 (0.0734)  loss_rpn_box_reg: 0.0646 (0.0718)  time: 0.6813  data: 0.2955  max mem: 5067\n",
      "Training Epoch: [34]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1447 (0.1451)  loss_objectness: 0.0699 (0.0729)  loss_rpn_box_reg: 0.0661 (0.0722)  time: 0.6881  data: 0.2969  max mem: 5067\n",
      "Training Epoch: [34]  [100/250]  eta: 0:01:44  lr: 0.000300  loss: 0.1544 (0.1463)  loss_objectness: 0.0712 (0.0732)  loss_rpn_box_reg: 0.0733 (0.0730)  time: 0.6968  data: 0.2948  max mem: 5067\n",
      "Training Epoch: [34]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1502 (0.1456)  loss_objectness: 0.0731 (0.0731)  loss_rpn_box_reg: 0.0733 (0.0724)  time: 0.6964  data: 0.2963  max mem: 5067\n",
      "Training Epoch: [34]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1327 (0.1461)  loss_objectness: 0.0734 (0.0737)  loss_rpn_box_reg: 0.0643 (0.0724)  time: 0.6971  data: 0.2936  max mem: 5067\n",
      "Training Epoch: [34]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1480 (0.1459)  loss_objectness: 0.0738 (0.0740)  loss_rpn_box_reg: 0.0643 (0.0719)  time: 0.6885  data: 0.2939  max mem: 5067\n",
      "Training Epoch: [34]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1344 (0.1450)  loss_objectness: 0.0738 (0.0736)  loss_rpn_box_reg: 0.0655 (0.0714)  time: 0.6826  data: 0.2955  max mem: 5067\n",
      "Training Epoch: [34]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1468 (0.1459)  loss_objectness: 0.0766 (0.0744)  loss_rpn_box_reg: 0.0682 (0.0715)  time: 0.6918  data: 0.2953  max mem: 5067\n",
      "Training Epoch: [34]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1501 (0.1453)  loss_objectness: 0.0685 (0.0736)  loss_rpn_box_reg: 0.0682 (0.0717)  time: 0.6961  data: 0.2909  max mem: 5067\n",
      "Training Epoch: [34]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1301 (0.1453)  loss_objectness: 0.0598 (0.0732)  loss_rpn_box_reg: 0.0730 (0.0721)  time: 0.6938  data: 0.2895  max mem: 5067\n",
      "Training Epoch: [34]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1495 (0.1454)  loss_objectness: 0.0667 (0.0735)  loss_rpn_box_reg: 0.0708 (0.0719)  time: 0.6987  data: 0.2988  max mem: 5067\n",
      "Training Epoch: [34]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1495 (0.1452)  loss_objectness: 0.0737 (0.0739)  loss_rpn_box_reg: 0.0640 (0.0713)  time: 0.6875  data: 0.2991  max mem: 5067\n",
      "Training Epoch: [34]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1555 (0.1462)  loss_objectness: 0.0737 (0.0742)  loss_rpn_box_reg: 0.0713 (0.0720)  time: 0.6888  data: 0.2966  max mem: 5067\n",
      "Training Epoch: [34]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1462 (0.1462)  loss_objectness: 0.0784 (0.0745)  loss_rpn_box_reg: 0.0722 (0.0717)  time: 0.6962  data: 0.2963  max mem: 5067\n",
      "Training Epoch: [34]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1461 (0.1468)  loss_objectness: 0.0751 (0.0749)  loss_rpn_box_reg: 0.0622 (0.0719)  time: 0.6855  data: 0.2939  max mem: 5067\n",
      "Training Epoch: [34]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1466 (0.1468)  loss_objectness: 0.0811 (0.0753)  loss_rpn_box_reg: 0.0633 (0.0716)  time: 0.6939  data: 0.2938  max mem: 5067\n",
      "Training Epoch: [34]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1492 (0.1473)  loss_objectness: 0.0835 (0.0759)  loss_rpn_box_reg: 0.0588 (0.0714)  time: 0.6863  data: 0.2948  max mem: 5067\n",
      "Training Epoch: [34]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1521 (0.1479)  loss_objectness: 0.0869 (0.0764)  loss_rpn_box_reg: 0.0633 (0.0715)  time: 0.6751  data: 0.2982  max mem: 5067\n",
      "Training Epoch: [34] Total time: 0:02:52 (0.6915 s / it)\n",
      "Testing Epoch: [34]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1299 (0.1299)  loss_objectness: 0.0454 (0.0454)  loss_rpn_box_reg: 0.0845 (0.0845)  time: 0.6351  data: 0.3101  max mem: 5067\n",
      "Testing Epoch: [34]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1329 (0.1398)  loss_objectness: 0.0582 (0.0614)  loss_rpn_box_reg: 0.0706 (0.0784)  time: 0.6368  data: 0.3114  max mem: 5067\n",
      "Testing Epoch: [34] Total time: 0:00:39 (0.6363 s / it)\n",
      "Training Epoch: [35]  [  0/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1163 (0.1163)  loss_objectness: 0.0624 (0.0624)  loss_rpn_box_reg: 0.0539 (0.0539)  time: 0.6872  data: 0.3121  max mem: 5067\n",
      "Training Epoch: [35]  [ 10/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1498 (0.1501)  loss_objectness: 0.0661 (0.0689)  loss_rpn_box_reg: 0.0749 (0.0812)  time: 0.6768  data: 0.2939  max mem: 5067\n",
      "Training Epoch: [35]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1460 (0.1500)  loss_objectness: 0.0661 (0.0690)  loss_rpn_box_reg: 0.0749 (0.0810)  time: 0.6779  data: 0.2945  max mem: 5067\n",
      "Training Epoch: [35]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1428 (0.1483)  loss_objectness: 0.0706 (0.0711)  loss_rpn_box_reg: 0.0684 (0.0773)  time: 0.6925  data: 0.2956  max mem: 5067\n",
      "Training Epoch: [35]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1468 (0.1508)  loss_objectness: 0.0800 (0.0743)  loss_rpn_box_reg: 0.0687 (0.0766)  time: 0.6842  data: 0.2946  max mem: 5067\n",
      "Training Epoch: [35]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1500 (0.1506)  loss_objectness: 0.0839 (0.0748)  loss_rpn_box_reg: 0.0716 (0.0758)  time: 0.6652  data: 0.2929  max mem: 5067\n",
      "Training Epoch: [35]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1478 (0.1507)  loss_objectness: 0.0775 (0.0751)  loss_rpn_box_reg: 0.0716 (0.0757)  time: 0.6805  data: 0.2926  max mem: 5067\n",
      "Training Epoch: [35]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1336 (0.1472)  loss_objectness: 0.0733 (0.0748)  loss_rpn_box_reg: 0.0601 (0.0724)  time: 0.6880  data: 0.2930  max mem: 5067\n",
      "Training Epoch: [35]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1257 (0.1476)  loss_objectness: 0.0739 (0.0754)  loss_rpn_box_reg: 0.0612 (0.0722)  time: 0.6741  data: 0.2954  max mem: 5067\n",
      "Training Epoch: [35]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1611 (0.1487)  loss_objectness: 0.0772 (0.0759)  loss_rpn_box_reg: 0.0669 (0.0728)  time: 0.6667  data: 0.2947  max mem: 5067\n",
      "Training Epoch: [35]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1460 (0.1484)  loss_objectness: 0.0726 (0.0751)  loss_rpn_box_reg: 0.0817 (0.0733)  time: 0.6740  data: 0.2885  max mem: 5067\n",
      "Training Epoch: [35]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1413 (0.1484)  loss_objectness: 0.0690 (0.0756)  loss_rpn_box_reg: 0.0650 (0.0727)  time: 0.6879  data: 0.2897  max mem: 5067\n",
      "Training Epoch: [35]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1384 (0.1483)  loss_objectness: 0.0690 (0.0752)  loss_rpn_box_reg: 0.0630 (0.0731)  time: 0.6854  data: 0.2931  max mem: 5067\n",
      "Training Epoch: [35]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1396 (0.1484)  loss_objectness: 0.0675 (0.0751)  loss_rpn_box_reg: 0.0672 (0.0732)  time: 0.6851  data: 0.2955  max mem: 5067\n",
      "Training Epoch: [35]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1268 (0.1471)  loss_objectness: 0.0750 (0.0754)  loss_rpn_box_reg: 0.0597 (0.0716)  time: 0.6858  data: 0.2952  max mem: 5067\n",
      "Training Epoch: [35]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1442 (0.1477)  loss_objectness: 0.0772 (0.0756)  loss_rpn_box_reg: 0.0597 (0.0721)  time: 0.6927  data: 0.2947  max mem: 5067\n",
      "Training Epoch: [35]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1436 (0.1469)  loss_objectness: 0.0772 (0.0755)  loss_rpn_box_reg: 0.0671 (0.0714)  time: 0.7050  data: 0.2953  max mem: 5067\n",
      "Training Epoch: [35]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1436 (0.1473)  loss_objectness: 0.0735 (0.0758)  loss_rpn_box_reg: 0.0616 (0.0715)  time: 0.6989  data: 0.2960  max mem: 5067\n",
      "Training Epoch: [35]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1336 (0.1465)  loss_objectness: 0.0718 (0.0753)  loss_rpn_box_reg: 0.0607 (0.0711)  time: 0.6856  data: 0.2932  max mem: 5067\n",
      "Training Epoch: [35]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1336 (0.1467)  loss_objectness: 0.0680 (0.0754)  loss_rpn_box_reg: 0.0607 (0.0712)  time: 0.6856  data: 0.2941  max mem: 5067\n",
      "Training Epoch: [35]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1513 (0.1471)  loss_objectness: 0.0739 (0.0758)  loss_rpn_box_reg: 0.0728 (0.0713)  time: 0.6965  data: 0.2980  max mem: 5067\n",
      "Training Epoch: [35]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1448 (0.1469)  loss_objectness: 0.0694 (0.0754)  loss_rpn_box_reg: 0.0710 (0.0715)  time: 0.6949  data: 0.2919  max mem: 5067\n",
      "Training Epoch: [35]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1409 (0.1469)  loss_objectness: 0.0685 (0.0756)  loss_rpn_box_reg: 0.0679 (0.0714)  time: 0.6835  data: 0.2901  max mem: 5067\n",
      "Training Epoch: [35]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1423 (0.1468)  loss_objectness: 0.0699 (0.0758)  loss_rpn_box_reg: 0.0604 (0.0710)  time: 0.6901  data: 0.2958  max mem: 5067\n",
      "Training Epoch: [35]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1421 (0.1468)  loss_objectness: 0.0733 (0.0758)  loss_rpn_box_reg: 0.0619 (0.0710)  time: 0.7036  data: 0.2961  max mem: 5067\n",
      "Training Epoch: [35]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1421 (0.1472)  loss_objectness: 0.0805 (0.0761)  loss_rpn_box_reg: 0.0638 (0.0712)  time: 0.6844  data: 0.2908  max mem: 5067\n",
      "Training Epoch: [35] Total time: 0:02:51 (0.6857 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:02  model_time: 0.6702 (0.6702)  evaluator_time: 0.0490 (0.0490)  time: 1.0122  data: 0.2781  max mem: 5067\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3591 (0.3677)  evaluator_time: 0.0590 (0.0693)  time: 0.7358  data: 0.2947  max mem: 5067\n",
      "Test: Total time: 0:00:46 (0.7432 s / it)\n",
      "Averaged stats: model_time: 0.3591 (0.3677)  evaluator_time: 0.0590 (0.0693)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.96s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.175\n",
      "Testing Epoch: [35]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1302 (0.1302)  loss_objectness: 0.0453 (0.0453)  loss_rpn_box_reg: 0.0848 (0.0848)  time: 0.6041  data: 0.2791  max mem: 5067\n",
      "Testing Epoch: [35]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1257 (0.1342)  loss_objectness: 0.0554 (0.0570)  loss_rpn_box_reg: 0.0681 (0.0772)  time: 0.6304  data: 0.3065  max mem: 5067\n",
      "Testing Epoch: [35] Total time: 0:00:39 (0.6344 s / it)\n",
      "Training Epoch: [36]  [  0/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1831 (0.1831)  loss_objectness: 0.1044 (0.1044)  loss_rpn_box_reg: 0.0787 (0.0787)  time: 0.6712  data: 0.3031  max mem: 5067\n",
      "Training Epoch: [36]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1483 (0.1435)  loss_objectness: 0.0635 (0.0714)  loss_rpn_box_reg: 0.0635 (0.0721)  time: 0.6749  data: 0.2953  max mem: 5067\n",
      "Training Epoch: [36]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1427 (0.1433)  loss_objectness: 0.0659 (0.0728)  loss_rpn_box_reg: 0.0660 (0.0706)  time: 0.6803  data: 0.2921  max mem: 5067\n",
      "Training Epoch: [36]  [ 30/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1323 (0.1399)  loss_objectness: 0.0750 (0.0719)  loss_rpn_box_reg: 0.0574 (0.0680)  time: 0.6762  data: 0.2899  max mem: 5067\n",
      "Training Epoch: [36]  [ 40/250]  eta: 0:02:21  lr: 0.000300  loss: 0.1319 (0.1431)  loss_objectness: 0.0740 (0.0734)  loss_rpn_box_reg: 0.0563 (0.0698)  time: 0.6702  data: 0.2905  max mem: 5067\n",
      "Training Epoch: [36]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1692 (0.1473)  loss_objectness: 0.0816 (0.0771)  loss_rpn_box_reg: 0.0757 (0.0702)  time: 0.6775  data: 0.2919  max mem: 5067\n",
      "Training Epoch: [36]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1688 (0.1473)  loss_objectness: 0.0807 (0.0774)  loss_rpn_box_reg: 0.0714 (0.0699)  time: 0.6907  data: 0.2929  max mem: 5067\n",
      "Training Epoch: [36]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1574 (0.1488)  loss_objectness: 0.0702 (0.0778)  loss_rpn_box_reg: 0.0714 (0.0710)  time: 0.6849  data: 0.2910  max mem: 5067\n",
      "Training Epoch: [36]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1553 (0.1493)  loss_objectness: 0.0798 (0.0785)  loss_rpn_box_reg: 0.0658 (0.0707)  time: 0.6823  data: 0.2912  max mem: 5067\n",
      "Training Epoch: [36]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1473 (0.1479)  loss_objectness: 0.0779 (0.0778)  loss_rpn_box_reg: 0.0641 (0.0700)  time: 0.6896  data: 0.2887  max mem: 5067\n",
      "Training Epoch: [36]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1473 (0.1482)  loss_objectness: 0.0772 (0.0780)  loss_rpn_box_reg: 0.0641 (0.0702)  time: 0.6865  data: 0.2900  max mem: 5067\n",
      "Training Epoch: [36]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1507 (0.1486)  loss_objectness: 0.0757 (0.0777)  loss_rpn_box_reg: 0.0673 (0.0708)  time: 0.6809  data: 0.2943  max mem: 5067\n",
      "Training Epoch: [36]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1418 (0.1477)  loss_objectness: 0.0757 (0.0778)  loss_rpn_box_reg: 0.0646 (0.0699)  time: 0.6828  data: 0.2889  max mem: 5067\n",
      "Training Epoch: [36]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1453 (0.1484)  loss_objectness: 0.0712 (0.0776)  loss_rpn_box_reg: 0.0660 (0.0709)  time: 0.6868  data: 0.2880  max mem: 5067\n",
      "Training Epoch: [36]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1453 (0.1480)  loss_objectness: 0.0706 (0.0772)  loss_rpn_box_reg: 0.0699 (0.0708)  time: 0.6788  data: 0.2895  max mem: 5067\n",
      "Training Epoch: [36]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1392 (0.1482)  loss_objectness: 0.0706 (0.0771)  loss_rpn_box_reg: 0.0734 (0.0712)  time: 0.6888  data: 0.2907  max mem: 5067\n",
      "Training Epoch: [36]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1427 (0.1484)  loss_objectness: 0.0746 (0.0772)  loss_rpn_box_reg: 0.0734 (0.0712)  time: 0.7075  data: 0.2917  max mem: 5067\n",
      "Training Epoch: [36]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1427 (0.1479)  loss_objectness: 0.0734 (0.0772)  loss_rpn_box_reg: 0.0560 (0.0707)  time: 0.6957  data: 0.2998  max mem: 5067\n",
      "Training Epoch: [36]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1410 (0.1478)  loss_objectness: 0.0693 (0.0768)  loss_rpn_box_reg: 0.0566 (0.0710)  time: 0.6885  data: 0.2978  max mem: 5067\n",
      "Training Epoch: [36]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1410 (0.1476)  loss_objectness: 0.0685 (0.0766)  loss_rpn_box_reg: 0.0566 (0.0711)  time: 0.6987  data: 0.2896  max mem: 5067\n",
      "Training Epoch: [36]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1471 (0.1475)  loss_objectness: 0.0752 (0.0771)  loss_rpn_box_reg: 0.0545 (0.0704)  time: 0.6927  data: 0.2936  max mem: 5067\n",
      "Training Epoch: [36]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1553 (0.1480)  loss_objectness: 0.0867 (0.0774)  loss_rpn_box_reg: 0.0645 (0.0706)  time: 0.6813  data: 0.2941  max mem: 5067\n",
      "Training Epoch: [36]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1529 (0.1483)  loss_objectness: 0.0787 (0.0773)  loss_rpn_box_reg: 0.0725 (0.0710)  time: 0.6798  data: 0.2980  max mem: 5067\n",
      "Training Epoch: [36]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1526 (0.1482)  loss_objectness: 0.0793 (0.0774)  loss_rpn_box_reg: 0.0719 (0.0708)  time: 0.6838  data: 0.2977  max mem: 5067\n",
      "Training Epoch: [36]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1459 (0.1484)  loss_objectness: 0.0822 (0.0774)  loss_rpn_box_reg: 0.0678 (0.0710)  time: 0.6883  data: 0.2941  max mem: 5067\n",
      "Training Epoch: [36]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1440 (0.1485)  loss_objectness: 0.0789 (0.0773)  loss_rpn_box_reg: 0.0678 (0.0712)  time: 0.6977  data: 0.2945  max mem: 5067\n",
      "Training Epoch: [36] Total time: 0:02:51 (0.6863 s / it)\n",
      "Testing Epoch: [36]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1346 (0.1346)  loss_objectness: 0.0484 (0.0484)  loss_rpn_box_reg: 0.0863 (0.0863)  time: 0.6281  data: 0.2911  max mem: 5067\n",
      "Testing Epoch: [36]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1270 (0.1389)  loss_objectness: 0.0577 (0.0605)  loss_rpn_box_reg: 0.0693 (0.0784)  time: 0.6315  data: 0.3110  max mem: 5067\n",
      "Testing Epoch: [36] Total time: 0:00:39 (0.6371 s / it)\n",
      "Training Epoch: [37]  [  0/250]  eta: 0:02:49  lr: 0.000300  loss: 0.1505 (0.1505)  loss_objectness: 0.1057 (0.1057)  loss_rpn_box_reg: 0.0449 (0.0449)  time: 0.6772  data: 0.2801  max mem: 5067\n",
      "Training Epoch: [37]  [ 10/250]  eta: 0:02:52  lr: 0.000300  loss: 0.1505 (0.1447)  loss_objectness: 0.0796 (0.0763)  loss_rpn_box_reg: 0.0629 (0.0685)  time: 0.7202  data: 0.2925  max mem: 5067\n",
      "Training Epoch: [37]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1457 (0.1409)  loss_objectness: 0.0667 (0.0751)  loss_rpn_box_reg: 0.0635 (0.0658)  time: 0.6953  data: 0.2913  max mem: 5067\n",
      "Training Epoch: [37]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1477 (0.1492)  loss_objectness: 0.0711 (0.0742)  loss_rpn_box_reg: 0.0692 (0.0751)  time: 0.6731  data: 0.2913  max mem: 5067\n",
      "Training Epoch: [37]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1499 (0.1510)  loss_objectness: 0.0743 (0.0744)  loss_rpn_box_reg: 0.0772 (0.0766)  time: 0.6920  data: 0.2961  max mem: 5067\n",
      "Training Epoch: [37]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1484 (0.1511)  loss_objectness: 0.0714 (0.0739)  loss_rpn_box_reg: 0.0733 (0.0772)  time: 0.7000  data: 0.2957  max mem: 5067\n",
      "Training Epoch: [37]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1420 (0.1505)  loss_objectness: 0.0714 (0.0749)  loss_rpn_box_reg: 0.0719 (0.0756)  time: 0.6850  data: 0.2923  max mem: 5067\n",
      "Training Epoch: [37]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1403 (0.1480)  loss_objectness: 0.0729 (0.0743)  loss_rpn_box_reg: 0.0629 (0.0737)  time: 0.6774  data: 0.2944  max mem: 5067\n",
      "Training Epoch: [37]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1298 (0.1478)  loss_objectness: 0.0707 (0.0749)  loss_rpn_box_reg: 0.0588 (0.0728)  time: 0.6890  data: 0.2984  max mem: 5067\n",
      "Training Epoch: [37]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1509 (0.1486)  loss_objectness: 0.0761 (0.0757)  loss_rpn_box_reg: 0.0711 (0.0729)  time: 0.6994  data: 0.2975  max mem: 5067\n",
      "Training Epoch: [37]  [100/250]  eta: 0:01:44  lr: 0.000300  loss: 0.1552 (0.1496)  loss_objectness: 0.0761 (0.0767)  loss_rpn_box_reg: 0.0813 (0.0729)  time: 0.7110  data: 0.2966  max mem: 5067\n",
      "Training Epoch: [37]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1578 (0.1505)  loss_objectness: 0.0745 (0.0767)  loss_rpn_box_reg: 0.0751 (0.0738)  time: 0.7128  data: 0.2933  max mem: 5067\n",
      "Training Epoch: [37]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1429 (0.1491)  loss_objectness: 0.0679 (0.0760)  loss_rpn_box_reg: 0.0745 (0.0731)  time: 0.6849  data: 0.2909  max mem: 5067\n",
      "Training Epoch: [37]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1404 (0.1486)  loss_objectness: 0.0614 (0.0753)  loss_rpn_box_reg: 0.0770 (0.0733)  time: 0.6784  data: 0.2918  max mem: 5067\n",
      "Training Epoch: [37]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1409 (0.1486)  loss_objectness: 0.0651 (0.0756)  loss_rpn_box_reg: 0.0800 (0.0730)  time: 0.6811  data: 0.2927  max mem: 5067\n",
      "Training Epoch: [37]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1466 (0.1485)  loss_objectness: 0.0710 (0.0759)  loss_rpn_box_reg: 0.0650 (0.0726)  time: 0.6795  data: 0.2942  max mem: 5067\n",
      "Training Epoch: [37]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1480 (0.1489)  loss_objectness: 0.0748 (0.0762)  loss_rpn_box_reg: 0.0691 (0.0727)  time: 0.6865  data: 0.2977  max mem: 5067\n",
      "Training Epoch: [37]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1469 (0.1485)  loss_objectness: 0.0738 (0.0761)  loss_rpn_box_reg: 0.0690 (0.0724)  time: 0.6811  data: 0.2989  max mem: 5067\n",
      "Training Epoch: [37]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1379 (0.1483)  loss_objectness: 0.0718 (0.0761)  loss_rpn_box_reg: 0.0604 (0.0721)  time: 0.6880  data: 0.2959  max mem: 5067\n",
      "Training Epoch: [37]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1379 (0.1482)  loss_objectness: 0.0742 (0.0759)  loss_rpn_box_reg: 0.0606 (0.0722)  time: 0.6925  data: 0.2957  max mem: 5067\n",
      "Training Epoch: [37]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1401 (0.1482)  loss_objectness: 0.0748 (0.0762)  loss_rpn_box_reg: 0.0612 (0.0719)  time: 0.6884  data: 0.2965  max mem: 5067\n",
      "Training Epoch: [37]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1369 (0.1479)  loss_objectness: 0.0668 (0.0758)  loss_rpn_box_reg: 0.0637 (0.0721)  time: 0.6821  data: 0.2939  max mem: 5067\n",
      "Training Epoch: [37]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1369 (0.1477)  loss_objectness: 0.0657 (0.0757)  loss_rpn_box_reg: 0.0706 (0.0720)  time: 0.6859  data: 0.2937  max mem: 5067\n",
      "Training Epoch: [37]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1354 (0.1472)  loss_objectness: 0.0672 (0.0755)  loss_rpn_box_reg: 0.0641 (0.0717)  time: 0.6861  data: 0.2939  max mem: 5067\n",
      "Training Epoch: [37]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1311 (0.1474)  loss_objectness: 0.0713 (0.0759)  loss_rpn_box_reg: 0.0641 (0.0715)  time: 0.6773  data: 0.2944  max mem: 5067\n",
      "Training Epoch: [37]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1398 (0.1472)  loss_objectness: 0.0736 (0.0757)  loss_rpn_box_reg: 0.0685 (0.0714)  time: 0.6840  data: 0.2936  max mem: 5067\n",
      "Training Epoch: [37] Total time: 0:02:52 (0.6890 s / it)\n",
      "Testing Epoch: [37]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1353 (0.1353)  loss_objectness: 0.0495 (0.0495)  loss_rpn_box_reg: 0.0858 (0.0858)  time: 0.6411  data: 0.2861  max mem: 5067\n",
      "Testing Epoch: [37]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1234 (0.1371)  loss_objectness: 0.0552 (0.0576)  loss_rpn_box_reg: 0.0682 (0.0794)  time: 0.6224  data: 0.3036  max mem: 5067\n",
      "Testing Epoch: [37] Total time: 0:00:39 (0.6322 s / it)\n",
      "Training Epoch: [38]  [  0/250]  eta: 0:03:02  lr: 0.000300  loss: 0.1266 (0.1266)  loss_objectness: 0.0841 (0.0841)  loss_rpn_box_reg: 0.0424 (0.0424)  time: 0.7302  data: 0.2931  max mem: 5067\n",
      "Training Epoch: [38]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1342 (0.1408)  loss_objectness: 0.0779 (0.0745)  loss_rpn_box_reg: 0.0646 (0.0663)  time: 0.6925  data: 0.2932  max mem: 5067\n",
      "Training Epoch: [38]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1368 (0.1434)  loss_objectness: 0.0717 (0.0735)  loss_rpn_box_reg: 0.0705 (0.0699)  time: 0.6848  data: 0.2930  max mem: 5067\n",
      "Training Epoch: [38]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1442 (0.1471)  loss_objectness: 0.0743 (0.0754)  loss_rpn_box_reg: 0.0723 (0.0717)  time: 0.6878  data: 0.2938  max mem: 5067\n",
      "Training Epoch: [38]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1502 (0.1485)  loss_objectness: 0.0732 (0.0752)  loss_rpn_box_reg: 0.0723 (0.0733)  time: 0.6995  data: 0.2944  max mem: 5067\n",
      "Training Epoch: [38]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1426 (0.1468)  loss_objectness: 0.0672 (0.0742)  loss_rpn_box_reg: 0.0720 (0.0726)  time: 0.6860  data: 0.2944  max mem: 5067\n",
      "Training Epoch: [38]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1265 (0.1431)  loss_objectness: 0.0671 (0.0732)  loss_rpn_box_reg: 0.0660 (0.0699)  time: 0.6725  data: 0.2925  max mem: 5067\n",
      "Training Epoch: [38]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1242 (0.1428)  loss_objectness: 0.0646 (0.0729)  loss_rpn_box_reg: 0.0565 (0.0699)  time: 0.6796  data: 0.2902  max mem: 5067\n",
      "Training Epoch: [38]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1369 (0.1421)  loss_objectness: 0.0646 (0.0720)  loss_rpn_box_reg: 0.0659 (0.0701)  time: 0.6892  data: 0.2919  max mem: 5067\n",
      "Training Epoch: [38]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1345 (0.1419)  loss_objectness: 0.0622 (0.0716)  loss_rpn_box_reg: 0.0741 (0.0703)  time: 0.6793  data: 0.2943  max mem: 5067\n",
      "Training Epoch: [38]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1249 (0.1404)  loss_objectness: 0.0590 (0.0706)  loss_rpn_box_reg: 0.0598 (0.0698)  time: 0.6767  data: 0.2930  max mem: 5067\n",
      "Training Epoch: [38]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1187 (0.1393)  loss_objectness: 0.0618 (0.0703)  loss_rpn_box_reg: 0.0563 (0.0690)  time: 0.6851  data: 0.2935  max mem: 5067\n",
      "Training Epoch: [38]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1275 (0.1402)  loss_objectness: 0.0734 (0.0711)  loss_rpn_box_reg: 0.0563 (0.0691)  time: 0.6783  data: 0.2936  max mem: 5067\n",
      "Training Epoch: [38]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1387 (0.1401)  loss_objectness: 0.0743 (0.0712)  loss_rpn_box_reg: 0.0691 (0.0689)  time: 0.6844  data: 0.2943  max mem: 5067\n",
      "Training Epoch: [38]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1474 (0.1419)  loss_objectness: 0.0756 (0.0718)  loss_rpn_box_reg: 0.0758 (0.0701)  time: 0.6961  data: 0.2978  max mem: 5067\n",
      "Training Epoch: [38]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1392 (0.1415)  loss_objectness: 0.0723 (0.0717)  loss_rpn_box_reg: 0.0786 (0.0698)  time: 0.6968  data: 0.2927  max mem: 5067\n",
      "Training Epoch: [38]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1325 (0.1413)  loss_objectness: 0.0723 (0.0720)  loss_rpn_box_reg: 0.0588 (0.0693)  time: 0.6851  data: 0.2885  max mem: 5067\n",
      "Training Epoch: [38]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1409 (0.1413)  loss_objectness: 0.0728 (0.0722)  loss_rpn_box_reg: 0.0580 (0.0690)  time: 0.6792  data: 0.2896  max mem: 5067\n",
      "Training Epoch: [38]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1444 (0.1421)  loss_objectness: 0.0723 (0.0722)  loss_rpn_box_reg: 0.0686 (0.0699)  time: 0.6866  data: 0.2910  max mem: 5067\n",
      "Training Epoch: [38]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1417 (0.1423)  loss_objectness: 0.0748 (0.0724)  loss_rpn_box_reg: 0.0627 (0.0698)  time: 0.6764  data: 0.2936  max mem: 5067\n",
      "Training Epoch: [38]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1355 (0.1420)  loss_objectness: 0.0765 (0.0724)  loss_rpn_box_reg: 0.0606 (0.0696)  time: 0.6656  data: 0.2930  max mem: 5067\n",
      "Training Epoch: [38]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1379 (0.1422)  loss_objectness: 0.0685 (0.0722)  loss_rpn_box_reg: 0.0733 (0.0700)  time: 0.6848  data: 0.2921  max mem: 5067\n",
      "Training Epoch: [38]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1416 (0.1429)  loss_objectness: 0.0703 (0.0726)  loss_rpn_box_reg: 0.0736 (0.0703)  time: 0.6975  data: 0.2956  max mem: 5067\n",
      "Training Epoch: [38]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1416 (0.1433)  loss_objectness: 0.0794 (0.0731)  loss_rpn_box_reg: 0.0634 (0.0702)  time: 0.6861  data: 0.2959  max mem: 5067\n",
      "Training Epoch: [38]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1513 (0.1438)  loss_objectness: 0.0805 (0.0733)  loss_rpn_box_reg: 0.0635 (0.0705)  time: 0.6869  data: 0.2947  max mem: 5067\n",
      "Training Epoch: [38]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1457 (0.1441)  loss_objectness: 0.0791 (0.0736)  loss_rpn_box_reg: 0.0678 (0.0705)  time: 0.7058  data: 0.2942  max mem: 5067\n",
      "Training Epoch: [38] Total time: 0:02:51 (0.6861 s / it)\n",
      "Testing Epoch: [38]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1353 (0.1353)  loss_objectness: 0.0488 (0.0488)  loss_rpn_box_reg: 0.0864 (0.0864)  time: 0.7112  data: 0.3881  max mem: 5067\n",
      "Testing Epoch: [38]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1334 (0.1426)  loss_objectness: 0.0594 (0.0635)  loss_rpn_box_reg: 0.0751 (0.0791)  time: 0.6376  data: 0.3163  max mem: 5067\n",
      "Testing Epoch: [38] Total time: 0:00:39 (0.6364 s / it)\n",
      "Training Epoch: [39]  [  0/250]  eta: 0:03:08  lr: 0.000300  loss: 0.1136 (0.1136)  loss_objectness: 0.0630 (0.0630)  loss_rpn_box_reg: 0.0507 (0.0507)  time: 0.7542  data: 0.2721  max mem: 5067\n",
      "Training Epoch: [39]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1432 (0.1433)  loss_objectness: 0.0686 (0.0726)  loss_rpn_box_reg: 0.0750 (0.0707)  time: 0.6926  data: 0.2937  max mem: 5067\n",
      "Training Epoch: [39]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1447 (0.1465)  loss_objectness: 0.0752 (0.0749)  loss_rpn_box_reg: 0.0750 (0.0715)  time: 0.6835  data: 0.2964  max mem: 5067\n",
      "Training Epoch: [39]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1500 (0.1467)  loss_objectness: 0.0771 (0.0768)  loss_rpn_box_reg: 0.0703 (0.0699)  time: 0.6862  data: 0.2932  max mem: 5067\n",
      "Training Epoch: [39]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1404 (0.1450)  loss_objectness: 0.0810 (0.0771)  loss_rpn_box_reg: 0.0581 (0.0678)  time: 0.6966  data: 0.2930  max mem: 5067\n",
      "Training Epoch: [39]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1456 (0.1456)  loss_objectness: 0.0808 (0.0772)  loss_rpn_box_reg: 0.0664 (0.0684)  time: 0.6865  data: 0.2961  max mem: 5067\n",
      "Training Epoch: [39]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1268 (0.1412)  loss_objectness: 0.0674 (0.0748)  loss_rpn_box_reg: 0.0622 (0.0664)  time: 0.6725  data: 0.2889  max mem: 5067\n",
      "Training Epoch: [39]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1252 (0.1412)  loss_objectness: 0.0618 (0.0732)  loss_rpn_box_reg: 0.0622 (0.0680)  time: 0.6864  data: 0.2865  max mem: 5067\n",
      "Training Epoch: [39]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1310 (0.1407)  loss_objectness: 0.0689 (0.0728)  loss_rpn_box_reg: 0.0688 (0.0678)  time: 0.7025  data: 0.2925  max mem: 5067\n",
      "Training Epoch: [39]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1584 (0.1434)  loss_objectness: 0.0757 (0.0738)  loss_rpn_box_reg: 0.0803 (0.0695)  time: 0.6973  data: 0.2968  max mem: 5067\n",
      "Training Epoch: [39]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1532 (0.1433)  loss_objectness: 0.0753 (0.0733)  loss_rpn_box_reg: 0.0779 (0.0700)  time: 0.6957  data: 0.2961  max mem: 5067\n",
      "Training Epoch: [39]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1401 (0.1426)  loss_objectness: 0.0693 (0.0729)  loss_rpn_box_reg: 0.0693 (0.0697)  time: 0.7004  data: 0.2931  max mem: 5067\n",
      "Training Epoch: [39]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1358 (0.1427)  loss_objectness: 0.0752 (0.0737)  loss_rpn_box_reg: 0.0619 (0.0690)  time: 0.6778  data: 0.2902  max mem: 5067\n",
      "Training Epoch: [39]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1370 (0.1428)  loss_objectness: 0.0793 (0.0737)  loss_rpn_box_reg: 0.0634 (0.0691)  time: 0.6610  data: 0.2882  max mem: 5067\n",
      "Training Epoch: [39]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1370 (0.1423)  loss_objectness: 0.0684 (0.0741)  loss_rpn_box_reg: 0.0614 (0.0682)  time: 0.6718  data: 0.2900  max mem: 5067\n",
      "Training Epoch: [39]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1470 (0.1434)  loss_objectness: 0.0847 (0.0746)  loss_rpn_box_reg: 0.0647 (0.0688)  time: 0.6783  data: 0.2942  max mem: 5067\n",
      "Training Epoch: [39]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1622 (0.1443)  loss_objectness: 0.0810 (0.0748)  loss_rpn_box_reg: 0.0787 (0.0695)  time: 0.6816  data: 0.2981  max mem: 5067\n",
      "Training Epoch: [39]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1442 (0.1438)  loss_objectness: 0.0677 (0.0743)  loss_rpn_box_reg: 0.0690 (0.0694)  time: 0.6913  data: 0.2955  max mem: 5067\n",
      "Training Epoch: [39]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1391 (0.1439)  loss_objectness: 0.0759 (0.0750)  loss_rpn_box_reg: 0.0609 (0.0689)  time: 0.7091  data: 0.2968  max mem: 5067\n",
      "Training Epoch: [39]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1507 (0.1449)  loss_objectness: 0.0782 (0.0755)  loss_rpn_box_reg: 0.0640 (0.0694)  time: 0.7027  data: 0.2985  max mem: 5067\n",
      "Training Epoch: [39]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1573 (0.1461)  loss_objectness: 0.0782 (0.0759)  loss_rpn_box_reg: 0.0731 (0.0702)  time: 0.6807  data: 0.2955  max mem: 5067\n",
      "Training Epoch: [39]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1488 (0.1460)  loss_objectness: 0.0770 (0.0759)  loss_rpn_box_reg: 0.0710 (0.0701)  time: 0.6830  data: 0.2929  max mem: 5067\n",
      "Training Epoch: [39]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1425 (0.1460)  loss_objectness: 0.0770 (0.0762)  loss_rpn_box_reg: 0.0656 (0.0698)  time: 0.6764  data: 0.2933  max mem: 5067\n",
      "Training Epoch: [39]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1425 (0.1462)  loss_objectness: 0.0745 (0.0759)  loss_rpn_box_reg: 0.0735 (0.0703)  time: 0.6793  data: 0.2942  max mem: 5067\n",
      "Training Epoch: [39]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1588 (0.1471)  loss_objectness: 0.0798 (0.0760)  loss_rpn_box_reg: 0.0775 (0.0711)  time: 0.6878  data: 0.2934  max mem: 5067\n",
      "Training Epoch: [39]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1407 (0.1465)  loss_objectness: 0.0756 (0.0759)  loss_rpn_box_reg: 0.0686 (0.0706)  time: 0.6901  data: 0.2940  max mem: 5067\n",
      "Training Epoch: [39] Total time: 0:02:51 (0.6873 s / it)\n",
      "Testing Epoch: [39]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1373 (0.1373)  loss_objectness: 0.0484 (0.0484)  loss_rpn_box_reg: 0.0889 (0.0889)  time: 0.6261  data: 0.3001  max mem: 5067\n",
      "Testing Epoch: [39]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1293 (0.1416)  loss_objectness: 0.0577 (0.0622)  loss_rpn_box_reg: 0.0746 (0.0794)  time: 0.6365  data: 0.3118  max mem: 5067\n",
      "Testing Epoch: [39] Total time: 0:00:39 (0.6401 s / it)\n",
      "Training Epoch: [40]  [  0/250]  eta: 0:02:53  lr: 0.000300  loss: 0.1616 (0.1616)  loss_objectness: 0.0931 (0.0931)  loss_rpn_box_reg: 0.0685 (0.0685)  time: 0.6952  data: 0.2891  max mem: 5067\n",
      "Training Epoch: [40]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1415 (0.1416)  loss_objectness: 0.0777 (0.0786)  loss_rpn_box_reg: 0.0558 (0.0630)  time: 0.6978  data: 0.2955  max mem: 5067\n",
      "Training Epoch: [40]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1379 (0.1409)  loss_objectness: 0.0727 (0.0747)  loss_rpn_box_reg: 0.0585 (0.0662)  time: 0.6878  data: 0.2949  max mem: 5067\n",
      "Training Epoch: [40]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1373 (0.1414)  loss_objectness: 0.0727 (0.0756)  loss_rpn_box_reg: 0.0602 (0.0658)  time: 0.6862  data: 0.2932  max mem: 5067\n",
      "Training Epoch: [40]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1334 (0.1384)  loss_objectness: 0.0699 (0.0733)  loss_rpn_box_reg: 0.0558 (0.0651)  time: 0.6918  data: 0.2896  max mem: 5067\n",
      "Training Epoch: [40]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1334 (0.1399)  loss_objectness: 0.0654 (0.0735)  loss_rpn_box_reg: 0.0608 (0.0663)  time: 0.6870  data: 0.2924  max mem: 5067\n",
      "Training Epoch: [40]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1392 (0.1385)  loss_objectness: 0.0654 (0.0711)  loss_rpn_box_reg: 0.0722 (0.0674)  time: 0.6898  data: 0.2949  max mem: 5067\n",
      "Training Epoch: [40]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1327 (0.1388)  loss_objectness: 0.0641 (0.0708)  loss_rpn_box_reg: 0.0669 (0.0681)  time: 0.6971  data: 0.2929  max mem: 5067\n",
      "Training Epoch: [40]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1412 (0.1405)  loss_objectness: 0.0701 (0.0714)  loss_rpn_box_reg: 0.0655 (0.0691)  time: 0.6843  data: 0.2926  max mem: 5067\n",
      "Training Epoch: [40]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1603 (0.1433)  loss_objectness: 0.0809 (0.0731)  loss_rpn_box_reg: 0.0778 (0.0703)  time: 0.6712  data: 0.2933  max mem: 5067\n",
      "Training Epoch: [40]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1515 (0.1430)  loss_objectness: 0.0768 (0.0731)  loss_rpn_box_reg: 0.0756 (0.0699)  time: 0.6826  data: 0.2997  max mem: 5067\n",
      "Training Epoch: [40]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1471 (0.1437)  loss_objectness: 0.0732 (0.0735)  loss_rpn_box_reg: 0.0665 (0.0703)  time: 0.6942  data: 0.2972  max mem: 5067\n",
      "Training Epoch: [40]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1471 (0.1439)  loss_objectness: 0.0786 (0.0736)  loss_rpn_box_reg: 0.0726 (0.0703)  time: 0.6852  data: 0.2930  max mem: 5067\n",
      "Training Epoch: [40]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1426 (0.1445)  loss_objectness: 0.0775 (0.0740)  loss_rpn_box_reg: 0.0692 (0.0705)  time: 0.6689  data: 0.2891  max mem: 5067\n",
      "Training Epoch: [40]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1355 (0.1451)  loss_objectness: 0.0731 (0.0740)  loss_rpn_box_reg: 0.0692 (0.0711)  time: 0.6898  data: 0.2878  max mem: 5067\n",
      "Training Epoch: [40]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1355 (0.1446)  loss_objectness: 0.0685 (0.0737)  loss_rpn_box_reg: 0.0686 (0.0709)  time: 0.7021  data: 0.2946  max mem: 5067\n",
      "Training Epoch: [40]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1361 (0.1448)  loss_objectness: 0.0698 (0.0743)  loss_rpn_box_reg: 0.0561 (0.0705)  time: 0.6864  data: 0.2936  max mem: 5067\n",
      "Training Epoch: [40]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1391 (0.1450)  loss_objectness: 0.0744 (0.0746)  loss_rpn_box_reg: 0.0636 (0.0704)  time: 0.6898  data: 0.2918  max mem: 5067\n",
      "Training Epoch: [40]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1423 (0.1450)  loss_objectness: 0.0719 (0.0744)  loss_rpn_box_reg: 0.0721 (0.0706)  time: 0.6880  data: 0.2910  max mem: 5067\n",
      "Training Epoch: [40]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1413 (0.1445)  loss_objectness: 0.0715 (0.0746)  loss_rpn_box_reg: 0.0640 (0.0699)  time: 0.6770  data: 0.2887  max mem: 5067\n",
      "Training Epoch: [40]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1367 (0.1445)  loss_objectness: 0.0747 (0.0749)  loss_rpn_box_reg: 0.0544 (0.0695)  time: 0.6815  data: 0.2918  max mem: 5067\n",
      "Training Epoch: [40]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1509 (0.1453)  loss_objectness: 0.0789 (0.0754)  loss_rpn_box_reg: 0.0628 (0.0699)  time: 0.6904  data: 0.2946  max mem: 5067\n",
      "Training Epoch: [40]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1439 (0.1453)  loss_objectness: 0.0756 (0.0754)  loss_rpn_box_reg: 0.0664 (0.0698)  time: 0.6879  data: 0.2958  max mem: 5067\n",
      "Training Epoch: [40]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1431 (0.1458)  loss_objectness: 0.0822 (0.0758)  loss_rpn_box_reg: 0.0674 (0.0699)  time: 0.6776  data: 0.2932  max mem: 5067\n",
      "Training Epoch: [40]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1483 (0.1457)  loss_objectness: 0.0733 (0.0755)  loss_rpn_box_reg: 0.0739 (0.0702)  time: 0.6831  data: 0.2931  max mem: 5067\n",
      "Training Epoch: [40]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1516 (0.1460)  loss_objectness: 0.0629 (0.0754)  loss_rpn_box_reg: 0.0786 (0.0706)  time: 0.6889  data: 0.2928  max mem: 5067\n",
      "Training Epoch: [40] Total time: 0:02:51 (0.6866 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:06  model_time: 0.7272 (0.7272)  evaluator_time: 0.0540 (0.0540)  time: 1.0782  data: 0.2821  max mem: 5067\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3731 (0.3766)  evaluator_time: 0.0650 (0.0742)  time: 0.7576  data: 0.3087  max mem: 5216\n",
      "Test: Total time: 0:00:46 (0.7578 s / it)\n",
      "Averaged stats: model_time: 0.3731 (0.3766)  evaluator_time: 0.0650 (0.0742)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.99s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.099\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\n",
      "Testing Epoch: [40]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1352 (0.1352)  loss_objectness: 0.0415 (0.0415)  loss_rpn_box_reg: 0.0938 (0.0938)  time: 0.6111  data: 0.2841  max mem: 5216\n",
      "Testing Epoch: [40]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1334 (0.1413)  loss_objectness: 0.0550 (0.0577)  loss_rpn_box_reg: 0.0782 (0.0836)  time: 0.6367  data: 0.3154  max mem: 5216\n",
      "Testing Epoch: [40] Total time: 0:00:39 (0.6365 s / it)\n",
      "Training Epoch: [41]  [  0/250]  eta: 0:02:20  lr: 0.000300  loss: 0.1774 (0.1774)  loss_objectness: 0.0747 (0.0747)  loss_rpn_box_reg: 0.1027 (0.1027)  time: 0.5611  data: 0.3051  max mem: 5216\n",
      "Training Epoch: [41]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1391 (0.1417)  loss_objectness: 0.0668 (0.0696)  loss_rpn_box_reg: 0.0723 (0.0721)  time: 0.6833  data: 0.2931  max mem: 5216\n",
      "Training Epoch: [41]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1306 (0.1386)  loss_objectness: 0.0668 (0.0724)  loss_rpn_box_reg: 0.0612 (0.0662)  time: 0.7007  data: 0.2909  max mem: 5216\n",
      "Training Epoch: [41]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1245 (0.1347)  loss_objectness: 0.0706 (0.0692)  loss_rpn_box_reg: 0.0537 (0.0654)  time: 0.6937  data: 0.2949  max mem: 5216\n",
      "Training Epoch: [41]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1270 (0.1350)  loss_objectness: 0.0699 (0.0693)  loss_rpn_box_reg: 0.0697 (0.0657)  time: 0.6710  data: 0.2973  max mem: 5216\n",
      "Training Epoch: [41]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1400 (0.1379)  loss_objectness: 0.0705 (0.0712)  loss_rpn_box_reg: 0.0697 (0.0667)  time: 0.6760  data: 0.2943  max mem: 5216\n",
      "Training Epoch: [41]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1601 (0.1418)  loss_objectness: 0.0762 (0.0725)  loss_rpn_box_reg: 0.0735 (0.0693)  time: 0.6994  data: 0.2952  max mem: 5216\n",
      "Training Epoch: [41]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1566 (0.1427)  loss_objectness: 0.0731 (0.0724)  loss_rpn_box_reg: 0.0735 (0.0703)  time: 0.6941  data: 0.2957  max mem: 5216\n",
      "Training Epoch: [41]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1429 (0.1431)  loss_objectness: 0.0680 (0.0714)  loss_rpn_box_reg: 0.0741 (0.0717)  time: 0.6795  data: 0.2937  max mem: 5216\n",
      "Training Epoch: [41]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1399 (0.1444)  loss_objectness: 0.0686 (0.0724)  loss_rpn_box_reg: 0.0741 (0.0720)  time: 0.6844  data: 0.2916  max mem: 5216\n",
      "Training Epoch: [41]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1467 (0.1440)  loss_objectness: 0.0730 (0.0727)  loss_rpn_box_reg: 0.0641 (0.0713)  time: 0.6804  data: 0.2920  max mem: 5216\n",
      "Training Epoch: [41]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1370 (0.1430)  loss_objectness: 0.0766 (0.0734)  loss_rpn_box_reg: 0.0510 (0.0696)  time: 0.6687  data: 0.2919  max mem: 5216\n",
      "Training Epoch: [41]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1370 (0.1434)  loss_objectness: 0.0791 (0.0739)  loss_rpn_box_reg: 0.0540 (0.0695)  time: 0.6929  data: 0.2931  max mem: 5216\n",
      "Training Epoch: [41]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1462 (0.1441)  loss_objectness: 0.0754 (0.0743)  loss_rpn_box_reg: 0.0708 (0.0698)  time: 0.7032  data: 0.2954  max mem: 5216\n",
      "Training Epoch: [41]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1451 (0.1442)  loss_objectness: 0.0706 (0.0741)  loss_rpn_box_reg: 0.0708 (0.0701)  time: 0.6869  data: 0.2931  max mem: 5216\n",
      "Training Epoch: [41]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1387 (0.1454)  loss_objectness: 0.0706 (0.0750)  loss_rpn_box_reg: 0.0633 (0.0704)  time: 0.6820  data: 0.2915  max mem: 5216\n",
      "Training Epoch: [41]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1490 (0.1461)  loss_objectness: 0.0831 (0.0756)  loss_rpn_box_reg: 0.0642 (0.0705)  time: 0.6897  data: 0.2936  max mem: 5216\n",
      "Training Epoch: [41]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1586 (0.1472)  loss_objectness: 0.0831 (0.0761)  loss_rpn_box_reg: 0.0715 (0.0711)  time: 0.6909  data: 0.2960  max mem: 5216\n",
      "Training Epoch: [41]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1378 (0.1467)  loss_objectness: 0.0724 (0.0756)  loss_rpn_box_reg: 0.0669 (0.0711)  time: 0.6770  data: 0.2939  max mem: 5216\n",
      "Training Epoch: [41]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1378 (0.1468)  loss_objectness: 0.0691 (0.0756)  loss_rpn_box_reg: 0.0653 (0.0712)  time: 0.6766  data: 0.2907  max mem: 5216\n",
      "Training Epoch: [41]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1529 (0.1475)  loss_objectness: 0.0781 (0.0762)  loss_rpn_box_reg: 0.0722 (0.0712)  time: 0.6837  data: 0.2935  max mem: 5216\n",
      "Training Epoch: [41]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1456 (0.1468)  loss_objectness: 0.0742 (0.0761)  loss_rpn_box_reg: 0.0718 (0.0707)  time: 0.6938  data: 0.2951  max mem: 5216\n",
      "Training Epoch: [41]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1387 (0.1482)  loss_objectness: 0.0720 (0.0767)  loss_rpn_box_reg: 0.0719 (0.0715)  time: 0.6850  data: 0.2947  max mem: 5216\n",
      "Training Epoch: [41]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1470 (0.1478)  loss_objectness: 0.0763 (0.0765)  loss_rpn_box_reg: 0.0719 (0.0713)  time: 0.6868  data: 0.2941  max mem: 5216\n",
      "Training Epoch: [41]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1294 (0.1476)  loss_objectness: 0.0713 (0.0766)  loss_rpn_box_reg: 0.0598 (0.0709)  time: 0.6931  data: 0.2914  max mem: 5216\n",
      "Training Epoch: [41]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1412 (0.1475)  loss_objectness: 0.0690 (0.0764)  loss_rpn_box_reg: 0.0641 (0.0711)  time: 0.6814  data: 0.2922  max mem: 5216\n",
      "Training Epoch: [41] Total time: 0:02:51 (0.6860 s / it)\n",
      "Testing Epoch: [41]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1310 (0.1310)  loss_objectness: 0.0423 (0.0423)  loss_rpn_box_reg: 0.0887 (0.0887)  time: 0.6301  data: 0.3031  max mem: 5216\n",
      "Testing Epoch: [41]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1339 (0.1411)  loss_objectness: 0.0564 (0.0597)  loss_rpn_box_reg: 0.0770 (0.0814)  time: 0.6345  data: 0.3109  max mem: 5216\n",
      "Testing Epoch: [41] Total time: 0:00:39 (0.6374 s / it)\n",
      "Training Epoch: [42]  [  0/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1434 (0.1434)  loss_objectness: 0.0589 (0.0589)  loss_rpn_box_reg: 0.0845 (0.0845)  time: 0.6581  data: 0.3031  max mem: 5216\n",
      "Training Epoch: [42]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1368 (0.1346)  loss_objectness: 0.0621 (0.0681)  loss_rpn_box_reg: 0.0578 (0.0665)  time: 0.6982  data: 0.2942  max mem: 5216\n",
      "Training Epoch: [42]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1339 (0.1353)  loss_objectness: 0.0700 (0.0701)  loss_rpn_box_reg: 0.0578 (0.0652)  time: 0.7009  data: 0.2930  max mem: 5216\n",
      "Training Epoch: [42]  [ 30/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1404 (0.1420)  loss_objectness: 0.0711 (0.0716)  loss_rpn_box_reg: 0.0650 (0.0704)  time: 0.7012  data: 0.2939  max mem: 5216\n",
      "Training Epoch: [42]  [ 40/250]  eta: 0:02:26  lr: 0.000300  loss: 0.1483 (0.1436)  loss_objectness: 0.0711 (0.0723)  loss_rpn_box_reg: 0.0700 (0.0713)  time: 0.6918  data: 0.2919  max mem: 5216\n",
      "Training Epoch: [42]  [ 50/250]  eta: 0:02:20  lr: 0.000300  loss: 0.1394 (0.1422)  loss_objectness: 0.0656 (0.0727)  loss_rpn_box_reg: 0.0668 (0.0696)  time: 0.7004  data: 0.2918  max mem: 5216\n",
      "Training Epoch: [42]  [ 60/250]  eta: 0:02:12  lr: 0.000300  loss: 0.1420 (0.1453)  loss_objectness: 0.0761 (0.0735)  loss_rpn_box_reg: 0.0696 (0.0718)  time: 0.7002  data: 0.2947  max mem: 5216\n",
      "Training Epoch: [42]  [ 70/250]  eta: 0:02:05  lr: 0.000300  loss: 0.1457 (0.1443)  loss_objectness: 0.0713 (0.0731)  loss_rpn_box_reg: 0.0746 (0.0711)  time: 0.6811  data: 0.2942  max mem: 5216\n",
      "Training Epoch: [42]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1377 (0.1445)  loss_objectness: 0.0703 (0.0736)  loss_rpn_box_reg: 0.0630 (0.0709)  time: 0.6772  data: 0.2961  max mem: 5216\n",
      "Training Epoch: [42]  [ 90/250]  eta: 0:01:51  lr: 0.000300  loss: 0.1323 (0.1436)  loss_objectness: 0.0690 (0.0729)  loss_rpn_box_reg: 0.0655 (0.0707)  time: 0.6921  data: 0.2966  max mem: 5216\n",
      "Training Epoch: [42]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1402 (0.1441)  loss_objectness: 0.0685 (0.0726)  loss_rpn_box_reg: 0.0660 (0.0715)  time: 0.6978  data: 0.2923  max mem: 5216\n",
      "Training Epoch: [42]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1509 (0.1450)  loss_objectness: 0.0752 (0.0733)  loss_rpn_box_reg: 0.0727 (0.0717)  time: 0.6744  data: 0.2897  max mem: 5216\n",
      "Training Epoch: [42]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1458 (0.1456)  loss_objectness: 0.0757 (0.0738)  loss_rpn_box_reg: 0.0717 (0.0718)  time: 0.6798  data: 0.2939  max mem: 5216\n",
      "Training Epoch: [42]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1416 (0.1454)  loss_objectness: 0.0687 (0.0732)  loss_rpn_box_reg: 0.0698 (0.0722)  time: 0.6796  data: 0.2950  max mem: 5216\n",
      "Training Epoch: [42]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1329 (0.1446)  loss_objectness: 0.0666 (0.0732)  loss_rpn_box_reg: 0.0665 (0.0714)  time: 0.6718  data: 0.2945  max mem: 5216\n",
      "Training Epoch: [42]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1331 (0.1450)  loss_objectness: 0.0741 (0.0737)  loss_rpn_box_reg: 0.0686 (0.0713)  time: 0.6882  data: 0.3022  max mem: 5216\n",
      "Training Epoch: [42]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1409 (0.1446)  loss_objectness: 0.0673 (0.0732)  loss_rpn_box_reg: 0.0718 (0.0714)  time: 0.6988  data: 0.3035  max mem: 5216\n",
      "Training Epoch: [42]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1289 (0.1437)  loss_objectness: 0.0617 (0.0729)  loss_rpn_box_reg: 0.0635 (0.0708)  time: 0.6879  data: 0.2966  max mem: 5216\n",
      "Training Epoch: [42]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1289 (0.1437)  loss_objectness: 0.0617 (0.0728)  loss_rpn_box_reg: 0.0611 (0.0708)  time: 0.6846  data: 0.2912  max mem: 5216\n",
      "Training Epoch: [42]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1461 (0.1440)  loss_objectness: 0.0702 (0.0731)  loss_rpn_box_reg: 0.0681 (0.0709)  time: 0.6865  data: 0.2918  max mem: 5216\n",
      "Training Epoch: [42]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1419 (0.1441)  loss_objectness: 0.0767 (0.0732)  loss_rpn_box_reg: 0.0704 (0.0708)  time: 0.6795  data: 0.2960  max mem: 5216\n",
      "Training Epoch: [42]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1410 (0.1435)  loss_objectness: 0.0723 (0.0730)  loss_rpn_box_reg: 0.0631 (0.0705)  time: 0.6838  data: 0.2938  max mem: 5216\n",
      "Training Epoch: [42]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1438 (0.1440)  loss_objectness: 0.0674 (0.0729)  loss_rpn_box_reg: 0.0632 (0.0710)  time: 0.6861  data: 0.2954  max mem: 5216\n",
      "Training Epoch: [42]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1462 (0.1438)  loss_objectness: 0.0663 (0.0729)  loss_rpn_box_reg: 0.0667 (0.0710)  time: 0.6933  data: 0.2986  max mem: 5216\n",
      "Training Epoch: [42]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1328 (0.1437)  loss_objectness: 0.0731 (0.0730)  loss_rpn_box_reg: 0.0635 (0.0707)  time: 0.7005  data: 0.2907  max mem: 5216\n",
      "Training Epoch: [42]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1434 (0.1439)  loss_objectness: 0.0759 (0.0733)  loss_rpn_box_reg: 0.0651 (0.0706)  time: 0.7007  data: 0.2897  max mem: 5216\n",
      "Training Epoch: [42] Total time: 0:02:52 (0.6894 s / it)\n",
      "Testing Epoch: [42]  [ 0/62]  eta: 0:00:46  lr: 0.000300  loss: 0.1375 (0.1375)  loss_objectness: 0.0499 (0.0499)  loss_rpn_box_reg: 0.0875 (0.0875)  time: 0.7492  data: 0.4151  max mem: 5216\n",
      "Testing Epoch: [42]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1350 (0.1424)  loss_objectness: 0.0583 (0.0623)  loss_rpn_box_reg: 0.0775 (0.0801)  time: 0.6301  data: 0.3118  max mem: 5216\n",
      "Testing Epoch: [42] Total time: 0:00:39 (0.6348 s / it)\n",
      "Training Epoch: [43]  [  0/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1347 (0.1347)  loss_objectness: 0.0653 (0.0653)  loss_rpn_box_reg: 0.0694 (0.0694)  time: 0.6692  data: 0.2981  max mem: 5216\n",
      "Training Epoch: [43]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1347 (0.1346)  loss_objectness: 0.0695 (0.0704)  loss_rpn_box_reg: 0.0694 (0.0642)  time: 0.6741  data: 0.2909  max mem: 5216\n",
      "Training Epoch: [43]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1291 (0.1422)  loss_objectness: 0.0695 (0.0701)  loss_rpn_box_reg: 0.0726 (0.0721)  time: 0.6892  data: 0.2918  max mem: 5216\n",
      "Training Epoch: [43]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1365 (0.1414)  loss_objectness: 0.0661 (0.0702)  loss_rpn_box_reg: 0.0684 (0.0713)  time: 0.6916  data: 0.2945  max mem: 5216\n",
      "Training Epoch: [43]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1365 (0.1423)  loss_objectness: 0.0654 (0.0712)  loss_rpn_box_reg: 0.0638 (0.0712)  time: 0.6900  data: 0.2943  max mem: 5216\n",
      "Training Epoch: [43]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1352 (0.1432)  loss_objectness: 0.0689 (0.0712)  loss_rpn_box_reg: 0.0695 (0.0720)  time: 0.6861  data: 0.2923  max mem: 5216\n",
      "Training Epoch: [43]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1352 (0.1417)  loss_objectness: 0.0703 (0.0720)  loss_rpn_box_reg: 0.0643 (0.0697)  time: 0.6776  data: 0.2938  max mem: 5216\n",
      "Training Epoch: [43]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1344 (0.1410)  loss_objectness: 0.0685 (0.0718)  loss_rpn_box_reg: 0.0607 (0.0692)  time: 0.6844  data: 0.2953  max mem: 5216\n",
      "Training Epoch: [43]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1386 (0.1416)  loss_objectness: 0.0654 (0.0713)  loss_rpn_box_reg: 0.0697 (0.0703)  time: 0.6951  data: 0.2944  max mem: 5216\n",
      "Training Epoch: [43]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1430 (0.1415)  loss_objectness: 0.0644 (0.0711)  loss_rpn_box_reg: 0.0704 (0.0704)  time: 0.6984  data: 0.2937  max mem: 5216\n",
      "Training Epoch: [43]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1359 (0.1417)  loss_objectness: 0.0677 (0.0720)  loss_rpn_box_reg: 0.0665 (0.0698)  time: 0.6928  data: 0.2938  max mem: 5216\n",
      "Training Epoch: [43]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1359 (0.1416)  loss_objectness: 0.0770 (0.0726)  loss_rpn_box_reg: 0.0580 (0.0690)  time: 0.7017  data: 0.2943  max mem: 5216\n",
      "Training Epoch: [43]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1443 (0.1427)  loss_objectness: 0.0773 (0.0728)  loss_rpn_box_reg: 0.0647 (0.0699)  time: 0.6984  data: 0.2935  max mem: 5216\n",
      "Training Epoch: [43]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1337 (0.1412)  loss_objectness: 0.0633 (0.0718)  loss_rpn_box_reg: 0.0668 (0.0694)  time: 0.6935  data: 0.2902  max mem: 5216\n",
      "Training Epoch: [43]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1304 (0.1422)  loss_objectness: 0.0621 (0.0717)  loss_rpn_box_reg: 0.0624 (0.0705)  time: 0.6921  data: 0.2919  max mem: 5216\n",
      "Training Epoch: [43]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1478 (0.1426)  loss_objectness: 0.0673 (0.0712)  loss_rpn_box_reg: 0.0717 (0.0714)  time: 0.6827  data: 0.2923  max mem: 5216\n",
      "Training Epoch: [43]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1426 (0.1423)  loss_objectness: 0.0699 (0.0716)  loss_rpn_box_reg: 0.0705 (0.0707)  time: 0.6800  data: 0.2896  max mem: 5216\n",
      "Training Epoch: [43]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1346 (0.1420)  loss_objectness: 0.0715 (0.0718)  loss_rpn_box_reg: 0.0621 (0.0702)  time: 0.6776  data: 0.2900  max mem: 5216\n",
      "Training Epoch: [43]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1429 (0.1422)  loss_objectness: 0.0739 (0.0722)  loss_rpn_box_reg: 0.0645 (0.0700)  time: 0.6832  data: 0.2892  max mem: 5216\n",
      "Training Epoch: [43]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1465 (0.1429)  loss_objectness: 0.0879 (0.0732)  loss_rpn_box_reg: 0.0645 (0.0697)  time: 0.6879  data: 0.2943  max mem: 5216\n",
      "Training Epoch: [43]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1421 (0.1426)  loss_objectness: 0.0775 (0.0732)  loss_rpn_box_reg: 0.0614 (0.0694)  time: 0.6802  data: 0.2953  max mem: 5216\n",
      "Training Epoch: [43]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1320 (0.1426)  loss_objectness: 0.0739 (0.0733)  loss_rpn_box_reg: 0.0612 (0.0693)  time: 0.6729  data: 0.2924  max mem: 5216\n",
      "Training Epoch: [43]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1482 (0.1427)  loss_objectness: 0.0739 (0.0735)  loss_rpn_box_reg: 0.0603 (0.0692)  time: 0.6883  data: 0.2940  max mem: 5216\n",
      "Training Epoch: [43]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1482 (0.1432)  loss_objectness: 0.0694 (0.0734)  loss_rpn_box_reg: 0.0737 (0.0698)  time: 0.6987  data: 0.2924  max mem: 5216\n",
      "Training Epoch: [43]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1403 (0.1436)  loss_objectness: 0.0750 (0.0738)  loss_rpn_box_reg: 0.0798 (0.0698)  time: 0.6956  data: 0.2903  max mem: 5216\n",
      "Training Epoch: [43]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1403 (0.1435)  loss_objectness: 0.0742 (0.0735)  loss_rpn_box_reg: 0.0653 (0.0700)  time: 0.6903  data: 0.2938  max mem: 5216\n",
      "Training Epoch: [43] Total time: 0:02:52 (0.6882 s / it)\n",
      "Testing Epoch: [43]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1333 (0.1333)  loss_objectness: 0.0421 (0.0421)  loss_rpn_box_reg: 0.0912 (0.0912)  time: 0.6451  data: 0.2901  max mem: 5216\n",
      "Testing Epoch: [43]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1265 (0.1395)  loss_objectness: 0.0515 (0.0574)  loss_rpn_box_reg: 0.0767 (0.0821)  time: 0.6289  data: 0.3096  max mem: 5216\n",
      "Testing Epoch: [43] Total time: 0:00:39 (0.6388 s / it)\n",
      "Training Epoch: [44]  [  0/250]  eta: 0:02:59  lr: 0.000300  loss: 0.1109 (0.1109)  loss_objectness: 0.0769 (0.0769)  loss_rpn_box_reg: 0.0340 (0.0340)  time: 0.7162  data: 0.3051  max mem: 5216\n",
      "Training Epoch: [44]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1282 (0.1357)  loss_objectness: 0.0698 (0.0685)  loss_rpn_box_reg: 0.0724 (0.0672)  time: 0.6950  data: 0.2945  max mem: 5216\n",
      "Training Epoch: [44]  [ 20/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1370 (0.1364)  loss_objectness: 0.0698 (0.0716)  loss_rpn_box_reg: 0.0721 (0.0649)  time: 0.7006  data: 0.2977  max mem: 5216\n",
      "Training Epoch: [44]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1375 (0.1410)  loss_objectness: 0.0719 (0.0716)  loss_rpn_box_reg: 0.0733 (0.0694)  time: 0.6903  data: 0.2951  max mem: 5216\n",
      "Training Epoch: [44]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1479 (0.1435)  loss_objectness: 0.0794 (0.0759)  loss_rpn_box_reg: 0.0668 (0.0676)  time: 0.6877  data: 0.2935  max mem: 5216\n",
      "Training Epoch: [44]  [ 50/250]  eta: 0:02:19  lr: 0.000300  loss: 0.1432 (0.1451)  loss_objectness: 0.0776 (0.0759)  loss_rpn_box_reg: 0.0647 (0.0692)  time: 0.7024  data: 0.2957  max mem: 5216\n",
      "Training Epoch: [44]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1432 (0.1450)  loss_objectness: 0.0719 (0.0755)  loss_rpn_box_reg: 0.0648 (0.0695)  time: 0.6791  data: 0.2917  max mem: 5216\n",
      "Training Epoch: [44]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1358 (0.1435)  loss_objectness: 0.0677 (0.0747)  loss_rpn_box_reg: 0.0552 (0.0688)  time: 0.6672  data: 0.2909  max mem: 5216\n",
      "Training Epoch: [44]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1323 (0.1419)  loss_objectness: 0.0605 (0.0733)  loss_rpn_box_reg: 0.0613 (0.0687)  time: 0.6911  data: 0.2907  max mem: 5216\n",
      "Training Epoch: [44]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1323 (0.1415)  loss_objectness: 0.0662 (0.0740)  loss_rpn_box_reg: 0.0607 (0.0675)  time: 0.6900  data: 0.2936  max mem: 5216\n",
      "Training Epoch: [44]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1341 (0.1420)  loss_objectness: 0.0667 (0.0735)  loss_rpn_box_reg: 0.0607 (0.0685)  time: 0.6822  data: 0.2916  max mem: 5216\n",
      "Training Epoch: [44]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1384 (0.1428)  loss_objectness: 0.0649 (0.0734)  loss_rpn_box_reg: 0.0666 (0.0694)  time: 0.6887  data: 0.2912  max mem: 5216\n",
      "Training Epoch: [44]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1352 (0.1430)  loss_objectness: 0.0671 (0.0733)  loss_rpn_box_reg: 0.0682 (0.0697)  time: 0.6876  data: 0.2952  max mem: 5216\n",
      "Training Epoch: [44]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1292 (0.1431)  loss_objectness: 0.0688 (0.0736)  loss_rpn_box_reg: 0.0675 (0.0695)  time: 0.6829  data: 0.2969  max mem: 5216\n",
      "Training Epoch: [44]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1387 (0.1427)  loss_objectness: 0.0688 (0.0733)  loss_rpn_box_reg: 0.0659 (0.0694)  time: 0.6716  data: 0.2976  max mem: 5216\n",
      "Training Epoch: [44]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1394 (0.1436)  loss_objectness: 0.0683 (0.0736)  loss_rpn_box_reg: 0.0662 (0.0700)  time: 0.6727  data: 0.2941  max mem: 5216\n",
      "Training Epoch: [44]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1432 (0.1435)  loss_objectness: 0.0706 (0.0734)  loss_rpn_box_reg: 0.0670 (0.0701)  time: 0.6868  data: 0.2909  max mem: 5216\n",
      "Training Epoch: [44]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1517 (0.1453)  loss_objectness: 0.0745 (0.0738)  loss_rpn_box_reg: 0.0720 (0.0715)  time: 0.6833  data: 0.2919  max mem: 5216\n",
      "Training Epoch: [44]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1517 (0.1451)  loss_objectness: 0.0766 (0.0740)  loss_rpn_box_reg: 0.0685 (0.0711)  time: 0.6785  data: 0.2955  max mem: 5216\n",
      "Training Epoch: [44]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1473 (0.1452)  loss_objectness: 0.0717 (0.0741)  loss_rpn_box_reg: 0.0661 (0.0711)  time: 0.6983  data: 0.2950  max mem: 5216\n",
      "Training Epoch: [44]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1423 (0.1442)  loss_objectness: 0.0704 (0.0735)  loss_rpn_box_reg: 0.0649 (0.0706)  time: 0.7059  data: 0.2904  max mem: 5216\n",
      "Training Epoch: [44]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1364 (0.1445)  loss_objectness: 0.0721 (0.0739)  loss_rpn_box_reg: 0.0615 (0.0705)  time: 0.6901  data: 0.2892  max mem: 5216\n",
      "Training Epoch: [44]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1488 (0.1449)  loss_objectness: 0.0824 (0.0741)  loss_rpn_box_reg: 0.0696 (0.0709)  time: 0.6743  data: 0.2920  max mem: 5216\n",
      "Training Epoch: [44]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1488 (0.1447)  loss_objectness: 0.0715 (0.0741)  loss_rpn_box_reg: 0.0692 (0.0706)  time: 0.6697  data: 0.2919  max mem: 5216\n",
      "Training Epoch: [44]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1458 (0.1449)  loss_objectness: 0.0674 (0.0739)  loss_rpn_box_reg: 0.0692 (0.0710)  time: 0.6719  data: 0.2936  max mem: 5216\n",
      "Training Epoch: [44]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1375 (0.1446)  loss_objectness: 0.0698 (0.0743)  loss_rpn_box_reg: 0.0627 (0.0703)  time: 0.6906  data: 0.2953  max mem: 5216\n",
      "Training Epoch: [44] Total time: 0:02:51 (0.6857 s / it)\n",
      "Testing Epoch: [44]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1325 (0.1325)  loss_objectness: 0.0440 (0.0440)  loss_rpn_box_reg: 0.0885 (0.0885)  time: 0.7222  data: 0.3991  max mem: 5216\n",
      "Testing Epoch: [44]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1308 (0.1388)  loss_objectness: 0.0577 (0.0598)  loss_rpn_box_reg: 0.0725 (0.0789)  time: 0.6359  data: 0.3103  max mem: 5216\n",
      "Testing Epoch: [44] Total time: 0:00:39 (0.6389 s / it)\n",
      "Training Epoch: [45]  [  0/250]  eta: 0:02:46  lr: 0.000300  loss: 0.0865 (0.0865)  loss_objectness: 0.0428 (0.0428)  loss_rpn_box_reg: 0.0437 (0.0437)  time: 0.6662  data: 0.2811  max mem: 5216\n",
      "Training Epoch: [45]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1338 (0.1324)  loss_objectness: 0.0707 (0.0736)  loss_rpn_box_reg: 0.0604 (0.0588)  time: 0.6822  data: 0.2871  max mem: 5216\n",
      "Training Epoch: [45]  [ 20/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1414 (0.1362)  loss_objectness: 0.0728 (0.0734)  loss_rpn_box_reg: 0.0704 (0.0628)  time: 0.6786  data: 0.2917  max mem: 5216\n",
      "Training Epoch: [45]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1438 (0.1383)  loss_objectness: 0.0756 (0.0744)  loss_rpn_box_reg: 0.0691 (0.0639)  time: 0.7010  data: 0.2968  max mem: 5216\n",
      "Training Epoch: [45]  [ 40/250]  eta: 0:02:26  lr: 0.000300  loss: 0.1473 (0.1446)  loss_objectness: 0.0800 (0.0763)  loss_rpn_box_reg: 0.0675 (0.0683)  time: 0.7188  data: 0.2987  max mem: 5216\n",
      "Training Epoch: [45]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1547 (0.1440)  loss_objectness: 0.0700 (0.0761)  loss_rpn_box_reg: 0.0661 (0.0678)  time: 0.6882  data: 0.2970  max mem: 5216\n",
      "Training Epoch: [45]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1477 (0.1447)  loss_objectness: 0.0669 (0.0754)  loss_rpn_box_reg: 0.0641 (0.0693)  time: 0.6817  data: 0.2938  max mem: 5216\n",
      "Training Epoch: [45]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1477 (0.1444)  loss_objectness: 0.0689 (0.0742)  loss_rpn_box_reg: 0.0676 (0.0702)  time: 0.6934  data: 0.2920  max mem: 5216\n",
      "Training Epoch: [45]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1204 (0.1442)  loss_objectness: 0.0710 (0.0743)  loss_rpn_box_reg: 0.0633 (0.0699)  time: 0.6871  data: 0.2880  max mem: 5216\n",
      "Training Epoch: [45]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1259 (0.1437)  loss_objectness: 0.0666 (0.0735)  loss_rpn_box_reg: 0.0618 (0.0702)  time: 0.6851  data: 0.2899  max mem: 5216\n",
      "Training Epoch: [45]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1434 (0.1445)  loss_objectness: 0.0660 (0.0735)  loss_rpn_box_reg: 0.0720 (0.0711)  time: 0.6987  data: 0.2992  max mem: 5216\n",
      "Training Epoch: [45]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1400 (0.1447)  loss_objectness: 0.0767 (0.0737)  loss_rpn_box_reg: 0.0698 (0.0710)  time: 0.6952  data: 0.3002  max mem: 5216\n",
      "Training Epoch: [45]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1405 (0.1456)  loss_objectness: 0.0767 (0.0741)  loss_rpn_box_reg: 0.0698 (0.0715)  time: 0.6805  data: 0.2960  max mem: 5216\n",
      "Training Epoch: [45]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1422 (0.1462)  loss_objectness: 0.0784 (0.0744)  loss_rpn_box_reg: 0.0698 (0.0718)  time: 0.6902  data: 0.2943  max mem: 5216\n",
      "Training Epoch: [45]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1393 (0.1453)  loss_objectness: 0.0673 (0.0737)  loss_rpn_box_reg: 0.0615 (0.0715)  time: 0.6927  data: 0.2953  max mem: 5216\n",
      "Training Epoch: [45]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1377 (0.1455)  loss_objectness: 0.0686 (0.0739)  loss_rpn_box_reg: 0.0652 (0.0716)  time: 0.6952  data: 0.2956  max mem: 5216\n",
      "Training Epoch: [45]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1401 (0.1454)  loss_objectness: 0.0689 (0.0740)  loss_rpn_box_reg: 0.0727 (0.0714)  time: 0.6954  data: 0.2903  max mem: 5216\n",
      "Training Epoch: [45]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1463 (0.1458)  loss_objectness: 0.0718 (0.0740)  loss_rpn_box_reg: 0.0780 (0.0719)  time: 0.6926  data: 0.2891  max mem: 5216\n",
      "Training Epoch: [45]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1465 (0.1455)  loss_objectness: 0.0718 (0.0739)  loss_rpn_box_reg: 0.0708 (0.0716)  time: 0.6940  data: 0.2913  max mem: 5216\n",
      "Training Epoch: [45]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1345 (0.1450)  loss_objectness: 0.0676 (0.0737)  loss_rpn_box_reg: 0.0661 (0.0713)  time: 0.6872  data: 0.2933  max mem: 5216\n",
      "Training Epoch: [45]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1367 (0.1452)  loss_objectness: 0.0708 (0.0738)  loss_rpn_box_reg: 0.0667 (0.0714)  time: 0.6866  data: 0.2957  max mem: 5216\n",
      "Training Epoch: [45]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1439 (0.1447)  loss_objectness: 0.0741 (0.0737)  loss_rpn_box_reg: 0.0652 (0.0710)  time: 0.6921  data: 0.2951  max mem: 5216\n",
      "Training Epoch: [45]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1439 (0.1454)  loss_objectness: 0.0718 (0.0740)  loss_rpn_box_reg: 0.0710 (0.0714)  time: 0.6919  data: 0.2931  max mem: 5216\n",
      "Training Epoch: [45]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1428 (0.1448)  loss_objectness: 0.0713 (0.0737)  loss_rpn_box_reg: 0.0708 (0.0710)  time: 0.6699  data: 0.2885  max mem: 5216\n",
      "Training Epoch: [45]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1402 (0.1447)  loss_objectness: 0.0761 (0.0740)  loss_rpn_box_reg: 0.0627 (0.0707)  time: 0.6735  data: 0.2893  max mem: 5216\n",
      "Training Epoch: [45]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1386 (0.1441)  loss_objectness: 0.0761 (0.0740)  loss_rpn_box_reg: 0.0618 (0.0702)  time: 0.6792  data: 0.2893  max mem: 5216\n",
      "Training Epoch: [45] Total time: 0:02:52 (0.6894 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:05  model_time: 0.6081 (0.6081)  evaluator_time: 0.0570 (0.0570)  time: 1.0612  data: 0.3811  max mem: 5216\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3781 (0.3838)  evaluator_time: 0.0670 (0.0785)  time: 0.7655  data: 0.3011  max mem: 5528\n",
      "Test: Total time: 0:00:47 (0.7691 s / it)\n",
      "Averaged stats: model_time: 0.3781 (0.3838)  evaluator_time: 0.0670 (0.0785)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.05s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.166\n",
      "Testing Epoch: [45]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1342 (0.1342)  loss_objectness: 0.0474 (0.0474)  loss_rpn_box_reg: 0.0868 (0.0868)  time: 0.6151  data: 0.2931  max mem: 5528\n",
      "Testing Epoch: [45]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1309 (0.1375)  loss_objectness: 0.0553 (0.0587)  loss_rpn_box_reg: 0.0726 (0.0788)  time: 0.6410  data: 0.3125  max mem: 5528\n",
      "Testing Epoch: [45] Total time: 0:00:39 (0.6395 s / it)\n",
      "Training Epoch: [46]  [  0/250]  eta: 0:02:55  lr: 0.000300  loss: 0.1099 (0.1099)  loss_objectness: 0.0565 (0.0565)  loss_rpn_box_reg: 0.0534 (0.0534)  time: 0.7022  data: 0.2991  max mem: 5528\n",
      "Training Epoch: [46]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1358 (0.1468)  loss_objectness: 0.0809 (0.0814)  loss_rpn_box_reg: 0.0614 (0.0654)  time: 0.6800  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [46]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1276 (0.1358)  loss_objectness: 0.0707 (0.0719)  loss_rpn_box_reg: 0.0614 (0.0639)  time: 0.6964  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [46]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1363 (0.1394)  loss_objectness: 0.0698 (0.0755)  loss_rpn_box_reg: 0.0631 (0.0639)  time: 0.7002  data: 0.2886  max mem: 5528\n",
      "Training Epoch: [46]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1382 (0.1381)  loss_objectness: 0.0715 (0.0756)  loss_rpn_box_reg: 0.0541 (0.0625)  time: 0.6862  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [46]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1357 (0.1388)  loss_objectness: 0.0667 (0.0741)  loss_rpn_box_reg: 0.0585 (0.0647)  time: 0.6805  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [46]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1236 (0.1380)  loss_objectness: 0.0656 (0.0728)  loss_rpn_box_reg: 0.0633 (0.0653)  time: 0.6763  data: 0.2865  max mem: 5528\n",
      "Training Epoch: [46]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1230 (0.1393)  loss_objectness: 0.0711 (0.0732)  loss_rpn_box_reg: 0.0566 (0.0661)  time: 0.6694  data: 0.2880  max mem: 5528\n",
      "Training Epoch: [46]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1425 (0.1393)  loss_objectness: 0.0757 (0.0731)  loss_rpn_box_reg: 0.0579 (0.0662)  time: 0.7037  data: 0.3047  max mem: 5528\n",
      "Training Epoch: [46]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1450 (0.1405)  loss_objectness: 0.0792 (0.0736)  loss_rpn_box_reg: 0.0643 (0.0669)  time: 0.7324  data: 0.3121  max mem: 5528\n",
      "Training Epoch: [46]  [100/250]  eta: 0:01:44  lr: 0.000300  loss: 0.1400 (0.1408)  loss_objectness: 0.0795 (0.0738)  loss_rpn_box_reg: 0.0648 (0.0670)  time: 0.7197  data: 0.3001  max mem: 5528\n",
      "Training Epoch: [46]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1234 (0.1395)  loss_objectness: 0.0655 (0.0731)  loss_rpn_box_reg: 0.0546 (0.0664)  time: 0.6942  data: 0.2909  max mem: 5528\n",
      "Training Epoch: [46]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1294 (0.1402)  loss_objectness: 0.0700 (0.0733)  loss_rpn_box_reg: 0.0557 (0.0668)  time: 0.6781  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [46]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1423 (0.1409)  loss_objectness: 0.0756 (0.0741)  loss_rpn_box_reg: 0.0629 (0.0668)  time: 0.6951  data: 0.2996  max mem: 5528\n",
      "Training Epoch: [46]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1499 (0.1420)  loss_objectness: 0.0837 (0.0743)  loss_rpn_box_reg: 0.0731 (0.0677)  time: 0.6828  data: 0.2996  max mem: 5528\n",
      "Training Epoch: [46]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1577 (0.1434)  loss_objectness: 0.0800 (0.0748)  loss_rpn_box_reg: 0.0742 (0.0686)  time: 0.6801  data: 0.2948  max mem: 5528\n",
      "Training Epoch: [46]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1506 (0.1437)  loss_objectness: 0.0782 (0.0751)  loss_rpn_box_reg: 0.0641 (0.0685)  time: 0.6924  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [46]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1506 (0.1443)  loss_objectness: 0.0782 (0.0756)  loss_rpn_box_reg: 0.0673 (0.0686)  time: 0.6942  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [46]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1435 (0.1440)  loss_objectness: 0.0735 (0.0756)  loss_rpn_box_reg: 0.0673 (0.0684)  time: 0.6886  data: 0.2944  max mem: 5528\n",
      "Training Epoch: [46]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1435 (0.1449)  loss_objectness: 0.0689 (0.0754)  loss_rpn_box_reg: 0.0685 (0.0695)  time: 0.6843  data: 0.2955  max mem: 5528\n",
      "Training Epoch: [46]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1449 (0.1445)  loss_objectness: 0.0644 (0.0746)  loss_rpn_box_reg: 0.0830 (0.0698)  time: 0.6976  data: 0.2977  max mem: 5528\n",
      "Training Epoch: [46]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1449 (0.1449)  loss_objectness: 0.0644 (0.0745)  loss_rpn_box_reg: 0.0826 (0.0704)  time: 0.7072  data: 0.3042  max mem: 5528\n",
      "Training Epoch: [46]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1461 (0.1448)  loss_objectness: 0.0680 (0.0742)  loss_rpn_box_reg: 0.0744 (0.0706)  time: 0.6910  data: 0.3020  max mem: 5528\n",
      "Training Epoch: [46]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1310 (0.1443)  loss_objectness: 0.0680 (0.0740)  loss_rpn_box_reg: 0.0686 (0.0703)  time: 0.6708  data: 0.2937  max mem: 5528\n",
      "Training Epoch: [46]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1200 (0.1436)  loss_objectness: 0.0560 (0.0733)  loss_rpn_box_reg: 0.0616 (0.0703)  time: 0.6733  data: 0.2913  max mem: 5528\n",
      "Training Epoch: [46]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1371 (0.1438)  loss_objectness: 0.0583 (0.0735)  loss_rpn_box_reg: 0.0652 (0.0704)  time: 0.6840  data: 0.2948  max mem: 5528\n",
      "Training Epoch: [46] Total time: 0:02:52 (0.6908 s / it)\n",
      "Testing Epoch: [46]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1365 (0.1365)  loss_objectness: 0.0461 (0.0461)  loss_rpn_box_reg: 0.0905 (0.0905)  time: 0.6051  data: 0.2821  max mem: 5528\n",
      "Testing Epoch: [46]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1326 (0.1371)  loss_objectness: 0.0556 (0.0568)  loss_rpn_box_reg: 0.0770 (0.0803)  time: 0.6319  data: 0.3100  max mem: 5528\n",
      "Testing Epoch: [46] Total time: 0:00:39 (0.6332 s / it)\n",
      "Training Epoch: [47]  [  0/250]  eta: 0:03:07  lr: 0.000300  loss: 0.1274 (0.1274)  loss_objectness: 0.0700 (0.0700)  loss_rpn_box_reg: 0.0574 (0.0574)  time: 0.7502  data: 0.3141  max mem: 5528\n",
      "Training Epoch: [47]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1406 (0.1343)  loss_objectness: 0.0728 (0.0722)  loss_rpn_box_reg: 0.0611 (0.0621)  time: 0.6873  data: 0.2999  max mem: 5528\n",
      "Training Epoch: [47]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1400 (0.1335)  loss_objectness: 0.0728 (0.0711)  loss_rpn_box_reg: 0.0651 (0.0624)  time: 0.6800  data: 0.2967  max mem: 5528\n",
      "Training Epoch: [47]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1400 (0.1415)  loss_objectness: 0.0733 (0.0725)  loss_rpn_box_reg: 0.0698 (0.0690)  time: 0.6843  data: 0.2935  max mem: 5528\n",
      "Training Epoch: [47]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1467 (0.1435)  loss_objectness: 0.0728 (0.0733)  loss_rpn_box_reg: 0.0803 (0.0702)  time: 0.6753  data: 0.2906  max mem: 5528\n",
      "Training Epoch: [47]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1430 (0.1421)  loss_objectness: 0.0728 (0.0741)  loss_rpn_box_reg: 0.0599 (0.0681)  time: 0.6798  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [47]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1344 (0.1414)  loss_objectness: 0.0705 (0.0732)  loss_rpn_box_reg: 0.0599 (0.0682)  time: 0.6974  data: 0.2904  max mem: 5528\n",
      "Training Epoch: [47]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1371 (0.1424)  loss_objectness: 0.0704 (0.0732)  loss_rpn_box_reg: 0.0713 (0.0692)  time: 0.6867  data: 0.2927  max mem: 5528\n",
      "Training Epoch: [47]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1493 (0.1429)  loss_objectness: 0.0704 (0.0729)  loss_rpn_box_reg: 0.0713 (0.0700)  time: 0.6831  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [47]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1363 (0.1427)  loss_objectness: 0.0696 (0.0730)  loss_rpn_box_reg: 0.0706 (0.0697)  time: 0.6848  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [47]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1359 (0.1419)  loss_objectness: 0.0723 (0.0730)  loss_rpn_box_reg: 0.0666 (0.0689)  time: 0.6816  data: 0.2936  max mem: 5528\n",
      "Training Epoch: [47]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1430 (0.1425)  loss_objectness: 0.0695 (0.0725)  loss_rpn_box_reg: 0.0683 (0.0700)  time: 0.6910  data: 0.2895  max mem: 5528\n",
      "Training Epoch: [47]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1546 (0.1454)  loss_objectness: 0.0758 (0.0742)  loss_rpn_box_reg: 0.0814 (0.0712)  time: 0.6940  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [47]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1546 (0.1456)  loss_objectness: 0.0758 (0.0741)  loss_rpn_box_reg: 0.0715 (0.0715)  time: 0.6872  data: 0.2940  max mem: 5528\n",
      "Training Epoch: [47]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1521 (0.1474)  loss_objectness: 0.0746 (0.0752)  loss_rpn_box_reg: 0.0794 (0.0722)  time: 0.6847  data: 0.2932  max mem: 5528\n",
      "Training Epoch: [47]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1575 (0.1473)  loss_objectness: 0.0820 (0.0755)  loss_rpn_box_reg: 0.0716 (0.0718)  time: 0.6798  data: 0.2958  max mem: 5528\n",
      "Training Epoch: [47]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1470 (0.1477)  loss_objectness: 0.0807 (0.0759)  loss_rpn_box_reg: 0.0649 (0.0718)  time: 0.6822  data: 0.2949  max mem: 5528\n",
      "Training Epoch: [47]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1564 (0.1481)  loss_objectness: 0.0770 (0.0760)  loss_rpn_box_reg: 0.0722 (0.0720)  time: 0.6870  data: 0.2945  max mem: 5528\n",
      "Training Epoch: [47]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1416 (0.1471)  loss_objectness: 0.0661 (0.0752)  loss_rpn_box_reg: 0.0633 (0.0718)  time: 0.6843  data: 0.2962  max mem: 5528\n",
      "Training Epoch: [47]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1413 (0.1472)  loss_objectness: 0.0607 (0.0753)  loss_rpn_box_reg: 0.0647 (0.0719)  time: 0.6878  data: 0.2955  max mem: 5528\n",
      "Training Epoch: [47]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1413 (0.1465)  loss_objectness: 0.0643 (0.0749)  loss_rpn_box_reg: 0.0679 (0.0716)  time: 0.6925  data: 0.2936  max mem: 5528\n",
      "Training Epoch: [47]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1405 (0.1464)  loss_objectness: 0.0718 (0.0749)  loss_rpn_box_reg: 0.0694 (0.0715)  time: 0.6933  data: 0.2915  max mem: 5528\n",
      "Training Epoch: [47]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1390 (0.1459)  loss_objectness: 0.0712 (0.0746)  loss_rpn_box_reg: 0.0694 (0.0713)  time: 0.6868  data: 0.2891  max mem: 5528\n",
      "Training Epoch: [47]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1286 (0.1457)  loss_objectness: 0.0650 (0.0744)  loss_rpn_box_reg: 0.0645 (0.0713)  time: 0.6768  data: 0.2878  max mem: 5528\n",
      "Training Epoch: [47]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1332 (0.1454)  loss_objectness: 0.0673 (0.0744)  loss_rpn_box_reg: 0.0641 (0.0710)  time: 0.6882  data: 0.2890  max mem: 5528\n",
      "Training Epoch: [47]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1292 (0.1447)  loss_objectness: 0.0723 (0.0743)  loss_rpn_box_reg: 0.0556 (0.0703)  time: 0.6856  data: 0.2876  max mem: 5528\n",
      "Training Epoch: [47] Total time: 0:02:51 (0.6855 s / it)\n",
      "Testing Epoch: [47]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1447 (0.1447)  loss_objectness: 0.0558 (0.0558)  loss_rpn_box_reg: 0.0889 (0.0889)  time: 0.6141  data: 0.2871  max mem: 5528\n",
      "Testing Epoch: [47]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1368 (0.1437)  loss_objectness: 0.0602 (0.0641)  loss_rpn_box_reg: 0.0728 (0.0796)  time: 0.6453  data: 0.3232  max mem: 5528\n",
      "Testing Epoch: [47] Total time: 0:00:39 (0.6445 s / it)\n",
      "Training Epoch: [48]  [  0/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1443 (0.1443)  loss_objectness: 0.0627 (0.0627)  loss_rpn_box_reg: 0.0816 (0.0816)  time: 0.6491  data: 0.2951  max mem: 5528\n",
      "Training Epoch: [48]  [ 10/250]  eta: 0:02:48  lr: 0.000300  loss: 0.1474 (0.1450)  loss_objectness: 0.0690 (0.0756)  loss_rpn_box_reg: 0.0706 (0.0694)  time: 0.7024  data: 0.3023  max mem: 5528\n",
      "Training Epoch: [48]  [ 20/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1404 (0.1433)  loss_objectness: 0.0693 (0.0741)  loss_rpn_box_reg: 0.0640 (0.0692)  time: 0.7088  data: 0.3011  max mem: 5528\n",
      "Training Epoch: [48]  [ 30/250]  eta: 0:02:33  lr: 0.000300  loss: 0.1361 (0.1416)  loss_objectness: 0.0693 (0.0724)  loss_rpn_box_reg: 0.0688 (0.0692)  time: 0.6926  data: 0.3026  max mem: 5528\n",
      "Training Epoch: [48]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1520 (0.1454)  loss_objectness: 0.0747 (0.0752)  loss_rpn_box_reg: 0.0634 (0.0702)  time: 0.6835  data: 0.3081  max mem: 5528\n",
      "Training Epoch: [48]  [ 50/250]  eta: 0:02:20  lr: 0.000300  loss: 0.1520 (0.1462)  loss_objectness: 0.0795 (0.0767)  loss_rpn_box_reg: 0.0634 (0.0695)  time: 0.7069  data: 0.3072  max mem: 5528\n",
      "Training Epoch: [48]  [ 60/250]  eta: 0:02:12  lr: 0.000300  loss: 0.1583 (0.1482)  loss_objectness: 0.0826 (0.0783)  loss_rpn_box_reg: 0.0670 (0.0699)  time: 0.7074  data: 0.3070  max mem: 5528\n",
      "Training Epoch: [48]  [ 70/250]  eta: 0:02:05  lr: 0.000300  loss: 0.1495 (0.1483)  loss_objectness: 0.0729 (0.0771)  loss_rpn_box_reg: 0.0707 (0.0713)  time: 0.6933  data: 0.3071  max mem: 5528\n",
      "Training Epoch: [48]  [ 80/250]  eta: 0:01:58  lr: 0.000300  loss: 0.1495 (0.1506)  loss_objectness: 0.0656 (0.0769)  loss_rpn_box_reg: 0.0807 (0.0737)  time: 0.6917  data: 0.3026  max mem: 5528\n",
      "Training Epoch: [48]  [ 90/250]  eta: 0:01:51  lr: 0.000300  loss: 0.1535 (0.1493)  loss_objectness: 0.0713 (0.0775)  loss_rpn_box_reg: 0.0602 (0.0717)  time: 0.6881  data: 0.2975  max mem: 5528\n",
      "Training Epoch: [48]  [100/250]  eta: 0:01:44  lr: 0.000300  loss: 0.1385 (0.1475)  loss_objectness: 0.0693 (0.0766)  loss_rpn_box_reg: 0.0596 (0.0709)  time: 0.6787  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [48]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1388 (0.1476)  loss_objectness: 0.0712 (0.0764)  loss_rpn_box_reg: 0.0725 (0.0712)  time: 0.6793  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [48]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1496 (0.1468)  loss_objectness: 0.0738 (0.0767)  loss_rpn_box_reg: 0.0645 (0.0701)  time: 0.6911  data: 0.2938  max mem: 5528\n",
      "Training Epoch: [48]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1392 (0.1469)  loss_objectness: 0.0743 (0.0768)  loss_rpn_box_reg: 0.0614 (0.0701)  time: 0.6902  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [48]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1515 (0.1471)  loss_objectness: 0.0742 (0.0763)  loss_rpn_box_reg: 0.0734 (0.0708)  time: 0.6822  data: 0.2932  max mem: 5528\n",
      "Training Epoch: [48]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1499 (0.1477)  loss_objectness: 0.0714 (0.0765)  loss_rpn_box_reg: 0.0777 (0.0713)  time: 0.6881  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [48]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1416 (0.1474)  loss_objectness: 0.0699 (0.0765)  loss_rpn_box_reg: 0.0621 (0.0709)  time: 0.6876  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [48]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1405 (0.1467)  loss_objectness: 0.0686 (0.0765)  loss_rpn_box_reg: 0.0570 (0.0702)  time: 0.6802  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [48]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1334 (0.1458)  loss_objectness: 0.0679 (0.0762)  loss_rpn_box_reg: 0.0570 (0.0696)  time: 0.6868  data: 0.2914  max mem: 5528\n",
      "Training Epoch: [48]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1340 (0.1457)  loss_objectness: 0.0699 (0.0763)  loss_rpn_box_reg: 0.0623 (0.0694)  time: 0.6946  data: 0.2918  max mem: 5528\n",
      "Training Epoch: [48]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1444 (0.1457)  loss_objectness: 0.0767 (0.0764)  loss_rpn_box_reg: 0.0629 (0.0693)  time: 0.6947  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [48]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1419 (0.1458)  loss_objectness: 0.0767 (0.0764)  loss_rpn_box_reg: 0.0674 (0.0694)  time: 0.6761  data: 0.2878  max mem: 5528\n",
      "Training Epoch: [48]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1404 (0.1461)  loss_objectness: 0.0694 (0.0763)  loss_rpn_box_reg: 0.0700 (0.0698)  time: 0.6729  data: 0.2906  max mem: 5528\n",
      "Training Epoch: [48]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1504 (0.1472)  loss_objectness: 0.0753 (0.0768)  loss_rpn_box_reg: 0.0808 (0.0704)  time: 0.6867  data: 0.2952  max mem: 5528\n",
      "Training Epoch: [48]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1614 (0.1471)  loss_objectness: 0.0714 (0.0764)  loss_rpn_box_reg: 0.0897 (0.0707)  time: 0.6781  data: 0.2927  max mem: 5528\n",
      "Training Epoch: [48]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1408 (0.1473)  loss_objectness: 0.0700 (0.0762)  loss_rpn_box_reg: 0.0723 (0.0711)  time: 0.6904  data: 0.2890  max mem: 5528\n",
      "Training Epoch: [48] Total time: 0:02:52 (0.6892 s / it)\n",
      "Testing Epoch: [48]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1364 (0.1364)  loss_objectness: 0.0420 (0.0420)  loss_rpn_box_reg: 0.0943 (0.0943)  time: 0.6311  data: 0.3031  max mem: 5528\n",
      "Testing Epoch: [48]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1337 (0.1418)  loss_objectness: 0.0557 (0.0579)  loss_rpn_box_reg: 0.0794 (0.0839)  time: 0.6289  data: 0.3090  max mem: 5528\n",
      "Testing Epoch: [48] Total time: 0:00:39 (0.6355 s / it)\n",
      "Training Epoch: [49]  [  0/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1003 (0.1003)  loss_objectness: 0.0577 (0.0577)  loss_rpn_box_reg: 0.0426 (0.0426)  time: 0.6611  data: 0.2961  max mem: 5528\n",
      "Training Epoch: [49]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1433 (0.1395)  loss_objectness: 0.0677 (0.0701)  loss_rpn_box_reg: 0.0603 (0.0694)  time: 0.6846  data: 0.2992  max mem: 5528\n",
      "Training Epoch: [49]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1468 (0.1433)  loss_objectness: 0.0757 (0.0751)  loss_rpn_box_reg: 0.0692 (0.0682)  time: 0.6967  data: 0.2987  max mem: 5528\n",
      "Training Epoch: [49]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1608 (0.1462)  loss_objectness: 0.0824 (0.0781)  loss_rpn_box_reg: 0.0692 (0.0681)  time: 0.6947  data: 0.2968  max mem: 5528\n",
      "Training Epoch: [49]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1334 (0.1436)  loss_objectness: 0.0727 (0.0761)  loss_rpn_box_reg: 0.0640 (0.0674)  time: 0.6929  data: 0.2942  max mem: 5528\n",
      "Training Epoch: [49]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1341 (0.1473)  loss_objectness: 0.0731 (0.0789)  loss_rpn_box_reg: 0.0612 (0.0685)  time: 0.6827  data: 0.2899  max mem: 5528\n",
      "Training Epoch: [49]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1440 (0.1449)  loss_objectness: 0.0796 (0.0789)  loss_rpn_box_reg: 0.0558 (0.0660)  time: 0.6696  data: 0.2881  max mem: 5528\n",
      "Training Epoch: [49]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1377 (0.1448)  loss_objectness: 0.0785 (0.0782)  loss_rpn_box_reg: 0.0612 (0.0666)  time: 0.6851  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [49]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1347 (0.1438)  loss_objectness: 0.0712 (0.0770)  loss_rpn_box_reg: 0.0689 (0.0668)  time: 0.6846  data: 0.2878  max mem: 5528\n",
      "Training Epoch: [49]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1306 (0.1437)  loss_objectness: 0.0707 (0.0767)  loss_rpn_box_reg: 0.0675 (0.0670)  time: 0.6776  data: 0.2896  max mem: 5528\n",
      "Training Epoch: [49]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1306 (0.1425)  loss_objectness: 0.0719 (0.0758)  loss_rpn_box_reg: 0.0635 (0.0667)  time: 0.6826  data: 0.2923  max mem: 5528\n",
      "Training Epoch: [49]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1320 (0.1425)  loss_objectness: 0.0727 (0.0759)  loss_rpn_box_reg: 0.0616 (0.0666)  time: 0.6925  data: 0.2926  max mem: 5528\n",
      "Training Epoch: [49]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1342 (0.1425)  loss_objectness: 0.0752 (0.0759)  loss_rpn_box_reg: 0.0629 (0.0666)  time: 0.6893  data: 0.2936  max mem: 5528\n",
      "Training Epoch: [49]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1404 (0.1417)  loss_objectness: 0.0705 (0.0751)  loss_rpn_box_reg: 0.0647 (0.0666)  time: 0.6788  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [49]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1277 (0.1412)  loss_objectness: 0.0603 (0.0743)  loss_rpn_box_reg: 0.0631 (0.0670)  time: 0.6760  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [49]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1394 (0.1418)  loss_objectness: 0.0669 (0.0743)  loss_rpn_box_reg: 0.0751 (0.0675)  time: 0.6719  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [49]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1462 (0.1416)  loss_objectness: 0.0736 (0.0739)  loss_rpn_box_reg: 0.0652 (0.0677)  time: 0.6766  data: 0.2890  max mem: 5528\n",
      "Training Epoch: [49]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1357 (0.1422)  loss_objectness: 0.0633 (0.0737)  loss_rpn_box_reg: 0.0725 (0.0684)  time: 0.6858  data: 0.2897  max mem: 5528\n",
      "Training Epoch: [49]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1391 (0.1433)  loss_objectness: 0.0721 (0.0740)  loss_rpn_box_reg: 0.0725 (0.0693)  time: 0.6845  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [49]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1399 (0.1442)  loss_objectness: 0.0762 (0.0743)  loss_rpn_box_reg: 0.0687 (0.0699)  time: 0.6840  data: 0.2964  max mem: 5528\n",
      "Training Epoch: [49]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1581 (0.1445)  loss_objectness: 0.0726 (0.0740)  loss_rpn_box_reg: 0.0716 (0.0705)  time: 0.6964  data: 0.2974  max mem: 5528\n",
      "Training Epoch: [49]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1472 (0.1445)  loss_objectness: 0.0638 (0.0737)  loss_rpn_box_reg: 0.0704 (0.0707)  time: 0.6903  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [49]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1280 (0.1436)  loss_objectness: 0.0621 (0.0734)  loss_rpn_box_reg: 0.0624 (0.0703)  time: 0.6790  data: 0.2926  max mem: 5528\n",
      "Training Epoch: [49]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1357 (0.1443)  loss_objectness: 0.0667 (0.0732)  loss_rpn_box_reg: 0.0647 (0.0712)  time: 0.6775  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [49]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1431 (0.1443)  loss_objectness: 0.0737 (0.0735)  loss_rpn_box_reg: 0.0707 (0.0708)  time: 0.6807  data: 0.2898  max mem: 5528\n",
      "Training Epoch: [49]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1373 (0.1443)  loss_objectness: 0.0765 (0.0736)  loss_rpn_box_reg: 0.0639 (0.0707)  time: 0.6849  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [49] Total time: 0:02:50 (0.6840 s / it)\n",
      "Testing Epoch: [49]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1403 (0.1403)  loss_objectness: 0.0490 (0.0490)  loss_rpn_box_reg: 0.0913 (0.0913)  time: 0.7152  data: 0.3841  max mem: 5528\n",
      "Testing Epoch: [49]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1270 (0.1361)  loss_objectness: 0.0534 (0.0564)  loss_rpn_box_reg: 0.0753 (0.0796)  time: 0.6341  data: 0.3125  max mem: 5528\n",
      "Testing Epoch: [49] Total time: 0:00:39 (0.6349 s / it)\n",
      "Training Epoch: [50]  [  0/250]  eta: 0:03:04  lr: 0.000300  loss: 0.1393 (0.1393)  loss_objectness: 0.0567 (0.0567)  loss_rpn_box_reg: 0.0825 (0.0825)  time: 0.7382  data: 0.2891  max mem: 5528\n",
      "Training Epoch: [50]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1393 (0.1428)  loss_objectness: 0.0765 (0.0732)  loss_rpn_box_reg: 0.0594 (0.0696)  time: 0.6966  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [50]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1489 (0.1455)  loss_objectness: 0.0765 (0.0739)  loss_rpn_box_reg: 0.0598 (0.0717)  time: 0.6884  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [50]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1457 (0.1459)  loss_objectness: 0.0727 (0.0758)  loss_rpn_box_reg: 0.0643 (0.0701)  time: 0.6792  data: 0.2918  max mem: 5528\n",
      "Training Epoch: [50]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1302 (0.1435)  loss_objectness: 0.0690 (0.0744)  loss_rpn_box_reg: 0.0639 (0.0691)  time: 0.6954  data: 0.2939  max mem: 5528\n",
      "Training Epoch: [50]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1357 (0.1459)  loss_objectness: 0.0645 (0.0735)  loss_rpn_box_reg: 0.0694 (0.0724)  time: 0.6992  data: 0.2932  max mem: 5528\n",
      "Training Epoch: [50]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1499 (0.1487)  loss_objectness: 0.0707 (0.0743)  loss_rpn_box_reg: 0.0787 (0.0743)  time: 0.6875  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [50]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1442 (0.1481)  loss_objectness: 0.0784 (0.0750)  loss_rpn_box_reg: 0.0710 (0.0731)  time: 0.7001  data: 0.2927  max mem: 5528\n",
      "Training Epoch: [50]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1429 (0.1465)  loss_objectness: 0.0647 (0.0734)  loss_rpn_box_reg: 0.0659 (0.0731)  time: 0.6937  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [50]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1379 (0.1447)  loss_objectness: 0.0612 (0.0732)  loss_rpn_box_reg: 0.0648 (0.0715)  time: 0.6938  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [50]  [100/250]  eta: 0:01:44  lr: 0.000300  loss: 0.1379 (0.1449)  loss_objectness: 0.0767 (0.0737)  loss_rpn_box_reg: 0.0567 (0.0712)  time: 0.7027  data: 0.2951  max mem: 5528\n",
      "Training Epoch: [50]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1483 (0.1451)  loss_objectness: 0.0778 (0.0741)  loss_rpn_box_reg: 0.0669 (0.0710)  time: 0.6984  data: 0.2963  max mem: 5528\n",
      "Training Epoch: [50]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1305 (0.1441)  loss_objectness: 0.0720 (0.0740)  loss_rpn_box_reg: 0.0642 (0.0702)  time: 0.6945  data: 0.2977  max mem: 5528\n",
      "Training Epoch: [50]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1287 (0.1440)  loss_objectness: 0.0705 (0.0737)  loss_rpn_box_reg: 0.0602 (0.0703)  time: 0.6843  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [50]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1287 (0.1434)  loss_objectness: 0.0692 (0.0733)  loss_rpn_box_reg: 0.0602 (0.0701)  time: 0.6787  data: 0.2897  max mem: 5528\n",
      "Training Epoch: [50]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1357 (0.1432)  loss_objectness: 0.0744 (0.0737)  loss_rpn_box_reg: 0.0605 (0.0695)  time: 0.6836  data: 0.2890  max mem: 5528\n",
      "Training Epoch: [50]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1374 (0.1441)  loss_objectness: 0.0824 (0.0742)  loss_rpn_box_reg: 0.0653 (0.0699)  time: 0.6823  data: 0.2871  max mem: 5528\n",
      "Training Epoch: [50]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1425 (0.1436)  loss_objectness: 0.0728 (0.0745)  loss_rpn_box_reg: 0.0655 (0.0691)  time: 0.6977  data: 0.2980  max mem: 5528\n",
      "Training Epoch: [50]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1233 (0.1429)  loss_objectness: 0.0722 (0.0746)  loss_rpn_box_reg: 0.0518 (0.0683)  time: 0.7255  data: 0.3115  max mem: 5528\n",
      "Training Epoch: [50]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1450 (0.1440)  loss_objectness: 0.0721 (0.0748)  loss_rpn_box_reg: 0.0592 (0.0691)  time: 0.7013  data: 0.3024  max mem: 5528\n",
      "Training Epoch: [50]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1451 (0.1445)  loss_objectness: 0.0734 (0.0751)  loss_rpn_box_reg: 0.0747 (0.0694)  time: 0.6658  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [50]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1451 (0.1450)  loss_objectness: 0.0767 (0.0754)  loss_rpn_box_reg: 0.0727 (0.0696)  time: 0.6806  data: 0.2957  max mem: 5528\n",
      "Training Epoch: [50]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1490 (0.1442)  loss_objectness: 0.0710 (0.0750)  loss_rpn_box_reg: 0.0623 (0.0692)  time: 0.6952  data: 0.2973  max mem: 5528\n",
      "Training Epoch: [50]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1441 (0.1451)  loss_objectness: 0.0720 (0.0754)  loss_rpn_box_reg: 0.0641 (0.0697)  time: 0.6868  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [50]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1472 (0.1452)  loss_objectness: 0.0839 (0.0756)  loss_rpn_box_reg: 0.0694 (0.0696)  time: 0.6808  data: 0.2947  max mem: 5528\n",
      "Training Epoch: [50]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1472 (0.1452)  loss_objectness: 0.0684 (0.0755)  loss_rpn_box_reg: 0.0715 (0.0698)  time: 0.6820  data: 0.2940  max mem: 5528\n",
      "Training Epoch: [50] Total time: 0:02:52 (0.6908 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:11  model_time: 0.6942 (0.6942)  evaluator_time: 0.0550 (0.0550)  time: 1.1463  data: 0.3821  max mem: 5528\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3821 (0.3813)  evaluator_time: 0.0660 (0.0747)  time: 0.7641  data: 0.3088  max mem: 5528\n",
      "Test: Total time: 0:00:47 (0.7653 s / it)\n",
      "Averaged stats: model_time: 0.3821 (0.3813)  evaluator_time: 0.0660 (0.0747)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.00s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.165\n",
      "Testing Epoch: [50]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1352 (0.1352)  loss_objectness: 0.0449 (0.0449)  loss_rpn_box_reg: 0.0903 (0.0903)  time: 0.6171  data: 0.2951  max mem: 5528\n",
      "Testing Epoch: [50]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1308 (0.1366)  loss_objectness: 0.0516 (0.0568)  loss_rpn_box_reg: 0.0737 (0.0798)  time: 0.6357  data: 0.3059  max mem: 5528\n",
      "Testing Epoch: [50] Total time: 0:00:39 (0.6331 s / it)\n",
      "Training Epoch: [51]  [  0/250]  eta: 0:03:15  lr: 0.000300  loss: 0.1507 (0.1507)  loss_objectness: 0.0991 (0.0991)  loss_rpn_box_reg: 0.0516 (0.0516)  time: 0.7822  data: 0.3081  max mem: 5528\n",
      "Training Epoch: [51]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1356 (0.1382)  loss_objectness: 0.0641 (0.0706)  loss_rpn_box_reg: 0.0688 (0.0676)  time: 0.6927  data: 0.2849  max mem: 5528\n",
      "Training Epoch: [51]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1220 (0.1306)  loss_objectness: 0.0637 (0.0687)  loss_rpn_box_reg: 0.0679 (0.0619)  time: 0.6769  data: 0.2850  max mem: 5528\n",
      "Training Epoch: [51]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1220 (0.1328)  loss_objectness: 0.0637 (0.0683)  loss_rpn_box_reg: 0.0570 (0.0646)  time: 0.6785  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [51]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1399 (0.1349)  loss_objectness: 0.0680 (0.0693)  loss_rpn_box_reg: 0.0614 (0.0656)  time: 0.6766  data: 0.2942  max mem: 5528\n",
      "Training Epoch: [51]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1392 (0.1361)  loss_objectness: 0.0696 (0.0699)  loss_rpn_box_reg: 0.0651 (0.0662)  time: 0.6635  data: 0.2939  max mem: 5528\n",
      "Training Epoch: [51]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1412 (0.1365)  loss_objectness: 0.0635 (0.0690)  loss_rpn_box_reg: 0.0704 (0.0675)  time: 0.6811  data: 0.2960  max mem: 5528\n",
      "Training Epoch: [51]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1430 (0.1376)  loss_objectness: 0.0676 (0.0697)  loss_rpn_box_reg: 0.0704 (0.0679)  time: 0.6874  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [51]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1359 (0.1366)  loss_objectness: 0.0640 (0.0688)  loss_rpn_box_reg: 0.0631 (0.0679)  time: 0.6778  data: 0.2902  max mem: 5528\n",
      "Training Epoch: [51]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1406 (0.1378)  loss_objectness: 0.0640 (0.0694)  loss_rpn_box_reg: 0.0650 (0.0684)  time: 0.6766  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [51]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1386 (0.1369)  loss_objectness: 0.0646 (0.0689)  loss_rpn_box_reg: 0.0676 (0.0680)  time: 0.6791  data: 0.2878  max mem: 5528\n",
      "Training Epoch: [51]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1295 (0.1372)  loss_objectness: 0.0621 (0.0689)  loss_rpn_box_reg: 0.0619 (0.0684)  time: 0.6874  data: 0.2874  max mem: 5528\n",
      "Training Epoch: [51]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1295 (0.1371)  loss_objectness: 0.0684 (0.0689)  loss_rpn_box_reg: 0.0613 (0.0682)  time: 0.6774  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [51]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1467 (0.1390)  loss_objectness: 0.0726 (0.0697)  loss_rpn_box_reg: 0.0688 (0.0694)  time: 0.6934  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [51]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1619 (0.1395)  loss_objectness: 0.0720 (0.0699)  loss_rpn_box_reg: 0.0691 (0.0696)  time: 0.7069  data: 0.2951  max mem: 5528\n",
      "Training Epoch: [51]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1513 (0.1406)  loss_objectness: 0.0755 (0.0708)  loss_rpn_box_reg: 0.0722 (0.0698)  time: 0.6957  data: 0.2984  max mem: 5528\n",
      "Training Epoch: [51]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1538 (0.1419)  loss_objectness: 0.0823 (0.0714)  loss_rpn_box_reg: 0.0722 (0.0705)  time: 0.7017  data: 0.2959  max mem: 5528\n",
      "Training Epoch: [51]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1412 (0.1425)  loss_objectness: 0.0733 (0.0716)  loss_rpn_box_reg: 0.0682 (0.0709)  time: 0.6998  data: 0.2954  max mem: 5528\n",
      "Training Epoch: [51]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1339 (0.1427)  loss_objectness: 0.0739 (0.0720)  loss_rpn_box_reg: 0.0636 (0.0707)  time: 0.6952  data: 0.2928  max mem: 5528\n",
      "Training Epoch: [51]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1446 (0.1427)  loss_objectness: 0.0734 (0.0722)  loss_rpn_box_reg: 0.0680 (0.0705)  time: 0.6827  data: 0.2888  max mem: 5528\n",
      "Training Epoch: [51]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1337 (0.1428)  loss_objectness: 0.0719 (0.0721)  loss_rpn_box_reg: 0.0678 (0.0706)  time: 0.6699  data: 0.2885  max mem: 5528\n",
      "Training Epoch: [51]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1315 (0.1425)  loss_objectness: 0.0679 (0.0720)  loss_rpn_box_reg: 0.0581 (0.0705)  time: 0.6832  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [51]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1505 (0.1433)  loss_objectness: 0.0679 (0.0724)  loss_rpn_box_reg: 0.0744 (0.0709)  time: 0.6964  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [51]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1534 (0.1433)  loss_objectness: 0.0690 (0.0725)  loss_rpn_box_reg: 0.0738 (0.0707)  time: 0.6913  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [51]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1381 (0.1430)  loss_objectness: 0.0687 (0.0727)  loss_rpn_box_reg: 0.0615 (0.0703)  time: 0.6842  data: 0.2902  max mem: 5528\n",
      "Training Epoch: [51]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1381 (0.1436)  loss_objectness: 0.0771 (0.0729)  loss_rpn_box_reg: 0.0660 (0.0707)  time: 0.6872  data: 0.2919  max mem: 5528\n",
      "Training Epoch: [51] Total time: 0:02:51 (0.6861 s / it)\n",
      "Testing Epoch: [51]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1340 (0.1340)  loss_objectness: 0.0449 (0.0449)  loss_rpn_box_reg: 0.0891 (0.0891)  time: 0.6101  data: 0.2881  max mem: 5528\n",
      "Testing Epoch: [51]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1294 (0.1369)  loss_objectness: 0.0546 (0.0576)  loss_rpn_box_reg: 0.0734 (0.0794)  time: 0.6368  data: 0.3105  max mem: 5528\n",
      "Testing Epoch: [51] Total time: 0:00:39 (0.6356 s / it)\n",
      "Training Epoch: [52]  [  0/250]  eta: 0:02:53  lr: 0.000300  loss: 0.1512 (0.1512)  loss_objectness: 0.0812 (0.0812)  loss_rpn_box_reg: 0.0700 (0.0700)  time: 0.6942  data: 0.3001  max mem: 5528\n",
      "Training Epoch: [52]  [ 10/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1490 (0.1477)  loss_objectness: 0.0713 (0.0726)  loss_rpn_box_reg: 0.0700 (0.0750)  time: 0.6792  data: 0.2919  max mem: 5528\n",
      "Training Epoch: [52]  [ 20/250]  eta: 0:02:33  lr: 0.000300  loss: 0.1466 (0.1433)  loss_objectness: 0.0713 (0.0739)  loss_rpn_box_reg: 0.0613 (0.0694)  time: 0.6640  data: 0.2897  max mem: 5528\n",
      "Training Epoch: [52]  [ 30/250]  eta: 0:02:27  lr: 0.000300  loss: 0.1158 (0.1361)  loss_objectness: 0.0564 (0.0685)  loss_rpn_box_reg: 0.0617 (0.0676)  time: 0.6660  data: 0.2904  max mem: 5528\n",
      "Training Epoch: [52]  [ 40/250]  eta: 0:02:21  lr: 0.000300  loss: 0.1372 (0.1436)  loss_objectness: 0.0675 (0.0721)  loss_rpn_box_reg: 0.0748 (0.0715)  time: 0.6871  data: 0.2922  max mem: 5528\n",
      "Training Epoch: [52]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1468 (0.1416)  loss_objectness: 0.0723 (0.0730)  loss_rpn_box_reg: 0.0626 (0.0687)  time: 0.6862  data: 0.2905  max mem: 5528\n",
      "Training Epoch: [52]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1352 (0.1416)  loss_objectness: 0.0704 (0.0730)  loss_rpn_box_reg: 0.0556 (0.0687)  time: 0.6923  data: 0.2893  max mem: 5528\n",
      "Training Epoch: [52]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1413 (0.1416)  loss_objectness: 0.0682 (0.0722)  loss_rpn_box_reg: 0.0730 (0.0694)  time: 0.6921  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [52]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1308 (0.1399)  loss_objectness: 0.0662 (0.0720)  loss_rpn_box_reg: 0.0530 (0.0679)  time: 0.6854  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [52]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1308 (0.1403)  loss_objectness: 0.0746 (0.0726)  loss_rpn_box_reg: 0.0515 (0.0677)  time: 0.7029  data: 0.2965  max mem: 5528\n",
      "Training Epoch: [52]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1469 (0.1414)  loss_objectness: 0.0753 (0.0726)  loss_rpn_box_reg: 0.0655 (0.0688)  time: 0.7010  data: 0.2959  max mem: 5528\n",
      "Training Epoch: [52]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1440 (0.1417)  loss_objectness: 0.0743 (0.0733)  loss_rpn_box_reg: 0.0689 (0.0685)  time: 0.6848  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [52]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1506 (0.1429)  loss_objectness: 0.0779 (0.0740)  loss_rpn_box_reg: 0.0701 (0.0689)  time: 0.6796  data: 0.2913  max mem: 5528\n",
      "Training Epoch: [52]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1506 (0.1431)  loss_objectness: 0.0784 (0.0742)  loss_rpn_box_reg: 0.0716 (0.0689)  time: 0.6831  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [52]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1439 (0.1438)  loss_objectness: 0.0707 (0.0740)  loss_rpn_box_reg: 0.0734 (0.0698)  time: 0.6735  data: 0.2897  max mem: 5528\n",
      "Training Epoch: [52]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1464 (0.1436)  loss_objectness: 0.0754 (0.0745)  loss_rpn_box_reg: 0.0709 (0.0691)  time: 0.6574  data: 0.2892  max mem: 5528\n",
      "Training Epoch: [52]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1446 (0.1436)  loss_objectness: 0.0760 (0.0744)  loss_rpn_box_reg: 0.0565 (0.0692)  time: 0.6799  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [52]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1446 (0.1438)  loss_objectness: 0.0758 (0.0744)  loss_rpn_box_reg: 0.0658 (0.0694)  time: 0.6914  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [52]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1361 (0.1434)  loss_objectness: 0.0758 (0.0743)  loss_rpn_box_reg: 0.0600 (0.0691)  time: 0.6727  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [52]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1365 (0.1435)  loss_objectness: 0.0717 (0.0742)  loss_rpn_box_reg: 0.0680 (0.0693)  time: 0.6868  data: 0.2902  max mem: 5528\n",
      "Training Epoch: [52]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1391 (0.1436)  loss_objectness: 0.0733 (0.0742)  loss_rpn_box_reg: 0.0799 (0.0694)  time: 0.6972  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [52]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1417 (0.1442)  loss_objectness: 0.0708 (0.0745)  loss_rpn_box_reg: 0.0724 (0.0697)  time: 0.6839  data: 0.2922  max mem: 5528\n",
      "Training Epoch: [52]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1417 (0.1440)  loss_objectness: 0.0705 (0.0742)  loss_rpn_box_reg: 0.0724 (0.0698)  time: 0.6811  data: 0.2922  max mem: 5528\n",
      "Training Epoch: [52]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1503 (0.1445)  loss_objectness: 0.0730 (0.0744)  loss_rpn_box_reg: 0.0733 (0.0702)  time: 0.6860  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [52]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1501 (0.1444)  loss_objectness: 0.0789 (0.0747)  loss_rpn_box_reg: 0.0621 (0.0697)  time: 0.6984  data: 0.2898  max mem: 5528\n",
      "Training Epoch: [52]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1501 (0.1447)  loss_objectness: 0.0790 (0.0746)  loss_rpn_box_reg: 0.0655 (0.0701)  time: 0.6904  data: 0.2905  max mem: 5528\n",
      "Training Epoch: [52] Total time: 0:02:50 (0.6839 s / it)\n",
      "Testing Epoch: [52]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1364 (0.1364)  loss_objectness: 0.0465 (0.0465)  loss_rpn_box_reg: 0.0899 (0.0899)  time: 0.6111  data: 0.2871  max mem: 5528\n",
      "Testing Epoch: [52]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1283 (0.1382)  loss_objectness: 0.0524 (0.0582)  loss_rpn_box_reg: 0.0715 (0.0800)  time: 0.6302  data: 0.3059  max mem: 5528\n",
      "Testing Epoch: [52] Total time: 0:00:39 (0.6334 s / it)\n",
      "Training Epoch: [53]  [  0/250]  eta: 0:02:52  lr: 0.000300  loss: 0.1403 (0.1403)  loss_objectness: 0.0743 (0.0743)  loss_rpn_box_reg: 0.0660 (0.0660)  time: 0.6892  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [53]  [ 10/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1403 (0.1420)  loss_objectness: 0.0738 (0.0764)  loss_rpn_box_reg: 0.0660 (0.0656)  time: 0.6902  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [53]  [ 20/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1480 (0.1481)  loss_objectness: 0.0730 (0.0766)  loss_rpn_box_reg: 0.0750 (0.0715)  time: 0.6776  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [53]  [ 30/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1432 (0.1440)  loss_objectness: 0.0699 (0.0751)  loss_rpn_box_reg: 0.0695 (0.0689)  time: 0.6695  data: 0.2905  max mem: 5528\n",
      "Training Epoch: [53]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1288 (0.1433)  loss_objectness: 0.0699 (0.0755)  loss_rpn_box_reg: 0.0603 (0.0679)  time: 0.6791  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [53]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1262 (0.1417)  loss_objectness: 0.0668 (0.0747)  loss_rpn_box_reg: 0.0558 (0.0671)  time: 0.6732  data: 0.2888  max mem: 5528\n",
      "Training Epoch: [53]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1296 (0.1423)  loss_objectness: 0.0711 (0.0754)  loss_rpn_box_reg: 0.0623 (0.0668)  time: 0.6818  data: 0.2952  max mem: 5528\n",
      "Training Epoch: [53]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1473 (0.1439)  loss_objectness: 0.0787 (0.0766)  loss_rpn_box_reg: 0.0675 (0.0674)  time: 0.7029  data: 0.3023  max mem: 5528\n",
      "Training Epoch: [53]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1453 (0.1431)  loss_objectness: 0.0773 (0.0768)  loss_rpn_box_reg: 0.0670 (0.0663)  time: 0.6919  data: 0.2967  max mem: 5528\n",
      "Training Epoch: [53]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1453 (0.1450)  loss_objectness: 0.0732 (0.0770)  loss_rpn_box_reg: 0.0665 (0.0680)  time: 0.6822  data: 0.2905  max mem: 5528\n",
      "Training Epoch: [53]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1608 (0.1462)  loss_objectness: 0.0720 (0.0763)  loss_rpn_box_reg: 0.0809 (0.0698)  time: 0.6939  data: 0.2897  max mem: 5528\n",
      "Training Epoch: [53]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1494 (0.1461)  loss_objectness: 0.0712 (0.0761)  loss_rpn_box_reg: 0.0741 (0.0700)  time: 0.6953  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [53]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1370 (0.1450)  loss_objectness: 0.0693 (0.0754)  loss_rpn_box_reg: 0.0690 (0.0696)  time: 0.6980  data: 0.2914  max mem: 5528\n",
      "Training Epoch: [53]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1340 (0.1446)  loss_objectness: 0.0606 (0.0747)  loss_rpn_box_reg: 0.0695 (0.0698)  time: 0.7007  data: 0.2887  max mem: 5528\n",
      "Training Epoch: [53]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1377 (0.1441)  loss_objectness: 0.0586 (0.0740)  loss_rpn_box_reg: 0.0749 (0.0701)  time: 0.6894  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [53]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1371 (0.1437)  loss_objectness: 0.0578 (0.0734)  loss_rpn_box_reg: 0.0758 (0.0703)  time: 0.6920  data: 0.2879  max mem: 5528\n",
      "Training Epoch: [53]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1371 (0.1437)  loss_objectness: 0.0673 (0.0734)  loss_rpn_box_reg: 0.0632 (0.0702)  time: 0.6837  data: 0.2888  max mem: 5528\n",
      "Training Epoch: [53]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1564 (0.1451)  loss_objectness: 0.0730 (0.0738)  loss_rpn_box_reg: 0.0728 (0.0713)  time: 0.6775  data: 0.2922  max mem: 5528\n",
      "Training Epoch: [53]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1536 (0.1448)  loss_objectness: 0.0747 (0.0738)  loss_rpn_box_reg: 0.0692 (0.0710)  time: 0.6773  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [53]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1286 (0.1446)  loss_objectness: 0.0659 (0.0738)  loss_rpn_box_reg: 0.0631 (0.0708)  time: 0.6787  data: 0.2928  max mem: 5528\n",
      "Training Epoch: [53]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1292 (0.1443)  loss_objectness: 0.0702 (0.0737)  loss_rpn_box_reg: 0.0654 (0.0706)  time: 0.6895  data: 0.2909  max mem: 5528\n",
      "Training Epoch: [53]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1292 (0.1436)  loss_objectness: 0.0702 (0.0735)  loss_rpn_box_reg: 0.0577 (0.0700)  time: 0.6822  data: 0.2865  max mem: 5528\n",
      "Training Epoch: [53]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1334 (0.1439)  loss_objectness: 0.0720 (0.0734)  loss_rpn_box_reg: 0.0680 (0.0705)  time: 0.6791  data: 0.2854  max mem: 5528\n",
      "Training Epoch: [53]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1400 (0.1443)  loss_objectness: 0.0720 (0.0737)  loss_rpn_box_reg: 0.0748 (0.0706)  time: 0.6833  data: 0.2918  max mem: 5528\n",
      "Training Epoch: [53]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1433 (0.1443)  loss_objectness: 0.0765 (0.0738)  loss_rpn_box_reg: 0.0676 (0.0706)  time: 0.6818  data: 0.2949  max mem: 5528\n",
      "Training Epoch: [53]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1434 (0.1441)  loss_objectness: 0.0644 (0.0735)  loss_rpn_box_reg: 0.0676 (0.0707)  time: 0.6880  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [53] Total time: 0:02:51 (0.6856 s / it)\n",
      "Testing Epoch: [53]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1377 (0.1377)  loss_objectness: 0.0491 (0.0491)  loss_rpn_box_reg: 0.0886 (0.0886)  time: 0.7172  data: 0.3901  max mem: 5528\n",
      "Testing Epoch: [53]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1247 (0.1372)  loss_objectness: 0.0519 (0.0571)  loss_rpn_box_reg: 0.0760 (0.0801)  time: 0.6347  data: 0.3120  max mem: 5528\n",
      "Testing Epoch: [53] Total time: 0:00:39 (0.6360 s / it)\n",
      "Training Epoch: [54]  [  0/250]  eta: 0:02:52  lr: 0.000300  loss: 0.1765 (0.1765)  loss_objectness: 0.0686 (0.0686)  loss_rpn_box_reg: 0.1079 (0.1079)  time: 0.6912  data: 0.2841  max mem: 5528\n",
      "Training Epoch: [54]  [ 10/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1544 (0.1524)  loss_objectness: 0.0760 (0.0794)  loss_rpn_box_reg: 0.0726 (0.0730)  time: 0.6790  data: 0.2913  max mem: 5528\n",
      "Training Epoch: [54]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1322 (0.1378)  loss_objectness: 0.0713 (0.0721)  loss_rpn_box_reg: 0.0582 (0.0657)  time: 0.6863  data: 0.2902  max mem: 5528\n",
      "Training Epoch: [54]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1269 (0.1395)  loss_objectness: 0.0669 (0.0712)  loss_rpn_box_reg: 0.0582 (0.0683)  time: 0.6887  data: 0.2884  max mem: 5528\n",
      "Training Epoch: [54]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1363 (0.1397)  loss_objectness: 0.0714 (0.0720)  loss_rpn_box_reg: 0.0635 (0.0677)  time: 0.6728  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [54]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1437 (0.1393)  loss_objectness: 0.0696 (0.0711)  loss_rpn_box_reg: 0.0679 (0.0682)  time: 0.6872  data: 0.2948  max mem: 5528\n",
      "Training Epoch: [54]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1357 (0.1406)  loss_objectness: 0.0675 (0.0711)  loss_rpn_box_reg: 0.0693 (0.0695)  time: 0.7022  data: 0.2929  max mem: 5528\n",
      "Training Epoch: [54]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1270 (0.1383)  loss_objectness: 0.0618 (0.0689)  loss_rpn_box_reg: 0.0706 (0.0694)  time: 0.6824  data: 0.2881  max mem: 5528\n",
      "Training Epoch: [54]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1227 (0.1378)  loss_objectness: 0.0559 (0.0684)  loss_rpn_box_reg: 0.0689 (0.0694)  time: 0.6739  data: 0.2886  max mem: 5528\n",
      "Training Epoch: [54]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1335 (0.1384)  loss_objectness: 0.0652 (0.0698)  loss_rpn_box_reg: 0.0651 (0.0686)  time: 0.6686  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [54]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1483 (0.1405)  loss_objectness: 0.0783 (0.0711)  loss_rpn_box_reg: 0.0655 (0.0694)  time: 0.6748  data: 0.2940  max mem: 5528\n",
      "Training Epoch: [54]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1483 (0.1408)  loss_objectness: 0.0741 (0.0713)  loss_rpn_box_reg: 0.0706 (0.0695)  time: 0.6784  data: 0.2937  max mem: 5528\n",
      "Training Epoch: [54]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1370 (0.1405)  loss_objectness: 0.0723 (0.0711)  loss_rpn_box_reg: 0.0708 (0.0693)  time: 0.6913  data: 0.2904  max mem: 5528\n",
      "Training Epoch: [54]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1364 (0.1406)  loss_objectness: 0.0735 (0.0715)  loss_rpn_box_reg: 0.0709 (0.0691)  time: 0.6989  data: 0.2898  max mem: 5528\n",
      "Training Epoch: [54]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1404 (0.1417)  loss_objectness: 0.0764 (0.0723)  loss_rpn_box_reg: 0.0629 (0.0694)  time: 0.6703  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [54]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1408 (0.1414)  loss_objectness: 0.0750 (0.0724)  loss_rpn_box_reg: 0.0629 (0.0689)  time: 0.6819  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [54]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1525 (0.1429)  loss_objectness: 0.0744 (0.0730)  loss_rpn_box_reg: 0.0688 (0.0699)  time: 0.6913  data: 0.2946  max mem: 5528\n",
      "Training Epoch: [54]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1556 (0.1433)  loss_objectness: 0.0736 (0.0729)  loss_rpn_box_reg: 0.0813 (0.0704)  time: 0.6965  data: 0.3000  max mem: 5528\n",
      "Training Epoch: [54]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1387 (0.1425)  loss_objectness: 0.0718 (0.0729)  loss_rpn_box_reg: 0.0657 (0.0696)  time: 0.7264  data: 0.3068  max mem: 5528\n",
      "Training Epoch: [54]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1309 (0.1419)  loss_objectness: 0.0669 (0.0726)  loss_rpn_box_reg: 0.0582 (0.0692)  time: 0.7114  data: 0.2988  max mem: 5528\n",
      "Training Epoch: [54]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1339 (0.1424)  loss_objectness: 0.0628 (0.0722)  loss_rpn_box_reg: 0.0629 (0.0702)  time: 0.6797  data: 0.2892  max mem: 5528\n",
      "Training Epoch: [54]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1395 (0.1420)  loss_objectness: 0.0666 (0.0722)  loss_rpn_box_reg: 0.0690 (0.0698)  time: 0.6777  data: 0.2893  max mem: 5528\n",
      "Training Epoch: [54]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1387 (0.1422)  loss_objectness: 0.0732 (0.0723)  loss_rpn_box_reg: 0.0639 (0.0700)  time: 0.6768  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [54]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1547 (0.1430)  loss_objectness: 0.0739 (0.0726)  loss_rpn_box_reg: 0.0701 (0.0705)  time: 0.6933  data: 0.2949  max mem: 5528\n",
      "Training Epoch: [54]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1526 (0.1431)  loss_objectness: 0.0796 (0.0730)  loss_rpn_box_reg: 0.0608 (0.0701)  time: 0.7016  data: 0.2979  max mem: 5528\n",
      "Training Epoch: [54]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1408 (0.1429)  loss_objectness: 0.0716 (0.0728)  loss_rpn_box_reg: 0.0602 (0.0702)  time: 0.6833  data: 0.2918  max mem: 5528\n",
      "Training Epoch: [54] Total time: 0:02:51 (0.6870 s / it)\n",
      "Testing Epoch: [54]  [ 0/62]  eta: 0:00:40  lr: 0.000300  loss: 0.1338 (0.1338)  loss_objectness: 0.0492 (0.0492)  loss_rpn_box_reg: 0.0846 (0.0846)  time: 0.6461  data: 0.3021  max mem: 5528\n",
      "Testing Epoch: [54]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1233 (0.1346)  loss_objectness: 0.0529 (0.0560)  loss_rpn_box_reg: 0.0720 (0.0786)  time: 0.6278  data: 0.3080  max mem: 5528\n",
      "Testing Epoch: [54] Total time: 0:00:39 (0.6380 s / it)\n",
      "Training Epoch: [55]  [  0/250]  eta: 0:02:56  lr: 0.000300  loss: 0.1440 (0.1440)  loss_objectness: 0.0728 (0.0728)  loss_rpn_box_reg: 0.0712 (0.0712)  time: 0.7052  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [55]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1476 (0.1474)  loss_objectness: 0.0728 (0.0684)  loss_rpn_box_reg: 0.0744 (0.0790)  time: 0.6953  data: 0.2926  max mem: 5528\n",
      "Training Epoch: [55]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1517 (0.1444)  loss_objectness: 0.0612 (0.0672)  loss_rpn_box_reg: 0.0744 (0.0772)  time: 0.6830  data: 0.2938  max mem: 5528\n",
      "Training Epoch: [55]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1310 (0.1371)  loss_objectness: 0.0612 (0.0670)  loss_rpn_box_reg: 0.0580 (0.0701)  time: 0.6784  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [55]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1302 (0.1359)  loss_objectness: 0.0670 (0.0686)  loss_rpn_box_reg: 0.0564 (0.0673)  time: 0.6750  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [55]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1314 (0.1339)  loss_objectness: 0.0670 (0.0680)  loss_rpn_box_reg: 0.0620 (0.0658)  time: 0.6834  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [55]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1309 (0.1361)  loss_objectness: 0.0685 (0.0701)  loss_rpn_box_reg: 0.0621 (0.0660)  time: 0.6900  data: 0.2951  max mem: 5528\n",
      "Training Epoch: [55]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1349 (0.1370)  loss_objectness: 0.0685 (0.0696)  loss_rpn_box_reg: 0.0649 (0.0674)  time: 0.6814  data: 0.2934  max mem: 5528\n",
      "Training Epoch: [55]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1365 (0.1388)  loss_objectness: 0.0672 (0.0699)  loss_rpn_box_reg: 0.0713 (0.0689)  time: 0.6825  data: 0.2934  max mem: 5528\n",
      "Training Epoch: [55]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1402 (0.1401)  loss_objectness: 0.0748 (0.0709)  loss_rpn_box_reg: 0.0659 (0.0692)  time: 0.6792  data: 0.2939  max mem: 5528\n",
      "Training Epoch: [55]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1454 (0.1417)  loss_objectness: 0.0755 (0.0708)  loss_rpn_box_reg: 0.0652 (0.0709)  time: 0.6910  data: 0.2927  max mem: 5528\n",
      "Training Epoch: [55]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1362 (0.1420)  loss_objectness: 0.0660 (0.0709)  loss_rpn_box_reg: 0.0741 (0.0711)  time: 0.7094  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [55]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1362 (0.1424)  loss_objectness: 0.0748 (0.0715)  loss_rpn_box_reg: 0.0663 (0.0710)  time: 0.6936  data: 0.2906  max mem: 5528\n",
      "Training Epoch: [55]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1404 (0.1434)  loss_objectness: 0.0780 (0.0716)  loss_rpn_box_reg: 0.0663 (0.0718)  time: 0.6731  data: 0.2897  max mem: 5528\n",
      "Training Epoch: [55]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1338 (0.1427)  loss_objectness: 0.0663 (0.0715)  loss_rpn_box_reg: 0.0657 (0.0712)  time: 0.6752  data: 0.2944  max mem: 5528\n",
      "Training Epoch: [55]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1329 (0.1424)  loss_objectness: 0.0710 (0.0720)  loss_rpn_box_reg: 0.0621 (0.0704)  time: 0.6925  data: 0.2972  max mem: 5528\n",
      "Training Epoch: [55]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1365 (0.1421)  loss_objectness: 0.0782 (0.0720)  loss_rpn_box_reg: 0.0618 (0.0701)  time: 0.7021  data: 0.2932  max mem: 5528\n",
      "Training Epoch: [55]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1449 (0.1427)  loss_objectness: 0.0673 (0.0720)  loss_rpn_box_reg: 0.0695 (0.0707)  time: 0.6830  data: 0.2914  max mem: 5528\n",
      "Training Epoch: [55]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1448 (0.1421)  loss_objectness: 0.0695 (0.0724)  loss_rpn_box_reg: 0.0653 (0.0697)  time: 0.6878  data: 0.2864  max mem: 5528\n",
      "Training Epoch: [55]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1542 (0.1435)  loss_objectness: 0.0717 (0.0727)  loss_rpn_box_reg: 0.0683 (0.0708)  time: 0.6955  data: 0.2869  max mem: 5528\n",
      "Training Epoch: [55]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1450 (0.1434)  loss_objectness: 0.0765 (0.0729)  loss_rpn_box_reg: 0.0736 (0.0706)  time: 0.6882  data: 0.2915  max mem: 5528\n",
      "Training Epoch: [55]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1382 (0.1438)  loss_objectness: 0.0810 (0.0734)  loss_rpn_box_reg: 0.0606 (0.0704)  time: 0.6970  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [55]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1414 (0.1434)  loss_objectness: 0.0810 (0.0736)  loss_rpn_box_reg: 0.0550 (0.0698)  time: 0.7018  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [55]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1528 (0.1441)  loss_objectness: 0.0822 (0.0741)  loss_rpn_box_reg: 0.0680 (0.0699)  time: 0.6859  data: 0.2951  max mem: 5528\n",
      "Training Epoch: [55]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1517 (0.1443)  loss_objectness: 0.0803 (0.0741)  loss_rpn_box_reg: 0.0681 (0.0701)  time: 0.6835  data: 0.2939  max mem: 5528\n",
      "Training Epoch: [55]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1464 (0.1442)  loss_objectness: 0.0713 (0.0739)  loss_rpn_box_reg: 0.0773 (0.0704)  time: 0.6976  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [55] Total time: 0:02:52 (0.6884 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:00:57  model_time: 0.5851 (0.5851)  evaluator_time: 0.0540 (0.0540)  time: 0.9332  data: 0.2791  max mem: 5528\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3751 (0.3805)  evaluator_time: 0.0670 (0.0789)  time: 0.7609  data: 0.3073  max mem: 5528\n",
      "Test: Total time: 0:00:47 (0.7665 s / it)\n",
      "Averaged stats: model_time: 0.3751 (0.3805)  evaluator_time: 0.0670 (0.0789)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.059\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.170\n",
      "Testing Epoch: [55]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1352 (0.1352)  loss_objectness: 0.0474 (0.0474)  loss_rpn_box_reg: 0.0878 (0.0878)  time: 0.6181  data: 0.2921  max mem: 5528\n",
      "Testing Epoch: [55]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1290 (0.1375)  loss_objectness: 0.0534 (0.0572)  loss_rpn_box_reg: 0.0748 (0.0803)  time: 0.6343  data: 0.3096  max mem: 5528\n",
      "Testing Epoch: [55] Total time: 0:00:39 (0.6329 s / it)\n",
      "Training Epoch: [56]  [  0/250]  eta: 0:03:06  lr: 0.000300  loss: 0.0951 (0.0951)  loss_objectness: 0.0406 (0.0406)  loss_rpn_box_reg: 0.0545 (0.0545)  time: 0.7472  data: 0.2771  max mem: 5528\n",
      "Training Epoch: [56]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1421 (0.1336)  loss_objectness: 0.0779 (0.0725)  loss_rpn_box_reg: 0.0612 (0.0611)  time: 0.6813  data: 0.2876  max mem: 5528\n",
      "Training Epoch: [56]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1376 (0.1333)  loss_objectness: 0.0667 (0.0681)  loss_rpn_box_reg: 0.0656 (0.0652)  time: 0.6802  data: 0.2861  max mem: 5528\n",
      "Training Epoch: [56]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1369 (0.1367)  loss_objectness: 0.0742 (0.0715)  loss_rpn_box_reg: 0.0674 (0.0652)  time: 0.6907  data: 0.2884  max mem: 5528\n",
      "Training Epoch: [56]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1276 (0.1354)  loss_objectness: 0.0760 (0.0712)  loss_rpn_box_reg: 0.0569 (0.0642)  time: 0.6896  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [56]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1303 (0.1378)  loss_objectness: 0.0676 (0.0723)  loss_rpn_box_reg: 0.0571 (0.0655)  time: 0.6737  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [56]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1457 (0.1393)  loss_objectness: 0.0660 (0.0718)  loss_rpn_box_reg: 0.0787 (0.0676)  time: 0.6789  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [56]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1413 (0.1402)  loss_objectness: 0.0675 (0.0725)  loss_rpn_box_reg: 0.0687 (0.0676)  time: 0.7015  data: 0.2940  max mem: 5528\n",
      "Training Epoch: [56]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1391 (0.1407)  loss_objectness: 0.0777 (0.0726)  loss_rpn_box_reg: 0.0637 (0.0681)  time: 0.6928  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [56]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1493 (0.1426)  loss_objectness: 0.0741 (0.0730)  loss_rpn_box_reg: 0.0683 (0.0697)  time: 0.6783  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [56]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1507 (0.1429)  loss_objectness: 0.0755 (0.0740)  loss_rpn_box_reg: 0.0683 (0.0689)  time: 0.6702  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [56]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1399 (0.1422)  loss_objectness: 0.0762 (0.0736)  loss_rpn_box_reg: 0.0590 (0.0686)  time: 0.6826  data: 0.2899  max mem: 5528\n",
      "Training Epoch: [56]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1358 (0.1417)  loss_objectness: 0.0670 (0.0734)  loss_rpn_box_reg: 0.0659 (0.0683)  time: 0.7037  data: 0.2892  max mem: 5528\n",
      "Training Epoch: [56]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1290 (0.1409)  loss_objectness: 0.0670 (0.0727)  loss_rpn_box_reg: 0.0685 (0.0682)  time: 0.6966  data: 0.2889  max mem: 5528\n",
      "Training Epoch: [56]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1420 (0.1422)  loss_objectness: 0.0690 (0.0734)  loss_rpn_box_reg: 0.0699 (0.0688)  time: 0.6893  data: 0.2886  max mem: 5528\n",
      "Training Epoch: [56]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1483 (0.1426)  loss_objectness: 0.0818 (0.0738)  loss_rpn_box_reg: 0.0693 (0.0688)  time: 0.6671  data: 0.2865  max mem: 5528\n",
      "Training Epoch: [56]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1441 (0.1422)  loss_objectness: 0.0720 (0.0735)  loss_rpn_box_reg: 0.0632 (0.0687)  time: 0.6627  data: 0.2887  max mem: 5528\n",
      "Training Epoch: [56]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1367 (0.1424)  loss_objectness: 0.0695 (0.0735)  loss_rpn_box_reg: 0.0702 (0.0689)  time: 0.6903  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [56]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1444 (0.1432)  loss_objectness: 0.0758 (0.0739)  loss_rpn_box_reg: 0.0744 (0.0694)  time: 0.6975  data: 0.2942  max mem: 5528\n",
      "Training Epoch: [56]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1448 (0.1437)  loss_objectness: 0.0789 (0.0740)  loss_rpn_box_reg: 0.0696 (0.0697)  time: 0.6966  data: 0.2922  max mem: 5528\n",
      "Training Epoch: [56]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1397 (0.1435)  loss_objectness: 0.0664 (0.0735)  loss_rpn_box_reg: 0.0655 (0.0700)  time: 0.6957  data: 0.2892  max mem: 5528\n",
      "Training Epoch: [56]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1367 (0.1432)  loss_objectness: 0.0664 (0.0737)  loss_rpn_box_reg: 0.0655 (0.0695)  time: 0.6842  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [56]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1272 (0.1428)  loss_objectness: 0.0775 (0.0737)  loss_rpn_box_reg: 0.0651 (0.0691)  time: 0.6873  data: 0.2891  max mem: 5528\n",
      "Training Epoch: [56]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1459 (0.1435)  loss_objectness: 0.0775 (0.0740)  loss_rpn_box_reg: 0.0681 (0.0695)  time: 0.6981  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [56]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1493 (0.1440)  loss_objectness: 0.0736 (0.0741)  loss_rpn_box_reg: 0.0764 (0.0699)  time: 0.6898  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [56]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1412 (0.1442)  loss_objectness: 0.0743 (0.0744)  loss_rpn_box_reg: 0.0723 (0.0698)  time: 0.6860  data: 0.2879  max mem: 5528\n",
      "Training Epoch: [56] Total time: 0:02:51 (0.6868 s / it)\n",
      "Testing Epoch: [56]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1367 (0.1367)  loss_objectness: 0.0459 (0.0459)  loss_rpn_box_reg: 0.0909 (0.0909)  time: 0.6061  data: 0.2791  max mem: 5528\n",
      "Testing Epoch: [56]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1250 (0.1381)  loss_objectness: 0.0511 (0.0575)  loss_rpn_box_reg: 0.0694 (0.0806)  time: 0.6335  data: 0.3079  max mem: 5528\n",
      "Testing Epoch: [56] Total time: 0:00:39 (0.6321 s / it)\n",
      "Training Epoch: [57]  [  0/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1109 (0.1109)  loss_objectness: 0.0648 (0.0648)  loss_rpn_box_reg: 0.0461 (0.0461)  time: 0.6461  data: 0.2821  max mem: 5528\n",
      "Training Epoch: [57]  [ 10/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1255 (0.1210)  loss_objectness: 0.0648 (0.0626)  loss_rpn_box_reg: 0.0593 (0.0584)  time: 0.6681  data: 0.2848  max mem: 5528\n",
      "Training Epoch: [57]  [ 20/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1284 (0.1303)  loss_objectness: 0.0674 (0.0681)  loss_rpn_box_reg: 0.0593 (0.0622)  time: 0.6643  data: 0.2895  max mem: 5528\n",
      "Training Epoch: [57]  [ 30/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1351 (0.1306)  loss_objectness: 0.0658 (0.0671)  loss_rpn_box_reg: 0.0607 (0.0635)  time: 0.6762  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [57]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1274 (0.1309)  loss_objectness: 0.0652 (0.0678)  loss_rpn_box_reg: 0.0594 (0.0631)  time: 0.6934  data: 0.2906  max mem: 5528\n",
      "Training Epoch: [57]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1274 (0.1333)  loss_objectness: 0.0652 (0.0672)  loss_rpn_box_reg: 0.0594 (0.0661)  time: 0.6931  data: 0.2923  max mem: 5528\n",
      "Training Epoch: [57]  [ 60/250]  eta: 0:02:08  lr: 0.000300  loss: 0.1255 (0.1348)  loss_objectness: 0.0637 (0.0684)  loss_rpn_box_reg: 0.0592 (0.0664)  time: 0.6758  data: 0.2932  max mem: 5528\n",
      "Training Epoch: [57]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1364 (0.1364)  loss_objectness: 0.0727 (0.0688)  loss_rpn_box_reg: 0.0713 (0.0675)  time: 0.6813  data: 0.2932  max mem: 5528\n",
      "Training Epoch: [57]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1371 (0.1364)  loss_objectness: 0.0726 (0.0693)  loss_rpn_box_reg: 0.0661 (0.0670)  time: 0.6915  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [57]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1316 (0.1369)  loss_objectness: 0.0726 (0.0708)  loss_rpn_box_reg: 0.0572 (0.0661)  time: 0.6667  data: 0.2929  max mem: 5528\n",
      "Training Epoch: [57]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1461 (0.1382)  loss_objectness: 0.0831 (0.0721)  loss_rpn_box_reg: 0.0593 (0.0660)  time: 0.6761  data: 0.2932  max mem: 5528\n",
      "Training Epoch: [57]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1475 (0.1387)  loss_objectness: 0.0721 (0.0716)  loss_rpn_box_reg: 0.0708 (0.0670)  time: 0.6937  data: 0.2928  max mem: 5528\n",
      "Training Epoch: [57]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1364 (0.1381)  loss_objectness: 0.0663 (0.0716)  loss_rpn_box_reg: 0.0706 (0.0665)  time: 0.6828  data: 0.2891  max mem: 5528\n",
      "Training Epoch: [57]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1258 (0.1378)  loss_objectness: 0.0697 (0.0719)  loss_rpn_box_reg: 0.0575 (0.0659)  time: 0.6807  data: 0.2895  max mem: 5528\n",
      "Training Epoch: [57]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1300 (0.1381)  loss_objectness: 0.0696 (0.0717)  loss_rpn_box_reg: 0.0604 (0.0664)  time: 0.6762  data: 0.2929  max mem: 5528\n",
      "Training Epoch: [57]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1267 (0.1384)  loss_objectness: 0.0713 (0.0721)  loss_rpn_box_reg: 0.0604 (0.0663)  time: 0.6867  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [57]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1287 (0.1388)  loss_objectness: 0.0747 (0.0720)  loss_rpn_box_reg: 0.0676 (0.0667)  time: 0.6995  data: 0.2905  max mem: 5528\n",
      "Training Epoch: [57]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1389 (0.1388)  loss_objectness: 0.0722 (0.0723)  loss_rpn_box_reg: 0.0676 (0.0665)  time: 0.7036  data: 0.2893  max mem: 5528\n",
      "Training Epoch: [57]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1323 (0.1397)  loss_objectness: 0.0713 (0.0724)  loss_rpn_box_reg: 0.0640 (0.0673)  time: 0.7082  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [57]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1323 (0.1395)  loss_objectness: 0.0691 (0.0721)  loss_rpn_box_reg: 0.0653 (0.0674)  time: 0.6930  data: 0.2901  max mem: 5528\n",
      "Training Epoch: [57]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1383 (0.1407)  loss_objectness: 0.0712 (0.0724)  loss_rpn_box_reg: 0.0735 (0.0684)  time: 0.6977  data: 0.2882  max mem: 5528\n",
      "Training Epoch: [57]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1565 (0.1417)  loss_objectness: 0.0736 (0.0727)  loss_rpn_box_reg: 0.0811 (0.0690)  time: 0.6825  data: 0.2883  max mem: 5528\n",
      "Training Epoch: [57]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1393 (0.1418)  loss_objectness: 0.0703 (0.0726)  loss_rpn_box_reg: 0.0695 (0.0692)  time: 0.6647  data: 0.2868  max mem: 5528\n",
      "Training Epoch: [57]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1393 (0.1421)  loss_objectness: 0.0748 (0.0728)  loss_rpn_box_reg: 0.0606 (0.0693)  time: 0.6825  data: 0.2878  max mem: 5528\n",
      "Training Epoch: [57]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1436 (0.1423)  loss_objectness: 0.0761 (0.0729)  loss_rpn_box_reg: 0.0651 (0.0694)  time: 0.6901  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [57]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1378 (0.1420)  loss_objectness: 0.0704 (0.0725)  loss_rpn_box_reg: 0.0629 (0.0695)  time: 0.6959  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [57] Total time: 0:02:51 (0.6854 s / it)\n",
      "Testing Epoch: [57]  [ 0/62]  eta: 0:00:45  lr: 0.000300  loss: 0.1318 (0.1318)  loss_objectness: 0.0451 (0.0451)  loss_rpn_box_reg: 0.0867 (0.0867)  time: 0.7392  data: 0.4071  max mem: 5528\n",
      "Testing Epoch: [57]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1242 (0.1368)  loss_objectness: 0.0525 (0.0569)  loss_rpn_box_reg: 0.0703 (0.0799)  time: 0.6397  data: 0.3101  max mem: 5528\n",
      "Testing Epoch: [57] Total time: 0:00:39 (0.6370 s / it)\n",
      "Training Epoch: [58]  [  0/250]  eta: 0:02:37  lr: 0.000300  loss: 0.0792 (0.0792)  loss_objectness: 0.0448 (0.0448)  loss_rpn_box_reg: 0.0344 (0.0344)  time: 0.6291  data: 0.2771  max mem: 5528\n",
      "Training Epoch: [58]  [ 10/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1132 (0.1194)  loss_objectness: 0.0606 (0.0630)  loss_rpn_box_reg: 0.0515 (0.0563)  time: 0.6681  data: 0.2856  max mem: 5528\n",
      "Training Epoch: [58]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1176 (0.1289)  loss_objectness: 0.0643 (0.0663)  loss_rpn_box_reg: 0.0542 (0.0626)  time: 0.6952  data: 0.2972  max mem: 5528\n",
      "Training Epoch: [58]  [ 30/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1225 (0.1312)  loss_objectness: 0.0643 (0.0675)  loss_rpn_box_reg: 0.0603 (0.0636)  time: 0.7215  data: 0.3078  max mem: 5528\n",
      "Training Epoch: [58]  [ 40/250]  eta: 0:02:27  lr: 0.000300  loss: 0.1329 (0.1340)  loss_objectness: 0.0643 (0.0674)  loss_rpn_box_reg: 0.0687 (0.0665)  time: 0.7086  data: 0.3086  max mem: 5528\n",
      "Training Epoch: [58]  [ 50/250]  eta: 0:02:20  lr: 0.000300  loss: 0.1327 (0.1321)  loss_objectness: 0.0662 (0.0668)  loss_rpn_box_reg: 0.0661 (0.0653)  time: 0.6979  data: 0.3059  max mem: 5528\n",
      "Training Epoch: [58]  [ 60/250]  eta: 0:02:13  lr: 0.000300  loss: 0.1385 (0.1333)  loss_objectness: 0.0650 (0.0671)  loss_rpn_box_reg: 0.0656 (0.0663)  time: 0.7056  data: 0.3059  max mem: 5528\n",
      "Training Epoch: [58]  [ 70/250]  eta: 0:02:06  lr: 0.000300  loss: 0.1385 (0.1341)  loss_objectness: 0.0707 (0.0680)  loss_rpn_box_reg: 0.0614 (0.0661)  time: 0.7103  data: 0.3175  max mem: 5528\n",
      "Training Epoch: [58]  [ 80/250]  eta: 0:02:00  lr: 0.000300  loss: 0.1486 (0.1378)  loss_objectness: 0.0768 (0.0694)  loss_rpn_box_reg: 0.0727 (0.0683)  time: 0.7255  data: 0.3288  max mem: 5528\n",
      "Training Epoch: [58]  [ 90/250]  eta: 0:01:53  lr: 0.000300  loss: 0.1401 (0.1365)  loss_objectness: 0.0722 (0.0697)  loss_rpn_box_reg: 0.0684 (0.0668)  time: 0.7308  data: 0.3275  max mem: 5528\n",
      "Training Epoch: [58]  [100/250]  eta: 0:01:46  lr: 0.000300  loss: 0.1145 (0.1346)  loss_objectness: 0.0699 (0.0692)  loss_rpn_box_reg: 0.0540 (0.0654)  time: 0.7206  data: 0.3148  max mem: 5528\n",
      "Training Epoch: [58]  [110/250]  eta: 0:01:39  lr: 0.000300  loss: 0.1244 (0.1363)  loss_objectness: 0.0699 (0.0699)  loss_rpn_box_reg: 0.0580 (0.0664)  time: 0.7311  data: 0.3108  max mem: 5528\n",
      "Training Epoch: [58]  [120/250]  eta: 0:01:33  lr: 0.000300  loss: 0.1379 (0.1372)  loss_objectness: 0.0691 (0.0695)  loss_rpn_box_reg: 0.0742 (0.0676)  time: 0.7466  data: 0.3186  max mem: 5528\n",
      "Training Epoch: [58]  [130/250]  eta: 0:01:25  lr: 0.000300  loss: 0.1337 (0.1373)  loss_objectness: 0.0635 (0.0692)  loss_rpn_box_reg: 0.0742 (0.0681)  time: 0.7318  data: 0.3130  max mem: 5528\n",
      "Training Epoch: [58]  [140/250]  eta: 0:01:18  lr: 0.000300  loss: 0.1423 (0.1383)  loss_objectness: 0.0677 (0.0697)  loss_rpn_box_reg: 0.0754 (0.0687)  time: 0.7147  data: 0.3023  max mem: 5528\n",
      "Training Epoch: [58]  [150/250]  eta: 0:01:11  lr: 0.000300  loss: 0.1445 (0.1377)  loss_objectness: 0.0672 (0.0696)  loss_rpn_box_reg: 0.0628 (0.0681)  time: 0.7031  data: 0.3003  max mem: 5528\n",
      "Training Epoch: [58]  [160/250]  eta: 0:01:04  lr: 0.000300  loss: 0.1318 (0.1378)  loss_objectness: 0.0676 (0.0699)  loss_rpn_box_reg: 0.0616 (0.0679)  time: 0.7089  data: 0.3009  max mem: 5528\n",
      "Training Epoch: [58]  [170/250]  eta: 0:00:57  lr: 0.000300  loss: 0.1408 (0.1383)  loss_objectness: 0.0696 (0.0702)  loss_rpn_box_reg: 0.0653 (0.0681)  time: 0.7177  data: 0.3009  max mem: 5528\n",
      "Training Epoch: [58]  [180/250]  eta: 0:00:49  lr: 0.000300  loss: 0.1470 (0.1389)  loss_objectness: 0.0720 (0.0706)  loss_rpn_box_reg: 0.0681 (0.0684)  time: 0.6898  data: 0.2982  max mem: 5528\n",
      "Training Epoch: [58]  [190/250]  eta: 0:00:42  lr: 0.000300  loss: 0.1453 (0.1393)  loss_objectness: 0.0741 (0.0708)  loss_rpn_box_reg: 0.0737 (0.0685)  time: 0.6871  data: 0.2987  max mem: 5528\n",
      "Training Epoch: [58]  [200/250]  eta: 0:00:35  lr: 0.000300  loss: 0.1522 (0.1404)  loss_objectness: 0.0741 (0.0712)  loss_rpn_box_reg: 0.0765 (0.0692)  time: 0.7207  data: 0.3008  max mem: 5528\n",
      "Training Epoch: [58]  [210/250]  eta: 0:00:28  lr: 0.000300  loss: 0.1564 (0.1408)  loss_objectness: 0.0709 (0.0711)  loss_rpn_box_reg: 0.0782 (0.0697)  time: 0.7386  data: 0.3046  max mem: 5528\n",
      "Training Epoch: [58]  [220/250]  eta: 0:00:21  lr: 0.000300  loss: 0.1488 (0.1410)  loss_objectness: 0.0701 (0.0713)  loss_rpn_box_reg: 0.0687 (0.0697)  time: 0.7214  data: 0.3045  max mem: 5528\n",
      "Training Epoch: [58]  [230/250]  eta: 0:00:14  lr: 0.000300  loss: 0.1350 (0.1407)  loss_objectness: 0.0735 (0.0713)  loss_rpn_box_reg: 0.0687 (0.0694)  time: 0.6944  data: 0.2965  max mem: 5528\n",
      "Training Epoch: [58]  [240/250]  eta: 0:00:07  lr: 0.000300  loss: 0.1378 (0.1415)  loss_objectness: 0.0757 (0.0716)  loss_rpn_box_reg: 0.0752 (0.0699)  time: 0.6796  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [58]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1509 (0.1418)  loss_objectness: 0.0791 (0.0719)  loss_rpn_box_reg: 0.0752 (0.0699)  time: 0.6768  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [58] Total time: 0:02:57 (0.7098 s / it)\n",
      "Testing Epoch: [58]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1335 (0.1335)  loss_objectness: 0.0459 (0.0459)  loss_rpn_box_reg: 0.0876 (0.0876)  time: 0.6051  data: 0.2811  max mem: 5528\n",
      "Testing Epoch: [58]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1301 (0.1403)  loss_objectness: 0.0560 (0.0611)  loss_rpn_box_reg: 0.0683 (0.0792)  time: 0.6225  data: 0.3026  max mem: 5528\n",
      "Testing Epoch: [58] Total time: 0:00:39 (0.6340 s / it)\n",
      "Training Epoch: [59]  [  0/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1507 (0.1507)  loss_objectness: 0.0707 (0.0707)  loss_rpn_box_reg: 0.0800 (0.0800)  time: 0.6291  data: 0.3011  max mem: 5528\n",
      "Training Epoch: [59]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1476 (0.1540)  loss_objectness: 0.0685 (0.0724)  loss_rpn_box_reg: 0.0753 (0.0816)  time: 0.6931  data: 0.2956  max mem: 5528\n",
      "Training Epoch: [59]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1365 (0.1432)  loss_objectness: 0.0673 (0.0683)  loss_rpn_box_reg: 0.0700 (0.0749)  time: 0.6881  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [59]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1339 (0.1410)  loss_objectness: 0.0701 (0.0696)  loss_rpn_box_reg: 0.0665 (0.0714)  time: 0.6741  data: 0.2870  max mem: 5528\n",
      "Training Epoch: [59]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1320 (0.1396)  loss_objectness: 0.0710 (0.0683)  loss_rpn_box_reg: 0.0690 (0.0713)  time: 0.6705  data: 0.2859  max mem: 5528\n",
      "Training Epoch: [59]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1255 (0.1377)  loss_objectness: 0.0673 (0.0681)  loss_rpn_box_reg: 0.0690 (0.0696)  time: 0.6810  data: 0.2887  max mem: 5528\n",
      "Training Epoch: [59]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1254 (0.1375)  loss_objectness: 0.0686 (0.0688)  loss_rpn_box_reg: 0.0519 (0.0687)  time: 0.6837  data: 0.2886  max mem: 5528\n",
      "Training Epoch: [59]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1317 (0.1394)  loss_objectness: 0.0677 (0.0687)  loss_rpn_box_reg: 0.0637 (0.0707)  time: 0.6746  data: 0.2913  max mem: 5528\n",
      "Training Epoch: [59]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1294 (0.1399)  loss_objectness: 0.0644 (0.0692)  loss_rpn_box_reg: 0.0612 (0.0707)  time: 0.6949  data: 0.2932  max mem: 5528\n",
      "Training Epoch: [59]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1254 (0.1386)  loss_objectness: 0.0599 (0.0687)  loss_rpn_box_reg: 0.0612 (0.0698)  time: 0.7164  data: 0.2906  max mem: 5528\n",
      "Training Epoch: [59]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1394 (0.1399)  loss_objectness: 0.0736 (0.0698)  loss_rpn_box_reg: 0.0657 (0.0700)  time: 0.6988  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [59]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1400 (0.1410)  loss_objectness: 0.0794 (0.0707)  loss_rpn_box_reg: 0.0657 (0.0703)  time: 0.6796  data: 0.2963  max mem: 5528\n",
      "Training Epoch: [59]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1384 (0.1408)  loss_objectness: 0.0759 (0.0708)  loss_rpn_box_reg: 0.0668 (0.0701)  time: 0.6871  data: 0.2942  max mem: 5528\n",
      "Training Epoch: [59]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1387 (0.1414)  loss_objectness: 0.0763 (0.0717)  loss_rpn_box_reg: 0.0632 (0.0697)  time: 0.6723  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [59]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1485 (0.1416)  loss_objectness: 0.0763 (0.0717)  loss_rpn_box_reg: 0.0683 (0.0699)  time: 0.6696  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [59]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1584 (0.1429)  loss_objectness: 0.0700 (0.0719)  loss_rpn_box_reg: 0.0732 (0.0710)  time: 0.7010  data: 0.2947  max mem: 5528\n",
      "Training Epoch: [59]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1571 (0.1437)  loss_objectness: 0.0771 (0.0724)  loss_rpn_box_reg: 0.0739 (0.0713)  time: 0.6991  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [59]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1388 (0.1433)  loss_objectness: 0.0761 (0.0723)  loss_rpn_box_reg: 0.0651 (0.0710)  time: 0.6817  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [59]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1300 (0.1426)  loss_objectness: 0.0671 (0.0718)  loss_rpn_box_reg: 0.0611 (0.0708)  time: 0.6728  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [59]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1302 (0.1426)  loss_objectness: 0.0641 (0.0716)  loss_rpn_box_reg: 0.0670 (0.0710)  time: 0.6791  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [59]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1310 (0.1422)  loss_objectness: 0.0652 (0.0717)  loss_rpn_box_reg: 0.0640 (0.0705)  time: 0.6734  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [59]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1322 (0.1423)  loss_objectness: 0.0708 (0.0717)  loss_rpn_box_reg: 0.0640 (0.0706)  time: 0.6791  data: 0.2913  max mem: 5528\n",
      "Training Epoch: [59]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1383 (0.1421)  loss_objectness: 0.0720 (0.0717)  loss_rpn_box_reg: 0.0681 (0.0704)  time: 0.6938  data: 0.2889  max mem: 5528\n",
      "Training Epoch: [59]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1436 (0.1424)  loss_objectness: 0.0735 (0.0719)  loss_rpn_box_reg: 0.0688 (0.0705)  time: 0.6787  data: 0.2860  max mem: 5528\n",
      "Training Epoch: [59]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1342 (0.1419)  loss_objectness: 0.0722 (0.0718)  loss_rpn_box_reg: 0.0607 (0.0701)  time: 0.6703  data: 0.2858  max mem: 5528\n",
      "Training Epoch: [59]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1342 (0.1424)  loss_objectness: 0.0754 (0.0722)  loss_rpn_box_reg: 0.0591 (0.0701)  time: 0.6791  data: 0.2877  max mem: 5528\n",
      "Training Epoch: [59] Total time: 0:02:50 (0.6836 s / it)\n",
      "Testing Epoch: [59]  [ 0/62]  eta: 0:00:43  lr: 0.000300  loss: 0.1316 (0.1316)  loss_objectness: 0.0446 (0.0446)  loss_rpn_box_reg: 0.0870 (0.0870)  time: 0.6992  data: 0.3751  max mem: 5528\n",
      "Testing Epoch: [59]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1265 (0.1373)  loss_objectness: 0.0510 (0.0573)  loss_rpn_box_reg: 0.0744 (0.0800)  time: 0.6302  data: 0.3091  max mem: 5528\n",
      "Testing Epoch: [59] Total time: 0:00:39 (0.6318 s / it)\n",
      "Training Epoch: [60]  [  0/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1430 (0.1430)  loss_objectness: 0.0603 (0.0603)  loss_rpn_box_reg: 0.0828 (0.0828)  time: 0.6842  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [60]  [ 10/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1405 (0.1464)  loss_objectness: 0.0630 (0.0720)  loss_rpn_box_reg: 0.0805 (0.0745)  time: 0.6775  data: 0.2960  max mem: 5528\n",
      "Training Epoch: [60]  [ 20/250]  eta: 0:02:33  lr: 0.000300  loss: 0.1378 (0.1437)  loss_objectness: 0.0667 (0.0699)  loss_rpn_box_reg: 0.0734 (0.0738)  time: 0.6645  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [60]  [ 30/250]  eta: 0:02:27  lr: 0.000300  loss: 0.1327 (0.1431)  loss_objectness: 0.0667 (0.0695)  loss_rpn_box_reg: 0.0643 (0.0736)  time: 0.6666  data: 0.2906  max mem: 5528\n",
      "Training Epoch: [60]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1350 (0.1430)  loss_objectness: 0.0642 (0.0700)  loss_rpn_box_reg: 0.0681 (0.0730)  time: 0.6918  data: 0.2922  max mem: 5528\n",
      "Training Epoch: [60]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1446 (0.1456)  loss_objectness: 0.0719 (0.0715)  loss_rpn_box_reg: 0.0724 (0.0741)  time: 0.7052  data: 0.2923  max mem: 5528\n",
      "Training Epoch: [60]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1506 (0.1458)  loss_objectness: 0.0693 (0.0713)  loss_rpn_box_reg: 0.0724 (0.0745)  time: 0.7048  data: 0.2890  max mem: 5528\n",
      "Training Epoch: [60]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1393 (0.1451)  loss_objectness: 0.0655 (0.0704)  loss_rpn_box_reg: 0.0707 (0.0747)  time: 0.6915  data: 0.2881  max mem: 5528\n",
      "Training Epoch: [60]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1351 (0.1449)  loss_objectness: 0.0666 (0.0716)  loss_rpn_box_reg: 0.0675 (0.0733)  time: 0.6864  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [60]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1319 (0.1430)  loss_objectness: 0.0672 (0.0709)  loss_rpn_box_reg: 0.0629 (0.0721)  time: 0.6904  data: 0.2947  max mem: 5528\n",
      "Training Epoch: [60]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1312 (0.1426)  loss_objectness: 0.0682 (0.0710)  loss_rpn_box_reg: 0.0629 (0.0717)  time: 0.6728  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [60]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1392 (0.1429)  loss_objectness: 0.0683 (0.0707)  loss_rpn_box_reg: 0.0715 (0.0722)  time: 0.6708  data: 0.2906  max mem: 5528\n",
      "Training Epoch: [60]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1383 (0.1425)  loss_objectness: 0.0740 (0.0711)  loss_rpn_box_reg: 0.0611 (0.0714)  time: 0.6851  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [60]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1383 (0.1428)  loss_objectness: 0.0714 (0.0710)  loss_rpn_box_reg: 0.0626 (0.0718)  time: 0.6920  data: 0.2926  max mem: 5528\n",
      "Training Epoch: [60]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1327 (0.1422)  loss_objectness: 0.0700 (0.0714)  loss_rpn_box_reg: 0.0609 (0.0708)  time: 0.6988  data: 0.2950  max mem: 5528\n",
      "Training Epoch: [60]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1327 (0.1424)  loss_objectness: 0.0717 (0.0716)  loss_rpn_box_reg: 0.0589 (0.0708)  time: 0.6999  data: 0.2906  max mem: 5528\n",
      "Training Epoch: [60]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1379 (0.1421)  loss_objectness: 0.0727 (0.0718)  loss_rpn_box_reg: 0.0599 (0.0704)  time: 0.6898  data: 0.2886  max mem: 5528\n",
      "Training Epoch: [60]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1339 (0.1423)  loss_objectness: 0.0743 (0.0722)  loss_rpn_box_reg: 0.0582 (0.0702)  time: 0.6703  data: 0.2914  max mem: 5528\n",
      "Training Epoch: [60]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1379 (0.1425)  loss_objectness: 0.0786 (0.0725)  loss_rpn_box_reg: 0.0653 (0.0700)  time: 0.6693  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [60]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1448 (0.1433)  loss_objectness: 0.0773 (0.0729)  loss_rpn_box_reg: 0.0704 (0.0704)  time: 0.6971  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [60]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1479 (0.1435)  loss_objectness: 0.0747 (0.0726)  loss_rpn_box_reg: 0.0719 (0.0709)  time: 0.7025  data: 0.2896  max mem: 5528\n",
      "Training Epoch: [60]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1479 (0.1436)  loss_objectness: 0.0739 (0.0727)  loss_rpn_box_reg: 0.0756 (0.0709)  time: 0.6922  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [60]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1435 (0.1434)  loss_objectness: 0.0699 (0.0727)  loss_rpn_box_reg: 0.0704 (0.0707)  time: 0.6942  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [60]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1262 (0.1429)  loss_objectness: 0.0661 (0.0724)  loss_rpn_box_reg: 0.0612 (0.0705)  time: 0.6866  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [60]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1280 (0.1425)  loss_objectness: 0.0657 (0.0724)  loss_rpn_box_reg: 0.0606 (0.0701)  time: 0.6811  data: 0.2855  max mem: 5528\n",
      "Training Epoch: [60]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1329 (0.1425)  loss_objectness: 0.0717 (0.0724)  loss_rpn_box_reg: 0.0606 (0.0701)  time: 0.6846  data: 0.2887  max mem: 5528\n",
      "Training Epoch: [60] Total time: 0:02:51 (0.6870 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:02  model_time: 0.6531 (0.6531)  evaluator_time: 0.0540 (0.0540)  time: 1.0032  data: 0.2791  max mem: 5528\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3801 (0.3817)  evaluator_time: 0.0680 (0.0728)  time: 0.7614  data: 0.3007  max mem: 5528\n",
      "Test: Total time: 0:00:47 (0.7645 s / it)\n",
      "Averaged stats: model_time: 0.3801 (0.3817)  evaluator_time: 0.0680 (0.0728)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.099\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.165\n",
      "Testing Epoch: [60]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1367 (0.1367)  loss_objectness: 0.0466 (0.0466)  loss_rpn_box_reg: 0.0900 (0.0900)  time: 0.6111  data: 0.2861  max mem: 5528\n",
      "Testing Epoch: [60]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1296 (0.1388)  loss_objectness: 0.0571 (0.0592)  loss_rpn_box_reg: 0.0719 (0.0796)  time: 0.6284  data: 0.3061  max mem: 5528\n",
      "Testing Epoch: [60] Total time: 0:00:39 (0.6293 s / it)\n",
      "Training Epoch: [61]  [  0/250]  eta: 0:03:01  lr: 0.000300  loss: 0.1406 (0.1406)  loss_objectness: 0.0690 (0.0690)  loss_rpn_box_reg: 0.0716 (0.0716)  time: 0.7262  data: 0.3041  max mem: 5528\n",
      "Training Epoch: [61]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1262 (0.1329)  loss_objectness: 0.0690 (0.0697)  loss_rpn_box_reg: 0.0599 (0.0632)  time: 0.6993  data: 0.2929  max mem: 5528\n",
      "Training Epoch: [61]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1306 (0.1416)  loss_objectness: 0.0764 (0.0765)  loss_rpn_box_reg: 0.0599 (0.0651)  time: 0.6975  data: 0.2979  max mem: 5528\n",
      "Training Epoch: [61]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1383 (0.1382)  loss_objectness: 0.0703 (0.0730)  loss_rpn_box_reg: 0.0614 (0.0652)  time: 0.6907  data: 0.2964  max mem: 5528\n",
      "Training Epoch: [61]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1353 (0.1382)  loss_objectness: 0.0672 (0.0721)  loss_rpn_box_reg: 0.0662 (0.0660)  time: 0.6703  data: 0.2905  max mem: 5528\n",
      "Training Epoch: [61]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1282 (0.1359)  loss_objectness: 0.0672 (0.0708)  loss_rpn_box_reg: 0.0627 (0.0651)  time: 0.6667  data: 0.2886  max mem: 5528\n",
      "Training Epoch: [61]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1387 (0.1383)  loss_objectness: 0.0693 (0.0718)  loss_rpn_box_reg: 0.0655 (0.0665)  time: 0.6710  data: 0.2880  max mem: 5528\n",
      "Training Epoch: [61]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1505 (0.1412)  loss_objectness: 0.0747 (0.0735)  loss_rpn_box_reg: 0.0773 (0.0678)  time: 0.6690  data: 0.2915  max mem: 5528\n",
      "Training Epoch: [61]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1505 (0.1419)  loss_objectness: 0.0786 (0.0736)  loss_rpn_box_reg: 0.0755 (0.0683)  time: 0.6721  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [61]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1329 (0.1409)  loss_objectness: 0.0772 (0.0737)  loss_rpn_box_reg: 0.0538 (0.0672)  time: 0.6778  data: 0.2913  max mem: 5528\n",
      "Training Epoch: [61]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1330 (0.1402)  loss_objectness: 0.0745 (0.0737)  loss_rpn_box_reg: 0.0564 (0.0665)  time: 0.6752  data: 0.2888  max mem: 5528\n",
      "Training Epoch: [61]  [110/250]  eta: 0:01:34  lr: 0.000300  loss: 0.1415 (0.1421)  loss_objectness: 0.0724 (0.0741)  loss_rpn_box_reg: 0.0656 (0.0680)  time: 0.6746  data: 0.2896  max mem: 5528\n",
      "Training Epoch: [61]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1522 (0.1431)  loss_objectness: 0.0736 (0.0747)  loss_rpn_box_reg: 0.0720 (0.0684)  time: 0.6853  data: 0.2944  max mem: 5528\n",
      "Training Epoch: [61]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1312 (0.1422)  loss_objectness: 0.0736 (0.0742)  loss_rpn_box_reg: 0.0720 (0.0680)  time: 0.6914  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [61]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1326 (0.1419)  loss_objectness: 0.0656 (0.0739)  loss_rpn_box_reg: 0.0657 (0.0680)  time: 0.6982  data: 0.2879  max mem: 5528\n",
      "Training Epoch: [61]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1349 (0.1417)  loss_objectness: 0.0782 (0.0743)  loss_rpn_box_reg: 0.0605 (0.0674)  time: 0.6832  data: 0.2888  max mem: 5528\n",
      "Training Epoch: [61]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1438 (0.1424)  loss_objectness: 0.0775 (0.0747)  loss_rpn_box_reg: 0.0633 (0.0677)  time: 0.6629  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [61]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1339 (0.1421)  loss_objectness: 0.0670 (0.0742)  loss_rpn_box_reg: 0.0653 (0.0678)  time: 0.6595  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [61]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1478 (0.1426)  loss_objectness: 0.0652 (0.0740)  loss_rpn_box_reg: 0.0771 (0.0686)  time: 0.6758  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [61]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1509 (0.1429)  loss_objectness: 0.0687 (0.0738)  loss_rpn_box_reg: 0.0792 (0.0691)  time: 0.6882  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [61]  [200/250]  eta: 0:00:33  lr: 0.000300  loss: 0.1359 (0.1428)  loss_objectness: 0.0683 (0.0736)  loss_rpn_box_reg: 0.0695 (0.0691)  time: 0.6795  data: 0.2876  max mem: 5528\n",
      "Training Epoch: [61]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1412 (0.1436)  loss_objectness: 0.0706 (0.0741)  loss_rpn_box_reg: 0.0678 (0.0694)  time: 0.6834  data: 0.2877  max mem: 5528\n",
      "Training Epoch: [61]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1525 (0.1441)  loss_objectness: 0.0713 (0.0743)  loss_rpn_box_reg: 0.0694 (0.0698)  time: 0.6764  data: 0.2877  max mem: 5528\n",
      "Training Epoch: [61]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1525 (0.1446)  loss_objectness: 0.0733 (0.0746)  loss_rpn_box_reg: 0.0694 (0.0700)  time: 0.6684  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [61]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1354 (0.1445)  loss_objectness: 0.0669 (0.0741)  loss_rpn_box_reg: 0.0685 (0.0703)  time: 0.6792  data: 0.2896  max mem: 5528\n",
      "Training Epoch: [61]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1354 (0.1444)  loss_objectness: 0.0661 (0.0741)  loss_rpn_box_reg: 0.0684 (0.0703)  time: 0.6880  data: 0.2874  max mem: 5528\n",
      "Training Epoch: [61] Total time: 0:02:49 (0.6794 s / it)\n",
      "Testing Epoch: [61]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1312 (0.1312)  loss_objectness: 0.0433 (0.0433)  loss_rpn_box_reg: 0.0880 (0.0880)  time: 0.6161  data: 0.2851  max mem: 5528\n",
      "Testing Epoch: [61]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1252 (0.1380)  loss_objectness: 0.0538 (0.0580)  loss_rpn_box_reg: 0.0699 (0.0800)  time: 0.6258  data: 0.3036  max mem: 5528\n",
      "Testing Epoch: [61] Total time: 0:00:39 (0.6304 s / it)\n",
      "Training Epoch: [62]  [  0/250]  eta: 0:02:59  lr: 0.000300  loss: 0.1177 (0.1177)  loss_objectness: 0.0510 (0.0510)  loss_rpn_box_reg: 0.0667 (0.0667)  time: 0.7182  data: 0.2901  max mem: 5528\n",
      "Training Epoch: [62]  [ 10/250]  eta: 0:02:48  lr: 0.000300  loss: 0.1408 (0.1406)  loss_objectness: 0.0848 (0.0768)  loss_rpn_box_reg: 0.0598 (0.0638)  time: 0.7012  data: 0.2919  max mem: 5528\n",
      "Training Epoch: [62]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1343 (0.1363)  loss_objectness: 0.0734 (0.0765)  loss_rpn_box_reg: 0.0503 (0.0598)  time: 0.6796  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [62]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1204 (0.1334)  loss_objectness: 0.0681 (0.0747)  loss_rpn_box_reg: 0.0482 (0.0587)  time: 0.6676  data: 0.2887  max mem: 5528\n",
      "Training Epoch: [62]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1337 (0.1344)  loss_objectness: 0.0721 (0.0748)  loss_rpn_box_reg: 0.0539 (0.0596)  time: 0.6713  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [62]  [ 50/250]  eta: 0:02:14  lr: 0.000300  loss: 0.1463 (0.1374)  loss_objectness: 0.0704 (0.0740)  loss_rpn_box_reg: 0.0584 (0.0633)  time: 0.6677  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [62]  [ 60/250]  eta: 0:02:08  lr: 0.000300  loss: 0.1494 (0.1383)  loss_objectness: 0.0668 (0.0732)  loss_rpn_box_reg: 0.0829 (0.0652)  time: 0.6823  data: 0.2881  max mem: 5528\n",
      "Training Epoch: [62]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1405 (0.1383)  loss_objectness: 0.0717 (0.0723)  loss_rpn_box_reg: 0.0708 (0.0659)  time: 0.7034  data: 0.2896  max mem: 5528\n",
      "Training Epoch: [62]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1328 (0.1389)  loss_objectness: 0.0618 (0.0712)  loss_rpn_box_reg: 0.0733 (0.0676)  time: 0.6843  data: 0.2886  max mem: 5528\n",
      "Training Epoch: [62]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1350 (0.1383)  loss_objectness: 0.0618 (0.0705)  loss_rpn_box_reg: 0.0749 (0.0678)  time: 0.6681  data: 0.2879  max mem: 5528\n",
      "Training Epoch: [62]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1377 (0.1386)  loss_objectness: 0.0717 (0.0715)  loss_rpn_box_reg: 0.0620 (0.0671)  time: 0.6840  data: 0.2895  max mem: 5528\n",
      "Training Epoch: [62]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1407 (0.1388)  loss_objectness: 0.0726 (0.0713)  loss_rpn_box_reg: 0.0613 (0.0675)  time: 0.6938  data: 0.2890  max mem: 5528\n",
      "Training Epoch: [62]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1347 (0.1385)  loss_objectness: 0.0678 (0.0716)  loss_rpn_box_reg: 0.0580 (0.0669)  time: 0.6851  data: 0.2893  max mem: 5528\n",
      "Training Epoch: [62]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1368 (0.1391)  loss_objectness: 0.0678 (0.0714)  loss_rpn_box_reg: 0.0615 (0.0676)  time: 0.6722  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [62]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1407 (0.1398)  loss_objectness: 0.0745 (0.0720)  loss_rpn_box_reg: 0.0742 (0.0678)  time: 0.6831  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [62]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1407 (0.1400)  loss_objectness: 0.0783 (0.0720)  loss_rpn_box_reg: 0.0619 (0.0680)  time: 0.6969  data: 0.2884  max mem: 5528\n",
      "Training Epoch: [62]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1379 (0.1403)  loss_objectness: 0.0780 (0.0725)  loss_rpn_box_reg: 0.0640 (0.0678)  time: 0.6870  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [62]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1471 (0.1407)  loss_objectness: 0.0728 (0.0724)  loss_rpn_box_reg: 0.0649 (0.0683)  time: 0.6800  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [62]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1451 (0.1413)  loss_objectness: 0.0739 (0.0728)  loss_rpn_box_reg: 0.0649 (0.0685)  time: 0.6889  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [62]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1484 (0.1419)  loss_objectness: 0.0745 (0.0729)  loss_rpn_box_reg: 0.0696 (0.0690)  time: 0.6813  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [62]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1472 (0.1421)  loss_objectness: 0.0718 (0.0730)  loss_rpn_box_reg: 0.0729 (0.0692)  time: 0.6752  data: 0.2867  max mem: 5528\n",
      "Training Epoch: [62]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1472 (0.1431)  loss_objectness: 0.0751 (0.0731)  loss_rpn_box_reg: 0.0729 (0.0700)  time: 0.6961  data: 0.2868  max mem: 5528\n",
      "Training Epoch: [62]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1468 (0.1430)  loss_objectness: 0.0729 (0.0732)  loss_rpn_box_reg: 0.0695 (0.0698)  time: 0.6956  data: 0.2901  max mem: 5528\n",
      "Training Epoch: [62]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1468 (0.1439)  loss_objectness: 0.0774 (0.0737)  loss_rpn_box_reg: 0.0715 (0.0702)  time: 0.6820  data: 0.2922  max mem: 5528\n",
      "Training Epoch: [62]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1352 (0.1433)  loss_objectness: 0.0701 (0.0734)  loss_rpn_box_reg: 0.0668 (0.0698)  time: 0.6820  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [62]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1318 (0.1439)  loss_objectness: 0.0673 (0.0738)  loss_rpn_box_reg: 0.0646 (0.0701)  time: 0.6849  data: 0.2878  max mem: 5528\n",
      "Training Epoch: [62] Total time: 0:02:50 (0.6836 s / it)\n",
      "Testing Epoch: [62]  [ 0/62]  eta: 0:00:43  lr: 0.000300  loss: 0.1301 (0.1301)  loss_objectness: 0.0410 (0.0410)  loss_rpn_box_reg: 0.0890 (0.0890)  time: 0.7032  data: 0.3731  max mem: 5528\n",
      "Testing Epoch: [62]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1318 (0.1385)  loss_objectness: 0.0570 (0.0588)  loss_rpn_box_reg: 0.0748 (0.0796)  time: 0.6303  data: 0.3091  max mem: 5528\n",
      "Testing Epoch: [62] Total time: 0:00:39 (0.6321 s / it)\n",
      "Training Epoch: [63]  [  0/250]  eta: 0:03:12  lr: 0.000300  loss: 0.0799 (0.0799)  loss_objectness: 0.0497 (0.0497)  loss_rpn_box_reg: 0.0302 (0.0302)  time: 0.7712  data: 0.2841  max mem: 5528\n",
      "Training Epoch: [63]  [ 10/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1509 (0.1509)  loss_objectness: 0.0830 (0.0769)  loss_rpn_box_reg: 0.0726 (0.0739)  time: 0.6893  data: 0.2919  max mem: 5528\n",
      "Training Epoch: [63]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1441 (0.1469)  loss_objectness: 0.0740 (0.0775)  loss_rpn_box_reg: 0.0678 (0.0693)  time: 0.6866  data: 0.2929  max mem: 5528\n",
      "Training Epoch: [63]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1362 (0.1406)  loss_objectness: 0.0734 (0.0764)  loss_rpn_box_reg: 0.0570 (0.0642)  time: 0.6977  data: 0.2923  max mem: 5528\n",
      "Training Epoch: [63]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1276 (0.1356)  loss_objectness: 0.0648 (0.0738)  loss_rpn_box_reg: 0.0517 (0.0618)  time: 0.6914  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [63]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1271 (0.1345)  loss_objectness: 0.0630 (0.0723)  loss_rpn_box_reg: 0.0523 (0.0622)  time: 0.6807  data: 0.2902  max mem: 5528\n",
      "Training Epoch: [63]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1304 (0.1379)  loss_objectness: 0.0676 (0.0741)  loss_rpn_box_reg: 0.0645 (0.0637)  time: 0.6712  data: 0.2923  max mem: 5528\n",
      "Training Epoch: [63]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1465 (0.1413)  loss_objectness: 0.0741 (0.0747)  loss_rpn_box_reg: 0.0722 (0.0666)  time: 0.6663  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [63]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1439 (0.1405)  loss_objectness: 0.0708 (0.0742)  loss_rpn_box_reg: 0.0708 (0.0663)  time: 0.6847  data: 0.2936  max mem: 5528\n",
      "Training Epoch: [63]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1288 (0.1398)  loss_objectness: 0.0653 (0.0734)  loss_rpn_box_reg: 0.0656 (0.0664)  time: 0.7014  data: 0.2940  max mem: 5528\n",
      "Training Epoch: [63]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1314 (0.1402)  loss_objectness: 0.0682 (0.0729)  loss_rpn_box_reg: 0.0694 (0.0673)  time: 0.7003  data: 0.2914  max mem: 5528\n",
      "Training Epoch: [63]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1357 (0.1402)  loss_objectness: 0.0703 (0.0728)  loss_rpn_box_reg: 0.0732 (0.0674)  time: 0.6888  data: 0.2929  max mem: 5528\n",
      "Training Epoch: [63]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1407 (0.1409)  loss_objectness: 0.0760 (0.0727)  loss_rpn_box_reg: 0.0737 (0.0682)  time: 0.6753  data: 0.2929  max mem: 5528\n",
      "Training Epoch: [63]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1453 (0.1410)  loss_objectness: 0.0740 (0.0729)  loss_rpn_box_reg: 0.0711 (0.0681)  time: 0.6700  data: 0.2888  max mem: 5528\n",
      "Training Epoch: [63]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1490 (0.1419)  loss_objectness: 0.0740 (0.0733)  loss_rpn_box_reg: 0.0658 (0.0686)  time: 0.6858  data: 0.2909  max mem: 5528\n",
      "Training Epoch: [63]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1484 (0.1422)  loss_objectness: 0.0678 (0.0733)  loss_rpn_box_reg: 0.0667 (0.0688)  time: 0.6925  data: 0.2946  max mem: 5528\n",
      "Training Epoch: [63]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1484 (0.1427)  loss_objectness: 0.0722 (0.0738)  loss_rpn_box_reg: 0.0667 (0.0688)  time: 0.6919  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [63]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1520 (0.1436)  loss_objectness: 0.0766 (0.0738)  loss_rpn_box_reg: 0.0784 (0.0698)  time: 0.6864  data: 0.2905  max mem: 5528\n",
      "Training Epoch: [63]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1509 (0.1434)  loss_objectness: 0.0766 (0.0741)  loss_rpn_box_reg: 0.0722 (0.0694)  time: 0.6763  data: 0.2895  max mem: 5528\n",
      "Training Epoch: [63]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1407 (0.1434)  loss_objectness: 0.0698 (0.0739)  loss_rpn_box_reg: 0.0577 (0.0694)  time: 0.6827  data: 0.2889  max mem: 5528\n",
      "Training Epoch: [63]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1412 (0.1432)  loss_objectness: 0.0666 (0.0736)  loss_rpn_box_reg: 0.0719 (0.0696)  time: 0.6869  data: 0.2866  max mem: 5528\n",
      "Training Epoch: [63]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1541 (0.1439)  loss_objectness: 0.0734 (0.0742)  loss_rpn_box_reg: 0.0745 (0.0697)  time: 0.6861  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [63]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1444 (0.1441)  loss_objectness: 0.0763 (0.0741)  loss_rpn_box_reg: 0.0771 (0.0700)  time: 0.6776  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [63]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1493 (0.1450)  loss_objectness: 0.0758 (0.0744)  loss_rpn_box_reg: 0.0830 (0.0706)  time: 0.6733  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [63]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1511 (0.1449)  loss_objectness: 0.0800 (0.0746)  loss_rpn_box_reg: 0.0711 (0.0703)  time: 0.6847  data: 0.2895  max mem: 5528\n",
      "Training Epoch: [63]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1442 (0.1450)  loss_objectness: 0.0747 (0.0747)  loss_rpn_box_reg: 0.0646 (0.0703)  time: 0.6881  data: 0.2874  max mem: 5528\n",
      "Training Epoch: [63] Total time: 0:02:51 (0.6848 s / it)\n",
      "Testing Epoch: [63]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1428 (0.1428)  loss_objectness: 0.0526 (0.0526)  loss_rpn_box_reg: 0.0902 (0.0902)  time: 0.6141  data: 0.2911  max mem: 5528\n",
      "Testing Epoch: [63]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1401 (0.1431)  loss_objectness: 0.0580 (0.0614)  loss_rpn_box_reg: 0.0781 (0.0817)  time: 0.6262  data: 0.3035  max mem: 5528\n",
      "Testing Epoch: [63] Total time: 0:00:39 (0.6355 s / it)\n",
      "Training Epoch: [64]  [  0/250]  eta: 0:02:33  lr: 0.000300  loss: 0.1684 (0.1684)  loss_objectness: 0.0969 (0.0969)  loss_rpn_box_reg: 0.0716 (0.0716)  time: 0.6151  data: 0.2951  max mem: 5528\n",
      "Training Epoch: [64]  [ 10/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1501 (0.1447)  loss_objectness: 0.0830 (0.0812)  loss_rpn_box_reg: 0.0663 (0.0635)  time: 0.6697  data: 0.2934  max mem: 5528\n",
      "Training Epoch: [64]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1333 (0.1366)  loss_objectness: 0.0749 (0.0775)  loss_rpn_box_reg: 0.0531 (0.0591)  time: 0.6935  data: 0.3021  max mem: 5528\n",
      "Training Epoch: [64]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1347 (0.1380)  loss_objectness: 0.0664 (0.0733)  loss_rpn_box_reg: 0.0572 (0.0647)  time: 0.7090  data: 0.3038  max mem: 5528\n",
      "Training Epoch: [64]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1372 (0.1377)  loss_objectness: 0.0649 (0.0721)  loss_rpn_box_reg: 0.0719 (0.0656)  time: 0.6828  data: 0.2938  max mem: 5528\n",
      "Training Epoch: [64]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1343 (0.1384)  loss_objectness: 0.0644 (0.0706)  loss_rpn_box_reg: 0.0672 (0.0678)  time: 0.6627  data: 0.2937  max mem: 5528\n",
      "Training Epoch: [64]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1358 (0.1403)  loss_objectness: 0.0678 (0.0713)  loss_rpn_box_reg: 0.0693 (0.0690)  time: 0.6790  data: 0.2978  max mem: 5528\n",
      "Training Epoch: [64]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1358 (0.1397)  loss_objectness: 0.0726 (0.0713)  loss_rpn_box_reg: 0.0721 (0.0684)  time: 0.6827  data: 0.2986  max mem: 5528\n",
      "Training Epoch: [64]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1356 (0.1405)  loss_objectness: 0.0704 (0.0709)  loss_rpn_box_reg: 0.0707 (0.0697)  time: 0.6860  data: 0.3041  max mem: 5528\n",
      "Training Epoch: [64]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1323 (0.1398)  loss_objectness: 0.0689 (0.0703)  loss_rpn_box_reg: 0.0636 (0.0695)  time: 0.6941  data: 0.3031  max mem: 5528\n",
      "Training Epoch: [64]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1394 (0.1401)  loss_objectness: 0.0689 (0.0701)  loss_rpn_box_reg: 0.0643 (0.0700)  time: 0.6878  data: 0.2957  max mem: 5528\n",
      "Training Epoch: [64]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1487 (0.1424)  loss_objectness: 0.0709 (0.0707)  loss_rpn_box_reg: 0.0706 (0.0717)  time: 0.6914  data: 0.2954  max mem: 5528\n",
      "Training Epoch: [64]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1508 (0.1432)  loss_objectness: 0.0733 (0.0715)  loss_rpn_box_reg: 0.0725 (0.0717)  time: 0.6990  data: 0.2966  max mem: 5528\n",
      "Training Epoch: [64]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1473 (0.1441)  loss_objectness: 0.0768 (0.0725)  loss_rpn_box_reg: 0.0681 (0.0716)  time: 0.6945  data: 0.2923  max mem: 5528\n",
      "Training Epoch: [64]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1353 (0.1435)  loss_objectness: 0.0731 (0.0724)  loss_rpn_box_reg: 0.0670 (0.0711)  time: 0.6860  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [64]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1217 (0.1422)  loss_objectness: 0.0675 (0.0721)  loss_rpn_box_reg: 0.0563 (0.0701)  time: 0.6858  data: 0.2913  max mem: 5528\n",
      "Training Epoch: [64]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1283 (0.1418)  loss_objectness: 0.0657 (0.0718)  loss_rpn_box_reg: 0.0642 (0.0700)  time: 0.6770  data: 0.2863  max mem: 5528\n",
      "Training Epoch: [64]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1311 (0.1414)  loss_objectness: 0.0690 (0.0717)  loss_rpn_box_reg: 0.0664 (0.0697)  time: 0.6806  data: 0.2862  max mem: 5528\n",
      "Training Epoch: [64]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1315 (0.1417)  loss_objectness: 0.0707 (0.0720)  loss_rpn_box_reg: 0.0634 (0.0697)  time: 0.6840  data: 0.2886  max mem: 5528\n",
      "Training Epoch: [64]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1569 (0.1426)  loss_objectness: 0.0707 (0.0723)  loss_rpn_box_reg: 0.0728 (0.0703)  time: 0.6748  data: 0.2896  max mem: 5528\n",
      "Training Epoch: [64]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1513 (0.1425)  loss_objectness: 0.0697 (0.0725)  loss_rpn_box_reg: 0.0709 (0.0700)  time: 0.6777  data: 0.2885  max mem: 5528\n",
      "Training Epoch: [64]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1406 (0.1424)  loss_objectness: 0.0674 (0.0726)  loss_rpn_box_reg: 0.0645 (0.0698)  time: 0.6745  data: 0.2857  max mem: 5528\n",
      "Training Epoch: [64]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1478 (0.1430)  loss_objectness: 0.0672 (0.0731)  loss_rpn_box_reg: 0.0648 (0.0699)  time: 0.6777  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [64]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1485 (0.1434)  loss_objectness: 0.0796 (0.0733)  loss_rpn_box_reg: 0.0710 (0.0702)  time: 0.6917  data: 0.2957  max mem: 5528\n",
      "Training Epoch: [64]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1464 (0.1433)  loss_objectness: 0.0774 (0.0734)  loss_rpn_box_reg: 0.0710 (0.0700)  time: 0.6895  data: 0.2949  max mem: 5528\n",
      "Training Epoch: [64]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1330 (0.1430)  loss_objectness: 0.0744 (0.0732)  loss_rpn_box_reg: 0.0597 (0.0698)  time: 0.6880  data: 0.2945  max mem: 5528\n",
      "Training Epoch: [64] Total time: 0:02:51 (0.6849 s / it)\n",
      "Testing Epoch: [64]  [ 0/62]  eta: 0:00:40  lr: 0.000300  loss: 0.1335 (0.1335)  loss_objectness: 0.0445 (0.0445)  loss_rpn_box_reg: 0.0890 (0.0890)  time: 0.6461  data: 0.3171  max mem: 5528\n",
      "Testing Epoch: [64]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1283 (0.1374)  loss_objectness: 0.0514 (0.0571)  loss_rpn_box_reg: 0.0710 (0.0802)  time: 0.6310  data: 0.3095  max mem: 5528\n",
      "Testing Epoch: [64] Total time: 0:00:39 (0.6322 s / it)\n",
      "Training Epoch: [65]  [  0/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1404 (0.1404)  loss_objectness: 0.0901 (0.0901)  loss_rpn_box_reg: 0.0504 (0.0504)  time: 0.6852  data: 0.2861  max mem: 5528\n",
      "Training Epoch: [65]  [ 10/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1503 (0.1574)  loss_objectness: 0.0740 (0.0782)  loss_rpn_box_reg: 0.0749 (0.0791)  time: 0.6792  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [65]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1489 (0.1488)  loss_objectness: 0.0740 (0.0750)  loss_rpn_box_reg: 0.0702 (0.0738)  time: 0.6824  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [65]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1457 (0.1473)  loss_objectness: 0.0726 (0.0741)  loss_rpn_box_reg: 0.0613 (0.0732)  time: 0.6860  data: 0.2878  max mem: 5528\n",
      "Training Epoch: [65]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1455 (0.1480)  loss_objectness: 0.0705 (0.0742)  loss_rpn_box_reg: 0.0616 (0.0738)  time: 0.6796  data: 0.2893  max mem: 5528\n",
      "Training Epoch: [65]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1356 (0.1444)  loss_objectness: 0.0705 (0.0735)  loss_rpn_box_reg: 0.0616 (0.0709)  time: 0.6844  data: 0.2892  max mem: 5528\n",
      "Training Epoch: [65]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1410 (0.1470)  loss_objectness: 0.0743 (0.0750)  loss_rpn_box_reg: 0.0650 (0.0720)  time: 0.6978  data: 0.2936  max mem: 5528\n",
      "Training Epoch: [65]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1450 (0.1456)  loss_objectness: 0.0716 (0.0743)  loss_rpn_box_reg: 0.0651 (0.0713)  time: 0.6915  data: 0.2937  max mem: 5528\n",
      "Training Epoch: [65]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1346 (0.1444)  loss_objectness: 0.0662 (0.0733)  loss_rpn_box_reg: 0.0620 (0.0711)  time: 0.6860  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [65]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1290 (0.1441)  loss_objectness: 0.0669 (0.0737)  loss_rpn_box_reg: 0.0655 (0.0704)  time: 0.6831  data: 0.2926  max mem: 5528\n",
      "Training Epoch: [65]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1370 (0.1434)  loss_objectness: 0.0697 (0.0733)  loss_rpn_box_reg: 0.0598 (0.0701)  time: 0.6775  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [65]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1476 (0.1449)  loss_objectness: 0.0704 (0.0736)  loss_rpn_box_reg: 0.0784 (0.0712)  time: 0.6745  data: 0.2932  max mem: 5528\n",
      "Training Epoch: [65]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1551 (0.1448)  loss_objectness: 0.0742 (0.0739)  loss_rpn_box_reg: 0.0784 (0.0710)  time: 0.6648  data: 0.2901  max mem: 5528\n",
      "Training Epoch: [65]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1508 (0.1460)  loss_objectness: 0.0773 (0.0746)  loss_rpn_box_reg: 0.0782 (0.0714)  time: 0.6701  data: 0.2884  max mem: 5528\n",
      "Training Epoch: [65]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1551 (0.1470)  loss_objectness: 0.0797 (0.0752)  loss_rpn_box_reg: 0.0788 (0.0718)  time: 0.6832  data: 0.2927  max mem: 5528\n",
      "Training Epoch: [65]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1521 (0.1474)  loss_objectness: 0.0736 (0.0751)  loss_rpn_box_reg: 0.0792 (0.0723)  time: 0.6829  data: 0.2935  max mem: 5528\n",
      "Training Epoch: [65]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1355 (0.1460)  loss_objectness: 0.0689 (0.0746)  loss_rpn_box_reg: 0.0595 (0.0714)  time: 0.6764  data: 0.2888  max mem: 5528\n",
      "Training Epoch: [65]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1318 (0.1458)  loss_objectness: 0.0710 (0.0745)  loss_rpn_box_reg: 0.0595 (0.0713)  time: 0.6835  data: 0.2880  max mem: 5528\n",
      "Training Epoch: [65]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1419 (0.1456)  loss_objectness: 0.0710 (0.0749)  loss_rpn_box_reg: 0.0615 (0.0707)  time: 0.6737  data: 0.2899  max mem: 5528\n",
      "Training Epoch: [65]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1488 (0.1456)  loss_objectness: 0.0757 (0.0750)  loss_rpn_box_reg: 0.0615 (0.0707)  time: 0.6801  data: 0.2923  max mem: 5528\n",
      "Training Epoch: [65]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1395 (0.1452)  loss_objectness: 0.0726 (0.0747)  loss_rpn_box_reg: 0.0665 (0.0705)  time: 0.6935  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [65]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1326 (0.1450)  loss_objectness: 0.0730 (0.0749)  loss_rpn_box_reg: 0.0544 (0.0701)  time: 0.6790  data: 0.2914  max mem: 5528\n",
      "Training Epoch: [65]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1383 (0.1451)  loss_objectness: 0.0782 (0.0749)  loss_rpn_box_reg: 0.0627 (0.0702)  time: 0.6909  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [65]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1453 (0.1450)  loss_objectness: 0.0748 (0.0749)  loss_rpn_box_reg: 0.0712 (0.0702)  time: 0.6903  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [65]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1354 (0.1447)  loss_objectness: 0.0669 (0.0744)  loss_rpn_box_reg: 0.0712 (0.0704)  time: 0.6889  data: 0.2890  max mem: 5528\n",
      "Training Epoch: [65]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1345 (0.1446)  loss_objectness: 0.0688 (0.0745)  loss_rpn_box_reg: 0.0657 (0.0701)  time: 0.6877  data: 0.2883  max mem: 5528\n",
      "Training Epoch: [65] Total time: 0:02:50 (0.6826 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:00:56  model_time: 0.5611 (0.5611)  evaluator_time: 0.0590 (0.0590)  time: 0.9142  data: 0.2791  max mem: 5528\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3791 (0.3829)  evaluator_time: 0.0690 (0.0747)  time: 0.7576  data: 0.2995  max mem: 5528\n",
      "Test: Total time: 0:00:47 (0.7659 s / it)\n",
      "Averaged stats: model_time: 0.3791 (0.3829)  evaluator_time: 0.0690 (0.0747)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.03s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.110\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.072\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.172\n",
      "Testing Epoch: [65]  [ 0/62]  eta: 0:00:43  lr: 0.000300  loss: 0.1348 (0.1348)  loss_objectness: 0.0448 (0.0448)  loss_rpn_box_reg: 0.0900 (0.0900)  time: 0.7042  data: 0.3821  max mem: 5528\n",
      "Testing Epoch: [65]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1335 (0.1427)  loss_objectness: 0.0554 (0.0616)  loss_rpn_box_reg: 0.0746 (0.0811)  time: 0.6263  data: 0.3076  max mem: 5528\n",
      "Testing Epoch: [65] Total time: 0:00:39 (0.6303 s / it)\n",
      "Training Epoch: [66]  [  0/250]  eta: 0:02:58  lr: 0.000300  loss: 0.1221 (0.1221)  loss_objectness: 0.0637 (0.0637)  loss_rpn_box_reg: 0.0584 (0.0584)  time: 0.7132  data: 0.3101  max mem: 5528\n",
      "Training Epoch: [66]  [ 10/250]  eta: 0:02:48  lr: 0.000300  loss: 0.1281 (0.1339)  loss_objectness: 0.0633 (0.0663)  loss_rpn_box_reg: 0.0687 (0.0675)  time: 0.7002  data: 0.2913  max mem: 5528\n",
      "Training Epoch: [66]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1328 (0.1388)  loss_objectness: 0.0637 (0.0702)  loss_rpn_box_reg: 0.0651 (0.0686)  time: 0.6917  data: 0.2928  max mem: 5528\n",
      "Training Epoch: [66]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1272 (0.1351)  loss_objectness: 0.0637 (0.0662)  loss_rpn_box_reg: 0.0633 (0.0689)  time: 0.6799  data: 0.2946  max mem: 5528\n",
      "Training Epoch: [66]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1264 (0.1353)  loss_objectness: 0.0646 (0.0684)  loss_rpn_box_reg: 0.0607 (0.0668)  time: 0.6714  data: 0.2938  max mem: 5528\n",
      "Training Epoch: [66]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1337 (0.1363)  loss_objectness: 0.0671 (0.0680)  loss_rpn_box_reg: 0.0616 (0.0682)  time: 0.6826  data: 0.2936  max mem: 5528\n",
      "Training Epoch: [66]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1337 (0.1364)  loss_objectness: 0.0690 (0.0688)  loss_rpn_box_reg: 0.0672 (0.0676)  time: 0.6863  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [66]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1339 (0.1366)  loss_objectness: 0.0692 (0.0690)  loss_rpn_box_reg: 0.0664 (0.0676)  time: 0.6713  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [66]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1406 (0.1380)  loss_objectness: 0.0715 (0.0693)  loss_rpn_box_reg: 0.0664 (0.0687)  time: 0.6892  data: 0.2896  max mem: 5528\n",
      "Training Epoch: [66]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1460 (0.1385)  loss_objectness: 0.0715 (0.0692)  loss_rpn_box_reg: 0.0685 (0.0693)  time: 0.7030  data: 0.2895  max mem: 5528\n",
      "Training Epoch: [66]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1471 (0.1388)  loss_objectness: 0.0704 (0.0697)  loss_rpn_box_reg: 0.0685 (0.0691)  time: 0.6836  data: 0.2887  max mem: 5528\n",
      "Training Epoch: [66]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1440 (0.1391)  loss_objectness: 0.0724 (0.0701)  loss_rpn_box_reg: 0.0622 (0.0691)  time: 0.6785  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [66]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1501 (0.1405)  loss_objectness: 0.0763 (0.0714)  loss_rpn_box_reg: 0.0629 (0.0691)  time: 0.6822  data: 0.2927  max mem: 5528\n",
      "Training Epoch: [66]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1509 (0.1405)  loss_objectness: 0.0730 (0.0717)  loss_rpn_box_reg: 0.0642 (0.0688)  time: 0.6817  data: 0.2880  max mem: 5528\n",
      "Training Epoch: [66]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1415 (0.1407)  loss_objectness: 0.0742 (0.0720)  loss_rpn_box_reg: 0.0619 (0.0687)  time: 0.6855  data: 0.2913  max mem: 5528\n",
      "Training Epoch: [66]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1454 (0.1411)  loss_objectness: 0.0782 (0.0724)  loss_rpn_box_reg: 0.0672 (0.0688)  time: 0.6897  data: 0.2986  max mem: 5528\n",
      "Training Epoch: [66]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1586 (0.1420)  loss_objectness: 0.0779 (0.0726)  loss_rpn_box_reg: 0.0708 (0.0694)  time: 0.6777  data: 0.2955  max mem: 5528\n",
      "Training Epoch: [66]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1396 (0.1416)  loss_objectness: 0.0698 (0.0723)  loss_rpn_box_reg: 0.0676 (0.0693)  time: 0.6808  data: 0.2922  max mem: 5528\n",
      "Training Epoch: [66]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1347 (0.1422)  loss_objectness: 0.0688 (0.0724)  loss_rpn_box_reg: 0.0649 (0.0698)  time: 0.7015  data: 0.2887  max mem: 5528\n",
      "Training Epoch: [66]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1457 (0.1432)  loss_objectness: 0.0700 (0.0727)  loss_rpn_box_reg: 0.0705 (0.0704)  time: 0.6912  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [66]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1318 (0.1420)  loss_objectness: 0.0689 (0.0725)  loss_rpn_box_reg: 0.0590 (0.0696)  time: 0.6811  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [66]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1318 (0.1426)  loss_objectness: 0.0688 (0.0724)  loss_rpn_box_reg: 0.0595 (0.0702)  time: 0.6803  data: 0.2918  max mem: 5528\n",
      "Training Epoch: [66]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1533 (0.1423)  loss_objectness: 0.0722 (0.0723)  loss_rpn_box_reg: 0.0690 (0.0700)  time: 0.6773  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [66]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1425 (0.1422)  loss_objectness: 0.0722 (0.0725)  loss_rpn_box_reg: 0.0568 (0.0696)  time: 0.6775  data: 0.2875  max mem: 5528\n",
      "Training Epoch: [66]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1353 (0.1419)  loss_objectness: 0.0718 (0.0723)  loss_rpn_box_reg: 0.0634 (0.0695)  time: 0.6744  data: 0.2869  max mem: 5528\n",
      "Training Epoch: [66]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1280 (0.1417)  loss_objectness: 0.0740 (0.0725)  loss_rpn_box_reg: 0.0579 (0.0692)  time: 0.6599  data: 0.2863  max mem: 5528\n",
      "Training Epoch: [66] Total time: 0:02:50 (0.6824 s / it)\n",
      "Testing Epoch: [66]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1421 (0.1421)  loss_objectness: 0.0540 (0.0540)  loss_rpn_box_reg: 0.0880 (0.0880)  time: 0.6341  data: 0.2921  max mem: 5528\n",
      "Testing Epoch: [66]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1303 (0.1400)  loss_objectness: 0.0542 (0.0596)  loss_rpn_box_reg: 0.0752 (0.0804)  time: 0.6246  data: 0.3051  max mem: 5528\n",
      "Testing Epoch: [66] Total time: 0:00:39 (0.6304 s / it)\n",
      "Training Epoch: [67]  [  0/250]  eta: 0:02:55  lr: 0.000300  loss: 0.1424 (0.1424)  loss_objectness: 0.0472 (0.0472)  loss_rpn_box_reg: 0.0952 (0.0952)  time: 0.7022  data: 0.2801  max mem: 5528\n",
      "Training Epoch: [67]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1358 (0.1326)  loss_objectness: 0.0659 (0.0640)  loss_rpn_box_reg: 0.0636 (0.0686)  time: 0.6972  data: 0.2902  max mem: 5528\n",
      "Training Epoch: [67]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1358 (0.1394)  loss_objectness: 0.0719 (0.0684)  loss_rpn_box_reg: 0.0632 (0.0709)  time: 0.6931  data: 0.2893  max mem: 5528\n",
      "Training Epoch: [67]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1453 (0.1408)  loss_objectness: 0.0725 (0.0676)  loss_rpn_box_reg: 0.0750 (0.0733)  time: 0.6878  data: 0.2863  max mem: 5528\n",
      "Training Epoch: [67]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1453 (0.1425)  loss_objectness: 0.0691 (0.0689)  loss_rpn_box_reg: 0.0830 (0.0737)  time: 0.6934  data: 0.2891  max mem: 5528\n",
      "Training Epoch: [67]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1388 (0.1401)  loss_objectness: 0.0691 (0.0692)  loss_rpn_box_reg: 0.0615 (0.0709)  time: 0.6998  data: 0.2927  max mem: 5528\n",
      "Training Epoch: [67]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1388 (0.1409)  loss_objectness: 0.0704 (0.0711)  loss_rpn_box_reg: 0.0609 (0.0698)  time: 0.6941  data: 0.2932  max mem: 5528\n",
      "Training Epoch: [67]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1418 (0.1405)  loss_objectness: 0.0731 (0.0716)  loss_rpn_box_reg: 0.0609 (0.0689)  time: 0.6861  data: 0.2952  max mem: 5528\n",
      "Training Epoch: [67]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1262 (0.1393)  loss_objectness: 0.0706 (0.0716)  loss_rpn_box_reg: 0.0538 (0.0676)  time: 0.6933  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [67]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1463 (0.1412)  loss_objectness: 0.0775 (0.0732)  loss_rpn_box_reg: 0.0507 (0.0680)  time: 0.6913  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [67]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1514 (0.1415)  loss_objectness: 0.0726 (0.0724)  loss_rpn_box_reg: 0.0744 (0.0690)  time: 0.6508  data: 0.2868  max mem: 5528\n",
      "Training Epoch: [67]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1380 (0.1409)  loss_objectness: 0.0640 (0.0721)  loss_rpn_box_reg: 0.0635 (0.0689)  time: 0.6506  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [67]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1479 (0.1433)  loss_objectness: 0.0680 (0.0728)  loss_rpn_box_reg: 0.0709 (0.0705)  time: 0.6782  data: 0.2918  max mem: 5528\n",
      "Training Epoch: [67]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1645 (0.1448)  loss_objectness: 0.0776 (0.0735)  loss_rpn_box_reg: 0.0799 (0.0714)  time: 0.6753  data: 0.2890  max mem: 5528\n",
      "Training Epoch: [67]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1493 (0.1441)  loss_objectness: 0.0754 (0.0731)  loss_rpn_box_reg: 0.0699 (0.0710)  time: 0.6759  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [67]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1493 (0.1449)  loss_objectness: 0.0687 (0.0739)  loss_rpn_box_reg: 0.0686 (0.0710)  time: 0.6824  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [67]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1458 (0.1446)  loss_objectness: 0.0741 (0.0735)  loss_rpn_box_reg: 0.0685 (0.0711)  time: 0.6841  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [67]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1332 (0.1441)  loss_objectness: 0.0649 (0.0731)  loss_rpn_box_reg: 0.0665 (0.0710)  time: 0.6885  data: 0.2865  max mem: 5528\n",
      "Training Epoch: [67]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1365 (0.1437)  loss_objectness: 0.0708 (0.0732)  loss_rpn_box_reg: 0.0610 (0.0705)  time: 0.6923  data: 0.2863  max mem: 5528\n",
      "Training Epoch: [67]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1365 (0.1434)  loss_objectness: 0.0743 (0.0732)  loss_rpn_box_reg: 0.0610 (0.0703)  time: 0.6874  data: 0.2864  max mem: 5528\n",
      "Training Epoch: [67]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1325 (0.1436)  loss_objectness: 0.0707 (0.0734)  loss_rpn_box_reg: 0.0611 (0.0701)  time: 0.6848  data: 0.2886  max mem: 5528\n",
      "Training Epoch: [67]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1293 (0.1430)  loss_objectness: 0.0657 (0.0730)  loss_rpn_box_reg: 0.0613 (0.0700)  time: 0.6817  data: 0.2892  max mem: 5528\n",
      "Training Epoch: [67]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1284 (0.1426)  loss_objectness: 0.0641 (0.0730)  loss_rpn_box_reg: 0.0612 (0.0697)  time: 0.6841  data: 0.2890  max mem: 5528\n",
      "Training Epoch: [67]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1437 (0.1429)  loss_objectness: 0.0667 (0.0732)  loss_rpn_box_reg: 0.0616 (0.0698)  time: 0.6867  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [67]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1494 (0.1434)  loss_objectness: 0.0670 (0.0733)  loss_rpn_box_reg: 0.0721 (0.0701)  time: 0.6800  data: 0.2897  max mem: 5528\n",
      "Training Epoch: [67]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1399 (0.1431)  loss_objectness: 0.0643 (0.0730)  loss_rpn_box_reg: 0.0666 (0.0701)  time: 0.6768  data: 0.2873  max mem: 5528\n",
      "Training Epoch: [67] Total time: 0:02:50 (0.6835 s / it)\n",
      "Testing Epoch: [67]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1358 (0.1358)  loss_objectness: 0.0477 (0.0477)  loss_rpn_box_reg: 0.0881 (0.0881)  time: 0.7252  data: 0.3931  max mem: 5528\n",
      "Testing Epoch: [67]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1252 (0.1408)  loss_objectness: 0.0551 (0.0583)  loss_rpn_box_reg: 0.0731 (0.0825)  time: 0.6324  data: 0.3085  max mem: 5528\n",
      "Testing Epoch: [67] Total time: 0:00:39 (0.6336 s / it)\n",
      "Training Epoch: [68]  [  0/250]  eta: 0:03:03  lr: 0.000300  loss: 0.1359 (0.1359)  loss_objectness: 0.0661 (0.0661)  loss_rpn_box_reg: 0.0698 (0.0698)  time: 0.7332  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [68]  [ 10/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1359 (0.1405)  loss_objectness: 0.0661 (0.0634)  loss_rpn_box_reg: 0.0673 (0.0771)  time: 0.6892  data: 0.2961  max mem: 5528\n",
      "Training Epoch: [68]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1415 (0.1406)  loss_objectness: 0.0642 (0.0653)  loss_rpn_box_reg: 0.0673 (0.0754)  time: 0.6792  data: 0.2939  max mem: 5528\n",
      "Training Epoch: [68]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1397 (0.1396)  loss_objectness: 0.0680 (0.0660)  loss_rpn_box_reg: 0.0681 (0.0736)  time: 0.6776  data: 0.2909  max mem: 5528\n",
      "Training Epoch: [68]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1281 (0.1382)  loss_objectness: 0.0704 (0.0672)  loss_rpn_box_reg: 0.0626 (0.0710)  time: 0.6798  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [68]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1356 (0.1396)  loss_objectness: 0.0704 (0.0687)  loss_rpn_box_reg: 0.0589 (0.0709)  time: 0.6803  data: 0.2949  max mem: 5528\n",
      "Training Epoch: [68]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1356 (0.1384)  loss_objectness: 0.0709 (0.0687)  loss_rpn_box_reg: 0.0636 (0.0696)  time: 0.6770  data: 0.2948  max mem: 5528\n",
      "Training Epoch: [68]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1321 (0.1385)  loss_objectness: 0.0723 (0.0700)  loss_rpn_box_reg: 0.0587 (0.0685)  time: 0.6778  data: 0.2937  max mem: 5528\n",
      "Training Epoch: [68]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1481 (0.1401)  loss_objectness: 0.0772 (0.0709)  loss_rpn_box_reg: 0.0587 (0.0692)  time: 0.6829  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [68]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1438 (0.1401)  loss_objectness: 0.0821 (0.0718)  loss_rpn_box_reg: 0.0617 (0.0683)  time: 0.6963  data: 0.2938  max mem: 5528\n",
      "Training Epoch: [68]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1441 (0.1415)  loss_objectness: 0.0762 (0.0723)  loss_rpn_box_reg: 0.0637 (0.0692)  time: 0.6894  data: 0.2952  max mem: 5528\n",
      "Training Epoch: [68]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1419 (0.1412)  loss_objectness: 0.0689 (0.0723)  loss_rpn_box_reg: 0.0672 (0.0689)  time: 0.6722  data: 0.2897  max mem: 5528\n",
      "Training Epoch: [68]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1304 (0.1404)  loss_objectness: 0.0689 (0.0717)  loss_rpn_box_reg: 0.0672 (0.0687)  time: 0.6810  data: 0.2871  max mem: 5528\n",
      "Training Epoch: [68]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1478 (0.1411)  loss_objectness: 0.0691 (0.0717)  loss_rpn_box_reg: 0.0754 (0.0695)  time: 0.6871  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [68]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1470 (0.1410)  loss_objectness: 0.0686 (0.0715)  loss_rpn_box_reg: 0.0671 (0.0694)  time: 0.6987  data: 0.2947  max mem: 5528\n",
      "Training Epoch: [68]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1299 (0.1410)  loss_objectness: 0.0662 (0.0713)  loss_rpn_box_reg: 0.0658 (0.0696)  time: 0.7014  data: 0.2936  max mem: 5528\n",
      "Training Epoch: [68]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1365 (0.1409)  loss_objectness: 0.0688 (0.0716)  loss_rpn_box_reg: 0.0670 (0.0693)  time: 0.6929  data: 0.2935  max mem: 5528\n",
      "Training Epoch: [68]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1430 (0.1419)  loss_objectness: 0.0708 (0.0723)  loss_rpn_box_reg: 0.0741 (0.0696)  time: 0.6867  data: 0.2914  max mem: 5528\n",
      "Training Epoch: [68]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1298 (0.1407)  loss_objectness: 0.0639 (0.0716)  loss_rpn_box_reg: 0.0723 (0.0691)  time: 0.6829  data: 0.2864  max mem: 5528\n",
      "Training Epoch: [68]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1282 (0.1406)  loss_objectness: 0.0596 (0.0713)  loss_rpn_box_reg: 0.0687 (0.0692)  time: 0.6767  data: 0.2852  max mem: 5528\n",
      "Training Epoch: [68]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1340 (0.1403)  loss_objectness: 0.0727 (0.0719)  loss_rpn_box_reg: 0.0645 (0.0684)  time: 0.6748  data: 0.2896  max mem: 5528\n",
      "Training Epoch: [68]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1340 (0.1406)  loss_objectness: 0.0759 (0.0721)  loss_rpn_box_reg: 0.0560 (0.0685)  time: 0.6782  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [68]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1359 (0.1408)  loss_objectness: 0.0636 (0.0720)  loss_rpn_box_reg: 0.0645 (0.0688)  time: 0.6944  data: 0.2950  max mem: 5528\n",
      "Training Epoch: [68]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1379 (0.1408)  loss_objectness: 0.0680 (0.0719)  loss_rpn_box_reg: 0.0730 (0.0689)  time: 0.6957  data: 0.2953  max mem: 5528\n",
      "Training Epoch: [68]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1436 (0.1412)  loss_objectness: 0.0696 (0.0720)  loss_rpn_box_reg: 0.0730 (0.0692)  time: 0.6778  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [68]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1470 (0.1422)  loss_objectness: 0.0738 (0.0724)  loss_rpn_box_reg: 0.0744 (0.0698)  time: 0.6819  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [68] Total time: 0:02:51 (0.6848 s / it)\n",
      "Testing Epoch: [68]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1306 (0.1306)  loss_objectness: 0.0442 (0.0442)  loss_rpn_box_reg: 0.0864 (0.0864)  time: 0.6181  data: 0.2931  max mem: 5528\n",
      "Testing Epoch: [68]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1381 (0.1402)  loss_objectness: 0.0557 (0.0607)  loss_rpn_box_reg: 0.0709 (0.0795)  time: 0.6331  data: 0.3121  max mem: 5528\n",
      "Testing Epoch: [68] Total time: 0:00:39 (0.6348 s / it)\n",
      "Training Epoch: [69]  [  0/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1071 (0.1071)  loss_objectness: 0.0531 (0.0531)  loss_rpn_box_reg: 0.0540 (0.0540)  time: 0.6842  data: 0.2841  max mem: 5528\n",
      "Training Epoch: [69]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1364 (0.1511)  loss_objectness: 0.0796 (0.0787)  loss_rpn_box_reg: 0.0586 (0.0724)  time: 0.6716  data: 0.2914  max mem: 5528\n",
      "Training Epoch: [69]  [ 20/250]  eta: 0:02:33  lr: 0.000300  loss: 0.1431 (0.1506)  loss_objectness: 0.0738 (0.0773)  loss_rpn_box_reg: 0.0665 (0.0733)  time: 0.6668  data: 0.2932  max mem: 5528\n",
      "Training Epoch: [69]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1494 (0.1500)  loss_objectness: 0.0770 (0.0788)  loss_rpn_box_reg: 0.0770 (0.0713)  time: 0.6837  data: 0.3008  max mem: 5528\n",
      "Training Epoch: [69]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1496 (0.1502)  loss_objectness: 0.0770 (0.0767)  loss_rpn_box_reg: 0.0770 (0.0735)  time: 0.7106  data: 0.3043  max mem: 5528\n",
      "Training Epoch: [69]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1454 (0.1473)  loss_objectness: 0.0658 (0.0743)  loss_rpn_box_reg: 0.0760 (0.0730)  time: 0.7063  data: 0.2996  max mem: 5528\n",
      "Training Epoch: [69]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1335 (0.1452)  loss_objectness: 0.0662 (0.0735)  loss_rpn_box_reg: 0.0711 (0.0716)  time: 0.6840  data: 0.2945  max mem: 5528\n",
      "Training Epoch: [69]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1396 (0.1443)  loss_objectness: 0.0693 (0.0738)  loss_rpn_box_reg: 0.0581 (0.0705)  time: 0.6921  data: 0.2954  max mem: 5528\n",
      "Training Epoch: [69]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1396 (0.1433)  loss_objectness: 0.0707 (0.0735)  loss_rpn_box_reg: 0.0619 (0.0699)  time: 0.6984  data: 0.3003  max mem: 5528\n",
      "Training Epoch: [69]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1474 (0.1446)  loss_objectness: 0.0695 (0.0739)  loss_rpn_box_reg: 0.0724 (0.0708)  time: 0.6792  data: 0.3021  max mem: 5528\n",
      "Training Epoch: [69]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1528 (0.1448)  loss_objectness: 0.0719 (0.0740)  loss_rpn_box_reg: 0.0775 (0.0708)  time: 0.6990  data: 0.3103  max mem: 5528\n",
      "Training Epoch: [69]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1500 (0.1455)  loss_objectness: 0.0720 (0.0738)  loss_rpn_box_reg: 0.0743 (0.0717)  time: 0.7157  data: 0.3051  max mem: 5528\n",
      "Training Epoch: [69]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1385 (0.1447)  loss_objectness: 0.0772 (0.0739)  loss_rpn_box_reg: 0.0675 (0.0708)  time: 0.6959  data: 0.2953  max mem: 5528\n",
      "Training Epoch: [69]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1371 (0.1452)  loss_objectness: 0.0756 (0.0741)  loss_rpn_box_reg: 0.0577 (0.0711)  time: 0.6912  data: 0.2994  max mem: 5528\n",
      "Training Epoch: [69]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1463 (0.1457)  loss_objectness: 0.0735 (0.0740)  loss_rpn_box_reg: 0.0723 (0.0718)  time: 0.6955  data: 0.3029  max mem: 5528\n",
      "Training Epoch: [69]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1279 (0.1437)  loss_objectness: 0.0692 (0.0735)  loss_rpn_box_reg: 0.0641 (0.0703)  time: 0.6856  data: 0.3030  max mem: 5528\n",
      "Training Epoch: [69]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1309 (0.1446)  loss_objectness: 0.0665 (0.0736)  loss_rpn_box_reg: 0.0665 (0.0710)  time: 0.6771  data: 0.3043  max mem: 5528\n",
      "Training Epoch: [69]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1438 (0.1452)  loss_objectness: 0.0770 (0.0744)  loss_rpn_box_reg: 0.0689 (0.0708)  time: 0.6902  data: 0.3025  max mem: 5528\n",
      "Training Epoch: [69]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1436 (0.1450)  loss_objectness: 0.0782 (0.0748)  loss_rpn_box_reg: 0.0590 (0.0702)  time: 0.7094  data: 0.2985  max mem: 5528\n",
      "Training Epoch: [69]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1328 (0.1444)  loss_objectness: 0.0683 (0.0742)  loss_rpn_box_reg: 0.0601 (0.0701)  time: 0.6910  data: 0.2968  max mem: 5528\n",
      "Training Epoch: [69]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1247 (0.1446)  loss_objectness: 0.0623 (0.0741)  loss_rpn_box_reg: 0.0637 (0.0705)  time: 0.6732  data: 0.2945  max mem: 5528\n",
      "Training Epoch: [69]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1329 (0.1444)  loss_objectness: 0.0686 (0.0738)  loss_rpn_box_reg: 0.0598 (0.0706)  time: 0.6917  data: 0.2973  max mem: 5528\n",
      "Training Epoch: [69]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1329 (0.1441)  loss_objectness: 0.0686 (0.0741)  loss_rpn_box_reg: 0.0588 (0.0701)  time: 0.6918  data: 0.2999  max mem: 5528\n",
      "Training Epoch: [69]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1437 (0.1446)  loss_objectness: 0.0748 (0.0742)  loss_rpn_box_reg: 0.0654 (0.0704)  time: 0.6809  data: 0.3023  max mem: 5528\n",
      "Training Epoch: [69]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1437 (0.1442)  loss_objectness: 0.0718 (0.0738)  loss_rpn_box_reg: 0.0727 (0.0703)  time: 0.7012  data: 0.3041  max mem: 5528\n",
      "Training Epoch: [69]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1395 (0.1440)  loss_objectness: 0.0702 (0.0737)  loss_rpn_box_reg: 0.0705 (0.0703)  time: 0.7308  data: 0.3204  max mem: 5528\n",
      "Training Epoch: [69] Total time: 0:02:53 (0.6937 s / it)\n",
      "Testing Epoch: [69]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1365 (0.1365)  loss_objectness: 0.0515 (0.0515)  loss_rpn_box_reg: 0.0850 (0.0850)  time: 0.6451  data: 0.3191  max mem: 5528\n",
      "Testing Epoch: [69]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1354 (0.1386)  loss_objectness: 0.0538 (0.0599)  loss_rpn_box_reg: 0.0725 (0.0788)  time: 0.6451  data: 0.3206  max mem: 5528\n",
      "Testing Epoch: [69] Total time: 0:00:40 (0.6501 s / it)\n",
      "Training Epoch: [70]  [  0/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1278 (0.1278)  loss_objectness: 0.0561 (0.0561)  loss_rpn_box_reg: 0.0717 (0.0717)  time: 0.6561  data: 0.3001  max mem: 5528\n",
      "Training Epoch: [70]  [ 10/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1357 (0.1405)  loss_objectness: 0.0670 (0.0683)  loss_rpn_box_reg: 0.0717 (0.0722)  time: 0.7144  data: 0.3053  max mem: 5528\n",
      "Training Epoch: [70]  [ 20/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1389 (0.1411)  loss_objectness: 0.0686 (0.0701)  loss_rpn_box_reg: 0.0671 (0.0710)  time: 0.7082  data: 0.3054  max mem: 5528\n",
      "Training Epoch: [70]  [ 30/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1453 (0.1433)  loss_objectness: 0.0727 (0.0705)  loss_rpn_box_reg: 0.0687 (0.0728)  time: 0.6956  data: 0.3056  max mem: 5528\n",
      "Training Epoch: [70]  [ 40/250]  eta: 0:02:27  lr: 0.000300  loss: 0.1467 (0.1412)  loss_objectness: 0.0741 (0.0712)  loss_rpn_box_reg: 0.0643 (0.0700)  time: 0.6975  data: 0.3063  max mem: 5528\n",
      "Training Epoch: [70]  [ 50/250]  eta: 0:02:19  lr: 0.000300  loss: 0.1395 (0.1422)  loss_objectness: 0.0722 (0.0717)  loss_rpn_box_reg: 0.0625 (0.0705)  time: 0.6907  data: 0.3050  max mem: 5528\n",
      "Training Epoch: [70]  [ 60/250]  eta: 0:02:12  lr: 0.000300  loss: 0.1462 (0.1411)  loss_objectness: 0.0701 (0.0714)  loss_rpn_box_reg: 0.0682 (0.0696)  time: 0.6831  data: 0.3016  max mem: 5528\n",
      "Training Epoch: [70]  [ 70/250]  eta: 0:02:05  lr: 0.000300  loss: 0.1201 (0.1383)  loss_objectness: 0.0648 (0.0711)  loss_rpn_box_reg: 0.0536 (0.0672)  time: 0.6877  data: 0.2980  max mem: 5528\n",
      "Training Epoch: [70]  [ 80/250]  eta: 0:01:58  lr: 0.000300  loss: 0.1274 (0.1393)  loss_objectness: 0.0676 (0.0712)  loss_rpn_box_reg: 0.0574 (0.0681)  time: 0.6990  data: 0.2970  max mem: 5528\n",
      "Training Epoch: [70]  [ 90/250]  eta: 0:01:51  lr: 0.000300  loss: 0.1377 (0.1392)  loss_objectness: 0.0697 (0.0714)  loss_rpn_box_reg: 0.0641 (0.0678)  time: 0.7104  data: 0.3012  max mem: 5528\n",
      "Training Epoch: [70]  [100/250]  eta: 0:01:44  lr: 0.000300  loss: 0.1321 (0.1390)  loss_objectness: 0.0683 (0.0713)  loss_rpn_box_reg: 0.0590 (0.0676)  time: 0.7034  data: 0.3025  max mem: 5528\n",
      "Training Epoch: [70]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1328 (0.1387)  loss_objectness: 0.0711 (0.0713)  loss_rpn_box_reg: 0.0641 (0.0674)  time: 0.6893  data: 0.3011  max mem: 5528\n",
      "Training Epoch: [70]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1354 (0.1388)  loss_objectness: 0.0711 (0.0709)  loss_rpn_box_reg: 0.0669 (0.0680)  time: 0.6875  data: 0.2978  max mem: 5528\n",
      "Training Epoch: [70]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1401 (0.1390)  loss_objectness: 0.0597 (0.0713)  loss_rpn_box_reg: 0.0668 (0.0677)  time: 0.6938  data: 0.2973  max mem: 5528\n",
      "Training Epoch: [70]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1395 (0.1393)  loss_objectness: 0.0631 (0.0714)  loss_rpn_box_reg: 0.0635 (0.0679)  time: 0.6940  data: 0.3027  max mem: 5528\n",
      "Training Epoch: [70]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1408 (0.1403)  loss_objectness: 0.0689 (0.0719)  loss_rpn_box_reg: 0.0719 (0.0684)  time: 0.6849  data: 0.2987  max mem: 5528\n",
      "Training Epoch: [70]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1484 (0.1406)  loss_objectness: 0.0695 (0.0718)  loss_rpn_box_reg: 0.0719 (0.0687)  time: 0.6823  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [70]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1460 (0.1410)  loss_objectness: 0.0698 (0.0723)  loss_rpn_box_reg: 0.0631 (0.0687)  time: 0.6815  data: 0.2922  max mem: 5528\n",
      "Training Epoch: [70]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1460 (0.1415)  loss_objectness: 0.0717 (0.0725)  loss_rpn_box_reg: 0.0640 (0.0690)  time: 0.6914  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [70]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1522 (0.1425)  loss_objectness: 0.0721 (0.0729)  loss_rpn_box_reg: 0.0767 (0.0696)  time: 0.6962  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [70]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1515 (0.1424)  loss_objectness: 0.0659 (0.0726)  loss_rpn_box_reg: 0.0767 (0.0698)  time: 0.6907  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [70]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1277 (0.1420)  loss_objectness: 0.0648 (0.0725)  loss_rpn_box_reg: 0.0623 (0.0695)  time: 0.6889  data: 0.2905  max mem: 5528\n",
      "Training Epoch: [70]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1320 (0.1419)  loss_objectness: 0.0734 (0.0730)  loss_rpn_box_reg: 0.0512 (0.0689)  time: 0.6726  data: 0.2897  max mem: 5528\n",
      "Training Epoch: [70]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1447 (0.1423)  loss_objectness: 0.0734 (0.0728)  loss_rpn_box_reg: 0.0633 (0.0694)  time: 0.6830  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [70]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1447 (0.1425)  loss_objectness: 0.0703 (0.0728)  loss_rpn_box_reg: 0.0671 (0.0697)  time: 0.7028  data: 0.2923  max mem: 5528\n",
      "Training Epoch: [70]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1386 (0.1426)  loss_objectness: 0.0795 (0.0732)  loss_rpn_box_reg: 0.0629 (0.0694)  time: 0.6926  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [70] Total time: 0:02:53 (0.6925 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:00:58  model_time: 0.5791 (0.5791)  evaluator_time: 0.0540 (0.0540)  time: 0.9362  data: 0.2881  max mem: 5528\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3761 (0.3800)  evaluator_time: 0.0640 (0.0725)  time: 0.7695  data: 0.3159  max mem: 5528\n",
      "Test: Total time: 0:00:47 (0.7711 s / it)\n",
      "Averaged stats: model_time: 0.3761 (0.3800)  evaluator_time: 0.0640 (0.0725)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.059\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.169\n",
      "Testing Epoch: [70]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1316 (0.1316)  loss_objectness: 0.0448 (0.0448)  loss_rpn_box_reg: 0.0868 (0.0868)  time: 0.6431  data: 0.3121  max mem: 5528\n",
      "Testing Epoch: [70]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1294 (0.1381)  loss_objectness: 0.0519 (0.0588)  loss_rpn_box_reg: 0.0751 (0.0793)  time: 0.6389  data: 0.3193  max mem: 5528\n",
      "Testing Epoch: [70] Total time: 0:00:39 (0.6415 s / it)\n",
      "Training Epoch: [71]  [  0/250]  eta: 0:02:59  lr: 0.000300  loss: 0.1740 (0.1740)  loss_objectness: 0.1063 (0.1063)  loss_rpn_box_reg: 0.0677 (0.0677)  time: 0.7182  data: 0.3401  max mem: 5528\n",
      "Training Epoch: [71]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1412 (0.1422)  loss_objectness: 0.0754 (0.0801)  loss_rpn_box_reg: 0.0645 (0.0621)  time: 0.6986  data: 0.3054  max mem: 5528\n",
      "Training Epoch: [71]  [ 20/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1310 (0.1332)  loss_objectness: 0.0696 (0.0724)  loss_rpn_box_reg: 0.0565 (0.0607)  time: 0.7069  data: 0.3019  max mem: 5528\n",
      "Training Epoch: [71]  [ 30/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1179 (0.1292)  loss_objectness: 0.0607 (0.0691)  loss_rpn_box_reg: 0.0539 (0.0601)  time: 0.7054  data: 0.3012  max mem: 5528\n",
      "Training Epoch: [71]  [ 40/250]  eta: 0:02:26  lr: 0.000300  loss: 0.1201 (0.1315)  loss_objectness: 0.0655 (0.0702)  loss_rpn_box_reg: 0.0519 (0.0612)  time: 0.6886  data: 0.3008  max mem: 5528\n",
      "Training Epoch: [71]  [ 50/250]  eta: 0:02:19  lr: 0.000300  loss: 0.1468 (0.1331)  loss_objectness: 0.0752 (0.0715)  loss_rpn_box_reg: 0.0673 (0.0616)  time: 0.6940  data: 0.3026  max mem: 5528\n",
      "Training Epoch: [71]  [ 60/250]  eta: 0:02:12  lr: 0.000300  loss: 0.1426 (0.1352)  loss_objectness: 0.0736 (0.0713)  loss_rpn_box_reg: 0.0673 (0.0639)  time: 0.7035  data: 0.3026  max mem: 5528\n",
      "Training Epoch: [71]  [ 70/250]  eta: 0:02:05  lr: 0.000300  loss: 0.1365 (0.1360)  loss_objectness: 0.0700 (0.0719)  loss_rpn_box_reg: 0.0634 (0.0641)  time: 0.6944  data: 0.3006  max mem: 5528\n",
      "Training Epoch: [71]  [ 80/250]  eta: 0:01:58  lr: 0.000300  loss: 0.1355 (0.1378)  loss_objectness: 0.0689 (0.0715)  loss_rpn_box_reg: 0.0685 (0.0664)  time: 0.6960  data: 0.3014  max mem: 5528\n",
      "Training Epoch: [71]  [ 90/250]  eta: 0:01:51  lr: 0.000300  loss: 0.1355 (0.1375)  loss_objectness: 0.0695 (0.0717)  loss_rpn_box_reg: 0.0721 (0.0658)  time: 0.6962  data: 0.3003  max mem: 5528\n",
      "Training Epoch: [71]  [100/250]  eta: 0:01:44  lr: 0.000300  loss: 0.1290 (0.1370)  loss_objectness: 0.0704 (0.0712)  loss_rpn_box_reg: 0.0633 (0.0658)  time: 0.6795  data: 0.3003  max mem: 5528\n",
      "Training Epoch: [71]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1249 (0.1364)  loss_objectness: 0.0690 (0.0714)  loss_rpn_box_reg: 0.0545 (0.0650)  time: 0.6888  data: 0.2994  max mem: 5528\n",
      "Training Epoch: [71]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1363 (0.1373)  loss_objectness: 0.0698 (0.0714)  loss_rpn_box_reg: 0.0679 (0.0659)  time: 0.6957  data: 0.2978  max mem: 5528\n",
      "Training Epoch: [71]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1403 (0.1383)  loss_objectness: 0.0704 (0.0719)  loss_rpn_box_reg: 0.0714 (0.0664)  time: 0.6990  data: 0.3052  max mem: 5528\n",
      "Training Epoch: [71]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1407 (0.1388)  loss_objectness: 0.0693 (0.0719)  loss_rpn_box_reg: 0.0671 (0.0669)  time: 0.7074  data: 0.3064  max mem: 5528\n",
      "Training Epoch: [71]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1493 (0.1395)  loss_objectness: 0.0745 (0.0724)  loss_rpn_box_reg: 0.0618 (0.0670)  time: 0.6909  data: 0.2992  max mem: 5528\n",
      "Training Epoch: [71]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1493 (0.1396)  loss_objectness: 0.0729 (0.0721)  loss_rpn_box_reg: 0.0662 (0.0675)  time: 0.6834  data: 0.3004  max mem: 5528\n",
      "Training Epoch: [71]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1348 (0.1398)  loss_objectness: 0.0603 (0.0716)  loss_rpn_box_reg: 0.0683 (0.0682)  time: 0.6909  data: 0.3003  max mem: 5528\n",
      "Training Epoch: [71]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1299 (0.1398)  loss_objectness: 0.0631 (0.0713)  loss_rpn_box_reg: 0.0710 (0.0685)  time: 0.6934  data: 0.2969  max mem: 5528\n",
      "Training Epoch: [71]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1448 (0.1407)  loss_objectness: 0.0700 (0.0718)  loss_rpn_box_reg: 0.0736 (0.0689)  time: 0.6999  data: 0.3033  max mem: 5528\n",
      "Training Epoch: [71]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1448 (0.1411)  loss_objectness: 0.0875 (0.0724)  loss_rpn_box_reg: 0.0736 (0.0687)  time: 0.6923  data: 0.3076  max mem: 5528\n",
      "Training Epoch: [71]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1534 (0.1418)  loss_objectness: 0.0879 (0.0726)  loss_rpn_box_reg: 0.0691 (0.0692)  time: 0.6958  data: 0.3029  max mem: 5528\n",
      "Training Epoch: [71]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1534 (0.1419)  loss_objectness: 0.0790 (0.0729)  loss_rpn_box_reg: 0.0660 (0.0690)  time: 0.6920  data: 0.3015  max mem: 5528\n",
      "Training Epoch: [71]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1327 (0.1419)  loss_objectness: 0.0724 (0.0728)  loss_rpn_box_reg: 0.0597 (0.0691)  time: 0.6727  data: 0.2952  max mem: 5528\n",
      "Training Epoch: [71]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1337 (0.1417)  loss_objectness: 0.0684 (0.0728)  loss_rpn_box_reg: 0.0665 (0.0689)  time: 0.6760  data: 0.2896  max mem: 5528\n",
      "Training Epoch: [71]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1388 (0.1421)  loss_objectness: 0.0684 (0.0727)  loss_rpn_box_reg: 0.0739 (0.0694)  time: 0.6821  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [71] Total time: 0:02:53 (0.6930 s / it)\n",
      "Testing Epoch: [71]  [ 0/62]  eta: 0:00:41  lr: 0.000300  loss: 0.1325 (0.1325)  loss_objectness: 0.0461 (0.0461)  loss_rpn_box_reg: 0.0863 (0.0863)  time: 0.6652  data: 0.3101  max mem: 5528\n",
      "Testing Epoch: [71]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1328 (0.1384)  loss_objectness: 0.0552 (0.0582)  loss_rpn_box_reg: 0.0772 (0.0802)  time: 0.6359  data: 0.3132  max mem: 5528\n",
      "Testing Epoch: [71] Total time: 0:00:39 (0.6360 s / it)\n",
      "Training Epoch: [72]  [  0/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1125 (0.1125)  loss_objectness: 0.0532 (0.0532)  loss_rpn_box_reg: 0.0593 (0.0593)  time: 0.6621  data: 0.2801  max mem: 5528\n",
      "Training Epoch: [72]  [ 10/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1356 (0.1398)  loss_objectness: 0.0618 (0.0689)  loss_rpn_box_reg: 0.0622 (0.0709)  time: 0.6887  data: 0.2951  max mem: 5528\n",
      "Training Epoch: [72]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1501 (0.1437)  loss_objectness: 0.0686 (0.0699)  loss_rpn_box_reg: 0.0737 (0.0738)  time: 0.6859  data: 0.2950  max mem: 5528\n",
      "Training Epoch: [72]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1501 (0.1430)  loss_objectness: 0.0693 (0.0709)  loss_rpn_box_reg: 0.0718 (0.0721)  time: 0.6815  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [72]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1487 (0.1462)  loss_objectness: 0.0661 (0.0707)  loss_rpn_box_reg: 0.0718 (0.0755)  time: 0.6732  data: 0.2936  max mem: 5528\n",
      "Training Epoch: [72]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1463 (0.1438)  loss_objectness: 0.0661 (0.0699)  loss_rpn_box_reg: 0.0751 (0.0740)  time: 0.6767  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [72]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1330 (0.1438)  loss_objectness: 0.0644 (0.0704)  loss_rpn_box_reg: 0.0693 (0.0734)  time: 0.6977  data: 0.2878  max mem: 5528\n",
      "Training Epoch: [72]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1459 (0.1456)  loss_objectness: 0.0728 (0.0721)  loss_rpn_box_reg: 0.0636 (0.0736)  time: 0.6886  data: 0.2890  max mem: 5528\n",
      "Training Epoch: [72]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1459 (0.1453)  loss_objectness: 0.0791 (0.0735)  loss_rpn_box_reg: 0.0594 (0.0718)  time: 0.6703  data: 0.2914  max mem: 5528\n",
      "Training Epoch: [72]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1389 (0.1449)  loss_objectness: 0.0703 (0.0733)  loss_rpn_box_reg: 0.0612 (0.0716)  time: 0.6717  data: 0.2870  max mem: 5528\n",
      "Training Epoch: [72]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1337 (0.1447)  loss_objectness: 0.0718 (0.0735)  loss_rpn_box_reg: 0.0651 (0.0712)  time: 0.6807  data: 0.2843  max mem: 5528\n",
      "Training Epoch: [72]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1302 (0.1437)  loss_objectness: 0.0759 (0.0737)  loss_rpn_box_reg: 0.0578 (0.0700)  time: 0.6822  data: 0.2871  max mem: 5528\n",
      "Training Epoch: [72]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1248 (0.1426)  loss_objectness: 0.0689 (0.0734)  loss_rpn_box_reg: 0.0462 (0.0692)  time: 0.6805  data: 0.2895  max mem: 5528\n",
      "Training Epoch: [72]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1254 (0.1429)  loss_objectness: 0.0664 (0.0736)  loss_rpn_box_reg: 0.0559 (0.0693)  time: 0.6837  data: 0.2928  max mem: 5528\n",
      "Training Epoch: [72]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1367 (0.1425)  loss_objectness: 0.0727 (0.0737)  loss_rpn_box_reg: 0.0617 (0.0687)  time: 0.6764  data: 0.2919  max mem: 5528\n",
      "Training Epoch: [72]  [150/250]  eta: 0:01:07  lr: 0.000300  loss: 0.1406 (0.1423)  loss_objectness: 0.0699 (0.0734)  loss_rpn_box_reg: 0.0645 (0.0689)  time: 0.6709  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [72]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1406 (0.1422)  loss_objectness: 0.0664 (0.0732)  loss_rpn_box_reg: 0.0731 (0.0690)  time: 0.6737  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [72]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1279 (0.1417)  loss_objectness: 0.0663 (0.0732)  loss_rpn_box_reg: 0.0643 (0.0685)  time: 0.6685  data: 0.2882  max mem: 5528\n",
      "Training Epoch: [72]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1421 (0.1422)  loss_objectness: 0.0696 (0.0735)  loss_rpn_box_reg: 0.0643 (0.0687)  time: 0.6762  data: 0.2892  max mem: 5528\n",
      "Training Epoch: [72]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1446 (0.1428)  loss_objectness: 0.0779 (0.0737)  loss_rpn_box_reg: 0.0696 (0.0691)  time: 0.6855  data: 0.2938  max mem: 5528\n",
      "Training Epoch: [72]  [200/250]  eta: 0:00:33  lr: 0.000300  loss: 0.1467 (0.1434)  loss_objectness: 0.0747 (0.0737)  loss_rpn_box_reg: 0.0720 (0.0696)  time: 0.6752  data: 0.2918  max mem: 5528\n",
      "Training Epoch: [72]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1321 (0.1429)  loss_objectness: 0.0744 (0.0736)  loss_rpn_box_reg: 0.0665 (0.0693)  time: 0.6816  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [72]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1318 (0.1433)  loss_objectness: 0.0748 (0.0740)  loss_rpn_box_reg: 0.0618 (0.0693)  time: 0.6985  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [72]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1441 (0.1432)  loss_objectness: 0.0777 (0.0742)  loss_rpn_box_reg: 0.0641 (0.0690)  time: 0.6983  data: 0.2915  max mem: 5528\n",
      "Training Epoch: [72]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1467 (0.1435)  loss_objectness: 0.0718 (0.0742)  loss_rpn_box_reg: 0.0680 (0.0693)  time: 0.6899  data: 0.2896  max mem: 5528\n",
      "Training Epoch: [72]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1387 (0.1430)  loss_objectness: 0.0699 (0.0738)  loss_rpn_box_reg: 0.0724 (0.0692)  time: 0.6884  data: 0.2871  max mem: 5528\n",
      "Training Epoch: [72] Total time: 0:02:50 (0.6816 s / it)\n",
      "Testing Epoch: [72]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1315 (0.1315)  loss_objectness: 0.0454 (0.0454)  loss_rpn_box_reg: 0.0861 (0.0861)  time: 0.6071  data: 0.2761  max mem: 5528\n",
      "Testing Epoch: [72]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1293 (0.1375)  loss_objectness: 0.0554 (0.0573)  loss_rpn_box_reg: 0.0755 (0.0803)  time: 0.6348  data: 0.3121  max mem: 5528\n",
      "Testing Epoch: [72] Total time: 0:00:39 (0.6337 s / it)\n",
      "Training Epoch: [73]  [  0/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1329 (0.1329)  loss_objectness: 0.0778 (0.0778)  loss_rpn_box_reg: 0.0550 (0.0550)  time: 0.6561  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [73]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1392 (0.1385)  loss_objectness: 0.0709 (0.0689)  loss_rpn_box_reg: 0.0732 (0.0696)  time: 0.6731  data: 0.2872  max mem: 5528\n",
      "Training Epoch: [73]  [ 20/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1381 (0.1429)  loss_objectness: 0.0706 (0.0747)  loss_rpn_box_reg: 0.0687 (0.0682)  time: 0.6615  data: 0.2898  max mem: 5528\n",
      "Training Epoch: [73]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1381 (0.1416)  loss_objectness: 0.0693 (0.0736)  loss_rpn_box_reg: 0.0621 (0.0680)  time: 0.6808  data: 0.2974  max mem: 5528\n",
      "Training Epoch: [73]  [ 40/250]  eta: 0:02:21  lr: 0.000300  loss: 0.1409 (0.1430)  loss_objectness: 0.0667 (0.0731)  loss_rpn_box_reg: 0.0708 (0.0699)  time: 0.6897  data: 0.2993  max mem: 5528\n",
      "Training Epoch: [73]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1328 (0.1387)  loss_objectness: 0.0676 (0.0721)  loss_rpn_box_reg: 0.0635 (0.0666)  time: 0.6928  data: 0.2971  max mem: 5528\n",
      "Training Epoch: [73]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1328 (0.1398)  loss_objectness: 0.0688 (0.0722)  loss_rpn_box_reg: 0.0624 (0.0676)  time: 0.7080  data: 0.3020  max mem: 5528\n",
      "Training Epoch: [73]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1374 (0.1392)  loss_objectness: 0.0688 (0.0713)  loss_rpn_box_reg: 0.0661 (0.0679)  time: 0.6906  data: 0.3015  max mem: 5528\n",
      "Training Epoch: [73]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1399 (0.1394)  loss_objectness: 0.0668 (0.0709)  loss_rpn_box_reg: 0.0720 (0.0685)  time: 0.6943  data: 0.2944  max mem: 5528\n",
      "Training Epoch: [73]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1351 (0.1381)  loss_objectness: 0.0638 (0.0702)  loss_rpn_box_reg: 0.0640 (0.0680)  time: 0.6936  data: 0.2970  max mem: 5528\n",
      "Training Epoch: [73]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1332 (0.1384)  loss_objectness: 0.0646 (0.0701)  loss_rpn_box_reg: 0.0634 (0.0683)  time: 0.7007  data: 0.2996  max mem: 5528\n",
      "Training Epoch: [73]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1358 (0.1391)  loss_objectness: 0.0681 (0.0702)  loss_rpn_box_reg: 0.0662 (0.0689)  time: 0.7014  data: 0.2952  max mem: 5528\n",
      "Training Epoch: [73]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1370 (0.1395)  loss_objectness: 0.0676 (0.0703)  loss_rpn_box_reg: 0.0691 (0.0692)  time: 0.6880  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [73]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1353 (0.1393)  loss_objectness: 0.0680 (0.0706)  loss_rpn_box_reg: 0.0640 (0.0687)  time: 0.6884  data: 0.2953  max mem: 5528\n",
      "Training Epoch: [73]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1331 (0.1400)  loss_objectness: 0.0708 (0.0712)  loss_rpn_box_reg: 0.0640 (0.0688)  time: 0.6855  data: 0.2963  max mem: 5528\n",
      "Training Epoch: [73]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1363 (0.1405)  loss_objectness: 0.0767 (0.0719)  loss_rpn_box_reg: 0.0657 (0.0686)  time: 0.6749  data: 0.2974  max mem: 5528\n",
      "Training Epoch: [73]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1401 (0.1405)  loss_objectness: 0.0751 (0.0721)  loss_rpn_box_reg: 0.0631 (0.0684)  time: 0.6701  data: 0.2975  max mem: 5528\n",
      "Training Epoch: [73]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1401 (0.1402)  loss_objectness: 0.0745 (0.0720)  loss_rpn_box_reg: 0.0657 (0.0682)  time: 0.6897  data: 0.2968  max mem: 5528\n",
      "Training Epoch: [73]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1368 (0.1405)  loss_objectness: 0.0725 (0.0722)  loss_rpn_box_reg: 0.0657 (0.0683)  time: 0.6982  data: 0.2949  max mem: 5528\n",
      "Training Epoch: [73]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1418 (0.1406)  loss_objectness: 0.0773 (0.0728)  loss_rpn_box_reg: 0.0609 (0.0678)  time: 0.6964  data: 0.2937  max mem: 5528\n",
      "Training Epoch: [73]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1397 (0.1406)  loss_objectness: 0.0824 (0.0731)  loss_rpn_box_reg: 0.0624 (0.0676)  time: 0.6950  data: 0.2968  max mem: 5528\n",
      "Training Epoch: [73]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1380 (0.1410)  loss_objectness: 0.0723 (0.0733)  loss_rpn_box_reg: 0.0686 (0.0677)  time: 0.6926  data: 0.2950  max mem: 5528\n",
      "Training Epoch: [73]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1486 (0.1418)  loss_objectness: 0.0713 (0.0731)  loss_rpn_box_reg: 0.0763 (0.0686)  time: 0.6857  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [73]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1472 (0.1420)  loss_objectness: 0.0723 (0.0733)  loss_rpn_box_reg: 0.0695 (0.0687)  time: 0.6849  data: 0.2929  max mem: 5528\n",
      "Training Epoch: [73]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1445 (0.1424)  loss_objectness: 0.0752 (0.0732)  loss_rpn_box_reg: 0.0701 (0.0692)  time: 0.7038  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [73]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1486 (0.1428)  loss_objectness: 0.0771 (0.0736)  loss_rpn_box_reg: 0.0731 (0.0693)  time: 0.6993  data: 0.2940  max mem: 5528\n",
      "Training Epoch: [73] Total time: 0:02:52 (0.6896 s / it)\n",
      "Testing Epoch: [73]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1374 (0.1374)  loss_objectness: 0.0492 (0.0492)  loss_rpn_box_reg: 0.0881 (0.0881)  time: 0.6111  data: 0.2871  max mem: 5528\n",
      "Testing Epoch: [73]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1339 (0.1413)  loss_objectness: 0.0581 (0.0611)  loss_rpn_box_reg: 0.0700 (0.0801)  time: 0.6422  data: 0.3163  max mem: 5528\n",
      "Testing Epoch: [73] Total time: 0:00:39 (0.6420 s / it)\n",
      "Training Epoch: [74]  [  0/250]  eta: 0:02:55  lr: 0.000300  loss: 0.1187 (0.1187)  loss_objectness: 0.0616 (0.0616)  loss_rpn_box_reg: 0.0571 (0.0571)  time: 0.7012  data: 0.3071  max mem: 5528\n",
      "Training Epoch: [74]  [ 10/250]  eta: 0:02:49  lr: 0.000300  loss: 0.1302 (0.1382)  loss_objectness: 0.0785 (0.0787)  loss_rpn_box_reg: 0.0526 (0.0595)  time: 0.7060  data: 0.3138  max mem: 5528\n",
      "Training Epoch: [74]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1341 (0.1386)  loss_objectness: 0.0731 (0.0742)  loss_rpn_box_reg: 0.0553 (0.0644)  time: 0.6942  data: 0.3023  max mem: 5528\n",
      "Training Epoch: [74]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1353 (0.1393)  loss_objectness: 0.0679 (0.0732)  loss_rpn_box_reg: 0.0680 (0.0661)  time: 0.6814  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [74]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1477 (0.1406)  loss_objectness: 0.0695 (0.0730)  loss_rpn_box_reg: 0.0680 (0.0676)  time: 0.6859  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [74]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1418 (0.1399)  loss_objectness: 0.0722 (0.0723)  loss_rpn_box_reg: 0.0679 (0.0676)  time: 0.6794  data: 0.2891  max mem: 5528\n",
      "Training Epoch: [74]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1342 (0.1400)  loss_objectness: 0.0723 (0.0723)  loss_rpn_box_reg: 0.0631 (0.0677)  time: 0.6879  data: 0.2878  max mem: 5528\n",
      "Training Epoch: [74]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1358 (0.1396)  loss_objectness: 0.0664 (0.0706)  loss_rpn_box_reg: 0.0689 (0.0690)  time: 0.6971  data: 0.2888  max mem: 5528\n",
      "Training Epoch: [74]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1400 (0.1414)  loss_objectness: 0.0675 (0.0722)  loss_rpn_box_reg: 0.0748 (0.0692)  time: 0.6831  data: 0.2934  max mem: 5528\n",
      "Training Epoch: [74]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1453 (0.1415)  loss_objectness: 0.0719 (0.0719)  loss_rpn_box_reg: 0.0740 (0.0695)  time: 0.6858  data: 0.2972  max mem: 5528\n",
      "Training Epoch: [74]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1304 (0.1406)  loss_objectness: 0.0698 (0.0719)  loss_rpn_box_reg: 0.0613 (0.0688)  time: 0.6893  data: 0.2891  max mem: 5528\n",
      "Training Epoch: [74]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1304 (0.1406)  loss_objectness: 0.0707 (0.0724)  loss_rpn_box_reg: 0.0613 (0.0682)  time: 0.6710  data: 0.2871  max mem: 5528\n",
      "Training Epoch: [74]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1400 (0.1407)  loss_objectness: 0.0732 (0.0723)  loss_rpn_box_reg: 0.0632 (0.0684)  time: 0.6758  data: 0.2923  max mem: 5528\n",
      "Training Epoch: [74]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1400 (0.1412)  loss_objectness: 0.0766 (0.0728)  loss_rpn_box_reg: 0.0608 (0.0684)  time: 0.6913  data: 0.2909  max mem: 5528\n",
      "Training Epoch: [74]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1331 (0.1409)  loss_objectness: 0.0773 (0.0726)  loss_rpn_box_reg: 0.0633 (0.0683)  time: 0.6709  data: 0.2881  max mem: 5528\n",
      "Training Epoch: [74]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1331 (0.1408)  loss_objectness: 0.0724 (0.0730)  loss_rpn_box_reg: 0.0643 (0.0678)  time: 0.6704  data: 0.2915  max mem: 5528\n",
      "Training Epoch: [74]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1423 (0.1411)  loss_objectness: 0.0687 (0.0726)  loss_rpn_box_reg: 0.0720 (0.0685)  time: 0.6959  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [74]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1462 (0.1414)  loss_objectness: 0.0682 (0.0725)  loss_rpn_box_reg: 0.0804 (0.0689)  time: 0.6986  data: 0.2883  max mem: 5528\n",
      "Training Epoch: [74]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1344 (0.1404)  loss_objectness: 0.0682 (0.0722)  loss_rpn_box_reg: 0.0589 (0.0683)  time: 0.6795  data: 0.2869  max mem: 5528\n",
      "Training Epoch: [74]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1286 (0.1403)  loss_objectness: 0.0675 (0.0718)  loss_rpn_box_reg: 0.0589 (0.0686)  time: 0.6757  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [74]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1393 (0.1411)  loss_objectness: 0.0705 (0.0720)  loss_rpn_box_reg: 0.0727 (0.0691)  time: 0.6861  data: 0.2965  max mem: 5528\n",
      "Training Epoch: [74]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1622 (0.1418)  loss_objectness: 0.0829 (0.0730)  loss_rpn_box_reg: 0.0712 (0.0688)  time: 0.6932  data: 0.2998  max mem: 5528\n",
      "Training Epoch: [74]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1521 (0.1416)  loss_objectness: 0.0756 (0.0728)  loss_rpn_box_reg: 0.0627 (0.0688)  time: 0.6894  data: 0.2971  max mem: 5528\n",
      "Training Epoch: [74]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1294 (0.1414)  loss_objectness: 0.0658 (0.0727)  loss_rpn_box_reg: 0.0709 (0.0688)  time: 0.6780  data: 0.2960  max mem: 5528\n",
      "Training Epoch: [74]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1459 (0.1421)  loss_objectness: 0.0712 (0.0730)  loss_rpn_box_reg: 0.0747 (0.0691)  time: 0.6840  data: 0.2965  max mem: 5528\n",
      "Training Epoch: [74]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1569 (0.1429)  loss_objectness: 0.0778 (0.0735)  loss_rpn_box_reg: 0.0710 (0.0695)  time: 0.6964  data: 0.2974  max mem: 5528\n",
      "Training Epoch: [74] Total time: 0:02:51 (0.6860 s / it)\n",
      "Testing Epoch: [74]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1379 (0.1379)  loss_objectness: 0.0509 (0.0509)  loss_rpn_box_reg: 0.0870 (0.0870)  time: 0.6441  data: 0.3061  max mem: 5528\n",
      "Testing Epoch: [74]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1348 (0.1410)  loss_objectness: 0.0616 (0.0619)  loss_rpn_box_reg: 0.0692 (0.0791)  time: 0.6339  data: 0.3120  max mem: 5528\n",
      "Testing Epoch: [74] Total time: 0:00:39 (0.6346 s / it)\n",
      "Training Epoch: [75]  [  0/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1526 (0.1526)  loss_objectness: 0.0809 (0.0809)  loss_rpn_box_reg: 0.0717 (0.0717)  time: 0.6621  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [75]  [ 10/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1403 (0.1418)  loss_objectness: 0.0710 (0.0682)  loss_rpn_box_reg: 0.0698 (0.0735)  time: 0.6679  data: 0.2915  max mem: 5528\n",
      "Training Epoch: [75]  [ 20/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1333 (0.1365)  loss_objectness: 0.0651 (0.0684)  loss_rpn_box_reg: 0.0647 (0.0681)  time: 0.6747  data: 0.2937  max mem: 5528\n",
      "Training Epoch: [75]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1270 (0.1363)  loss_objectness: 0.0682 (0.0688)  loss_rpn_box_reg: 0.0631 (0.0675)  time: 0.6881  data: 0.2953  max mem: 5528\n",
      "Training Epoch: [75]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1340 (0.1378)  loss_objectness: 0.0700 (0.0691)  loss_rpn_box_reg: 0.0666 (0.0687)  time: 0.6837  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [75]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1388 (0.1387)  loss_objectness: 0.0687 (0.0696)  loss_rpn_box_reg: 0.0688 (0.0690)  time: 0.6800  data: 0.2947  max mem: 5528\n",
      "Training Epoch: [75]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1330 (0.1380)  loss_objectness: 0.0656 (0.0689)  loss_rpn_box_reg: 0.0646 (0.0690)  time: 0.6873  data: 0.2959  max mem: 5528\n",
      "Training Epoch: [75]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1287 (0.1384)  loss_objectness: 0.0663 (0.0690)  loss_rpn_box_reg: 0.0640 (0.0695)  time: 0.6831  data: 0.2952  max mem: 5528\n",
      "Training Epoch: [75]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1299 (0.1380)  loss_objectness: 0.0688 (0.0692)  loss_rpn_box_reg: 0.0640 (0.0689)  time: 0.6847  data: 0.2946  max mem: 5528\n",
      "Training Epoch: [75]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1421 (0.1389)  loss_objectness: 0.0704 (0.0693)  loss_rpn_box_reg: 0.0689 (0.0696)  time: 0.6961  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [75]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1442 (0.1392)  loss_objectness: 0.0673 (0.0692)  loss_rpn_box_reg: 0.0747 (0.0701)  time: 0.7007  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [75]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1414 (0.1400)  loss_objectness: 0.0697 (0.0698)  loss_rpn_box_reg: 0.0697 (0.0702)  time: 0.6997  data: 0.2973  max mem: 5528\n",
      "Training Epoch: [75]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1397 (0.1398)  loss_objectness: 0.0697 (0.0696)  loss_rpn_box_reg: 0.0697 (0.0703)  time: 0.6986  data: 0.2955  max mem: 5528\n",
      "Training Epoch: [75]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1338 (0.1395)  loss_objectness: 0.0642 (0.0692)  loss_rpn_box_reg: 0.0644 (0.0702)  time: 0.6960  data: 0.2963  max mem: 5528\n",
      "Training Epoch: [75]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1312 (0.1390)  loss_objectness: 0.0696 (0.0697)  loss_rpn_box_reg: 0.0608 (0.0694)  time: 0.6853  data: 0.2957  max mem: 5528\n",
      "Training Epoch: [75]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1409 (0.1401)  loss_objectness: 0.0770 (0.0703)  loss_rpn_box_reg: 0.0608 (0.0698)  time: 0.6822  data: 0.2923  max mem: 5528\n",
      "Training Epoch: [75]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1527 (0.1414)  loss_objectness: 0.0792 (0.0712)  loss_rpn_box_reg: 0.0812 (0.0702)  time: 0.6909  data: 0.2968  max mem: 5528\n",
      "Training Epoch: [75]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1388 (0.1406)  loss_objectness: 0.0658 (0.0708)  loss_rpn_box_reg: 0.0675 (0.0698)  time: 0.6892  data: 0.2934  max mem: 5528\n",
      "Training Epoch: [75]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1362 (0.1402)  loss_objectness: 0.0642 (0.0707)  loss_rpn_box_reg: 0.0599 (0.0695)  time: 0.6851  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [75]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1418 (0.1405)  loss_objectness: 0.0706 (0.0710)  loss_rpn_box_reg: 0.0613 (0.0695)  time: 0.6882  data: 0.2942  max mem: 5528\n",
      "Training Epoch: [75]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1352 (0.1404)  loss_objectness: 0.0731 (0.0710)  loss_rpn_box_reg: 0.0625 (0.0694)  time: 0.6852  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [75]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1352 (0.1410)  loss_objectness: 0.0731 (0.0715)  loss_rpn_box_reg: 0.0700 (0.0695)  time: 0.6785  data: 0.2948  max mem: 5528\n",
      "Training Epoch: [75]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1335 (0.1407)  loss_objectness: 0.0696 (0.0712)  loss_rpn_box_reg: 0.0704 (0.0694)  time: 0.6818  data: 0.2952  max mem: 5528\n",
      "Training Epoch: [75]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1311 (0.1407)  loss_objectness: 0.0640 (0.0711)  loss_rpn_box_reg: 0.0725 (0.0695)  time: 0.6923  data: 0.2965  max mem: 5528\n",
      "Training Epoch: [75]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1341 (0.1406)  loss_objectness: 0.0640 (0.0713)  loss_rpn_box_reg: 0.0600 (0.0693)  time: 0.6901  data: 0.2940  max mem: 5528\n",
      "Training Epoch: [75]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1347 (0.1411)  loss_objectness: 0.0744 (0.0714)  loss_rpn_box_reg: 0.0612 (0.0697)  time: 0.6740  data: 0.2915  max mem: 5528\n",
      "Training Epoch: [75] Total time: 0:02:51 (0.6864 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:06  model_time: 0.7182 (0.7182)  evaluator_time: 0.0550 (0.0550)  time: 1.0722  data: 0.2841  max mem: 5528\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3781 (0.3873)  evaluator_time: 0.0680 (0.0776)  time: 0.7712  data: 0.3110  max mem: 5528\n",
      "Test: Total time: 0:00:48 (0.7782 s / it)\n",
      "Averaged stats: model_time: 0.3781 (0.3873)  evaluator_time: 0.0680 (0.0776)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.05s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.023\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.059\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.168\n",
      "Testing Epoch: [75]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1364 (0.1364)  loss_objectness: 0.0473 (0.0473)  loss_rpn_box_reg: 0.0891 (0.0891)  time: 0.6141  data: 0.2901  max mem: 5528\n",
      "Testing Epoch: [75]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1304 (0.1396)  loss_objectness: 0.0551 (0.0589)  loss_rpn_box_reg: 0.0742 (0.0807)  time: 0.6358  data: 0.3158  max mem: 5528\n",
      "Testing Epoch: [75] Total time: 0:00:39 (0.6347 s / it)\n",
      "Training Epoch: [76]  [  0/250]  eta: 0:02:51  lr: 0.000300  loss: 0.0999 (0.0999)  loss_objectness: 0.0644 (0.0644)  loss_rpn_box_reg: 0.0355 (0.0355)  time: 0.6872  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [76]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1391 (0.1362)  loss_objectness: 0.0661 (0.0658)  loss_rpn_box_reg: 0.0638 (0.0704)  time: 0.6935  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [76]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1391 (0.1411)  loss_objectness: 0.0724 (0.0716)  loss_rpn_box_reg: 0.0637 (0.0695)  time: 0.6963  data: 0.2945  max mem: 5528\n",
      "Training Epoch: [76]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1321 (0.1407)  loss_objectness: 0.0749 (0.0737)  loss_rpn_box_reg: 0.0536 (0.0670)  time: 0.6923  data: 0.2951  max mem: 5528\n",
      "Training Epoch: [76]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1367 (0.1412)  loss_objectness: 0.0687 (0.0731)  loss_rpn_box_reg: 0.0591 (0.0681)  time: 0.6909  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [76]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1417 (0.1414)  loss_objectness: 0.0651 (0.0719)  loss_rpn_box_reg: 0.0659 (0.0695)  time: 0.6891  data: 0.2959  max mem: 5528\n",
      "Training Epoch: [76]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1521 (0.1439)  loss_objectness: 0.0651 (0.0724)  loss_rpn_box_reg: 0.0758 (0.0715)  time: 0.6830  data: 0.2990  max mem: 5528\n",
      "Training Epoch: [76]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1281 (0.1414)  loss_objectness: 0.0664 (0.0712)  loss_rpn_box_reg: 0.0671 (0.0702)  time: 0.6908  data: 0.2998  max mem: 5528\n",
      "Training Epoch: [76]  [ 80/250]  eta: 0:01:58  lr: 0.000300  loss: 0.1262 (0.1406)  loss_objectness: 0.0599 (0.0695)  loss_rpn_box_reg: 0.0683 (0.0712)  time: 0.7079  data: 0.2987  max mem: 5528\n",
      "Training Epoch: [76]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1225 (0.1386)  loss_objectness: 0.0595 (0.0688)  loss_rpn_box_reg: 0.0681 (0.0698)  time: 0.6969  data: 0.2966  max mem: 5528\n",
      "Training Epoch: [76]  [100/250]  eta: 0:01:44  lr: 0.000300  loss: 0.1213 (0.1388)  loss_objectness: 0.0648 (0.0686)  loss_rpn_box_reg: 0.0562 (0.0702)  time: 0.6945  data: 0.2980  max mem: 5528\n",
      "Training Epoch: [76]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1390 (0.1379)  loss_objectness: 0.0674 (0.0688)  loss_rpn_box_reg: 0.0622 (0.0691)  time: 0.7127  data: 0.3022  max mem: 5528\n",
      "Training Epoch: [76]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1390 (0.1400)  loss_objectness: 0.0714 (0.0696)  loss_rpn_box_reg: 0.0622 (0.0704)  time: 0.6984  data: 0.3016  max mem: 5528\n",
      "Training Epoch: [76]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1398 (0.1401)  loss_objectness: 0.0717 (0.0703)  loss_rpn_box_reg: 0.0615 (0.0699)  time: 0.6823  data: 0.2968  max mem: 5528\n",
      "Training Epoch: [76]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1287 (0.1398)  loss_objectness: 0.0695 (0.0702)  loss_rpn_box_reg: 0.0589 (0.0697)  time: 0.6981  data: 0.2957  max mem: 5528\n",
      "Training Epoch: [76]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1287 (0.1393)  loss_objectness: 0.0684 (0.0701)  loss_rpn_box_reg: 0.0627 (0.0692)  time: 0.6978  data: 0.2968  max mem: 5528\n",
      "Training Epoch: [76]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1347 (0.1398)  loss_objectness: 0.0706 (0.0703)  loss_rpn_box_reg: 0.0624 (0.0695)  time: 0.6781  data: 0.2947  max mem: 5528\n",
      "Training Epoch: [76]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1436 (0.1410)  loss_objectness: 0.0752 (0.0711)  loss_rpn_box_reg: 0.0725 (0.0698)  time: 0.6836  data: 0.2992  max mem: 5528\n",
      "Training Epoch: [76]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1444 (0.1412)  loss_objectness: 0.0805 (0.0714)  loss_rpn_box_reg: 0.0676 (0.0698)  time: 0.6893  data: 0.3012  max mem: 5528\n",
      "Training Epoch: [76]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1325 (0.1411)  loss_objectness: 0.0775 (0.0718)  loss_rpn_box_reg: 0.0619 (0.0693)  time: 0.7010  data: 0.3001  max mem: 5528\n",
      "Training Epoch: [76]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1325 (0.1415)  loss_objectness: 0.0665 (0.0717)  loss_rpn_box_reg: 0.0632 (0.0698)  time: 0.6948  data: 0.2995  max mem: 5528\n",
      "Training Epoch: [76]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1329 (0.1413)  loss_objectness: 0.0665 (0.0717)  loss_rpn_box_reg: 0.0632 (0.0695)  time: 0.6780  data: 0.2982  max mem: 5528\n",
      "Training Epoch: [76]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1329 (0.1416)  loss_objectness: 0.0703 (0.0718)  loss_rpn_box_reg: 0.0628 (0.0698)  time: 0.6802  data: 0.2996  max mem: 5528\n",
      "Training Epoch: [76]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1343 (0.1414)  loss_objectness: 0.0683 (0.0716)  loss_rpn_box_reg: 0.0628 (0.0698)  time: 0.6822  data: 0.2997  max mem: 5528\n",
      "Training Epoch: [76]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1351 (0.1420)  loss_objectness: 0.0715 (0.0719)  loss_rpn_box_reg: 0.0633 (0.0701)  time: 0.6932  data: 0.3037  max mem: 5528\n",
      "Training Epoch: [76]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1488 (0.1423)  loss_objectness: 0.0789 (0.0724)  loss_rpn_box_reg: 0.0633 (0.0699)  time: 0.6807  data: 0.3049  max mem: 5528\n",
      "Training Epoch: [76] Total time: 0:02:52 (0.6909 s / it)\n",
      "Testing Epoch: [76]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1385 (0.1385)  loss_objectness: 0.0539 (0.0539)  loss_rpn_box_reg: 0.0846 (0.0846)  time: 0.6151  data: 0.2891  max mem: 5528\n",
      "Testing Epoch: [76]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1308 (0.1411)  loss_objectness: 0.0599 (0.0620)  loss_rpn_box_reg: 0.0728 (0.0792)  time: 0.6388  data: 0.3169  max mem: 5528\n",
      "Testing Epoch: [76] Total time: 0:00:39 (0.6392 s / it)\n",
      "Training Epoch: [77]  [  0/250]  eta: 0:03:05  lr: 0.000300  loss: 0.1240 (0.1240)  loss_objectness: 0.0725 (0.0725)  loss_rpn_box_reg: 0.0515 (0.0515)  time: 0.7422  data: 0.3001  max mem: 5528\n",
      "Training Epoch: [77]  [ 10/250]  eta: 0:02:48  lr: 0.000300  loss: 0.1281 (0.1315)  loss_objectness: 0.0566 (0.0620)  loss_rpn_box_reg: 0.0689 (0.0694)  time: 0.7034  data: 0.3029  max mem: 5528\n",
      "Training Epoch: [77]  [ 20/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1305 (0.1318)  loss_objectness: 0.0608 (0.0664)  loss_rpn_box_reg: 0.0621 (0.0654)  time: 0.7069  data: 0.3046  max mem: 5528\n",
      "Training Epoch: [77]  [ 30/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1301 (0.1353)  loss_objectness: 0.0677 (0.0679)  loss_rpn_box_reg: 0.0593 (0.0673)  time: 0.7023  data: 0.3040  max mem: 5528\n",
      "Training Epoch: [77]  [ 40/250]  eta: 0:02:26  lr: 0.000300  loss: 0.1301 (0.1364)  loss_objectness: 0.0694 (0.0686)  loss_rpn_box_reg: 0.0581 (0.0678)  time: 0.6863  data: 0.3018  max mem: 5528\n",
      "Training Epoch: [77]  [ 50/250]  eta: 0:02:19  lr: 0.000300  loss: 0.1412 (0.1387)  loss_objectness: 0.0690 (0.0698)  loss_rpn_box_reg: 0.0754 (0.0689)  time: 0.6857  data: 0.3062  max mem: 5528\n",
      "Training Epoch: [77]  [ 60/250]  eta: 0:02:12  lr: 0.000300  loss: 0.1412 (0.1403)  loss_objectness: 0.0661 (0.0708)  loss_rpn_box_reg: 0.0735 (0.0695)  time: 0.6943  data: 0.3114  max mem: 5528\n",
      "Training Epoch: [77]  [ 70/250]  eta: 0:02:05  lr: 0.000300  loss: 0.1582 (0.1424)  loss_objectness: 0.0649 (0.0702)  loss_rpn_box_reg: 0.0793 (0.0721)  time: 0.7025  data: 0.3053  max mem: 5528\n",
      "Training Epoch: [77]  [ 80/250]  eta: 0:01:58  lr: 0.000300  loss: 0.1495 (0.1428)  loss_objectness: 0.0650 (0.0710)  loss_rpn_box_reg: 0.0747 (0.0718)  time: 0.6936  data: 0.3002  max mem: 5528\n",
      "Training Epoch: [77]  [ 90/250]  eta: 0:01:51  lr: 0.000300  loss: 0.1297 (0.1416)  loss_objectness: 0.0702 (0.0704)  loss_rpn_box_reg: 0.0603 (0.0712)  time: 0.6848  data: 0.3005  max mem: 5528\n",
      "Training Epoch: [77]  [100/250]  eta: 0:01:44  lr: 0.000300  loss: 0.1299 (0.1418)  loss_objectness: 0.0677 (0.0701)  loss_rpn_box_reg: 0.0649 (0.0717)  time: 0.7006  data: 0.2997  max mem: 5528\n",
      "Training Epoch: [77]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1385 (0.1414)  loss_objectness: 0.0728 (0.0704)  loss_rpn_box_reg: 0.0629 (0.0709)  time: 0.7005  data: 0.2994  max mem: 5528\n",
      "Training Epoch: [77]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1343 (0.1416)  loss_objectness: 0.0743 (0.0708)  loss_rpn_box_reg: 0.0618 (0.0708)  time: 0.6834  data: 0.3040  max mem: 5528\n",
      "Training Epoch: [77]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1340 (0.1416)  loss_objectness: 0.0732 (0.0711)  loss_rpn_box_reg: 0.0618 (0.0705)  time: 0.6914  data: 0.3072  max mem: 5528\n",
      "Training Epoch: [77]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1346 (0.1417)  loss_objectness: 0.0732 (0.0709)  loss_rpn_box_reg: 0.0666 (0.0708)  time: 0.6950  data: 0.2995  max mem: 5528\n",
      "Training Epoch: [77]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1353 (0.1413)  loss_objectness: 0.0675 (0.0708)  loss_rpn_box_reg: 0.0680 (0.0705)  time: 0.6744  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [77]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1353 (0.1412)  loss_objectness: 0.0722 (0.0709)  loss_rpn_box_reg: 0.0660 (0.0703)  time: 0.6818  data: 0.2883  max mem: 5528\n",
      "Training Epoch: [77]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1332 (0.1419)  loss_objectness: 0.0747 (0.0716)  loss_rpn_box_reg: 0.0623 (0.0703)  time: 0.6910  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [77]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1332 (0.1419)  loss_objectness: 0.0703 (0.0717)  loss_rpn_box_reg: 0.0608 (0.0702)  time: 0.6879  data: 0.2927  max mem: 5528\n",
      "Training Epoch: [77]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1283 (0.1414)  loss_objectness: 0.0694 (0.0715)  loss_rpn_box_reg: 0.0624 (0.0698)  time: 0.6813  data: 0.2906  max mem: 5528\n",
      "Training Epoch: [77]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1357 (0.1415)  loss_objectness: 0.0718 (0.0717)  loss_rpn_box_reg: 0.0624 (0.0698)  time: 0.6784  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [77]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1379 (0.1411)  loss_objectness: 0.0744 (0.0717)  loss_rpn_box_reg: 0.0562 (0.0694)  time: 0.6836  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [77]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1313 (0.1411)  loss_objectness: 0.0699 (0.0720)  loss_rpn_box_reg: 0.0576 (0.0691)  time: 0.6727  data: 0.2949  max mem: 5528\n",
      "Training Epoch: [77]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1446 (0.1421)  loss_objectness: 0.0756 (0.0724)  loss_rpn_box_reg: 0.0660 (0.0697)  time: 0.6753  data: 0.2922  max mem: 5528\n",
      "Training Epoch: [77]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1433 (0.1424)  loss_objectness: 0.0813 (0.0726)  loss_rpn_box_reg: 0.0740 (0.0698)  time: 0.6889  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [77]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1433 (0.1425)  loss_objectness: 0.0785 (0.0730)  loss_rpn_box_reg: 0.0642 (0.0696)  time: 0.6995  data: 0.2914  max mem: 5528\n",
      "Training Epoch: [77] Total time: 0:02:52 (0.6898 s / it)\n",
      "Testing Epoch: [77]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1327 (0.1327)  loss_objectness: 0.0476 (0.0476)  loss_rpn_box_reg: 0.0851 (0.0851)  time: 0.6191  data: 0.2961  max mem: 5528\n",
      "Testing Epoch: [77]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1340 (0.1405)  loss_objectness: 0.0545 (0.0604)  loss_rpn_box_reg: 0.0736 (0.0801)  time: 0.6348  data: 0.3086  max mem: 5528\n",
      "Testing Epoch: [77] Total time: 0:00:39 (0.6359 s / it)\n",
      "Training Epoch: [78]  [  0/250]  eta: 0:02:57  lr: 0.000300  loss: 0.1262 (0.1262)  loss_objectness: 0.0700 (0.0700)  loss_rpn_box_reg: 0.0562 (0.0562)  time: 0.7112  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [78]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1357 (0.1469)  loss_objectness: 0.0620 (0.0723)  loss_rpn_box_reg: 0.0668 (0.0746)  time: 0.6722  data: 0.2902  max mem: 5528\n",
      "Training Epoch: [78]  [ 20/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1340 (0.1417)  loss_objectness: 0.0683 (0.0709)  loss_rpn_box_reg: 0.0644 (0.0708)  time: 0.6712  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [78]  [ 30/250]  eta: 0:02:27  lr: 0.000300  loss: 0.1306 (0.1388)  loss_objectness: 0.0683 (0.0701)  loss_rpn_box_reg: 0.0611 (0.0687)  time: 0.6704  data: 0.2915  max mem: 5528\n",
      "Training Epoch: [78]  [ 40/250]  eta: 0:02:20  lr: 0.000300  loss: 0.1306 (0.1387)  loss_objectness: 0.0728 (0.0720)  loss_rpn_box_reg: 0.0575 (0.0667)  time: 0.6680  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [78]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1384 (0.1395)  loss_objectness: 0.0735 (0.0725)  loss_rpn_box_reg: 0.0575 (0.0670)  time: 0.6863  data: 0.2939  max mem: 5528\n",
      "Training Epoch: [78]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1412 (0.1379)  loss_objectness: 0.0734 (0.0726)  loss_rpn_box_reg: 0.0586 (0.0653)  time: 0.7038  data: 0.2935  max mem: 5528\n",
      "Training Epoch: [78]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1325 (0.1379)  loss_objectness: 0.0711 (0.0719)  loss_rpn_box_reg: 0.0602 (0.0661)  time: 0.6880  data: 0.2895  max mem: 5528\n",
      "Training Epoch: [78]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1368 (0.1376)  loss_objectness: 0.0682 (0.0713)  loss_rpn_box_reg: 0.0707 (0.0663)  time: 0.6831  data: 0.2858  max mem: 5528\n",
      "Training Epoch: [78]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1369 (0.1399)  loss_objectness: 0.0734 (0.0723)  loss_rpn_box_reg: 0.0707 (0.0676)  time: 0.6939  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [78]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1432 (0.1405)  loss_objectness: 0.0752 (0.0721)  loss_rpn_box_reg: 0.0758 (0.0683)  time: 0.6941  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [78]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1394 (0.1406)  loss_objectness: 0.0752 (0.0724)  loss_rpn_box_reg: 0.0680 (0.0682)  time: 0.6922  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [78]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1310 (0.1403)  loss_objectness: 0.0762 (0.0728)  loss_rpn_box_reg: 0.0636 (0.0675)  time: 0.6889  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [78]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1372 (0.1406)  loss_objectness: 0.0732 (0.0731)  loss_rpn_box_reg: 0.0636 (0.0675)  time: 0.6884  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [78]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1362 (0.1402)  loss_objectness: 0.0728 (0.0728)  loss_rpn_box_reg: 0.0636 (0.0674)  time: 0.6899  data: 0.2898  max mem: 5528\n",
      "Training Epoch: [78]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1362 (0.1403)  loss_objectness: 0.0631 (0.0728)  loss_rpn_box_reg: 0.0599 (0.0675)  time: 0.6805  data: 0.2914  max mem: 5528\n",
      "Training Epoch: [78]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1369 (0.1399)  loss_objectness: 0.0676 (0.0727)  loss_rpn_box_reg: 0.0633 (0.0672)  time: 0.6816  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [78]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1439 (0.1408)  loss_objectness: 0.0686 (0.0728)  loss_rpn_box_reg: 0.0639 (0.0680)  time: 0.6835  data: 0.2936  max mem: 5528\n",
      "Training Epoch: [78]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1523 (0.1412)  loss_objectness: 0.0681 (0.0724)  loss_rpn_box_reg: 0.0857 (0.0688)  time: 0.6841  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [78]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1491 (0.1420)  loss_objectness: 0.0683 (0.0725)  loss_rpn_box_reg: 0.0747 (0.0696)  time: 0.6888  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [78]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1502 (0.1425)  loss_objectness: 0.0748 (0.0729)  loss_rpn_box_reg: 0.0715 (0.0697)  time: 0.6873  data: 0.2928  max mem: 5528\n",
      "Training Epoch: [78]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1385 (0.1425)  loss_objectness: 0.0773 (0.0731)  loss_rpn_box_reg: 0.0639 (0.0694)  time: 0.6815  data: 0.2915  max mem: 5528\n",
      "Training Epoch: [78]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1270 (0.1423)  loss_objectness: 0.0612 (0.0728)  loss_rpn_box_reg: 0.0614 (0.0694)  time: 0.6819  data: 0.2886  max mem: 5528\n",
      "Training Epoch: [78]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1291 (0.1423)  loss_objectness: 0.0659 (0.0728)  loss_rpn_box_reg: 0.0618 (0.0695)  time: 0.6919  data: 0.2891  max mem: 5528\n",
      "Training Epoch: [78]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1337 (0.1422)  loss_objectness: 0.0686 (0.0728)  loss_rpn_box_reg: 0.0637 (0.0694)  time: 0.6963  data: 0.2957  max mem: 5528\n",
      "Training Epoch: [78]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1499 (0.1429)  loss_objectness: 0.0725 (0.0731)  loss_rpn_box_reg: 0.0753 (0.0698)  time: 0.6960  data: 0.2994  max mem: 5528\n",
      "Training Epoch: [78] Total time: 0:02:51 (0.6864 s / it)\n",
      "Testing Epoch: [78]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1342 (0.1342)  loss_objectness: 0.0460 (0.0460)  loss_rpn_box_reg: 0.0882 (0.0882)  time: 0.6211  data: 0.2941  max mem: 5528\n",
      "Testing Epoch: [78]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1306 (0.1445)  loss_objectness: 0.0559 (0.0623)  loss_rpn_box_reg: 0.0749 (0.0823)  time: 0.6308  data: 0.3092  max mem: 5528\n",
      "Testing Epoch: [78] Total time: 0:00:39 (0.6334 s / it)\n",
      "Training Epoch: [79]  [  0/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1150 (0.1150)  loss_objectness: 0.0836 (0.0836)  loss_rpn_box_reg: 0.0314 (0.0314)  time: 0.6641  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [79]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1508 (0.1483)  loss_objectness: 0.0836 (0.0833)  loss_rpn_box_reg: 0.0546 (0.0651)  time: 0.6743  data: 0.2959  max mem: 5528\n",
      "Training Epoch: [79]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1375 (0.1458)  loss_objectness: 0.0759 (0.0766)  loss_rpn_box_reg: 0.0675 (0.0691)  time: 0.6887  data: 0.2949  max mem: 5528\n",
      "Training Epoch: [79]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1349 (0.1455)  loss_objectness: 0.0663 (0.0740)  loss_rpn_box_reg: 0.0740 (0.0716)  time: 0.6888  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [79]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1384 (0.1434)  loss_objectness: 0.0663 (0.0743)  loss_rpn_box_reg: 0.0587 (0.0692)  time: 0.6899  data: 0.2947  max mem: 5528\n",
      "Training Epoch: [79]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1323 (0.1417)  loss_objectness: 0.0677 (0.0736)  loss_rpn_box_reg: 0.0593 (0.0681)  time: 0.6911  data: 0.2926  max mem: 5528\n",
      "Training Epoch: [79]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1293 (0.1418)  loss_objectness: 0.0628 (0.0731)  loss_rpn_box_reg: 0.0657 (0.0687)  time: 0.6875  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [79]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1485 (0.1440)  loss_objectness: 0.0695 (0.0744)  loss_rpn_box_reg: 0.0713 (0.0696)  time: 0.6708  data: 0.2905  max mem: 5528\n",
      "Training Epoch: [79]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1442 (0.1423)  loss_objectness: 0.0754 (0.0735)  loss_rpn_box_reg: 0.0616 (0.0688)  time: 0.6600  data: 0.2905  max mem: 5528\n",
      "Training Epoch: [79]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1370 (0.1416)  loss_objectness: 0.0679 (0.0732)  loss_rpn_box_reg: 0.0595 (0.0684)  time: 0.6885  data: 0.2898  max mem: 5528\n",
      "Training Epoch: [79]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1348 (0.1417)  loss_objectness: 0.0727 (0.0734)  loss_rpn_box_reg: 0.0595 (0.0682)  time: 0.6821  data: 0.2901  max mem: 5528\n",
      "Training Epoch: [79]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1447 (0.1425)  loss_objectness: 0.0758 (0.0734)  loss_rpn_box_reg: 0.0681 (0.0691)  time: 0.6723  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [79]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1447 (0.1430)  loss_objectness: 0.0737 (0.0733)  loss_rpn_box_reg: 0.0745 (0.0697)  time: 0.6842  data: 0.2896  max mem: 5528\n",
      "Training Epoch: [79]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1423 (0.1424)  loss_objectness: 0.0704 (0.0732)  loss_rpn_box_reg: 0.0637 (0.0692)  time: 0.6898  data: 0.2880  max mem: 5528\n",
      "Training Epoch: [79]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1287 (0.1421)  loss_objectness: 0.0672 (0.0729)  loss_rpn_box_reg: 0.0627 (0.0692)  time: 0.6814  data: 0.2891  max mem: 5528\n",
      "Training Epoch: [79]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1256 (0.1411)  loss_objectness: 0.0633 (0.0723)  loss_rpn_box_reg: 0.0570 (0.0689)  time: 0.6693  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [79]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1239 (0.1409)  loss_objectness: 0.0625 (0.0721)  loss_rpn_box_reg: 0.0573 (0.0689)  time: 0.6865  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [79]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1198 (0.1399)  loss_objectness: 0.0700 (0.0718)  loss_rpn_box_reg: 0.0573 (0.0680)  time: 0.6969  data: 0.2922  max mem: 5528\n",
      "Training Epoch: [79]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1219 (0.1398)  loss_objectness: 0.0617 (0.0713)  loss_rpn_box_reg: 0.0595 (0.0684)  time: 0.6857  data: 0.2881  max mem: 5528\n",
      "Training Epoch: [79]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1447 (0.1406)  loss_objectness: 0.0675 (0.0720)  loss_rpn_box_reg: 0.0736 (0.0686)  time: 0.6727  data: 0.2909  max mem: 5528\n",
      "Training Epoch: [79]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1459 (0.1414)  loss_objectness: 0.0783 (0.0723)  loss_rpn_box_reg: 0.0726 (0.0690)  time: 0.6643  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [79]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1597 (0.1421)  loss_objectness: 0.0794 (0.0728)  loss_rpn_box_reg: 0.0736 (0.0693)  time: 0.6767  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [79]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1485 (0.1420)  loss_objectness: 0.0786 (0.0729)  loss_rpn_box_reg: 0.0721 (0.0691)  time: 0.6820  data: 0.2918  max mem: 5528\n",
      "Training Epoch: [79]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1338 (0.1418)  loss_objectness: 0.0753 (0.0729)  loss_rpn_box_reg: 0.0663 (0.0689)  time: 0.6819  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [79]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1412 (0.1423)  loss_objectness: 0.0711 (0.0728)  loss_rpn_box_reg: 0.0672 (0.0695)  time: 0.6852  data: 0.2870  max mem: 5528\n",
      "Training Epoch: [79]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1517 (0.1425)  loss_objectness: 0.0671 (0.0726)  loss_rpn_box_reg: 0.0699 (0.0698)  time: 0.6896  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [79] Total time: 0:02:50 (0.6819 s / it)\n",
      "Testing Epoch: [79]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1353 (0.1353)  loss_objectness: 0.0445 (0.0445)  loss_rpn_box_reg: 0.0909 (0.0909)  time: 0.6251  data: 0.3021  max mem: 5528\n",
      "Testing Epoch: [79]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1271 (0.1370)  loss_objectness: 0.0519 (0.0562)  loss_rpn_box_reg: 0.0703 (0.0809)  time: 0.6334  data: 0.3135  max mem: 5528\n",
      "Testing Epoch: [79] Total time: 0:00:39 (0.6331 s / it)\n",
      "Training Epoch: [80]  [  0/250]  eta: 0:02:52  lr: 0.000300  loss: 0.1379 (0.1379)  loss_objectness: 0.0820 (0.0820)  loss_rpn_box_reg: 0.0560 (0.0560)  time: 0.6902  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [80]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1379 (0.1504)  loss_objectness: 0.0689 (0.0734)  loss_rpn_box_reg: 0.0705 (0.0770)  time: 0.6988  data: 0.3001  max mem: 5528\n",
      "Training Epoch: [80]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1378 (0.1465)  loss_objectness: 0.0686 (0.0735)  loss_rpn_box_reg: 0.0655 (0.0730)  time: 0.6963  data: 0.2966  max mem: 5528\n",
      "Training Epoch: [80]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1343 (0.1426)  loss_objectness: 0.0671 (0.0726)  loss_rpn_box_reg: 0.0634 (0.0700)  time: 0.6891  data: 0.2946  max mem: 5528\n",
      "Training Epoch: [80]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1374 (0.1427)  loss_objectness: 0.0698 (0.0717)  loss_rpn_box_reg: 0.0637 (0.0710)  time: 0.6855  data: 0.2939  max mem: 5528\n",
      "Training Epoch: [80]  [ 50/250]  eta: 0:02:20  lr: 0.000300  loss: 0.1328 (0.1415)  loss_objectness: 0.0684 (0.0717)  loss_rpn_box_reg: 0.0671 (0.0698)  time: 0.7150  data: 0.3026  max mem: 5528\n",
      "Training Epoch: [80]  [ 60/250]  eta: 0:02:12  lr: 0.000300  loss: 0.1202 (0.1388)  loss_objectness: 0.0645 (0.0701)  loss_rpn_box_reg: 0.0603 (0.0687)  time: 0.7159  data: 0.3041  max mem: 5528\n",
      "Training Epoch: [80]  [ 70/250]  eta: 0:02:05  lr: 0.000300  loss: 0.1178 (0.1378)  loss_objectness: 0.0592 (0.0701)  loss_rpn_box_reg: 0.0591 (0.0677)  time: 0.6837  data: 0.2966  max mem: 5528\n",
      "Training Epoch: [80]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1262 (0.1391)  loss_objectness: 0.0619 (0.0705)  loss_rpn_box_reg: 0.0632 (0.0686)  time: 0.6699  data: 0.2970  max mem: 5528\n",
      "Training Epoch: [80]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1369 (0.1388)  loss_objectness: 0.0644 (0.0700)  loss_rpn_box_reg: 0.0690 (0.0688)  time: 0.6757  data: 0.2972  max mem: 5528\n",
      "Training Epoch: [80]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1369 (0.1397)  loss_objectness: 0.0700 (0.0711)  loss_rpn_box_reg: 0.0741 (0.0686)  time: 0.6852  data: 0.2961  max mem: 5528\n",
      "Training Epoch: [80]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1358 (0.1392)  loss_objectness: 0.0697 (0.0710)  loss_rpn_box_reg: 0.0697 (0.0683)  time: 0.6795  data: 0.2968  max mem: 5528\n",
      "Training Epoch: [80]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1368 (0.1397)  loss_objectness: 0.0667 (0.0711)  loss_rpn_box_reg: 0.0721 (0.0685)  time: 0.6915  data: 0.3004  max mem: 5528\n",
      "Training Epoch: [80]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1430 (0.1394)  loss_objectness: 0.0697 (0.0715)  loss_rpn_box_reg: 0.0654 (0.0679)  time: 0.6936  data: 0.3006  max mem: 5528\n",
      "Training Epoch: [80]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1393 (0.1401)  loss_objectness: 0.0697 (0.0717)  loss_rpn_box_reg: 0.0629 (0.0683)  time: 0.6815  data: 0.2959  max mem: 5528\n",
      "Training Epoch: [80]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1393 (0.1403)  loss_objectness: 0.0698 (0.0718)  loss_rpn_box_reg: 0.0742 (0.0685)  time: 0.6832  data: 0.2881  max mem: 5528\n",
      "Training Epoch: [80]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1436 (0.1417)  loss_objectness: 0.0745 (0.0723)  loss_rpn_box_reg: 0.0761 (0.0694)  time: 0.6822  data: 0.2902  max mem: 5528\n",
      "Training Epoch: [80]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1393 (0.1415)  loss_objectness: 0.0708 (0.0720)  loss_rpn_box_reg: 0.0762 (0.0695)  time: 0.6715  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [80]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1360 (0.1417)  loss_objectness: 0.0693 (0.0724)  loss_rpn_box_reg: 0.0693 (0.0694)  time: 0.6838  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [80]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1378 (0.1412)  loss_objectness: 0.0678 (0.0720)  loss_rpn_box_reg: 0.0658 (0.0692)  time: 0.6932  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [80]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1305 (0.1412)  loss_objectness: 0.0690 (0.0721)  loss_rpn_box_reg: 0.0658 (0.0691)  time: 0.6791  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [80]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1304 (0.1416)  loss_objectness: 0.0788 (0.0727)  loss_rpn_box_reg: 0.0630 (0.0689)  time: 0.6853  data: 0.2899  max mem: 5528\n",
      "Training Epoch: [80]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1318 (0.1415)  loss_objectness: 0.0728 (0.0726)  loss_rpn_box_reg: 0.0627 (0.0689)  time: 0.6929  data: 0.2893  max mem: 5528\n",
      "Training Epoch: [80]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1376 (0.1416)  loss_objectness: 0.0715 (0.0730)  loss_rpn_box_reg: 0.0627 (0.0686)  time: 0.6949  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [80]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1390 (0.1419)  loss_objectness: 0.0706 (0.0728)  loss_rpn_box_reg: 0.0670 (0.0691)  time: 0.6903  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [80]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1412 (0.1424)  loss_objectness: 0.0675 (0.0726)  loss_rpn_box_reg: 0.0746 (0.0698)  time: 0.6812  data: 0.2891  max mem: 5528\n",
      "Training Epoch: [80] Total time: 0:02:51 (0.6878 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:00  model_time: 0.6301 (0.6301)  evaluator_time: 0.0560 (0.0560)  time: 0.9792  data: 0.2781  max mem: 5528\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3811 (0.3817)  evaluator_time: 0.0640 (0.0748)  time: 0.7546  data: 0.2940  max mem: 5528\n",
      "Test: Total time: 0:00:47 (0.7647 s / it)\n",
      "Averaged stats: model_time: 0.3811 (0.3817)  evaluator_time: 0.0640 (0.0748)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.016\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.182\n",
      "Testing Epoch: [80]  [ 0/62]  eta: 0:00:46  lr: 0.000300  loss: 0.1340 (0.1340)  loss_objectness: 0.0470 (0.0470)  loss_rpn_box_reg: 0.0869 (0.0869)  time: 0.7482  data: 0.4001  max mem: 5528\n",
      "Testing Epoch: [80]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1330 (0.1396)  loss_objectness: 0.0538 (0.0589)  loss_rpn_box_reg: 0.0746 (0.0807)  time: 0.6333  data: 0.3116  max mem: 5528\n",
      "Testing Epoch: [80] Total time: 0:00:39 (0.6345 s / it)\n",
      "Training Epoch: [81]  [  0/250]  eta: 0:03:02  lr: 0.000300  loss: 0.1333 (0.1333)  loss_objectness: 0.0856 (0.0856)  loss_rpn_box_reg: 0.0477 (0.0477)  time: 0.7312  data: 0.3051  max mem: 5528\n",
      "Training Epoch: [81]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1333 (0.1341)  loss_objectness: 0.0813 (0.0774)  loss_rpn_box_reg: 0.0620 (0.0567)  time: 0.6930  data: 0.2999  max mem: 5528\n",
      "Training Epoch: [81]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1314 (0.1362)  loss_objectness: 0.0724 (0.0728)  loss_rpn_box_reg: 0.0672 (0.0634)  time: 0.6947  data: 0.2999  max mem: 5528\n",
      "Training Epoch: [81]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1417 (0.1392)  loss_objectness: 0.0722 (0.0734)  loss_rpn_box_reg: 0.0704 (0.0658)  time: 0.6846  data: 0.2967  max mem: 5528\n",
      "Training Epoch: [81]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1345 (0.1360)  loss_objectness: 0.0708 (0.0723)  loss_rpn_box_reg: 0.0588 (0.0637)  time: 0.6740  data: 0.2897  max mem: 5528\n",
      "Training Epoch: [81]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1256 (0.1366)  loss_objectness: 0.0628 (0.0712)  loss_rpn_box_reg: 0.0614 (0.0654)  time: 0.6779  data: 0.2891  max mem: 5528\n",
      "Training Epoch: [81]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1428 (0.1396)  loss_objectness: 0.0679 (0.0723)  loss_rpn_box_reg: 0.0699 (0.0673)  time: 0.6759  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [81]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1522 (0.1413)  loss_objectness: 0.0710 (0.0729)  loss_rpn_box_reg: 0.0666 (0.0684)  time: 0.6791  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [81]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1522 (0.1416)  loss_objectness: 0.0713 (0.0737)  loss_rpn_box_reg: 0.0661 (0.0679)  time: 0.6688  data: 0.2904  max mem: 5528\n",
      "Training Epoch: [81]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1529 (0.1430)  loss_objectness: 0.0704 (0.0737)  loss_rpn_box_reg: 0.0685 (0.0692)  time: 0.6597  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [81]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1387 (0.1425)  loss_objectness: 0.0679 (0.0732)  loss_rpn_box_reg: 0.0685 (0.0693)  time: 0.6767  data: 0.2926  max mem: 5528\n",
      "Training Epoch: [81]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1271 (0.1418)  loss_objectness: 0.0656 (0.0730)  loss_rpn_box_reg: 0.0666 (0.0688)  time: 0.6933  data: 0.2902  max mem: 5528\n",
      "Training Epoch: [81]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1270 (0.1417)  loss_objectness: 0.0704 (0.0734)  loss_rpn_box_reg: 0.0601 (0.0683)  time: 0.6864  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [81]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1414 (0.1431)  loss_objectness: 0.0712 (0.0735)  loss_rpn_box_reg: 0.0718 (0.0696)  time: 0.6706  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [81]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1371 (0.1422)  loss_objectness: 0.0690 (0.0732)  loss_rpn_box_reg: 0.0709 (0.0690)  time: 0.6810  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [81]  [150/250]  eta: 0:01:07  lr: 0.000300  loss: 0.1305 (0.1413)  loss_objectness: 0.0682 (0.0727)  loss_rpn_box_reg: 0.0592 (0.0685)  time: 0.6834  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [81]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1407 (0.1421)  loss_objectness: 0.0688 (0.0732)  loss_rpn_box_reg: 0.0669 (0.0688)  time: 0.6818  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [81]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1352 (0.1418)  loss_objectness: 0.0749 (0.0731)  loss_rpn_box_reg: 0.0669 (0.0687)  time: 0.6830  data: 0.2923  max mem: 5528\n",
      "Training Epoch: [81]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1319 (0.1419)  loss_objectness: 0.0612 (0.0728)  loss_rpn_box_reg: 0.0624 (0.0691)  time: 0.6792  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [81]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1388 (0.1417)  loss_objectness: 0.0649 (0.0725)  loss_rpn_box_reg: 0.0695 (0.0692)  time: 0.6963  data: 0.2887  max mem: 5528\n",
      "Training Epoch: [81]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1393 (0.1420)  loss_objectness: 0.0649 (0.0723)  loss_rpn_box_reg: 0.0695 (0.0697)  time: 0.6923  data: 0.2877  max mem: 5528\n",
      "Training Epoch: [81]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1373 (0.1418)  loss_objectness: 0.0752 (0.0723)  loss_rpn_box_reg: 0.0621 (0.0695)  time: 0.6733  data: 0.2909  max mem: 5528\n",
      "Training Epoch: [81]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1348 (0.1422)  loss_objectness: 0.0757 (0.0726)  loss_rpn_box_reg: 0.0614 (0.0697)  time: 0.6687  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [81]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1456 (0.1425)  loss_objectness: 0.0753 (0.0729)  loss_rpn_box_reg: 0.0644 (0.0696)  time: 0.6810  data: 0.2915  max mem: 5528\n",
      "Training Epoch: [81]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1454 (0.1421)  loss_objectness: 0.0736 (0.0725)  loss_rpn_box_reg: 0.0719 (0.0697)  time: 0.6913  data: 0.2961  max mem: 5528\n",
      "Training Epoch: [81]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1380 (0.1429)  loss_objectness: 0.0666 (0.0726)  loss_rpn_box_reg: 0.0775 (0.0704)  time: 0.6863  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [81] Total time: 0:02:50 (0.6812 s / it)\n",
      "Testing Epoch: [81]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1311 (0.1311)  loss_objectness: 0.0423 (0.0423)  loss_rpn_box_reg: 0.0888 (0.0888)  time: 0.6191  data: 0.2871  max mem: 5528\n",
      "Testing Epoch: [81]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1390 (0.1404)  loss_objectness: 0.0628 (0.0606)  loss_rpn_box_reg: 0.0740 (0.0798)  time: 0.6297  data: 0.3079  max mem: 5528\n",
      "Testing Epoch: [81] Total time: 0:00:39 (0.6337 s / it)\n",
      "Training Epoch: [82]  [  0/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1550 (0.1550)  loss_objectness: 0.0809 (0.0809)  loss_rpn_box_reg: 0.0741 (0.0741)  time: 0.6531  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [82]  [ 10/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1437 (0.1454)  loss_objectness: 0.0706 (0.0735)  loss_rpn_box_reg: 0.0741 (0.0718)  time: 0.6896  data: 0.2942  max mem: 5528\n",
      "Training Epoch: [82]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1315 (0.1394)  loss_objectness: 0.0701 (0.0748)  loss_rpn_box_reg: 0.0647 (0.0646)  time: 0.6885  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [82]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1302 (0.1344)  loss_objectness: 0.0664 (0.0718)  loss_rpn_box_reg: 0.0552 (0.0627)  time: 0.6895  data: 0.2882  max mem: 5528\n",
      "Training Epoch: [82]  [ 40/250]  eta: 0:02:26  lr: 0.000300  loss: 0.1328 (0.1364)  loss_objectness: 0.0629 (0.0721)  loss_rpn_box_reg: 0.0612 (0.0643)  time: 0.7045  data: 0.2949  max mem: 5528\n",
      "Training Epoch: [82]  [ 50/250]  eta: 0:02:19  lr: 0.000300  loss: 0.1367 (0.1361)  loss_objectness: 0.0605 (0.0703)  loss_rpn_box_reg: 0.0673 (0.0658)  time: 0.7087  data: 0.2971  max mem: 5528\n",
      "Training Epoch: [82]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1367 (0.1371)  loss_objectness: 0.0662 (0.0703)  loss_rpn_box_reg: 0.0632 (0.0668)  time: 0.6803  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [82]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1491 (0.1387)  loss_objectness: 0.0702 (0.0708)  loss_rpn_box_reg: 0.0752 (0.0679)  time: 0.6751  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [82]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1338 (0.1380)  loss_objectness: 0.0756 (0.0715)  loss_rpn_box_reg: 0.0583 (0.0665)  time: 0.6840  data: 0.2946  max mem: 5528\n",
      "Training Epoch: [82]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1296 (0.1370)  loss_objectness: 0.0676 (0.0709)  loss_rpn_box_reg: 0.0583 (0.0661)  time: 0.6794  data: 0.2891  max mem: 5528\n",
      "Training Epoch: [82]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1384 (0.1381)  loss_objectness: 0.0678 (0.0715)  loss_rpn_box_reg: 0.0632 (0.0667)  time: 0.6927  data: 0.2891  max mem: 5528\n",
      "Training Epoch: [82]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1460 (0.1389)  loss_objectness: 0.0721 (0.0720)  loss_rpn_box_reg: 0.0687 (0.0669)  time: 0.6858  data: 0.2935  max mem: 5528\n",
      "Training Epoch: [82]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1471 (0.1398)  loss_objectness: 0.0746 (0.0724)  loss_rpn_box_reg: 0.0735 (0.0675)  time: 0.6648  data: 0.2940  max mem: 5528\n",
      "Training Epoch: [82]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1490 (0.1406)  loss_objectness: 0.0747 (0.0729)  loss_rpn_box_reg: 0.0732 (0.0678)  time: 0.6739  data: 0.2942  max mem: 5528\n",
      "Training Epoch: [82]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1490 (0.1421)  loss_objectness: 0.0754 (0.0729)  loss_rpn_box_reg: 0.0713 (0.0692)  time: 0.6824  data: 0.2946  max mem: 5528\n",
      "Training Epoch: [82]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1393 (0.1415)  loss_objectness: 0.0654 (0.0721)  loss_rpn_box_reg: 0.0731 (0.0694)  time: 0.6936  data: 0.2940  max mem: 5528\n",
      "Training Epoch: [82]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1276 (0.1418)  loss_objectness: 0.0654 (0.0724)  loss_rpn_box_reg: 0.0699 (0.0694)  time: 0.6984  data: 0.2929  max mem: 5528\n",
      "Training Epoch: [82]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1391 (0.1419)  loss_objectness: 0.0817 (0.0730)  loss_rpn_box_reg: 0.0612 (0.0689)  time: 0.6966  data: 0.2957  max mem: 5528\n",
      "Training Epoch: [82]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1391 (0.1416)  loss_objectness: 0.0677 (0.0724)  loss_rpn_box_reg: 0.0644 (0.0692)  time: 0.7079  data: 0.2957  max mem: 5528\n",
      "Training Epoch: [82]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1385 (0.1421)  loss_objectness: 0.0617 (0.0723)  loss_rpn_box_reg: 0.0731 (0.0698)  time: 0.7022  data: 0.2977  max mem: 5528\n",
      "Training Epoch: [82]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1460 (0.1427)  loss_objectness: 0.0725 (0.0728)  loss_rpn_box_reg: 0.0731 (0.0699)  time: 0.6976  data: 0.2987  max mem: 5528\n",
      "Training Epoch: [82]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1451 (0.1427)  loss_objectness: 0.0782 (0.0730)  loss_rpn_box_reg: 0.0686 (0.0696)  time: 0.7030  data: 0.2948  max mem: 5528\n",
      "Training Epoch: [82]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1384 (0.1425)  loss_objectness: 0.0701 (0.0728)  loss_rpn_box_reg: 0.0686 (0.0697)  time: 0.6961  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [82]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1464 (0.1423)  loss_objectness: 0.0646 (0.0727)  loss_rpn_box_reg: 0.0658 (0.0696)  time: 0.6745  data: 0.2882  max mem: 5528\n",
      "Training Epoch: [82]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1408 (0.1426)  loss_objectness: 0.0697 (0.0727)  loss_rpn_box_reg: 0.0629 (0.0699)  time: 0.6765  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [82]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1369 (0.1425)  loss_objectness: 0.0697 (0.0727)  loss_rpn_box_reg: 0.0629 (0.0698)  time: 0.6715  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [82] Total time: 0:02:51 (0.6880 s / it)\n",
      "Testing Epoch: [82]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1288 (0.1288)  loss_objectness: 0.0402 (0.0402)  loss_rpn_box_reg: 0.0885 (0.0885)  time: 0.6111  data: 0.2881  max mem: 5528\n",
      "Testing Epoch: [82]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1301 (0.1369)  loss_objectness: 0.0573 (0.0569)  loss_rpn_box_reg: 0.0702 (0.0800)  time: 0.6335  data: 0.3087  max mem: 5528\n",
      "Testing Epoch: [82] Total time: 0:00:39 (0.6348 s / it)\n",
      "Training Epoch: [83]  [  0/250]  eta: 0:02:58  lr: 0.000300  loss: 0.0943 (0.0943)  loss_objectness: 0.0643 (0.0643)  loss_rpn_box_reg: 0.0299 (0.0299)  time: 0.7132  data: 0.2971  max mem: 5528\n",
      "Training Epoch: [83]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1335 (0.1322)  loss_objectness: 0.0708 (0.0697)  loss_rpn_box_reg: 0.0637 (0.0625)  time: 0.6741  data: 0.2919  max mem: 5528\n",
      "Training Epoch: [83]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1360 (0.1328)  loss_objectness: 0.0724 (0.0708)  loss_rpn_box_reg: 0.0644 (0.0620)  time: 0.6822  data: 0.2929  max mem: 5528\n",
      "Training Epoch: [83]  [ 30/250]  eta: 0:02:33  lr: 0.000300  loss: 0.1269 (0.1293)  loss_objectness: 0.0662 (0.0680)  loss_rpn_box_reg: 0.0633 (0.0613)  time: 0.7091  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [83]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1302 (0.1290)  loss_objectness: 0.0637 (0.0662)  loss_rpn_box_reg: 0.0632 (0.0627)  time: 0.7069  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [83]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1341 (0.1318)  loss_objectness: 0.0650 (0.0674)  loss_rpn_box_reg: 0.0628 (0.0644)  time: 0.6863  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [83]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1369 (0.1346)  loss_objectness: 0.0716 (0.0680)  loss_rpn_box_reg: 0.0658 (0.0666)  time: 0.6794  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [83]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1448 (0.1351)  loss_objectness: 0.0725 (0.0685)  loss_rpn_box_reg: 0.0690 (0.0666)  time: 0.6911  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [83]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1322 (0.1347)  loss_objectness: 0.0701 (0.0685)  loss_rpn_box_reg: 0.0672 (0.0662)  time: 0.6984  data: 0.2902  max mem: 5528\n",
      "Training Epoch: [83]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1366 (0.1356)  loss_objectness: 0.0676 (0.0687)  loss_rpn_box_reg: 0.0672 (0.0669)  time: 0.6764  data: 0.2888  max mem: 5528\n",
      "Training Epoch: [83]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1415 (0.1366)  loss_objectness: 0.0723 (0.0701)  loss_rpn_box_reg: 0.0663 (0.0665)  time: 0.6750  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [83]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1322 (0.1363)  loss_objectness: 0.0740 (0.0707)  loss_rpn_box_reg: 0.0562 (0.0656)  time: 0.6878  data: 0.2918  max mem: 5528\n",
      "Training Epoch: [83]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1319 (0.1362)  loss_objectness: 0.0678 (0.0706)  loss_rpn_box_reg: 0.0589 (0.0656)  time: 0.6794  data: 0.2887  max mem: 5528\n",
      "Training Epoch: [83]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1319 (0.1364)  loss_objectness: 0.0654 (0.0703)  loss_rpn_box_reg: 0.0673 (0.0661)  time: 0.6903  data: 0.2913  max mem: 5528\n",
      "Training Epoch: [83]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1445 (0.1379)  loss_objectness: 0.0676 (0.0706)  loss_rpn_box_reg: 0.0788 (0.0673)  time: 0.6951  data: 0.2965  max mem: 5528\n",
      "Training Epoch: [83]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1474 (0.1392)  loss_objectness: 0.0691 (0.0707)  loss_rpn_box_reg: 0.0833 (0.0685)  time: 0.6827  data: 0.2971  max mem: 5528\n",
      "Training Epoch: [83]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1471 (0.1399)  loss_objectness: 0.0644 (0.0705)  loss_rpn_box_reg: 0.0813 (0.0694)  time: 0.6964  data: 0.2926  max mem: 5528\n",
      "Training Epoch: [83]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1439 (0.1410)  loss_objectness: 0.0701 (0.0710)  loss_rpn_box_reg: 0.0750 (0.0700)  time: 0.6923  data: 0.2909  max mem: 5528\n",
      "Training Epoch: [83]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1337 (0.1407)  loss_objectness: 0.0726 (0.0709)  loss_rpn_box_reg: 0.0597 (0.0698)  time: 0.6854  data: 0.2938  max mem: 5528\n",
      "Training Epoch: [83]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1276 (0.1407)  loss_objectness: 0.0640 (0.0710)  loss_rpn_box_reg: 0.0617 (0.0697)  time: 0.6924  data: 0.2966  max mem: 5528\n",
      "Training Epoch: [83]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1285 (0.1409)  loss_objectness: 0.0660 (0.0712)  loss_rpn_box_reg: 0.0655 (0.0696)  time: 0.6905  data: 0.2960  max mem: 5528\n",
      "Training Epoch: [83]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1443 (0.1414)  loss_objectness: 0.0729 (0.0714)  loss_rpn_box_reg: 0.0655 (0.0699)  time: 0.6970  data: 0.2948  max mem: 5528\n",
      "Training Epoch: [83]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1358 (0.1412)  loss_objectness: 0.0717 (0.0713)  loss_rpn_box_reg: 0.0668 (0.0699)  time: 0.6967  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [83]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1253 (0.1406)  loss_objectness: 0.0639 (0.0710)  loss_rpn_box_reg: 0.0668 (0.0696)  time: 0.6738  data: 0.2858  max mem: 5528\n",
      "Training Epoch: [83]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1347 (0.1410)  loss_objectness: 0.0648 (0.0712)  loss_rpn_box_reg: 0.0538 (0.0698)  time: 0.6711  data: 0.2863  max mem: 5528\n",
      "Training Epoch: [83]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1286 (0.1405)  loss_objectness: 0.0698 (0.0710)  loss_rpn_box_reg: 0.0583 (0.0695)  time: 0.6767  data: 0.2850  max mem: 5528\n",
      "Training Epoch: [83] Total time: 0:02:51 (0.6876 s / it)\n",
      "Testing Epoch: [83]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1297 (0.1297)  loss_objectness: 0.0420 (0.0420)  loss_rpn_box_reg: 0.0877 (0.0877)  time: 0.6111  data: 0.2871  max mem: 5528\n",
      "Testing Epoch: [83]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1264 (0.1366)  loss_objectness: 0.0494 (0.0577)  loss_rpn_box_reg: 0.0725 (0.0789)  time: 0.6315  data: 0.3097  max mem: 5528\n",
      "Testing Epoch: [83] Total time: 0:00:39 (0.6333 s / it)\n",
      "Training Epoch: [84]  [  0/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1175 (0.1175)  loss_objectness: 0.0563 (0.0563)  loss_rpn_box_reg: 0.0612 (0.0612)  time: 0.6251  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [84]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1325 (0.1314)  loss_objectness: 0.0710 (0.0700)  loss_rpn_box_reg: 0.0644 (0.0614)  time: 0.6938  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [84]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1479 (0.1450)  loss_objectness: 0.0724 (0.0717)  loss_rpn_box_reg: 0.0728 (0.0732)  time: 0.6949  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [84]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1537 (0.1422)  loss_objectness: 0.0664 (0.0708)  loss_rpn_box_reg: 0.0755 (0.0714)  time: 0.6837  data: 0.2886  max mem: 5528\n",
      "Training Epoch: [84]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1343 (0.1411)  loss_objectness: 0.0645 (0.0706)  loss_rpn_box_reg: 0.0630 (0.0705)  time: 0.6807  data: 0.2939  max mem: 5528\n",
      "Training Epoch: [84]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1332 (0.1404)  loss_objectness: 0.0661 (0.0700)  loss_rpn_box_reg: 0.0670 (0.0704)  time: 0.6711  data: 0.2978  max mem: 5528\n",
      "Training Epoch: [84]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1305 (0.1392)  loss_objectness: 0.0661 (0.0705)  loss_rpn_box_reg: 0.0630 (0.0688)  time: 0.6643  data: 0.2940  max mem: 5528\n",
      "Training Epoch: [84]  [ 70/250]  eta: 0:02:01  lr: 0.000300  loss: 0.1309 (0.1390)  loss_objectness: 0.0672 (0.0706)  loss_rpn_box_reg: 0.0583 (0.0685)  time: 0.6695  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [84]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1340 (0.1408)  loss_objectness: 0.0706 (0.0706)  loss_rpn_box_reg: 0.0704 (0.0701)  time: 0.6770  data: 0.2905  max mem: 5528\n",
      "Training Epoch: [84]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1429 (0.1415)  loss_objectness: 0.0671 (0.0706)  loss_rpn_box_reg: 0.0721 (0.0710)  time: 0.6772  data: 0.2904  max mem: 5528\n",
      "Training Epoch: [84]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1427 (0.1411)  loss_objectness: 0.0671 (0.0704)  loss_rpn_box_reg: 0.0692 (0.0708)  time: 0.6792  data: 0.2902  max mem: 5528\n",
      "Training Epoch: [84]  [110/250]  eta: 0:01:34  lr: 0.000300  loss: 0.1324 (0.1409)  loss_objectness: 0.0702 (0.0708)  loss_rpn_box_reg: 0.0670 (0.0701)  time: 0.6673  data: 0.2895  max mem: 5528\n",
      "Training Epoch: [84]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1293 (0.1404)  loss_objectness: 0.0666 (0.0706)  loss_rpn_box_reg: 0.0670 (0.0698)  time: 0.6748  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [84]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1397 (0.1408)  loss_objectness: 0.0704 (0.0709)  loss_rpn_box_reg: 0.0665 (0.0699)  time: 0.6982  data: 0.2913  max mem: 5528\n",
      "Training Epoch: [84]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1469 (0.1418)  loss_objectness: 0.0771 (0.0718)  loss_rpn_box_reg: 0.0661 (0.0700)  time: 0.6926  data: 0.2936  max mem: 5528\n",
      "Training Epoch: [84]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1485 (0.1428)  loss_objectness: 0.0838 (0.0723)  loss_rpn_box_reg: 0.0672 (0.0704)  time: 0.6903  data: 0.2962  max mem: 5528\n",
      "Training Epoch: [84]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1421 (0.1435)  loss_objectness: 0.0780 (0.0725)  loss_rpn_box_reg: 0.0721 (0.0709)  time: 0.6858  data: 0.2927  max mem: 5528\n",
      "Training Epoch: [84]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1333 (0.1435)  loss_objectness: 0.0770 (0.0729)  loss_rpn_box_reg: 0.0685 (0.0706)  time: 0.6922  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [84]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1333 (0.1428)  loss_objectness: 0.0769 (0.0727)  loss_rpn_box_reg: 0.0595 (0.0701)  time: 0.7015  data: 0.2938  max mem: 5528\n",
      "Training Epoch: [84]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1304 (0.1424)  loss_objectness: 0.0687 (0.0728)  loss_rpn_box_reg: 0.0582 (0.0695)  time: 0.6927  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [84]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1285 (0.1424)  loss_objectness: 0.0677 (0.0727)  loss_rpn_box_reg: 0.0582 (0.0697)  time: 0.6905  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [84]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1298 (0.1422)  loss_objectness: 0.0672 (0.0725)  loss_rpn_box_reg: 0.0607 (0.0697)  time: 0.6916  data: 0.2927  max mem: 5528\n",
      "Training Epoch: [84]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1390 (0.1423)  loss_objectness: 0.0581 (0.0722)  loss_rpn_box_reg: 0.0714 (0.0701)  time: 0.6834  data: 0.2906  max mem: 5528\n",
      "Training Epoch: [84]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1275 (0.1419)  loss_objectness: 0.0702 (0.0722)  loss_rpn_box_reg: 0.0573 (0.0697)  time: 0.6752  data: 0.2880  max mem: 5528\n",
      "Training Epoch: [84]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1275 (0.1416)  loss_objectness: 0.0718 (0.0722)  loss_rpn_box_reg: 0.0560 (0.0694)  time: 0.6822  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [84]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1380 (0.1415)  loss_objectness: 0.0729 (0.0722)  loss_rpn_box_reg: 0.0651 (0.0694)  time: 0.6890  data: 0.2899  max mem: 5528\n",
      "Training Epoch: [84] Total time: 0:02:50 (0.6837 s / it)\n",
      "Testing Epoch: [84]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1389 (0.1389)  loss_objectness: 0.0436 (0.0436)  loss_rpn_box_reg: 0.0953 (0.0953)  time: 0.6091  data: 0.2871  max mem: 5528\n",
      "Testing Epoch: [84]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1297 (0.1398)  loss_objectness: 0.0546 (0.0580)  loss_rpn_box_reg: 0.0747 (0.0818)  time: 0.6306  data: 0.3055  max mem: 5528\n",
      "Testing Epoch: [84] Total time: 0:00:39 (0.6344 s / it)\n",
      "Training Epoch: [85]  [  0/250]  eta: 0:03:03  lr: 0.000300  loss: 0.1431 (0.1431)  loss_objectness: 0.0693 (0.0693)  loss_rpn_box_reg: 0.0738 (0.0738)  time: 0.7352  data: 0.2971  max mem: 5528\n",
      "Training Epoch: [85]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1342 (0.1366)  loss_objectness: 0.0565 (0.0634)  loss_rpn_box_reg: 0.0760 (0.0732)  time: 0.6813  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [85]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1302 (0.1394)  loss_objectness: 0.0663 (0.0695)  loss_rpn_box_reg: 0.0605 (0.0699)  time: 0.6825  data: 0.2952  max mem: 5528\n",
      "Training Epoch: [85]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1191 (0.1340)  loss_objectness: 0.0664 (0.0668)  loss_rpn_box_reg: 0.0517 (0.0672)  time: 0.6914  data: 0.2967  max mem: 5528\n",
      "Training Epoch: [85]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1297 (0.1368)  loss_objectness: 0.0664 (0.0701)  loss_rpn_box_reg: 0.0582 (0.0667)  time: 0.6921  data: 0.2959  max mem: 5528\n",
      "Training Epoch: [85]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1297 (0.1343)  loss_objectness: 0.0626 (0.0690)  loss_rpn_box_reg: 0.0609 (0.0653)  time: 0.6843  data: 0.2886  max mem: 5528\n",
      "Training Epoch: [85]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1218 (0.1346)  loss_objectness: 0.0609 (0.0685)  loss_rpn_box_reg: 0.0665 (0.0660)  time: 0.6864  data: 0.2878  max mem: 5528\n",
      "Training Epoch: [85]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1354 (0.1373)  loss_objectness: 0.0646 (0.0693)  loss_rpn_box_reg: 0.0732 (0.0680)  time: 0.7045  data: 0.2939  max mem: 5528\n",
      "Training Epoch: [85]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1399 (0.1392)  loss_objectness: 0.0730 (0.0706)  loss_rpn_box_reg: 0.0753 (0.0686)  time: 0.6858  data: 0.2919  max mem: 5528\n",
      "Training Epoch: [85]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1393 (0.1386)  loss_objectness: 0.0648 (0.0703)  loss_rpn_box_reg: 0.0643 (0.0682)  time: 0.6816  data: 0.2889  max mem: 5528\n",
      "Training Epoch: [85]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1393 (0.1383)  loss_objectness: 0.0601 (0.0701)  loss_rpn_box_reg: 0.0566 (0.0682)  time: 0.6843  data: 0.2886  max mem: 5528\n",
      "Training Epoch: [85]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1304 (0.1390)  loss_objectness: 0.0652 (0.0701)  loss_rpn_box_reg: 0.0566 (0.0689)  time: 0.6799  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [85]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1506 (0.1406)  loss_objectness: 0.0704 (0.0704)  loss_rpn_box_reg: 0.0741 (0.0702)  time: 0.7000  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [85]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1506 (0.1404)  loss_objectness: 0.0709 (0.0703)  loss_rpn_box_reg: 0.0741 (0.0701)  time: 0.7018  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [85]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1382 (0.1405)  loss_objectness: 0.0706 (0.0706)  loss_rpn_box_reg: 0.0677 (0.0700)  time: 0.6944  data: 0.2932  max mem: 5528\n",
      "Training Epoch: [85]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1429 (0.1413)  loss_objectness: 0.0711 (0.0709)  loss_rpn_box_reg: 0.0695 (0.0704)  time: 0.6840  data: 0.2951  max mem: 5528\n",
      "Training Epoch: [85]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1503 (0.1412)  loss_objectness: 0.0710 (0.0705)  loss_rpn_box_reg: 0.0725 (0.0707)  time: 0.6785  data: 0.2895  max mem: 5528\n",
      "Training Epoch: [85]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1273 (0.1407)  loss_objectness: 0.0652 (0.0706)  loss_rpn_box_reg: 0.0605 (0.0702)  time: 0.6791  data: 0.2904  max mem: 5528\n",
      "Training Epoch: [85]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1258 (0.1397)  loss_objectness: 0.0643 (0.0704)  loss_rpn_box_reg: 0.0503 (0.0694)  time: 0.6728  data: 0.2969  max mem: 5528\n",
      "Training Epoch: [85]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1290 (0.1396)  loss_objectness: 0.0642 (0.0702)  loss_rpn_box_reg: 0.0642 (0.0693)  time: 0.6578  data: 0.2919  max mem: 5528\n",
      "Training Epoch: [85]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1394 (0.1400)  loss_objectness: 0.0692 (0.0705)  loss_rpn_box_reg: 0.0690 (0.0695)  time: 0.6577  data: 0.2922  max mem: 5528\n",
      "Training Epoch: [85]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1461 (0.1398)  loss_objectness: 0.0629 (0.0702)  loss_rpn_box_reg: 0.0662 (0.0695)  time: 0.6649  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [85]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1461 (0.1404)  loss_objectness: 0.0724 (0.0706)  loss_rpn_box_reg: 0.0667 (0.0698)  time: 0.6799  data: 0.2906  max mem: 5528\n",
      "Training Epoch: [85]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1442 (0.1403)  loss_objectness: 0.0750 (0.0706)  loss_rpn_box_reg: 0.0667 (0.0696)  time: 0.6960  data: 0.2922  max mem: 5528\n",
      "Training Epoch: [85]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1338 (0.1404)  loss_objectness: 0.0662 (0.0708)  loss_rpn_box_reg: 0.0661 (0.0696)  time: 0.6805  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [85]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1423 (0.1406)  loss_objectness: 0.0674 (0.0708)  loss_rpn_box_reg: 0.0691 (0.0698)  time: 0.6785  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [85] Total time: 0:02:50 (0.6834 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:00:59  model_time: 0.6161 (0.6161)  evaluator_time: 0.0500 (0.0500)  time: 0.9602  data: 0.2781  max mem: 5528\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3771 (0.3752)  evaluator_time: 0.0650 (0.0751)  time: 0.7570  data: 0.3016  max mem: 5528\n",
      "Test: Total time: 0:00:46 (0.7575 s / it)\n",
      "Averaged stats: model_time: 0.3771 (0.3752)  evaluator_time: 0.0650 (0.0751)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.00s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.173\n",
      "Testing Epoch: [85]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1329 (0.1329)  loss_objectness: 0.0454 (0.0454)  loss_rpn_box_reg: 0.0875 (0.0875)  time: 0.6101  data: 0.2871  max mem: 5528\n",
      "Testing Epoch: [85]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1315 (0.1379)  loss_objectness: 0.0522 (0.0582)  loss_rpn_box_reg: 0.0720 (0.0796)  time: 0.6293  data: 0.3103  max mem: 5528\n",
      "Testing Epoch: [85] Total time: 0:00:39 (0.6308 s / it)\n",
      "Training Epoch: [86]  [  0/250]  eta: 0:02:44  lr: 0.000300  loss: 0.0908 (0.0908)  loss_objectness: 0.0469 (0.0469)  loss_rpn_box_reg: 0.0438 (0.0438)  time: 0.6581  data: 0.2951  max mem: 5528\n",
      "Training Epoch: [86]  [ 10/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1338 (0.1375)  loss_objectness: 0.0778 (0.0772)  loss_rpn_box_reg: 0.0596 (0.0603)  time: 0.6661  data: 0.2888  max mem: 5528\n",
      "Training Epoch: [86]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1417 (0.1434)  loss_objectness: 0.0778 (0.0762)  loss_rpn_box_reg: 0.0678 (0.0672)  time: 0.6820  data: 0.2867  max mem: 5528\n",
      "Training Epoch: [86]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1373 (0.1413)  loss_objectness: 0.0744 (0.0756)  loss_rpn_box_reg: 0.0676 (0.0657)  time: 0.6897  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [86]  [ 40/250]  eta: 0:02:21  lr: 0.000300  loss: 0.1373 (0.1441)  loss_objectness: 0.0744 (0.0771)  loss_rpn_box_reg: 0.0612 (0.0670)  time: 0.6700  data: 0.2905  max mem: 5528\n",
      "Training Epoch: [86]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1437 (0.1411)  loss_objectness: 0.0694 (0.0751)  loss_rpn_box_reg: 0.0636 (0.0660)  time: 0.6678  data: 0.2891  max mem: 5528\n",
      "Training Epoch: [86]  [ 60/250]  eta: 0:02:08  lr: 0.000300  loss: 0.1395 (0.1414)  loss_objectness: 0.0666 (0.0746)  loss_rpn_box_reg: 0.0636 (0.0668)  time: 0.6795  data: 0.2899  max mem: 5528\n",
      "Training Epoch: [86]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1354 (0.1407)  loss_objectness: 0.0666 (0.0736)  loss_rpn_box_reg: 0.0748 (0.0672)  time: 0.6854  data: 0.2892  max mem: 5528\n",
      "Training Epoch: [86]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1272 (0.1395)  loss_objectness: 0.0640 (0.0726)  loss_rpn_box_reg: 0.0700 (0.0669)  time: 0.6883  data: 0.2904  max mem: 5528\n",
      "Training Epoch: [86]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1210 (0.1380)  loss_objectness: 0.0608 (0.0711)  loss_rpn_box_reg: 0.0666 (0.0669)  time: 0.6877  data: 0.2896  max mem: 5528\n",
      "Training Epoch: [86]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1227 (0.1375)  loss_objectness: 0.0605 (0.0704)  loss_rpn_box_reg: 0.0665 (0.0672)  time: 0.6815  data: 0.2870  max mem: 5528\n",
      "Training Epoch: [86]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1291 (0.1378)  loss_objectness: 0.0698 (0.0708)  loss_rpn_box_reg: 0.0624 (0.0671)  time: 0.6865  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [86]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1291 (0.1386)  loss_objectness: 0.0709 (0.0715)  loss_rpn_box_reg: 0.0551 (0.0671)  time: 0.6877  data: 0.2926  max mem: 5528\n",
      "Training Epoch: [86]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1430 (0.1398)  loss_objectness: 0.0759 (0.0722)  loss_rpn_box_reg: 0.0590 (0.0676)  time: 0.6633  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [86]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1444 (0.1402)  loss_objectness: 0.0733 (0.0720)  loss_rpn_box_reg: 0.0665 (0.0682)  time: 0.6607  data: 0.2899  max mem: 5528\n",
      "Training Epoch: [86]  [150/250]  eta: 0:01:07  lr: 0.000300  loss: 0.1481 (0.1405)  loss_objectness: 0.0674 (0.0721)  loss_rpn_box_reg: 0.0675 (0.0685)  time: 0.6798  data: 0.2864  max mem: 5528\n",
      "Training Epoch: [86]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1481 (0.1410)  loss_objectness: 0.0720 (0.0723)  loss_rpn_box_reg: 0.0668 (0.0687)  time: 0.6796  data: 0.2877  max mem: 5528\n",
      "Training Epoch: [86]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1505 (0.1415)  loss_objectness: 0.0778 (0.0730)  loss_rpn_box_reg: 0.0627 (0.0685)  time: 0.6756  data: 0.2936  max mem: 5528\n",
      "Training Epoch: [86]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1505 (0.1422)  loss_objectness: 0.0793 (0.0735)  loss_rpn_box_reg: 0.0708 (0.0687)  time: 0.6790  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [86]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1492 (0.1425)  loss_objectness: 0.0747 (0.0736)  loss_rpn_box_reg: 0.0827 (0.0689)  time: 0.6810  data: 0.2889  max mem: 5528\n",
      "Training Epoch: [86]  [200/250]  eta: 0:00:33  lr: 0.000300  loss: 0.1440 (0.1430)  loss_objectness: 0.0685 (0.0733)  loss_rpn_box_reg: 0.0839 (0.0697)  time: 0.6850  data: 0.2880  max mem: 5528\n",
      "Training Epoch: [86]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1383 (0.1428)  loss_objectness: 0.0627 (0.0730)  loss_rpn_box_reg: 0.0740 (0.0698)  time: 0.6822  data: 0.2893  max mem: 5528\n",
      "Training Epoch: [86]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1355 (0.1424)  loss_objectness: 0.0663 (0.0728)  loss_rpn_box_reg: 0.0606 (0.0696)  time: 0.6934  data: 0.2885  max mem: 5528\n",
      "Training Epoch: [86]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1303 (0.1421)  loss_objectness: 0.0700 (0.0728)  loss_rpn_box_reg: 0.0605 (0.0693)  time: 0.7069  data: 0.2897  max mem: 5528\n",
      "Training Epoch: [86]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1303 (0.1416)  loss_objectness: 0.0641 (0.0725)  loss_rpn_box_reg: 0.0578 (0.0691)  time: 0.6966  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [86]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1389 (0.1419)  loss_objectness: 0.0638 (0.0724)  loss_rpn_box_reg: 0.0650 (0.0695)  time: 0.6876  data: 0.2888  max mem: 5528\n",
      "Training Epoch: [86] Total time: 0:02:50 (0.6824 s / it)\n",
      "Testing Epoch: [86]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1346 (0.1346)  loss_objectness: 0.0459 (0.0459)  loss_rpn_box_reg: 0.0887 (0.0887)  time: 0.6141  data: 0.2931  max mem: 5528\n",
      "Testing Epoch: [86]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1330 (0.1378)  loss_objectness: 0.0533 (0.0579)  loss_rpn_box_reg: 0.0726 (0.0799)  time: 0.6227  data: 0.3039  max mem: 5528\n",
      "Testing Epoch: [86] Total time: 0:00:39 (0.6325 s / it)\n",
      "Training Epoch: [87]  [  0/250]  eta: 0:03:03  lr: 0.000300  loss: 0.1321 (0.1321)  loss_objectness: 0.0494 (0.0494)  loss_rpn_box_reg: 0.0827 (0.0827)  time: 0.7342  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [87]  [ 10/250]  eta: 0:02:49  lr: 0.000300  loss: 0.1352 (0.1353)  loss_objectness: 0.0651 (0.0699)  loss_rpn_box_reg: 0.0607 (0.0655)  time: 0.7082  data: 0.2897  max mem: 5528\n",
      "Training Epoch: [87]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1376 (0.1382)  loss_objectness: 0.0657 (0.0704)  loss_rpn_box_reg: 0.0600 (0.0678)  time: 0.6929  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [87]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1174 (0.1297)  loss_objectness: 0.0601 (0.0660)  loss_rpn_box_reg: 0.0573 (0.0637)  time: 0.6772  data: 0.2870  max mem: 5528\n",
      "Training Epoch: [87]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1173 (0.1305)  loss_objectness: 0.0600 (0.0663)  loss_rpn_box_reg: 0.0573 (0.0642)  time: 0.6827  data: 0.2867  max mem: 5528\n",
      "Training Epoch: [87]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1374 (0.1325)  loss_objectness: 0.0661 (0.0682)  loss_rpn_box_reg: 0.0629 (0.0642)  time: 0.6841  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [87]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1382 (0.1348)  loss_objectness: 0.0777 (0.0702)  loss_rpn_box_reg: 0.0629 (0.0646)  time: 0.6812  data: 0.2942  max mem: 5528\n",
      "Training Epoch: [87]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1362 (0.1352)  loss_objectness: 0.0723 (0.0694)  loss_rpn_box_reg: 0.0588 (0.0658)  time: 0.6799  data: 0.2902  max mem: 5528\n",
      "Training Epoch: [87]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1439 (0.1370)  loss_objectness: 0.0694 (0.0708)  loss_rpn_box_reg: 0.0647 (0.0661)  time: 0.6784  data: 0.2915  max mem: 5528\n",
      "Training Epoch: [87]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1514 (0.1376)  loss_objectness: 0.0760 (0.0713)  loss_rpn_box_reg: 0.0647 (0.0663)  time: 0.6750  data: 0.2942  max mem: 5528\n",
      "Training Epoch: [87]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1520 (0.1399)  loss_objectness: 0.0760 (0.0724)  loss_rpn_box_reg: 0.0671 (0.0675)  time: 0.6702  data: 0.2946  max mem: 5528\n",
      "Training Epoch: [87]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1506 (0.1402)  loss_objectness: 0.0742 (0.0722)  loss_rpn_box_reg: 0.0682 (0.0680)  time: 0.6811  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [87]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1364 (0.1389)  loss_objectness: 0.0661 (0.0716)  loss_rpn_box_reg: 0.0602 (0.0672)  time: 0.7015  data: 0.2918  max mem: 5528\n",
      "Training Epoch: [87]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1263 (0.1388)  loss_objectness: 0.0638 (0.0713)  loss_rpn_box_reg: 0.0598 (0.0675)  time: 0.7009  data: 0.2884  max mem: 5528\n",
      "Training Epoch: [87]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1342 (0.1388)  loss_objectness: 0.0702 (0.0710)  loss_rpn_box_reg: 0.0615 (0.0678)  time: 0.6776  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [87]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1401 (0.1388)  loss_objectness: 0.0702 (0.0710)  loss_rpn_box_reg: 0.0660 (0.0678)  time: 0.6861  data: 0.2949  max mem: 5528\n",
      "Training Epoch: [87]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1401 (0.1381)  loss_objectness: 0.0667 (0.0707)  loss_rpn_box_reg: 0.0631 (0.0674)  time: 0.6957  data: 0.2951  max mem: 5528\n",
      "Training Epoch: [87]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1320 (0.1380)  loss_objectness: 0.0659 (0.0707)  loss_rpn_box_reg: 0.0648 (0.0674)  time: 0.6843  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [87]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1412 (0.1382)  loss_objectness: 0.0685 (0.0704)  loss_rpn_box_reg: 0.0705 (0.0678)  time: 0.6900  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [87]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1420 (0.1386)  loss_objectness: 0.0646 (0.0704)  loss_rpn_box_reg: 0.0742 (0.0682)  time: 0.6937  data: 0.2887  max mem: 5528\n",
      "Training Epoch: [87]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1472 (0.1393)  loss_objectness: 0.0664 (0.0705)  loss_rpn_box_reg: 0.0757 (0.0688)  time: 0.7011  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [87]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1446 (0.1391)  loss_objectness: 0.0688 (0.0705)  loss_rpn_box_reg: 0.0603 (0.0686)  time: 0.6942  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [87]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1289 (0.1396)  loss_objectness: 0.0703 (0.0710)  loss_rpn_box_reg: 0.0677 (0.0686)  time: 0.6935  data: 0.2971  max mem: 5528\n",
      "Training Epoch: [87]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1539 (0.1400)  loss_objectness: 0.0716 (0.0710)  loss_rpn_box_reg: 0.0753 (0.0691)  time: 0.6928  data: 0.2959  max mem: 5528\n",
      "Training Epoch: [87]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1479 (0.1403)  loss_objectness: 0.0682 (0.0711)  loss_rpn_box_reg: 0.0686 (0.0692)  time: 0.6686  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [87]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1315 (0.1400)  loss_objectness: 0.0682 (0.0709)  loss_rpn_box_reg: 0.0622 (0.0691)  time: 0.6820  data: 0.2898  max mem: 5528\n",
      "Training Epoch: [87] Total time: 0:02:51 (0.6868 s / it)\n",
      "Testing Epoch: [87]  [ 0/62]  eta: 0:00:46  lr: 0.000300  loss: 0.1343 (0.1343)  loss_objectness: 0.0468 (0.0468)  loss_rpn_box_reg: 0.0875 (0.0875)  time: 0.7492  data: 0.3971  max mem: 5528\n",
      "Testing Epoch: [87]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1243 (0.1409)  loss_objectness: 0.0529 (0.0602)  loss_rpn_box_reg: 0.0726 (0.0807)  time: 0.6317  data: 0.3111  max mem: 5528\n",
      "Testing Epoch: [87] Total time: 0:00:39 (0.6385 s / it)\n",
      "Training Epoch: [88]  [  0/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1813 (0.1813)  loss_objectness: 0.0817 (0.0817)  loss_rpn_box_reg: 0.0995 (0.0995)  time: 0.6692  data: 0.3011  max mem: 5528\n",
      "Training Epoch: [88]  [ 10/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1356 (0.1416)  loss_objectness: 0.0715 (0.0698)  loss_rpn_box_reg: 0.0679 (0.0718)  time: 0.6764  data: 0.2896  max mem: 5528\n",
      "Training Epoch: [88]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1254 (0.1345)  loss_objectness: 0.0571 (0.0690)  loss_rpn_box_reg: 0.0536 (0.0655)  time: 0.6795  data: 0.2870  max mem: 5528\n",
      "Training Epoch: [88]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1271 (0.1348)  loss_objectness: 0.0633 (0.0694)  loss_rpn_box_reg: 0.0520 (0.0655)  time: 0.6853  data: 0.2882  max mem: 5528\n",
      "Training Epoch: [88]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1332 (0.1348)  loss_objectness: 0.0660 (0.0681)  loss_rpn_box_reg: 0.0650 (0.0666)  time: 0.6867  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [88]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1407 (0.1390)  loss_objectness: 0.0665 (0.0690)  loss_rpn_box_reg: 0.0715 (0.0699)  time: 0.6922  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [88]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1320 (0.1359)  loss_objectness: 0.0707 (0.0683)  loss_rpn_box_reg: 0.0632 (0.0676)  time: 0.6834  data: 0.2936  max mem: 5528\n",
      "Training Epoch: [88]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1189 (0.1352)  loss_objectness: 0.0659 (0.0686)  loss_rpn_box_reg: 0.0537 (0.0666)  time: 0.6766  data: 0.2895  max mem: 5528\n",
      "Training Epoch: [88]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1208 (0.1336)  loss_objectness: 0.0655 (0.0683)  loss_rpn_box_reg: 0.0548 (0.0654)  time: 0.6835  data: 0.2914  max mem: 5528\n",
      "Training Epoch: [88]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1259 (0.1334)  loss_objectness: 0.0608 (0.0677)  loss_rpn_box_reg: 0.0608 (0.0657)  time: 0.6845  data: 0.2929  max mem: 5528\n",
      "Training Epoch: [88]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1338 (0.1350)  loss_objectness: 0.0661 (0.0690)  loss_rpn_box_reg: 0.0649 (0.0660)  time: 0.6871  data: 0.2909  max mem: 5528\n",
      "Training Epoch: [88]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1317 (0.1365)  loss_objectness: 0.0723 (0.0698)  loss_rpn_box_reg: 0.0659 (0.0667)  time: 0.6923  data: 0.2927  max mem: 5528\n",
      "Training Epoch: [88]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1314 (0.1360)  loss_objectness: 0.0692 (0.0698)  loss_rpn_box_reg: 0.0657 (0.0662)  time: 0.6931  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [88]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1323 (0.1366)  loss_objectness: 0.0704 (0.0699)  loss_rpn_box_reg: 0.0624 (0.0667)  time: 0.6715  data: 0.2856  max mem: 5528\n",
      "Training Epoch: [88]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1400 (0.1370)  loss_objectness: 0.0741 (0.0704)  loss_rpn_box_reg: 0.0651 (0.0665)  time: 0.6650  data: 0.2884  max mem: 5528\n",
      "Training Epoch: [88]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1419 (0.1381)  loss_objectness: 0.0707 (0.0706)  loss_rpn_box_reg: 0.0598 (0.0675)  time: 0.6825  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [88]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1479 (0.1384)  loss_objectness: 0.0733 (0.0706)  loss_rpn_box_reg: 0.0675 (0.0678)  time: 0.6813  data: 0.2902  max mem: 5528\n",
      "Training Epoch: [88]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1358 (0.1386)  loss_objectness: 0.0661 (0.0706)  loss_rpn_box_reg: 0.0667 (0.0680)  time: 0.6771  data: 0.2915  max mem: 5528\n",
      "Training Epoch: [88]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1327 (0.1383)  loss_objectness: 0.0646 (0.0704)  loss_rpn_box_reg: 0.0656 (0.0680)  time: 0.6925  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [88]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1328 (0.1388)  loss_objectness: 0.0731 (0.0706)  loss_rpn_box_reg: 0.0642 (0.0682)  time: 0.6930  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [88]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1510 (0.1393)  loss_objectness: 0.0743 (0.0708)  loss_rpn_box_reg: 0.0675 (0.0685)  time: 0.6889  data: 0.2951  max mem: 5528\n",
      "Training Epoch: [88]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1530 (0.1397)  loss_objectness: 0.0627 (0.0705)  loss_rpn_box_reg: 0.0748 (0.0693)  time: 0.6844  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [88]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1536 (0.1399)  loss_objectness: 0.0615 (0.0704)  loss_rpn_box_reg: 0.0765 (0.0695)  time: 0.6771  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [88]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1466 (0.1402)  loss_objectness: 0.0658 (0.0707)  loss_rpn_box_reg: 0.0692 (0.0695)  time: 0.6889  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [88]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1466 (0.1403)  loss_objectness: 0.0693 (0.0710)  loss_rpn_box_reg: 0.0665 (0.0693)  time: 0.6805  data: 0.2919  max mem: 5528\n",
      "Training Epoch: [88]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1454 (0.1405)  loss_objectness: 0.0746 (0.0712)  loss_rpn_box_reg: 0.0665 (0.0694)  time: 0.6738  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [88] Total time: 0:02:50 (0.6832 s / it)\n",
      "Testing Epoch: [88]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1404 (0.1404)  loss_objectness: 0.0501 (0.0501)  loss_rpn_box_reg: 0.0903 (0.0903)  time: 0.6321  data: 0.3081  max mem: 5528\n",
      "Testing Epoch: [88]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1376 (0.1429)  loss_objectness: 0.0615 (0.0621)  loss_rpn_box_reg: 0.0697 (0.0808)  time: 0.6258  data: 0.3063  max mem: 5528\n",
      "Testing Epoch: [88] Total time: 0:00:39 (0.6325 s / it)\n",
      "Training Epoch: [89]  [  0/250]  eta: 0:03:09  lr: 0.000300  loss: 0.0944 (0.0944)  loss_objectness: 0.0529 (0.0529)  loss_rpn_box_reg: 0.0415 (0.0415)  time: 0.7562  data: 0.2971  max mem: 5528\n",
      "Training Epoch: [89]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1342 (0.1341)  loss_objectness: 0.0661 (0.0666)  loss_rpn_box_reg: 0.0705 (0.0674)  time: 0.6932  data: 0.2923  max mem: 5528\n",
      "Training Epoch: [89]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1342 (0.1335)  loss_objectness: 0.0661 (0.0643)  loss_rpn_box_reg: 0.0727 (0.0692)  time: 0.6909  data: 0.2918  max mem: 5528\n",
      "Training Epoch: [89]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1331 (0.1350)  loss_objectness: 0.0654 (0.0658)  loss_rpn_box_reg: 0.0677 (0.0692)  time: 0.6913  data: 0.2918  max mem: 5528\n",
      "Training Epoch: [89]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1331 (0.1345)  loss_objectness: 0.0699 (0.0664)  loss_rpn_box_reg: 0.0677 (0.0681)  time: 0.6824  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [89]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1296 (0.1348)  loss_objectness: 0.0705 (0.0671)  loss_rpn_box_reg: 0.0637 (0.0677)  time: 0.6825  data: 0.2954  max mem: 5528\n",
      "Training Epoch: [89]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1266 (0.1346)  loss_objectness: 0.0631 (0.0666)  loss_rpn_box_reg: 0.0637 (0.0680)  time: 0.6834  data: 0.2928  max mem: 5528\n",
      "Training Epoch: [89]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1299 (0.1339)  loss_objectness: 0.0631 (0.0665)  loss_rpn_box_reg: 0.0643 (0.0674)  time: 0.6934  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [89]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1321 (0.1344)  loss_objectness: 0.0656 (0.0665)  loss_rpn_box_reg: 0.0643 (0.0679)  time: 0.7069  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [89]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1328 (0.1355)  loss_objectness: 0.0713 (0.0672)  loss_rpn_box_reg: 0.0654 (0.0683)  time: 0.6874  data: 0.2883  max mem: 5528\n",
      "Training Epoch: [89]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1394 (0.1377)  loss_objectness: 0.0755 (0.0684)  loss_rpn_box_reg: 0.0654 (0.0693)  time: 0.6695  data: 0.2858  max mem: 5528\n",
      "Training Epoch: [89]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1413 (0.1373)  loss_objectness: 0.0761 (0.0695)  loss_rpn_box_reg: 0.0596 (0.0677)  time: 0.6816  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [89]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1341 (0.1382)  loss_objectness: 0.0748 (0.0696)  loss_rpn_box_reg: 0.0543 (0.0687)  time: 0.6919  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [89]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1477 (0.1394)  loss_objectness: 0.0684 (0.0699)  loss_rpn_box_reg: 0.0797 (0.0695)  time: 0.6805  data: 0.2898  max mem: 5528\n",
      "Training Epoch: [89]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1475 (0.1393)  loss_objectness: 0.0627 (0.0700)  loss_rpn_box_reg: 0.0686 (0.0693)  time: 0.6681  data: 0.2850  max mem: 5528\n",
      "Training Epoch: [89]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1391 (0.1396)  loss_objectness: 0.0665 (0.0702)  loss_rpn_box_reg: 0.0673 (0.0694)  time: 0.6782  data: 0.2860  max mem: 5528\n",
      "Training Epoch: [89]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1370 (0.1396)  loss_objectness: 0.0713 (0.0702)  loss_rpn_box_reg: 0.0622 (0.0695)  time: 0.6824  data: 0.2921  max mem: 5528\n",
      "Training Epoch: [89]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1389 (0.1403)  loss_objectness: 0.0701 (0.0701)  loss_rpn_box_reg: 0.0771 (0.0702)  time: 0.6872  data: 0.2949  max mem: 5528\n",
      "Training Epoch: [89]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1389 (0.1401)  loss_objectness: 0.0667 (0.0704)  loss_rpn_box_reg: 0.0664 (0.0697)  time: 0.7009  data: 0.2981  max mem: 5528\n",
      "Training Epoch: [89]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1295 (0.1402)  loss_objectness: 0.0640 (0.0702)  loss_rpn_box_reg: 0.0640 (0.0700)  time: 0.7109  data: 0.2988  max mem: 5528\n",
      "Training Epoch: [89]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1350 (0.1406)  loss_objectness: 0.0640 (0.0702)  loss_rpn_box_reg: 0.0680 (0.0704)  time: 0.6992  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [89]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1314 (0.1397)  loss_objectness: 0.0640 (0.0698)  loss_rpn_box_reg: 0.0636 (0.0699)  time: 0.6951  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [89]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1348 (0.1403)  loss_objectness: 0.0657 (0.0701)  loss_rpn_box_reg: 0.0614 (0.0702)  time: 0.7004  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [89]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1438 (0.1402)  loss_objectness: 0.0768 (0.0701)  loss_rpn_box_reg: 0.0684 (0.0701)  time: 0.6821  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [89]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1426 (0.1404)  loss_objectness: 0.0768 (0.0707)  loss_rpn_box_reg: 0.0645 (0.0697)  time: 0.6790  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [89]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1390 (0.1404)  loss_objectness: 0.0748 (0.0709)  loss_rpn_box_reg: 0.0611 (0.0695)  time: 0.6864  data: 0.2958  max mem: 5528\n",
      "Training Epoch: [89] Total time: 0:02:52 (0.6883 s / it)\n",
      "Testing Epoch: [89]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1393 (0.1393)  loss_objectness: 0.0482 (0.0482)  loss_rpn_box_reg: 0.0911 (0.0911)  time: 0.6261  data: 0.2951  max mem: 5528\n",
      "Testing Epoch: [89]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1294 (0.1391)  loss_objectness: 0.0554 (0.0580)  loss_rpn_box_reg: 0.0714 (0.0811)  time: 0.6367  data: 0.3095  max mem: 5528\n",
      "Testing Epoch: [89] Total time: 0:00:39 (0.6344 s / it)\n",
      "Training Epoch: [90]  [  0/250]  eta: 0:02:49  lr: 0.000300  loss: 0.1793 (0.1793)  loss_objectness: 0.1162 (0.1162)  loss_rpn_box_reg: 0.0630 (0.0630)  time: 0.6782  data: 0.3011  max mem: 5528\n",
      "Training Epoch: [90]  [ 10/250]  eta: 0:02:49  lr: 0.000300  loss: 0.1235 (0.1317)  loss_objectness: 0.0668 (0.0712)  loss_rpn_box_reg: 0.0583 (0.0605)  time: 0.7059  data: 0.2888  max mem: 5528\n",
      "Training Epoch: [90]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1174 (0.1301)  loss_objectness: 0.0591 (0.0670)  loss_rpn_box_reg: 0.0564 (0.0632)  time: 0.6950  data: 0.2896  max mem: 5528\n",
      "Training Epoch: [90]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1394 (0.1388)  loss_objectness: 0.0613 (0.0679)  loss_rpn_box_reg: 0.0692 (0.0709)  time: 0.6889  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [90]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1394 (0.1403)  loss_objectness: 0.0668 (0.0693)  loss_rpn_box_reg: 0.0692 (0.0710)  time: 0.6930  data: 0.2958  max mem: 5528\n",
      "Training Epoch: [90]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1285 (0.1379)  loss_objectness: 0.0658 (0.0689)  loss_rpn_box_reg: 0.0582 (0.0690)  time: 0.6868  data: 0.2958  max mem: 5528\n",
      "Training Epoch: [90]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1207 (0.1354)  loss_objectness: 0.0643 (0.0680)  loss_rpn_box_reg: 0.0520 (0.0673)  time: 0.6831  data: 0.2878  max mem: 5528\n",
      "Training Epoch: [90]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1240 (0.1361)  loss_objectness: 0.0640 (0.0683)  loss_rpn_box_reg: 0.0597 (0.0678)  time: 0.6951  data: 0.2883  max mem: 5528\n",
      "Training Epoch: [90]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1243 (0.1352)  loss_objectness: 0.0636 (0.0683)  loss_rpn_box_reg: 0.0597 (0.0670)  time: 0.6950  data: 0.2914  max mem: 5528\n",
      "Training Epoch: [90]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1304 (0.1362)  loss_objectness: 0.0686 (0.0694)  loss_rpn_box_reg: 0.0524 (0.0668)  time: 0.6795  data: 0.2878  max mem: 5528\n",
      "Training Epoch: [90]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1366 (0.1375)  loss_objectness: 0.0739 (0.0697)  loss_rpn_box_reg: 0.0765 (0.0678)  time: 0.6952  data: 0.2932  max mem: 5528\n",
      "Training Epoch: [90]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1366 (0.1372)  loss_objectness: 0.0703 (0.0694)  loss_rpn_box_reg: 0.0765 (0.0678)  time: 0.6951  data: 0.2932  max mem: 5528\n",
      "Training Epoch: [90]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1295 (0.1359)  loss_objectness: 0.0642 (0.0692)  loss_rpn_box_reg: 0.0596 (0.0667)  time: 0.6770  data: 0.2895  max mem: 5528\n",
      "Training Epoch: [90]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1363 (0.1376)  loss_objectness: 0.0712 (0.0697)  loss_rpn_box_reg: 0.0630 (0.0679)  time: 0.6709  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [90]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1607 (0.1388)  loss_objectness: 0.0725 (0.0701)  loss_rpn_box_reg: 0.0733 (0.0687)  time: 0.6710  data: 0.2956  max mem: 5528\n",
      "Training Epoch: [90]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1309 (0.1389)  loss_objectness: 0.0675 (0.0703)  loss_rpn_box_reg: 0.0719 (0.0686)  time: 0.6743  data: 0.2929  max mem: 5528\n",
      "Training Epoch: [90]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1244 (0.1390)  loss_objectness: 0.0621 (0.0705)  loss_rpn_box_reg: 0.0615 (0.0685)  time: 0.6672  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [90]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1217 (0.1386)  loss_objectness: 0.0651 (0.0703)  loss_rpn_box_reg: 0.0603 (0.0683)  time: 0.6785  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [90]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1391 (0.1390)  loss_objectness: 0.0667 (0.0704)  loss_rpn_box_reg: 0.0725 (0.0685)  time: 0.6904  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [90]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1472 (0.1401)  loss_objectness: 0.0797 (0.0715)  loss_rpn_box_reg: 0.0729 (0.0686)  time: 0.6821  data: 0.2915  max mem: 5528\n",
      "Training Epoch: [90]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1514 (0.1401)  loss_objectness: 0.0810 (0.0721)  loss_rpn_box_reg: 0.0627 (0.0680)  time: 0.6800  data: 0.2895  max mem: 5528\n",
      "Training Epoch: [90]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1462 (0.1405)  loss_objectness: 0.0774 (0.0724)  loss_rpn_box_reg: 0.0564 (0.0681)  time: 0.6962  data: 0.2950  max mem: 5528\n",
      "Training Epoch: [90]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1429 (0.1410)  loss_objectness: 0.0716 (0.0725)  loss_rpn_box_reg: 0.0711 (0.0685)  time: 0.6844  data: 0.2951  max mem: 5528\n",
      "Training Epoch: [90]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1403 (0.1414)  loss_objectness: 0.0696 (0.0726)  loss_rpn_box_reg: 0.0689 (0.0689)  time: 0.6689  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [90]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1472 (0.1426)  loss_objectness: 0.0737 (0.0728)  loss_rpn_box_reg: 0.0689 (0.0698)  time: 0.6971  data: 0.2983  max mem: 5528\n",
      "Training Epoch: [90]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1451 (0.1423)  loss_objectness: 0.0723 (0.0725)  loss_rpn_box_reg: 0.0756 (0.0698)  time: 0.6985  data: 0.2994  max mem: 5528\n",
      "Training Epoch: [90] Total time: 0:02:51 (0.6857 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:00  model_time: 0.6221 (0.6221)  evaluator_time: 0.0540 (0.0540)  time: 0.9752  data: 0.2831  max mem: 5528\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3781 (0.3820)  evaluator_time: 0.0640 (0.0769)  time: 0.7584  data: 0.3080  max mem: 5528\n",
      "Test: Total time: 0:00:47 (0.7644 s / it)\n",
      "Averaged stats: model_time: 0.3781 (0.3820)  evaluator_time: 0.0640 (0.0769)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.03s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.054\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.163\n",
      "Testing Epoch: [90]  [ 0/62]  eta: 0:00:45  lr: 0.000300  loss: 0.1297 (0.1297)  loss_objectness: 0.0423 (0.0423)  loss_rpn_box_reg: 0.0874 (0.0874)  time: 0.7292  data: 0.4081  max mem: 5528\n",
      "Testing Epoch: [90]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1332 (0.1397)  loss_objectness: 0.0540 (0.0604)  loss_rpn_box_reg: 0.0718 (0.0793)  time: 0.6349  data: 0.3102  max mem: 5528\n",
      "Testing Epoch: [90] Total time: 0:00:39 (0.6356 s / it)\n",
      "Training Epoch: [91]  [  0/250]  eta: 0:03:16  lr: 0.000300  loss: 0.1223 (0.1223)  loss_objectness: 0.0550 (0.0550)  loss_rpn_box_reg: 0.0673 (0.0673)  time: 0.7862  data: 0.2831  max mem: 5528\n",
      "Training Epoch: [91]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1223 (0.1262)  loss_objectness: 0.0561 (0.0689)  loss_rpn_box_reg: 0.0577 (0.0573)  time: 0.6825  data: 0.2893  max mem: 5528\n",
      "Training Epoch: [91]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1234 (0.1304)  loss_objectness: 0.0623 (0.0677)  loss_rpn_box_reg: 0.0577 (0.0628)  time: 0.6865  data: 0.2926  max mem: 5528\n",
      "Training Epoch: [91]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1305 (0.1302)  loss_objectness: 0.0673 (0.0695)  loss_rpn_box_reg: 0.0575 (0.0607)  time: 0.6919  data: 0.2928  max mem: 5528\n",
      "Training Epoch: [91]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1400 (0.1328)  loss_objectness: 0.0726 (0.0709)  loss_rpn_box_reg: 0.0575 (0.0619)  time: 0.6797  data: 0.2923  max mem: 5528\n",
      "Training Epoch: [91]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1340 (0.1337)  loss_objectness: 0.0708 (0.0717)  loss_rpn_box_reg: 0.0645 (0.0620)  time: 0.6764  data: 0.2922  max mem: 5528\n",
      "Training Epoch: [91]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1267 (0.1322)  loss_objectness: 0.0665 (0.0703)  loss_rpn_box_reg: 0.0677 (0.0620)  time: 0.6709  data: 0.2889  max mem: 5528\n",
      "Training Epoch: [91]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1290 (0.1343)  loss_objectness: 0.0630 (0.0711)  loss_rpn_box_reg: 0.0677 (0.0633)  time: 0.6662  data: 0.2885  max mem: 5528\n",
      "Training Epoch: [91]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1338 (0.1330)  loss_objectness: 0.0718 (0.0709)  loss_rpn_box_reg: 0.0624 (0.0622)  time: 0.6732  data: 0.2875  max mem: 5528\n",
      "Training Epoch: [91]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1230 (0.1329)  loss_objectness: 0.0671 (0.0703)  loss_rpn_box_reg: 0.0606 (0.0626)  time: 0.6880  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [91]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1365 (0.1338)  loss_objectness: 0.0632 (0.0695)  loss_rpn_box_reg: 0.0687 (0.0643)  time: 0.6896  data: 0.2933  max mem: 5528\n",
      "Training Epoch: [91]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1320 (0.1342)  loss_objectness: 0.0593 (0.0691)  loss_rpn_box_reg: 0.0707 (0.0652)  time: 0.6742  data: 0.2889  max mem: 5528\n",
      "Training Epoch: [91]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1320 (0.1352)  loss_objectness: 0.0608 (0.0691)  loss_rpn_box_reg: 0.0663 (0.0660)  time: 0.6696  data: 0.2886  max mem: 5528\n",
      "Training Epoch: [91]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1418 (0.1356)  loss_objectness: 0.0635 (0.0693)  loss_rpn_box_reg: 0.0643 (0.0663)  time: 0.6807  data: 0.2879  max mem: 5528\n",
      "Training Epoch: [91]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1460 (0.1361)  loss_objectness: 0.0623 (0.0689)  loss_rpn_box_reg: 0.0693 (0.0672)  time: 0.6824  data: 0.2860  max mem: 5528\n",
      "Training Epoch: [91]  [150/250]  eta: 0:01:07  lr: 0.000300  loss: 0.1455 (0.1372)  loss_objectness: 0.0623 (0.0689)  loss_rpn_box_reg: 0.0788 (0.0682)  time: 0.6767  data: 0.2887  max mem: 5528\n",
      "Training Epoch: [91]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1431 (0.1367)  loss_objectness: 0.0668 (0.0691)  loss_rpn_box_reg: 0.0663 (0.0676)  time: 0.6821  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [91]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1312 (0.1368)  loss_objectness: 0.0649 (0.0689)  loss_rpn_box_reg: 0.0566 (0.0679)  time: 0.6894  data: 0.2877  max mem: 5528\n",
      "Training Epoch: [91]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1522 (0.1378)  loss_objectness: 0.0716 (0.0694)  loss_rpn_box_reg: 0.0771 (0.0683)  time: 0.6927  data: 0.2925  max mem: 5528\n",
      "Training Epoch: [91]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1516 (0.1379)  loss_objectness: 0.0716 (0.0695)  loss_rpn_box_reg: 0.0659 (0.0684)  time: 0.6880  data: 0.2937  max mem: 5528\n",
      "Training Epoch: [91]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1320 (0.1384)  loss_objectness: 0.0680 (0.0700)  loss_rpn_box_reg: 0.0654 (0.0684)  time: 0.6823  data: 0.2901  max mem: 5528\n",
      "Training Epoch: [91]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1362 (0.1388)  loss_objectness: 0.0702 (0.0701)  loss_rpn_box_reg: 0.0663 (0.0687)  time: 0.6848  data: 0.2931  max mem: 5528\n",
      "Training Epoch: [91]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1450 (0.1395)  loss_objectness: 0.0753 (0.0703)  loss_rpn_box_reg: 0.0690 (0.0692)  time: 0.6864  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [91]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1450 (0.1397)  loss_objectness: 0.0719 (0.0704)  loss_rpn_box_reg: 0.0672 (0.0692)  time: 0.6971  data: 0.2927  max mem: 5528\n",
      "Training Epoch: [91]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1318 (0.1398)  loss_objectness: 0.0679 (0.0707)  loss_rpn_box_reg: 0.0608 (0.0691)  time: 0.6958  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [91]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1308 (0.1396)  loss_objectness: 0.0679 (0.0704)  loss_rpn_box_reg: 0.0688 (0.0692)  time: 0.6676  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [91] Total time: 0:02:50 (0.6818 s / it)\n",
      "Testing Epoch: [91]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1350 (0.1350)  loss_objectness: 0.0441 (0.0441)  loss_rpn_box_reg: 0.0908 (0.0908)  time: 0.6181  data: 0.2831  max mem: 5528\n",
      "Testing Epoch: [91]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1320 (0.1400)  loss_objectness: 0.0541 (0.0584)  loss_rpn_box_reg: 0.0740 (0.0816)  time: 0.6265  data: 0.3057  max mem: 5528\n",
      "Testing Epoch: [91] Total time: 0:00:39 (0.6339 s / it)\n",
      "Training Epoch: [92]  [  0/250]  eta: 0:02:49  lr: 0.000300  loss: 0.1255 (0.1255)  loss_objectness: 0.0678 (0.0678)  loss_rpn_box_reg: 0.0577 (0.0577)  time: 0.6762  data: 0.3081  max mem: 5528\n",
      "Training Epoch: [92]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1357 (0.1390)  loss_objectness: 0.0705 (0.0716)  loss_rpn_box_reg: 0.0628 (0.0674)  time: 0.6842  data: 0.2956  max mem: 5528\n",
      "Training Epoch: [92]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1225 (0.1314)  loss_objectness: 0.0628 (0.0674)  loss_rpn_box_reg: 0.0624 (0.0640)  time: 0.6799  data: 0.2908  max mem: 5528\n",
      "Training Epoch: [92]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1250 (0.1322)  loss_objectness: 0.0628 (0.0700)  loss_rpn_box_reg: 0.0501 (0.0622)  time: 0.6814  data: 0.2871  max mem: 5528\n",
      "Training Epoch: [92]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1293 (0.1342)  loss_objectness: 0.0656 (0.0699)  loss_rpn_box_reg: 0.0604 (0.0643)  time: 0.6826  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [92]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1463 (0.1374)  loss_objectness: 0.0685 (0.0705)  loss_rpn_box_reg: 0.0681 (0.0669)  time: 0.6899  data: 0.2928  max mem: 5528\n",
      "Training Epoch: [92]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1509 (0.1394)  loss_objectness: 0.0729 (0.0713)  loss_rpn_box_reg: 0.0732 (0.0681)  time: 0.6896  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [92]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1420 (0.1409)  loss_objectness: 0.0749 (0.0730)  loss_rpn_box_reg: 0.0685 (0.0679)  time: 0.6740  data: 0.2951  max mem: 5528\n",
      "Training Epoch: [92]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1361 (0.1402)  loss_objectness: 0.0662 (0.0723)  loss_rpn_box_reg: 0.0630 (0.0679)  time: 0.6739  data: 0.2887  max mem: 5528\n",
      "Training Epoch: [92]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1389 (0.1419)  loss_objectness: 0.0715 (0.0731)  loss_rpn_box_reg: 0.0742 (0.0688)  time: 0.6801  data: 0.2899  max mem: 5528\n",
      "Training Epoch: [92]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1373 (0.1410)  loss_objectness: 0.0639 (0.0718)  loss_rpn_box_reg: 0.0776 (0.0692)  time: 0.6843  data: 0.2938  max mem: 5528\n",
      "Training Epoch: [92]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1283 (0.1400)  loss_objectness: 0.0592 (0.0713)  loss_rpn_box_reg: 0.0650 (0.0687)  time: 0.6735  data: 0.2911  max mem: 5528\n",
      "Training Epoch: [92]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1275 (0.1397)  loss_objectness: 0.0673 (0.0708)  loss_rpn_box_reg: 0.0693 (0.0688)  time: 0.6873  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [92]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1275 (0.1398)  loss_objectness: 0.0670 (0.0709)  loss_rpn_box_reg: 0.0704 (0.0689)  time: 0.6893  data: 0.2946  max mem: 5528\n",
      "Training Epoch: [92]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1312 (0.1400)  loss_objectness: 0.0678 (0.0713)  loss_rpn_box_reg: 0.0675 (0.0688)  time: 0.6626  data: 0.2926  max mem: 5528\n",
      "Training Epoch: [92]  [150/250]  eta: 0:01:07  lr: 0.000300  loss: 0.1399 (0.1405)  loss_objectness: 0.0717 (0.0715)  loss_rpn_box_reg: 0.0678 (0.0690)  time: 0.6652  data: 0.2932  max mem: 5528\n",
      "Training Epoch: [92]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1526 (0.1410)  loss_objectness: 0.0726 (0.0716)  loss_rpn_box_reg: 0.0699 (0.0694)  time: 0.6980  data: 0.2929  max mem: 5528\n",
      "Training Epoch: [92]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1526 (0.1419)  loss_objectness: 0.0715 (0.0722)  loss_rpn_box_reg: 0.0660 (0.0696)  time: 0.7017  data: 0.2914  max mem: 5528\n",
      "Training Epoch: [92]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1574 (0.1428)  loss_objectness: 0.0832 (0.0728)  loss_rpn_box_reg: 0.0660 (0.0700)  time: 0.6796  data: 0.2944  max mem: 5528\n",
      "Training Epoch: [92]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1554 (0.1432)  loss_objectness: 0.0791 (0.0728)  loss_rpn_box_reg: 0.0680 (0.0704)  time: 0.6910  data: 0.2963  max mem: 5528\n",
      "Training Epoch: [92]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1488 (0.1434)  loss_objectness: 0.0709 (0.0730)  loss_rpn_box_reg: 0.0758 (0.0704)  time: 0.6961  data: 0.2944  max mem: 5528\n",
      "Training Epoch: [92]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1363 (0.1431)  loss_objectness: 0.0704 (0.0727)  loss_rpn_box_reg: 0.0650 (0.0703)  time: 0.6854  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [92]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1363 (0.1430)  loss_objectness: 0.0666 (0.0727)  loss_rpn_box_reg: 0.0689 (0.0703)  time: 0.6779  data: 0.2865  max mem: 5528\n",
      "Training Epoch: [92]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1402 (0.1427)  loss_objectness: 0.0634 (0.0725)  loss_rpn_box_reg: 0.0725 (0.0702)  time: 0.6908  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [92]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1301 (0.1427)  loss_objectness: 0.0634 (0.0724)  loss_rpn_box_reg: 0.0682 (0.0703)  time: 0.6924  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [92]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1296 (0.1421)  loss_objectness: 0.0649 (0.0724)  loss_rpn_box_reg: 0.0565 (0.0697)  time: 0.6731  data: 0.2897  max mem: 5528\n",
      "Training Epoch: [92] Total time: 0:02:50 (0.6828 s / it)\n",
      "Testing Epoch: [92]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1348 (0.1348)  loss_objectness: 0.0489 (0.0489)  loss_rpn_box_reg: 0.0858 (0.0858)  time: 0.6161  data: 0.2871  max mem: 5528\n",
      "Testing Epoch: [92]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1276 (0.1395)  loss_objectness: 0.0558 (0.0599)  loss_rpn_box_reg: 0.0743 (0.0796)  time: 0.6300  data: 0.3095  max mem: 5528\n",
      "Testing Epoch: [92] Total time: 0:00:39 (0.6330 s / it)\n",
      "Training Epoch: [93]  [  0/250]  eta: 0:03:09  lr: 0.000300  loss: 0.1321 (0.1321)  loss_objectness: 0.0440 (0.0440)  loss_rpn_box_reg: 0.0881 (0.0881)  time: 0.7572  data: 0.2971  max mem: 5528\n",
      "Training Epoch: [93]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1321 (0.1388)  loss_objectness: 0.0642 (0.0641)  loss_rpn_box_reg: 0.0682 (0.0746)  time: 0.6815  data: 0.2929  max mem: 5528\n",
      "Training Epoch: [93]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1330 (0.1400)  loss_objectness: 0.0642 (0.0673)  loss_rpn_box_reg: 0.0664 (0.0727)  time: 0.6874  data: 0.2946  max mem: 5528\n",
      "Training Epoch: [93]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1388 (0.1401)  loss_objectness: 0.0665 (0.0677)  loss_rpn_box_reg: 0.0652 (0.0724)  time: 0.6897  data: 0.2942  max mem: 5528\n",
      "Training Epoch: [93]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1277 (0.1382)  loss_objectness: 0.0644 (0.0681)  loss_rpn_box_reg: 0.0627 (0.0700)  time: 0.6804  data: 0.2898  max mem: 5528\n",
      "Training Epoch: [93]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1442 (0.1399)  loss_objectness: 0.0593 (0.0668)  loss_rpn_box_reg: 0.0716 (0.0731)  time: 0.6781  data: 0.2872  max mem: 5528\n",
      "Training Epoch: [93]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1442 (0.1385)  loss_objectness: 0.0611 (0.0671)  loss_rpn_box_reg: 0.0740 (0.0714)  time: 0.6838  data: 0.2866  max mem: 5528\n",
      "Training Epoch: [93]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1298 (0.1369)  loss_objectness: 0.0636 (0.0672)  loss_rpn_box_reg: 0.0564 (0.0697)  time: 0.6882  data: 0.2891  max mem: 5528\n",
      "Training Epoch: [93]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1231 (0.1361)  loss_objectness: 0.0640 (0.0673)  loss_rpn_box_reg: 0.0567 (0.0689)  time: 0.6796  data: 0.2910  max mem: 5528\n",
      "Training Epoch: [93]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1274 (0.1355)  loss_objectness: 0.0640 (0.0674)  loss_rpn_box_reg: 0.0601 (0.0681)  time: 0.6871  data: 0.2907  max mem: 5528\n",
      "Training Epoch: [93]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1329 (0.1364)  loss_objectness: 0.0632 (0.0674)  loss_rpn_box_reg: 0.0676 (0.0690)  time: 0.6900  data: 0.2989  max mem: 5528\n",
      "Training Epoch: [93]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1381 (0.1362)  loss_objectness: 0.0653 (0.0674)  loss_rpn_box_reg: 0.0677 (0.0687)  time: 0.6836  data: 0.2963  max mem: 5528\n",
      "Training Epoch: [93]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1396 (0.1358)  loss_objectness: 0.0687 (0.0675)  loss_rpn_box_reg: 0.0649 (0.0683)  time: 0.6942  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [93]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1363 (0.1361)  loss_objectness: 0.0720 (0.0680)  loss_rpn_box_reg: 0.0619 (0.0681)  time: 0.6991  data: 0.2945  max mem: 5528\n",
      "Training Epoch: [93]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1361 (0.1363)  loss_objectness: 0.0651 (0.0678)  loss_rpn_box_reg: 0.0619 (0.0685)  time: 0.6888  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [93]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1460 (0.1368)  loss_objectness: 0.0651 (0.0680)  loss_rpn_box_reg: 0.0781 (0.0688)  time: 0.6844  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [93]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1463 (0.1378)  loss_objectness: 0.0745 (0.0685)  loss_rpn_box_reg: 0.0772 (0.0693)  time: 0.6833  data: 0.2935  max mem: 5528\n",
      "Training Epoch: [93]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1439 (0.1381)  loss_objectness: 0.0758 (0.0689)  loss_rpn_box_reg: 0.0635 (0.0692)  time: 0.6869  data: 0.2916  max mem: 5528\n",
      "Training Epoch: [93]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1377 (0.1374)  loss_objectness: 0.0721 (0.0691)  loss_rpn_box_reg: 0.0617 (0.0683)  time: 0.6850  data: 0.2935  max mem: 5528\n",
      "Training Epoch: [93]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1339 (0.1378)  loss_objectness: 0.0699 (0.0695)  loss_rpn_box_reg: 0.0567 (0.0683)  time: 0.7018  data: 0.2902  max mem: 5528\n",
      "Training Epoch: [93]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1348 (0.1378)  loss_objectness: 0.0697 (0.0696)  loss_rpn_box_reg: 0.0582 (0.0683)  time: 0.7068  data: 0.2879  max mem: 5528\n",
      "Training Epoch: [93]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1359 (0.1381)  loss_objectness: 0.0703 (0.0699)  loss_rpn_box_reg: 0.0678 (0.0682)  time: 0.6824  data: 0.2937  max mem: 5528\n",
      "Training Epoch: [93]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1398 (0.1385)  loss_objectness: 0.0713 (0.0700)  loss_rpn_box_reg: 0.0699 (0.0685)  time: 0.6882  data: 0.2938  max mem: 5528\n",
      "Training Epoch: [93]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1448 (0.1396)  loss_objectness: 0.0787 (0.0708)  loss_rpn_box_reg: 0.0735 (0.0688)  time: 0.7001  data: 0.2946  max mem: 5528\n",
      "Training Epoch: [93]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1613 (0.1401)  loss_objectness: 0.0767 (0.0709)  loss_rpn_box_reg: 0.0722 (0.0691)  time: 0.7020  data: 0.2951  max mem: 5528\n",
      "Training Epoch: [93]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1577 (0.1409)  loss_objectness: 0.0723 (0.0713)  loss_rpn_box_reg: 0.0877 (0.0696)  time: 0.6733  data: 0.2935  max mem: 5528\n",
      "Training Epoch: [93] Total time: 0:02:51 (0.6876 s / it)\n",
      "Testing Epoch: [93]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1315 (0.1315)  loss_objectness: 0.0438 (0.0438)  loss_rpn_box_reg: 0.0876 (0.0876)  time: 0.6141  data: 0.2911  max mem: 5528\n",
      "Testing Epoch: [93]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1253 (0.1366)  loss_objectness: 0.0511 (0.0568)  loss_rpn_box_reg: 0.0733 (0.0798)  time: 0.6308  data: 0.3113  max mem: 5528\n",
      "Testing Epoch: [93] Total time: 0:00:39 (0.6376 s / it)\n",
      "Training Epoch: [94]  [  0/250]  eta: 0:03:00  lr: 0.000300  loss: 0.1716 (0.1716)  loss_objectness: 0.0989 (0.0989)  loss_rpn_box_reg: 0.0727 (0.0727)  time: 0.7202  data: 0.2851  max mem: 5528\n",
      "Training Epoch: [94]  [ 10/250]  eta: 0:02:50  lr: 0.000300  loss: 0.1404 (0.1448)  loss_objectness: 0.0771 (0.0770)  loss_rpn_box_reg: 0.0708 (0.0678)  time: 0.7104  data: 0.2984  max mem: 5528\n",
      "Training Epoch: [94]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1396 (0.1443)  loss_objectness: 0.0664 (0.0726)  loss_rpn_box_reg: 0.0693 (0.0717)  time: 0.6959  data: 0.2945  max mem: 5528\n",
      "Training Epoch: [94]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1383 (0.1460)  loss_objectness: 0.0637 (0.0713)  loss_rpn_box_reg: 0.0678 (0.0747)  time: 0.6841  data: 0.2899  max mem: 5528\n",
      "Training Epoch: [94]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1293 (0.1436)  loss_objectness: 0.0663 (0.0713)  loss_rpn_box_reg: 0.0632 (0.0723)  time: 0.6857  data: 0.2903  max mem: 5528\n",
      "Training Epoch: [94]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1291 (0.1435)  loss_objectness: 0.0726 (0.0710)  loss_rpn_box_reg: 0.0628 (0.0725)  time: 0.6833  data: 0.2906  max mem: 5528\n",
      "Training Epoch: [94]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1333 (0.1418)  loss_objectness: 0.0722 (0.0702)  loss_rpn_box_reg: 0.0629 (0.0717)  time: 0.6796  data: 0.2927  max mem: 5528\n",
      "Training Epoch: [94]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1219 (0.1393)  loss_objectness: 0.0638 (0.0696)  loss_rpn_box_reg: 0.0596 (0.0697)  time: 0.6849  data: 0.2888  max mem: 5528\n",
      "Training Epoch: [94]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1253 (0.1411)  loss_objectness: 0.0672 (0.0702)  loss_rpn_box_reg: 0.0644 (0.0709)  time: 0.6918  data: 0.2878  max mem: 5528\n",
      "Training Epoch: [94]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1510 (0.1412)  loss_objectness: 0.0672 (0.0700)  loss_rpn_box_reg: 0.0762 (0.0712)  time: 0.6864  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [94]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1440 (0.1415)  loss_objectness: 0.0684 (0.0705)  loss_rpn_box_reg: 0.0676 (0.0710)  time: 0.6896  data: 0.2899  max mem: 5528\n",
      "Training Epoch: [94]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1463 (0.1425)  loss_objectness: 0.0758 (0.0713)  loss_rpn_box_reg: 0.0607 (0.0712)  time: 0.6893  data: 0.2943  max mem: 5528\n",
      "Training Epoch: [94]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1441 (0.1423)  loss_objectness: 0.0737 (0.0717)  loss_rpn_box_reg: 0.0627 (0.0706)  time: 0.6827  data: 0.2975  max mem: 5528\n",
      "Training Epoch: [94]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1323 (0.1423)  loss_objectness: 0.0700 (0.0721)  loss_rpn_box_reg: 0.0623 (0.0703)  time: 0.6855  data: 0.2888  max mem: 5528\n",
      "Training Epoch: [94]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1323 (0.1416)  loss_objectness: 0.0655 (0.0719)  loss_rpn_box_reg: 0.0597 (0.0697)  time: 0.6827  data: 0.2863  max mem: 5528\n",
      "Training Epoch: [94]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1335 (0.1416)  loss_objectness: 0.0659 (0.0721)  loss_rpn_box_reg: 0.0621 (0.0696)  time: 0.6869  data: 0.2904  max mem: 5528\n",
      "Training Epoch: [94]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1480 (0.1418)  loss_objectness: 0.0746 (0.0721)  loss_rpn_box_reg: 0.0710 (0.0696)  time: 0.6795  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [94]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1494 (0.1423)  loss_objectness: 0.0746 (0.0723)  loss_rpn_box_reg: 0.0783 (0.0700)  time: 0.6786  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [94]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1574 (0.1438)  loss_objectness: 0.0758 (0.0729)  loss_rpn_box_reg: 0.0803 (0.0709)  time: 0.6782  data: 0.2919  max mem: 5528\n",
      "Training Epoch: [94]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1535 (0.1441)  loss_objectness: 0.0758 (0.0729)  loss_rpn_box_reg: 0.0755 (0.0712)  time: 0.6767  data: 0.2937  max mem: 5528\n",
      "Training Epoch: [94]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1393 (0.1435)  loss_objectness: 0.0660 (0.0727)  loss_rpn_box_reg: 0.0671 (0.0708)  time: 0.6893  data: 0.2939  max mem: 5528\n",
      "Training Epoch: [94]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1286 (0.1432)  loss_objectness: 0.0618 (0.0725)  loss_rpn_box_reg: 0.0553 (0.0707)  time: 0.6848  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [94]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1322 (0.1428)  loss_objectness: 0.0703 (0.0726)  loss_rpn_box_reg: 0.0606 (0.0702)  time: 0.6960  data: 0.2935  max mem: 5528\n",
      "Training Epoch: [94]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1333 (0.1424)  loss_objectness: 0.0660 (0.0722)  loss_rpn_box_reg: 0.0617 (0.0702)  time: 0.6994  data: 0.2930  max mem: 5528\n",
      "Training Epoch: [94]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1333 (0.1427)  loss_objectness: 0.0660 (0.0725)  loss_rpn_box_reg: 0.0634 (0.0702)  time: 0.6812  data: 0.2901  max mem: 5528\n",
      "Training Epoch: [94]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1478 (0.1432)  loss_objectness: 0.0757 (0.0728)  loss_rpn_box_reg: 0.0683 (0.0704)  time: 0.6798  data: 0.2912  max mem: 5528\n",
      "Training Epoch: [94] Total time: 0:02:51 (0.6864 s / it)\n",
      "Testing Epoch: [94]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1339 (0.1339)  loss_objectness: 0.0449 (0.0449)  loss_rpn_box_reg: 0.0890 (0.0890)  time: 0.6181  data: 0.2861  max mem: 5528\n",
      "Testing Epoch: [94]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1271 (0.1408)  loss_objectness: 0.0560 (0.0601)  loss_rpn_box_reg: 0.0758 (0.0807)  time: 0.6227  data: 0.3036  max mem: 5528\n",
      "Testing Epoch: [94] Total time: 0:00:39 (0.6302 s / it)\n",
      "Training Epoch: [95]  [  0/250]  eta: 0:03:07  lr: 0.000300  loss: 0.1234 (0.1234)  loss_objectness: 0.0524 (0.0524)  loss_rpn_box_reg: 0.0710 (0.0710)  time: 0.7512  data: 0.2941  max mem: 5528\n",
      "Training Epoch: [95]  [ 10/250]  eta: 0:02:48  lr: 0.000300  loss: 0.1291 (0.1410)  loss_objectness: 0.0772 (0.0734)  loss_rpn_box_reg: 0.0659 (0.0676)  time: 0.7031  data: 0.2971  max mem: 5528\n",
      "Training Epoch: [95]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1283 (0.1378)  loss_objectness: 0.0650 (0.0671)  loss_rpn_box_reg: 0.0659 (0.0706)  time: 0.6946  data: 0.2956  max mem: 5528\n",
      "Training Epoch: [95]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1281 (0.1352)  loss_objectness: 0.0650 (0.0691)  loss_rpn_box_reg: 0.0633 (0.0660)  time: 0.6806  data: 0.2924  max mem: 5528\n",
      "Training Epoch: [95]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1323 (0.1359)  loss_objectness: 0.0728 (0.0695)  loss_rpn_box_reg: 0.0615 (0.0664)  time: 0.6756  data: 0.2918  max mem: 5528\n",
      "Training Epoch: [95]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1323 (0.1375)  loss_objectness: 0.0643 (0.0702)  loss_rpn_box_reg: 0.0664 (0.0673)  time: 0.6843  data: 0.3014  max mem: 5528\n",
      "Training Epoch: [95]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1306 (0.1379)  loss_objectness: 0.0673 (0.0698)  loss_rpn_box_reg: 0.0704 (0.0681)  time: 0.6825  data: 0.3013  max mem: 5528\n",
      "Training Epoch: [95]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1365 (0.1390)  loss_objectness: 0.0709 (0.0706)  loss_rpn_box_reg: 0.0659 (0.0684)  time: 0.6850  data: 0.2947  max mem: 5528\n",
      "Training Epoch: [95]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1387 (0.1401)  loss_objectness: 0.0693 (0.0711)  loss_rpn_box_reg: 0.0659 (0.0691)  time: 0.6918  data: 0.2984  max mem: 5528\n",
      "Training Epoch: [95]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1436 (0.1411)  loss_objectness: 0.0695 (0.0716)  loss_rpn_box_reg: 0.0682 (0.0695)  time: 0.6794  data: 0.2966  max mem: 5528\n",
      "Training Epoch: [95]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1368 (0.1403)  loss_objectness: 0.0680 (0.0712)  loss_rpn_box_reg: 0.0665 (0.0691)  time: 0.6591  data: 0.2917  max mem: 5528\n",
      "Training Epoch: [95]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1384 (0.1408)  loss_objectness: 0.0690 (0.0714)  loss_rpn_box_reg: 0.0650 (0.0694)  time: 0.6922  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [95]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1494 (0.1410)  loss_objectness: 0.0705 (0.0715)  loss_rpn_box_reg: 0.0718 (0.0695)  time: 0.7125  data: 0.2937  max mem: 5528\n",
      "Training Epoch: [95]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1426 (0.1407)  loss_objectness: 0.0677 (0.0712)  loss_rpn_box_reg: 0.0718 (0.0695)  time: 0.6687  data: 0.2900  max mem: 5528\n",
      "Training Epoch: [95]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1347 (0.1401)  loss_objectness: 0.0677 (0.0709)  loss_rpn_box_reg: 0.0637 (0.0692)  time: 0.6552  data: 0.2868  max mem: 5528\n",
      "Training Epoch: [95]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1313 (0.1394)  loss_objectness: 0.0677 (0.0708)  loss_rpn_box_reg: 0.0555 (0.0687)  time: 0.6844  data: 0.2885  max mem: 5528\n",
      "Training Epoch: [95]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1395 (0.1403)  loss_objectness: 0.0717 (0.0708)  loss_rpn_box_reg: 0.0709 (0.0696)  time: 0.6964  data: 0.2920  max mem: 5528\n",
      "Training Epoch: [95]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1361 (0.1398)  loss_objectness: 0.0710 (0.0707)  loss_rpn_box_reg: 0.0637 (0.0691)  time: 0.6642  data: 0.2901  max mem: 5528\n",
      "Training Epoch: [95]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1361 (0.1402)  loss_objectness: 0.0647 (0.0711)  loss_rpn_box_reg: 0.0589 (0.0691)  time: 0.6588  data: 0.2885  max mem: 5528\n",
      "Training Epoch: [95]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1365 (0.1402)  loss_objectness: 0.0748 (0.0711)  loss_rpn_box_reg: 0.0601 (0.0692)  time: 0.6775  data: 0.2898  max mem: 5528\n",
      "Training Epoch: [95]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1339 (0.1400)  loss_objectness: 0.0685 (0.0711)  loss_rpn_box_reg: 0.0601 (0.0689)  time: 0.6850  data: 0.2894  max mem: 5528\n",
      "Training Epoch: [95]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1390 (0.1401)  loss_objectness: 0.0647 (0.0709)  loss_rpn_box_reg: 0.0654 (0.0692)  time: 0.6814  data: 0.2881  max mem: 5528\n",
      "Training Epoch: [95]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1406 (0.1404)  loss_objectness: 0.0661 (0.0709)  loss_rpn_box_reg: 0.0769 (0.0695)  time: 0.6838  data: 0.2854  max mem: 5528\n",
      "Training Epoch: [95]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1405 (0.1407)  loss_objectness: 0.0724 (0.0711)  loss_rpn_box_reg: 0.0675 (0.0696)  time: 0.6871  data: 0.2856  max mem: 5528\n",
      "Training Epoch: [95]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1420 (0.1413)  loss_objectness: 0.0830 (0.0717)  loss_rpn_box_reg: 0.0642 (0.0696)  time: 0.6631  data: 0.2853  max mem: 5528\n",
      "Training Epoch: [95]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1434 (0.1411)  loss_objectness: 0.0759 (0.0717)  loss_rpn_box_reg: 0.0642 (0.0695)  time: 0.6645  data: 0.2844  max mem: 5528\n",
      "Training Epoch: [95] Total time: 0:02:50 (0.6803 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:00  model_time: 0.6221 (0.6221)  evaluator_time: 0.0600 (0.0600)  time: 0.9762  data: 0.2781  max mem: 5528\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3921 (0.3955)  evaluator_time: 0.0690 (0.0823)  time: 0.7852  data: 0.3080  max mem: 5607\n",
      "Test: Total time: 0:00:48 (0.7875 s / it)\n",
      "Averaged stats: model_time: 0.3921 (0.3955)  evaluator_time: 0.0690 (0.0823)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.11s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.059\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.116\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.074\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.183\n",
      "Testing Epoch: [95]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1358 (0.1358)  loss_objectness: 0.0515 (0.0515)  loss_rpn_box_reg: 0.0843 (0.0843)  time: 0.6431  data: 0.3021  max mem: 5607\n",
      "Testing Epoch: [95]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1330 (0.1410)  loss_objectness: 0.0595 (0.0602)  loss_rpn_box_reg: 0.0740 (0.0808)  time: 0.6402  data: 0.3202  max mem: 5607\n",
      "Testing Epoch: [95] Total time: 0:00:39 (0.6366 s / it)\n",
      "Training Epoch: [96]  [  0/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1276 (0.1276)  loss_objectness: 0.0592 (0.0592)  loss_rpn_box_reg: 0.0684 (0.0684)  time: 0.5971  data: 0.2911  max mem: 5607\n",
      "Training Epoch: [96]  [ 10/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1352 (0.1331)  loss_objectness: 0.0657 (0.0676)  loss_rpn_box_reg: 0.0637 (0.0654)  time: 0.6698  data: 0.2900  max mem: 5607\n",
      "Training Epoch: [96]  [ 20/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1361 (0.1358)  loss_objectness: 0.0670 (0.0698)  loss_rpn_box_reg: 0.0637 (0.0660)  time: 0.6812  data: 0.2929  max mem: 5607\n",
      "Training Epoch: [96]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1359 (0.1353)  loss_objectness: 0.0722 (0.0687)  loss_rpn_box_reg: 0.0668 (0.0665)  time: 0.6847  data: 0.2956  max mem: 5607\n",
      "Training Epoch: [96]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1247 (0.1330)  loss_objectness: 0.0668 (0.0679)  loss_rpn_box_reg: 0.0621 (0.0651)  time: 0.6824  data: 0.2947  max mem: 5607\n",
      "Training Epoch: [96]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1247 (0.1326)  loss_objectness: 0.0664 (0.0678)  loss_rpn_box_reg: 0.0581 (0.0648)  time: 0.6816  data: 0.2932  max mem: 5607\n",
      "Training Epoch: [96]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1326 (0.1334)  loss_objectness: 0.0664 (0.0684)  loss_rpn_box_reg: 0.0614 (0.0650)  time: 0.6849  data: 0.2940  max mem: 5607\n",
      "Training Epoch: [96]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1317 (0.1342)  loss_objectness: 0.0683 (0.0685)  loss_rpn_box_reg: 0.0713 (0.0657)  time: 0.6844  data: 0.2971  max mem: 5607\n",
      "Training Epoch: [96]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1241 (0.1346)  loss_objectness: 0.0675 (0.0686)  loss_rpn_box_reg: 0.0668 (0.0660)  time: 0.6755  data: 0.2929  max mem: 5607\n",
      "Training Epoch: [96]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1427 (0.1366)  loss_objectness: 0.0705 (0.0698)  loss_rpn_box_reg: 0.0605 (0.0668)  time: 0.6814  data: 0.2893  max mem: 5607\n",
      "Training Epoch: [96]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1473 (0.1374)  loss_objectness: 0.0695 (0.0692)  loss_rpn_box_reg: 0.0749 (0.0682)  time: 0.6879  data: 0.2909  max mem: 5607\n",
      "Training Epoch: [96]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1473 (0.1390)  loss_objectness: 0.0673 (0.0700)  loss_rpn_box_reg: 0.0789 (0.0690)  time: 0.6860  data: 0.2930  max mem: 5607\n",
      "Training Epoch: [96]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1465 (0.1396)  loss_objectness: 0.0805 (0.0707)  loss_rpn_box_reg: 0.0652 (0.0689)  time: 0.6882  data: 0.2963  max mem: 5607\n",
      "Training Epoch: [96]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1423 (0.1393)  loss_objectness: 0.0700 (0.0706)  loss_rpn_box_reg: 0.0622 (0.0686)  time: 0.6864  data: 0.2953  max mem: 5607\n",
      "Training Epoch: [96]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1341 (0.1394)  loss_objectness: 0.0679 (0.0705)  loss_rpn_box_reg: 0.0629 (0.0689)  time: 0.6960  data: 0.2931  max mem: 5607\n",
      "Training Epoch: [96]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1352 (0.1397)  loss_objectness: 0.0696 (0.0709)  loss_rpn_box_reg: 0.0674 (0.0689)  time: 0.7009  data: 0.2929  max mem: 5607\n",
      "Training Epoch: [96]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1363 (0.1399)  loss_objectness: 0.0634 (0.0706)  loss_rpn_box_reg: 0.0761 (0.0693)  time: 0.6883  data: 0.2914  max mem: 5607\n",
      "Training Epoch: [96]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1336 (0.1404)  loss_objectness: 0.0702 (0.0710)  loss_rpn_box_reg: 0.0591 (0.0694)  time: 0.6985  data: 0.2898  max mem: 5607\n",
      "Training Epoch: [96]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1354 (0.1406)  loss_objectness: 0.0744 (0.0709)  loss_rpn_box_reg: 0.0686 (0.0696)  time: 0.7116  data: 0.2904  max mem: 5607\n",
      "Training Epoch: [96]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1523 (0.1412)  loss_objectness: 0.0742 (0.0713)  loss_rpn_box_reg: 0.0760 (0.0698)  time: 0.6937  data: 0.2953  max mem: 5607\n",
      "Training Epoch: [96]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1377 (0.1410)  loss_objectness: 0.0742 (0.0713)  loss_rpn_box_reg: 0.0663 (0.0696)  time: 0.6939  data: 0.2924  max mem: 5607\n",
      "Training Epoch: [96]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1326 (0.1404)  loss_objectness: 0.0675 (0.0710)  loss_rpn_box_reg: 0.0592 (0.0694)  time: 0.6913  data: 0.2872  max mem: 5607\n",
      "Training Epoch: [96]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1359 (0.1407)  loss_objectness: 0.0675 (0.0711)  loss_rpn_box_reg: 0.0605 (0.0696)  time: 0.6761  data: 0.2923  max mem: 5607\n",
      "Training Epoch: [96]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1359 (0.1401)  loss_objectness: 0.0647 (0.0707)  loss_rpn_box_reg: 0.0620 (0.0694)  time: 0.6815  data: 0.2896  max mem: 5607\n",
      "Training Epoch: [96]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1332 (0.1408)  loss_objectness: 0.0654 (0.0709)  loss_rpn_box_reg: 0.0669 (0.0700)  time: 0.6863  data: 0.2870  max mem: 5607\n",
      "Training Epoch: [96]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1407 (0.1406)  loss_objectness: 0.0675 (0.0707)  loss_rpn_box_reg: 0.0669 (0.0699)  time: 0.6844  data: 0.2896  max mem: 5607\n",
      "Training Epoch: [96] Total time: 0:02:51 (0.6870 s / it)\n",
      "Testing Epoch: [96]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1343 (0.1343)  loss_objectness: 0.0465 (0.0465)  loss_rpn_box_reg: 0.0878 (0.0878)  time: 0.6221  data: 0.3001  max mem: 5607\n",
      "Testing Epoch: [96]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1368 (0.1414)  loss_objectness: 0.0594 (0.0600)  loss_rpn_box_reg: 0.0770 (0.0814)  time: 0.6329  data: 0.3058  max mem: 5607\n",
      "Testing Epoch: [96] Total time: 0:00:39 (0.6337 s / it)\n",
      "Training Epoch: [97]  [  0/250]  eta: 0:02:48  lr: 0.000300  loss: 0.1181 (0.1181)  loss_objectness: 0.0761 (0.0761)  loss_rpn_box_reg: 0.0420 (0.0420)  time: 0.6752  data: 0.2891  max mem: 5607\n",
      "Training Epoch: [97]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1209 (0.1250)  loss_objectness: 0.0691 (0.0681)  loss_rpn_box_reg: 0.0498 (0.0569)  time: 0.6721  data: 0.2910  max mem: 5607\n",
      "Training Epoch: [97]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1243 (0.1320)  loss_objectness: 0.0653 (0.0687)  loss_rpn_box_reg: 0.0571 (0.0633)  time: 0.6865  data: 0.2898  max mem: 5607\n",
      "Training Epoch: [97]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1309 (0.1344)  loss_objectness: 0.0615 (0.0681)  loss_rpn_box_reg: 0.0634 (0.0663)  time: 0.7077  data: 0.2901  max mem: 5607\n",
      "Training Epoch: [97]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1437 (0.1390)  loss_objectness: 0.0689 (0.0694)  loss_rpn_box_reg: 0.0705 (0.0696)  time: 0.6925  data: 0.2933  max mem: 5607\n",
      "Training Epoch: [97]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1437 (0.1403)  loss_objectness: 0.0727 (0.0705)  loss_rpn_box_reg: 0.0753 (0.0698)  time: 0.6732  data: 0.2941  max mem: 5607\n",
      "Training Epoch: [97]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1331 (0.1396)  loss_objectness: 0.0718 (0.0705)  loss_rpn_box_reg: 0.0682 (0.0691)  time: 0.6876  data: 0.2922  max mem: 5607\n",
      "Training Epoch: [97]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1353 (0.1408)  loss_objectness: 0.0672 (0.0710)  loss_rpn_box_reg: 0.0711 (0.0698)  time: 0.6996  data: 0.2908  max mem: 5607\n",
      "Training Epoch: [97]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1427 (0.1418)  loss_objectness: 0.0773 (0.0716)  loss_rpn_box_reg: 0.0699 (0.0702)  time: 0.6936  data: 0.2919  max mem: 5607\n",
      "Training Epoch: [97]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1441 (0.1424)  loss_objectness: 0.0685 (0.0713)  loss_rpn_box_reg: 0.0699 (0.0711)  time: 0.6786  data: 0.2935  max mem: 5607\n",
      "Training Epoch: [97]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1325 (0.1407)  loss_objectness: 0.0629 (0.0709)  loss_rpn_box_reg: 0.0649 (0.0698)  time: 0.6765  data: 0.2909  max mem: 5607\n",
      "Training Epoch: [97]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1325 (0.1411)  loss_objectness: 0.0708 (0.0712)  loss_rpn_box_reg: 0.0707 (0.0699)  time: 0.6910  data: 0.2904  max mem: 5607\n",
      "Training Epoch: [97]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1477 (0.1414)  loss_objectness: 0.0744 (0.0714)  loss_rpn_box_reg: 0.0715 (0.0700)  time: 0.6921  data: 0.2913  max mem: 5607\n",
      "Training Epoch: [97]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1331 (0.1407)  loss_objectness: 0.0736 (0.0715)  loss_rpn_box_reg: 0.0598 (0.0692)  time: 0.6880  data: 0.2902  max mem: 5607\n",
      "Training Epoch: [97]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1331 (0.1415)  loss_objectness: 0.0637 (0.0713)  loss_rpn_box_reg: 0.0717 (0.0702)  time: 0.6993  data: 0.2900  max mem: 5607\n",
      "Training Epoch: [97]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1497 (0.1419)  loss_objectness: 0.0675 (0.0712)  loss_rpn_box_reg: 0.0793 (0.0706)  time: 0.6890  data: 0.2871  max mem: 5607\n",
      "Training Epoch: [97]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1361 (0.1416)  loss_objectness: 0.0699 (0.0713)  loss_rpn_box_reg: 0.0717 (0.0703)  time: 0.6927  data: 0.2892  max mem: 5607\n",
      "Training Epoch: [97]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1345 (0.1417)  loss_objectness: 0.0707 (0.0714)  loss_rpn_box_reg: 0.0595 (0.0703)  time: 0.6948  data: 0.2904  max mem: 5607\n",
      "Training Epoch: [97]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1329 (0.1410)  loss_objectness: 0.0675 (0.0710)  loss_rpn_box_reg: 0.0648 (0.0700)  time: 0.6909  data: 0.2898  max mem: 5607\n",
      "Training Epoch: [97]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1218 (0.1406)  loss_objectness: 0.0637 (0.0709)  loss_rpn_box_reg: 0.0648 (0.0696)  time: 0.6953  data: 0.2926  max mem: 5607\n",
      "Training Epoch: [97]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1306 (0.1402)  loss_objectness: 0.0682 (0.0710)  loss_rpn_box_reg: 0.0603 (0.0692)  time: 0.6774  data: 0.2906  max mem: 5607\n",
      "Training Epoch: [97]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1351 (0.1407)  loss_objectness: 0.0702 (0.0712)  loss_rpn_box_reg: 0.0630 (0.0695)  time: 0.6765  data: 0.2897  max mem: 5607\n",
      "Training Epoch: [97]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1351 (0.1409)  loss_objectness: 0.0729 (0.0714)  loss_rpn_box_reg: 0.0651 (0.0695)  time: 0.6888  data: 0.2933  max mem: 5607\n",
      "Training Epoch: [97]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1347 (0.1408)  loss_objectness: 0.0695 (0.0712)  loss_rpn_box_reg: 0.0636 (0.0696)  time: 0.6818  data: 0.2917  max mem: 5607\n",
      "Training Epoch: [97]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1347 (0.1408)  loss_objectness: 0.0704 (0.0713)  loss_rpn_box_reg: 0.0636 (0.0695)  time: 0.6868  data: 0.2948  max mem: 5607\n",
      "Training Epoch: [97]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1307 (0.1408)  loss_objectness: 0.0704 (0.0714)  loss_rpn_box_reg: 0.0650 (0.0694)  time: 0.6877  data: 0.2985  max mem: 5607\n",
      "Training Epoch: [97] Total time: 0:02:51 (0.6879 s / it)\n",
      "Testing Epoch: [97]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1350 (0.1350)  loss_objectness: 0.0495 (0.0495)  loss_rpn_box_reg: 0.0855 (0.0855)  time: 0.7192  data: 0.3971  max mem: 5607\n",
      "Testing Epoch: [97]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1286 (0.1384)  loss_objectness: 0.0553 (0.0592)  loss_rpn_box_reg: 0.0763 (0.0792)  time: 0.6315  data: 0.3073  max mem: 5607\n",
      "Testing Epoch: [97] Total time: 0:00:39 (0.6351 s / it)\n",
      "Training Epoch: [98]  [  0/250]  eta: 0:03:09  lr: 0.000300  loss: 0.1280 (0.1280)  loss_objectness: 0.0495 (0.0495)  loss_rpn_box_reg: 0.0784 (0.0784)  time: 0.7592  data: 0.2991  max mem: 5607\n",
      "Training Epoch: [98]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1280 (0.1320)  loss_objectness: 0.0681 (0.0680)  loss_rpn_box_reg: 0.0632 (0.0640)  time: 0.6742  data: 0.2930  max mem: 5607\n",
      "Training Epoch: [98]  [ 20/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1270 (0.1304)  loss_objectness: 0.0681 (0.0682)  loss_rpn_box_reg: 0.0594 (0.0622)  time: 0.6734  data: 0.2922  max mem: 5607\n",
      "Training Epoch: [98]  [ 30/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1228 (0.1327)  loss_objectness: 0.0705 (0.0679)  loss_rpn_box_reg: 0.0584 (0.0648)  time: 0.6739  data: 0.2921  max mem: 5607\n",
      "Training Epoch: [98]  [ 40/250]  eta: 0:02:20  lr: 0.000300  loss: 0.1240 (0.1325)  loss_objectness: 0.0705 (0.0687)  loss_rpn_box_reg: 0.0565 (0.0637)  time: 0.6641  data: 0.2885  max mem: 5607\n",
      "Training Epoch: [98]  [ 50/250]  eta: 0:02:14  lr: 0.000300  loss: 0.1240 (0.1336)  loss_objectness: 0.0657 (0.0680)  loss_rpn_box_reg: 0.0594 (0.0656)  time: 0.6714  data: 0.2851  max mem: 5607\n",
      "Training Epoch: [98]  [ 60/250]  eta: 0:02:08  lr: 0.000300  loss: 0.1375 (0.1363)  loss_objectness: 0.0612 (0.0681)  loss_rpn_box_reg: 0.0679 (0.0682)  time: 0.6801  data: 0.2879  max mem: 5607\n",
      "Training Epoch: [98]  [ 70/250]  eta: 0:02:01  lr: 0.000300  loss: 0.1375 (0.1384)  loss_objectness: 0.0679 (0.0682)  loss_rpn_box_reg: 0.0750 (0.0702)  time: 0.6875  data: 0.2932  max mem: 5607\n",
      "Training Epoch: [98]  [ 80/250]  eta: 0:01:54  lr: 0.000300  loss: 0.1508 (0.1390)  loss_objectness: 0.0670 (0.0681)  loss_rpn_box_reg: 0.0754 (0.0710)  time: 0.6798  data: 0.2931  max mem: 5607\n",
      "Training Epoch: [98]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1337 (0.1383)  loss_objectness: 0.0670 (0.0682)  loss_rpn_box_reg: 0.0619 (0.0701)  time: 0.6860  data: 0.2898  max mem: 5607\n",
      "Training Epoch: [98]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1337 (0.1380)  loss_objectness: 0.0734 (0.0691)  loss_rpn_box_reg: 0.0585 (0.0689)  time: 0.6907  data: 0.2904  max mem: 5607\n",
      "Training Epoch: [98]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1345 (0.1375)  loss_objectness: 0.0734 (0.0697)  loss_rpn_box_reg: 0.0502 (0.0679)  time: 0.6841  data: 0.2927  max mem: 5607\n",
      "Training Epoch: [98]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1382 (0.1375)  loss_objectness: 0.0689 (0.0697)  loss_rpn_box_reg: 0.0578 (0.0678)  time: 0.6898  data: 0.2900  max mem: 5607\n",
      "Training Epoch: [98]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1382 (0.1380)  loss_objectness: 0.0646 (0.0693)  loss_rpn_box_reg: 0.0720 (0.0687)  time: 0.6895  data: 0.2886  max mem: 5607\n",
      "Training Epoch: [98]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1327 (0.1385)  loss_objectness: 0.0584 (0.0693)  loss_rpn_box_reg: 0.0705 (0.0692)  time: 0.6819  data: 0.2887  max mem: 5607\n",
      "Training Epoch: [98]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1503 (0.1398)  loss_objectness: 0.0794 (0.0705)  loss_rpn_box_reg: 0.0680 (0.0693)  time: 0.6744  data: 0.2887  max mem: 5607\n",
      "Training Epoch: [98]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1606 (0.1409)  loss_objectness: 0.0879 (0.0715)  loss_rpn_box_reg: 0.0668 (0.0695)  time: 0.6924  data: 0.2932  max mem: 5607\n",
      "Training Epoch: [98]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1387 (0.1404)  loss_objectness: 0.0717 (0.0710)  loss_rpn_box_reg: 0.0687 (0.0694)  time: 0.6931  data: 0.2898  max mem: 5607\n",
      "Training Epoch: [98]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1350 (0.1403)  loss_objectness: 0.0663 (0.0710)  loss_rpn_box_reg: 0.0634 (0.0693)  time: 0.6830  data: 0.2860  max mem: 5607\n",
      "Training Epoch: [98]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1406 (0.1403)  loss_objectness: 0.0732 (0.0713)  loss_rpn_box_reg: 0.0592 (0.0691)  time: 0.6799  data: 0.2888  max mem: 5607\n",
      "Training Epoch: [98]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1451 (0.1417)  loss_objectness: 0.0816 (0.0723)  loss_rpn_box_reg: 0.0682 (0.0693)  time: 0.6804  data: 0.2931  max mem: 5607\n",
      "Training Epoch: [98]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1609 (0.1421)  loss_objectness: 0.0816 (0.0723)  loss_rpn_box_reg: 0.0703 (0.0698)  time: 0.6816  data: 0.2969  max mem: 5607\n",
      "Training Epoch: [98]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1589 (0.1431)  loss_objectness: 0.0704 (0.0726)  loss_rpn_box_reg: 0.0722 (0.0704)  time: 0.6823  data: 0.2953  max mem: 5607\n",
      "Training Epoch: [98]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1554 (0.1431)  loss_objectness: 0.0721 (0.0726)  loss_rpn_box_reg: 0.0728 (0.0705)  time: 0.6991  data: 0.2914  max mem: 5607\n",
      "Training Epoch: [98]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1364 (0.1429)  loss_objectness: 0.0721 (0.0726)  loss_rpn_box_reg: 0.0689 (0.0703)  time: 0.7002  data: 0.2906  max mem: 5607\n",
      "Training Epoch: [98]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1335 (0.1426)  loss_objectness: 0.0707 (0.0728)  loss_rpn_box_reg: 0.0585 (0.0699)  time: 0.6917  data: 0.2900  max mem: 5607\n",
      "Training Epoch: [98] Total time: 0:02:50 (0.6837 s / it)\n",
      "Testing Epoch: [98]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1425 (0.1425)  loss_objectness: 0.0479 (0.0479)  loss_rpn_box_reg: 0.0946 (0.0946)  time: 0.6151  data: 0.2931  max mem: 5607\n",
      "Testing Epoch: [98]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1276 (0.1413)  loss_objectness: 0.0557 (0.0607)  loss_rpn_box_reg: 0.0753 (0.0806)  time: 0.6294  data: 0.3071  max mem: 5607\n",
      "Testing Epoch: [98] Total time: 0:00:39 (0.6397 s / it)\n",
      "Training Epoch: [99]  [  0/250]  eta: 0:02:48  lr: 0.000300  loss: 0.1141 (0.1141)  loss_objectness: 0.0609 (0.0609)  loss_rpn_box_reg: 0.0532 (0.0532)  time: 0.6722  data: 0.2931  max mem: 5607\n",
      "Training Epoch: [99]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1235 (0.1298)  loss_objectness: 0.0629 (0.0708)  loss_rpn_box_reg: 0.0598 (0.0590)  time: 0.6793  data: 0.3002  max mem: 5607\n",
      "Training Epoch: [99]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1249 (0.1345)  loss_objectness: 0.0665 (0.0722)  loss_rpn_box_reg: 0.0570 (0.0623)  time: 0.6815  data: 0.2973  max mem: 5607\n",
      "Training Epoch: [99]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1369 (0.1347)  loss_objectness: 0.0701 (0.0707)  loss_rpn_box_reg: 0.0547 (0.0640)  time: 0.6884  data: 0.2934  max mem: 5607\n",
      "Training Epoch: [99]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1369 (0.1349)  loss_objectness: 0.0666 (0.0705)  loss_rpn_box_reg: 0.0635 (0.0644)  time: 0.6843  data: 0.2887  max mem: 5607\n",
      "Training Epoch: [99]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1314 (0.1344)  loss_objectness: 0.0674 (0.0692)  loss_rpn_box_reg: 0.0655 (0.0652)  time: 0.6808  data: 0.2898  max mem: 5607\n",
      "Training Epoch: [99]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1326 (0.1344)  loss_objectness: 0.0674 (0.0690)  loss_rpn_box_reg: 0.0633 (0.0654)  time: 0.6792  data: 0.2920  max mem: 5607\n",
      "Training Epoch: [99]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1403 (0.1352)  loss_objectness: 0.0687 (0.0694)  loss_rpn_box_reg: 0.0622 (0.0658)  time: 0.6818  data: 0.2897  max mem: 5607\n",
      "Training Epoch: [99]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1445 (0.1361)  loss_objectness: 0.0682 (0.0692)  loss_rpn_box_reg: 0.0672 (0.0670)  time: 0.6943  data: 0.2913  max mem: 5607\n",
      "Training Epoch: [99]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1492 (0.1382)  loss_objectness: 0.0692 (0.0704)  loss_rpn_box_reg: 0.0738 (0.0678)  time: 0.6916  data: 0.2924  max mem: 5607\n",
      "Training Epoch: [99]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1403 (0.1386)  loss_objectness: 0.0692 (0.0702)  loss_rpn_box_reg: 0.0725 (0.0684)  time: 0.6830  data: 0.2907  max mem: 5607\n",
      "Training Epoch: [99]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1294 (0.1380)  loss_objectness: 0.0692 (0.0700)  loss_rpn_box_reg: 0.0609 (0.0681)  time: 0.6909  data: 0.2894  max mem: 5607\n",
      "Training Epoch: [99]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1275 (0.1374)  loss_objectness: 0.0686 (0.0697)  loss_rpn_box_reg: 0.0584 (0.0676)  time: 0.7005  data: 0.2932  max mem: 5607\n",
      "Training Epoch: [99]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1383 (0.1374)  loss_objectness: 0.0629 (0.0697)  loss_rpn_box_reg: 0.0622 (0.0677)  time: 0.6908  data: 0.2942  max mem: 5607\n",
      "Training Epoch: [99]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1430 (0.1392)  loss_objectness: 0.0768 (0.0714)  loss_rpn_box_reg: 0.0705 (0.0678)  time: 0.6844  data: 0.2950  max mem: 5607\n",
      "Training Epoch: [99]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1623 (0.1406)  loss_objectness: 0.0805 (0.0720)  loss_rpn_box_reg: 0.0778 (0.0686)  time: 0.6788  data: 0.2955  max mem: 5607\n",
      "Training Epoch: [99]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1368 (0.1401)  loss_objectness: 0.0704 (0.0719)  loss_rpn_box_reg: 0.0657 (0.0681)  time: 0.6882  data: 0.2924  max mem: 5607\n",
      "Training Epoch: [99]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1332 (0.1405)  loss_objectness: 0.0704 (0.0721)  loss_rpn_box_reg: 0.0628 (0.0684)  time: 0.6933  data: 0.2900  max mem: 5607\n",
      "Training Epoch: [99]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1421 (0.1409)  loss_objectness: 0.0683 (0.0719)  loss_rpn_box_reg: 0.0666 (0.0690)  time: 0.6887  data: 0.2919  max mem: 5607\n",
      "Training Epoch: [99]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1440 (0.1413)  loss_objectness: 0.0636 (0.0718)  loss_rpn_box_reg: 0.0696 (0.0695)  time: 0.6915  data: 0.2916  max mem: 5607\n",
      "Training Epoch: [99]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1482 (0.1420)  loss_objectness: 0.0720 (0.0724)  loss_rpn_box_reg: 0.0724 (0.0696)  time: 0.6886  data: 0.2903  max mem: 5607\n",
      "Training Epoch: [99]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1366 (0.1417)  loss_objectness: 0.0644 (0.0719)  loss_rpn_box_reg: 0.0722 (0.0698)  time: 0.6858  data: 0.2927  max mem: 5607\n",
      "Training Epoch: [99]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1277 (0.1419)  loss_objectness: 0.0639 (0.0717)  loss_rpn_box_reg: 0.0707 (0.0702)  time: 0.6873  data: 0.2961  max mem: 5607\n",
      "Training Epoch: [99]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1441 (0.1422)  loss_objectness: 0.0702 (0.0721)  loss_rpn_box_reg: 0.0575 (0.0701)  time: 0.6834  data: 0.2929  max mem: 5607\n",
      "Training Epoch: [99]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1441 (0.1418)  loss_objectness: 0.0722 (0.0723)  loss_rpn_box_reg: 0.0496 (0.0695)  time: 0.6938  data: 0.2879  max mem: 5607\n",
      "Training Epoch: [99]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1457 (0.1421)  loss_objectness: 0.0665 (0.0724)  loss_rpn_box_reg: 0.0656 (0.0697)  time: 0.6857  data: 0.2855  max mem: 5607\n",
      "Training Epoch: [99] Total time: 0:02:51 (0.6868 s / it)\n",
      "Testing Epoch: [99]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1356 (0.1356)  loss_objectness: 0.0494 (0.0494)  loss_rpn_box_reg: 0.0862 (0.0862)  time: 0.6271  data: 0.2871  max mem: 5607\n",
      "Testing Epoch: [99]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1303 (0.1415)  loss_objectness: 0.0577 (0.0620)  loss_rpn_box_reg: 0.0717 (0.0795)  time: 0.6332  data: 0.3109  max mem: 5607\n",
      "Testing Epoch: [99] Total time: 0:00:39 (0.6364 s / it)\n",
      "Training Epoch: [100]  [  0/250]  eta: 0:02:52  lr: 0.000300  loss: 0.1388 (0.1388)  loss_objectness: 0.0692 (0.0692)  loss_rpn_box_reg: 0.0696 (0.0696)  time: 0.6912  data: 0.2951  max mem: 5607\n",
      "Training Epoch: [100]  [ 10/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1175 (0.1213)  loss_objectness: 0.0620 (0.0635)  loss_rpn_box_reg: 0.0528 (0.0578)  time: 0.7125  data: 0.2921  max mem: 5607\n",
      "Training Epoch: [100]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1272 (0.1308)  loss_objectness: 0.0657 (0.0657)  loss_rpn_box_reg: 0.0547 (0.0651)  time: 0.6921  data: 0.2917  max mem: 5607\n",
      "Training Epoch: [100]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1331 (0.1326)  loss_objectness: 0.0657 (0.0643)  loss_rpn_box_reg: 0.0684 (0.0683)  time: 0.6783  data: 0.2921  max mem: 5607\n",
      "Training Epoch: [100]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1331 (0.1353)  loss_objectness: 0.0614 (0.0661)  loss_rpn_box_reg: 0.0662 (0.0692)  time: 0.6744  data: 0.2918  max mem: 5607\n",
      "Training Epoch: [100]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1397 (0.1377)  loss_objectness: 0.0649 (0.0672)  loss_rpn_box_reg: 0.0662 (0.0704)  time: 0.6748  data: 0.2940  max mem: 5607\n",
      "Training Epoch: [100]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1427 (0.1392)  loss_objectness: 0.0716 (0.0679)  loss_rpn_box_reg: 0.0720 (0.0713)  time: 0.6711  data: 0.2935  max mem: 5607\n",
      "Training Epoch: [100]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1427 (0.1389)  loss_objectness: 0.0685 (0.0687)  loss_rpn_box_reg: 0.0691 (0.0702)  time: 0.6640  data: 0.2911  max mem: 5607\n",
      "Training Epoch: [100]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1252 (0.1367)  loss_objectness: 0.0651 (0.0675)  loss_rpn_box_reg: 0.0573 (0.0692)  time: 0.6882  data: 0.2918  max mem: 5607\n",
      "Training Epoch: [100]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1242 (0.1376)  loss_objectness: 0.0678 (0.0691)  loss_rpn_box_reg: 0.0560 (0.0685)  time: 0.6934  data: 0.2918  max mem: 5607\n",
      "Training Epoch: [100]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1442 (0.1394)  loss_objectness: 0.0760 (0.0698)  loss_rpn_box_reg: 0.0687 (0.0696)  time: 0.6783  data: 0.2915  max mem: 5607\n",
      "Training Epoch: [100]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1478 (0.1406)  loss_objectness: 0.0719 (0.0705)  loss_rpn_box_reg: 0.0769 (0.0701)  time: 0.6883  data: 0.2896  max mem: 5607\n",
      "Training Epoch: [100]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1358 (0.1404)  loss_objectness: 0.0706 (0.0700)  loss_rpn_box_reg: 0.0665 (0.0704)  time: 0.7005  data: 0.2915  max mem: 5607\n",
      "Training Epoch: [100]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1437 (0.1413)  loss_objectness: 0.0696 (0.0703)  loss_rpn_box_reg: 0.0796 (0.0710)  time: 0.6869  data: 0.2918  max mem: 5607\n",
      "Training Epoch: [100]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1567 (0.1424)  loss_objectness: 0.0762 (0.0709)  loss_rpn_box_reg: 0.0793 (0.0715)  time: 0.6846  data: 0.2907  max mem: 5607\n",
      "Training Epoch: [100]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1396 (0.1416)  loss_objectness: 0.0762 (0.0710)  loss_rpn_box_reg: 0.0632 (0.0707)  time: 0.6884  data: 0.2894  max mem: 5607\n",
      "Training Epoch: [100]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1324 (0.1417)  loss_objectness: 0.0709 (0.0715)  loss_rpn_box_reg: 0.0494 (0.0702)  time: 0.6818  data: 0.2866  max mem: 5607\n",
      "Training Epoch: [100]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1341 (0.1408)  loss_objectness: 0.0682 (0.0710)  loss_rpn_box_reg: 0.0569 (0.0699)  time: 0.6837  data: 0.2898  max mem: 5607\n",
      "Training Epoch: [100]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1385 (0.1409)  loss_objectness: 0.0632 (0.0711)  loss_rpn_box_reg: 0.0651 (0.0698)  time: 0.6897  data: 0.2917  max mem: 5607\n",
      "Training Epoch: [100]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1388 (0.1408)  loss_objectness: 0.0666 (0.0710)  loss_rpn_box_reg: 0.0651 (0.0697)  time: 0.6946  data: 0.2890  max mem: 5607\n",
      "Training Epoch: [100]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1369 (0.1409)  loss_objectness: 0.0724 (0.0714)  loss_rpn_box_reg: 0.0685 (0.0695)  time: 0.6979  data: 0.2874  max mem: 5607\n",
      "Training Epoch: [100]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1441 (0.1411)  loss_objectness: 0.0751 (0.0715)  loss_rpn_box_reg: 0.0658 (0.0697)  time: 0.6974  data: 0.2900  max mem: 5607\n",
      "Training Epoch: [100]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1538 (0.1413)  loss_objectness: 0.0753 (0.0718)  loss_rpn_box_reg: 0.0724 (0.0695)  time: 0.7083  data: 0.2978  max mem: 5607\n",
      "Training Epoch: [100]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1415 (0.1412)  loss_objectness: 0.0709 (0.0716)  loss_rpn_box_reg: 0.0627 (0.0695)  time: 0.7179  data: 0.3233  max mem: 5607\n",
      "Training Epoch: [100]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1197 (0.1404)  loss_objectness: 0.0632 (0.0714)  loss_rpn_box_reg: 0.0577 (0.0691)  time: 0.7366  data: 0.3455  max mem: 5607\n",
      "Training Epoch: [100]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1412 (0.1408)  loss_objectness: 0.0684 (0.0716)  loss_rpn_box_reg: 0.0656 (0.0692)  time: 0.7419  data: 0.3439  max mem: 5607\n",
      "Training Epoch: [100] Total time: 0:02:53 (0.6932 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:03  model_time: 0.6672 (0.6672)  evaluator_time: 0.0530 (0.0530)  time: 1.0192  data: 0.2821  max mem: 5607\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3851 (0.3827)  evaluator_time: 0.0640 (0.0753)  time: 0.7698  data: 0.3177  max mem: 5607\n",
      "Test: Total time: 0:00:47 (0.7706 s / it)\n",
      "Averaged stats: model_time: 0.3851 (0.3827)  evaluator_time: 0.0640 (0.0753)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.101\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.162\n",
      "Testing Epoch: [100]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1365 (0.1365)  loss_objectness: 0.0445 (0.0445)  loss_rpn_box_reg: 0.0921 (0.0921)  time: 0.6171  data: 0.2831  max mem: 5607\n",
      "Testing Epoch: [100]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1279 (0.1362)  loss_objectness: 0.0518 (0.0568)  loss_rpn_box_reg: 0.0757 (0.0794)  time: 0.6377  data: 0.3117  max mem: 5607\n",
      "Testing Epoch: [100] Total time: 0:00:39 (0.6391 s / it)\n",
      "Training Epoch: [101]  [  0/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1540 (0.1540)  loss_objectness: 0.0820 (0.0820)  loss_rpn_box_reg: 0.0720 (0.0720)  time: 0.6161  data: 0.2891  max mem: 5607\n",
      "Training Epoch: [101]  [ 10/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1263 (0.1284)  loss_objectness: 0.0602 (0.0609)  loss_rpn_box_reg: 0.0720 (0.0674)  time: 0.6878  data: 0.2939  max mem: 5607\n",
      "Training Epoch: [101]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1252 (0.1302)  loss_objectness: 0.0621 (0.0657)  loss_rpn_box_reg: 0.0547 (0.0645)  time: 0.6895  data: 0.2934  max mem: 5607\n",
      "Training Epoch: [101]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1382 (0.1377)  loss_objectness: 0.0672 (0.0676)  loss_rpn_box_reg: 0.0674 (0.0701)  time: 0.6780  data: 0.2920  max mem: 5607\n",
      "Training Epoch: [101]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1423 (0.1395)  loss_objectness: 0.0722 (0.0692)  loss_rpn_box_reg: 0.0720 (0.0703)  time: 0.6810  data: 0.2932  max mem: 5607\n",
      "Training Epoch: [101]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1353 (0.1400)  loss_objectness: 0.0722 (0.0703)  loss_rpn_box_reg: 0.0633 (0.0697)  time: 0.6832  data: 0.2924  max mem: 5607\n",
      "Training Epoch: [101]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1305 (0.1385)  loss_objectness: 0.0670 (0.0700)  loss_rpn_box_reg: 0.0607 (0.0685)  time: 0.6811  data: 0.2929  max mem: 5607\n",
      "Training Epoch: [101]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1240 (0.1381)  loss_objectness: 0.0603 (0.0694)  loss_rpn_box_reg: 0.0615 (0.0687)  time: 0.6938  data: 0.2971  max mem: 5607\n",
      "Training Epoch: [101]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1357 (0.1399)  loss_objectness: 0.0603 (0.0705)  loss_rpn_box_reg: 0.0639 (0.0694)  time: 0.6893  data: 0.2948  max mem: 5607\n",
      "Training Epoch: [101]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1357 (0.1393)  loss_objectness: 0.0647 (0.0701)  loss_rpn_box_reg: 0.0618 (0.0693)  time: 0.6727  data: 0.2898  max mem: 5607\n",
      "Training Epoch: [101]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1299 (0.1390)  loss_objectness: 0.0687 (0.0700)  loss_rpn_box_reg: 0.0631 (0.0690)  time: 0.6715  data: 0.2872  max mem: 5607\n",
      "Training Epoch: [101]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1367 (0.1391)  loss_objectness: 0.0663 (0.0699)  loss_rpn_box_reg: 0.0649 (0.0692)  time: 0.6802  data: 0.2905  max mem: 5607\n",
      "Training Epoch: [101]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1338 (0.1387)  loss_objectness: 0.0641 (0.0699)  loss_rpn_box_reg: 0.0616 (0.0688)  time: 0.6936  data: 0.2901  max mem: 5607\n",
      "Training Epoch: [101]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1338 (0.1391)  loss_objectness: 0.0671 (0.0700)  loss_rpn_box_reg: 0.0652 (0.0691)  time: 0.6985  data: 0.2919  max mem: 5607\n",
      "Training Epoch: [101]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1376 (0.1389)  loss_objectness: 0.0698 (0.0698)  loss_rpn_box_reg: 0.0707 (0.0691)  time: 0.6932  data: 0.2942  max mem: 5607\n",
      "Training Epoch: [101]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1376 (0.1393)  loss_objectness: 0.0658 (0.0693)  loss_rpn_box_reg: 0.0709 (0.0700)  time: 0.6759  data: 0.2880  max mem: 5607\n",
      "Training Epoch: [101]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1424 (0.1400)  loss_objectness: 0.0673 (0.0697)  loss_rpn_box_reg: 0.0740 (0.0703)  time: 0.6794  data: 0.2891  max mem: 5607\n",
      "Training Epoch: [101]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1412 (0.1408)  loss_objectness: 0.0768 (0.0703)  loss_rpn_box_reg: 0.0690 (0.0705)  time: 0.7024  data: 0.2927  max mem: 5607\n",
      "Training Epoch: [101]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1375 (0.1399)  loss_objectness: 0.0753 (0.0701)  loss_rpn_box_reg: 0.0607 (0.0698)  time: 0.6884  data: 0.2901  max mem: 5607\n",
      "Training Epoch: [101]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1379 (0.1408)  loss_objectness: 0.0753 (0.0708)  loss_rpn_box_reg: 0.0672 (0.0700)  time: 0.6591  data: 0.2881  max mem: 5607\n",
      "Training Epoch: [101]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1499 (0.1410)  loss_objectness: 0.0725 (0.0706)  loss_rpn_box_reg: 0.0683 (0.0704)  time: 0.6589  data: 0.2913  max mem: 5607\n",
      "Training Epoch: [101]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1277 (0.1407)  loss_objectness: 0.0619 (0.0704)  loss_rpn_box_reg: 0.0647 (0.0703)  time: 0.6708  data: 0.2933  max mem: 5607\n",
      "Training Epoch: [101]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1244 (0.1397)  loss_objectness: 0.0653 (0.0701)  loss_rpn_box_reg: 0.0591 (0.0696)  time: 0.6699  data: 0.2905  max mem: 5607\n",
      "Training Epoch: [101]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1244 (0.1399)  loss_objectness: 0.0689 (0.0706)  loss_rpn_box_reg: 0.0556 (0.0693)  time: 0.6686  data: 0.2888  max mem: 5607\n",
      "Training Epoch: [101]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1335 (0.1399)  loss_objectness: 0.0756 (0.0704)  loss_rpn_box_reg: 0.0615 (0.0694)  time: 0.6770  data: 0.2873  max mem: 5607\n",
      "Training Epoch: [101]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1498 (0.1401)  loss_objectness: 0.0662 (0.0703)  loss_rpn_box_reg: 0.0692 (0.0697)  time: 0.6898  data: 0.2886  max mem: 5607\n",
      "Training Epoch: [101] Total time: 0:02:50 (0.6813 s / it)\n",
      "Testing Epoch: [101]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1388 (0.1388)  loss_objectness: 0.0486 (0.0486)  loss_rpn_box_reg: 0.0902 (0.0902)  time: 0.6181  data: 0.2921  max mem: 5607\n",
      "Testing Epoch: [101]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1267 (0.1406)  loss_objectness: 0.0553 (0.0601)  loss_rpn_box_reg: 0.0750 (0.0805)  time: 0.6273  data: 0.3072  max mem: 5607\n",
      "Testing Epoch: [101] Total time: 0:00:39 (0.6317 s / it)\n",
      "Training Epoch: [102]  [  0/250]  eta: 0:03:07  lr: 0.000300  loss: 0.1070 (0.1070)  loss_objectness: 0.0444 (0.0444)  loss_rpn_box_reg: 0.0626 (0.0626)  time: 0.7492  data: 0.3011  max mem: 5607\n",
      "Training Epoch: [102]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1159 (0.1262)  loss_objectness: 0.0645 (0.0668)  loss_rpn_box_reg: 0.0586 (0.0594)  time: 0.6999  data: 0.2903  max mem: 5607\n",
      "Training Epoch: [102]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1256 (0.1339)  loss_objectness: 0.0602 (0.0653)  loss_rpn_box_reg: 0.0655 (0.0686)  time: 0.6786  data: 0.2875  max mem: 5607\n",
      "Training Epoch: [102]  [ 30/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1256 (0.1306)  loss_objectness: 0.0585 (0.0647)  loss_rpn_box_reg: 0.0633 (0.0659)  time: 0.6637  data: 0.2898  max mem: 5607\n",
      "Training Epoch: [102]  [ 40/250]  eta: 0:02:21  lr: 0.000300  loss: 0.1258 (0.1311)  loss_objectness: 0.0633 (0.0657)  loss_rpn_box_reg: 0.0552 (0.0655)  time: 0.6655  data: 0.2907  max mem: 5607\n",
      "Training Epoch: [102]  [ 50/250]  eta: 0:02:14  lr: 0.000300  loss: 0.1272 (0.1306)  loss_objectness: 0.0638 (0.0669)  loss_rpn_box_reg: 0.0542 (0.0637)  time: 0.6667  data: 0.2893  max mem: 5607\n",
      "Training Epoch: [102]  [ 60/250]  eta: 0:02:07  lr: 0.000300  loss: 0.1260 (0.1322)  loss_objectness: 0.0659 (0.0675)  loss_rpn_box_reg: 0.0569 (0.0647)  time: 0.6678  data: 0.2914  max mem: 5607\n",
      "Training Epoch: [102]  [ 70/250]  eta: 0:02:00  lr: 0.000300  loss: 0.1440 (0.1339)  loss_objectness: 0.0656 (0.0681)  loss_rpn_box_reg: 0.0612 (0.0658)  time: 0.6566  data: 0.2897  max mem: 5607\n",
      "Training Epoch: [102]  [ 80/250]  eta: 0:01:54  lr: 0.000300  loss: 0.1262 (0.1326)  loss_objectness: 0.0654 (0.0682)  loss_rpn_box_reg: 0.0582 (0.0644)  time: 0.6705  data: 0.2882  max mem: 5607\n",
      "Training Epoch: [102]  [ 90/250]  eta: 0:01:47  lr: 0.000300  loss: 0.1238 (0.1326)  loss_objectness: 0.0619 (0.0680)  loss_rpn_box_reg: 0.0598 (0.0646)  time: 0.6868  data: 0.2895  max mem: 5607\n",
      "Training Epoch: [102]  [100/250]  eta: 0:01:40  lr: 0.000300  loss: 0.1370 (0.1330)  loss_objectness: 0.0677 (0.0685)  loss_rpn_box_reg: 0.0667 (0.0645)  time: 0.6780  data: 0.2909  max mem: 5607\n",
      "Training Epoch: [102]  [110/250]  eta: 0:01:33  lr: 0.000300  loss: 0.1418 (0.1352)  loss_objectness: 0.0694 (0.0695)  loss_rpn_box_reg: 0.0678 (0.0657)  time: 0.6676  data: 0.2909  max mem: 5607\n",
      "Training Epoch: [102]  [120/250]  eta: 0:01:27  lr: 0.000300  loss: 0.1418 (0.1363)  loss_objectness: 0.0645 (0.0697)  loss_rpn_box_reg: 0.0723 (0.0666)  time: 0.6767  data: 0.2934  max mem: 5607\n",
      "Training Epoch: [102]  [130/250]  eta: 0:01:20  lr: 0.000300  loss: 0.1534 (0.1388)  loss_objectness: 0.0779 (0.0717)  loss_rpn_box_reg: 0.0731 (0.0671)  time: 0.6785  data: 0.2934  max mem: 5607\n",
      "Training Epoch: [102]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1611 (0.1397)  loss_objectness: 0.0765 (0.0717)  loss_rpn_box_reg: 0.0761 (0.0680)  time: 0.6875  data: 0.2884  max mem: 5607\n",
      "Training Epoch: [102]  [150/250]  eta: 0:01:07  lr: 0.000300  loss: 0.1517 (0.1397)  loss_objectness: 0.0695 (0.0718)  loss_rpn_box_reg: 0.0761 (0.0679)  time: 0.7002  data: 0.2892  max mem: 5607\n",
      "Training Epoch: [102]  [160/250]  eta: 0:01:00  lr: 0.000300  loss: 0.1343 (0.1397)  loss_objectness: 0.0708 (0.0715)  loss_rpn_box_reg: 0.0672 (0.0682)  time: 0.6869  data: 0.2905  max mem: 5607\n",
      "Training Epoch: [102]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1371 (0.1402)  loss_objectness: 0.0708 (0.0718)  loss_rpn_box_reg: 0.0672 (0.0684)  time: 0.6936  data: 0.2953  max mem: 5607\n",
      "Training Epoch: [102]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1300 (0.1397)  loss_objectness: 0.0713 (0.0715)  loss_rpn_box_reg: 0.0584 (0.0682)  time: 0.7002  data: 0.2960  max mem: 5607\n",
      "Training Epoch: [102]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1378 (0.1401)  loss_objectness: 0.0760 (0.0722)  loss_rpn_box_reg: 0.0602 (0.0679)  time: 0.6873  data: 0.2920  max mem: 5607\n",
      "Training Epoch: [102]  [200/250]  eta: 0:00:33  lr: 0.000300  loss: 0.1395 (0.1400)  loss_objectness: 0.0746 (0.0721)  loss_rpn_box_reg: 0.0621 (0.0679)  time: 0.6805  data: 0.2934  max mem: 5607\n",
      "Training Epoch: [102]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1395 (0.1403)  loss_objectness: 0.0655 (0.0719)  loss_rpn_box_reg: 0.0745 (0.0684)  time: 0.6878  data: 0.2902  max mem: 5607\n",
      "Training Epoch: [102]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1485 (0.1409)  loss_objectness: 0.0664 (0.0721)  loss_rpn_box_reg: 0.0796 (0.0688)  time: 0.6823  data: 0.2863  max mem: 5607\n",
      "Training Epoch: [102]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1387 (0.1407)  loss_objectness: 0.0682 (0.0721)  loss_rpn_box_reg: 0.0668 (0.0687)  time: 0.6777  data: 0.2857  max mem: 5607\n",
      "Training Epoch: [102]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1414 (0.1413)  loss_objectness: 0.0682 (0.0721)  loss_rpn_box_reg: 0.0668 (0.0692)  time: 0.6908  data: 0.2935  max mem: 5607\n",
      "Training Epoch: [102]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1398 (0.1411)  loss_objectness: 0.0623 (0.0717)  loss_rpn_box_reg: 0.0692 (0.0694)  time: 0.7111  data: 0.2950  max mem: 5607\n",
      "Training Epoch: [102] Total time: 0:02:50 (0.6821 s / it)\n",
      "Testing Epoch: [102]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1412 (0.1412)  loss_objectness: 0.0538 (0.0538)  loss_rpn_box_reg: 0.0875 (0.0875)  time: 0.6161  data: 0.2831  max mem: 5607\n",
      "Testing Epoch: [102]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1272 (0.1389)  loss_objectness: 0.0533 (0.0578)  loss_rpn_box_reg: 0.0729 (0.0811)  time: 0.6344  data: 0.3054  max mem: 5607\n",
      "Testing Epoch: [102] Total time: 0:00:39 (0.6327 s / it)\n",
      "Training Epoch: [103]  [  0/250]  eta: 0:02:57  lr: 0.000300  loss: 0.1275 (0.1275)  loss_objectness: 0.0582 (0.0582)  loss_rpn_box_reg: 0.0692 (0.0692)  time: 0.7092  data: 0.2741  max mem: 5607\n",
      "Training Epoch: [103]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1275 (0.1367)  loss_objectness: 0.0582 (0.0657)  loss_rpn_box_reg: 0.0662 (0.0710)  time: 0.6809  data: 0.2887  max mem: 5607\n",
      "Training Epoch: [103]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1265 (0.1354)  loss_objectness: 0.0675 (0.0729)  loss_rpn_box_reg: 0.0589 (0.0625)  time: 0.6782  data: 0.2897  max mem: 5607\n",
      "Training Epoch: [103]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1345 (0.1366)  loss_objectness: 0.0647 (0.0718)  loss_rpn_box_reg: 0.0623 (0.0648)  time: 0.6891  data: 0.2907  max mem: 5607\n",
      "Training Epoch: [103]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1359 (0.1359)  loss_objectness: 0.0599 (0.0704)  loss_rpn_box_reg: 0.0658 (0.0654)  time: 0.6819  data: 0.2898  max mem: 5607\n",
      "Training Epoch: [103]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1409 (0.1357)  loss_objectness: 0.0648 (0.0697)  loss_rpn_box_reg: 0.0696 (0.0660)  time: 0.6681  data: 0.2913  max mem: 5607\n",
      "Training Epoch: [103]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1483 (0.1365)  loss_objectness: 0.0668 (0.0695)  loss_rpn_box_reg: 0.0742 (0.0670)  time: 0.6855  data: 0.2932  max mem: 5607\n",
      "Training Epoch: [103]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1420 (0.1359)  loss_objectness: 0.0660 (0.0689)  loss_rpn_box_reg: 0.0725 (0.0670)  time: 0.6882  data: 0.2900  max mem: 5607\n",
      "Training Epoch: [103]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1368 (0.1379)  loss_objectness: 0.0704 (0.0700)  loss_rpn_box_reg: 0.0671 (0.0679)  time: 0.6920  data: 0.2885  max mem: 5607\n",
      "Training Epoch: [103]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1463 (0.1387)  loss_objectness: 0.0764 (0.0709)  loss_rpn_box_reg: 0.0673 (0.0678)  time: 0.6884  data: 0.2914  max mem: 5607\n",
      "Training Epoch: [103]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1463 (0.1386)  loss_objectness: 0.0714 (0.0707)  loss_rpn_box_reg: 0.0669 (0.0679)  time: 0.6707  data: 0.2917  max mem: 5607\n",
      "Training Epoch: [103]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1386 (0.1380)  loss_objectness: 0.0646 (0.0703)  loss_rpn_box_reg: 0.0665 (0.0678)  time: 0.6724  data: 0.2891  max mem: 5607\n",
      "Training Epoch: [103]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1321 (0.1375)  loss_objectness: 0.0579 (0.0695)  loss_rpn_box_reg: 0.0590 (0.0681)  time: 0.6783  data: 0.2858  max mem: 5607\n",
      "Training Epoch: [103]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1359 (0.1386)  loss_objectness: 0.0645 (0.0702)  loss_rpn_box_reg: 0.0590 (0.0684)  time: 0.6909  data: 0.2893  max mem: 5607\n",
      "Training Epoch: [103]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1375 (0.1377)  loss_objectness: 0.0709 (0.0703)  loss_rpn_box_reg: 0.0587 (0.0674)  time: 0.6869  data: 0.2934  max mem: 5607\n",
      "Training Epoch: [103]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1375 (0.1388)  loss_objectness: 0.0664 (0.0710)  loss_rpn_box_reg: 0.0641 (0.0678)  time: 0.6741  data: 0.2875  max mem: 5607\n",
      "Training Epoch: [103]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1391 (0.1383)  loss_objectness: 0.0708 (0.0709)  loss_rpn_box_reg: 0.0678 (0.0674)  time: 0.6718  data: 0.2856  max mem: 5607\n",
      "Training Epoch: [103]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1391 (0.1388)  loss_objectness: 0.0696 (0.0710)  loss_rpn_box_reg: 0.0680 (0.0678)  time: 0.6813  data: 0.2889  max mem: 5607\n",
      "Training Epoch: [103]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1429 (0.1397)  loss_objectness: 0.0739 (0.0716)  loss_rpn_box_reg: 0.0757 (0.0682)  time: 0.6823  data: 0.2896  max mem: 5607\n",
      "Training Epoch: [103]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1419 (0.1399)  loss_objectness: 0.0739 (0.0718)  loss_rpn_box_reg: 0.0651 (0.0682)  time: 0.6611  data: 0.2892  max mem: 5607\n",
      "Training Epoch: [103]  [200/250]  eta: 0:00:33  lr: 0.000300  loss: 0.1419 (0.1406)  loss_objectness: 0.0718 (0.0719)  loss_rpn_box_reg: 0.0666 (0.0687)  time: 0.6577  data: 0.2882  max mem: 5607\n",
      "Training Epoch: [103]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1484 (0.1412)  loss_objectness: 0.0705 (0.0716)  loss_rpn_box_reg: 0.0792 (0.0696)  time: 0.6826  data: 0.2883  max mem: 5607\n",
      "Training Epoch: [103]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1563 (0.1417)  loss_objectness: 0.0705 (0.0719)  loss_rpn_box_reg: 0.0753 (0.0697)  time: 0.6866  data: 0.2907  max mem: 5607\n",
      "Training Epoch: [103]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1459 (0.1414)  loss_objectness: 0.0709 (0.0718)  loss_rpn_box_reg: 0.0645 (0.0696)  time: 0.6701  data: 0.2925  max mem: 5607\n",
      "Training Epoch: [103]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1459 (0.1422)  loss_objectness: 0.0746 (0.0722)  loss_rpn_box_reg: 0.0642 (0.0700)  time: 0.6789  data: 0.2927  max mem: 5607\n",
      "Training Epoch: [103]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1457 (0.1421)  loss_objectness: 0.0765 (0.0722)  loss_rpn_box_reg: 0.0741 (0.0699)  time: 0.6796  data: 0.2871  max mem: 5607\n",
      "Training Epoch: [103] Total time: 0:02:49 (0.6787 s / it)\n",
      "Testing Epoch: [103]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1370 (0.1370)  loss_objectness: 0.0455 (0.0455)  loss_rpn_box_reg: 0.0915 (0.0915)  time: 0.6151  data: 0.2931  max mem: 5607\n",
      "Testing Epoch: [103]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1349 (0.1428)  loss_objectness: 0.0586 (0.0626)  loss_rpn_box_reg: 0.0721 (0.0803)  time: 0.6348  data: 0.3083  max mem: 5607\n",
      "Testing Epoch: [103] Total time: 0:00:39 (0.6324 s / it)\n",
      "Training Epoch: [104]  [  0/250]  eta: 0:02:43  lr: 0.000300  loss: 0.0938 (0.0938)  loss_objectness: 0.0674 (0.0674)  loss_rpn_box_reg: 0.0265 (0.0265)  time: 0.6551  data: 0.2971  max mem: 5607\n",
      "Training Epoch: [104]  [ 10/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1412 (0.1358)  loss_objectness: 0.0674 (0.0714)  loss_rpn_box_reg: 0.0661 (0.0644)  time: 0.6701  data: 0.2955  max mem: 5607\n",
      "Training Epoch: [104]  [ 20/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1376 (0.1378)  loss_objectness: 0.0711 (0.0731)  loss_rpn_box_reg: 0.0625 (0.0647)  time: 0.6735  data: 0.2984  max mem: 5607\n",
      "Training Epoch: [104]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1303 (0.1341)  loss_objectness: 0.0684 (0.0699)  loss_rpn_box_reg: 0.0619 (0.0642)  time: 0.6852  data: 0.2958  max mem: 5607\n",
      "Training Epoch: [104]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1332 (0.1374)  loss_objectness: 0.0613 (0.0698)  loss_rpn_box_reg: 0.0688 (0.0676)  time: 0.6980  data: 0.2885  max mem: 5607\n",
      "Training Epoch: [104]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1369 (0.1390)  loss_objectness: 0.0605 (0.0702)  loss_rpn_box_reg: 0.0688 (0.0688)  time: 0.6937  data: 0.2889  max mem: 5607\n",
      "Training Epoch: [104]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1401 (0.1400)  loss_objectness: 0.0671 (0.0701)  loss_rpn_box_reg: 0.0749 (0.0699)  time: 0.6739  data: 0.2912  max mem: 5607\n",
      "Training Epoch: [104]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1457 (0.1417)  loss_objectness: 0.0671 (0.0705)  loss_rpn_box_reg: 0.0780 (0.0712)  time: 0.6779  data: 0.2908  max mem: 5607\n",
      "Training Epoch: [104]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1457 (0.1410)  loss_objectness: 0.0657 (0.0705)  loss_rpn_box_reg: 0.0696 (0.0705)  time: 0.6936  data: 0.2919  max mem: 5607\n",
      "Training Epoch: [104]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1454 (0.1413)  loss_objectness: 0.0662 (0.0705)  loss_rpn_box_reg: 0.0696 (0.0708)  time: 0.6844  data: 0.2883  max mem: 5607\n",
      "Training Epoch: [104]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1469 (0.1415)  loss_objectness: 0.0640 (0.0701)  loss_rpn_box_reg: 0.0751 (0.0715)  time: 0.6749  data: 0.2825  max mem: 5607\n",
      "Training Epoch: [104]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1379 (0.1413)  loss_objectness: 0.0640 (0.0702)  loss_rpn_box_reg: 0.0703 (0.0711)  time: 0.6707  data: 0.2874  max mem: 5607\n",
      "Training Epoch: [104]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1435 (0.1427)  loss_objectness: 0.0725 (0.0705)  loss_rpn_box_reg: 0.0738 (0.0722)  time: 0.6685  data: 0.2879  max mem: 5607\n",
      "Training Epoch: [104]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1440 (0.1430)  loss_objectness: 0.0730 (0.0711)  loss_rpn_box_reg: 0.0706 (0.0719)  time: 0.6752  data: 0.2875  max mem: 5607\n",
      "Training Epoch: [104]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1404 (0.1427)  loss_objectness: 0.0753 (0.0718)  loss_rpn_box_reg: 0.0564 (0.0709)  time: 0.6799  data: 0.2909  max mem: 5607\n",
      "Training Epoch: [104]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1413 (0.1433)  loss_objectness: 0.0829 (0.0726)  loss_rpn_box_reg: 0.0585 (0.0707)  time: 0.6797  data: 0.2908  max mem: 5607\n",
      "Training Epoch: [104]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1402 (0.1436)  loss_objectness: 0.0829 (0.0727)  loss_rpn_box_reg: 0.0693 (0.0709)  time: 0.6856  data: 0.2890  max mem: 5607\n",
      "Training Epoch: [104]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1369 (0.1439)  loss_objectness: 0.0665 (0.0727)  loss_rpn_box_reg: 0.0752 (0.0713)  time: 0.6862  data: 0.2876  max mem: 5607\n",
      "Training Epoch: [104]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1424 (0.1438)  loss_objectness: 0.0711 (0.0731)  loss_rpn_box_reg: 0.0677 (0.0707)  time: 0.6777  data: 0.2906  max mem: 5607\n",
      "Training Epoch: [104]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1424 (0.1440)  loss_objectness: 0.0709 (0.0728)  loss_rpn_box_reg: 0.0671 (0.0712)  time: 0.6812  data: 0.2889  max mem: 5607\n",
      "Training Epoch: [104]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1349 (0.1435)  loss_objectness: 0.0638 (0.0724)  loss_rpn_box_reg: 0.0663 (0.0711)  time: 0.6919  data: 0.2879  max mem: 5607\n",
      "Training Epoch: [104]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1349 (0.1431)  loss_objectness: 0.0649 (0.0723)  loss_rpn_box_reg: 0.0663 (0.0708)  time: 0.6870  data: 0.2907  max mem: 5607\n",
      "Training Epoch: [104]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1405 (0.1436)  loss_objectness: 0.0704 (0.0725)  loss_rpn_box_reg: 0.0734 (0.0711)  time: 0.6835  data: 0.2888  max mem: 5607\n",
      "Training Epoch: [104]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1551 (0.1436)  loss_objectness: 0.0710 (0.0724)  loss_rpn_box_reg: 0.0825 (0.0713)  time: 0.6876  data: 0.2896  max mem: 5607\n",
      "Training Epoch: [104]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1305 (0.1426)  loss_objectness: 0.0717 (0.0722)  loss_rpn_box_reg: 0.0609 (0.0703)  time: 0.6887  data: 0.2907  max mem: 5607\n",
      "Training Epoch: [104]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1254 (0.1423)  loss_objectness: 0.0717 (0.0724)  loss_rpn_box_reg: 0.0530 (0.0699)  time: 0.6864  data: 0.2892  max mem: 5607\n",
      "Training Epoch: [104] Total time: 0:02:50 (0.6826 s / it)\n",
      "Testing Epoch: [104]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1351 (0.1351)  loss_objectness: 0.0477 (0.0477)  loss_rpn_box_reg: 0.0874 (0.0874)  time: 0.6221  data: 0.2901  max mem: 5607\n",
      "Testing Epoch: [104]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1277 (0.1385)  loss_objectness: 0.0537 (0.0593)  loss_rpn_box_reg: 0.0711 (0.0793)  time: 0.6333  data: 0.3092  max mem: 5607\n",
      "Testing Epoch: [104] Total time: 0:00:39 (0.6336 s / it)\n",
      "Training Epoch: [105]  [  0/250]  eta: 0:02:50  lr: 0.000300  loss: 0.1574 (0.1574)  loss_objectness: 0.0552 (0.0552)  loss_rpn_box_reg: 0.1022 (0.1022)  time: 0.6812  data: 0.2881  max mem: 5607\n",
      "Training Epoch: [105]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1397 (0.1365)  loss_objectness: 0.0677 (0.0684)  loss_rpn_box_reg: 0.0659 (0.0680)  time: 0.6847  data: 0.2885  max mem: 5607\n",
      "Training Epoch: [105]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1397 (0.1482)  loss_objectness: 0.0721 (0.0722)  loss_rpn_box_reg: 0.0645 (0.0761)  time: 0.6821  data: 0.2886  max mem: 5607\n",
      "Training Epoch: [105]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1418 (0.1463)  loss_objectness: 0.0688 (0.0712)  loss_rpn_box_reg: 0.0652 (0.0751)  time: 0.6864  data: 0.2926  max mem: 5607\n",
      "Training Epoch: [105]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1454 (0.1447)  loss_objectness: 0.0657 (0.0717)  loss_rpn_box_reg: 0.0659 (0.0730)  time: 0.6761  data: 0.2920  max mem: 5607\n",
      "Training Epoch: [105]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1467 (0.1439)  loss_objectness: 0.0650 (0.0711)  loss_rpn_box_reg: 0.0671 (0.0728)  time: 0.6702  data: 0.2875  max mem: 5607\n",
      "Training Epoch: [105]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1448 (0.1453)  loss_objectness: 0.0661 (0.0711)  loss_rpn_box_reg: 0.0791 (0.0742)  time: 0.6810  data: 0.2897  max mem: 5607\n",
      "Training Epoch: [105]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1448 (0.1454)  loss_objectness: 0.0695 (0.0716)  loss_rpn_box_reg: 0.0776 (0.0738)  time: 0.6891  data: 0.2934  max mem: 5607\n",
      "Training Epoch: [105]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1278 (0.1420)  loss_objectness: 0.0625 (0.0697)  loss_rpn_box_reg: 0.0622 (0.0724)  time: 0.7037  data: 0.2945  max mem: 5607\n",
      "Training Epoch: [105]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1271 (0.1411)  loss_objectness: 0.0599 (0.0699)  loss_rpn_box_reg: 0.0574 (0.0712)  time: 0.6919  data: 0.2923  max mem: 5607\n",
      "Training Epoch: [105]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1270 (0.1397)  loss_objectness: 0.0680 (0.0700)  loss_rpn_box_reg: 0.0551 (0.0698)  time: 0.6807  data: 0.2878  max mem: 5607\n",
      "Training Epoch: [105]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1343 (0.1399)  loss_objectness: 0.0718 (0.0701)  loss_rpn_box_reg: 0.0577 (0.0698)  time: 0.6763  data: 0.2863  max mem: 5607\n",
      "Training Epoch: [105]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1437 (0.1402)  loss_objectness: 0.0691 (0.0704)  loss_rpn_box_reg: 0.0620 (0.0698)  time: 0.6652  data: 0.2899  max mem: 5607\n",
      "Training Epoch: [105]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1346 (0.1394)  loss_objectness: 0.0640 (0.0700)  loss_rpn_box_reg: 0.0621 (0.0694)  time: 0.6752  data: 0.2886  max mem: 5607\n",
      "Training Epoch: [105]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1346 (0.1394)  loss_objectness: 0.0667 (0.0702)  loss_rpn_box_reg: 0.0635 (0.0692)  time: 0.6923  data: 0.2901  max mem: 5607\n",
      "Training Epoch: [105]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1417 (0.1397)  loss_objectness: 0.0695 (0.0704)  loss_rpn_box_reg: 0.0635 (0.0693)  time: 0.6785  data: 0.2934  max mem: 5607\n",
      "Training Epoch: [105]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1417 (0.1397)  loss_objectness: 0.0685 (0.0702)  loss_rpn_box_reg: 0.0691 (0.0696)  time: 0.6751  data: 0.2922  max mem: 5607\n",
      "Training Epoch: [105]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1418 (0.1405)  loss_objectness: 0.0685 (0.0708)  loss_rpn_box_reg: 0.0734 (0.0696)  time: 0.6888  data: 0.2936  max mem: 5607\n",
      "Training Epoch: [105]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1433 (0.1407)  loss_objectness: 0.0752 (0.0713)  loss_rpn_box_reg: 0.0644 (0.0694)  time: 0.6832  data: 0.2897  max mem: 5607\n",
      "Training Epoch: [105]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1442 (0.1409)  loss_objectness: 0.0752 (0.0716)  loss_rpn_box_reg: 0.0613 (0.0693)  time: 0.6841  data: 0.2854  max mem: 5607\n",
      "Training Epoch: [105]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1467 (0.1414)  loss_objectness: 0.0728 (0.0717)  loss_rpn_box_reg: 0.0665 (0.0696)  time: 0.6909  data: 0.2882  max mem: 5607\n",
      "Training Epoch: [105]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1438 (0.1416)  loss_objectness: 0.0728 (0.0719)  loss_rpn_box_reg: 0.0710 (0.0696)  time: 0.6857  data: 0.2924  max mem: 5607\n",
      "Training Epoch: [105]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1438 (0.1418)  loss_objectness: 0.0707 (0.0721)  loss_rpn_box_reg: 0.0734 (0.0697)  time: 0.6786  data: 0.2931  max mem: 5607\n",
      "Training Epoch: [105]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1354 (0.1415)  loss_objectness: 0.0695 (0.0720)  loss_rpn_box_reg: 0.0655 (0.0695)  time: 0.6884  data: 0.2916  max mem: 5607\n",
      "Training Epoch: [105]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1354 (0.1420)  loss_objectness: 0.0682 (0.0720)  loss_rpn_box_reg: 0.0655 (0.0700)  time: 0.6981  data: 0.2889  max mem: 5607\n",
      "Training Epoch: [105]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1490 (0.1417)  loss_objectness: 0.0682 (0.0719)  loss_rpn_box_reg: 0.0677 (0.0698)  time: 0.6909  data: 0.2882  max mem: 5607\n",
      "Training Epoch: [105] Total time: 0:02:51 (0.6840 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:05  model_time: 0.7072 (0.7072)  evaluator_time: 0.0560 (0.0560)  time: 1.0552  data: 0.2771  max mem: 5607\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3901 (0.3936)  evaluator_time: 0.0670 (0.0774)  time: 0.7793  data: 0.3072  max mem: 5624\n",
      "Test: Total time: 0:00:48 (0.7816 s / it)\n",
      "Averaged stats: model_time: 0.3901 (0.3936)  evaluator_time: 0.0670 (0.0774)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.08s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.059\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.171\n",
      "Testing Epoch: [105]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1374 (0.1374)  loss_objectness: 0.0467 (0.0467)  loss_rpn_box_reg: 0.0907 (0.0907)  time: 0.6451  data: 0.2851  max mem: 5624\n",
      "Testing Epoch: [105]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1326 (0.1401)  loss_objectness: 0.0575 (0.0598)  loss_rpn_box_reg: 0.0751 (0.0804)  time: 0.6325  data: 0.3104  max mem: 5624\n",
      "Testing Epoch: [105] Total time: 0:00:39 (0.6333 s / it)\n",
      "Training Epoch: [106]  [  0/250]  eta: 0:03:10  lr: 0.000300  loss: 0.1275 (0.1275)  loss_objectness: 0.0667 (0.0667)  loss_rpn_box_reg: 0.0608 (0.0608)  time: 0.7612  data: 0.2811  max mem: 5624\n",
      "Training Epoch: [106]  [ 10/250]  eta: 0:02:52  lr: 0.000300  loss: 0.1275 (0.1282)  loss_objectness: 0.0667 (0.0629)  loss_rpn_box_reg: 0.0650 (0.0653)  time: 0.7168  data: 0.2946  max mem: 5624\n",
      "Training Epoch: [106]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1226 (0.1257)  loss_objectness: 0.0677 (0.0639)  loss_rpn_box_reg: 0.0624 (0.0618)  time: 0.6882  data: 0.2931  max mem: 5624\n",
      "Training Epoch: [106]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1244 (0.1326)  loss_objectness: 0.0677 (0.0651)  loss_rpn_box_reg: 0.0663 (0.0675)  time: 0.6739  data: 0.2921  max mem: 5624\n",
      "Training Epoch: [106]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1367 (0.1353)  loss_objectness: 0.0697 (0.0692)  loss_rpn_box_reg: 0.0739 (0.0660)  time: 0.6988  data: 0.2922  max mem: 5624\n",
      "Training Epoch: [106]  [ 50/250]  eta: 0:02:19  lr: 0.000300  loss: 0.1373 (0.1375)  loss_objectness: 0.0827 (0.0707)  loss_rpn_box_reg: 0.0591 (0.0667)  time: 0.7060  data: 0.2891  max mem: 5624\n",
      "Training Epoch: [106]  [ 60/250]  eta: 0:02:12  lr: 0.000300  loss: 0.1446 (0.1387)  loss_objectness: 0.0702 (0.0708)  loss_rpn_box_reg: 0.0639 (0.0679)  time: 0.6968  data: 0.2910  max mem: 5624\n",
      "Training Epoch: [106]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1474 (0.1404)  loss_objectness: 0.0716 (0.0719)  loss_rpn_box_reg: 0.0705 (0.0685)  time: 0.6816  data: 0.2935  max mem: 5624\n",
      "Training Epoch: [106]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1406 (0.1401)  loss_objectness: 0.0716 (0.0715)  loss_rpn_box_reg: 0.0716 (0.0686)  time: 0.6614  data: 0.2891  max mem: 5624\n",
      "Training Epoch: [106]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1382 (0.1410)  loss_objectness: 0.0702 (0.0719)  loss_rpn_box_reg: 0.0748 (0.0691)  time: 0.6618  data: 0.2883  max mem: 5624\n",
      "Training Epoch: [106]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1407 (0.1429)  loss_objectness: 0.0796 (0.0726)  loss_rpn_box_reg: 0.0774 (0.0703)  time: 0.6694  data: 0.2905  max mem: 5624\n",
      "Training Epoch: [106]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1396 (0.1428)  loss_objectness: 0.0666 (0.0720)  loss_rpn_box_reg: 0.0775 (0.0708)  time: 0.6755  data: 0.2893  max mem: 5624\n",
      "Training Epoch: [106]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1331 (0.1428)  loss_objectness: 0.0648 (0.0716)  loss_rpn_box_reg: 0.0721 (0.0712)  time: 0.6818  data: 0.2896  max mem: 5624\n",
      "Training Epoch: [106]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1317 (0.1420)  loss_objectness: 0.0659 (0.0711)  loss_rpn_box_reg: 0.0649 (0.0710)  time: 0.6815  data: 0.2899  max mem: 5624\n",
      "Training Epoch: [106]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1300 (0.1409)  loss_objectness: 0.0634 (0.0709)  loss_rpn_box_reg: 0.0610 (0.0700)  time: 0.6704  data: 0.2912  max mem: 5624\n",
      "Training Epoch: [106]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1213 (0.1399)  loss_objectness: 0.0652 (0.0710)  loss_rpn_box_reg: 0.0528 (0.0689)  time: 0.6750  data: 0.2924  max mem: 5624\n",
      "Training Epoch: [106]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1221 (0.1395)  loss_objectness: 0.0652 (0.0708)  loss_rpn_box_reg: 0.0518 (0.0687)  time: 0.6796  data: 0.2886  max mem: 5624\n",
      "Training Epoch: [106]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1245 (0.1394)  loss_objectness: 0.0628 (0.0709)  loss_rpn_box_reg: 0.0592 (0.0685)  time: 0.6845  data: 0.2877  max mem: 5624\n",
      "Training Epoch: [106]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1418 (0.1396)  loss_objectness: 0.0731 (0.0709)  loss_rpn_box_reg: 0.0719 (0.0687)  time: 0.6931  data: 0.2957  max mem: 5624\n",
      "Training Epoch: [106]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1457 (0.1402)  loss_objectness: 0.0716 (0.0709)  loss_rpn_box_reg: 0.0743 (0.0692)  time: 0.6801  data: 0.2982  max mem: 5624\n",
      "Training Epoch: [106]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1365 (0.1403)  loss_objectness: 0.0742 (0.0713)  loss_rpn_box_reg: 0.0643 (0.0690)  time: 0.6830  data: 0.2947  max mem: 5624\n",
      "Training Epoch: [106]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1281 (0.1403)  loss_objectness: 0.0672 (0.0711)  loss_rpn_box_reg: 0.0638 (0.0693)  time: 0.6985  data: 0.2932  max mem: 5624\n",
      "Training Epoch: [106]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1317 (0.1401)  loss_objectness: 0.0629 (0.0710)  loss_rpn_box_reg: 0.0617 (0.0691)  time: 0.6898  data: 0.2927  max mem: 5624\n",
      "Training Epoch: [106]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1476 (0.1411)  loss_objectness: 0.0746 (0.0716)  loss_rpn_box_reg: 0.0700 (0.0695)  time: 0.6695  data: 0.2905  max mem: 5624\n",
      "Training Epoch: [106]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1512 (0.1416)  loss_objectness: 0.0745 (0.0717)  loss_rpn_box_reg: 0.0799 (0.0699)  time: 0.6727  data: 0.2864  max mem: 5624\n",
      "Training Epoch: [106]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1524 (0.1419)  loss_objectness: 0.0732 (0.0720)  loss_rpn_box_reg: 0.0784 (0.0699)  time: 0.6946  data: 0.2839  max mem: 5624\n",
      "Training Epoch: [106] Total time: 0:02:50 (0.6833 s / it)\n",
      "Testing Epoch: [106]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1386 (0.1386)  loss_objectness: 0.0481 (0.0481)  loss_rpn_box_reg: 0.0905 (0.0905)  time: 0.6241  data: 0.2761  max mem: 5624\n",
      "Testing Epoch: [106]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1353 (0.1402)  loss_objectness: 0.0538 (0.0597)  loss_rpn_box_reg: 0.0733 (0.0805)  time: 0.6242  data: 0.3041  max mem: 5624\n",
      "Testing Epoch: [106] Total time: 0:00:39 (0.6307 s / it)\n",
      "Training Epoch: [107]  [  0/250]  eta: 0:02:52  lr: 0.000300  loss: 0.1233 (0.1233)  loss_objectness: 0.0756 (0.0756)  loss_rpn_box_reg: 0.0477 (0.0477)  time: 0.6912  data: 0.2851  max mem: 5624\n",
      "Training Epoch: [107]  [ 10/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1301 (0.1339)  loss_objectness: 0.0640 (0.0658)  loss_rpn_box_reg: 0.0599 (0.0681)  time: 0.6787  data: 0.2839  max mem: 5624\n",
      "Training Epoch: [107]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1454 (0.1442)  loss_objectness: 0.0657 (0.0687)  loss_rpn_box_reg: 0.0805 (0.0755)  time: 0.6806  data: 0.2882  max mem: 5624\n",
      "Training Epoch: [107]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1504 (0.1475)  loss_objectness: 0.0657 (0.0700)  loss_rpn_box_reg: 0.0798 (0.0776)  time: 0.6784  data: 0.2932  max mem: 5624\n",
      "Training Epoch: [107]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1372 (0.1446)  loss_objectness: 0.0651 (0.0707)  loss_rpn_box_reg: 0.0693 (0.0739)  time: 0.6756  data: 0.2927  max mem: 5624\n",
      "Training Epoch: [107]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1306 (0.1449)  loss_objectness: 0.0659 (0.0716)  loss_rpn_box_reg: 0.0658 (0.0733)  time: 0.6859  data: 0.2949  max mem: 5624\n",
      "Training Epoch: [107]  [ 60/250]  eta: 0:02:08  lr: 0.000300  loss: 0.1352 (0.1437)  loss_objectness: 0.0719 (0.0719)  loss_rpn_box_reg: 0.0638 (0.0718)  time: 0.6799  data: 0.2920  max mem: 5624\n",
      "Training Epoch: [107]  [ 70/250]  eta: 0:02:01  lr: 0.000300  loss: 0.1272 (0.1408)  loss_objectness: 0.0671 (0.0705)  loss_rpn_box_reg: 0.0637 (0.0703)  time: 0.6681  data: 0.2864  max mem: 5624\n",
      "Training Epoch: [107]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1292 (0.1400)  loss_objectness: 0.0708 (0.0714)  loss_rpn_box_reg: 0.0577 (0.0686)  time: 0.6749  data: 0.2879  max mem: 5624\n",
      "Training Epoch: [107]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1320 (0.1385)  loss_objectness: 0.0697 (0.0706)  loss_rpn_box_reg: 0.0625 (0.0679)  time: 0.6847  data: 0.2889  max mem: 5624\n",
      "Training Epoch: [107]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1329 (0.1399)  loss_objectness: 0.0701 (0.0715)  loss_rpn_box_reg: 0.0619 (0.0684)  time: 0.6853  data: 0.2888  max mem: 5624\n",
      "Training Epoch: [107]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1329 (0.1395)  loss_objectness: 0.0773 (0.0709)  loss_rpn_box_reg: 0.0636 (0.0686)  time: 0.6824  data: 0.2873  max mem: 5624\n",
      "Training Epoch: [107]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1341 (0.1392)  loss_objectness: 0.0608 (0.0703)  loss_rpn_box_reg: 0.0640 (0.0689)  time: 0.6826  data: 0.2904  max mem: 5624\n",
      "Training Epoch: [107]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1332 (0.1390)  loss_objectness: 0.0608 (0.0702)  loss_rpn_box_reg: 0.0683 (0.0688)  time: 0.6939  data: 0.2920  max mem: 5624\n",
      "Training Epoch: [107]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1259 (0.1386)  loss_objectness: 0.0643 (0.0700)  loss_rpn_box_reg: 0.0648 (0.0686)  time: 0.7052  data: 0.2935  max mem: 5624\n",
      "Training Epoch: [107]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1366 (0.1388)  loss_objectness: 0.0672 (0.0700)  loss_rpn_box_reg: 0.0687 (0.0688)  time: 0.7006  data: 0.2924  max mem: 5624\n",
      "Training Epoch: [107]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1447 (0.1396)  loss_objectness: 0.0729 (0.0706)  loss_rpn_box_reg: 0.0713 (0.0690)  time: 0.6910  data: 0.2884  max mem: 5624\n",
      "Training Epoch: [107]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1495 (0.1407)  loss_objectness: 0.0700 (0.0708)  loss_rpn_box_reg: 0.0755 (0.0700)  time: 0.6846  data: 0.2920  max mem: 5624\n",
      "Training Epoch: [107]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1499 (0.1403)  loss_objectness: 0.0699 (0.0708)  loss_rpn_box_reg: 0.0728 (0.0694)  time: 0.6915  data: 0.2921  max mem: 5624\n",
      "Training Epoch: [107]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1427 (0.1403)  loss_objectness: 0.0665 (0.0706)  loss_rpn_box_reg: 0.0590 (0.0697)  time: 0.6893  data: 0.2901  max mem: 5624\n",
      "Training Epoch: [107]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1363 (0.1402)  loss_objectness: 0.0686 (0.0711)  loss_rpn_box_reg: 0.0587 (0.0691)  time: 0.6784  data: 0.2924  max mem: 5624\n",
      "Training Epoch: [107]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1372 (0.1401)  loss_objectness: 0.0686 (0.0712)  loss_rpn_box_reg: 0.0572 (0.0689)  time: 0.6749  data: 0.2918  max mem: 5624\n",
      "Training Epoch: [107]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1440 (0.1407)  loss_objectness: 0.0668 (0.0714)  loss_rpn_box_reg: 0.0682 (0.0693)  time: 0.6872  data: 0.2916  max mem: 5624\n",
      "Training Epoch: [107]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1447 (0.1407)  loss_objectness: 0.0755 (0.0714)  loss_rpn_box_reg: 0.0681 (0.0693)  time: 0.6900  data: 0.2932  max mem: 5624\n",
      "Training Epoch: [107]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1431 (0.1409)  loss_objectness: 0.0725 (0.0717)  loss_rpn_box_reg: 0.0653 (0.0693)  time: 0.6730  data: 0.2908  max mem: 5624\n",
      "Training Epoch: [107]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1449 (0.1409)  loss_objectness: 0.0715 (0.0714)  loss_rpn_box_reg: 0.0725 (0.0695)  time: 0.6792  data: 0.2901  max mem: 5624\n",
      "Training Epoch: [107] Total time: 0:02:51 (0.6841 s / it)\n",
      "Testing Epoch: [107]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1392 (0.1392)  loss_objectness: 0.0474 (0.0474)  loss_rpn_box_reg: 0.0918 (0.0918)  time: 0.7222  data: 0.3841  max mem: 5624\n",
      "Testing Epoch: [107]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1344 (0.1391)  loss_objectness: 0.0552 (0.0591)  loss_rpn_box_reg: 0.0706 (0.0800)  time: 0.6326  data: 0.3102  max mem: 5624\n",
      "Testing Epoch: [107] Total time: 0:00:39 (0.6349 s / it)\n",
      "Training Epoch: [108]  [  0/250]  eta: 0:02:53  lr: 0.000300  loss: 0.1348 (0.1348)  loss_objectness: 0.0733 (0.0733)  loss_rpn_box_reg: 0.0616 (0.0616)  time: 0.6932  data: 0.2991  max mem: 5624\n",
      "Training Epoch: [108]  [ 10/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1483 (0.1408)  loss_objectness: 0.0760 (0.0746)  loss_rpn_box_reg: 0.0720 (0.0663)  time: 0.6915  data: 0.2968  max mem: 5624\n",
      "Training Epoch: [108]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1515 (0.1447)  loss_objectness: 0.0746 (0.0735)  loss_rpn_box_reg: 0.0748 (0.0712)  time: 0.6922  data: 0.2942  max mem: 5624\n",
      "Training Epoch: [108]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1364 (0.1387)  loss_objectness: 0.0640 (0.0694)  loss_rpn_box_reg: 0.0711 (0.0692)  time: 0.6833  data: 0.2879  max mem: 5624\n",
      "Training Epoch: [108]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1298 (0.1399)  loss_objectness: 0.0640 (0.0697)  loss_rpn_box_reg: 0.0691 (0.0702)  time: 0.6838  data: 0.2846  max mem: 5624\n",
      "Training Epoch: [108]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1289 (0.1380)  loss_objectness: 0.0684 (0.0699)  loss_rpn_box_reg: 0.0619 (0.0681)  time: 0.6961  data: 0.2901  max mem: 5624\n",
      "Training Epoch: [108]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1364 (0.1390)  loss_objectness: 0.0684 (0.0709)  loss_rpn_box_reg: 0.0629 (0.0681)  time: 0.6793  data: 0.2950  max mem: 5624\n",
      "Training Epoch: [108]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1364 (0.1380)  loss_objectness: 0.0759 (0.0715)  loss_rpn_box_reg: 0.0664 (0.0665)  time: 0.6795  data: 0.2920  max mem: 5624\n",
      "Training Epoch: [108]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1270 (0.1392)  loss_objectness: 0.0682 (0.0704)  loss_rpn_box_reg: 0.0553 (0.0688)  time: 0.6827  data: 0.2876  max mem: 5624\n",
      "Training Epoch: [108]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1505 (0.1402)  loss_objectness: 0.0679 (0.0712)  loss_rpn_box_reg: 0.0695 (0.0690)  time: 0.6772  data: 0.2871  max mem: 5624\n",
      "Training Epoch: [108]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1497 (0.1400)  loss_objectness: 0.0706 (0.0706)  loss_rpn_box_reg: 0.0718 (0.0695)  time: 0.6938  data: 0.2900  max mem: 5624\n",
      "Training Epoch: [108]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1493 (0.1417)  loss_objectness: 0.0706 (0.0713)  loss_rpn_box_reg: 0.0819 (0.0704)  time: 0.7067  data: 0.2937  max mem: 5624\n",
      "Training Epoch: [108]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1494 (0.1425)  loss_objectness: 0.0769 (0.0720)  loss_rpn_box_reg: 0.0720 (0.0705)  time: 0.7016  data: 0.2928  max mem: 5624\n",
      "Training Epoch: [108]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1477 (0.1424)  loss_objectness: 0.0769 (0.0721)  loss_rpn_box_reg: 0.0676 (0.0703)  time: 0.6896  data: 0.2905  max mem: 5624\n",
      "Training Epoch: [108]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1187 (0.1414)  loss_objectness: 0.0692 (0.0715)  loss_rpn_box_reg: 0.0586 (0.0699)  time: 0.7012  data: 0.2917  max mem: 5624\n",
      "Training Epoch: [108]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1392 (0.1417)  loss_objectness: 0.0678 (0.0719)  loss_rpn_box_reg: 0.0653 (0.0698)  time: 0.6925  data: 0.2925  max mem: 5624\n",
      "Training Epoch: [108]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1457 (0.1418)  loss_objectness: 0.0714 (0.0720)  loss_rpn_box_reg: 0.0689 (0.0698)  time: 0.6763  data: 0.2923  max mem: 5624\n",
      "Training Epoch: [108]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1457 (0.1419)  loss_objectness: 0.0692 (0.0720)  loss_rpn_box_reg: 0.0655 (0.0699)  time: 0.6776  data: 0.2923  max mem: 5624\n",
      "Training Epoch: [108]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1350 (0.1419)  loss_objectness: 0.0645 (0.0715)  loss_rpn_box_reg: 0.0700 (0.0704)  time: 0.6828  data: 0.2883  max mem: 5624\n",
      "Training Epoch: [108]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1314 (0.1417)  loss_objectness: 0.0641 (0.0719)  loss_rpn_box_reg: 0.0704 (0.0699)  time: 0.6926  data: 0.2878  max mem: 5624\n",
      "Training Epoch: [108]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1333 (0.1414)  loss_objectness: 0.0696 (0.0717)  loss_rpn_box_reg: 0.0561 (0.0697)  time: 0.6832  data: 0.2908  max mem: 5624\n",
      "Training Epoch: [108]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1394 (0.1417)  loss_objectness: 0.0687 (0.0717)  loss_rpn_box_reg: 0.0682 (0.0700)  time: 0.6802  data: 0.2894  max mem: 5624\n",
      "Training Epoch: [108]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1446 (0.1416)  loss_objectness: 0.0738 (0.0719)  loss_rpn_box_reg: 0.0647 (0.0697)  time: 0.6854  data: 0.2876  max mem: 5624\n",
      "Training Epoch: [108]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1344 (0.1416)  loss_objectness: 0.0735 (0.0718)  loss_rpn_box_reg: 0.0593 (0.0697)  time: 0.6734  data: 0.2894  max mem: 5624\n",
      "Training Epoch: [108]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1407 (0.1420)  loss_objectness: 0.0676 (0.0720)  loss_rpn_box_reg: 0.0760 (0.0700)  time: 0.6716  data: 0.2924  max mem: 5624\n",
      "Training Epoch: [108]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1370 (0.1416)  loss_objectness: 0.0665 (0.0717)  loss_rpn_box_reg: 0.0599 (0.0699)  time: 0.6714  data: 0.2896  max mem: 5624\n",
      "Training Epoch: [108] Total time: 0:02:51 (0.6855 s / it)\n",
      "Testing Epoch: [108]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1306 (0.1306)  loss_objectness: 0.0444 (0.0444)  loss_rpn_box_reg: 0.0862 (0.0862)  time: 0.6221  data: 0.2871  max mem: 5624\n",
      "Testing Epoch: [108]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1295 (0.1398)  loss_objectness: 0.0545 (0.0583)  loss_rpn_box_reg: 0.0757 (0.0815)  time: 0.6284  data: 0.3078  max mem: 5624\n",
      "Testing Epoch: [108] Total time: 0:00:39 (0.6340 s / it)\n",
      "Training Epoch: [109]  [  0/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1338 (0.1338)  loss_objectness: 0.0535 (0.0535)  loss_rpn_box_reg: 0.0804 (0.0804)  time: 0.6852  data: 0.2801  max mem: 5624\n",
      "Training Epoch: [109]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1245 (0.1254)  loss_objectness: 0.0590 (0.0649)  loss_rpn_box_reg: 0.0628 (0.0605)  time: 0.6749  data: 0.2883  max mem: 5624\n",
      "Training Epoch: [109]  [ 20/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1245 (0.1313)  loss_objectness: 0.0640 (0.0673)  loss_rpn_box_reg: 0.0628 (0.0641)  time: 0.6711  data: 0.2897  max mem: 5624\n",
      "Training Epoch: [109]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1370 (0.1334)  loss_objectness: 0.0650 (0.0680)  loss_rpn_box_reg: 0.0633 (0.0653)  time: 0.6842  data: 0.2913  max mem: 5624\n",
      "Training Epoch: [109]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1381 (0.1359)  loss_objectness: 0.0650 (0.0690)  loss_rpn_box_reg: 0.0637 (0.0669)  time: 0.6884  data: 0.2928  max mem: 5624\n",
      "Training Epoch: [109]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1275 (0.1355)  loss_objectness: 0.0695 (0.0706)  loss_rpn_box_reg: 0.0637 (0.0649)  time: 0.6826  data: 0.2932  max mem: 5624\n",
      "Training Epoch: [109]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1235 (0.1344)  loss_objectness: 0.0653 (0.0691)  loss_rpn_box_reg: 0.0614 (0.0652)  time: 0.6856  data: 0.2910  max mem: 5624\n",
      "Training Epoch: [109]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1354 (0.1349)  loss_objectness: 0.0628 (0.0694)  loss_rpn_box_reg: 0.0631 (0.0655)  time: 0.6822  data: 0.2882  max mem: 5624\n",
      "Training Epoch: [109]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1436 (0.1373)  loss_objectness: 0.0792 (0.0708)  loss_rpn_box_reg: 0.0674 (0.0665)  time: 0.6903  data: 0.2909  max mem: 5624\n",
      "Training Epoch: [109]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1453 (0.1389)  loss_objectness: 0.0735 (0.0710)  loss_rpn_box_reg: 0.0680 (0.0678)  time: 0.7016  data: 0.2967  max mem: 5624\n",
      "Training Epoch: [109]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1395 (0.1396)  loss_objectness: 0.0679 (0.0718)  loss_rpn_box_reg: 0.0680 (0.0679)  time: 0.7007  data: 0.2954  max mem: 5624\n",
      "Training Epoch: [109]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1498 (0.1410)  loss_objectness: 0.0767 (0.0725)  loss_rpn_box_reg: 0.0686 (0.0686)  time: 0.6924  data: 0.2926  max mem: 5624\n",
      "Training Epoch: [109]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1498 (0.1414)  loss_objectness: 0.0775 (0.0727)  loss_rpn_box_reg: 0.0632 (0.0687)  time: 0.6941  data: 0.2916  max mem: 5624\n",
      "Training Epoch: [109]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1311 (0.1408)  loss_objectness: 0.0705 (0.0726)  loss_rpn_box_reg: 0.0591 (0.0681)  time: 0.6857  data: 0.2910  max mem: 5624\n",
      "Training Epoch: [109]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1241 (0.1402)  loss_objectness: 0.0673 (0.0725)  loss_rpn_box_reg: 0.0604 (0.0676)  time: 0.6759  data: 0.2956  max mem: 5624\n",
      "Training Epoch: [109]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1379 (0.1407)  loss_objectness: 0.0653 (0.0727)  loss_rpn_box_reg: 0.0669 (0.0680)  time: 0.6787  data: 0.2953  max mem: 5624\n",
      "Training Epoch: [109]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1420 (0.1413)  loss_objectness: 0.0711 (0.0727)  loss_rpn_box_reg: 0.0711 (0.0686)  time: 0.6743  data: 0.2911  max mem: 5624\n",
      "Training Epoch: [109]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1336 (0.1412)  loss_objectness: 0.0736 (0.0728)  loss_rpn_box_reg: 0.0623 (0.0684)  time: 0.6921  data: 0.2915  max mem: 5624\n",
      "Training Epoch: [109]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1371 (0.1410)  loss_objectness: 0.0754 (0.0729)  loss_rpn_box_reg: 0.0608 (0.0681)  time: 0.6873  data: 0.2904  max mem: 5624\n",
      "Training Epoch: [109]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1441 (0.1413)  loss_objectness: 0.0715 (0.0727)  loss_rpn_box_reg: 0.0714 (0.0686)  time: 0.6702  data: 0.2915  max mem: 5624\n",
      "Training Epoch: [109]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1457 (0.1419)  loss_objectness: 0.0703 (0.0729)  loss_rpn_box_reg: 0.0730 (0.0690)  time: 0.6815  data: 0.2938  max mem: 5624\n",
      "Training Epoch: [109]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1481 (0.1424)  loss_objectness: 0.0724 (0.0731)  loss_rpn_box_reg: 0.0725 (0.0694)  time: 0.6920  data: 0.2920  max mem: 5624\n",
      "Training Epoch: [109]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1460 (0.1426)  loss_objectness: 0.0663 (0.0727)  loss_rpn_box_reg: 0.0801 (0.0699)  time: 0.6917  data: 0.2914  max mem: 5624\n",
      "Training Epoch: [109]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1370 (0.1427)  loss_objectness: 0.0660 (0.0725)  loss_rpn_box_reg: 0.0756 (0.0702)  time: 0.6864  data: 0.2889  max mem: 5624\n",
      "Training Epoch: [109]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1330 (0.1424)  loss_objectness: 0.0664 (0.0725)  loss_rpn_box_reg: 0.0660 (0.0699)  time: 0.6941  data: 0.2909  max mem: 5624\n",
      "Training Epoch: [109]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1370 (0.1423)  loss_objectness: 0.0667 (0.0724)  loss_rpn_box_reg: 0.0660 (0.0699)  time: 0.6994  data: 0.2936  max mem: 5624\n",
      "Training Epoch: [109] Total time: 0:02:51 (0.6867 s / it)\n",
      "Testing Epoch: [109]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1337 (0.1337)  loss_objectness: 0.0423 (0.0423)  loss_rpn_box_reg: 0.0914 (0.0914)  time: 0.6281  data: 0.3021  max mem: 5624\n",
      "Testing Epoch: [109]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1332 (0.1403)  loss_objectness: 0.0568 (0.0597)  loss_rpn_box_reg: 0.0770 (0.0806)  time: 0.6357  data: 0.3087  max mem: 5624\n",
      "Testing Epoch: [109] Total time: 0:00:39 (0.6336 s / it)\n",
      "Training Epoch: [110]  [  0/250]  eta: 0:02:55  lr: 0.000300  loss: 0.1296 (0.1296)  loss_objectness: 0.0590 (0.0590)  loss_rpn_box_reg: 0.0705 (0.0705)  time: 0.7012  data: 0.3001  max mem: 5624\n",
      "Training Epoch: [110]  [ 10/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1182 (0.1216)  loss_objectness: 0.0622 (0.0656)  loss_rpn_box_reg: 0.0479 (0.0560)  time: 0.6773  data: 0.2949  max mem: 5624\n",
      "Training Epoch: [110]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1248 (0.1298)  loss_objectness: 0.0600 (0.0657)  loss_rpn_box_reg: 0.0569 (0.0641)  time: 0.6807  data: 0.2907  max mem: 5624\n",
      "Training Epoch: [110]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1321 (0.1346)  loss_objectness: 0.0594 (0.0656)  loss_rpn_box_reg: 0.0695 (0.0690)  time: 0.6815  data: 0.2878  max mem: 5624\n",
      "Training Epoch: [110]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1410 (0.1353)  loss_objectness: 0.0596 (0.0654)  loss_rpn_box_reg: 0.0668 (0.0699)  time: 0.6937  data: 0.2918  max mem: 5624\n",
      "Training Epoch: [110]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1416 (0.1367)  loss_objectness: 0.0671 (0.0677)  loss_rpn_box_reg: 0.0641 (0.0690)  time: 0.6972  data: 0.2964  max mem: 5624\n",
      "Training Epoch: [110]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1390 (0.1371)  loss_objectness: 0.0735 (0.0679)  loss_rpn_box_reg: 0.0594 (0.0692)  time: 0.6845  data: 0.2948  max mem: 5624\n",
      "Training Epoch: [110]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1333 (0.1367)  loss_objectness: 0.0622 (0.0671)  loss_rpn_box_reg: 0.0718 (0.0696)  time: 0.6800  data: 0.2872  max mem: 5624\n",
      "Training Epoch: [110]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1333 (0.1377)  loss_objectness: 0.0635 (0.0673)  loss_rpn_box_reg: 0.0742 (0.0705)  time: 0.6821  data: 0.2882  max mem: 5624\n",
      "Training Epoch: [110]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1401 (0.1396)  loss_objectness: 0.0642 (0.0671)  loss_rpn_box_reg: 0.0742 (0.0725)  time: 0.6879  data: 0.2907  max mem: 5624\n",
      "Training Epoch: [110]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1345 (0.1398)  loss_objectness: 0.0656 (0.0678)  loss_rpn_box_reg: 0.0652 (0.0720)  time: 0.6887  data: 0.2908  max mem: 5624\n",
      "Training Epoch: [110]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1364 (0.1409)  loss_objectness: 0.0758 (0.0693)  loss_rpn_box_reg: 0.0566 (0.0716)  time: 0.6818  data: 0.2924  max mem: 5624\n",
      "Training Epoch: [110]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1364 (0.1412)  loss_objectness: 0.0725 (0.0699)  loss_rpn_box_reg: 0.0609 (0.0713)  time: 0.6861  data: 0.2910  max mem: 5624\n",
      "Training Epoch: [110]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1240 (0.1406)  loss_objectness: 0.0686 (0.0698)  loss_rpn_box_reg: 0.0664 (0.0708)  time: 0.6952  data: 0.2879  max mem: 5624\n",
      "Training Epoch: [110]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1297 (0.1404)  loss_objectness: 0.0655 (0.0698)  loss_rpn_box_reg: 0.0664 (0.0706)  time: 0.6845  data: 0.2862  max mem: 5624\n",
      "Training Epoch: [110]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1277 (0.1397)  loss_objectness: 0.0683 (0.0699)  loss_rpn_box_reg: 0.0580 (0.0698)  time: 0.6829  data: 0.2857  max mem: 5624\n",
      "Training Epoch: [110]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1280 (0.1402)  loss_objectness: 0.0753 (0.0708)  loss_rpn_box_reg: 0.0573 (0.0694)  time: 0.6944  data: 0.2898  max mem: 5624\n",
      "Training Epoch: [110]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1280 (0.1393)  loss_objectness: 0.0741 (0.0704)  loss_rpn_box_reg: 0.0585 (0.0689)  time: 0.7015  data: 0.2927  max mem: 5624\n",
      "Training Epoch: [110]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1213 (0.1402)  loss_objectness: 0.0670 (0.0708)  loss_rpn_box_reg: 0.0603 (0.0694)  time: 0.6836  data: 0.2914  max mem: 5624\n",
      "Training Epoch: [110]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1345 (0.1392)  loss_objectness: 0.0670 (0.0704)  loss_rpn_box_reg: 0.0616 (0.0688)  time: 0.6764  data: 0.2903  max mem: 5624\n",
      "Training Epoch: [110]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1345 (0.1396)  loss_objectness: 0.0686 (0.0706)  loss_rpn_box_reg: 0.0614 (0.0690)  time: 0.6912  data: 0.2893  max mem: 5624\n",
      "Training Epoch: [110]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1525 (0.1406)  loss_objectness: 0.0714 (0.0709)  loss_rpn_box_reg: 0.0727 (0.0697)  time: 0.6872  data: 0.2914  max mem: 5624\n",
      "Training Epoch: [110]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1519 (0.1407)  loss_objectness: 0.0745 (0.0709)  loss_rpn_box_reg: 0.0786 (0.0698)  time: 0.6835  data: 0.2944  max mem: 5624\n",
      "Training Epoch: [110]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1446 (0.1409)  loss_objectness: 0.0745 (0.0714)  loss_rpn_box_reg: 0.0673 (0.0695)  time: 0.6839  data: 0.2934  max mem: 5624\n",
      "Training Epoch: [110]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1385 (0.1407)  loss_objectness: 0.0687 (0.0713)  loss_rpn_box_reg: 0.0673 (0.0695)  time: 0.6773  data: 0.2897  max mem: 5624\n",
      "Training Epoch: [110]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1286 (0.1408)  loss_objectness: 0.0670 (0.0714)  loss_rpn_box_reg: 0.0672 (0.0694)  time: 0.6764  data: 0.2893  max mem: 5624\n",
      "Training Epoch: [110] Total time: 0:02:51 (0.6856 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:05  model_time: 0.7072 (0.7072)  evaluator_time: 0.0550 (0.0550)  time: 1.0602  data: 0.2831  max mem: 5624\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3791 (0.3847)  evaluator_time: 0.0640 (0.0776)  time: 0.7686  data: 0.3028  max mem: 5624\n",
      "Test: Total time: 0:00:47 (0.7698 s / it)\n",
      "Averaged stats: model_time: 0.3791 (0.3847)  evaluator_time: 0.0640 (0.0776)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.03s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.059\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.059\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.175\n",
      "Testing Epoch: [110]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1349 (0.1349)  loss_objectness: 0.0471 (0.0471)  loss_rpn_box_reg: 0.0878 (0.0878)  time: 0.6211  data: 0.2971  max mem: 5624\n",
      "Testing Epoch: [110]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1226 (0.1374)  loss_objectness: 0.0563 (0.0587)  loss_rpn_box_reg: 0.0710 (0.0787)  time: 0.6297  data: 0.3097  max mem: 5624\n",
      "Testing Epoch: [110] Total time: 0:00:39 (0.6333 s / it)\n",
      "Training Epoch: [111]  [  0/250]  eta: 0:03:00  lr: 0.000300  loss: 0.1114 (0.1114)  loss_objectness: 0.0529 (0.0529)  loss_rpn_box_reg: 0.0585 (0.0585)  time: 0.7202  data: 0.2961  max mem: 5624\n",
      "Training Epoch: [111]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1252 (0.1374)  loss_objectness: 0.0696 (0.0698)  loss_rpn_box_reg: 0.0600 (0.0675)  time: 0.6815  data: 0.2906  max mem: 5624\n",
      "Training Epoch: [111]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1139 (0.1253)  loss_objectness: 0.0610 (0.0645)  loss_rpn_box_reg: 0.0567 (0.0609)  time: 0.6835  data: 0.2889  max mem: 5624\n",
      "Training Epoch: [111]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1236 (0.1321)  loss_objectness: 0.0606 (0.0655)  loss_rpn_box_reg: 0.0580 (0.0666)  time: 0.6928  data: 0.2920  max mem: 5624\n",
      "Training Epoch: [111]  [ 40/250]  eta: 0:02:26  lr: 0.000300  loss: 0.1273 (0.1333)  loss_objectness: 0.0609 (0.0656)  loss_rpn_box_reg: 0.0711 (0.0677)  time: 0.7065  data: 0.2930  max mem: 5624\n",
      "Training Epoch: [111]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1367 (0.1350)  loss_objectness: 0.0576 (0.0654)  loss_rpn_box_reg: 0.0704 (0.0696)  time: 0.7017  data: 0.2933  max mem: 5624\n",
      "Training Epoch: [111]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1375 (0.1357)  loss_objectness: 0.0638 (0.0657)  loss_rpn_box_reg: 0.0644 (0.0700)  time: 0.6740  data: 0.2934  max mem: 5624\n",
      "Training Epoch: [111]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1416 (0.1382)  loss_objectness: 0.0675 (0.0668)  loss_rpn_box_reg: 0.0771 (0.0714)  time: 0.6786  data: 0.2914  max mem: 5624\n",
      "Training Epoch: [111]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1450 (0.1390)  loss_objectness: 0.0675 (0.0677)  loss_rpn_box_reg: 0.0752 (0.0713)  time: 0.6904  data: 0.2906  max mem: 5624\n",
      "Training Epoch: [111]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1320 (0.1379)  loss_objectness: 0.0687 (0.0675)  loss_rpn_box_reg: 0.0644 (0.0704)  time: 0.6932  data: 0.2889  max mem: 5624\n",
      "Training Epoch: [111]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1348 (0.1379)  loss_objectness: 0.0653 (0.0674)  loss_rpn_box_reg: 0.0644 (0.0704)  time: 0.7063  data: 0.2896  max mem: 5624\n",
      "Training Epoch: [111]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1318 (0.1372)  loss_objectness: 0.0653 (0.0677)  loss_rpn_box_reg: 0.0654 (0.0695)  time: 0.7055  data: 0.2889  max mem: 5624\n",
      "Training Epoch: [111]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1356 (0.1381)  loss_objectness: 0.0737 (0.0680)  loss_rpn_box_reg: 0.0654 (0.0701)  time: 0.6895  data: 0.2895  max mem: 5624\n",
      "Training Epoch: [111]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1459 (0.1386)  loss_objectness: 0.0697 (0.0677)  loss_rpn_box_reg: 0.0718 (0.0709)  time: 0.6829  data: 0.2935  max mem: 5624\n",
      "Training Epoch: [111]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1292 (0.1388)  loss_objectness: 0.0689 (0.0680)  loss_rpn_box_reg: 0.0718 (0.0708)  time: 0.6800  data: 0.2921  max mem: 5624\n",
      "Training Epoch: [111]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1252 (0.1381)  loss_objectness: 0.0689 (0.0684)  loss_rpn_box_reg: 0.0567 (0.0697)  time: 0.6862  data: 0.2899  max mem: 5624\n",
      "Training Epoch: [111]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1367 (0.1400)  loss_objectness: 0.0737 (0.0696)  loss_rpn_box_reg: 0.0647 (0.0704)  time: 0.6981  data: 0.2949  max mem: 5624\n",
      "Training Epoch: [111]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1620 (0.1413)  loss_objectness: 0.0855 (0.0702)  loss_rpn_box_reg: 0.0857 (0.0711)  time: 0.6864  data: 0.2961  max mem: 5624\n",
      "Training Epoch: [111]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1499 (0.1416)  loss_objectness: 0.0831 (0.0707)  loss_rpn_box_reg: 0.0692 (0.0709)  time: 0.6773  data: 0.2938  max mem: 5624\n",
      "Training Epoch: [111]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1499 (0.1420)  loss_objectness: 0.0837 (0.0713)  loss_rpn_box_reg: 0.0651 (0.0707)  time: 0.6812  data: 0.2917  max mem: 5624\n",
      "Training Epoch: [111]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1399 (0.1418)  loss_objectness: 0.0799 (0.0716)  loss_rpn_box_reg: 0.0636 (0.0702)  time: 0.6809  data: 0.2889  max mem: 5624\n",
      "Training Epoch: [111]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1380 (0.1416)  loss_objectness: 0.0709 (0.0715)  loss_rpn_box_reg: 0.0611 (0.0701)  time: 0.6763  data: 0.2872  max mem: 5624\n",
      "Training Epoch: [111]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1412 (0.1421)  loss_objectness: 0.0735 (0.0720)  loss_rpn_box_reg: 0.0707 (0.0701)  time: 0.6780  data: 0.2873  max mem: 5624\n",
      "Training Epoch: [111]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1382 (0.1420)  loss_objectness: 0.0770 (0.0719)  loss_rpn_box_reg: 0.0688 (0.0701)  time: 0.6773  data: 0.2909  max mem: 5624\n",
      "Training Epoch: [111]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1321 (0.1415)  loss_objectness: 0.0667 (0.0718)  loss_rpn_box_reg: 0.0609 (0.0697)  time: 0.6733  data: 0.2926  max mem: 5624\n",
      "Training Epoch: [111]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1321 (0.1414)  loss_objectness: 0.0635 (0.0720)  loss_rpn_box_reg: 0.0598 (0.0695)  time: 0.6747  data: 0.2935  max mem: 5624\n",
      "Training Epoch: [111] Total time: 0:02:51 (0.6860 s / it)\n",
      "Testing Epoch: [111]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1419 (0.1419)  loss_objectness: 0.0510 (0.0510)  loss_rpn_box_reg: 0.0909 (0.0909)  time: 0.6421  data: 0.2781  max mem: 5624\n",
      "Testing Epoch: [111]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1236 (0.1373)  loss_objectness: 0.0538 (0.0577)  loss_rpn_box_reg: 0.0715 (0.0796)  time: 0.6315  data: 0.3099  max mem: 5624\n",
      "Testing Epoch: [111] Total time: 0:00:39 (0.6350 s / it)\n",
      "Training Epoch: [112]  [  0/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1251 (0.1251)  loss_objectness: 0.0591 (0.0591)  loss_rpn_box_reg: 0.0661 (0.0661)  time: 0.6471  data: 0.2791  max mem: 5624\n",
      "Training Epoch: [112]  [ 10/250]  eta: 0:02:49  lr: 0.000300  loss: 0.1459 (0.1398)  loss_objectness: 0.0611 (0.0654)  loss_rpn_box_reg: 0.0768 (0.0744)  time: 0.7066  data: 0.2881  max mem: 5624\n",
      "Training Epoch: [112]  [ 20/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1296 (0.1371)  loss_objectness: 0.0655 (0.0657)  loss_rpn_box_reg: 0.0717 (0.0714)  time: 0.7052  data: 0.2924  max mem: 5624\n",
      "Training Epoch: [112]  [ 30/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1182 (0.1336)  loss_objectness: 0.0655 (0.0666)  loss_rpn_box_reg: 0.0542 (0.0670)  time: 0.7015  data: 0.3008  max mem: 5624\n",
      "Training Epoch: [112]  [ 40/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1297 (0.1354)  loss_objectness: 0.0681 (0.0678)  loss_rpn_box_reg: 0.0606 (0.0676)  time: 0.7132  data: 0.3031  max mem: 5624\n",
      "Training Epoch: [112]  [ 50/250]  eta: 0:02:21  lr: 0.000300  loss: 0.1268 (0.1333)  loss_objectness: 0.0682 (0.0683)  loss_rpn_box_reg: 0.0578 (0.0650)  time: 0.7082  data: 0.2968  max mem: 5624\n",
      "Training Epoch: [112]  [ 60/250]  eta: 0:02:13  lr: 0.000300  loss: 0.1245 (0.1320)  loss_objectness: 0.0642 (0.0677)  loss_rpn_box_reg: 0.0541 (0.0643)  time: 0.6858  data: 0.2926  max mem: 5624\n",
      "Training Epoch: [112]  [ 70/250]  eta: 0:02:05  lr: 0.000300  loss: 0.1213 (0.1318)  loss_objectness: 0.0639 (0.0680)  loss_rpn_box_reg: 0.0644 (0.0638)  time: 0.6753  data: 0.2927  max mem: 5624\n",
      "Training Epoch: [112]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1304 (0.1320)  loss_objectness: 0.0674 (0.0680)  loss_rpn_box_reg: 0.0644 (0.0640)  time: 0.6735  data: 0.2897  max mem: 5624\n",
      "Training Epoch: [112]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1392 (0.1338)  loss_objectness: 0.0674 (0.0680)  loss_rpn_box_reg: 0.0755 (0.0658)  time: 0.6720  data: 0.2907  max mem: 5624\n",
      "Training Epoch: [112]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1408 (0.1337)  loss_objectness: 0.0600 (0.0672)  loss_rpn_box_reg: 0.0805 (0.0665)  time: 0.6698  data: 0.2916  max mem: 5624\n",
      "Training Epoch: [112]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1453 (0.1356)  loss_objectness: 0.0627 (0.0682)  loss_rpn_box_reg: 0.0805 (0.0674)  time: 0.6805  data: 0.2897  max mem: 5624\n",
      "Training Epoch: [112]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1598 (0.1383)  loss_objectness: 0.0672 (0.0684)  loss_rpn_box_reg: 0.0834 (0.0699)  time: 0.6977  data: 0.2966  max mem: 5624\n",
      "Training Epoch: [112]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1518 (0.1382)  loss_objectness: 0.0683 (0.0681)  loss_rpn_box_reg: 0.0773 (0.0701)  time: 0.6946  data: 0.3004  max mem: 5624\n",
      "Training Epoch: [112]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1446 (0.1391)  loss_objectness: 0.0679 (0.0682)  loss_rpn_box_reg: 0.0740 (0.0709)  time: 0.6804  data: 0.2944  max mem: 5624\n",
      "Training Epoch: [112]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1380 (0.1388)  loss_objectness: 0.0700 (0.0687)  loss_rpn_box_reg: 0.0604 (0.0701)  time: 0.6866  data: 0.2896  max mem: 5624\n",
      "Training Epoch: [112]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1179 (0.1379)  loss_objectness: 0.0705 (0.0687)  loss_rpn_box_reg: 0.0488 (0.0692)  time: 0.6906  data: 0.2912  max mem: 5624\n",
      "Training Epoch: [112]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1215 (0.1378)  loss_objectness: 0.0698 (0.0690)  loss_rpn_box_reg: 0.0534 (0.0688)  time: 0.6836  data: 0.2913  max mem: 5624\n",
      "Training Epoch: [112]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1466 (0.1385)  loss_objectness: 0.0685 (0.0693)  loss_rpn_box_reg: 0.0614 (0.0692)  time: 0.6800  data: 0.2889  max mem: 5624\n",
      "Training Epoch: [112]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1472 (0.1385)  loss_objectness: 0.0685 (0.0694)  loss_rpn_box_reg: 0.0749 (0.0691)  time: 0.6850  data: 0.2900  max mem: 5624\n",
      "Training Epoch: [112]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1437 (0.1389)  loss_objectness: 0.0765 (0.0698)  loss_rpn_box_reg: 0.0631 (0.0690)  time: 0.6838  data: 0.2901  max mem: 5624\n",
      "Training Epoch: [112]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1296 (0.1387)  loss_objectness: 0.0672 (0.0695)  loss_rpn_box_reg: 0.0629 (0.0692)  time: 0.6914  data: 0.2906  max mem: 5624\n",
      "Training Epoch: [112]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1296 (0.1385)  loss_objectness: 0.0644 (0.0695)  loss_rpn_box_reg: 0.0629 (0.0690)  time: 0.6806  data: 0.2893  max mem: 5624\n",
      "Training Epoch: [112]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1307 (0.1381)  loss_objectness: 0.0676 (0.0696)  loss_rpn_box_reg: 0.0586 (0.0685)  time: 0.6582  data: 0.2866  max mem: 5624\n",
      "Training Epoch: [112]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1307 (0.1388)  loss_objectness: 0.0656 (0.0701)  loss_rpn_box_reg: 0.0663 (0.0688)  time: 0.6729  data: 0.2933  max mem: 5624\n",
      "Training Epoch: [112]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1456 (0.1396)  loss_objectness: 0.0770 (0.0705)  loss_rpn_box_reg: 0.0781 (0.0691)  time: 0.6921  data: 0.2944  max mem: 5624\n",
      "Training Epoch: [112] Total time: 0:02:51 (0.6868 s / it)\n",
      "Testing Epoch: [112]  [ 0/62]  eta: 0:00:46  lr: 0.000300  loss: 0.1336 (0.1336)  loss_objectness: 0.0447 (0.0447)  loss_rpn_box_reg: 0.0889 (0.0889)  time: 0.7512  data: 0.3921  max mem: 5624\n",
      "Testing Epoch: [112]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1289 (0.1377)  loss_objectness: 0.0547 (0.0584)  loss_rpn_box_reg: 0.0716 (0.0793)  time: 0.6349  data: 0.3122  max mem: 5624\n",
      "Testing Epoch: [112] Total time: 0:00:39 (0.6390 s / it)\n",
      "Training Epoch: [113]  [  0/250]  eta: 0:03:00  lr: 0.000300  loss: 0.1344 (0.1344)  loss_objectness: 0.0710 (0.0710)  loss_rpn_box_reg: 0.0634 (0.0634)  time: 0.7212  data: 0.2951  max mem: 5624\n",
      "Training Epoch: [113]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1336 (0.1395)  loss_objectness: 0.0666 (0.0631)  loss_rpn_box_reg: 0.0634 (0.0764)  time: 0.6981  data: 0.2884  max mem: 5624\n",
      "Training Epoch: [113]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1277 (0.1368)  loss_objectness: 0.0633 (0.0648)  loss_rpn_box_reg: 0.0632 (0.0720)  time: 0.6966  data: 0.2907  max mem: 5624\n",
      "Training Epoch: [113]  [ 30/250]  eta: 0:02:33  lr: 0.000300  loss: 0.1243 (0.1332)  loss_objectness: 0.0633 (0.0654)  loss_rpn_box_reg: 0.0551 (0.0679)  time: 0.6943  data: 0.2921  max mem: 5624\n",
      "Training Epoch: [113]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1235 (0.1324)  loss_objectness: 0.0680 (0.0665)  loss_rpn_box_reg: 0.0551 (0.0659)  time: 0.6807  data: 0.2915  max mem: 5624\n",
      "Training Epoch: [113]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1321 (0.1364)  loss_objectness: 0.0693 (0.0684)  loss_rpn_box_reg: 0.0625 (0.0680)  time: 0.6799  data: 0.2949  max mem: 5624\n",
      "Training Epoch: [113]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1346 (0.1363)  loss_objectness: 0.0663 (0.0681)  loss_rpn_box_reg: 0.0690 (0.0682)  time: 0.6864  data: 0.2929  max mem: 5624\n",
      "Training Epoch: [113]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1301 (0.1350)  loss_objectness: 0.0667 (0.0688)  loss_rpn_box_reg: 0.0516 (0.0662)  time: 0.6931  data: 0.2898  max mem: 5624\n",
      "Training Epoch: [113]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1301 (0.1365)  loss_objectness: 0.0679 (0.0690)  loss_rpn_box_reg: 0.0602 (0.0674)  time: 0.6967  data: 0.2915  max mem: 5624\n",
      "Training Epoch: [113]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1337 (0.1369)  loss_objectness: 0.0668 (0.0691)  loss_rpn_box_reg: 0.0693 (0.0678)  time: 0.6782  data: 0.2917  max mem: 5624\n",
      "Training Epoch: [113]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1333 (0.1375)  loss_objectness: 0.0639 (0.0684)  loss_rpn_box_reg: 0.0709 (0.0691)  time: 0.6780  data: 0.2915  max mem: 5624\n",
      "Training Epoch: [113]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1333 (0.1384)  loss_objectness: 0.0677 (0.0695)  loss_rpn_box_reg: 0.0680 (0.0689)  time: 0.6974  data: 0.2932  max mem: 5624\n",
      "Training Epoch: [113]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1368 (0.1394)  loss_objectness: 0.0740 (0.0701)  loss_rpn_box_reg: 0.0658 (0.0693)  time: 0.6864  data: 0.2956  max mem: 5624\n",
      "Training Epoch: [113]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1403 (0.1394)  loss_objectness: 0.0711 (0.0703)  loss_rpn_box_reg: 0.0671 (0.0691)  time: 0.6811  data: 0.2959  max mem: 5624\n",
      "Training Epoch: [113]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1437 (0.1405)  loss_objectness: 0.0691 (0.0704)  loss_rpn_box_reg: 0.0725 (0.0701)  time: 0.6950  data: 0.2914  max mem: 5624\n",
      "Training Epoch: [113]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1522 (0.1413)  loss_objectness: 0.0713 (0.0705)  loss_rpn_box_reg: 0.0820 (0.0708)  time: 0.6999  data: 0.2911  max mem: 5624\n",
      "Training Epoch: [113]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1424 (0.1415)  loss_objectness: 0.0701 (0.0706)  loss_rpn_box_reg: 0.0770 (0.0709)  time: 0.6782  data: 0.2916  max mem: 5624\n",
      "Training Epoch: [113]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1191 (0.1402)  loss_objectness: 0.0657 (0.0701)  loss_rpn_box_reg: 0.0590 (0.0701)  time: 0.6718  data: 0.2901  max mem: 5624\n",
      "Training Epoch: [113]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1270 (0.1415)  loss_objectness: 0.0657 (0.0711)  loss_rpn_box_reg: 0.0603 (0.0704)  time: 0.6904  data: 0.2928  max mem: 5624\n",
      "Training Epoch: [113]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1532 (0.1414)  loss_objectness: 0.0692 (0.0710)  loss_rpn_box_reg: 0.0687 (0.0704)  time: 0.6823  data: 0.2940  max mem: 5624\n",
      "Training Epoch: [113]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1347 (0.1408)  loss_objectness: 0.0593 (0.0705)  loss_rpn_box_reg: 0.0606 (0.0702)  time: 0.6898  data: 0.2946  max mem: 5624\n",
      "Training Epoch: [113]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1380 (0.1413)  loss_objectness: 0.0654 (0.0708)  loss_rpn_box_reg: 0.0720 (0.0706)  time: 0.6925  data: 0.2954  max mem: 5624\n",
      "Training Epoch: [113]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1473 (0.1414)  loss_objectness: 0.0727 (0.0711)  loss_rpn_box_reg: 0.0716 (0.0703)  time: 0.6732  data: 0.2957  max mem: 5624\n",
      "Training Epoch: [113]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1435 (0.1415)  loss_objectness: 0.0703 (0.0711)  loss_rpn_box_reg: 0.0654 (0.0704)  time: 0.6612  data: 0.2924  max mem: 5624\n",
      "Training Epoch: [113]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1264 (0.1407)  loss_objectness: 0.0664 (0.0711)  loss_rpn_box_reg: 0.0538 (0.0697)  time: 0.6804  data: 0.2927  max mem: 5624\n",
      "Training Epoch: [113]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1264 (0.1408)  loss_objectness: 0.0690 (0.0711)  loss_rpn_box_reg: 0.0538 (0.0697)  time: 0.6987  data: 0.2938  max mem: 5624\n",
      "Training Epoch: [113] Total time: 0:02:51 (0.6864 s / it)\n",
      "Testing Epoch: [113]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1320 (0.1320)  loss_objectness: 0.0442 (0.0442)  loss_rpn_box_reg: 0.0878 (0.0878)  time: 0.6301  data: 0.2921  max mem: 5624\n",
      "Testing Epoch: [113]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1333 (0.1402)  loss_objectness: 0.0567 (0.0593)  loss_rpn_box_reg: 0.0700 (0.0809)  time: 0.6302  data: 0.3102  max mem: 5624\n",
      "Testing Epoch: [113] Total time: 0:00:39 (0.6374 s / it)\n",
      "Training Epoch: [114]  [  0/250]  eta: 0:03:01  lr: 0.000300  loss: 0.1232 (0.1232)  loss_objectness: 0.0596 (0.0596)  loss_rpn_box_reg: 0.0637 (0.0637)  time: 0.7242  data: 0.3071  max mem: 5624\n",
      "Training Epoch: [114]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1232 (0.1378)  loss_objectness: 0.0626 (0.0677)  loss_rpn_box_reg: 0.0638 (0.0701)  time: 0.6800  data: 0.2935  max mem: 5624\n",
      "Training Epoch: [114]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1189 (0.1269)  loss_objectness: 0.0626 (0.0640)  loss_rpn_box_reg: 0.0594 (0.0629)  time: 0.6793  data: 0.2916  max mem: 5624\n",
      "Training Epoch: [114]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1189 (0.1323)  loss_objectness: 0.0663 (0.0670)  loss_rpn_box_reg: 0.0583 (0.0653)  time: 0.6860  data: 0.2931  max mem: 5624\n",
      "Training Epoch: [114]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1311 (0.1314)  loss_objectness: 0.0670 (0.0665)  loss_rpn_box_reg: 0.0604 (0.0649)  time: 0.6859  data: 0.2931  max mem: 5624\n",
      "Training Epoch: [114]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1379 (0.1340)  loss_objectness: 0.0622 (0.0664)  loss_rpn_box_reg: 0.0708 (0.0675)  time: 0.6868  data: 0.2920  max mem: 5624\n",
      "Training Epoch: [114]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1381 (0.1340)  loss_objectness: 0.0650 (0.0673)  loss_rpn_box_reg: 0.0708 (0.0667)  time: 0.6968  data: 0.2900  max mem: 5624\n",
      "Training Epoch: [114]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1172 (0.1342)  loss_objectness: 0.0650 (0.0671)  loss_rpn_box_reg: 0.0591 (0.0671)  time: 0.6865  data: 0.2884  max mem: 5624\n",
      "Training Epoch: [114]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1195 (0.1325)  loss_objectness: 0.0623 (0.0666)  loss_rpn_box_reg: 0.0560 (0.0659)  time: 0.6819  data: 0.2891  max mem: 5624\n",
      "Training Epoch: [114]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1241 (0.1339)  loss_objectness: 0.0636 (0.0679)  loss_rpn_box_reg: 0.0560 (0.0659)  time: 0.6934  data: 0.2914  max mem: 5624\n",
      "Training Epoch: [114]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1409 (0.1350)  loss_objectness: 0.0785 (0.0693)  loss_rpn_box_reg: 0.0597 (0.0657)  time: 0.6844  data: 0.2908  max mem: 5624\n",
      "Training Epoch: [114]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1409 (0.1349)  loss_objectness: 0.0711 (0.0692)  loss_rpn_box_reg: 0.0670 (0.0657)  time: 0.6791  data: 0.2870  max mem: 5624\n",
      "Training Epoch: [114]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1464 (0.1369)  loss_objectness: 0.0675 (0.0700)  loss_rpn_box_reg: 0.0727 (0.0669)  time: 0.6777  data: 0.2863  max mem: 5624\n",
      "Training Epoch: [114]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1462 (0.1370)  loss_objectness: 0.0693 (0.0697)  loss_rpn_box_reg: 0.0727 (0.0673)  time: 0.6855  data: 0.2897  max mem: 5624\n",
      "Training Epoch: [114]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1462 (0.1376)  loss_objectness: 0.0703 (0.0699)  loss_rpn_box_reg: 0.0706 (0.0677)  time: 0.6953  data: 0.2927  max mem: 5624\n",
      "Training Epoch: [114]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1513 (0.1382)  loss_objectness: 0.0720 (0.0703)  loss_rpn_box_reg: 0.0692 (0.0679)  time: 0.6829  data: 0.2955  max mem: 5624\n",
      "Training Epoch: [114]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1412 (0.1385)  loss_objectness: 0.0717 (0.0702)  loss_rpn_box_reg: 0.0681 (0.0683)  time: 0.6792  data: 0.2977  max mem: 5624\n",
      "Training Epoch: [114]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1413 (0.1389)  loss_objectness: 0.0705 (0.0702)  loss_rpn_box_reg: 0.0690 (0.0688)  time: 0.6770  data: 0.2930  max mem: 5624\n",
      "Training Epoch: [114]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1462 (0.1391)  loss_objectness: 0.0671 (0.0704)  loss_rpn_box_reg: 0.0670 (0.0687)  time: 0.6828  data: 0.2923  max mem: 5624\n",
      "Training Epoch: [114]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1522 (0.1400)  loss_objectness: 0.0709 (0.0707)  loss_rpn_box_reg: 0.0741 (0.0693)  time: 0.6863  data: 0.2909  max mem: 5624\n",
      "Training Epoch: [114]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1420 (0.1399)  loss_objectness: 0.0768 (0.0707)  loss_rpn_box_reg: 0.0679 (0.0691)  time: 0.6827  data: 0.2915  max mem: 5624\n",
      "Training Epoch: [114]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1390 (0.1407)  loss_objectness: 0.0793 (0.0713)  loss_rpn_box_reg: 0.0653 (0.0694)  time: 0.6938  data: 0.2975  max mem: 5624\n",
      "Training Epoch: [114]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1517 (0.1409)  loss_objectness: 0.0763 (0.0713)  loss_rpn_box_reg: 0.0761 (0.0696)  time: 0.6928  data: 0.2941  max mem: 5624\n",
      "Training Epoch: [114]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1517 (0.1418)  loss_objectness: 0.0717 (0.0713)  loss_rpn_box_reg: 0.0820 (0.0705)  time: 0.6879  data: 0.2933  max mem: 5624\n",
      "Training Epoch: [114]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1432 (0.1418)  loss_objectness: 0.0704 (0.0713)  loss_rpn_box_reg: 0.0753 (0.0705)  time: 0.6862  data: 0.2964  max mem: 5624\n",
      "Training Epoch: [114]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1355 (0.1412)  loss_objectness: 0.0634 (0.0712)  loss_rpn_box_reg: 0.0681 (0.0701)  time: 0.6930  data: 0.2964  max mem: 5624\n",
      "Training Epoch: [114] Total time: 0:02:51 (0.6863 s / it)\n",
      "Testing Epoch: [114]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1353 (0.1353)  loss_objectness: 0.0474 (0.0474)  loss_rpn_box_reg: 0.0879 (0.0879)  time: 0.6381  data: 0.3071  max mem: 5624\n",
      "Testing Epoch: [114]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1323 (0.1399)  loss_objectness: 0.0569 (0.0589)  loss_rpn_box_reg: 0.0736 (0.0810)  time: 0.6379  data: 0.3091  max mem: 5624\n",
      "Testing Epoch: [114] Total time: 0:00:39 (0.6373 s / it)\n",
      "Training Epoch: [115]  [  0/250]  eta: 0:02:41  lr: 0.000300  loss: 0.0922 (0.0922)  loss_objectness: 0.0401 (0.0401)  loss_rpn_box_reg: 0.0521 (0.0521)  time: 0.6461  data: 0.2731  max mem: 5624\n",
      "Training Epoch: [115]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1259 (0.1340)  loss_objectness: 0.0562 (0.0608)  loss_rpn_box_reg: 0.0598 (0.0732)  time: 0.6796  data: 0.2909  max mem: 5624\n",
      "Training Epoch: [115]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1240 (0.1299)  loss_objectness: 0.0585 (0.0608)  loss_rpn_box_reg: 0.0597 (0.0691)  time: 0.6842  data: 0.2884  max mem: 5624\n",
      "Training Epoch: [115]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1247 (0.1357)  loss_objectness: 0.0652 (0.0638)  loss_rpn_box_reg: 0.0661 (0.0719)  time: 0.6857  data: 0.2898  max mem: 5624\n",
      "Training Epoch: [115]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1423 (0.1351)  loss_objectness: 0.0674 (0.0651)  loss_rpn_box_reg: 0.0628 (0.0700)  time: 0.6820  data: 0.2944  max mem: 5624\n",
      "Training Epoch: [115]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1396 (0.1345)  loss_objectness: 0.0631 (0.0655)  loss_rpn_box_reg: 0.0622 (0.0691)  time: 0.6806  data: 0.2930  max mem: 5624\n",
      "Training Epoch: [115]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1416 (0.1360)  loss_objectness: 0.0738 (0.0686)  loss_rpn_box_reg: 0.0636 (0.0674)  time: 0.6787  data: 0.2925  max mem: 5624\n",
      "Training Epoch: [115]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1319 (0.1363)  loss_objectness: 0.0699 (0.0684)  loss_rpn_box_reg: 0.0636 (0.0680)  time: 0.6926  data: 0.2899  max mem: 5624\n",
      "Training Epoch: [115]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1319 (0.1372)  loss_objectness: 0.0646 (0.0680)  loss_rpn_box_reg: 0.0681 (0.0692)  time: 0.6964  data: 0.2907  max mem: 5624\n",
      "Training Epoch: [115]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1344 (0.1364)  loss_objectness: 0.0623 (0.0682)  loss_rpn_box_reg: 0.0667 (0.0683)  time: 0.6909  data: 0.2943  max mem: 5624\n",
      "Training Epoch: [115]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1328 (0.1361)  loss_objectness: 0.0648 (0.0678)  loss_rpn_box_reg: 0.0656 (0.0683)  time: 0.7002  data: 0.2931  max mem: 5624\n",
      "Training Epoch: [115]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1376 (0.1369)  loss_objectness: 0.0673 (0.0685)  loss_rpn_box_reg: 0.0685 (0.0684)  time: 0.6814  data: 0.2902  max mem: 5624\n",
      "Training Epoch: [115]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1388 (0.1373)  loss_objectness: 0.0680 (0.0680)  loss_rpn_box_reg: 0.0746 (0.0694)  time: 0.6796  data: 0.2913  max mem: 5624\n",
      "Training Epoch: [115]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1380 (0.1378)  loss_objectness: 0.0695 (0.0684)  loss_rpn_box_reg: 0.0725 (0.0693)  time: 0.7007  data: 0.2966  max mem: 5624\n",
      "Training Epoch: [115]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1427 (0.1380)  loss_objectness: 0.0699 (0.0691)  loss_rpn_box_reg: 0.0601 (0.0689)  time: 0.6890  data: 0.2989  max mem: 5624\n",
      "Training Epoch: [115]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1488 (0.1378)  loss_objectness: 0.0681 (0.0691)  loss_rpn_box_reg: 0.0613 (0.0687)  time: 0.6648  data: 0.2954  max mem: 5624\n",
      "Training Epoch: [115]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1461 (0.1385)  loss_objectness: 0.0751 (0.0695)  loss_rpn_box_reg: 0.0682 (0.0690)  time: 0.6701  data: 0.2919  max mem: 5624\n",
      "Training Epoch: [115]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1317 (0.1382)  loss_objectness: 0.0675 (0.0692)  loss_rpn_box_reg: 0.0703 (0.0689)  time: 0.6814  data: 0.2920  max mem: 5624\n",
      "Training Epoch: [115]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1253 (0.1371)  loss_objectness: 0.0667 (0.0692)  loss_rpn_box_reg: 0.0662 (0.0680)  time: 0.6872  data: 0.2930  max mem: 5624\n",
      "Training Epoch: [115]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1366 (0.1383)  loss_objectness: 0.0755 (0.0697)  loss_rpn_box_reg: 0.0687 (0.0686)  time: 0.6884  data: 0.2945  max mem: 5624\n",
      "Training Epoch: [115]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1462 (0.1383)  loss_objectness: 0.0767 (0.0699)  loss_rpn_box_reg: 0.0690 (0.0685)  time: 0.7037  data: 0.2966  max mem: 5624\n",
      "Training Epoch: [115]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1328 (0.1378)  loss_objectness: 0.0709 (0.0698)  loss_rpn_box_reg: 0.0596 (0.0679)  time: 0.7076  data: 0.2965  max mem: 5624\n",
      "Training Epoch: [115]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1316 (0.1380)  loss_objectness: 0.0707 (0.0701)  loss_rpn_box_reg: 0.0596 (0.0679)  time: 0.6894  data: 0.2946  max mem: 5624\n",
      "Training Epoch: [115]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1375 (0.1380)  loss_objectness: 0.0682 (0.0700)  loss_rpn_box_reg: 0.0685 (0.0681)  time: 0.6852  data: 0.2918  max mem: 5624\n",
      "Training Epoch: [115]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1398 (0.1389)  loss_objectness: 0.0713 (0.0704)  loss_rpn_box_reg: 0.0709 (0.0685)  time: 0.6711  data: 0.2903  max mem: 5624\n",
      "Training Epoch: [115]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1508 (0.1395)  loss_objectness: 0.0730 (0.0705)  loss_rpn_box_reg: 0.0726 (0.0690)  time: 0.6839  data: 0.2912  max mem: 5624\n",
      "Training Epoch: [115] Total time: 0:02:51 (0.6867 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:00:57  model_time: 0.5721 (0.5721)  evaluator_time: 0.0610 (0.0610)  time: 0.9312  data: 0.2831  max mem: 5624\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.4001 (0.3993)  evaluator_time: 0.0750 (0.0844)  time: 0.7950  data: 0.3100  max mem: 5923\n",
      "Test: Total time: 0:00:49 (0.7922 s / it)\n",
      "Averaged stats: model_time: 0.4001 (0.3993)  evaluator_time: 0.0750 (0.0844)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.12s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.057\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n",
      "Testing Epoch: [115]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1398 (0.1398)  loss_objectness: 0.0460 (0.0460)  loss_rpn_box_reg: 0.0938 (0.0938)  time: 0.6201  data: 0.2951  max mem: 5923\n",
      "Testing Epoch: [115]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1317 (0.1467)  loss_objectness: 0.0573 (0.0647)  loss_rpn_box_reg: 0.0741 (0.0820)  time: 0.6357  data: 0.3140  max mem: 5923\n",
      "Testing Epoch: [115] Total time: 0:00:39 (0.6373 s / it)\n",
      "Training Epoch: [116]  [  0/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1329 (0.1329)  loss_objectness: 0.0575 (0.0575)  loss_rpn_box_reg: 0.0754 (0.0754)  time: 0.6461  data: 0.2821  max mem: 5923\n",
      "Training Epoch: [116]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1307 (0.1266)  loss_objectness: 0.0724 (0.0697)  loss_rpn_box_reg: 0.0538 (0.0569)  time: 0.6732  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [116]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1307 (0.1314)  loss_objectness: 0.0728 (0.0730)  loss_rpn_box_reg: 0.0555 (0.0585)  time: 0.6830  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [116]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1374 (0.1363)  loss_objectness: 0.0724 (0.0744)  loss_rpn_box_reg: 0.0612 (0.0619)  time: 0.6903  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [116]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1427 (0.1380)  loss_objectness: 0.0724 (0.0746)  loss_rpn_box_reg: 0.0723 (0.0633)  time: 0.6775  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [116]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1441 (0.1405)  loss_objectness: 0.0725 (0.0745)  loss_rpn_box_reg: 0.0732 (0.0660)  time: 0.6899  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [116]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1393 (0.1403)  loss_objectness: 0.0707 (0.0745)  loss_rpn_box_reg: 0.0712 (0.0658)  time: 0.7027  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [116]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1372 (0.1419)  loss_objectness: 0.0700 (0.0734)  loss_rpn_box_reg: 0.0737 (0.0685)  time: 0.6929  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [116]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1347 (0.1421)  loss_objectness: 0.0676 (0.0745)  loss_rpn_box_reg: 0.0656 (0.0676)  time: 0.6837  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [116]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1351 (0.1420)  loss_objectness: 0.0758 (0.0748)  loss_rpn_box_reg: 0.0614 (0.0672)  time: 0.6718  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [116]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1553 (0.1440)  loss_objectness: 0.0763 (0.0754)  loss_rpn_box_reg: 0.0729 (0.0686)  time: 0.6623  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [116]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1464 (0.1439)  loss_objectness: 0.0739 (0.0752)  loss_rpn_box_reg: 0.0674 (0.0687)  time: 0.6716  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [116]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1342 (0.1431)  loss_objectness: 0.0650 (0.0741)  loss_rpn_box_reg: 0.0626 (0.0690)  time: 0.6979  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [116]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1388 (0.1439)  loss_objectness: 0.0632 (0.0737)  loss_rpn_box_reg: 0.0635 (0.0702)  time: 0.6931  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [116]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1436 (0.1436)  loss_objectness: 0.0719 (0.0737)  loss_rpn_box_reg: 0.0667 (0.0698)  time: 0.6857  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [116]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1442 (0.1443)  loss_objectness: 0.0757 (0.0738)  loss_rpn_box_reg: 0.0679 (0.0706)  time: 0.7016  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [116]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1434 (0.1439)  loss_objectness: 0.0667 (0.0734)  loss_rpn_box_reg: 0.0698 (0.0706)  time: 0.7055  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [116]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1316 (0.1432)  loss_objectness: 0.0637 (0.0730)  loss_rpn_box_reg: 0.0632 (0.0702)  time: 0.6897  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [116]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1257 (0.1436)  loss_objectness: 0.0638 (0.0728)  loss_rpn_box_reg: 0.0632 (0.0708)  time: 0.6882  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [116]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1380 (0.1433)  loss_objectness: 0.0696 (0.0730)  loss_rpn_box_reg: 0.0606 (0.0703)  time: 0.6990  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [116]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1308 (0.1425)  loss_objectness: 0.0703 (0.0730)  loss_rpn_box_reg: 0.0548 (0.0695)  time: 0.6923  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [116]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1287 (0.1420)  loss_objectness: 0.0700 (0.0727)  loss_rpn_box_reg: 0.0548 (0.0693)  time: 0.6820  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [116]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1347 (0.1424)  loss_objectness: 0.0665 (0.0726)  loss_rpn_box_reg: 0.0663 (0.0698)  time: 0.6853  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [116]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1349 (0.1419)  loss_objectness: 0.0639 (0.0724)  loss_rpn_box_reg: 0.0629 (0.0695)  time: 0.6914  data: 0.2978  max mem: 5923\n",
      "Training Epoch: [116]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1399 (0.1428)  loss_objectness: 0.0768 (0.0729)  loss_rpn_box_reg: 0.0612 (0.0699)  time: 0.6806  data: 0.2983  max mem: 5923\n",
      "Training Epoch: [116]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1431 (0.1427)  loss_objectness: 0.0773 (0.0729)  loss_rpn_box_reg: 0.0701 (0.0698)  time: 0.6686  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [116] Total time: 0:02:51 (0.6863 s / it)\n",
      "Testing Epoch: [116]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1308 (0.1308)  loss_objectness: 0.0443 (0.0443)  loss_rpn_box_reg: 0.0865 (0.0865)  time: 0.6301  data: 0.3041  max mem: 5923\n",
      "Testing Epoch: [116]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1384 (0.1401)  loss_objectness: 0.0560 (0.0602)  loss_rpn_box_reg: 0.0756 (0.0799)  time: 0.6255  data: 0.3047  max mem: 5923\n",
      "Testing Epoch: [116] Total time: 0:00:39 (0.6364 s / it)\n",
      "Training Epoch: [117]  [  0/250]  eta: 0:02:31  lr: 0.000300  loss: 0.2075 (0.2075)  loss_objectness: 0.1155 (0.1155)  loss_rpn_box_reg: 0.0920 (0.0920)  time: 0.6051  data: 0.3141  max mem: 5923\n",
      "Training Epoch: [117]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1482 (0.1486)  loss_objectness: 0.0727 (0.0732)  loss_rpn_box_reg: 0.0749 (0.0754)  time: 0.6945  data: 0.2965  max mem: 5923\n",
      "Training Epoch: [117]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1314 (0.1410)  loss_objectness: 0.0710 (0.0719)  loss_rpn_box_reg: 0.0641 (0.0691)  time: 0.6919  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [117]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1423 (0.1423)  loss_objectness: 0.0711 (0.0710)  loss_rpn_box_reg: 0.0661 (0.0712)  time: 0.6817  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [117]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1430 (0.1418)  loss_objectness: 0.0707 (0.0710)  loss_rpn_box_reg: 0.0706 (0.0708)  time: 0.6852  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [117]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1308 (0.1406)  loss_objectness: 0.0635 (0.0699)  loss_rpn_box_reg: 0.0661 (0.0707)  time: 0.6881  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [117]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1308 (0.1403)  loss_objectness: 0.0631 (0.0690)  loss_rpn_box_reg: 0.0659 (0.0713)  time: 0.6950  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [117]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1209 (0.1388)  loss_objectness: 0.0631 (0.0688)  loss_rpn_box_reg: 0.0600 (0.0700)  time: 0.6970  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [117]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1268 (0.1392)  loss_objectness: 0.0640 (0.0687)  loss_rpn_box_reg: 0.0590 (0.0705)  time: 0.6863  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [117]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1405 (0.1396)  loss_objectness: 0.0687 (0.0691)  loss_rpn_box_reg: 0.0706 (0.0705)  time: 0.6733  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [117]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1378 (0.1386)  loss_objectness: 0.0698 (0.0693)  loss_rpn_box_reg: 0.0596 (0.0694)  time: 0.6787  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [117]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1380 (0.1400)  loss_objectness: 0.0676 (0.0690)  loss_rpn_box_reg: 0.0693 (0.0710)  time: 0.6975  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [117]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1534 (0.1406)  loss_objectness: 0.0644 (0.0690)  loss_rpn_box_reg: 0.0825 (0.0715)  time: 0.7041  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [117]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1474 (0.1403)  loss_objectness: 0.0640 (0.0690)  loss_rpn_box_reg: 0.0770 (0.0714)  time: 0.7077  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [117]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1322 (0.1403)  loss_objectness: 0.0641 (0.0687)  loss_rpn_box_reg: 0.0683 (0.0716)  time: 0.7021  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [117]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1432 (0.1409)  loss_objectness: 0.0646 (0.0693)  loss_rpn_box_reg: 0.0692 (0.0716)  time: 0.6930  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [117]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1315 (0.1400)  loss_objectness: 0.0644 (0.0687)  loss_rpn_box_reg: 0.0637 (0.0714)  time: 0.6870  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [117]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1168 (0.1391)  loss_objectness: 0.0604 (0.0683)  loss_rpn_box_reg: 0.0637 (0.0708)  time: 0.6832  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [117]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1231 (0.1396)  loss_objectness: 0.0716 (0.0691)  loss_rpn_box_reg: 0.0627 (0.0705)  time: 0.6834  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [117]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1502 (0.1402)  loss_objectness: 0.0802 (0.0695)  loss_rpn_box_reg: 0.0642 (0.0707)  time: 0.6922  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [117]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1502 (0.1406)  loss_objectness: 0.0706 (0.0696)  loss_rpn_box_reg: 0.0717 (0.0710)  time: 0.6900  data: 0.2978  max mem: 5923\n",
      "Training Epoch: [117]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1523 (0.1413)  loss_objectness: 0.0773 (0.0704)  loss_rpn_box_reg: 0.0663 (0.0709)  time: 0.6884  data: 0.2981  max mem: 5923\n",
      "Training Epoch: [117]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1447 (0.1413)  loss_objectness: 0.0809 (0.0707)  loss_rpn_box_reg: 0.0593 (0.0705)  time: 0.7012  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [117]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1361 (0.1415)  loss_objectness: 0.0708 (0.0713)  loss_rpn_box_reg: 0.0593 (0.0703)  time: 0.6863  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [117]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1314 (0.1408)  loss_objectness: 0.0670 (0.0711)  loss_rpn_box_reg: 0.0586 (0.0697)  time: 0.6776  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [117]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1248 (0.1404)  loss_objectness: 0.0662 (0.0711)  loss_rpn_box_reg: 0.0565 (0.0694)  time: 0.7017  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [117] Total time: 0:02:52 (0.6911 s / it)\n",
      "Testing Epoch: [117]  [ 0/62]  eta: 0:00:45  lr: 0.000300  loss: 0.1377 (0.1377)  loss_objectness: 0.0517 (0.0517)  loss_rpn_box_reg: 0.0860 (0.0860)  time: 0.7362  data: 0.4011  max mem: 5923\n",
      "Testing Epoch: [117]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1333 (0.1390)  loss_objectness: 0.0529 (0.0579)  loss_rpn_box_reg: 0.0777 (0.0812)  time: 0.6386  data: 0.3132  max mem: 5923\n",
      "Testing Epoch: [117] Total time: 0:00:39 (0.6394 s / it)\n",
      "Training Epoch: [118]  [  0/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1228 (0.1228)  loss_objectness: 0.0573 (0.0573)  loss_rpn_box_reg: 0.0655 (0.0655)  time: 0.6682  data: 0.3031  max mem: 5923\n",
      "Training Epoch: [118]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1228 (0.1233)  loss_objectness: 0.0618 (0.0630)  loss_rpn_box_reg: 0.0651 (0.0603)  time: 0.6712  data: 0.2874  max mem: 5923\n",
      "Training Epoch: [118]  [ 20/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1249 (0.1282)  loss_objectness: 0.0620 (0.0646)  loss_rpn_box_reg: 0.0651 (0.0637)  time: 0.6717  data: 0.2884  max mem: 5923\n",
      "Training Epoch: [118]  [ 30/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1359 (0.1322)  loss_objectness: 0.0682 (0.0664)  loss_rpn_box_reg: 0.0670 (0.0658)  time: 0.6803  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [118]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1344 (0.1316)  loss_objectness: 0.0670 (0.0670)  loss_rpn_box_reg: 0.0647 (0.0646)  time: 0.6949  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [118]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1309 (0.1349)  loss_objectness: 0.0733 (0.0692)  loss_rpn_box_reg: 0.0647 (0.0657)  time: 0.6847  data: 0.2968  max mem: 5923\n",
      "Training Epoch: [118]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1528 (0.1384)  loss_objectness: 0.0733 (0.0712)  loss_rpn_box_reg: 0.0704 (0.0673)  time: 0.6870  data: 0.2991  max mem: 5923\n",
      "Training Epoch: [118]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1455 (0.1379)  loss_objectness: 0.0699 (0.0703)  loss_rpn_box_reg: 0.0701 (0.0675)  time: 0.7015  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [118]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1362 (0.1378)  loss_objectness: 0.0673 (0.0703)  loss_rpn_box_reg: 0.0676 (0.0674)  time: 0.7006  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [118]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1382 (0.1380)  loss_objectness: 0.0715 (0.0705)  loss_rpn_box_reg: 0.0670 (0.0676)  time: 0.6873  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [118]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1427 (0.1395)  loss_objectness: 0.0690 (0.0708)  loss_rpn_box_reg: 0.0722 (0.0687)  time: 0.6902  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [118]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1377 (0.1386)  loss_objectness: 0.0685 (0.0707)  loss_rpn_box_reg: 0.0722 (0.0679)  time: 0.7055  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [118]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1308 (0.1380)  loss_objectness: 0.0683 (0.0705)  loss_rpn_box_reg: 0.0604 (0.0675)  time: 0.6929  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [118]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1445 (0.1393)  loss_objectness: 0.0720 (0.0708)  loss_rpn_box_reg: 0.0665 (0.0685)  time: 0.6829  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [118]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1455 (0.1393)  loss_objectness: 0.0720 (0.0706)  loss_rpn_box_reg: 0.0679 (0.0686)  time: 0.7037  data: 0.2969  max mem: 5923\n",
      "Training Epoch: [118]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1442 (0.1396)  loss_objectness: 0.0714 (0.0708)  loss_rpn_box_reg: 0.0765 (0.0688)  time: 0.7020  data: 0.2987  max mem: 5923\n",
      "Training Epoch: [118]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1498 (0.1402)  loss_objectness: 0.0734 (0.0709)  loss_rpn_box_reg: 0.0766 (0.0694)  time: 0.6810  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [118]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1498 (0.1407)  loss_objectness: 0.0727 (0.0710)  loss_rpn_box_reg: 0.0763 (0.0698)  time: 0.7040  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [118]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1451 (0.1408)  loss_objectness: 0.0687 (0.0710)  loss_rpn_box_reg: 0.0672 (0.0698)  time: 0.7072  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [118]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1398 (0.1410)  loss_objectness: 0.0684 (0.0709)  loss_rpn_box_reg: 0.0717 (0.0701)  time: 0.7104  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [118]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1331 (0.1405)  loss_objectness: 0.0641 (0.0705)  loss_rpn_box_reg: 0.0717 (0.0700)  time: 0.7017  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [118]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1453 (0.1411)  loss_objectness: 0.0641 (0.0706)  loss_rpn_box_reg: 0.0731 (0.0705)  time: 0.6846  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [118]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1488 (0.1408)  loss_objectness: 0.0646 (0.0702)  loss_rpn_box_reg: 0.0771 (0.0706)  time: 0.6913  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [118]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1400 (0.1410)  loss_objectness: 0.0688 (0.0708)  loss_rpn_box_reg: 0.0674 (0.0702)  time: 0.6854  data: 0.2997  max mem: 5923\n",
      "Training Epoch: [118]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1259 (0.1405)  loss_objectness: 0.0713 (0.0707)  loss_rpn_box_reg: 0.0529 (0.0698)  time: 0.6816  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [118]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1390 (0.1409)  loss_objectness: 0.0723 (0.0710)  loss_rpn_box_reg: 0.0574 (0.0699)  time: 0.6793  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [118] Total time: 0:02:52 (0.6915 s / it)\n",
      "Testing Epoch: [118]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1290 (0.1290)  loss_objectness: 0.0421 (0.0421)  loss_rpn_box_reg: 0.0870 (0.0870)  time: 0.6241  data: 0.2891  max mem: 5923\n",
      "Testing Epoch: [118]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1299 (0.1368)  loss_objectness: 0.0528 (0.0575)  loss_rpn_box_reg: 0.0729 (0.0793)  time: 0.6424  data: 0.3150  max mem: 5923\n",
      "Testing Epoch: [118] Total time: 0:00:39 (0.6405 s / it)\n",
      "Training Epoch: [119]  [  0/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1289 (0.1289)  loss_objectness: 0.0756 (0.0756)  loss_rpn_box_reg: 0.0533 (0.0533)  time: 0.6682  data: 0.2841  max mem: 5923\n",
      "Training Epoch: [119]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1329 (0.1311)  loss_objectness: 0.0634 (0.0662)  loss_rpn_box_reg: 0.0587 (0.0649)  time: 0.6718  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [119]  [ 20/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1363 (0.1354)  loss_objectness: 0.0634 (0.0680)  loss_rpn_box_reg: 0.0644 (0.0674)  time: 0.6724  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [119]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1363 (0.1356)  loss_objectness: 0.0665 (0.0675)  loss_rpn_box_reg: 0.0644 (0.0681)  time: 0.6876  data: 0.2969  max mem: 5923\n",
      "Training Epoch: [119]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1314 (0.1337)  loss_objectness: 0.0637 (0.0679)  loss_rpn_box_reg: 0.0592 (0.0658)  time: 0.6855  data: 0.2972  max mem: 5923\n",
      "Training Epoch: [119]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1304 (0.1337)  loss_objectness: 0.0663 (0.0692)  loss_rpn_box_reg: 0.0596 (0.0645)  time: 0.6807  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [119]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1393 (0.1402)  loss_objectness: 0.0770 (0.0723)  loss_rpn_box_reg: 0.0650 (0.0679)  time: 0.6875  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [119]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1555 (0.1411)  loss_objectness: 0.0695 (0.0709)  loss_rpn_box_reg: 0.0841 (0.0702)  time: 0.6913  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [119]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1470 (0.1419)  loss_objectness: 0.0645 (0.0712)  loss_rpn_box_reg: 0.0841 (0.0707)  time: 0.6909  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [119]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1348 (0.1411)  loss_objectness: 0.0712 (0.0711)  loss_rpn_box_reg: 0.0625 (0.0700)  time: 0.6895  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [119]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1357 (0.1406)  loss_objectness: 0.0703 (0.0708)  loss_rpn_box_reg: 0.0595 (0.0698)  time: 0.6905  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [119]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1376 (0.1397)  loss_objectness: 0.0689 (0.0703)  loss_rpn_box_reg: 0.0652 (0.0694)  time: 0.6859  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [119]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1266 (0.1407)  loss_objectness: 0.0698 (0.0705)  loss_rpn_box_reg: 0.0652 (0.0702)  time: 0.6844  data: 0.2962  max mem: 5923\n",
      "Training Epoch: [119]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1354 (0.1406)  loss_objectness: 0.0724 (0.0710)  loss_rpn_box_reg: 0.0618 (0.0696)  time: 0.6917  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [119]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1412 (0.1405)  loss_objectness: 0.0746 (0.0713)  loss_rpn_box_reg: 0.0564 (0.0692)  time: 0.7020  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [119]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1408 (0.1408)  loss_objectness: 0.0743 (0.0718)  loss_rpn_box_reg: 0.0627 (0.0690)  time: 0.6999  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [119]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1471 (0.1411)  loss_objectness: 0.0669 (0.0719)  loss_rpn_box_reg: 0.0682 (0.0692)  time: 0.6913  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [119]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1524 (0.1420)  loss_objectness: 0.0709 (0.0723)  loss_rpn_box_reg: 0.0746 (0.0697)  time: 0.6922  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [119]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1464 (0.1412)  loss_objectness: 0.0753 (0.0722)  loss_rpn_box_reg: 0.0712 (0.0690)  time: 0.7000  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [119]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1234 (0.1409)  loss_objectness: 0.0716 (0.0722)  loss_rpn_box_reg: 0.0487 (0.0686)  time: 0.6986  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [119]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1393 (0.1414)  loss_objectness: 0.0727 (0.0723)  loss_rpn_box_reg: 0.0643 (0.0691)  time: 0.6923  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [119]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1392 (0.1417)  loss_objectness: 0.0727 (0.0724)  loss_rpn_box_reg: 0.0742 (0.0694)  time: 0.6824  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [119]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1392 (0.1416)  loss_objectness: 0.0740 (0.0723)  loss_rpn_box_reg: 0.0730 (0.0693)  time: 0.6873  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [119]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1406 (0.1414)  loss_objectness: 0.0744 (0.0724)  loss_rpn_box_reg: 0.0671 (0.0690)  time: 0.6841  data: 0.2973  max mem: 5923\n",
      "Training Epoch: [119]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1375 (0.1417)  loss_objectness: 0.0726 (0.0723)  loss_rpn_box_reg: 0.0700 (0.0694)  time: 0.6877  data: 0.2963  max mem: 5923\n",
      "Training Epoch: [119]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1330 (0.1419)  loss_objectness: 0.0699 (0.0723)  loss_rpn_box_reg: 0.0683 (0.0696)  time: 0.6968  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [119] Total time: 0:02:52 (0.6893 s / it)\n",
      "Testing Epoch: [119]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1305 (0.1305)  loss_objectness: 0.0448 (0.0448)  loss_rpn_box_reg: 0.0857 (0.0857)  time: 0.6231  data: 0.2961  max mem: 5923\n",
      "Testing Epoch: [119]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1324 (0.1379)  loss_objectness: 0.0543 (0.0576)  loss_rpn_box_reg: 0.0763 (0.0803)  time: 0.6391  data: 0.3096  max mem: 5923\n",
      "Testing Epoch: [119] Total time: 0:00:39 (0.6396 s / it)\n",
      "Training Epoch: [120]  [  0/250]  eta: 0:02:52  lr: 0.000300  loss: 0.1676 (0.1676)  loss_objectness: 0.0647 (0.0647)  loss_rpn_box_reg: 0.1029 (0.1029)  time: 0.6902  data: 0.3171  max mem: 5923\n",
      "Training Epoch: [120]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1551 (0.1508)  loss_objectness: 0.0649 (0.0703)  loss_rpn_box_reg: 0.0777 (0.0805)  time: 0.6822  data: 0.2976  max mem: 5923\n",
      "Training Epoch: [120]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1443 (0.1401)  loss_objectness: 0.0666 (0.0694)  loss_rpn_box_reg: 0.0615 (0.0707)  time: 0.6875  data: 0.2969  max mem: 5923\n",
      "Training Epoch: [120]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1457 (0.1424)  loss_objectness: 0.0699 (0.0686)  loss_rpn_box_reg: 0.0649 (0.0738)  time: 0.6967  data: 0.2967  max mem: 5923\n",
      "Training Epoch: [120]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1485 (0.1407)  loss_objectness: 0.0690 (0.0686)  loss_rpn_box_reg: 0.0700 (0.0721)  time: 0.6994  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [120]  [ 50/250]  eta: 0:02:19  lr: 0.000300  loss: 0.1442 (0.1419)  loss_objectness: 0.0694 (0.0695)  loss_rpn_box_reg: 0.0591 (0.0723)  time: 0.7041  data: 0.2979  max mem: 5923\n",
      "Training Epoch: [120]  [ 60/250]  eta: 0:02:12  lr: 0.000300  loss: 0.1396 (0.1397)  loss_objectness: 0.0694 (0.0684)  loss_rpn_box_reg: 0.0591 (0.0713)  time: 0.7079  data: 0.2993  max mem: 5923\n",
      "Training Epoch: [120]  [ 70/250]  eta: 0:02:05  lr: 0.000300  loss: 0.1181 (0.1394)  loss_objectness: 0.0680 (0.0687)  loss_rpn_box_reg: 0.0625 (0.0707)  time: 0.6970  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [120]  [ 80/250]  eta: 0:01:58  lr: 0.000300  loss: 0.1301 (0.1393)  loss_objectness: 0.0680 (0.0692)  loss_rpn_box_reg: 0.0595 (0.0701)  time: 0.6838  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [120]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1289 (0.1385)  loss_objectness: 0.0684 (0.0687)  loss_rpn_box_reg: 0.0622 (0.0698)  time: 0.6789  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [120]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1327 (0.1390)  loss_objectness: 0.0738 (0.0698)  loss_rpn_box_reg: 0.0645 (0.0692)  time: 0.6881  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [120]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1394 (0.1390)  loss_objectness: 0.0742 (0.0699)  loss_rpn_box_reg: 0.0645 (0.0691)  time: 0.6964  data: 0.2978  max mem: 5923\n",
      "Training Epoch: [120]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1492 (0.1396)  loss_objectness: 0.0714 (0.0708)  loss_rpn_box_reg: 0.0703 (0.0688)  time: 0.7016  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [120]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1492 (0.1403)  loss_objectness: 0.0730 (0.0711)  loss_rpn_box_reg: 0.0738 (0.0692)  time: 0.7036  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [120]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1328 (0.1402)  loss_objectness: 0.0676 (0.0709)  loss_rpn_box_reg: 0.0633 (0.0693)  time: 0.6936  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [120]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1307 (0.1402)  loss_objectness: 0.0676 (0.0710)  loss_rpn_box_reg: 0.0669 (0.0692)  time: 0.6975  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [120]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1431 (0.1402)  loss_objectness: 0.0760 (0.0716)  loss_rpn_box_reg: 0.0652 (0.0686)  time: 0.7051  data: 0.2993  max mem: 5923\n",
      "Training Epoch: [120]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1518 (0.1410)  loss_objectness: 0.0756 (0.0723)  loss_rpn_box_reg: 0.0622 (0.0687)  time: 0.6805  data: 0.2999  max mem: 5923\n",
      "Training Epoch: [120]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1537 (0.1411)  loss_objectness: 0.0737 (0.0727)  loss_rpn_box_reg: 0.0650 (0.0684)  time: 0.6623  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [120]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1385 (0.1418)  loss_objectness: 0.0672 (0.0726)  loss_rpn_box_reg: 0.0650 (0.0692)  time: 0.6651  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [120]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1386 (0.1417)  loss_objectness: 0.0619 (0.0722)  loss_rpn_box_reg: 0.0780 (0.0696)  time: 0.6830  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [120]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1386 (0.1422)  loss_objectness: 0.0683 (0.0723)  loss_rpn_box_reg: 0.0785 (0.0700)  time: 0.7016  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [120]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1341 (0.1422)  loss_objectness: 0.0700 (0.0723)  loss_rpn_box_reg: 0.0633 (0.0699)  time: 0.6872  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [120]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1448 (0.1419)  loss_objectness: 0.0681 (0.0722)  loss_rpn_box_reg: 0.0594 (0.0697)  time: 0.6781  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [120]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1468 (0.1418)  loss_objectness: 0.0681 (0.0721)  loss_rpn_box_reg: 0.0672 (0.0697)  time: 0.6878  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [120]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1311 (0.1417)  loss_objectness: 0.0696 (0.0719)  loss_rpn_box_reg: 0.0672 (0.0698)  time: 0.6924  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [120] Total time: 0:02:52 (0.6908 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:00:59  model_time: 0.6171 (0.6171)  evaluator_time: 0.0530 (0.0530)  time: 0.9642  data: 0.2791  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3941 (0.3904)  evaluator_time: 0.0710 (0.0756)  time: 0.7768  data: 0.3089  max mem: 5923\n",
      "Test: Total time: 0:00:48 (0.7784 s / it)\n",
      "Averaged stats: model_time: 0.3941 (0.3904)  evaluator_time: 0.0710 (0.0756)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.06s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.171\n",
      "Testing Epoch: [120]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1343 (0.1343)  loss_objectness: 0.0482 (0.0482)  loss_rpn_box_reg: 0.0861 (0.0861)  time: 0.6381  data: 0.2911  max mem: 5923\n",
      "Testing Epoch: [120]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1356 (0.1380)  loss_objectness: 0.0541 (0.0579)  loss_rpn_box_reg: 0.0789 (0.0801)  time: 0.6324  data: 0.3115  max mem: 5923\n",
      "Testing Epoch: [120] Total time: 0:00:39 (0.6348 s / it)\n",
      "Training Epoch: [121]  [  0/250]  eta: 0:02:50  lr: 0.000300  loss: 0.1446 (0.1446)  loss_objectness: 0.0558 (0.0558)  loss_rpn_box_reg: 0.0889 (0.0889)  time: 0.6802  data: 0.2821  max mem: 5923\n",
      "Training Epoch: [121]  [ 10/250]  eta: 0:02:50  lr: 0.000300  loss: 0.1442 (0.1393)  loss_objectness: 0.0756 (0.0750)  loss_rpn_box_reg: 0.0686 (0.0643)  time: 0.7089  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [121]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1339 (0.1340)  loss_objectness: 0.0697 (0.0712)  loss_rpn_box_reg: 0.0644 (0.0628)  time: 0.6872  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [121]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1312 (0.1368)  loss_objectness: 0.0723 (0.0731)  loss_rpn_box_reg: 0.0619 (0.0637)  time: 0.6624  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [121]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1312 (0.1358)  loss_objectness: 0.0723 (0.0720)  loss_rpn_box_reg: 0.0635 (0.0638)  time: 0.6674  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [121]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1425 (0.1369)  loss_objectness: 0.0613 (0.0708)  loss_rpn_box_reg: 0.0690 (0.0661)  time: 0.6827  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [121]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1458 (0.1376)  loss_objectness: 0.0627 (0.0699)  loss_rpn_box_reg: 0.0690 (0.0677)  time: 0.6991  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [121]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1389 (0.1383)  loss_objectness: 0.0634 (0.0692)  loss_rpn_box_reg: 0.0729 (0.0691)  time: 0.6932  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [121]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1384 (0.1381)  loss_objectness: 0.0664 (0.0696)  loss_rpn_box_reg: 0.0729 (0.0685)  time: 0.6809  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [121]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1286 (0.1385)  loss_objectness: 0.0637 (0.0691)  loss_rpn_box_reg: 0.0648 (0.0694)  time: 0.6917  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [121]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1365 (0.1392)  loss_objectness: 0.0651 (0.0697)  loss_rpn_box_reg: 0.0651 (0.0695)  time: 0.6963  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [121]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1498 (0.1408)  loss_objectness: 0.0737 (0.0707)  loss_rpn_box_reg: 0.0703 (0.0701)  time: 0.6874  data: 0.2960  max mem: 5923\n",
      "Training Epoch: [121]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1337 (0.1402)  loss_objectness: 0.0721 (0.0706)  loss_rpn_box_reg: 0.0666 (0.0696)  time: 0.6752  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [121]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1337 (0.1401)  loss_objectness: 0.0721 (0.0710)  loss_rpn_box_reg: 0.0570 (0.0691)  time: 0.6807  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [121]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1472 (0.1413)  loss_objectness: 0.0721 (0.0709)  loss_rpn_box_reg: 0.0729 (0.0704)  time: 0.6968  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [121]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1528 (0.1418)  loss_objectness: 0.0766 (0.0714)  loss_rpn_box_reg: 0.0775 (0.0704)  time: 0.6864  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [121]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1299 (0.1405)  loss_objectness: 0.0743 (0.0712)  loss_rpn_box_reg: 0.0584 (0.0693)  time: 0.6811  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [121]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1275 (0.1403)  loss_objectness: 0.0695 (0.0709)  loss_rpn_box_reg: 0.0584 (0.0694)  time: 0.6846  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [121]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1451 (0.1407)  loss_objectness: 0.0723 (0.0711)  loss_rpn_box_reg: 0.0675 (0.0696)  time: 0.6822  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [121]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1414 (0.1401)  loss_objectness: 0.0705 (0.0712)  loss_rpn_box_reg: 0.0612 (0.0688)  time: 0.7017  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [121]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1258 (0.1395)  loss_objectness: 0.0760 (0.0712)  loss_rpn_box_reg: 0.0514 (0.0682)  time: 0.7026  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [121]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1402 (0.1395)  loss_objectness: 0.0714 (0.0712)  loss_rpn_box_reg: 0.0596 (0.0683)  time: 0.6939  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [121]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1497 (0.1399)  loss_objectness: 0.0627 (0.0708)  loss_rpn_box_reg: 0.0802 (0.0691)  time: 0.6929  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [121]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1551 (0.1403)  loss_objectness: 0.0697 (0.0711)  loss_rpn_box_reg: 0.0745 (0.0692)  time: 0.6811  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [121]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1299 (0.1405)  loss_objectness: 0.0741 (0.0710)  loss_rpn_box_reg: 0.0745 (0.0695)  time: 0.6863  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [121]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1285 (0.1402)  loss_objectness: 0.0589 (0.0708)  loss_rpn_box_reg: 0.0669 (0.0694)  time: 0.6900  data: 0.2879  max mem: 5923\n",
      "Training Epoch: [121] Total time: 0:02:51 (0.6877 s / it)\n",
      "Testing Epoch: [121]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1330 (0.1330)  loss_objectness: 0.0417 (0.0417)  loss_rpn_box_reg: 0.0913 (0.0913)  time: 0.6201  data: 0.2841  max mem: 5923\n",
      "Testing Epoch: [121]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1323 (0.1394)  loss_objectness: 0.0551 (0.0587)  loss_rpn_box_reg: 0.0720 (0.0807)  time: 0.6362  data: 0.3116  max mem: 5923\n",
      "Testing Epoch: [121] Total time: 0:00:39 (0.6371 s / it)\n",
      "Training Epoch: [122]  [  0/250]  eta: 0:02:49  lr: 0.000300  loss: 0.1274 (0.1274)  loss_objectness: 0.0673 (0.0673)  loss_rpn_box_reg: 0.0601 (0.0601)  time: 0.6792  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [122]  [ 10/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1427 (0.1492)  loss_objectness: 0.0677 (0.0695)  loss_rpn_box_reg: 0.0748 (0.0797)  time: 0.6889  data: 0.2977  max mem: 5923\n",
      "Training Epoch: [122]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1344 (0.1416)  loss_objectness: 0.0670 (0.0679)  loss_rpn_box_reg: 0.0697 (0.0738)  time: 0.6879  data: 0.2960  max mem: 5923\n",
      "Training Epoch: [122]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1360 (0.1418)  loss_objectness: 0.0703 (0.0706)  loss_rpn_box_reg: 0.0620 (0.0712)  time: 0.6854  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [122]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1381 (0.1434)  loss_objectness: 0.0749 (0.0721)  loss_rpn_box_reg: 0.0620 (0.0713)  time: 0.6961  data: 0.2964  max mem: 5923\n",
      "Training Epoch: [122]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1429 (0.1421)  loss_objectness: 0.0690 (0.0714)  loss_rpn_box_reg: 0.0680 (0.0707)  time: 0.6951  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [122]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1413 (0.1434)  loss_objectness: 0.0689 (0.0728)  loss_rpn_box_reg: 0.0680 (0.0707)  time: 0.6823  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [122]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1453 (0.1448)  loss_objectness: 0.0743 (0.0727)  loss_rpn_box_reg: 0.0716 (0.0721)  time: 0.6877  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [122]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1403 (0.1431)  loss_objectness: 0.0743 (0.0728)  loss_rpn_box_reg: 0.0716 (0.0703)  time: 0.6887  data: 0.2971  max mem: 5923\n",
      "Training Epoch: [122]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1300 (0.1420)  loss_objectness: 0.0658 (0.0723)  loss_rpn_box_reg: 0.0601 (0.0697)  time: 0.6840  data: 0.2968  max mem: 5923\n",
      "Training Epoch: [122]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1387 (0.1422)  loss_objectness: 0.0665 (0.0726)  loss_rpn_box_reg: 0.0684 (0.0696)  time: 0.7013  data: 0.2967  max mem: 5923\n",
      "Training Epoch: [122]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1339 (0.1415)  loss_objectness: 0.0656 (0.0718)  loss_rpn_box_reg: 0.0664 (0.0697)  time: 0.7098  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [122]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1200 (0.1406)  loss_objectness: 0.0634 (0.0714)  loss_rpn_box_reg: 0.0609 (0.0692)  time: 0.6966  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [122]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1319 (0.1402)  loss_objectness: 0.0672 (0.0711)  loss_rpn_box_reg: 0.0609 (0.0690)  time: 0.6905  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [122]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1295 (0.1397)  loss_objectness: 0.0645 (0.0706)  loss_rpn_box_reg: 0.0616 (0.0691)  time: 0.6873  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [122]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1243 (0.1401)  loss_objectness: 0.0641 (0.0708)  loss_rpn_box_reg: 0.0665 (0.0693)  time: 0.6806  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [122]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1324 (0.1389)  loss_objectness: 0.0594 (0.0703)  loss_rpn_box_reg: 0.0563 (0.0686)  time: 0.6705  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [122]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1364 (0.1404)  loss_objectness: 0.0724 (0.0711)  loss_rpn_box_reg: 0.0638 (0.0693)  time: 0.6710  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [122]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1532 (0.1409)  loss_objectness: 0.0728 (0.0708)  loss_rpn_box_reg: 0.0820 (0.0701)  time: 0.6859  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [122]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1398 (0.1410)  loss_objectness: 0.0685 (0.0710)  loss_rpn_box_reg: 0.0739 (0.0699)  time: 0.7041  data: 0.2991  max mem: 5923\n",
      "Training Epoch: [122]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1271 (0.1403)  loss_objectness: 0.0651 (0.0707)  loss_rpn_box_reg: 0.0574 (0.0695)  time: 0.7018  data: 0.3013  max mem: 5923\n",
      "Training Epoch: [122]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1326 (0.1404)  loss_objectness: 0.0651 (0.0708)  loss_rpn_box_reg: 0.0563 (0.0696)  time: 0.7000  data: 0.2997  max mem: 5923\n",
      "Training Epoch: [122]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1457 (0.1413)  loss_objectness: 0.0708 (0.0713)  loss_rpn_box_reg: 0.0670 (0.0700)  time: 0.7002  data: 0.3036  max mem: 5923\n",
      "Training Epoch: [122]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1501 (0.1414)  loss_objectness: 0.0727 (0.0714)  loss_rpn_box_reg: 0.0727 (0.0700)  time: 0.6866  data: 0.3022  max mem: 5923\n",
      "Training Epoch: [122]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1436 (0.1415)  loss_objectness: 0.0727 (0.0714)  loss_rpn_box_reg: 0.0680 (0.0701)  time: 0.6653  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [122]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1340 (0.1413)  loss_objectness: 0.0703 (0.0715)  loss_rpn_box_reg: 0.0624 (0.0698)  time: 0.6717  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [122] Total time: 0:02:52 (0.6889 s / it)\n",
      "Testing Epoch: [122]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1290 (0.1290)  loss_objectness: 0.0430 (0.0430)  loss_rpn_box_reg: 0.0860 (0.0860)  time: 0.6411  data: 0.3161  max mem: 5923\n",
      "Testing Epoch: [122]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1331 (0.1397)  loss_objectness: 0.0552 (0.0596)  loss_rpn_box_reg: 0.0699 (0.0801)  time: 0.6365  data: 0.3116  max mem: 5923\n",
      "Testing Epoch: [122] Total time: 0:00:39 (0.6368 s / it)\n",
      "Training Epoch: [123]  [  0/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1546 (0.1546)  loss_objectness: 0.0779 (0.0779)  loss_rpn_box_reg: 0.0767 (0.0767)  time: 0.6692  data: 0.3091  max mem: 5923\n",
      "Training Epoch: [123]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1515 (0.1549)  loss_objectness: 0.0710 (0.0707)  loss_rpn_box_reg: 0.0895 (0.0842)  time: 0.6994  data: 0.2992  max mem: 5923\n",
      "Training Epoch: [123]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1414 (0.1455)  loss_objectness: 0.0624 (0.0670)  loss_rpn_box_reg: 0.0784 (0.0785)  time: 0.6957  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [123]  [ 30/250]  eta: 0:02:33  lr: 0.000300  loss: 0.1320 (0.1410)  loss_objectness: 0.0633 (0.0677)  loss_rpn_box_reg: 0.0620 (0.0733)  time: 0.6934  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [123]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1320 (0.1425)  loss_objectness: 0.0692 (0.0711)  loss_rpn_box_reg: 0.0607 (0.0715)  time: 0.6838  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [123]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1513 (0.1432)  loss_objectness: 0.0767 (0.0711)  loss_rpn_box_reg: 0.0629 (0.0721)  time: 0.6792  data: 0.2982  max mem: 5923\n",
      "Training Epoch: [123]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1489 (0.1429)  loss_objectness: 0.0709 (0.0708)  loss_rpn_box_reg: 0.0726 (0.0721)  time: 0.6857  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [123]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1400 (0.1431)  loss_objectness: 0.0689 (0.0708)  loss_rpn_box_reg: 0.0726 (0.0724)  time: 0.6887  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [123]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1228 (0.1410)  loss_objectness: 0.0682 (0.0701)  loss_rpn_box_reg: 0.0668 (0.0709)  time: 0.7012  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [123]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1324 (0.1421)  loss_objectness: 0.0695 (0.0703)  loss_rpn_box_reg: 0.0632 (0.0718)  time: 0.6987  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [123]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1371 (0.1417)  loss_objectness: 0.0686 (0.0707)  loss_rpn_box_reg: 0.0715 (0.0709)  time: 0.6890  data: 0.2980  max mem: 5923\n",
      "Training Epoch: [123]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1292 (0.1422)  loss_objectness: 0.0711 (0.0714)  loss_rpn_box_reg: 0.0627 (0.0708)  time: 0.6752  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [123]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1315 (0.1412)  loss_objectness: 0.0701 (0.0710)  loss_rpn_box_reg: 0.0603 (0.0702)  time: 0.6776  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [123]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1315 (0.1413)  loss_objectness: 0.0697 (0.0715)  loss_rpn_box_reg: 0.0603 (0.0698)  time: 0.6928  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [123]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1379 (0.1417)  loss_objectness: 0.0704 (0.0717)  loss_rpn_box_reg: 0.0634 (0.0700)  time: 0.6853  data: 0.2977  max mem: 5923\n",
      "Training Epoch: [123]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1277 (0.1409)  loss_objectness: 0.0703 (0.0719)  loss_rpn_box_reg: 0.0561 (0.0690)  time: 0.6819  data: 0.2962  max mem: 5923\n",
      "Training Epoch: [123]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1277 (0.1414)  loss_objectness: 0.0732 (0.0723)  loss_rpn_box_reg: 0.0630 (0.0691)  time: 0.6870  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [123]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1446 (0.1418)  loss_objectness: 0.0674 (0.0717)  loss_rpn_box_reg: 0.0794 (0.0701)  time: 0.6918  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [123]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1379 (0.1414)  loss_objectness: 0.0672 (0.0718)  loss_rpn_box_reg: 0.0739 (0.0696)  time: 0.6981  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [123]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1440 (0.1416)  loss_objectness: 0.0705 (0.0718)  loss_rpn_box_reg: 0.0693 (0.0699)  time: 0.6878  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [123]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1396 (0.1413)  loss_objectness: 0.0661 (0.0715)  loss_rpn_box_reg: 0.0716 (0.0699)  time: 0.6864  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [123]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1396 (0.1417)  loss_objectness: 0.0672 (0.0716)  loss_rpn_box_reg: 0.0779 (0.0700)  time: 0.6897  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [123]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1415 (0.1420)  loss_objectness: 0.0796 (0.0719)  loss_rpn_box_reg: 0.0743 (0.0701)  time: 0.6817  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [123]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1398 (0.1419)  loss_objectness: 0.0796 (0.0721)  loss_rpn_box_reg: 0.0589 (0.0697)  time: 0.6823  data: 0.2975  max mem: 5923\n",
      "Training Epoch: [123]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1439 (0.1423)  loss_objectness: 0.0810 (0.0725)  loss_rpn_box_reg: 0.0632 (0.0698)  time: 0.6959  data: 0.2974  max mem: 5923\n",
      "Training Epoch: [123]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1410 (0.1418)  loss_objectness: 0.0795 (0.0724)  loss_rpn_box_reg: 0.0632 (0.0694)  time: 0.6933  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [123] Total time: 0:02:52 (0.6885 s / it)\n",
      "Testing Epoch: [123]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1410 (0.1410)  loss_objectness: 0.0489 (0.0489)  loss_rpn_box_reg: 0.0921 (0.0921)  time: 0.6291  data: 0.3051  max mem: 5923\n",
      "Testing Epoch: [123]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1250 (0.1427)  loss_objectness: 0.0564 (0.0614)  loss_rpn_box_reg: 0.0778 (0.0813)  time: 0.6338  data: 0.3051  max mem: 5923\n",
      "Testing Epoch: [123] Total time: 0:00:39 (0.6371 s / it)\n",
      "Training Epoch: [124]  [  0/250]  eta: 0:03:00  lr: 0.000300  loss: 0.1033 (0.1033)  loss_objectness: 0.0579 (0.0579)  loss_rpn_box_reg: 0.0453 (0.0453)  time: 0.7232  data: 0.2971  max mem: 5923\n",
      "Training Epoch: [124]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1498 (0.1594)  loss_objectness: 0.0748 (0.0756)  loss_rpn_box_reg: 0.0815 (0.0839)  time: 0.6956  data: 0.2994  max mem: 5923\n",
      "Training Epoch: [124]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1473 (0.1459)  loss_objectness: 0.0694 (0.0703)  loss_rpn_box_reg: 0.0673 (0.0756)  time: 0.6956  data: 0.2967  max mem: 5923\n",
      "Training Epoch: [124]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1197 (0.1407)  loss_objectness: 0.0655 (0.0701)  loss_rpn_box_reg: 0.0593 (0.0706)  time: 0.6904  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [124]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1296 (0.1399)  loss_objectness: 0.0680 (0.0699)  loss_rpn_box_reg: 0.0633 (0.0700)  time: 0.6842  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [124]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1333 (0.1376)  loss_objectness: 0.0629 (0.0682)  loss_rpn_box_reg: 0.0717 (0.0695)  time: 0.6944  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [124]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1332 (0.1370)  loss_objectness: 0.0602 (0.0673)  loss_rpn_box_reg: 0.0747 (0.0697)  time: 0.6902  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [124]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1299 (0.1348)  loss_objectness: 0.0577 (0.0664)  loss_rpn_box_reg: 0.0627 (0.0684)  time: 0.6796  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [124]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1312 (0.1361)  loss_objectness: 0.0701 (0.0679)  loss_rpn_box_reg: 0.0614 (0.0682)  time: 0.6881  data: 0.2983  max mem: 5923\n",
      "Training Epoch: [124]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1305 (0.1351)  loss_objectness: 0.0728 (0.0680)  loss_rpn_box_reg: 0.0585 (0.0671)  time: 0.6889  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [124]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1245 (0.1351)  loss_objectness: 0.0704 (0.0682)  loss_rpn_box_reg: 0.0596 (0.0669)  time: 0.6936  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [124]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1343 (0.1348)  loss_objectness: 0.0679 (0.0680)  loss_rpn_box_reg: 0.0674 (0.0668)  time: 0.6933  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [124]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1351 (0.1349)  loss_objectness: 0.0651 (0.0680)  loss_rpn_box_reg: 0.0673 (0.0669)  time: 0.6892  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [124]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1378 (0.1370)  loss_objectness: 0.0662 (0.0684)  loss_rpn_box_reg: 0.0691 (0.0685)  time: 0.6899  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [124]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1378 (0.1370)  loss_objectness: 0.0668 (0.0686)  loss_rpn_box_reg: 0.0682 (0.0684)  time: 0.6910  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [124]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1262 (0.1368)  loss_objectness: 0.0668 (0.0687)  loss_rpn_box_reg: 0.0609 (0.0681)  time: 0.6876  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [124]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1282 (0.1367)  loss_objectness: 0.0552 (0.0681)  loss_rpn_box_reg: 0.0609 (0.0685)  time: 0.6919  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [124]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1243 (0.1358)  loss_objectness: 0.0552 (0.0678)  loss_rpn_box_reg: 0.0639 (0.0680)  time: 0.7003  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [124]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1291 (0.1368)  loss_objectness: 0.0633 (0.0680)  loss_rpn_box_reg: 0.0654 (0.0688)  time: 0.7010  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [124]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1433 (0.1367)  loss_objectness: 0.0630 (0.0678)  loss_rpn_box_reg: 0.0673 (0.0689)  time: 0.6919  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [124]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1308 (0.1371)  loss_objectness: 0.0633 (0.0683)  loss_rpn_box_reg: 0.0635 (0.0688)  time: 0.6854  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [124]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1470 (0.1384)  loss_objectness: 0.0750 (0.0688)  loss_rpn_box_reg: 0.0735 (0.0696)  time: 0.6845  data: 0.2963  max mem: 5923\n",
      "Training Epoch: [124]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1387 (0.1387)  loss_objectness: 0.0732 (0.0692)  loss_rpn_box_reg: 0.0735 (0.0695)  time: 0.6830  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [124]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1411 (0.1397)  loss_objectness: 0.0714 (0.0696)  loss_rpn_box_reg: 0.0710 (0.0701)  time: 0.6963  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [124]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1472 (0.1399)  loss_objectness: 0.0714 (0.0697)  loss_rpn_box_reg: 0.0707 (0.0702)  time: 0.6942  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [124]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1356 (0.1396)  loss_objectness: 0.0773 (0.0700)  loss_rpn_box_reg: 0.0578 (0.0696)  time: 0.6867  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [124] Total time: 0:02:52 (0.6906 s / it)\n",
      "Testing Epoch: [124]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1351 (0.1351)  loss_objectness: 0.0460 (0.0460)  loss_rpn_box_reg: 0.0891 (0.0891)  time: 0.6181  data: 0.2941  max mem: 5923\n",
      "Testing Epoch: [124]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1249 (0.1400)  loss_objectness: 0.0552 (0.0606)  loss_rpn_box_reg: 0.0706 (0.0794)  time: 0.6414  data: 0.3144  max mem: 5923\n",
      "Testing Epoch: [124] Total time: 0:00:39 (0.6389 s / it)\n",
      "Training Epoch: [125]  [  0/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1353 (0.1353)  loss_objectness: 0.0795 (0.0795)  loss_rpn_box_reg: 0.0557 (0.0557)  time: 0.6171  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [125]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1366 (0.1400)  loss_objectness: 0.0765 (0.0714)  loss_rpn_box_reg: 0.0620 (0.0686)  time: 0.6729  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [125]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1366 (0.1404)  loss_objectness: 0.0711 (0.0711)  loss_rpn_box_reg: 0.0620 (0.0693)  time: 0.6884  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [125]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1216 (0.1353)  loss_objectness: 0.0604 (0.0680)  loss_rpn_box_reg: 0.0598 (0.0673)  time: 0.6942  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [125]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1203 (0.1397)  loss_objectness: 0.0650 (0.0705)  loss_rpn_box_reg: 0.0635 (0.0692)  time: 0.6813  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [125]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1367 (0.1386)  loss_objectness: 0.0749 (0.0710)  loss_rpn_box_reg: 0.0635 (0.0676)  time: 0.6801  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [125]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1499 (0.1417)  loss_objectness: 0.0760 (0.0725)  loss_rpn_box_reg: 0.0666 (0.0692)  time: 0.6884  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [125]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1517 (0.1421)  loss_objectness: 0.0692 (0.0721)  loss_rpn_box_reg: 0.0735 (0.0700)  time: 0.6873  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [125]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1349 (0.1417)  loss_objectness: 0.0686 (0.0724)  loss_rpn_box_reg: 0.0645 (0.0693)  time: 0.6920  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [125]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1250 (0.1404)  loss_objectness: 0.0671 (0.0719)  loss_rpn_box_reg: 0.0580 (0.0685)  time: 0.6883  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [125]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1250 (0.1413)  loss_objectness: 0.0673 (0.0727)  loss_rpn_box_reg: 0.0580 (0.0686)  time: 0.6762  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [125]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1358 (0.1405)  loss_objectness: 0.0663 (0.0718)  loss_rpn_box_reg: 0.0652 (0.0687)  time: 0.6752  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [125]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1295 (0.1403)  loss_objectness: 0.0653 (0.0713)  loss_rpn_box_reg: 0.0672 (0.0690)  time: 0.6809  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [125]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1295 (0.1397)  loss_objectness: 0.0603 (0.0709)  loss_rpn_box_reg: 0.0654 (0.0688)  time: 0.6868  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [125]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1250 (0.1386)  loss_objectness: 0.0601 (0.0703)  loss_rpn_box_reg: 0.0595 (0.0683)  time: 0.6872  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [125]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1312 (0.1387)  loss_objectness: 0.0601 (0.0697)  loss_rpn_box_reg: 0.0669 (0.0690)  time: 0.6994  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [125]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1428 (0.1396)  loss_objectness: 0.0698 (0.0703)  loss_rpn_box_reg: 0.0730 (0.0693)  time: 0.7030  data: 0.2968  max mem: 5923\n",
      "Training Epoch: [125]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1390 (0.1395)  loss_objectness: 0.0698 (0.0703)  loss_rpn_box_reg: 0.0670 (0.0693)  time: 0.6985  data: 0.2960  max mem: 5923\n",
      "Training Epoch: [125]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1371 (0.1398)  loss_objectness: 0.0686 (0.0707)  loss_rpn_box_reg: 0.0594 (0.0692)  time: 0.6920  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [125]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1382 (0.1399)  loss_objectness: 0.0669 (0.0704)  loss_rpn_box_reg: 0.0699 (0.0694)  time: 0.6919  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [125]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1395 (0.1403)  loss_objectness: 0.0661 (0.0707)  loss_rpn_box_reg: 0.0710 (0.0696)  time: 0.6964  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [125]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1548 (0.1413)  loss_objectness: 0.0773 (0.0714)  loss_rpn_box_reg: 0.0718 (0.0698)  time: 0.6749  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [125]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1506 (0.1416)  loss_objectness: 0.0773 (0.0716)  loss_rpn_box_reg: 0.0699 (0.0699)  time: 0.6790  data: 0.2965  max mem: 5923\n",
      "Training Epoch: [125]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1483 (0.1421)  loss_objectness: 0.0766 (0.0718)  loss_rpn_box_reg: 0.0721 (0.0703)  time: 0.6927  data: 0.3006  max mem: 5923\n",
      "Training Epoch: [125]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1478 (0.1419)  loss_objectness: 0.0718 (0.0718)  loss_rpn_box_reg: 0.0648 (0.0701)  time: 0.6771  data: 0.2974  max mem: 5923\n",
      "Training Epoch: [125]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1298 (0.1414)  loss_objectness: 0.0689 (0.0716)  loss_rpn_box_reg: 0.0617 (0.0698)  time: 0.6769  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [125] Total time: 0:02:51 (0.6867 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:12  model_time: 0.7322 (0.7322)  evaluator_time: 0.0510 (0.0510)  time: 1.1693  data: 0.3701  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3681 (0.3769)  evaluator_time: 0.0620 (0.0723)  time: 0.7553  data: 0.3079  max mem: 5923\n",
      "Test: Total time: 0:00:47 (0.7583 s / it)\n",
      "Averaged stats: model_time: 0.3681 (0.3769)  evaluator_time: 0.0620 (0.0723)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.00s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.168\n",
      "Testing Epoch: [125]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1320 (0.1320)  loss_objectness: 0.0418 (0.0418)  loss_rpn_box_reg: 0.0902 (0.0902)  time: 0.6061  data: 0.2791  max mem: 5923\n",
      "Testing Epoch: [125]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1314 (0.1393)  loss_objectness: 0.0570 (0.0586)  loss_rpn_box_reg: 0.0793 (0.0807)  time: 0.6237  data: 0.3048  max mem: 5923\n",
      "Testing Epoch: [125] Total time: 0:00:39 (0.6336 s / it)\n",
      "Training Epoch: [126]  [  0/250]  eta: 0:02:53  lr: 0.000300  loss: 0.0901 (0.0901)  loss_objectness: 0.0681 (0.0681)  loss_rpn_box_reg: 0.0220 (0.0220)  time: 0.6942  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [126]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1200 (0.1266)  loss_objectness: 0.0643 (0.0717)  loss_rpn_box_reg: 0.0509 (0.0549)  time: 0.6929  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [126]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1248 (0.1329)  loss_objectness: 0.0643 (0.0693)  loss_rpn_box_reg: 0.0588 (0.0636)  time: 0.6928  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [126]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1331 (0.1338)  loss_objectness: 0.0626 (0.0663)  loss_rpn_box_reg: 0.0741 (0.0674)  time: 0.6795  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [126]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1452 (0.1398)  loss_objectness: 0.0621 (0.0665)  loss_rpn_box_reg: 0.0775 (0.0733)  time: 0.6717  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [126]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1368 (0.1382)  loss_objectness: 0.0640 (0.0665)  loss_rpn_box_reg: 0.0768 (0.0717)  time: 0.6829  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [126]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1331 (0.1385)  loss_objectness: 0.0648 (0.0675)  loss_rpn_box_reg: 0.0626 (0.0710)  time: 0.6848  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [126]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1445 (0.1396)  loss_objectness: 0.0705 (0.0683)  loss_rpn_box_reg: 0.0658 (0.0713)  time: 0.6846  data: 0.2963  max mem: 5923\n",
      "Training Epoch: [126]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1524 (0.1405)  loss_objectness: 0.0705 (0.0685)  loss_rpn_box_reg: 0.0750 (0.0719)  time: 0.6870  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [126]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1360 (0.1391)  loss_objectness: 0.0631 (0.0679)  loss_rpn_box_reg: 0.0729 (0.0712)  time: 0.6773  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [126]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1360 (0.1386)  loss_objectness: 0.0698 (0.0681)  loss_rpn_box_reg: 0.0635 (0.0706)  time: 0.6714  data: 0.2866  max mem: 5923\n",
      "Training Epoch: [126]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1304 (0.1381)  loss_objectness: 0.0663 (0.0680)  loss_rpn_box_reg: 0.0624 (0.0701)  time: 0.6853  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [126]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1376 (0.1401)  loss_objectness: 0.0643 (0.0688)  loss_rpn_box_reg: 0.0718 (0.0714)  time: 0.6827  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [126]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1222 (0.1389)  loss_objectness: 0.0715 (0.0684)  loss_rpn_box_reg: 0.0677 (0.0705)  time: 0.6794  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [126]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1222 (0.1384)  loss_objectness: 0.0696 (0.0685)  loss_rpn_box_reg: 0.0596 (0.0699)  time: 0.6816  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [126]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1372 (0.1399)  loss_objectness: 0.0745 (0.0701)  loss_rpn_box_reg: 0.0603 (0.0698)  time: 0.6779  data: 0.2976  max mem: 5923\n",
      "Training Epoch: [126]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1435 (0.1384)  loss_objectness: 0.0690 (0.0697)  loss_rpn_box_reg: 0.0601 (0.0687)  time: 0.6854  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [126]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1187 (0.1379)  loss_objectness: 0.0669 (0.0698)  loss_rpn_box_reg: 0.0569 (0.0681)  time: 0.6994  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [126]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1359 (0.1380)  loss_objectness: 0.0645 (0.0692)  loss_rpn_box_reg: 0.0706 (0.0688)  time: 0.6961  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [126]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1412 (0.1381)  loss_objectness: 0.0599 (0.0692)  loss_rpn_box_reg: 0.0811 (0.0689)  time: 0.6762  data: 0.2879  max mem: 5923\n",
      "Training Epoch: [126]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1528 (0.1393)  loss_objectness: 0.0661 (0.0698)  loss_rpn_box_reg: 0.0745 (0.0695)  time: 0.6757  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [126]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1346 (0.1391)  loss_objectness: 0.0759 (0.0699)  loss_rpn_box_reg: 0.0632 (0.0692)  time: 0.6795  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [126]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1329 (0.1393)  loss_objectness: 0.0710 (0.0699)  loss_rpn_box_reg: 0.0552 (0.0694)  time: 0.6797  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [126]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1422 (0.1400)  loss_objectness: 0.0741 (0.0704)  loss_rpn_box_reg: 0.0678 (0.0696)  time: 0.6864  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [126]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1497 (0.1405)  loss_objectness: 0.0796 (0.0707)  loss_rpn_box_reg: 0.0701 (0.0697)  time: 0.6911  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [126]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1528 (0.1410)  loss_objectness: 0.0747 (0.0710)  loss_rpn_box_reg: 0.0716 (0.0700)  time: 0.6815  data: 0.2898  max mem: 5923\n",
      "Training Epoch: [126] Total time: 0:02:50 (0.6830 s / it)\n",
      "Testing Epoch: [126]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1337 (0.1337)  loss_objectness: 0.0454 (0.0454)  loss_rpn_box_reg: 0.0883 (0.0883)  time: 0.7252  data: 0.3821  max mem: 5923\n",
      "Testing Epoch: [126]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1315 (0.1376)  loss_objectness: 0.0546 (0.0582)  loss_rpn_box_reg: 0.0753 (0.0793)  time: 0.6294  data: 0.3093  max mem: 5923\n",
      "Testing Epoch: [126] Total time: 0:00:39 (0.6335 s / it)\n",
      "Training Epoch: [127]  [  0/250]  eta: 0:02:53  lr: 0.000300  loss: 0.1711 (0.1711)  loss_objectness: 0.0746 (0.0746)  loss_rpn_box_reg: 0.0965 (0.0965)  time: 0.6942  data: 0.2991  max mem: 5923\n",
      "Training Epoch: [127]  [ 10/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1334 (0.1398)  loss_objectness: 0.0746 (0.0696)  loss_rpn_box_reg: 0.0640 (0.0701)  time: 0.6767  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [127]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1270 (0.1339)  loss_objectness: 0.0648 (0.0660)  loss_rpn_box_reg: 0.0613 (0.0679)  time: 0.6794  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [127]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1328 (0.1337)  loss_objectness: 0.0652 (0.0681)  loss_rpn_box_reg: 0.0594 (0.0656)  time: 0.6919  data: 0.2978  max mem: 5923\n",
      "Training Epoch: [127]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1463 (0.1404)  loss_objectness: 0.0699 (0.0695)  loss_rpn_box_reg: 0.0748 (0.0709)  time: 0.6959  data: 0.2999  max mem: 5923\n",
      "Training Epoch: [127]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1541 (0.1394)  loss_objectness: 0.0699 (0.0698)  loss_rpn_box_reg: 0.0774 (0.0697)  time: 0.6891  data: 0.2974  max mem: 5923\n",
      "Training Epoch: [127]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1265 (0.1379)  loss_objectness: 0.0642 (0.0683)  loss_rpn_box_reg: 0.0602 (0.0695)  time: 0.6808  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [127]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1308 (0.1371)  loss_objectness: 0.0644 (0.0693)  loss_rpn_box_reg: 0.0583 (0.0678)  time: 0.6867  data: 0.2880  max mem: 5923\n",
      "Training Epoch: [127]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1289 (0.1371)  loss_objectness: 0.0724 (0.0700)  loss_rpn_box_reg: 0.0569 (0.0671)  time: 0.7009  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [127]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1278 (0.1377)  loss_objectness: 0.0714 (0.0702)  loss_rpn_box_reg: 0.0596 (0.0676)  time: 0.6886  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [127]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1342 (0.1380)  loss_objectness: 0.0674 (0.0701)  loss_rpn_box_reg: 0.0640 (0.0680)  time: 0.6724  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [127]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1453 (0.1395)  loss_objectness: 0.0633 (0.0701)  loss_rpn_box_reg: 0.0730 (0.0694)  time: 0.6808  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [127]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1501 (0.1398)  loss_objectness: 0.0642 (0.0700)  loss_rpn_box_reg: 0.0811 (0.0699)  time: 0.6876  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [127]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1501 (0.1407)  loss_objectness: 0.0736 (0.0705)  loss_rpn_box_reg: 0.0704 (0.0702)  time: 0.6844  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [127]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1480 (0.1403)  loss_objectness: 0.0736 (0.0704)  loss_rpn_box_reg: 0.0659 (0.0699)  time: 0.6817  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [127]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1423 (0.1409)  loss_objectness: 0.0737 (0.0711)  loss_rpn_box_reg: 0.0646 (0.0698)  time: 0.6836  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [127]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1423 (0.1418)  loss_objectness: 0.0777 (0.0719)  loss_rpn_box_reg: 0.0646 (0.0699)  time: 0.6790  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [127]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1432 (0.1420)  loss_objectness: 0.0736 (0.0717)  loss_rpn_box_reg: 0.0692 (0.0703)  time: 0.6750  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [127]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1407 (0.1412)  loss_objectness: 0.0655 (0.0711)  loss_rpn_box_reg: 0.0683 (0.0700)  time: 0.6813  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [127]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1295 (0.1413)  loss_objectness: 0.0683 (0.0714)  loss_rpn_box_reg: 0.0622 (0.0699)  time: 0.6773  data: 0.2870  max mem: 5923\n",
      "Training Epoch: [127]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1495 (0.1417)  loss_objectness: 0.0722 (0.0716)  loss_rpn_box_reg: 0.0694 (0.0701)  time: 0.6797  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [127]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1490 (0.1421)  loss_objectness: 0.0737 (0.0718)  loss_rpn_box_reg: 0.0694 (0.0703)  time: 0.6743  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [127]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1373 (0.1417)  loss_objectness: 0.0732 (0.0717)  loss_rpn_box_reg: 0.0628 (0.0700)  time: 0.6734  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [127]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1290 (0.1411)  loss_objectness: 0.0638 (0.0714)  loss_rpn_box_reg: 0.0590 (0.0698)  time: 0.6773  data: 0.2875  max mem: 5923\n",
      "Training Epoch: [127]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1289 (0.1410)  loss_objectness: 0.0691 (0.0715)  loss_rpn_box_reg: 0.0586 (0.0695)  time: 0.6696  data: 0.2884  max mem: 5923\n",
      "Training Epoch: [127]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1351 (0.1413)  loss_objectness: 0.0726 (0.0717)  loss_rpn_box_reg: 0.0701 (0.0696)  time: 0.6798  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [127] Total time: 0:02:50 (0.6821 s / it)\n",
      "Testing Epoch: [127]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1301 (0.1301)  loss_objectness: 0.0438 (0.0438)  loss_rpn_box_reg: 0.0864 (0.0864)  time: 0.6421  data: 0.2941  max mem: 5923\n",
      "Testing Epoch: [127]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1340 (0.1407)  loss_objectness: 0.0559 (0.0595)  loss_rpn_box_reg: 0.0781 (0.0812)  time: 0.6295  data: 0.3081  max mem: 5923\n",
      "Testing Epoch: [127] Total time: 0:00:39 (0.6365 s / it)\n",
      "Training Epoch: [128]  [  0/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1397 (0.1397)  loss_objectness: 0.0527 (0.0527)  loss_rpn_box_reg: 0.0870 (0.0870)  time: 0.6662  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [128]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1362 (0.1379)  loss_objectness: 0.0658 (0.0644)  loss_rpn_box_reg: 0.0770 (0.0735)  time: 0.6946  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [128]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1394 (0.1425)  loss_objectness: 0.0687 (0.0662)  loss_rpn_box_reg: 0.0759 (0.0763)  time: 0.6945  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [128]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1423 (0.1400)  loss_objectness: 0.0727 (0.0697)  loss_rpn_box_reg: 0.0671 (0.0703)  time: 0.6863  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [128]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1405 (0.1410)  loss_objectness: 0.0750 (0.0704)  loss_rpn_box_reg: 0.0590 (0.0707)  time: 0.6863  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [128]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1348 (0.1392)  loss_objectness: 0.0659 (0.0694)  loss_rpn_box_reg: 0.0586 (0.0698)  time: 0.6916  data: 0.2978  max mem: 5923\n",
      "Training Epoch: [128]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1279 (0.1402)  loss_objectness: 0.0685 (0.0699)  loss_rpn_box_reg: 0.0653 (0.0703)  time: 0.6984  data: 0.3031  max mem: 5923\n",
      "Training Epoch: [128]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1453 (0.1423)  loss_objectness: 0.0740 (0.0697)  loss_rpn_box_reg: 0.0708 (0.0725)  time: 0.7008  data: 0.3033  max mem: 5923\n",
      "Training Epoch: [128]  [ 80/250]  eta: 0:01:58  lr: 0.000300  loss: 0.1333 (0.1394)  loss_objectness: 0.0626 (0.0691)  loss_rpn_box_reg: 0.0612 (0.0704)  time: 0.7076  data: 0.3035  max mem: 5923\n",
      "Training Epoch: [128]  [ 90/250]  eta: 0:01:51  lr: 0.000300  loss: 0.1287 (0.1396)  loss_objectness: 0.0594 (0.0686)  loss_rpn_box_reg: 0.0596 (0.0709)  time: 0.6989  data: 0.3011  max mem: 5923\n",
      "Training Epoch: [128]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1294 (0.1397)  loss_objectness: 0.0597 (0.0687)  loss_rpn_box_reg: 0.0703 (0.0709)  time: 0.6776  data: 0.2980  max mem: 5923\n",
      "Training Epoch: [128]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1263 (0.1383)  loss_objectness: 0.0679 (0.0687)  loss_rpn_box_reg: 0.0589 (0.0696)  time: 0.6942  data: 0.2994  max mem: 5923\n",
      "Training Epoch: [128]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1181 (0.1377)  loss_objectness: 0.0605 (0.0681)  loss_rpn_box_reg: 0.0618 (0.0696)  time: 0.7024  data: 0.2967  max mem: 5923\n",
      "Training Epoch: [128]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1303 (0.1380)  loss_objectness: 0.0576 (0.0682)  loss_rpn_box_reg: 0.0670 (0.0698)  time: 0.6895  data: 0.2986  max mem: 5923\n",
      "Training Epoch: [128]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1354 (0.1387)  loss_objectness: 0.0674 (0.0685)  loss_rpn_box_reg: 0.0670 (0.0702)  time: 0.6829  data: 0.2981  max mem: 5923\n",
      "Training Epoch: [128]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1354 (0.1384)  loss_objectness: 0.0670 (0.0685)  loss_rpn_box_reg: 0.0607 (0.0699)  time: 0.6777  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [128]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1303 (0.1388)  loss_objectness: 0.0704 (0.0688)  loss_rpn_box_reg: 0.0604 (0.0699)  time: 0.6881  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [128]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1378 (0.1392)  loss_objectness: 0.0741 (0.0692)  loss_rpn_box_reg: 0.0675 (0.0700)  time: 0.6882  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [128]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1298 (0.1390)  loss_objectness: 0.0696 (0.0689)  loss_rpn_box_reg: 0.0652 (0.0701)  time: 0.6972  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [128]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1305 (0.1394)  loss_objectness: 0.0688 (0.0691)  loss_rpn_box_reg: 0.0666 (0.0704)  time: 0.6930  data: 0.2898  max mem: 5923\n",
      "Training Epoch: [128]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1414 (0.1398)  loss_objectness: 0.0714 (0.0692)  loss_rpn_box_reg: 0.0710 (0.0706)  time: 0.6719  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [128]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1474 (0.1404)  loss_objectness: 0.0716 (0.0696)  loss_rpn_box_reg: 0.0710 (0.0707)  time: 0.6658  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [128]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1415 (0.1399)  loss_objectness: 0.0767 (0.0697)  loss_rpn_box_reg: 0.0673 (0.0701)  time: 0.6729  data: 0.2894  max mem: 5923\n",
      "Training Epoch: [128]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1159 (0.1396)  loss_objectness: 0.0699 (0.0698)  loss_rpn_box_reg: 0.0580 (0.0698)  time: 0.6808  data: 0.2869  max mem: 5923\n",
      "Training Epoch: [128]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1401 (0.1395)  loss_objectness: 0.0663 (0.0698)  loss_rpn_box_reg: 0.0646 (0.0698)  time: 0.6754  data: 0.2880  max mem: 5923\n",
      "Training Epoch: [128]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1442 (0.1399)  loss_objectness: 0.0721 (0.0700)  loss_rpn_box_reg: 0.0666 (0.0699)  time: 0.6847  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [128] Total time: 0:02:51 (0.6879 s / it)\n",
      "Testing Epoch: [128]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1316 (0.1316)  loss_objectness: 0.0463 (0.0463)  loss_rpn_box_reg: 0.0852 (0.0852)  time: 0.7112  data: 0.3811  max mem: 5923\n",
      "Testing Epoch: [128]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1356 (0.1436)  loss_objectness: 0.0568 (0.0604)  loss_rpn_box_reg: 0.0735 (0.0832)  time: 0.6327  data: 0.3111  max mem: 5923\n",
      "Testing Epoch: [128] Total time: 0:00:39 (0.6329 s / it)\n",
      "Training Epoch: [129]  [  0/250]  eta: 0:03:04  lr: 0.000300  loss: 0.1395 (0.1395)  loss_objectness: 0.0594 (0.0594)  loss_rpn_box_reg: 0.0801 (0.0801)  time: 0.7362  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [129]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1343 (0.1354)  loss_objectness: 0.0603 (0.0676)  loss_rpn_box_reg: 0.0692 (0.0679)  time: 0.6955  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [129]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1327 (0.1372)  loss_objectness: 0.0645 (0.0693)  loss_rpn_box_reg: 0.0664 (0.0679)  time: 0.6869  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [129]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1315 (0.1355)  loss_objectness: 0.0637 (0.0679)  loss_rpn_box_reg: 0.0664 (0.0676)  time: 0.6873  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [129]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1285 (0.1358)  loss_objectness: 0.0618 (0.0673)  loss_rpn_box_reg: 0.0626 (0.0685)  time: 0.6894  data: 0.2892  max mem: 5923\n",
      "Training Epoch: [129]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1244 (0.1342)  loss_objectness: 0.0621 (0.0668)  loss_rpn_box_reg: 0.0642 (0.0674)  time: 0.6861  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [129]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1284 (0.1339)  loss_objectness: 0.0602 (0.0666)  loss_rpn_box_reg: 0.0647 (0.0673)  time: 0.6830  data: 0.2882  max mem: 5923\n",
      "Training Epoch: [129]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1274 (0.1318)  loss_objectness: 0.0602 (0.0661)  loss_rpn_box_reg: 0.0581 (0.0657)  time: 0.6894  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [129]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1214 (0.1334)  loss_objectness: 0.0590 (0.0662)  loss_rpn_box_reg: 0.0624 (0.0672)  time: 0.6851  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [129]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1298 (0.1332)  loss_objectness: 0.0590 (0.0657)  loss_rpn_box_reg: 0.0684 (0.0675)  time: 0.6774  data: 0.2882  max mem: 5923\n",
      "Training Epoch: [129]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1316 (0.1348)  loss_objectness: 0.0629 (0.0666)  loss_rpn_box_reg: 0.0652 (0.0683)  time: 0.6861  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [129]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1445 (0.1360)  loss_objectness: 0.0693 (0.0669)  loss_rpn_box_reg: 0.0703 (0.0691)  time: 0.6837  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [129]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1396 (0.1369)  loss_objectness: 0.0720 (0.0678)  loss_rpn_box_reg: 0.0674 (0.0691)  time: 0.6859  data: 0.2889  max mem: 5923\n",
      "Training Epoch: [129]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1419 (0.1375)  loss_objectness: 0.0811 (0.0685)  loss_rpn_box_reg: 0.0630 (0.0690)  time: 0.6775  data: 0.2894  max mem: 5923\n",
      "Training Epoch: [129]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1401 (0.1376)  loss_objectness: 0.0672 (0.0684)  loss_rpn_box_reg: 0.0630 (0.0691)  time: 0.6765  data: 0.2889  max mem: 5923\n",
      "Training Epoch: [129]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1399 (0.1377)  loss_objectness: 0.0651 (0.0681)  loss_rpn_box_reg: 0.0742 (0.0696)  time: 0.6798  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [129]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1399 (0.1377)  loss_objectness: 0.0725 (0.0685)  loss_rpn_box_reg: 0.0635 (0.0692)  time: 0.6773  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [129]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1272 (0.1374)  loss_objectness: 0.0688 (0.0682)  loss_rpn_box_reg: 0.0604 (0.0692)  time: 0.6846  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [129]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1292 (0.1377)  loss_objectness: 0.0658 (0.0684)  loss_rpn_box_reg: 0.0627 (0.0693)  time: 0.6847  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [129]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1368 (0.1380)  loss_objectness: 0.0735 (0.0688)  loss_rpn_box_reg: 0.0621 (0.0692)  time: 0.6820  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [129]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1612 (0.1400)  loss_objectness: 0.0825 (0.0698)  loss_rpn_box_reg: 0.0713 (0.0702)  time: 0.6787  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [129]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1591 (0.1403)  loss_objectness: 0.0756 (0.0697)  loss_rpn_box_reg: 0.0853 (0.0706)  time: 0.6769  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [129]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1441 (0.1403)  loss_objectness: 0.0693 (0.0701)  loss_rpn_box_reg: 0.0656 (0.0702)  time: 0.6713  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [129]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1407 (0.1407)  loss_objectness: 0.0742 (0.0703)  loss_rpn_box_reg: 0.0582 (0.0704)  time: 0.6833  data: 0.2883  max mem: 5923\n",
      "Training Epoch: [129]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1333 (0.1405)  loss_objectness: 0.0738 (0.0706)  loss_rpn_box_reg: 0.0582 (0.0699)  time: 0.7028  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [129]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1452 (0.1410)  loss_objectness: 0.0785 (0.0711)  loss_rpn_box_reg: 0.0587 (0.0698)  time: 0.7016  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [129] Total time: 0:02:51 (0.6846 s / it)\n",
      "Testing Epoch: [129]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1383 (0.1383)  loss_objectness: 0.0496 (0.0496)  loss_rpn_box_reg: 0.0886 (0.0886)  time: 0.5971  data: 0.2731  max mem: 5923\n",
      "Testing Epoch: [129]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1395 (0.1449)  loss_objectness: 0.0603 (0.0628)  loss_rpn_box_reg: 0.0781 (0.0821)  time: 0.6312  data: 0.3069  max mem: 5923\n",
      "Testing Epoch: [129] Total time: 0:00:39 (0.6312 s / it)\n",
      "Training Epoch: [130]  [  0/250]  eta: 0:02:55  lr: 0.000300  loss: 0.1270 (0.1270)  loss_objectness: 0.0775 (0.0775)  loss_rpn_box_reg: 0.0495 (0.0495)  time: 0.7002  data: 0.3051  max mem: 5923\n",
      "Training Epoch: [130]  [ 10/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1334 (0.1307)  loss_objectness: 0.0676 (0.0661)  loss_rpn_box_reg: 0.0615 (0.0645)  time: 0.6682  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [130]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1393 (0.1384)  loss_objectness: 0.0695 (0.0699)  loss_rpn_box_reg: 0.0646 (0.0685)  time: 0.6777  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [130]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1395 (0.1383)  loss_objectness: 0.0699 (0.0697)  loss_rpn_box_reg: 0.0664 (0.0686)  time: 0.6902  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [130]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1309 (0.1363)  loss_objectness: 0.0670 (0.0700)  loss_rpn_box_reg: 0.0633 (0.0663)  time: 0.6839  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [130]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1399 (0.1377)  loss_objectness: 0.0663 (0.0701)  loss_rpn_box_reg: 0.0630 (0.0676)  time: 0.6763  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [130]  [ 60/250]  eta: 0:02:08  lr: 0.000300  loss: 0.1364 (0.1371)  loss_objectness: 0.0653 (0.0696)  loss_rpn_box_reg: 0.0695 (0.0674)  time: 0.6732  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [130]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1364 (0.1378)  loss_objectness: 0.0697 (0.0712)  loss_rpn_box_reg: 0.0670 (0.0665)  time: 0.6789  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [130]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1421 (0.1400)  loss_objectness: 0.0741 (0.0726)  loss_rpn_box_reg: 0.0646 (0.0674)  time: 0.6800  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [130]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1471 (0.1414)  loss_objectness: 0.0700 (0.0733)  loss_rpn_box_reg: 0.0692 (0.0682)  time: 0.6761  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [130]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1331 (0.1406)  loss_objectness: 0.0637 (0.0720)  loss_rpn_box_reg: 0.0714 (0.0686)  time: 0.7013  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [130]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1328 (0.1405)  loss_objectness: 0.0625 (0.0718)  loss_rpn_box_reg: 0.0686 (0.0687)  time: 0.6992  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [130]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1361 (0.1407)  loss_objectness: 0.0663 (0.0719)  loss_rpn_box_reg: 0.0629 (0.0688)  time: 0.6958  data: 0.2866  max mem: 5923\n",
      "Training Epoch: [130]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1468 (0.1414)  loss_objectness: 0.0778 (0.0724)  loss_rpn_box_reg: 0.0721 (0.0690)  time: 0.7044  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [130]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1306 (0.1408)  loss_objectness: 0.0703 (0.0720)  loss_rpn_box_reg: 0.0650 (0.0688)  time: 0.6919  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [130]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1290 (0.1407)  loss_objectness: 0.0740 (0.0725)  loss_rpn_box_reg: 0.0598 (0.0682)  time: 0.6868  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [130]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1397 (0.1411)  loss_objectness: 0.0742 (0.0726)  loss_rpn_box_reg: 0.0630 (0.0685)  time: 0.6872  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [130]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1395 (0.1417)  loss_objectness: 0.0673 (0.0725)  loss_rpn_box_reg: 0.0723 (0.0693)  time: 0.6957  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [130]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1589 (0.1424)  loss_objectness: 0.0670 (0.0724)  loss_rpn_box_reg: 0.0763 (0.0700)  time: 0.6915  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [130]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1500 (0.1431)  loss_objectness: 0.0716 (0.0726)  loss_rpn_box_reg: 0.0763 (0.0704)  time: 0.6772  data: 0.2964  max mem: 5923\n",
      "Training Epoch: [130]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1496 (0.1435)  loss_objectness: 0.0742 (0.0729)  loss_rpn_box_reg: 0.0727 (0.0707)  time: 0.6823  data: 0.2967  max mem: 5923\n",
      "Training Epoch: [130]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1389 (0.1435)  loss_objectness: 0.0712 (0.0730)  loss_rpn_box_reg: 0.0668 (0.0706)  time: 0.6911  data: 0.2964  max mem: 5923\n",
      "Training Epoch: [130]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1322 (0.1430)  loss_objectness: 0.0676 (0.0730)  loss_rpn_box_reg: 0.0606 (0.0700)  time: 0.6832  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [130]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1309 (0.1428)  loss_objectness: 0.0682 (0.0729)  loss_rpn_box_reg: 0.0592 (0.0699)  time: 0.6708  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [130]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1356 (0.1428)  loss_objectness: 0.0682 (0.0730)  loss_rpn_box_reg: 0.0579 (0.0698)  time: 0.6639  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [130]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1444 (0.1433)  loss_objectness: 0.0764 (0.0733)  loss_rpn_box_reg: 0.0632 (0.0700)  time: 0.6667  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [130] Total time: 0:02:51 (0.6841 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:02  model_time: 0.6511 (0.6511)  evaluator_time: 0.0550 (0.0550)  time: 1.0042  data: 0.2831  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3891 (0.3817)  evaluator_time: 0.0710 (0.0744)  time: 0.7643  data: 0.2976  max mem: 5923\n",
      "Test: Total time: 0:00:47 (0.7654 s / it)\n",
      "Averaged stats: model_time: 0.3891 (0.3817)  evaluator_time: 0.0710 (0.0744)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.03s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.057\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\n",
      "Testing Epoch: [130]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1328 (0.1328)  loss_objectness: 0.0425 (0.0425)  loss_rpn_box_reg: 0.0903 (0.0903)  time: 0.7132  data: 0.3891  max mem: 5923\n",
      "Testing Epoch: [130]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1359 (0.1416)  loss_objectness: 0.0590 (0.0603)  loss_rpn_box_reg: 0.0782 (0.0813)  time: 0.6305  data: 0.3081  max mem: 5923\n",
      "Testing Epoch: [130] Total time: 0:00:39 (0.6345 s / it)\n",
      "Training Epoch: [131]  [  0/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1780 (0.1780)  loss_objectness: 0.0671 (0.0671)  loss_rpn_box_reg: 0.1109 (0.1109)  time: 0.6662  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [131]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1328 (0.1366)  loss_objectness: 0.0671 (0.0696)  loss_rpn_box_reg: 0.0685 (0.0670)  time: 0.6813  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [131]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1333 (0.1432)  loss_objectness: 0.0693 (0.0709)  loss_rpn_box_reg: 0.0727 (0.0724)  time: 0.6857  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [131]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1469 (0.1434)  loss_objectness: 0.0639 (0.0688)  loss_rpn_box_reg: 0.0816 (0.0746)  time: 0.6974  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [131]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1303 (0.1384)  loss_objectness: 0.0629 (0.0675)  loss_rpn_box_reg: 0.0712 (0.0710)  time: 0.6980  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [131]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1282 (0.1377)  loss_objectness: 0.0659 (0.0680)  loss_rpn_box_reg: 0.0625 (0.0697)  time: 0.6948  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [131]  [ 60/250]  eta: 0:02:12  lr: 0.000300  loss: 0.1362 (0.1366)  loss_objectness: 0.0706 (0.0683)  loss_rpn_box_reg: 0.0636 (0.0683)  time: 0.7025  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [131]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1149 (0.1341)  loss_objectness: 0.0672 (0.0683)  loss_rpn_box_reg: 0.0473 (0.0658)  time: 0.6940  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [131]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1149 (0.1354)  loss_objectness: 0.0667 (0.0687)  loss_rpn_box_reg: 0.0616 (0.0667)  time: 0.6763  data: 0.2892  max mem: 5923\n",
      "Training Epoch: [131]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1325 (0.1344)  loss_objectness: 0.0606 (0.0684)  loss_rpn_box_reg: 0.0641 (0.0661)  time: 0.6828  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [131]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1331 (0.1360)  loss_objectness: 0.0614 (0.0685)  loss_rpn_box_reg: 0.0666 (0.0675)  time: 0.6862  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [131]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1446 (0.1371)  loss_objectness: 0.0697 (0.0694)  loss_rpn_box_reg: 0.0719 (0.0677)  time: 0.6731  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [131]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1448 (0.1382)  loss_objectness: 0.0716 (0.0699)  loss_rpn_box_reg: 0.0726 (0.0683)  time: 0.6791  data: 0.2990  max mem: 5923\n",
      "Training Epoch: [131]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1393 (0.1377)  loss_objectness: 0.0646 (0.0694)  loss_rpn_box_reg: 0.0726 (0.0683)  time: 0.6896  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [131]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1393 (0.1378)  loss_objectness: 0.0635 (0.0693)  loss_rpn_box_reg: 0.0682 (0.0685)  time: 0.6905  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [131]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1429 (0.1383)  loss_objectness: 0.0705 (0.0694)  loss_rpn_box_reg: 0.0689 (0.0689)  time: 0.6892  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [131]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1422 (0.1387)  loss_objectness: 0.0706 (0.0698)  loss_rpn_box_reg: 0.0697 (0.0690)  time: 0.6937  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [131]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1398 (0.1385)  loss_objectness: 0.0686 (0.0697)  loss_rpn_box_reg: 0.0654 (0.0688)  time: 0.6979  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [131]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1354 (0.1385)  loss_objectness: 0.0686 (0.0700)  loss_rpn_box_reg: 0.0616 (0.0685)  time: 0.6920  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [131]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1351 (0.1384)  loss_objectness: 0.0646 (0.0696)  loss_rpn_box_reg: 0.0602 (0.0688)  time: 0.6877  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [131]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1351 (0.1381)  loss_objectness: 0.0610 (0.0694)  loss_rpn_box_reg: 0.0788 (0.0688)  time: 0.6930  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [131]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1222 (0.1386)  loss_objectness: 0.0637 (0.0698)  loss_rpn_box_reg: 0.0662 (0.0688)  time: 0.6901  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [131]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1465 (0.1390)  loss_objectness: 0.0669 (0.0697)  loss_rpn_box_reg: 0.0758 (0.0693)  time: 0.6901  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [131]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1500 (0.1396)  loss_objectness: 0.0669 (0.0701)  loss_rpn_box_reg: 0.0758 (0.0696)  time: 0.6959  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [131]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1500 (0.1400)  loss_objectness: 0.0663 (0.0704)  loss_rpn_box_reg: 0.0710 (0.0696)  time: 0.6886  data: 0.2995  max mem: 5923\n",
      "Training Epoch: [131]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1332 (0.1399)  loss_objectness: 0.0663 (0.0704)  loss_rpn_box_reg: 0.0622 (0.0695)  time: 0.6732  data: 0.2964  max mem: 5923\n",
      "Training Epoch: [131] Total time: 0:02:52 (0.6886 s / it)\n",
      "Testing Epoch: [131]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1289 (0.1289)  loss_objectness: 0.0444 (0.0444)  loss_rpn_box_reg: 0.0846 (0.0846)  time: 0.6151  data: 0.2871  max mem: 5923\n",
      "Testing Epoch: [131]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1408 (0.1381)  loss_objectness: 0.0572 (0.0588)  loss_rpn_box_reg: 0.0725 (0.0793)  time: 0.6287  data: 0.3069  max mem: 5923\n",
      "Testing Epoch: [131] Total time: 0:00:39 (0.6382 s / it)\n",
      "Training Epoch: [132]  [  0/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1503 (0.1503)  loss_objectness: 0.0673 (0.0673)  loss_rpn_box_reg: 0.0830 (0.0830)  time: 0.6451  data: 0.3241  max mem: 5923\n",
      "Training Epoch: [132]  [ 10/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1092 (0.1197)  loss_objectness: 0.0667 (0.0644)  loss_rpn_box_reg: 0.0539 (0.0553)  time: 0.7148  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [132]  [ 20/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1372 (0.1326)  loss_objectness: 0.0696 (0.0691)  loss_rpn_box_reg: 0.0624 (0.0635)  time: 0.7034  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [132]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1425 (0.1332)  loss_objectness: 0.0663 (0.0687)  loss_rpn_box_reg: 0.0672 (0.0645)  time: 0.6725  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [132]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1168 (0.1295)  loss_objectness: 0.0580 (0.0654)  loss_rpn_box_reg: 0.0608 (0.0641)  time: 0.6794  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [132]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1190 (0.1299)  loss_objectness: 0.0559 (0.0650)  loss_rpn_box_reg: 0.0639 (0.0649)  time: 0.6905  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [132]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1253 (0.1301)  loss_objectness: 0.0625 (0.0649)  loss_rpn_box_reg: 0.0690 (0.0653)  time: 0.6895  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [132]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1273 (0.1295)  loss_objectness: 0.0576 (0.0636)  loss_rpn_box_reg: 0.0711 (0.0658)  time: 0.6854  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [132]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1288 (0.1338)  loss_objectness: 0.0598 (0.0655)  loss_rpn_box_reg: 0.0765 (0.0682)  time: 0.6836  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [132]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1492 (0.1346)  loss_objectness: 0.0664 (0.0664)  loss_rpn_box_reg: 0.0722 (0.0682)  time: 0.6906  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [132]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1477 (0.1356)  loss_objectness: 0.0713 (0.0666)  loss_rpn_box_reg: 0.0717 (0.0689)  time: 0.6924  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [132]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1232 (0.1350)  loss_objectness: 0.0634 (0.0662)  loss_rpn_box_reg: 0.0717 (0.0688)  time: 0.6952  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [132]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1321 (0.1357)  loss_objectness: 0.0616 (0.0663)  loss_rpn_box_reg: 0.0694 (0.0694)  time: 0.6861  data: 0.2883  max mem: 5923\n",
      "Training Epoch: [132]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1386 (0.1361)  loss_objectness: 0.0628 (0.0665)  loss_rpn_box_reg: 0.0703 (0.0696)  time: 0.6843  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [132]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1435 (0.1374)  loss_objectness: 0.0712 (0.0674)  loss_rpn_box_reg: 0.0692 (0.0700)  time: 0.6906  data: 0.2967  max mem: 5923\n",
      "Training Epoch: [132]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1505 (0.1378)  loss_objectness: 0.0708 (0.0673)  loss_rpn_box_reg: 0.0704 (0.0705)  time: 0.6935  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [132]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1520 (0.1394)  loss_objectness: 0.0720 (0.0683)  loss_rpn_box_reg: 0.0717 (0.0711)  time: 0.6857  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [132]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1530 (0.1402)  loss_objectness: 0.0819 (0.0694)  loss_rpn_box_reg: 0.0704 (0.0708)  time: 0.6934  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [132]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1381 (0.1399)  loss_objectness: 0.0717 (0.0694)  loss_rpn_box_reg: 0.0699 (0.0705)  time: 0.7029  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [132]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1348 (0.1401)  loss_objectness: 0.0666 (0.0694)  loss_rpn_box_reg: 0.0699 (0.0706)  time: 0.6870  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [132]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1348 (0.1398)  loss_objectness: 0.0691 (0.0696)  loss_rpn_box_reg: 0.0621 (0.0702)  time: 0.6851  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [132]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1378 (0.1406)  loss_objectness: 0.0777 (0.0701)  loss_rpn_box_reg: 0.0648 (0.0705)  time: 0.6924  data: 0.2967  max mem: 5923\n",
      "Training Epoch: [132]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1468 (0.1405)  loss_objectness: 0.0767 (0.0706)  loss_rpn_box_reg: 0.0667 (0.0700)  time: 0.7051  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [132]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1414 (0.1408)  loss_objectness: 0.0694 (0.0707)  loss_rpn_box_reg: 0.0621 (0.0702)  time: 0.7102  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [132]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1362 (0.1407)  loss_objectness: 0.0753 (0.0711)  loss_rpn_box_reg: 0.0586 (0.0696)  time: 0.6959  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [132]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1345 (0.1405)  loss_objectness: 0.0689 (0.0709)  loss_rpn_box_reg: 0.0608 (0.0696)  time: 0.6847  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [132] Total time: 0:02:52 (0.6911 s / it)\n",
      "Testing Epoch: [132]  [ 0/62]  eta: 0:00:45  lr: 0.000300  loss: 0.1350 (0.1350)  loss_objectness: 0.0452 (0.0452)  loss_rpn_box_reg: 0.0898 (0.0898)  time: 0.7372  data: 0.3981  max mem: 5923\n",
      "Testing Epoch: [132]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1289 (0.1401)  loss_objectness: 0.0544 (0.0604)  loss_rpn_box_reg: 0.0715 (0.0797)  time: 0.6329  data: 0.3098  max mem: 5923\n",
      "Testing Epoch: [132] Total time: 0:00:39 (0.6374 s / it)\n",
      "Training Epoch: [133]  [  0/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1085 (0.1085)  loss_objectness: 0.0587 (0.0587)  loss_rpn_box_reg: 0.0498 (0.0498)  time: 0.6551  data: 0.2741  max mem: 5923\n",
      "Training Epoch: [133]  [ 10/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1274 (0.1318)  loss_objectness: 0.0663 (0.0748)  loss_rpn_box_reg: 0.0603 (0.0570)  time: 0.6649  data: 0.2874  max mem: 5923\n",
      "Training Epoch: [133]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1326 (0.1308)  loss_objectness: 0.0633 (0.0693)  loss_rpn_box_reg: 0.0620 (0.0615)  time: 0.6830  data: 0.2884  max mem: 5923\n",
      "Training Epoch: [133]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1319 (0.1323)  loss_objectness: 0.0632 (0.0672)  loss_rpn_box_reg: 0.0620 (0.0650)  time: 0.6918  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [133]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1295 (0.1366)  loss_objectness: 0.0672 (0.0703)  loss_rpn_box_reg: 0.0561 (0.0664)  time: 0.6985  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [133]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1423 (0.1390)  loss_objectness: 0.0735 (0.0705)  loss_rpn_box_reg: 0.0741 (0.0686)  time: 0.7035  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [133]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1411 (0.1396)  loss_objectness: 0.0696 (0.0701)  loss_rpn_box_reg: 0.0688 (0.0694)  time: 0.6809  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [133]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1411 (0.1396)  loss_objectness: 0.0726 (0.0702)  loss_rpn_box_reg: 0.0671 (0.0694)  time: 0.6823  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [133]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1253 (0.1374)  loss_objectness: 0.0604 (0.0688)  loss_rpn_box_reg: 0.0661 (0.0687)  time: 0.6895  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [133]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1259 (0.1388)  loss_objectness: 0.0612 (0.0689)  loss_rpn_box_reg: 0.0629 (0.0699)  time: 0.6815  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [133]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1448 (0.1396)  loss_objectness: 0.0665 (0.0699)  loss_rpn_box_reg: 0.0629 (0.0697)  time: 0.6657  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [133]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1295 (0.1378)  loss_objectness: 0.0696 (0.0695)  loss_rpn_box_reg: 0.0601 (0.0684)  time: 0.6783  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [133]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1197 (0.1376)  loss_objectness: 0.0656 (0.0691)  loss_rpn_box_reg: 0.0568 (0.0685)  time: 0.7085  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [133]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1212 (0.1378)  loss_objectness: 0.0656 (0.0697)  loss_rpn_box_reg: 0.0568 (0.0681)  time: 0.7095  data: 0.2986  max mem: 5923\n",
      "Training Epoch: [133]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1455 (0.1399)  loss_objectness: 0.0726 (0.0706)  loss_rpn_box_reg: 0.0658 (0.0693)  time: 0.7060  data: 0.3016  max mem: 5923\n",
      "Training Epoch: [133]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1424 (0.1399)  loss_objectness: 0.0704 (0.0709)  loss_rpn_box_reg: 0.0658 (0.0689)  time: 0.6986  data: 0.2977  max mem: 5923\n",
      "Training Epoch: [133]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1260 (0.1390)  loss_objectness: 0.0648 (0.0706)  loss_rpn_box_reg: 0.0576 (0.0684)  time: 0.6912  data: 0.2967  max mem: 5923\n",
      "Training Epoch: [133]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1260 (0.1393)  loss_objectness: 0.0637 (0.0704)  loss_rpn_box_reg: 0.0600 (0.0690)  time: 0.6850  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [133]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1406 (0.1394)  loss_objectness: 0.0639 (0.0707)  loss_rpn_box_reg: 0.0646 (0.0687)  time: 0.6772  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [133]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1314 (0.1388)  loss_objectness: 0.0657 (0.0704)  loss_rpn_box_reg: 0.0646 (0.0684)  time: 0.6828  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [133]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1510 (0.1402)  loss_objectness: 0.0728 (0.0712)  loss_rpn_box_reg: 0.0627 (0.0690)  time: 0.6753  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [133]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1459 (0.1403)  loss_objectness: 0.0780 (0.0716)  loss_rpn_box_reg: 0.0621 (0.0687)  time: 0.6752  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [133]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1370 (0.1403)  loss_objectness: 0.0672 (0.0715)  loss_rpn_box_reg: 0.0613 (0.0688)  time: 0.7008  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [133]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1444 (0.1406)  loss_objectness: 0.0642 (0.0714)  loss_rpn_box_reg: 0.0663 (0.0692)  time: 0.6929  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [133]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1435 (0.1406)  loss_objectness: 0.0660 (0.0713)  loss_rpn_box_reg: 0.0663 (0.0693)  time: 0.6817  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [133]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1435 (0.1410)  loss_objectness: 0.0712 (0.0715)  loss_rpn_box_reg: 0.0705 (0.0695)  time: 0.6970  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [133] Total time: 0:02:52 (0.6888 s / it)\n",
      "Testing Epoch: [133]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1357 (0.1357)  loss_objectness: 0.0465 (0.0465)  loss_rpn_box_reg: 0.0892 (0.0892)  time: 0.6261  data: 0.2971  max mem: 5923\n",
      "Testing Epoch: [133]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1281 (0.1404)  loss_objectness: 0.0540 (0.0609)  loss_rpn_box_reg: 0.0725 (0.0794)  time: 0.6289  data: 0.3061  max mem: 5923\n",
      "Testing Epoch: [133] Total time: 0:00:39 (0.6349 s / it)\n",
      "Training Epoch: [134]  [  0/250]  eta: 0:02:53  lr: 0.000300  loss: 0.1763 (0.1763)  loss_objectness: 0.0730 (0.0730)  loss_rpn_box_reg: 0.1034 (0.1034)  time: 0.6932  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [134]  [ 10/250]  eta: 0:02:52  lr: 0.000300  loss: 0.1154 (0.1294)  loss_objectness: 0.0628 (0.0682)  loss_rpn_box_reg: 0.0526 (0.0612)  time: 0.7206  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [134]  [ 20/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1368 (0.1347)  loss_objectness: 0.0690 (0.0709)  loss_rpn_box_reg: 0.0608 (0.0638)  time: 0.7113  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [134]  [ 30/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1418 (0.1380)  loss_objectness: 0.0776 (0.0724)  loss_rpn_box_reg: 0.0626 (0.0656)  time: 0.7024  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [134]  [ 40/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1365 (0.1381)  loss_objectness: 0.0763 (0.0718)  loss_rpn_box_reg: 0.0626 (0.0663)  time: 0.7032  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [134]  [ 50/250]  eta: 0:02:20  lr: 0.000300  loss: 0.1494 (0.1417)  loss_objectness: 0.0725 (0.0715)  loss_rpn_box_reg: 0.0696 (0.0701)  time: 0.6965  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [134]  [ 60/250]  eta: 0:02:12  lr: 0.000300  loss: 0.1489 (0.1429)  loss_objectness: 0.0778 (0.0721)  loss_rpn_box_reg: 0.0812 (0.0708)  time: 0.6828  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [134]  [ 70/250]  eta: 0:02:05  lr: 0.000300  loss: 0.1373 (0.1413)  loss_objectness: 0.0664 (0.0713)  loss_rpn_box_reg: 0.0693 (0.0700)  time: 0.6888  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [134]  [ 80/250]  eta: 0:01:58  lr: 0.000300  loss: 0.1214 (0.1395)  loss_objectness: 0.0604 (0.0713)  loss_rpn_box_reg: 0.0569 (0.0681)  time: 0.6872  data: 0.2878  max mem: 5923\n",
      "Training Epoch: [134]  [ 90/250]  eta: 0:01:51  lr: 0.000300  loss: 0.1186 (0.1377)  loss_objectness: 0.0644 (0.0705)  loss_rpn_box_reg: 0.0569 (0.0672)  time: 0.6773  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [134]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1380 (0.1388)  loss_objectness: 0.0693 (0.0716)  loss_rpn_box_reg: 0.0626 (0.0672)  time: 0.6791  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [134]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1457 (0.1399)  loss_objectness: 0.0756 (0.0719)  loss_rpn_box_reg: 0.0650 (0.0681)  time: 0.6799  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [134]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1403 (0.1400)  loss_objectness: 0.0687 (0.0714)  loss_rpn_box_reg: 0.0725 (0.0686)  time: 0.6791  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [134]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1361 (0.1405)  loss_objectness: 0.0673 (0.0713)  loss_rpn_box_reg: 0.0630 (0.0692)  time: 0.6660  data: 0.2886  max mem: 5923\n",
      "Training Epoch: [134]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1371 (0.1407)  loss_objectness: 0.0674 (0.0713)  loss_rpn_box_reg: 0.0666 (0.0694)  time: 0.6751  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [134]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1378 (0.1406)  loss_objectness: 0.0674 (0.0716)  loss_rpn_box_reg: 0.0666 (0.0690)  time: 0.6828  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [134]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1513 (0.1417)  loss_objectness: 0.0792 (0.0718)  loss_rpn_box_reg: 0.0667 (0.0699)  time: 0.6752  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [134]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1513 (0.1423)  loss_objectness: 0.0760 (0.0720)  loss_rpn_box_reg: 0.0755 (0.0703)  time: 0.6704  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [134]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1462 (0.1424)  loss_objectness: 0.0737 (0.0720)  loss_rpn_box_reg: 0.0753 (0.0704)  time: 0.6837  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [134]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1414 (0.1421)  loss_objectness: 0.0760 (0.0721)  loss_rpn_box_reg: 0.0679 (0.0700)  time: 0.6939  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [134]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1343 (0.1418)  loss_objectness: 0.0704 (0.0720)  loss_rpn_box_reg: 0.0595 (0.0698)  time: 0.6952  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [134]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1287 (0.1417)  loss_objectness: 0.0673 (0.0715)  loss_rpn_box_reg: 0.0673 (0.0702)  time: 0.7058  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [134]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1314 (0.1420)  loss_objectness: 0.0685 (0.0718)  loss_rpn_box_reg: 0.0673 (0.0702)  time: 0.6908  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [134]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1505 (0.1428)  loss_objectness: 0.0708 (0.0723)  loss_rpn_box_reg: 0.0709 (0.0705)  time: 0.6735  data: 0.3010  max mem: 5923\n",
      "Training Epoch: [134]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1434 (0.1424)  loss_objectness: 0.0733 (0.0724)  loss_rpn_box_reg: 0.0671 (0.0700)  time: 0.6902  data: 0.2990  max mem: 5923\n",
      "Training Epoch: [134]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1434 (0.1426)  loss_objectness: 0.0791 (0.0727)  loss_rpn_box_reg: 0.0657 (0.0700)  time: 0.6948  data: 0.2960  max mem: 5923\n",
      "Training Epoch: [134] Total time: 0:02:51 (0.6875 s / it)\n",
      "Testing Epoch: [134]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1301 (0.1301)  loss_objectness: 0.0460 (0.0460)  loss_rpn_box_reg: 0.0841 (0.0841)  time: 0.6161  data: 0.2931  max mem: 5923\n",
      "Testing Epoch: [134]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1369 (0.1412)  loss_objectness: 0.0565 (0.0599)  loss_rpn_box_reg: 0.0787 (0.0813)  time: 0.6354  data: 0.3108  max mem: 5923\n",
      "Testing Epoch: [134] Total time: 0:00:39 (0.6372 s / it)\n",
      "Training Epoch: [135]  [  0/250]  eta: 0:02:59  lr: 0.000300  loss: 0.1063 (0.1063)  loss_objectness: 0.0636 (0.0636)  loss_rpn_box_reg: 0.0427 (0.0427)  time: 0.7162  data: 0.3011  max mem: 5923\n",
      "Training Epoch: [135]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1364 (0.1390)  loss_objectness: 0.0740 (0.0745)  loss_rpn_box_reg: 0.0549 (0.0644)  time: 0.7000  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [135]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1364 (0.1375)  loss_objectness: 0.0729 (0.0738)  loss_rpn_box_reg: 0.0587 (0.0636)  time: 0.6844  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [135]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1481 (0.1440)  loss_objectness: 0.0722 (0.0756)  loss_rpn_box_reg: 0.0717 (0.0684)  time: 0.6854  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [135]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1539 (0.1418)  loss_objectness: 0.0719 (0.0740)  loss_rpn_box_reg: 0.0725 (0.0678)  time: 0.6928  data: 0.2972  max mem: 5923\n",
      "Training Epoch: [135]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1305 (0.1398)  loss_objectness: 0.0662 (0.0718)  loss_rpn_box_reg: 0.0693 (0.0680)  time: 0.6807  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [135]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1314 (0.1398)  loss_objectness: 0.0581 (0.0705)  loss_rpn_box_reg: 0.0693 (0.0694)  time: 0.6780  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [135]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1326 (0.1391)  loss_objectness: 0.0598 (0.0696)  loss_rpn_box_reg: 0.0598 (0.0695)  time: 0.6905  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [135]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1338 (0.1411)  loss_objectness: 0.0618 (0.0690)  loss_rpn_box_reg: 0.0741 (0.0721)  time: 0.6962  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [135]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1411 (0.1417)  loss_objectness: 0.0684 (0.0695)  loss_rpn_box_reg: 0.0741 (0.0721)  time: 0.6848  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [135]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1360 (0.1412)  loss_objectness: 0.0678 (0.0691)  loss_rpn_box_reg: 0.0677 (0.0721)  time: 0.6797  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [135]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1269 (0.1405)  loss_objectness: 0.0657 (0.0690)  loss_rpn_box_reg: 0.0693 (0.0715)  time: 0.6754  data: 0.2877  max mem: 5923\n",
      "Training Epoch: [135]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1338 (0.1403)  loss_objectness: 0.0663 (0.0690)  loss_rpn_box_reg: 0.0624 (0.0713)  time: 0.6698  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [135]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1236 (0.1390)  loss_objectness: 0.0657 (0.0686)  loss_rpn_box_reg: 0.0622 (0.0705)  time: 0.6792  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [135]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1297 (0.1400)  loss_objectness: 0.0625 (0.0692)  loss_rpn_box_reg: 0.0666 (0.0708)  time: 0.6826  data: 0.2978  max mem: 5923\n",
      "Training Epoch: [135]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1602 (0.1408)  loss_objectness: 0.0792 (0.0699)  loss_rpn_box_reg: 0.0731 (0.0709)  time: 0.6769  data: 0.2968  max mem: 5923\n",
      "Training Epoch: [135]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1524 (0.1415)  loss_objectness: 0.0774 (0.0703)  loss_rpn_box_reg: 0.0708 (0.0712)  time: 0.6829  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [135]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1541 (0.1425)  loss_objectness: 0.0785 (0.0713)  loss_rpn_box_reg: 0.0683 (0.0711)  time: 0.7018  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [135]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1375 (0.1419)  loss_objectness: 0.0769 (0.0710)  loss_rpn_box_reg: 0.0616 (0.0709)  time: 0.6999  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [135]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1187 (0.1414)  loss_objectness: 0.0669 (0.0713)  loss_rpn_box_reg: 0.0553 (0.0702)  time: 0.6966  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [135]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1362 (0.1414)  loss_objectness: 0.0745 (0.0714)  loss_rpn_box_reg: 0.0567 (0.0700)  time: 0.6894  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [135]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1403 (0.1413)  loss_objectness: 0.0731 (0.0711)  loss_rpn_box_reg: 0.0622 (0.0703)  time: 0.6858  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [135]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1420 (0.1416)  loss_objectness: 0.0647 (0.0711)  loss_rpn_box_reg: 0.0732 (0.0705)  time: 0.6945  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [135]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1367 (0.1414)  loss_objectness: 0.0731 (0.0711)  loss_rpn_box_reg: 0.0713 (0.0702)  time: 0.6843  data: 0.2879  max mem: 5923\n",
      "Training Epoch: [135]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1366 (0.1413)  loss_objectness: 0.0742 (0.0713)  loss_rpn_box_reg: 0.0628 (0.0700)  time: 0.6868  data: 0.2894  max mem: 5923\n",
      "Training Epoch: [135]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1366 (0.1414)  loss_objectness: 0.0758 (0.0716)  loss_rpn_box_reg: 0.0609 (0.0698)  time: 0.6777  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [135] Total time: 0:02:51 (0.6855 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:04  model_time: 0.6802 (0.6802)  evaluator_time: 0.0600 (0.0600)  time: 1.0412  data: 0.2851  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3981 (0.3989)  evaluator_time: 0.0720 (0.0819)  time: 0.7908  data: 0.3104  max mem: 5923\n",
      "Test: Total time: 0:00:49 (0.7912 s / it)\n",
      "Averaged stats: model_time: 0.3981 (0.3989)  evaluator_time: 0.0720 (0.0819)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.11s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.022\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n",
      "Testing Epoch: [135]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1358 (0.1358)  loss_objectness: 0.0455 (0.0455)  loss_rpn_box_reg: 0.0903 (0.0903)  time: 0.6241  data: 0.3001  max mem: 5923\n",
      "Testing Epoch: [135]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1292 (0.1414)  loss_objectness: 0.0559 (0.0613)  loss_rpn_box_reg: 0.0719 (0.0801)  time: 0.6337  data: 0.3099  max mem: 5923\n",
      "Testing Epoch: [135] Total time: 0:00:39 (0.6383 s / it)\n",
      "Training Epoch: [136]  [  0/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1120 (0.1120)  loss_objectness: 0.0631 (0.0631)  loss_rpn_box_reg: 0.0488 (0.0488)  time: 0.6221  data: 0.3001  max mem: 5923\n",
      "Training Epoch: [136]  [ 10/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1496 (0.1425)  loss_objectness: 0.0780 (0.0740)  loss_rpn_box_reg: 0.0655 (0.0684)  time: 0.6630  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [136]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1511 (0.1528)  loss_objectness: 0.0722 (0.0708)  loss_rpn_box_reg: 0.0701 (0.0820)  time: 0.6853  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [136]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1404 (0.1443)  loss_objectness: 0.0684 (0.0687)  loss_rpn_box_reg: 0.0677 (0.0757)  time: 0.6934  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [136]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1290 (0.1443)  loss_objectness: 0.0637 (0.0675)  loss_rpn_box_reg: 0.0677 (0.0768)  time: 0.6834  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [136]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1408 (0.1437)  loss_objectness: 0.0627 (0.0679)  loss_rpn_box_reg: 0.0754 (0.0758)  time: 0.7021  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [136]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1396 (0.1428)  loss_objectness: 0.0733 (0.0701)  loss_rpn_box_reg: 0.0619 (0.0727)  time: 0.6921  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [136]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1306 (0.1419)  loss_objectness: 0.0733 (0.0700)  loss_rpn_box_reg: 0.0592 (0.0719)  time: 0.6731  data: 0.2898  max mem: 5923\n",
      "Training Epoch: [136]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1270 (0.1395)  loss_objectness: 0.0613 (0.0692)  loss_rpn_box_reg: 0.0566 (0.0704)  time: 0.7051  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [136]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1179 (0.1391)  loss_objectness: 0.0640 (0.0694)  loss_rpn_box_reg: 0.0557 (0.0697)  time: 0.7140  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [136]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1384 (0.1387)  loss_objectness: 0.0640 (0.0694)  loss_rpn_box_reg: 0.0584 (0.0693)  time: 0.6944  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [136]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1384 (0.1385)  loss_objectness: 0.0638 (0.0697)  loss_rpn_box_reg: 0.0584 (0.0688)  time: 0.6833  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [136]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1348 (0.1388)  loss_objectness: 0.0657 (0.0695)  loss_rpn_box_reg: 0.0596 (0.0693)  time: 0.6906  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [136]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1197 (0.1380)  loss_objectness: 0.0640 (0.0691)  loss_rpn_box_reg: 0.0579 (0.0689)  time: 0.6862  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [136]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1245 (0.1378)  loss_objectness: 0.0644 (0.0690)  loss_rpn_box_reg: 0.0629 (0.0689)  time: 0.6729  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [136]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1312 (0.1387)  loss_objectness: 0.0745 (0.0699)  loss_rpn_box_reg: 0.0631 (0.0688)  time: 0.6936  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [136]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1456 (0.1391)  loss_objectness: 0.0748 (0.0701)  loss_rpn_box_reg: 0.0630 (0.0691)  time: 0.6926  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [136]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1332 (0.1394)  loss_objectness: 0.0693 (0.0702)  loss_rpn_box_reg: 0.0677 (0.0692)  time: 0.6742  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [136]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1332 (0.1389)  loss_objectness: 0.0634 (0.0702)  loss_rpn_box_reg: 0.0638 (0.0688)  time: 0.6835  data: 0.2861  max mem: 5923\n",
      "Training Epoch: [136]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1317 (0.1386)  loss_objectness: 0.0628 (0.0701)  loss_rpn_box_reg: 0.0620 (0.0685)  time: 0.7019  data: 0.2889  max mem: 5923\n",
      "Training Epoch: [136]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1389 (0.1390)  loss_objectness: 0.0642 (0.0699)  loss_rpn_box_reg: 0.0628 (0.0691)  time: 0.6922  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [136]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1245 (0.1388)  loss_objectness: 0.0617 (0.0697)  loss_rpn_box_reg: 0.0708 (0.0691)  time: 0.6808  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [136]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1282 (0.1387)  loss_objectness: 0.0640 (0.0698)  loss_rpn_box_reg: 0.0643 (0.0690)  time: 0.6886  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [136]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1406 (0.1394)  loss_objectness: 0.0687 (0.0701)  loss_rpn_box_reg: 0.0643 (0.0693)  time: 0.6821  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [136]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1423 (0.1400)  loss_objectness: 0.0716 (0.0705)  loss_rpn_box_reg: 0.0737 (0.0694)  time: 0.6769  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [136]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1413 (0.1399)  loss_objectness: 0.0716 (0.0706)  loss_rpn_box_reg: 0.0688 (0.0693)  time: 0.6830  data: 0.2977  max mem: 5923\n",
      "Training Epoch: [136] Total time: 0:02:52 (0.6880 s / it)\n",
      "Testing Epoch: [136]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1292 (0.1292)  loss_objectness: 0.0428 (0.0428)  loss_rpn_box_reg: 0.0864 (0.0864)  time: 0.6311  data: 0.2971  max mem: 5923\n",
      "Testing Epoch: [136]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1351 (0.1409)  loss_objectness: 0.0534 (0.0590)  loss_rpn_box_reg: 0.0734 (0.0819)  time: 0.6322  data: 0.3102  max mem: 5923\n",
      "Testing Epoch: [136] Total time: 0:00:39 (0.6337 s / it)\n",
      "Training Epoch: [137]  [  0/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1213 (0.1213)  loss_objectness: 0.0604 (0.0604)  loss_rpn_box_reg: 0.0609 (0.0609)  time: 0.6601  data: 0.2811  max mem: 5923\n",
      "Training Epoch: [137]  [ 10/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1213 (0.1347)  loss_objectness: 0.0732 (0.0738)  loss_rpn_box_reg: 0.0609 (0.0609)  time: 0.6582  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [137]  [ 20/250]  eta: 0:02:33  lr: 0.000300  loss: 0.1351 (0.1371)  loss_objectness: 0.0679 (0.0689)  loss_rpn_box_reg: 0.0663 (0.0682)  time: 0.6691  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [137]  [ 30/250]  eta: 0:02:26  lr: 0.000300  loss: 0.1321 (0.1344)  loss_objectness: 0.0656 (0.0703)  loss_rpn_box_reg: 0.0620 (0.0641)  time: 0.6703  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [137]  [ 40/250]  eta: 0:02:20  lr: 0.000300  loss: 0.1311 (0.1344)  loss_objectness: 0.0656 (0.0698)  loss_rpn_box_reg: 0.0592 (0.0646)  time: 0.6709  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [137]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1267 (0.1340)  loss_objectness: 0.0647 (0.0688)  loss_rpn_box_reg: 0.0596 (0.0652)  time: 0.6906  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [137]  [ 60/250]  eta: 0:02:08  lr: 0.000300  loss: 0.1310 (0.1355)  loss_objectness: 0.0649 (0.0684)  loss_rpn_box_reg: 0.0624 (0.0671)  time: 0.6879  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [137]  [ 70/250]  eta: 0:02:01  lr: 0.000300  loss: 0.1262 (0.1340)  loss_objectness: 0.0639 (0.0672)  loss_rpn_box_reg: 0.0659 (0.0668)  time: 0.6684  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [137]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1317 (0.1345)  loss_objectness: 0.0611 (0.0673)  loss_rpn_box_reg: 0.0664 (0.0672)  time: 0.6874  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [137]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1473 (0.1364)  loss_objectness: 0.0681 (0.0684)  loss_rpn_box_reg: 0.0724 (0.0680)  time: 0.7088  data: 0.2963  max mem: 5923\n",
      "Training Epoch: [137]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1526 (0.1372)  loss_objectness: 0.0689 (0.0686)  loss_rpn_box_reg: 0.0658 (0.0686)  time: 0.6993  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [137]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1396 (0.1367)  loss_objectness: 0.0659 (0.0688)  loss_rpn_box_reg: 0.0681 (0.0679)  time: 0.6970  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [137]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1338 (0.1359)  loss_objectness: 0.0648 (0.0688)  loss_rpn_box_reg: 0.0611 (0.0671)  time: 0.6877  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [137]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1344 (0.1374)  loss_objectness: 0.0615 (0.0692)  loss_rpn_box_reg: 0.0665 (0.0682)  time: 0.6820  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [137]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1454 (0.1380)  loss_objectness: 0.0620 (0.0695)  loss_rpn_box_reg: 0.0777 (0.0686)  time: 0.6791  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [137]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1355 (0.1387)  loss_objectness: 0.0735 (0.0697)  loss_rpn_box_reg: 0.0673 (0.0690)  time: 0.6788  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [137]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1328 (0.1383)  loss_objectness: 0.0668 (0.0697)  loss_rpn_box_reg: 0.0670 (0.0686)  time: 0.6941  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [137]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1444 (0.1392)  loss_objectness: 0.0668 (0.0701)  loss_rpn_box_reg: 0.0670 (0.0691)  time: 0.6977  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [137]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1423 (0.1387)  loss_objectness: 0.0741 (0.0702)  loss_rpn_box_reg: 0.0634 (0.0686)  time: 0.7027  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [137]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1467 (0.1398)  loss_objectness: 0.0779 (0.0709)  loss_rpn_box_reg: 0.0634 (0.0690)  time: 0.6904  data: 0.2984  max mem: 5923\n",
      "Training Epoch: [137]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1476 (0.1401)  loss_objectness: 0.0752 (0.0709)  loss_rpn_box_reg: 0.0689 (0.0692)  time: 0.6711  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [137]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1325 (0.1403)  loss_objectness: 0.0695 (0.0709)  loss_rpn_box_reg: 0.0671 (0.0694)  time: 0.6711  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [137]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1378 (0.1404)  loss_objectness: 0.0695 (0.0708)  loss_rpn_box_reg: 0.0661 (0.0697)  time: 0.6765  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [137]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1436 (0.1410)  loss_objectness: 0.0644 (0.0709)  loss_rpn_box_reg: 0.0849 (0.0702)  time: 0.6777  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [137]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1436 (0.1414)  loss_objectness: 0.0720 (0.0711)  loss_rpn_box_reg: 0.0813 (0.0703)  time: 0.6848  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [137]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1363 (0.1413)  loss_objectness: 0.0739 (0.0713)  loss_rpn_box_reg: 0.0545 (0.0700)  time: 0.6944  data: 0.2976  max mem: 5923\n",
      "Training Epoch: [137] Total time: 0:02:51 (0.6848 s / it)\n",
      "Testing Epoch: [137]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1313 (0.1313)  loss_objectness: 0.0434 (0.0434)  loss_rpn_box_reg: 0.0879 (0.0879)  time: 0.6331  data: 0.3001  max mem: 5923\n",
      "Testing Epoch: [137]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1314 (0.1380)  loss_objectness: 0.0558 (0.0575)  loss_rpn_box_reg: 0.0753 (0.0805)  time: 0.6352  data: 0.3117  max mem: 5923\n",
      "Testing Epoch: [137] Total time: 0:00:39 (0.6392 s / it)\n",
      "Training Epoch: [138]  [  0/250]  eta: 0:02:43  lr: 0.000300  loss: 0.0793 (0.0793)  loss_objectness: 0.0452 (0.0452)  loss_rpn_box_reg: 0.0341 (0.0341)  time: 0.6531  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [138]  [ 10/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1342 (0.1270)  loss_objectness: 0.0624 (0.0609)  loss_rpn_box_reg: 0.0625 (0.0661)  time: 0.6766  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [138]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1288 (0.1235)  loss_objectness: 0.0598 (0.0611)  loss_rpn_box_reg: 0.0603 (0.0625)  time: 0.6872  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [138]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1214 (0.1275)  loss_objectness: 0.0598 (0.0632)  loss_rpn_box_reg: 0.0564 (0.0643)  time: 0.7048  data: 0.2970  max mem: 5923\n",
      "Training Epoch: [138]  [ 40/250]  eta: 0:02:26  lr: 0.000300  loss: 0.1214 (0.1274)  loss_objectness: 0.0651 (0.0646)  loss_rpn_box_reg: 0.0577 (0.0628)  time: 0.7058  data: 0.2990  max mem: 5923\n",
      "Training Epoch: [138]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1247 (0.1289)  loss_objectness: 0.0652 (0.0650)  loss_rpn_box_reg: 0.0579 (0.0639)  time: 0.6824  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [138]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1418 (0.1332)  loss_objectness: 0.0683 (0.0672)  loss_rpn_box_reg: 0.0657 (0.0660)  time: 0.6751  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [138]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1486 (0.1353)  loss_objectness: 0.0727 (0.0677)  loss_rpn_box_reg: 0.0734 (0.0676)  time: 0.6872  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [138]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1401 (0.1350)  loss_objectness: 0.0685 (0.0677)  loss_rpn_box_reg: 0.0734 (0.0674)  time: 0.6844  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [138]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1351 (0.1349)  loss_objectness: 0.0680 (0.0678)  loss_rpn_box_reg: 0.0644 (0.0671)  time: 0.6785  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [138]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1327 (0.1351)  loss_objectness: 0.0702 (0.0679)  loss_rpn_box_reg: 0.0649 (0.0672)  time: 0.6719  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [138]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1266 (0.1351)  loss_objectness: 0.0658 (0.0678)  loss_rpn_box_reg: 0.0712 (0.0673)  time: 0.6709  data: 0.2880  max mem: 5923\n",
      "Training Epoch: [138]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1298 (0.1355)  loss_objectness: 0.0678 (0.0681)  loss_rpn_box_reg: 0.0660 (0.0674)  time: 0.6862  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [138]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1363 (0.1358)  loss_objectness: 0.0678 (0.0679)  loss_rpn_box_reg: 0.0660 (0.0679)  time: 0.6897  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [138]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1483 (0.1372)  loss_objectness: 0.0622 (0.0683)  loss_rpn_box_reg: 0.0735 (0.0689)  time: 0.6881  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [138]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1494 (0.1380)  loss_objectness: 0.0649 (0.0686)  loss_rpn_box_reg: 0.0705 (0.0694)  time: 0.6916  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [138]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1446 (0.1381)  loss_objectness: 0.0660 (0.0685)  loss_rpn_box_reg: 0.0689 (0.0695)  time: 0.6826  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [138]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1434 (0.1384)  loss_objectness: 0.0660 (0.0685)  loss_rpn_box_reg: 0.0732 (0.0698)  time: 0.6876  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [138]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1414 (0.1383)  loss_objectness: 0.0685 (0.0690)  loss_rpn_box_reg: 0.0644 (0.0694)  time: 0.7033  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [138]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1305 (0.1381)  loss_objectness: 0.0702 (0.0689)  loss_rpn_box_reg: 0.0604 (0.0692)  time: 0.6892  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [138]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1300 (0.1382)  loss_objectness: 0.0704 (0.0691)  loss_rpn_box_reg: 0.0630 (0.0690)  time: 0.6726  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [138]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1217 (0.1377)  loss_objectness: 0.0728 (0.0693)  loss_rpn_box_reg: 0.0515 (0.0684)  time: 0.6792  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [138]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1364 (0.1383)  loss_objectness: 0.0726 (0.0695)  loss_rpn_box_reg: 0.0633 (0.0687)  time: 0.6908  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [138]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1464 (0.1386)  loss_objectness: 0.0727 (0.0696)  loss_rpn_box_reg: 0.0705 (0.0690)  time: 0.6924  data: 0.2968  max mem: 5923\n",
      "Training Epoch: [138]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1429 (0.1389)  loss_objectness: 0.0701 (0.0696)  loss_rpn_box_reg: 0.0708 (0.0692)  time: 0.6924  data: 0.2969  max mem: 5923\n",
      "Training Epoch: [138]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1452 (0.1395)  loss_objectness: 0.0698 (0.0699)  loss_rpn_box_reg: 0.0742 (0.0695)  time: 0.6956  data: 0.2983  max mem: 5923\n",
      "Training Epoch: [138] Total time: 0:02:51 (0.6871 s / it)\n",
      "Testing Epoch: [138]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1332 (0.1332)  loss_objectness: 0.0456 (0.0456)  loss_rpn_box_reg: 0.0876 (0.0876)  time: 0.6231  data: 0.2921  max mem: 5923\n",
      "Testing Epoch: [138]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1380 (0.1433)  loss_objectness: 0.0593 (0.0625)  loss_rpn_box_reg: 0.0743 (0.0808)  time: 0.6321  data: 0.3100  max mem: 5923\n",
      "Testing Epoch: [138] Total time: 0:00:39 (0.6331 s / it)\n",
      "Training Epoch: [139]  [  0/250]  eta: 0:02:42  lr: 0.000300  loss: 0.0993 (0.0993)  loss_objectness: 0.0550 (0.0550)  loss_rpn_box_reg: 0.0444 (0.0444)  time: 0.6481  data: 0.2871  max mem: 5923\n",
      "Training Epoch: [139]  [ 10/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1174 (0.1279)  loss_objectness: 0.0624 (0.0672)  loss_rpn_box_reg: 0.0517 (0.0607)  time: 0.6913  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [139]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1307 (0.1336)  loss_objectness: 0.0657 (0.0691)  loss_rpn_box_reg: 0.0595 (0.0645)  time: 0.6907  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [139]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1400 (0.1349)  loss_objectness: 0.0751 (0.0723)  loss_rpn_box_reg: 0.0580 (0.0626)  time: 0.6893  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [139]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1529 (0.1382)  loss_objectness: 0.0815 (0.0744)  loss_rpn_box_reg: 0.0580 (0.0638)  time: 0.6761  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [139]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1303 (0.1358)  loss_objectness: 0.0750 (0.0736)  loss_rpn_box_reg: 0.0566 (0.0622)  time: 0.6663  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [139]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1197 (0.1361)  loss_objectness: 0.0670 (0.0724)  loss_rpn_box_reg: 0.0523 (0.0637)  time: 0.6794  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [139]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1422 (0.1372)  loss_objectness: 0.0637 (0.0717)  loss_rpn_box_reg: 0.0616 (0.0655)  time: 0.6948  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [139]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1447 (0.1374)  loss_objectness: 0.0677 (0.0715)  loss_rpn_box_reg: 0.0716 (0.0659)  time: 0.7013  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [139]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1324 (0.1379)  loss_objectness: 0.0699 (0.0715)  loss_rpn_box_reg: 0.0716 (0.0664)  time: 0.6922  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [139]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1343 (0.1396)  loss_objectness: 0.0709 (0.0713)  loss_rpn_box_reg: 0.0750 (0.0683)  time: 0.6869  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [139]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1380 (0.1393)  loss_objectness: 0.0690 (0.0711)  loss_rpn_box_reg: 0.0715 (0.0683)  time: 0.6979  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [139]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1381 (0.1397)  loss_objectness: 0.0690 (0.0707)  loss_rpn_box_reg: 0.0695 (0.0689)  time: 0.6970  data: 0.2962  max mem: 5923\n",
      "Training Epoch: [139]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1389 (0.1403)  loss_objectness: 0.0696 (0.0710)  loss_rpn_box_reg: 0.0736 (0.0693)  time: 0.6872  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [139]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1413 (0.1403)  loss_objectness: 0.0703 (0.0710)  loss_rpn_box_reg: 0.0638 (0.0693)  time: 0.6848  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [139]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1423 (0.1408)  loss_objectness: 0.0684 (0.0707)  loss_rpn_box_reg: 0.0651 (0.0701)  time: 0.6827  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [139]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1443 (0.1411)  loss_objectness: 0.0731 (0.0713)  loss_rpn_box_reg: 0.0663 (0.0698)  time: 0.6920  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [139]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1462 (0.1410)  loss_objectness: 0.0757 (0.0714)  loss_rpn_box_reg: 0.0645 (0.0696)  time: 0.6896  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [139]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1428 (0.1411)  loss_objectness: 0.0677 (0.0714)  loss_rpn_box_reg: 0.0669 (0.0697)  time: 0.6819  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [139]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1370 (0.1407)  loss_objectness: 0.0677 (0.0715)  loss_rpn_box_reg: 0.0669 (0.0692)  time: 0.6895  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [139]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1357 (0.1412)  loss_objectness: 0.0729 (0.0715)  loss_rpn_box_reg: 0.0705 (0.0696)  time: 0.6883  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [139]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1357 (0.1409)  loss_objectness: 0.0661 (0.0712)  loss_rpn_box_reg: 0.0764 (0.0697)  time: 0.6823  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [139]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1423 (0.1409)  loss_objectness: 0.0668 (0.0712)  loss_rpn_box_reg: 0.0683 (0.0697)  time: 0.6783  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [139]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1423 (0.1411)  loss_objectness: 0.0741 (0.0714)  loss_rpn_box_reg: 0.0656 (0.0697)  time: 0.6764  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [139]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1350 (0.1410)  loss_objectness: 0.0661 (0.0713)  loss_rpn_box_reg: 0.0626 (0.0697)  time: 0.6927  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [139]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1347 (0.1408)  loss_objectness: 0.0661 (0.0711)  loss_rpn_box_reg: 0.0626 (0.0697)  time: 0.6926  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [139] Total time: 0:02:51 (0.6870 s / it)\n",
      "Testing Epoch: [139]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1347 (0.1347)  loss_objectness: 0.0495 (0.0495)  loss_rpn_box_reg: 0.0852 (0.0852)  time: 0.6231  data: 0.2911  max mem: 5923\n",
      "Testing Epoch: [139]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1244 (0.1380)  loss_objectness: 0.0538 (0.0570)  loss_rpn_box_reg: 0.0737 (0.0810)  time: 0.6340  data: 0.3089  max mem: 5923\n",
      "Testing Epoch: [139] Total time: 0:00:39 (0.6339 s / it)\n",
      "Training Epoch: [140]  [  0/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1286 (0.1286)  loss_objectness: 0.0828 (0.0828)  loss_rpn_box_reg: 0.0458 (0.0458)  time: 0.6651  data: 0.3001  max mem: 5923\n",
      "Training Epoch: [140]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1475 (0.1464)  loss_objectness: 0.0709 (0.0711)  loss_rpn_box_reg: 0.0766 (0.0752)  time: 0.6828  data: 0.2991  max mem: 5923\n",
      "Training Epoch: [140]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1396 (0.1422)  loss_objectness: 0.0613 (0.0687)  loss_rpn_box_reg: 0.0755 (0.0735)  time: 0.6829  data: 0.2960  max mem: 5923\n",
      "Training Epoch: [140]  [ 30/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1355 (0.1405)  loss_objectness: 0.0722 (0.0699)  loss_rpn_box_reg: 0.0702 (0.0705)  time: 0.6736  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [140]  [ 40/250]  eta: 0:02:21  lr: 0.000300  loss: 0.1377 (0.1409)  loss_objectness: 0.0738 (0.0709)  loss_rpn_box_reg: 0.0645 (0.0700)  time: 0.6649  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [140]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1274 (0.1379)  loss_objectness: 0.0698 (0.0700)  loss_rpn_box_reg: 0.0564 (0.0678)  time: 0.6745  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [140]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1155 (0.1363)  loss_objectness: 0.0652 (0.0698)  loss_rpn_box_reg: 0.0554 (0.0665)  time: 0.6912  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [140]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1336 (0.1366)  loss_objectness: 0.0687 (0.0702)  loss_rpn_box_reg: 0.0574 (0.0665)  time: 0.6874  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [140]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1398 (0.1381)  loss_objectness: 0.0678 (0.0697)  loss_rpn_box_reg: 0.0685 (0.0684)  time: 0.6803  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [140]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1463 (0.1402)  loss_objectness: 0.0670 (0.0696)  loss_rpn_box_reg: 0.0822 (0.0706)  time: 0.6941  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [140]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1339 (0.1387)  loss_objectness: 0.0653 (0.0690)  loss_rpn_box_reg: 0.0654 (0.0697)  time: 0.6988  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [140]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1174 (0.1375)  loss_objectness: 0.0631 (0.0685)  loss_rpn_box_reg: 0.0597 (0.0691)  time: 0.6957  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [140]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1448 (0.1391)  loss_objectness: 0.0691 (0.0692)  loss_rpn_box_reg: 0.0691 (0.0700)  time: 0.6872  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [140]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1471 (0.1387)  loss_objectness: 0.0681 (0.0688)  loss_rpn_box_reg: 0.0735 (0.0699)  time: 0.6926  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [140]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1279 (0.1379)  loss_objectness: 0.0612 (0.0685)  loss_rpn_box_reg: 0.0625 (0.0694)  time: 0.6999  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [140]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1356 (0.1381)  loss_objectness: 0.0674 (0.0686)  loss_rpn_box_reg: 0.0655 (0.0695)  time: 0.6791  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [140]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1495 (0.1397)  loss_objectness: 0.0720 (0.0688)  loss_rpn_box_reg: 0.0770 (0.0709)  time: 0.6744  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [140]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1559 (0.1402)  loss_objectness: 0.0750 (0.0694)  loss_rpn_box_reg: 0.0752 (0.0709)  time: 0.6837  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [140]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1492 (0.1407)  loss_objectness: 0.0776 (0.0700)  loss_rpn_box_reg: 0.0647 (0.0707)  time: 0.6945  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [140]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1419 (0.1407)  loss_objectness: 0.0760 (0.0702)  loss_rpn_box_reg: 0.0644 (0.0705)  time: 0.7018  data: 0.2977  max mem: 5923\n",
      "Training Epoch: [140]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1419 (0.1411)  loss_objectness: 0.0738 (0.0705)  loss_rpn_box_reg: 0.0650 (0.0706)  time: 0.6980  data: 0.2988  max mem: 5923\n",
      "Training Epoch: [140]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1396 (0.1407)  loss_objectness: 0.0687 (0.0703)  loss_rpn_box_reg: 0.0647 (0.0704)  time: 0.6952  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [140]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1381 (0.1409)  loss_objectness: 0.0656 (0.0705)  loss_rpn_box_reg: 0.0682 (0.0704)  time: 0.6964  data: 0.2964  max mem: 5923\n",
      "Training Epoch: [140]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1423 (0.1409)  loss_objectness: 0.0718 (0.0704)  loss_rpn_box_reg: 0.0716 (0.0705)  time: 0.6871  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [140]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1440 (0.1410)  loss_objectness: 0.0733 (0.0708)  loss_rpn_box_reg: 0.0716 (0.0703)  time: 0.6858  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [140]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1375 (0.1406)  loss_objectness: 0.0698 (0.0707)  loss_rpn_box_reg: 0.0614 (0.0699)  time: 0.6803  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [140] Total time: 0:02:51 (0.6869 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:08  model_time: 0.6531 (0.6531)  evaluator_time: 0.1500 (0.1500)  time: 1.1072  data: 0.2891  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3861 (0.3850)  evaluator_time: 0.0670 (0.0755)  time: 0.7710  data: 0.3036  max mem: 5923\n",
      "Test: Total time: 0:00:47 (0.7705 s / it)\n",
      "Averaged stats: model_time: 0.3861 (0.3850)  evaluator_time: 0.0670 (0.0755)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.03s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.169\n",
      "Testing Epoch: [140]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1353 (0.1353)  loss_objectness: 0.0457 (0.0457)  loss_rpn_box_reg: 0.0896 (0.0896)  time: 0.6041  data: 0.2791  max mem: 5923\n",
      "Testing Epoch: [140]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1341 (0.1414)  loss_objectness: 0.0547 (0.0598)  loss_rpn_box_reg: 0.0723 (0.0816)  time: 0.6350  data: 0.3086  max mem: 5923\n",
      "Testing Epoch: [140] Total time: 0:00:39 (0.6335 s / it)\n",
      "Training Epoch: [141]  [  0/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1240 (0.1240)  loss_objectness: 0.0642 (0.0642)  loss_rpn_box_reg: 0.0599 (0.0599)  time: 0.6842  data: 0.2981  max mem: 5923\n",
      "Training Epoch: [141]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1240 (0.1215)  loss_objectness: 0.0609 (0.0591)  loss_rpn_box_reg: 0.0636 (0.0624)  time: 0.6934  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [141]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1217 (0.1226)  loss_objectness: 0.0609 (0.0619)  loss_rpn_box_reg: 0.0631 (0.0607)  time: 0.6915  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [141]  [ 30/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1256 (0.1260)  loss_objectness: 0.0666 (0.0642)  loss_rpn_box_reg: 0.0542 (0.0618)  time: 0.7093  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [141]  [ 40/250]  eta: 0:02:27  lr: 0.000300  loss: 0.1398 (0.1308)  loss_objectness: 0.0690 (0.0668)  loss_rpn_box_reg: 0.0707 (0.0640)  time: 0.7126  data: 0.2989  max mem: 5923\n",
      "Training Epoch: [141]  [ 50/250]  eta: 0:02:19  lr: 0.000300  loss: 0.1445 (0.1333)  loss_objectness: 0.0690 (0.0667)  loss_rpn_box_reg: 0.0739 (0.0666)  time: 0.6836  data: 0.2978  max mem: 5923\n",
      "Training Epoch: [141]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1361 (0.1336)  loss_objectness: 0.0650 (0.0672)  loss_rpn_box_reg: 0.0689 (0.0664)  time: 0.6765  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [141]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1338 (0.1338)  loss_objectness: 0.0650 (0.0676)  loss_rpn_box_reg: 0.0587 (0.0662)  time: 0.6829  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [141]  [ 80/250]  eta: 0:01:58  lr: 0.000300  loss: 0.1356 (0.1353)  loss_objectness: 0.0672 (0.0680)  loss_rpn_box_reg: 0.0616 (0.0673)  time: 0.6966  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [141]  [ 90/250]  eta: 0:01:51  lr: 0.000300  loss: 0.1489 (0.1363)  loss_objectness: 0.0673 (0.0682)  loss_rpn_box_reg: 0.0691 (0.0680)  time: 0.7066  data: 0.3009  max mem: 5923\n",
      "Training Epoch: [141]  [100/250]  eta: 0:01:44  lr: 0.000300  loss: 0.1390 (0.1363)  loss_objectness: 0.0682 (0.0679)  loss_rpn_box_reg: 0.0722 (0.0685)  time: 0.6956  data: 0.2996  max mem: 5923\n",
      "Training Epoch: [141]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1295 (0.1361)  loss_objectness: 0.0603 (0.0675)  loss_rpn_box_reg: 0.0723 (0.0686)  time: 0.6798  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [141]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1336 (0.1372)  loss_objectness: 0.0649 (0.0675)  loss_rpn_box_reg: 0.0740 (0.0697)  time: 0.6828  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [141]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1378 (0.1372)  loss_objectness: 0.0649 (0.0680)  loss_rpn_box_reg: 0.0605 (0.0691)  time: 0.6780  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [141]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1396 (0.1375)  loss_objectness: 0.0740 (0.0688)  loss_rpn_box_reg: 0.0605 (0.0687)  time: 0.6761  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [141]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1396 (0.1376)  loss_objectness: 0.0740 (0.0692)  loss_rpn_box_reg: 0.0618 (0.0684)  time: 0.6848  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [141]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1352 (0.1375)  loss_objectness: 0.0695 (0.0694)  loss_rpn_box_reg: 0.0619 (0.0681)  time: 0.6854  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [141]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1339 (0.1376)  loss_objectness: 0.0656 (0.0692)  loss_rpn_box_reg: 0.0640 (0.0684)  time: 0.6735  data: 0.2872  max mem: 5923\n",
      "Training Epoch: [141]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1322 (0.1373)  loss_objectness: 0.0679 (0.0692)  loss_rpn_box_reg: 0.0697 (0.0681)  time: 0.6654  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [141]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1300 (0.1374)  loss_objectness: 0.0679 (0.0690)  loss_rpn_box_reg: 0.0630 (0.0684)  time: 0.6842  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [141]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1515 (0.1383)  loss_objectness: 0.0720 (0.0697)  loss_rpn_box_reg: 0.0695 (0.0686)  time: 0.6882  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [141]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1498 (0.1383)  loss_objectness: 0.0720 (0.0697)  loss_rpn_box_reg: 0.0653 (0.0686)  time: 0.6940  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [141]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1381 (0.1391)  loss_objectness: 0.0689 (0.0698)  loss_rpn_box_reg: 0.0687 (0.0693)  time: 0.6972  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [141]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1467 (0.1392)  loss_objectness: 0.0732 (0.0702)  loss_rpn_box_reg: 0.0635 (0.0690)  time: 0.6827  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [141]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1420 (0.1393)  loss_objectness: 0.0732 (0.0700)  loss_rpn_box_reg: 0.0582 (0.0692)  time: 0.6857  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [141]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1253 (0.1396)  loss_objectness: 0.0666 (0.0702)  loss_rpn_box_reg: 0.0612 (0.0694)  time: 0.6895  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [141] Total time: 0:02:51 (0.6877 s / it)\n",
      "Testing Epoch: [141]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1407 (0.1407)  loss_objectness: 0.0501 (0.0501)  loss_rpn_box_reg: 0.0906 (0.0906)  time: 0.6041  data: 0.2781  max mem: 5923\n",
      "Testing Epoch: [141]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1326 (0.1423)  loss_objectness: 0.0542 (0.0608)  loss_rpn_box_reg: 0.0784 (0.0815)  time: 0.6315  data: 0.3065  max mem: 5923\n",
      "Testing Epoch: [141] Total time: 0:00:39 (0.6342 s / it)\n",
      "Training Epoch: [142]  [  0/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1451 (0.1451)  loss_objectness: 0.0809 (0.0809)  loss_rpn_box_reg: 0.0642 (0.0642)  time: 0.6091  data: 0.2871  max mem: 5923\n",
      "Training Epoch: [142]  [ 10/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1426 (0.1397)  loss_objectness: 0.0737 (0.0717)  loss_rpn_box_reg: 0.0644 (0.0680)  time: 0.6891  data: 0.2898  max mem: 5923\n",
      "Training Epoch: [142]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1282 (0.1367)  loss_objectness: 0.0737 (0.0714)  loss_rpn_box_reg: 0.0644 (0.0652)  time: 0.6835  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [142]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1390 (0.1412)  loss_objectness: 0.0684 (0.0700)  loss_rpn_box_reg: 0.0702 (0.0712)  time: 0.6809  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [142]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1557 (0.1428)  loss_objectness: 0.0629 (0.0681)  loss_rpn_box_reg: 0.0805 (0.0747)  time: 0.6882  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [142]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1302 (0.1395)  loss_objectness: 0.0682 (0.0689)  loss_rpn_box_reg: 0.0567 (0.0705)  time: 0.6806  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [142]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1262 (0.1389)  loss_objectness: 0.0690 (0.0687)  loss_rpn_box_reg: 0.0525 (0.0701)  time: 0.6707  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [142]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1295 (0.1364)  loss_objectness: 0.0595 (0.0677)  loss_rpn_box_reg: 0.0638 (0.0687)  time: 0.6763  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [142]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1299 (0.1366)  loss_objectness: 0.0595 (0.0683)  loss_rpn_box_reg: 0.0526 (0.0684)  time: 0.6923  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [142]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1340 (0.1364)  loss_objectness: 0.0697 (0.0682)  loss_rpn_box_reg: 0.0667 (0.0682)  time: 0.6995  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [142]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1340 (0.1361)  loss_objectness: 0.0678 (0.0681)  loss_rpn_box_reg: 0.0673 (0.0680)  time: 0.6844  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [142]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1315 (0.1360)  loss_objectness: 0.0673 (0.0685)  loss_rpn_box_reg: 0.0596 (0.0675)  time: 0.6778  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [142]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1397 (0.1372)  loss_objectness: 0.0667 (0.0687)  loss_rpn_box_reg: 0.0607 (0.0685)  time: 0.6970  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [142]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1450 (0.1373)  loss_objectness: 0.0691 (0.0687)  loss_rpn_box_reg: 0.0707 (0.0686)  time: 0.6908  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [142]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1370 (0.1371)  loss_objectness: 0.0705 (0.0690)  loss_rpn_box_reg: 0.0656 (0.0681)  time: 0.6738  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [142]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1370 (0.1378)  loss_objectness: 0.0696 (0.0689)  loss_rpn_box_reg: 0.0651 (0.0688)  time: 0.6901  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [142]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1393 (0.1383)  loss_objectness: 0.0696 (0.0693)  loss_rpn_box_reg: 0.0645 (0.0690)  time: 0.6924  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [142]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1413 (0.1390)  loss_objectness: 0.0712 (0.0702)  loss_rpn_box_reg: 0.0620 (0.0688)  time: 0.6810  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [142]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1464 (0.1394)  loss_objectness: 0.0697 (0.0705)  loss_rpn_box_reg: 0.0593 (0.0689)  time: 0.6826  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [142]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1407 (0.1399)  loss_objectness: 0.0694 (0.0708)  loss_rpn_box_reg: 0.0703 (0.0691)  time: 0.6844  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [142]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1411 (0.1408)  loss_objectness: 0.0756 (0.0714)  loss_rpn_box_reg: 0.0651 (0.0694)  time: 0.7049  data: 0.2974  max mem: 5923\n",
      "Training Epoch: [142]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1522 (0.1408)  loss_objectness: 0.0797 (0.0716)  loss_rpn_box_reg: 0.0609 (0.0693)  time: 0.7081  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [142]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1346 (0.1409)  loss_objectness: 0.0709 (0.0713)  loss_rpn_box_reg: 0.0642 (0.0695)  time: 0.6867  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [142]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1315 (0.1405)  loss_objectness: 0.0649 (0.0710)  loss_rpn_box_reg: 0.0602 (0.0695)  time: 0.6895  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [142]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1315 (0.1402)  loss_objectness: 0.0645 (0.0709)  loss_rpn_box_reg: 0.0667 (0.0693)  time: 0.6990  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [142]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1494 (0.1409)  loss_objectness: 0.0678 (0.0713)  loss_rpn_box_reg: 0.0672 (0.0696)  time: 0.6956  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [142] Total time: 0:02:51 (0.6879 s / it)\n",
      "Testing Epoch: [142]  [ 0/62]  eta: 0:00:45  lr: 0.000300  loss: 0.1404 (0.1404)  loss_objectness: 0.0519 (0.0519)  loss_rpn_box_reg: 0.0886 (0.0886)  time: 0.7312  data: 0.3981  max mem: 5923\n",
      "Testing Epoch: [142]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1343 (0.1424)  loss_objectness: 0.0602 (0.0619)  loss_rpn_box_reg: 0.0762 (0.0805)  time: 0.6299  data: 0.3088  max mem: 5923\n",
      "Testing Epoch: [142] Total time: 0:00:39 (0.6371 s / it)\n",
      "Training Epoch: [143]  [  0/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1854 (0.1854)  loss_objectness: 0.1114 (0.1114)  loss_rpn_box_reg: 0.0740 (0.0740)  time: 0.5991  data: 0.3131  max mem: 5923\n",
      "Training Epoch: [143]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1317 (0.1416)  loss_objectness: 0.0785 (0.0800)  loss_rpn_box_reg: 0.0640 (0.0616)  time: 0.6799  data: 0.2970  max mem: 5923\n",
      "Training Epoch: [143]  [ 20/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1291 (0.1350)  loss_objectness: 0.0698 (0.0751)  loss_rpn_box_reg: 0.0580 (0.0599)  time: 0.6737  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [143]  [ 30/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1258 (0.1395)  loss_objectness: 0.0694 (0.0747)  loss_rpn_box_reg: 0.0591 (0.0647)  time: 0.6735  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [143]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1259 (0.1389)  loss_objectness: 0.0640 (0.0735)  loss_rpn_box_reg: 0.0671 (0.0654)  time: 0.6845  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [143]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1365 (0.1397)  loss_objectness: 0.0638 (0.0714)  loss_rpn_box_reg: 0.0704 (0.0682)  time: 0.6846  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [143]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1377 (0.1390)  loss_objectness: 0.0605 (0.0709)  loss_rpn_box_reg: 0.0655 (0.0682)  time: 0.6871  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [143]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1273 (0.1366)  loss_objectness: 0.0630 (0.0698)  loss_rpn_box_reg: 0.0577 (0.0667)  time: 0.6988  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [143]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1237 (0.1376)  loss_objectness: 0.0648 (0.0696)  loss_rpn_box_reg: 0.0571 (0.0680)  time: 0.7100  data: 0.2963  max mem: 5923\n",
      "Training Epoch: [143]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1263 (0.1364)  loss_objectness: 0.0632 (0.0691)  loss_rpn_box_reg: 0.0631 (0.0673)  time: 0.7002  data: 0.2981  max mem: 5923\n",
      "Training Epoch: [143]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1310 (0.1365)  loss_objectness: 0.0619 (0.0686)  loss_rpn_box_reg: 0.0640 (0.0679)  time: 0.6863  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [143]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1373 (0.1375)  loss_objectness: 0.0677 (0.0687)  loss_rpn_box_reg: 0.0753 (0.0688)  time: 0.6900  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [143]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1401 (0.1379)  loss_objectness: 0.0730 (0.0690)  loss_rpn_box_reg: 0.0682 (0.0689)  time: 0.6953  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [143]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1280 (0.1372)  loss_objectness: 0.0657 (0.0684)  loss_rpn_box_reg: 0.0603 (0.0687)  time: 0.6832  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [143]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1369 (0.1380)  loss_objectness: 0.0661 (0.0691)  loss_rpn_box_reg: 0.0660 (0.0689)  time: 0.6703  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [143]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1387 (0.1377)  loss_objectness: 0.0691 (0.0691)  loss_rpn_box_reg: 0.0597 (0.0686)  time: 0.6683  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [143]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1387 (0.1378)  loss_objectness: 0.0719 (0.0692)  loss_rpn_box_reg: 0.0588 (0.0686)  time: 0.6704  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [143]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1371 (0.1378)  loss_objectness: 0.0732 (0.0695)  loss_rpn_box_reg: 0.0627 (0.0683)  time: 0.6747  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [143]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1371 (0.1380)  loss_objectness: 0.0677 (0.0693)  loss_rpn_box_reg: 0.0682 (0.0687)  time: 0.6823  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [143]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1510 (0.1393)  loss_objectness: 0.0755 (0.0700)  loss_rpn_box_reg: 0.0776 (0.0692)  time: 0.6835  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [143]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1335 (0.1380)  loss_objectness: 0.0688 (0.0694)  loss_rpn_box_reg: 0.0554 (0.0686)  time: 0.6842  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [143]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1157 (0.1379)  loss_objectness: 0.0600 (0.0695)  loss_rpn_box_reg: 0.0556 (0.0684)  time: 0.6799  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [143]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1408 (0.1381)  loss_objectness: 0.0676 (0.0694)  loss_rpn_box_reg: 0.0680 (0.0686)  time: 0.6771  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [143]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1408 (0.1385)  loss_objectness: 0.0687 (0.0696)  loss_rpn_box_reg: 0.0694 (0.0690)  time: 0.6941  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [143]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1464 (0.1390)  loss_objectness: 0.0692 (0.0698)  loss_rpn_box_reg: 0.0687 (0.0692)  time: 0.6884  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [143]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1414 (0.1387)  loss_objectness: 0.0695 (0.0697)  loss_rpn_box_reg: 0.0618 (0.0690)  time: 0.6726  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [143] Total time: 0:02:50 (0.6836 s / it)\n",
      "Testing Epoch: [143]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1410 (0.1410)  loss_objectness: 0.0492 (0.0492)  loss_rpn_box_reg: 0.0918 (0.0918)  time: 0.6031  data: 0.2751  max mem: 5923\n",
      "Testing Epoch: [143]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1302 (0.1439)  loss_objectness: 0.0567 (0.0640)  loss_rpn_box_reg: 0.0730 (0.0799)  time: 0.6263  data: 0.3084  max mem: 5923\n",
      "Testing Epoch: [143] Total time: 0:00:39 (0.6313 s / it)\n",
      "Training Epoch: [144]  [  0/250]  eta: 0:03:02  lr: 0.000300  loss: 0.1235 (0.1235)  loss_objectness: 0.0656 (0.0656)  loss_rpn_box_reg: 0.0579 (0.0579)  time: 0.7282  data: 0.3181  max mem: 5923\n",
      "Training Epoch: [144]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1340 (0.1389)  loss_objectness: 0.0683 (0.0744)  loss_rpn_box_reg: 0.0579 (0.0645)  time: 0.6849  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [144]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1340 (0.1367)  loss_objectness: 0.0690 (0.0721)  loss_rpn_box_reg: 0.0601 (0.0647)  time: 0.6918  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [144]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1415 (0.1389)  loss_objectness: 0.0655 (0.0704)  loss_rpn_box_reg: 0.0606 (0.0685)  time: 0.6867  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [144]  [ 40/250]  eta: 0:02:26  lr: 0.000300  loss: 0.1345 (0.1395)  loss_objectness: 0.0651 (0.0705)  loss_rpn_box_reg: 0.0676 (0.0690)  time: 0.6975  data: 0.3074  max mem: 5923\n",
      "Training Epoch: [144]  [ 50/250]  eta: 0:02:21  lr: 0.000300  loss: 0.1296 (0.1387)  loss_objectness: 0.0667 (0.0704)  loss_rpn_box_reg: 0.0618 (0.0683)  time: 0.7371  data: 0.3354  max mem: 5923\n",
      "Training Epoch: [144]  [ 60/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1190 (0.1364)  loss_objectness: 0.0689 (0.0698)  loss_rpn_box_reg: 0.0539 (0.0666)  time: 0.7456  data: 0.3393  max mem: 5923\n",
      "Training Epoch: [144]  [ 70/250]  eta: 0:02:08  lr: 0.000300  loss: 0.1262 (0.1376)  loss_objectness: 0.0689 (0.0706)  loss_rpn_box_reg: 0.0618 (0.0670)  time: 0.7328  data: 0.3250  max mem: 5923\n",
      "Training Epoch: [144]  [ 80/250]  eta: 0:02:01  lr: 0.000300  loss: 0.1354 (0.1384)  loss_objectness: 0.0791 (0.0710)  loss_rpn_box_reg: 0.0635 (0.0674)  time: 0.7222  data: 0.3247  max mem: 5923\n",
      "Training Epoch: [144]  [ 90/250]  eta: 0:01:54  lr: 0.000300  loss: 0.1392 (0.1381)  loss_objectness: 0.0793 (0.0715)  loss_rpn_box_reg: 0.0534 (0.0665)  time: 0.7278  data: 0.3379  max mem: 5923\n",
      "Training Epoch: [144]  [100/250]  eta: 0:01:47  lr: 0.000300  loss: 0.1392 (0.1377)  loss_objectness: 0.0736 (0.0718)  loss_rpn_box_reg: 0.0577 (0.0659)  time: 0.7250  data: 0.3312  max mem: 5923\n",
      "Training Epoch: [144]  [110/250]  eta: 0:01:40  lr: 0.000300  loss: 0.1311 (0.1370)  loss_objectness: 0.0736 (0.0719)  loss_rpn_box_reg: 0.0569 (0.0651)  time: 0.7095  data: 0.3085  max mem: 5923\n",
      "Training Epoch: [144]  [120/250]  eta: 0:01:32  lr: 0.000300  loss: 0.1311 (0.1376)  loss_objectness: 0.0721 (0.0718)  loss_rpn_box_reg: 0.0581 (0.0658)  time: 0.6987  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [144]  [130/250]  eta: 0:01:25  lr: 0.000300  loss: 0.1450 (0.1384)  loss_objectness: 0.0729 (0.0717)  loss_rpn_box_reg: 0.0811 (0.0668)  time: 0.6882  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [144]  [140/250]  eta: 0:01:18  lr: 0.000300  loss: 0.1450 (0.1389)  loss_objectness: 0.0747 (0.0717)  loss_rpn_box_reg: 0.0804 (0.0672)  time: 0.7016  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [144]  [150/250]  eta: 0:01:10  lr: 0.000300  loss: 0.1443 (0.1398)  loss_objectness: 0.0768 (0.0724)  loss_rpn_box_reg: 0.0691 (0.0674)  time: 0.7015  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [144]  [160/250]  eta: 0:01:03  lr: 0.000300  loss: 0.1368 (0.1396)  loss_objectness: 0.0768 (0.0722)  loss_rpn_box_reg: 0.0564 (0.0674)  time: 0.6795  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [144]  [170/250]  eta: 0:00:56  lr: 0.000300  loss: 0.1368 (0.1403)  loss_objectness: 0.0661 (0.0722)  loss_rpn_box_reg: 0.0660 (0.0681)  time: 0.6817  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [144]  [180/250]  eta: 0:00:49  lr: 0.000300  loss: 0.1469 (0.1406)  loss_objectness: 0.0655 (0.0720)  loss_rpn_box_reg: 0.0744 (0.0685)  time: 0.6819  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [144]  [190/250]  eta: 0:00:42  lr: 0.000300  loss: 0.1279 (0.1396)  loss_objectness: 0.0639 (0.0716)  loss_rpn_box_reg: 0.0579 (0.0681)  time: 0.6643  data: 0.2883  max mem: 5923\n",
      "Training Epoch: [144]  [200/250]  eta: 0:00:35  lr: 0.000300  loss: 0.1346 (0.1400)  loss_objectness: 0.0695 (0.0716)  loss_rpn_box_reg: 0.0591 (0.0684)  time: 0.6722  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [144]  [210/250]  eta: 0:00:28  lr: 0.000300  loss: 0.1380 (0.1400)  loss_objectness: 0.0727 (0.0715)  loss_rpn_box_reg: 0.0724 (0.0685)  time: 0.6968  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [144]  [220/250]  eta: 0:00:21  lr: 0.000300  loss: 0.1405 (0.1405)  loss_objectness: 0.0707 (0.0716)  loss_rpn_box_reg: 0.0724 (0.0689)  time: 0.6993  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [144]  [230/250]  eta: 0:00:14  lr: 0.000300  loss: 0.1471 (0.1409)  loss_objectness: 0.0779 (0.0721)  loss_rpn_box_reg: 0.0677 (0.0688)  time: 0.6884  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [144]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1372 (0.1410)  loss_objectness: 0.0751 (0.0721)  loss_rpn_box_reg: 0.0653 (0.0689)  time: 0.6694  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [144]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1444 (0.1416)  loss_objectness: 0.0751 (0.0721)  loss_rpn_box_reg: 0.0758 (0.0696)  time: 0.6779  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [144] Total time: 0:02:54 (0.6991 s / it)\n",
      "Testing Epoch: [144]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1322 (0.1322)  loss_objectness: 0.0458 (0.0458)  loss_rpn_box_reg: 0.0864 (0.0864)  time: 0.6221  data: 0.3001  max mem: 5923\n",
      "Testing Epoch: [144]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1271 (0.1393)  loss_objectness: 0.0586 (0.0602)  loss_rpn_box_reg: 0.0683 (0.0792)  time: 0.6329  data: 0.3098  max mem: 5923\n",
      "Testing Epoch: [144] Total time: 0:00:39 (0.6337 s / it)\n",
      "Training Epoch: [145]  [  0/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1142 (0.1142)  loss_objectness: 0.0472 (0.0472)  loss_rpn_box_reg: 0.0671 (0.0671)  time: 0.6692  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [145]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1368 (0.1468)  loss_objectness: 0.0705 (0.0689)  loss_rpn_box_reg: 0.0691 (0.0779)  time: 0.6932  data: 0.2975  max mem: 5923\n",
      "Training Epoch: [145]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1297 (0.1366)  loss_objectness: 0.0663 (0.0650)  loss_rpn_box_reg: 0.0661 (0.0716)  time: 0.6856  data: 0.2962  max mem: 5923\n",
      "Training Epoch: [145]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1297 (0.1421)  loss_objectness: 0.0721 (0.0699)  loss_rpn_box_reg: 0.0585 (0.0722)  time: 0.6737  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [145]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1425 (0.1389)  loss_objectness: 0.0733 (0.0691)  loss_rpn_box_reg: 0.0635 (0.0698)  time: 0.6762  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [145]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1294 (0.1374)  loss_objectness: 0.0694 (0.0688)  loss_rpn_box_reg: 0.0602 (0.0686)  time: 0.6924  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [145]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1294 (0.1381)  loss_objectness: 0.0697 (0.0687)  loss_rpn_box_reg: 0.0653 (0.0694)  time: 0.6862  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [145]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1312 (0.1366)  loss_objectness: 0.0662 (0.0683)  loss_rpn_box_reg: 0.0659 (0.0683)  time: 0.6665  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [145]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1332 (0.1383)  loss_objectness: 0.0725 (0.0699)  loss_rpn_box_reg: 0.0636 (0.0684)  time: 0.6754  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [145]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1332 (0.1376)  loss_objectness: 0.0715 (0.0698)  loss_rpn_box_reg: 0.0636 (0.0678)  time: 0.6883  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [145]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1262 (0.1377)  loss_objectness: 0.0654 (0.0695)  loss_rpn_box_reg: 0.0562 (0.0682)  time: 0.6900  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [145]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1314 (0.1369)  loss_objectness: 0.0654 (0.0692)  loss_rpn_box_reg: 0.0648 (0.0677)  time: 0.6933  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [145]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1287 (0.1371)  loss_objectness: 0.0633 (0.0688)  loss_rpn_box_reg: 0.0693 (0.0682)  time: 0.6791  data: 0.2875  max mem: 5923\n",
      "Training Epoch: [145]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1395 (0.1380)  loss_objectness: 0.0683 (0.0693)  loss_rpn_box_reg: 0.0693 (0.0686)  time: 0.6634  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [145]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1395 (0.1379)  loss_objectness: 0.0702 (0.0692)  loss_rpn_box_reg: 0.0670 (0.0687)  time: 0.6770  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [145]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1357 (0.1379)  loss_objectness: 0.0666 (0.0693)  loss_rpn_box_reg: 0.0655 (0.0686)  time: 0.6945  data: 0.2894  max mem: 5923\n",
      "Training Epoch: [145]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1360 (0.1381)  loss_objectness: 0.0666 (0.0694)  loss_rpn_box_reg: 0.0653 (0.0687)  time: 0.6778  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [145]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1552 (0.1393)  loss_objectness: 0.0693 (0.0696)  loss_rpn_box_reg: 0.0719 (0.0697)  time: 0.6713  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [145]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1539 (0.1396)  loss_objectness: 0.0726 (0.0696)  loss_rpn_box_reg: 0.0763 (0.0700)  time: 0.6962  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [145]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1415 (0.1397)  loss_objectness: 0.0746 (0.0696)  loss_rpn_box_reg: 0.0631 (0.0700)  time: 0.7009  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [145]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1328 (0.1399)  loss_objectness: 0.0698 (0.0697)  loss_rpn_box_reg: 0.0630 (0.0701)  time: 0.6977  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [145]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1348 (0.1403)  loss_objectness: 0.0714 (0.0699)  loss_rpn_box_reg: 0.0707 (0.0703)  time: 0.7001  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [145]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1461 (0.1402)  loss_objectness: 0.0736 (0.0703)  loss_rpn_box_reg: 0.0697 (0.0699)  time: 0.6917  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [145]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1399 (0.1407)  loss_objectness: 0.0762 (0.0707)  loss_rpn_box_reg: 0.0649 (0.0700)  time: 0.6711  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [145]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1399 (0.1407)  loss_objectness: 0.0763 (0.0709)  loss_rpn_box_reg: 0.0632 (0.0698)  time: 0.6775  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [145]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1331 (0.1409)  loss_objectness: 0.0745 (0.0710)  loss_rpn_box_reg: 0.0632 (0.0699)  time: 0.6833  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [145] Total time: 0:02:50 (0.6838 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:09  model_time: 0.7562 (0.7562)  evaluator_time: 0.0610 (0.0610)  time: 1.1193  data: 0.2861  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.4051 (0.4017)  evaluator_time: 0.0700 (0.0807)  time: 0.7932  data: 0.3171  max mem: 5923\n",
      "Test: Total time: 0:00:49 (0.7954 s / it)\n",
      "Averaged stats: model_time: 0.4051 (0.4017)  evaluator_time: 0.0700 (0.0807)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.11s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.115\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.184\n",
      "Testing Epoch: [145]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1312 (0.1312)  loss_objectness: 0.0418 (0.0418)  loss_rpn_box_reg: 0.0894 (0.0894)  time: 0.6291  data: 0.3041  max mem: 5923\n",
      "Testing Epoch: [145]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1300 (0.1388)  loss_objectness: 0.0542 (0.0578)  loss_rpn_box_reg: 0.0758 (0.0810)  time: 0.6391  data: 0.3165  max mem: 5923\n",
      "Testing Epoch: [145] Total time: 0:00:39 (0.6369 s / it)\n",
      "Training Epoch: [146]  [  0/250]  eta: 0:02:56  lr: 0.000300  loss: 0.1480 (0.1480)  loss_objectness: 0.0716 (0.0716)  loss_rpn_box_reg: 0.0764 (0.0764)  time: 0.7042  data: 0.3051  max mem: 5923\n",
      "Training Epoch: [146]  [ 10/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1429 (0.1423)  loss_objectness: 0.0712 (0.0707)  loss_rpn_box_reg: 0.0710 (0.0716)  time: 0.6785  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [146]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1332 (0.1369)  loss_objectness: 0.0721 (0.0721)  loss_rpn_box_reg: 0.0589 (0.0648)  time: 0.6787  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [146]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1257 (0.1360)  loss_objectness: 0.0718 (0.0700)  loss_rpn_box_reg: 0.0586 (0.0660)  time: 0.6901  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [146]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1356 (0.1394)  loss_objectness: 0.0710 (0.0710)  loss_rpn_box_reg: 0.0656 (0.0684)  time: 0.6915  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [146]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1434 (0.1409)  loss_objectness: 0.0710 (0.0704)  loss_rpn_box_reg: 0.0759 (0.0705)  time: 0.6943  data: 0.2898  max mem: 5923\n",
      "Training Epoch: [146]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1417 (0.1399)  loss_objectness: 0.0627 (0.0699)  loss_rpn_box_reg: 0.0728 (0.0700)  time: 0.6927  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [146]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1317 (0.1413)  loss_objectness: 0.0693 (0.0706)  loss_rpn_box_reg: 0.0608 (0.0706)  time: 0.6775  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [146]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1406 (0.1417)  loss_objectness: 0.0726 (0.0706)  loss_rpn_box_reg: 0.0644 (0.0711)  time: 0.6754  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [146]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1521 (0.1413)  loss_objectness: 0.0748 (0.0712)  loss_rpn_box_reg: 0.0627 (0.0701)  time: 0.6772  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [146]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1500 (0.1418)  loss_objectness: 0.0748 (0.0716)  loss_rpn_box_reg: 0.0645 (0.0703)  time: 0.6837  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [146]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1271 (0.1417)  loss_objectness: 0.0676 (0.0717)  loss_rpn_box_reg: 0.0652 (0.0700)  time: 0.6961  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [146]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1336 (0.1412)  loss_objectness: 0.0664 (0.0718)  loss_rpn_box_reg: 0.0618 (0.0694)  time: 0.6897  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [146]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1369 (0.1418)  loss_objectness: 0.0664 (0.0717)  loss_rpn_box_reg: 0.0698 (0.0702)  time: 0.6685  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [146]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1438 (0.1417)  loss_objectness: 0.0679 (0.0714)  loss_rpn_box_reg: 0.0722 (0.0703)  time: 0.6616  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [146]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1438 (0.1419)  loss_objectness: 0.0684 (0.0716)  loss_rpn_box_reg: 0.0660 (0.0704)  time: 0.6891  data: 0.2977  max mem: 5923\n",
      "Training Epoch: [146]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1470 (0.1432)  loss_objectness: 0.0734 (0.0724)  loss_rpn_box_reg: 0.0687 (0.0708)  time: 0.7022  data: 0.2979  max mem: 5923\n",
      "Training Epoch: [146]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1495 (0.1433)  loss_objectness: 0.0736 (0.0724)  loss_rpn_box_reg: 0.0687 (0.0709)  time: 0.6927  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [146]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1395 (0.1434)  loss_objectness: 0.0736 (0.0721)  loss_rpn_box_reg: 0.0657 (0.0713)  time: 0.6867  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [146]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1364 (0.1432)  loss_objectness: 0.0722 (0.0722)  loss_rpn_box_reg: 0.0657 (0.0710)  time: 0.6817  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [146]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1236 (0.1422)  loss_objectness: 0.0674 (0.0718)  loss_rpn_box_reg: 0.0608 (0.0703)  time: 0.6872  data: 0.2987  max mem: 5923\n",
      "Training Epoch: [146]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1189 (0.1417)  loss_objectness: 0.0593 (0.0713)  loss_rpn_box_reg: 0.0619 (0.0704)  time: 0.6889  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [146]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1293 (0.1414)  loss_objectness: 0.0627 (0.0714)  loss_rpn_box_reg: 0.0581 (0.0700)  time: 0.6807  data: 0.2865  max mem: 5923\n",
      "Training Epoch: [146]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1347 (0.1413)  loss_objectness: 0.0771 (0.0717)  loss_rpn_box_reg: 0.0530 (0.0696)  time: 0.6896  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [146]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1356 (0.1409)  loss_objectness: 0.0719 (0.0717)  loss_rpn_box_reg: 0.0510 (0.0693)  time: 0.6861  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [146]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1281 (0.1407)  loss_objectness: 0.0684 (0.0715)  loss_rpn_box_reg: 0.0583 (0.0692)  time: 0.6741  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [146] Total time: 0:02:51 (0.6848 s / it)\n",
      "Testing Epoch: [146]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1341 (0.1341)  loss_objectness: 0.0427 (0.0427)  loss_rpn_box_reg: 0.0913 (0.0913)  time: 0.6231  data: 0.3021  max mem: 5923\n",
      "Testing Epoch: [146]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1261 (0.1360)  loss_objectness: 0.0513 (0.0567)  loss_rpn_box_reg: 0.0687 (0.0793)  time: 0.6237  data: 0.3025  max mem: 5923\n",
      "Testing Epoch: [146] Total time: 0:00:39 (0.6326 s / it)\n",
      "Training Epoch: [147]  [  0/250]  eta: 0:03:20  lr: 0.000300  loss: 0.1241 (0.1241)  loss_objectness: 0.0805 (0.0805)  loss_rpn_box_reg: 0.0436 (0.0436)  time: 0.8032  data: 0.2981  max mem: 5923\n",
      "Training Epoch: [147]  [ 10/250]  eta: 0:02:50  lr: 0.000300  loss: 0.1281 (0.1389)  loss_objectness: 0.0730 (0.0736)  loss_rpn_box_reg: 0.0604 (0.0653)  time: 0.7092  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [147]  [ 20/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1377 (0.1430)  loss_objectness: 0.0730 (0.0729)  loss_rpn_box_reg: 0.0670 (0.0701)  time: 0.6952  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [147]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1461 (0.1391)  loss_objectness: 0.0685 (0.0694)  loss_rpn_box_reg: 0.0711 (0.0697)  time: 0.6757  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [147]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1496 (0.1420)  loss_objectness: 0.0652 (0.0694)  loss_rpn_box_reg: 0.0763 (0.0726)  time: 0.6713  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [147]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1405 (0.1403)  loss_objectness: 0.0669 (0.0694)  loss_rpn_box_reg: 0.0678 (0.0709)  time: 0.6839  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [147]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1381 (0.1424)  loss_objectness: 0.0669 (0.0695)  loss_rpn_box_reg: 0.0633 (0.0729)  time: 0.6802  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [147]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1381 (0.1415)  loss_objectness: 0.0646 (0.0695)  loss_rpn_box_reg: 0.0681 (0.0720)  time: 0.6624  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [147]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1257 (0.1411)  loss_objectness: 0.0611 (0.0688)  loss_rpn_box_reg: 0.0677 (0.0723)  time: 0.6623  data: 0.2878  max mem: 5923\n",
      "Training Epoch: [147]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1329 (0.1403)  loss_objectness: 0.0611 (0.0682)  loss_rpn_box_reg: 0.0647 (0.0722)  time: 0.6828  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [147]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1295 (0.1397)  loss_objectness: 0.0618 (0.0684)  loss_rpn_box_reg: 0.0647 (0.0713)  time: 0.6796  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [147]  [110/250]  eta: 0:01:34  lr: 0.000300  loss: 0.1222 (0.1378)  loss_objectness: 0.0601 (0.0675)  loss_rpn_box_reg: 0.0604 (0.0704)  time: 0.6677  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [147]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1208 (0.1372)  loss_objectness: 0.0570 (0.0672)  loss_rpn_box_reg: 0.0614 (0.0700)  time: 0.6767  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [147]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1254 (0.1365)  loss_objectness: 0.0624 (0.0670)  loss_rpn_box_reg: 0.0627 (0.0694)  time: 0.6856  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [147]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1244 (0.1362)  loss_objectness: 0.0704 (0.0672)  loss_rpn_box_reg: 0.0588 (0.0690)  time: 0.6852  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [147]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1343 (0.1362)  loss_objectness: 0.0732 (0.0677)  loss_rpn_box_reg: 0.0567 (0.0685)  time: 0.6899  data: 0.2889  max mem: 5923\n",
      "Training Epoch: [147]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1405 (0.1369)  loss_objectness: 0.0732 (0.0685)  loss_rpn_box_reg: 0.0602 (0.0684)  time: 0.6894  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [147]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1423 (0.1372)  loss_objectness: 0.0711 (0.0684)  loss_rpn_box_reg: 0.0690 (0.0688)  time: 0.6838  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [147]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1378 (0.1377)  loss_objectness: 0.0658 (0.0688)  loss_rpn_box_reg: 0.0594 (0.0690)  time: 0.6779  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [147]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1332 (0.1376)  loss_objectness: 0.0720 (0.0690)  loss_rpn_box_reg: 0.0594 (0.0686)  time: 0.6788  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [147]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1381 (0.1384)  loss_objectness: 0.0720 (0.0697)  loss_rpn_box_reg: 0.0630 (0.0688)  time: 0.6934  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [147]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1538 (0.1389)  loss_objectness: 0.0715 (0.0695)  loss_rpn_box_reg: 0.0765 (0.0694)  time: 0.6941  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [147]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1548 (0.1392)  loss_objectness: 0.0698 (0.0697)  loss_rpn_box_reg: 0.0823 (0.0695)  time: 0.6911  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [147]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1531 (0.1389)  loss_objectness: 0.0698 (0.0697)  loss_rpn_box_reg: 0.0669 (0.0692)  time: 0.6839  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [147]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1349 (0.1392)  loss_objectness: 0.0758 (0.0700)  loss_rpn_box_reg: 0.0646 (0.0692)  time: 0.6752  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [147]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1432 (0.1395)  loss_objectness: 0.0720 (0.0700)  loss_rpn_box_reg: 0.0730 (0.0695)  time: 0.6798  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [147] Total time: 0:02:50 (0.6821 s / it)\n",
      "Testing Epoch: [147]  [ 0/62]  eta: 0:00:43  lr: 0.000300  loss: 0.1352 (0.1352)  loss_objectness: 0.0460 (0.0460)  loss_rpn_box_reg: 0.0892 (0.0892)  time: 0.7092  data: 0.3811  max mem: 5923\n",
      "Testing Epoch: [147]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1299 (0.1402)  loss_objectness: 0.0546 (0.0591)  loss_rpn_box_reg: 0.0750 (0.0811)  time: 0.6299  data: 0.3109  max mem: 5923\n",
      "Testing Epoch: [147] Total time: 0:00:39 (0.6326 s / it)\n",
      "Training Epoch: [148]  [  0/250]  eta: 0:03:03  lr: 0.000300  loss: 0.1671 (0.1671)  loss_objectness: 0.0596 (0.0596)  loss_rpn_box_reg: 0.1075 (0.1075)  time: 0.7332  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [148]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1475 (0.1560)  loss_objectness: 0.0792 (0.0796)  loss_rpn_box_reg: 0.0725 (0.0764)  time: 0.6976  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [148]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1434 (0.1448)  loss_objectness: 0.0742 (0.0735)  loss_rpn_box_reg: 0.0692 (0.0713)  time: 0.6888  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [148]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1365 (0.1421)  loss_objectness: 0.0671 (0.0719)  loss_rpn_box_reg: 0.0665 (0.0702)  time: 0.6801  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [148]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1365 (0.1391)  loss_objectness: 0.0644 (0.0715)  loss_rpn_box_reg: 0.0663 (0.0676)  time: 0.6734  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [148]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1307 (0.1371)  loss_objectness: 0.0644 (0.0703)  loss_rpn_box_reg: 0.0610 (0.0668)  time: 0.6761  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [148]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1419 (0.1395)  loss_objectness: 0.0695 (0.0709)  loss_rpn_box_reg: 0.0727 (0.0686)  time: 0.6735  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [148]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1440 (0.1381)  loss_objectness: 0.0690 (0.0705)  loss_rpn_box_reg: 0.0728 (0.0677)  time: 0.6803  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [148]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1288 (0.1370)  loss_objectness: 0.0649 (0.0695)  loss_rpn_box_reg: 0.0645 (0.0675)  time: 0.7005  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [148]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1310 (0.1373)  loss_objectness: 0.0666 (0.0696)  loss_rpn_box_reg: 0.0663 (0.0677)  time: 0.6961  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [148]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1310 (0.1368)  loss_objectness: 0.0704 (0.0699)  loss_rpn_box_reg: 0.0602 (0.0669)  time: 0.6863  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [148]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1252 (0.1373)  loss_objectness: 0.0683 (0.0701)  loss_rpn_box_reg: 0.0496 (0.0672)  time: 0.6869  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [148]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1339 (0.1378)  loss_objectness: 0.0697 (0.0704)  loss_rpn_box_reg: 0.0709 (0.0675)  time: 0.6879  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [148]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1339 (0.1378)  loss_objectness: 0.0667 (0.0701)  loss_rpn_box_reg: 0.0672 (0.0678)  time: 0.6866  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [148]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1352 (0.1378)  loss_objectness: 0.0639 (0.0703)  loss_rpn_box_reg: 0.0662 (0.0676)  time: 0.6829  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [148]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1416 (0.1375)  loss_objectness: 0.0639 (0.0699)  loss_rpn_box_reg: 0.0677 (0.0676)  time: 0.6896  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [148]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1437 (0.1378)  loss_objectness: 0.0624 (0.0703)  loss_rpn_box_reg: 0.0656 (0.0675)  time: 0.6885  data: 0.2876  max mem: 5923\n",
      "Training Epoch: [148]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1364 (0.1379)  loss_objectness: 0.0669 (0.0705)  loss_rpn_box_reg: 0.0644 (0.0674)  time: 0.6804  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [148]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1512 (0.1383)  loss_objectness: 0.0697 (0.0707)  loss_rpn_box_reg: 0.0663 (0.0676)  time: 0.6865  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [148]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1504 (0.1385)  loss_objectness: 0.0688 (0.0705)  loss_rpn_box_reg: 0.0694 (0.0680)  time: 0.6882  data: 0.2878  max mem: 5923\n",
      "Training Epoch: [148]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1414 (0.1393)  loss_objectness: 0.0691 (0.0708)  loss_rpn_box_reg: 0.0715 (0.0686)  time: 0.6769  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [148]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1492 (0.1402)  loss_objectness: 0.0711 (0.0708)  loss_rpn_box_reg: 0.0745 (0.0694)  time: 0.6659  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [148]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1410 (0.1397)  loss_objectness: 0.0649 (0.0706)  loss_rpn_box_reg: 0.0614 (0.0690)  time: 0.6731  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [148]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1241 (0.1394)  loss_objectness: 0.0766 (0.0708)  loss_rpn_box_reg: 0.0593 (0.0686)  time: 0.6781  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [148]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1420 (0.1400)  loss_objectness: 0.0647 (0.0707)  loss_rpn_box_reg: 0.0718 (0.0693)  time: 0.6815  data: 0.2882  max mem: 5923\n",
      "Training Epoch: [148]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1567 (0.1405)  loss_objectness: 0.0642 (0.0710)  loss_rpn_box_reg: 0.0773 (0.0695)  time: 0.6929  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [148] Total time: 0:02:51 (0.6840 s / it)\n",
      "Testing Epoch: [148]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1369 (0.1369)  loss_objectness: 0.0460 (0.0460)  loss_rpn_box_reg: 0.0909 (0.0909)  time: 0.6201  data: 0.2951  max mem: 5923\n",
      "Testing Epoch: [148]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1305 (0.1426)  loss_objectness: 0.0586 (0.0604)  loss_rpn_box_reg: 0.0775 (0.0822)  time: 0.6299  data: 0.3077  max mem: 5923\n",
      "Testing Epoch: [148] Total time: 0:00:39 (0.6340 s / it)\n",
      "Training Epoch: [149]  [  0/250]  eta: 0:02:12  lr: 0.000300  loss: 0.1304 (0.1304)  loss_objectness: 0.0735 (0.0735)  loss_rpn_box_reg: 0.0569 (0.0569)  time: 0.5291  data: 0.2731  max mem: 5923\n",
      "Training Epoch: [149]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1304 (0.1372)  loss_objectness: 0.0681 (0.0731)  loss_rpn_box_reg: 0.0641 (0.0641)  time: 0.6813  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [149]  [ 20/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1246 (0.1336)  loss_objectness: 0.0595 (0.0699)  loss_rpn_box_reg: 0.0641 (0.0637)  time: 0.6835  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [149]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1283 (0.1378)  loss_objectness: 0.0667 (0.0711)  loss_rpn_box_reg: 0.0652 (0.0667)  time: 0.6855  data: 0.2967  max mem: 5923\n",
      "Training Epoch: [149]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1279 (0.1330)  loss_objectness: 0.0694 (0.0686)  loss_rpn_box_reg: 0.0559 (0.0644)  time: 0.6990  data: 0.2988  max mem: 5923\n",
      "Training Epoch: [149]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1193 (0.1317)  loss_objectness: 0.0683 (0.0690)  loss_rpn_box_reg: 0.0485 (0.0626)  time: 0.6811  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [149]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1204 (0.1302)  loss_objectness: 0.0645 (0.0685)  loss_rpn_box_reg: 0.0512 (0.0618)  time: 0.6746  data: 0.2898  max mem: 5923\n",
      "Training Epoch: [149]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1235 (0.1319)  loss_objectness: 0.0605 (0.0676)  loss_rpn_box_reg: 0.0596 (0.0643)  time: 0.6850  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [149]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1492 (0.1350)  loss_objectness: 0.0665 (0.0691)  loss_rpn_box_reg: 0.0666 (0.0659)  time: 0.6794  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [149]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1405 (0.1352)  loss_objectness: 0.0665 (0.0691)  loss_rpn_box_reg: 0.0699 (0.0661)  time: 0.6836  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [149]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1303 (0.1354)  loss_objectness: 0.0660 (0.0694)  loss_rpn_box_reg: 0.0620 (0.0660)  time: 0.6697  data: 0.2874  max mem: 5923\n",
      "Training Epoch: [149]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1295 (0.1354)  loss_objectness: 0.0666 (0.0698)  loss_rpn_box_reg: 0.0607 (0.0656)  time: 0.6597  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [149]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1400 (0.1356)  loss_objectness: 0.0680 (0.0697)  loss_rpn_box_reg: 0.0593 (0.0659)  time: 0.6729  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [149]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1333 (0.1358)  loss_objectness: 0.0656 (0.0698)  loss_rpn_box_reg: 0.0593 (0.0660)  time: 0.6786  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [149]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1320 (0.1363)  loss_objectness: 0.0652 (0.0698)  loss_rpn_box_reg: 0.0732 (0.0665)  time: 0.6835  data: 0.2979  max mem: 5923\n",
      "Training Epoch: [149]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1371 (0.1365)  loss_objectness: 0.0650 (0.0696)  loss_rpn_box_reg: 0.0741 (0.0669)  time: 0.6941  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [149]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1391 (0.1368)  loss_objectness: 0.0650 (0.0695)  loss_rpn_box_reg: 0.0694 (0.0673)  time: 0.7027  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [149]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1408 (0.1376)  loss_objectness: 0.0709 (0.0698)  loss_rpn_box_reg: 0.0679 (0.0678)  time: 0.6884  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [149]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1376 (0.1376)  loss_objectness: 0.0733 (0.0699)  loss_rpn_box_reg: 0.0659 (0.0677)  time: 0.6894  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [149]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1531 (0.1389)  loss_objectness: 0.0765 (0.0705)  loss_rpn_box_reg: 0.0693 (0.0684)  time: 0.6899  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [149]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1563 (0.1399)  loss_objectness: 0.0809 (0.0709)  loss_rpn_box_reg: 0.0722 (0.0690)  time: 0.6910  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [149]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1506 (0.1400)  loss_objectness: 0.0721 (0.0709)  loss_rpn_box_reg: 0.0741 (0.0691)  time: 0.6879  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [149]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1423 (0.1401)  loss_objectness: 0.0718 (0.0707)  loss_rpn_box_reg: 0.0689 (0.0694)  time: 0.6841  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [149]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1449 (0.1408)  loss_objectness: 0.0716 (0.0710)  loss_rpn_box_reg: 0.0686 (0.0698)  time: 0.6827  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [149]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1518 (0.1407)  loss_objectness: 0.0774 (0.0714)  loss_rpn_box_reg: 0.0659 (0.0693)  time: 0.6811  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [149]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1369 (0.1411)  loss_objectness: 0.0735 (0.0714)  loss_rpn_box_reg: 0.0646 (0.0698)  time: 0.6959  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [149] Total time: 0:02:51 (0.6842 s / it)\n",
      "Testing Epoch: [149]  [ 0/62]  eta: 0:00:48  lr: 0.000300  loss: 0.1363 (0.1363)  loss_objectness: 0.0474 (0.0474)  loss_rpn_box_reg: 0.0889 (0.0889)  time: 0.7892  data: 0.4221  max mem: 5923\n",
      "Testing Epoch: [149]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1348 (0.1398)  loss_objectness: 0.0591 (0.0599)  loss_rpn_box_reg: 0.0740 (0.0798)  time: 0.6251  data: 0.3058  max mem: 5923\n",
      "Testing Epoch: [149] Total time: 0:00:39 (0.6365 s / it)\n",
      "Training Epoch: [150]  [  0/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1521 (0.1521)  loss_objectness: 0.0759 (0.0759)  loss_rpn_box_reg: 0.0762 (0.0762)  time: 0.6521  data: 0.2821  max mem: 5923\n",
      "Training Epoch: [150]  [ 10/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1324 (0.1232)  loss_objectness: 0.0600 (0.0639)  loss_rpn_box_reg: 0.0541 (0.0594)  time: 0.6782  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [150]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1324 (0.1335)  loss_objectness: 0.0632 (0.0661)  loss_rpn_box_reg: 0.0659 (0.0674)  time: 0.6901  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [150]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1337 (0.1343)  loss_objectness: 0.0668 (0.0656)  loss_rpn_box_reg: 0.0692 (0.0687)  time: 0.6786  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [150]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1337 (0.1398)  loss_objectness: 0.0697 (0.0696)  loss_rpn_box_reg: 0.0695 (0.0701)  time: 0.6743  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [150]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1438 (0.1407)  loss_objectness: 0.0697 (0.0698)  loss_rpn_box_reg: 0.0675 (0.0709)  time: 0.6868  data: 0.2975  max mem: 5923\n",
      "Training Epoch: [150]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1404 (0.1405)  loss_objectness: 0.0599 (0.0690)  loss_rpn_box_reg: 0.0700 (0.0715)  time: 0.6883  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [150]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1402 (0.1384)  loss_objectness: 0.0658 (0.0684)  loss_rpn_box_reg: 0.0675 (0.0700)  time: 0.6875  data: 0.2849  max mem: 5923\n",
      "Training Epoch: [150]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1306 (0.1390)  loss_objectness: 0.0709 (0.0696)  loss_rpn_box_reg: 0.0567 (0.0695)  time: 0.6873  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [150]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1306 (0.1371)  loss_objectness: 0.0654 (0.0686)  loss_rpn_box_reg: 0.0567 (0.0685)  time: 0.6915  data: 0.2873  max mem: 5923\n",
      "Training Epoch: [150]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1281 (0.1377)  loss_objectness: 0.0641 (0.0696)  loss_rpn_box_reg: 0.0584 (0.0681)  time: 0.6872  data: 0.2872  max mem: 5923\n",
      "Training Epoch: [150]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1287 (0.1365)  loss_objectness: 0.0690 (0.0694)  loss_rpn_box_reg: 0.0557 (0.0672)  time: 0.6813  data: 0.2878  max mem: 5923\n",
      "Training Epoch: [150]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1287 (0.1368)  loss_objectness: 0.0686 (0.0693)  loss_rpn_box_reg: 0.0557 (0.0674)  time: 0.6816  data: 0.2878  max mem: 5923\n",
      "Training Epoch: [150]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1409 (0.1380)  loss_objectness: 0.0738 (0.0700)  loss_rpn_box_reg: 0.0614 (0.0680)  time: 0.6876  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [150]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1409 (0.1389)  loss_objectness: 0.0758 (0.0704)  loss_rpn_box_reg: 0.0624 (0.0685)  time: 0.6942  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [150]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1402 (0.1393)  loss_objectness: 0.0758 (0.0707)  loss_rpn_box_reg: 0.0624 (0.0686)  time: 0.6801  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [150]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1402 (0.1396)  loss_objectness: 0.0738 (0.0710)  loss_rpn_box_reg: 0.0617 (0.0686)  time: 0.6668  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [150]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1244 (0.1385)  loss_objectness: 0.0693 (0.0707)  loss_rpn_box_reg: 0.0543 (0.0678)  time: 0.6751  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [150]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1427 (0.1398)  loss_objectness: 0.0734 (0.0712)  loss_rpn_box_reg: 0.0578 (0.0686)  time: 0.6882  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [150]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1571 (0.1404)  loss_objectness: 0.0795 (0.0714)  loss_rpn_box_reg: 0.0739 (0.0690)  time: 0.6909  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [150]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1601 (0.1415)  loss_objectness: 0.0729 (0.0714)  loss_rpn_box_reg: 0.0825 (0.0701)  time: 0.6803  data: 0.2894  max mem: 5923\n",
      "Training Epoch: [150]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1544 (0.1418)  loss_objectness: 0.0702 (0.0718)  loss_rpn_box_reg: 0.0763 (0.0700)  time: 0.6848  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [150]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1469 (0.1421)  loss_objectness: 0.0681 (0.0718)  loss_rpn_box_reg: 0.0713 (0.0703)  time: 0.6905  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [150]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1279 (0.1416)  loss_objectness: 0.0640 (0.0717)  loss_rpn_box_reg: 0.0640 (0.0699)  time: 0.6771  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [150]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1320 (0.1418)  loss_objectness: 0.0642 (0.0719)  loss_rpn_box_reg: 0.0565 (0.0700)  time: 0.6658  data: 0.2894  max mem: 5923\n",
      "Training Epoch: [150]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1387 (0.1413)  loss_objectness: 0.0705 (0.0718)  loss_rpn_box_reg: 0.0542 (0.0695)  time: 0.6691  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [150] Total time: 0:02:50 (0.6828 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:08  model_time: 0.6521 (0.6521)  evaluator_time: 0.0570 (0.0570)  time: 1.1053  data: 0.3801  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3971 (0.3942)  evaluator_time: 0.0700 (0.0794)  time: 0.7775  data: 0.3019  max mem: 5923\n",
      "Test: Total time: 0:00:48 (0.7847 s / it)\n",
      "Averaged stats: model_time: 0.3971 (0.3942)  evaluator_time: 0.0700 (0.0794)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.09s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.023\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.185\n",
      "Testing Epoch: [150]  [ 0/62]  eta: 0:00:43  lr: 0.000300  loss: 0.1336 (0.1336)  loss_objectness: 0.0424 (0.0424)  loss_rpn_box_reg: 0.0912 (0.0912)  time: 0.7012  data: 0.3811  max mem: 5923\n",
      "Testing Epoch: [150]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1291 (0.1415)  loss_objectness: 0.0546 (0.0607)  loss_rpn_box_reg: 0.0707 (0.0808)  time: 0.6298  data: 0.3079  max mem: 5923\n",
      "Testing Epoch: [150] Total time: 0:00:39 (0.6365 s / it)\n",
      "Training Epoch: [151]  [  0/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1179 (0.1179)  loss_objectness: 0.0549 (0.0549)  loss_rpn_box_reg: 0.0630 (0.0630)  time: 0.6411  data: 0.2781  max mem: 5923\n",
      "Training Epoch: [151]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1315 (0.1385)  loss_objectness: 0.0748 (0.0741)  loss_rpn_box_reg: 0.0630 (0.0644)  time: 0.6847  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [151]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1297 (0.1334)  loss_objectness: 0.0679 (0.0700)  loss_rpn_box_reg: 0.0573 (0.0634)  time: 0.6877  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [151]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1299 (0.1360)  loss_objectness: 0.0652 (0.0688)  loss_rpn_box_reg: 0.0603 (0.0672)  time: 0.6854  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [151]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1368 (0.1377)  loss_objectness: 0.0581 (0.0677)  loss_rpn_box_reg: 0.0746 (0.0700)  time: 0.6719  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [151]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1267 (0.1358)  loss_objectness: 0.0581 (0.0666)  loss_rpn_box_reg: 0.0747 (0.0693)  time: 0.6661  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [151]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1321 (0.1368)  loss_objectness: 0.0701 (0.0677)  loss_rpn_box_reg: 0.0650 (0.0691)  time: 0.6886  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [151]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1377 (0.1367)  loss_objectness: 0.0730 (0.0676)  loss_rpn_box_reg: 0.0630 (0.0691)  time: 0.6823  data: 0.2889  max mem: 5923\n",
      "Training Epoch: [151]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1314 (0.1351)  loss_objectness: 0.0660 (0.0674)  loss_rpn_box_reg: 0.0589 (0.0677)  time: 0.6650  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [151]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1314 (0.1358)  loss_objectness: 0.0671 (0.0680)  loss_rpn_box_reg: 0.0605 (0.0678)  time: 0.6761  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [151]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1450 (0.1361)  loss_objectness: 0.0646 (0.0680)  loss_rpn_box_reg: 0.0681 (0.0680)  time: 0.6830  data: 0.2985  max mem: 5923\n",
      "Training Epoch: [151]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1423 (0.1365)  loss_objectness: 0.0581 (0.0675)  loss_rpn_box_reg: 0.0798 (0.0690)  time: 0.6870  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [151]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1383 (0.1363)  loss_objectness: 0.0604 (0.0670)  loss_rpn_box_reg: 0.0761 (0.0694)  time: 0.6878  data: 0.2868  max mem: 5923\n",
      "Training Epoch: [151]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1383 (0.1367)  loss_objectness: 0.0625 (0.0669)  loss_rpn_box_reg: 0.0761 (0.0697)  time: 0.7006  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [151]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1407 (0.1375)  loss_objectness: 0.0703 (0.0679)  loss_rpn_box_reg: 0.0644 (0.0696)  time: 0.7041  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [151]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1441 (0.1382)  loss_objectness: 0.0721 (0.0683)  loss_rpn_box_reg: 0.0605 (0.0699)  time: 0.6923  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [151]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1432 (0.1380)  loss_objectness: 0.0657 (0.0682)  loss_rpn_box_reg: 0.0686 (0.0698)  time: 0.6828  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [151]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1322 (0.1380)  loss_objectness: 0.0694 (0.0684)  loss_rpn_box_reg: 0.0616 (0.0695)  time: 0.6782  data: 0.2875  max mem: 5923\n",
      "Training Epoch: [151]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1322 (0.1380)  loss_objectness: 0.0716 (0.0687)  loss_rpn_box_reg: 0.0627 (0.0693)  time: 0.6737  data: 0.2874  max mem: 5923\n",
      "Training Epoch: [151]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1315 (0.1377)  loss_objectness: 0.0690 (0.0688)  loss_rpn_box_reg: 0.0650 (0.0690)  time: 0.6836  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [151]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1315 (0.1381)  loss_objectness: 0.0693 (0.0692)  loss_rpn_box_reg: 0.0570 (0.0689)  time: 0.6941  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [151]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1480 (0.1390)  loss_objectness: 0.0786 (0.0695)  loss_rpn_box_reg: 0.0590 (0.0695)  time: 0.6967  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [151]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1452 (0.1392)  loss_objectness: 0.0675 (0.0695)  loss_rpn_box_reg: 0.0715 (0.0697)  time: 0.7024  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [151]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1223 (0.1383)  loss_objectness: 0.0685 (0.0694)  loss_rpn_box_reg: 0.0572 (0.0689)  time: 0.7023  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [151]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1221 (0.1388)  loss_objectness: 0.0696 (0.0697)  loss_rpn_box_reg: 0.0530 (0.0691)  time: 0.6939  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [151]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1405 (0.1389)  loss_objectness: 0.0707 (0.0695)  loss_rpn_box_reg: 0.0721 (0.0694)  time: 0.6874  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [151] Total time: 0:02:51 (0.6861 s / it)\n",
      "Testing Epoch: [151]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1317 (0.1317)  loss_objectness: 0.0427 (0.0427)  loss_rpn_box_reg: 0.0889 (0.0889)  time: 0.6161  data: 0.2961  max mem: 5923\n",
      "Testing Epoch: [151]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1319 (0.1373)  loss_objectness: 0.0506 (0.0570)  loss_rpn_box_reg: 0.0708 (0.0803)  time: 0.6349  data: 0.3114  max mem: 5923\n",
      "Testing Epoch: [151] Total time: 0:00:39 (0.6320 s / it)\n",
      "Training Epoch: [152]  [  0/250]  eta: 0:02:49  lr: 0.000300  loss: 0.1357 (0.1357)  loss_objectness: 0.0699 (0.0699)  loss_rpn_box_reg: 0.0658 (0.0658)  time: 0.6792  data: 0.3171  max mem: 5923\n",
      "Training Epoch: [152]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1459 (0.1481)  loss_objectness: 0.0690 (0.0670)  loss_rpn_box_reg: 0.0800 (0.0811)  time: 0.6854  data: 0.3045  max mem: 5923\n",
      "Training Epoch: [152]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1315 (0.1341)  loss_objectness: 0.0659 (0.0651)  loss_rpn_box_reg: 0.0588 (0.0690)  time: 0.6897  data: 0.2966  max mem: 5923\n",
      "Training Epoch: [152]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1267 (0.1383)  loss_objectness: 0.0636 (0.0664)  loss_rpn_box_reg: 0.0672 (0.0719)  time: 0.6912  data: 0.2878  max mem: 5923\n",
      "Training Epoch: [152]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1352 (0.1382)  loss_objectness: 0.0655 (0.0664)  loss_rpn_box_reg: 0.0720 (0.0718)  time: 0.6922  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [152]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1329 (0.1378)  loss_objectness: 0.0648 (0.0669)  loss_rpn_box_reg: 0.0622 (0.0709)  time: 0.6908  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [152]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1257 (0.1355)  loss_objectness: 0.0637 (0.0657)  loss_rpn_box_reg: 0.0619 (0.0698)  time: 0.6822  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [152]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1232 (0.1355)  loss_objectness: 0.0601 (0.0659)  loss_rpn_box_reg: 0.0614 (0.0696)  time: 0.6857  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [152]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1375 (0.1372)  loss_objectness: 0.0733 (0.0673)  loss_rpn_box_reg: 0.0614 (0.0699)  time: 0.6961  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [152]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1414 (0.1374)  loss_objectness: 0.0739 (0.0675)  loss_rpn_box_reg: 0.0625 (0.0698)  time: 0.7116  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [152]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1396 (0.1381)  loss_objectness: 0.0704 (0.0677)  loss_rpn_box_reg: 0.0723 (0.0704)  time: 0.7037  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [152]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1378 (0.1379)  loss_objectness: 0.0673 (0.0674)  loss_rpn_box_reg: 0.0661 (0.0705)  time: 0.6900  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [152]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1317 (0.1387)  loss_objectness: 0.0657 (0.0679)  loss_rpn_box_reg: 0.0654 (0.0708)  time: 0.6932  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [152]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1428 (0.1390)  loss_objectness: 0.0686 (0.0682)  loss_rpn_box_reg: 0.0708 (0.0708)  time: 0.6968  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [152]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1440 (0.1392)  loss_objectness: 0.0718 (0.0686)  loss_rpn_box_reg: 0.0616 (0.0706)  time: 0.6915  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [152]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1386 (0.1396)  loss_objectness: 0.0725 (0.0687)  loss_rpn_box_reg: 0.0616 (0.0709)  time: 0.6822  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [152]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1352 (0.1393)  loss_objectness: 0.0731 (0.0692)  loss_rpn_box_reg: 0.0560 (0.0701)  time: 0.6941  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [152]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1352 (0.1394)  loss_objectness: 0.0701 (0.0694)  loss_rpn_box_reg: 0.0596 (0.0700)  time: 0.7003  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [152]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1419 (0.1396)  loss_objectness: 0.0667 (0.0697)  loss_rpn_box_reg: 0.0681 (0.0699)  time: 0.6900  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [152]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1405 (0.1398)  loss_objectness: 0.0730 (0.0700)  loss_rpn_box_reg: 0.0640 (0.0698)  time: 0.6927  data: 0.2964  max mem: 5923\n",
      "Training Epoch: [152]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1393 (0.1400)  loss_objectness: 0.0677 (0.0699)  loss_rpn_box_reg: 0.0642 (0.0701)  time: 0.6964  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [152]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1357 (0.1399)  loss_objectness: 0.0656 (0.0698)  loss_rpn_box_reg: 0.0646 (0.0701)  time: 0.6815  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [152]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1350 (0.1397)  loss_objectness: 0.0706 (0.0702)  loss_rpn_box_reg: 0.0569 (0.0695)  time: 0.6909  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [152]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1434 (0.1407)  loss_objectness: 0.0793 (0.0706)  loss_rpn_box_reg: 0.0652 (0.0701)  time: 0.6944  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [152]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1557 (0.1404)  loss_objectness: 0.0721 (0.0705)  loss_rpn_box_reg: 0.0705 (0.0698)  time: 0.6812  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [152]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1375 (0.1408)  loss_objectness: 0.0720 (0.0707)  loss_rpn_box_reg: 0.0588 (0.0701)  time: 0.6791  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [152] Total time: 0:02:52 (0.6914 s / it)\n",
      "Testing Epoch: [152]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1377 (0.1377)  loss_objectness: 0.0446 (0.0446)  loss_rpn_box_reg: 0.0931 (0.0931)  time: 0.6181  data: 0.2931  max mem: 5923\n",
      "Testing Epoch: [152]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1286 (0.1406)  loss_objectness: 0.0539 (0.0587)  loss_rpn_box_reg: 0.0764 (0.0819)  time: 0.6314  data: 0.3097  max mem: 5923\n",
      "Testing Epoch: [152] Total time: 0:00:39 (0.6357 s / it)\n",
      "Training Epoch: [153]  [  0/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1413 (0.1413)  loss_objectness: 0.0624 (0.0624)  loss_rpn_box_reg: 0.0789 (0.0789)  time: 0.6852  data: 0.3121  max mem: 5923\n",
      "Training Epoch: [153]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1354 (0.1389)  loss_objectness: 0.0722 (0.0686)  loss_rpn_box_reg: 0.0679 (0.0703)  time: 0.6734  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [153]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1352 (0.1385)  loss_objectness: 0.0713 (0.0717)  loss_rpn_box_reg: 0.0582 (0.0668)  time: 0.6838  data: 0.2964  max mem: 5923\n",
      "Training Epoch: [153]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1423 (0.1423)  loss_objectness: 0.0713 (0.0732)  loss_rpn_box_reg: 0.0617 (0.0691)  time: 0.6843  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [153]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1429 (0.1423)  loss_objectness: 0.0707 (0.0708)  loss_rpn_box_reg: 0.0770 (0.0715)  time: 0.6786  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [153]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1443 (0.1441)  loss_objectness: 0.0720 (0.0726)  loss_rpn_box_reg: 0.0735 (0.0715)  time: 0.6910  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [153]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1443 (0.1444)  loss_objectness: 0.0670 (0.0713)  loss_rpn_box_reg: 0.0727 (0.0731)  time: 0.6982  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [153]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1397 (0.1431)  loss_objectness: 0.0641 (0.0708)  loss_rpn_box_reg: 0.0722 (0.0723)  time: 0.6945  data: 0.2882  max mem: 5923\n",
      "Training Epoch: [153]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1438 (0.1430)  loss_objectness: 0.0679 (0.0708)  loss_rpn_box_reg: 0.0702 (0.0722)  time: 0.6905  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [153]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1330 (0.1414)  loss_objectness: 0.0651 (0.0701)  loss_rpn_box_reg: 0.0646 (0.0713)  time: 0.6933  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [153]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1295 (0.1404)  loss_objectness: 0.0652 (0.0697)  loss_rpn_box_reg: 0.0643 (0.0706)  time: 0.6947  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [153]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1350 (0.1402)  loss_objectness: 0.0655 (0.0694)  loss_rpn_box_reg: 0.0642 (0.0708)  time: 0.6812  data: 0.2889  max mem: 5923\n",
      "Training Epoch: [153]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1301 (0.1398)  loss_objectness: 0.0636 (0.0692)  loss_rpn_box_reg: 0.0564 (0.0705)  time: 0.6654  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [153]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1395 (0.1405)  loss_objectness: 0.0661 (0.0691)  loss_rpn_box_reg: 0.0683 (0.0714)  time: 0.6651  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [153]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1342 (0.1398)  loss_objectness: 0.0667 (0.0692)  loss_rpn_box_reg: 0.0675 (0.0706)  time: 0.6794  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [153]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1305 (0.1394)  loss_objectness: 0.0667 (0.0692)  loss_rpn_box_reg: 0.0566 (0.0702)  time: 0.6962  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [153]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1306 (0.1389)  loss_objectness: 0.0657 (0.0689)  loss_rpn_box_reg: 0.0597 (0.0701)  time: 0.6922  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [153]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1358 (0.1391)  loss_objectness: 0.0668 (0.0691)  loss_rpn_box_reg: 0.0666 (0.0700)  time: 0.6795  data: 0.2878  max mem: 5923\n",
      "Training Epoch: [153]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1423 (0.1395)  loss_objectness: 0.0712 (0.0692)  loss_rpn_box_reg: 0.0666 (0.0702)  time: 0.6733  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [153]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1412 (0.1398)  loss_objectness: 0.0712 (0.0695)  loss_rpn_box_reg: 0.0694 (0.0703)  time: 0.6756  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [153]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1386 (0.1396)  loss_objectness: 0.0750 (0.0697)  loss_rpn_box_reg: 0.0688 (0.0699)  time: 0.6948  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [153]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1394 (0.1399)  loss_objectness: 0.0764 (0.0701)  loss_rpn_box_reg: 0.0623 (0.0698)  time: 0.6980  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [153]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1413 (0.1396)  loss_objectness: 0.0761 (0.0703)  loss_rpn_box_reg: 0.0628 (0.0694)  time: 0.6944  data: 0.2981  max mem: 5923\n",
      "Training Epoch: [153]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1430 (0.1402)  loss_objectness: 0.0761 (0.0706)  loss_rpn_box_reg: 0.0651 (0.0696)  time: 0.7112  data: 0.2991  max mem: 5923\n",
      "Training Epoch: [153]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1329 (0.1392)  loss_objectness: 0.0717 (0.0704)  loss_rpn_box_reg: 0.0547 (0.0689)  time: 0.7050  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [153]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1329 (0.1398)  loss_objectness: 0.0733 (0.0705)  loss_rpn_box_reg: 0.0626 (0.0692)  time: 0.6921  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [153] Total time: 0:02:51 (0.6874 s / it)\n",
      "Testing Epoch: [153]  [ 0/62]  eta: 0:00:45  lr: 0.000300  loss: 0.1420 (0.1420)  loss_objectness: 0.0527 (0.0527)  loss_rpn_box_reg: 0.0893 (0.0893)  time: 0.7382  data: 0.4041  max mem: 5923\n",
      "Testing Epoch: [153]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1344 (0.1467)  loss_objectness: 0.0626 (0.0650)  loss_rpn_box_reg: 0.0792 (0.0818)  time: 0.6290  data: 0.3082  max mem: 5923\n",
      "Testing Epoch: [153] Total time: 0:00:39 (0.6371 s / it)\n",
      "Training Epoch: [154]  [  0/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1536 (0.1536)  loss_objectness: 0.0575 (0.0575)  loss_rpn_box_reg: 0.0961 (0.0961)  time: 0.6672  data: 0.3011  max mem: 5923\n",
      "Training Epoch: [154]  [ 10/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1449 (0.1469)  loss_objectness: 0.0717 (0.0704)  loss_rpn_box_reg: 0.0861 (0.0766)  time: 0.6885  data: 0.2988  max mem: 5923\n",
      "Training Epoch: [154]  [ 20/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1326 (0.1349)  loss_objectness: 0.0617 (0.0658)  loss_rpn_box_reg: 0.0616 (0.0692)  time: 0.6761  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [154]  [ 30/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1227 (0.1338)  loss_objectness: 0.0606 (0.0668)  loss_rpn_box_reg: 0.0565 (0.0671)  time: 0.6665  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [154]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1317 (0.1342)  loss_objectness: 0.0689 (0.0680)  loss_rpn_box_reg: 0.0637 (0.0661)  time: 0.6947  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [154]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1363 (0.1365)  loss_objectness: 0.0710 (0.0695)  loss_rpn_box_reg: 0.0657 (0.0669)  time: 0.7080  data: 0.2965  max mem: 5923\n",
      "Training Epoch: [154]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1402 (0.1372)  loss_objectness: 0.0710 (0.0700)  loss_rpn_box_reg: 0.0661 (0.0672)  time: 0.6986  data: 0.2969  max mem: 5923\n",
      "Training Epoch: [154]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1345 (0.1387)  loss_objectness: 0.0700 (0.0706)  loss_rpn_box_reg: 0.0664 (0.0682)  time: 0.7004  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [154]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1363 (0.1400)  loss_objectness: 0.0639 (0.0707)  loss_rpn_box_reg: 0.0741 (0.0693)  time: 0.7029  data: 0.2972  max mem: 5923\n",
      "Training Epoch: [154]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1353 (0.1391)  loss_objectness: 0.0623 (0.0705)  loss_rpn_box_reg: 0.0641 (0.0686)  time: 0.6992  data: 0.2964  max mem: 5923\n",
      "Training Epoch: [154]  [100/250]  eta: 0:01:44  lr: 0.000300  loss: 0.1274 (0.1384)  loss_objectness: 0.0653 (0.0705)  loss_rpn_box_reg: 0.0591 (0.0679)  time: 0.7003  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [154]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1327 (0.1389)  loss_objectness: 0.0643 (0.0705)  loss_rpn_box_reg: 0.0656 (0.0684)  time: 0.6980  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [154]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1311 (0.1386)  loss_objectness: 0.0648 (0.0702)  loss_rpn_box_reg: 0.0677 (0.0684)  time: 0.6844  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [154]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1283 (0.1382)  loss_objectness: 0.0619 (0.0698)  loss_rpn_box_reg: 0.0671 (0.0683)  time: 0.6815  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [154]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1312 (0.1381)  loss_objectness: 0.0690 (0.0698)  loss_rpn_box_reg: 0.0624 (0.0683)  time: 0.6851  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [154]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1389 (0.1379)  loss_objectness: 0.0696 (0.0697)  loss_rpn_box_reg: 0.0609 (0.0682)  time: 0.6969  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [154]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1398 (0.1378)  loss_objectness: 0.0696 (0.0698)  loss_rpn_box_reg: 0.0651 (0.0680)  time: 0.6944  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [154]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1420 (0.1383)  loss_objectness: 0.0723 (0.0703)  loss_rpn_box_reg: 0.0675 (0.0680)  time: 0.6991  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [154]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1243 (0.1375)  loss_objectness: 0.0708 (0.0701)  loss_rpn_box_reg: 0.0590 (0.0674)  time: 0.7052  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [154]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1276 (0.1385)  loss_objectness: 0.0708 (0.0705)  loss_rpn_box_reg: 0.0698 (0.0681)  time: 0.6874  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [154]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1388 (0.1387)  loss_objectness: 0.0738 (0.0705)  loss_rpn_box_reg: 0.0714 (0.0683)  time: 0.6853  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [154]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1398 (0.1394)  loss_objectness: 0.0720 (0.0706)  loss_rpn_box_reg: 0.0688 (0.0688)  time: 0.7016  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [154]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1333 (0.1394)  loss_objectness: 0.0728 (0.0706)  loss_rpn_box_reg: 0.0602 (0.0687)  time: 0.6971  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [154]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1317 (0.1397)  loss_objectness: 0.0774 (0.0709)  loss_rpn_box_reg: 0.0602 (0.0688)  time: 0.6852  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [154]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1522 (0.1407)  loss_objectness: 0.0800 (0.0714)  loss_rpn_box_reg: 0.0777 (0.0693)  time: 0.6770  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [154]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1522 (0.1412)  loss_objectness: 0.0797 (0.0716)  loss_rpn_box_reg: 0.0777 (0.0696)  time: 0.6752  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [154] Total time: 0:02:52 (0.6917 s / it)\n",
      "Testing Epoch: [154]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1375 (0.1375)  loss_objectness: 0.0506 (0.0506)  loss_rpn_box_reg: 0.0870 (0.0870)  time: 0.6091  data: 0.2841  max mem: 5923\n",
      "Testing Epoch: [154]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1303 (0.1482)  loss_objectness: 0.0584 (0.0665)  loss_rpn_box_reg: 0.0723 (0.0817)  time: 0.6335  data: 0.3091  max mem: 5923\n",
      "Testing Epoch: [154] Total time: 0:00:39 (0.6384 s / it)\n",
      "Training Epoch: [155]  [  0/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1540 (0.1540)  loss_objectness: 0.0761 (0.0761)  loss_rpn_box_reg: 0.0779 (0.0779)  time: 0.6652  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [155]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1591 (0.1606)  loss_objectness: 0.0678 (0.0739)  loss_rpn_box_reg: 0.0779 (0.0868)  time: 0.6986  data: 0.2967  max mem: 5923\n",
      "Training Epoch: [155]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1483 (0.1489)  loss_objectness: 0.0666 (0.0700)  loss_rpn_box_reg: 0.0679 (0.0789)  time: 0.6909  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [155]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1403 (0.1467)  loss_objectness: 0.0683 (0.0704)  loss_rpn_box_reg: 0.0671 (0.0764)  time: 0.6768  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [155]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1336 (0.1443)  loss_objectness: 0.0701 (0.0702)  loss_rpn_box_reg: 0.0604 (0.0742)  time: 0.6805  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [155]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1258 (0.1412)  loss_objectness: 0.0701 (0.0712)  loss_rpn_box_reg: 0.0548 (0.0700)  time: 0.6861  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [155]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1307 (0.1392)  loss_objectness: 0.0664 (0.0699)  loss_rpn_box_reg: 0.0586 (0.0693)  time: 0.6837  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [155]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1343 (0.1400)  loss_objectness: 0.0611 (0.0689)  loss_rpn_box_reg: 0.0722 (0.0711)  time: 0.6803  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [155]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1461 (0.1411)  loss_objectness: 0.0668 (0.0694)  loss_rpn_box_reg: 0.0793 (0.0717)  time: 0.6850  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [155]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1321 (0.1387)  loss_objectness: 0.0648 (0.0685)  loss_rpn_box_reg: 0.0657 (0.0702)  time: 0.6799  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [155]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1307 (0.1393)  loss_objectness: 0.0607 (0.0689)  loss_rpn_box_reg: 0.0654 (0.0704)  time: 0.6679  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [155]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1307 (0.1382)  loss_objectness: 0.0646 (0.0690)  loss_rpn_box_reg: 0.0684 (0.0692)  time: 0.6711  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [155]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1361 (0.1391)  loss_objectness: 0.0723 (0.0697)  loss_rpn_box_reg: 0.0608 (0.0695)  time: 0.6790  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [155]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1379 (0.1385)  loss_objectness: 0.0752 (0.0700)  loss_rpn_box_reg: 0.0572 (0.0685)  time: 0.6896  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [155]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1324 (0.1390)  loss_objectness: 0.0747 (0.0698)  loss_rpn_box_reg: 0.0572 (0.0691)  time: 0.6991  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [155]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1432 (0.1393)  loss_objectness: 0.0681 (0.0698)  loss_rpn_box_reg: 0.0686 (0.0695)  time: 0.6893  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [155]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1382 (0.1394)  loss_objectness: 0.0656 (0.0698)  loss_rpn_box_reg: 0.0714 (0.0697)  time: 0.6748  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [155]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1439 (0.1398)  loss_objectness: 0.0681 (0.0701)  loss_rpn_box_reg: 0.0714 (0.0697)  time: 0.6824  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [155]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1415 (0.1392)  loss_objectness: 0.0710 (0.0699)  loss_rpn_box_reg: 0.0671 (0.0693)  time: 0.6928  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [155]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1415 (0.1394)  loss_objectness: 0.0697 (0.0701)  loss_rpn_box_reg: 0.0664 (0.0693)  time: 0.6874  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [155]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1428 (0.1392)  loss_objectness: 0.0676 (0.0698)  loss_rpn_box_reg: 0.0730 (0.0693)  time: 0.6877  data: 0.2970  max mem: 5923\n",
      "Training Epoch: [155]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1226 (0.1388)  loss_objectness: 0.0658 (0.0698)  loss_rpn_box_reg: 0.0633 (0.0690)  time: 0.6897  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [155]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1259 (0.1389)  loss_objectness: 0.0645 (0.0695)  loss_rpn_box_reg: 0.0633 (0.0693)  time: 0.6961  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [155]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1419 (0.1388)  loss_objectness: 0.0656 (0.0696)  loss_rpn_box_reg: 0.0681 (0.0692)  time: 0.7016  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [155]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1362 (0.1388)  loss_objectness: 0.0684 (0.0697)  loss_rpn_box_reg: 0.0679 (0.0691)  time: 0.6818  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [155]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1367 (0.1389)  loss_objectness: 0.0684 (0.0699)  loss_rpn_box_reg: 0.0678 (0.0690)  time: 0.6768  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [155] Total time: 0:02:51 (0.6849 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:03  model_time: 0.6591 (0.6591)  evaluator_time: 0.0570 (0.0570)  time: 1.0172  data: 0.2851  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3961 (0.3922)  evaluator_time: 0.0650 (0.0836)  time: 0.7826  data: 0.3041  max mem: 5923\n",
      "Test: Total time: 0:00:48 (0.7820 s / it)\n",
      "Averaged stats: model_time: 0.3961 (0.3922)  evaluator_time: 0.0650 (0.0836)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.05s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.101\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.165\n",
      "Testing Epoch: [155]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1369 (0.1369)  loss_objectness: 0.0492 (0.0492)  loss_rpn_box_reg: 0.0878 (0.0878)  time: 0.6131  data: 0.2891  max mem: 5923\n",
      "Testing Epoch: [155]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1362 (0.1477)  loss_objectness: 0.0628 (0.0651)  loss_rpn_box_reg: 0.0772 (0.0825)  time: 0.6350  data: 0.3110  max mem: 5923\n",
      "Testing Epoch: [155] Total time: 0:00:39 (0.6357 s / it)\n",
      "Training Epoch: [156]  [  0/250]  eta: 0:02:53  lr: 0.000300  loss: 0.0975 (0.0975)  loss_objectness: 0.0634 (0.0634)  loss_rpn_box_reg: 0.0341 (0.0341)  time: 0.6952  data: 0.3101  max mem: 5923\n",
      "Training Epoch: [156]  [ 10/250]  eta: 0:02:50  lr: 0.000300  loss: 0.1319 (0.1282)  loss_objectness: 0.0599 (0.0616)  loss_rpn_box_reg: 0.0684 (0.0666)  time: 0.7119  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [156]  [ 20/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1329 (0.1325)  loss_objectness: 0.0605 (0.0656)  loss_rpn_box_reg: 0.0677 (0.0670)  time: 0.7008  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [156]  [ 30/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1329 (0.1330)  loss_objectness: 0.0689 (0.0684)  loss_rpn_box_reg: 0.0601 (0.0646)  time: 0.7076  data: 0.2892  max mem: 5923\n",
      "Training Epoch: [156]  [ 40/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1413 (0.1361)  loss_objectness: 0.0691 (0.0688)  loss_rpn_box_reg: 0.0601 (0.0673)  time: 0.7142  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [156]  [ 50/250]  eta: 0:02:19  lr: 0.000300  loss: 0.1372 (0.1363)  loss_objectness: 0.0710 (0.0693)  loss_rpn_box_reg: 0.0675 (0.0670)  time: 0.6782  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [156]  [ 60/250]  eta: 0:02:12  lr: 0.000300  loss: 0.1292 (0.1368)  loss_objectness: 0.0630 (0.0682)  loss_rpn_box_reg: 0.0675 (0.0686)  time: 0.6775  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [156]  [ 70/250]  eta: 0:02:05  lr: 0.000300  loss: 0.1416 (0.1373)  loss_objectness: 0.0600 (0.0682)  loss_rpn_box_reg: 0.0686 (0.0691)  time: 0.6933  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [156]  [ 80/250]  eta: 0:01:58  lr: 0.000300  loss: 0.1352 (0.1376)  loss_objectness: 0.0674 (0.0681)  loss_rpn_box_reg: 0.0730 (0.0695)  time: 0.6867  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [156]  [ 90/250]  eta: 0:01:51  lr: 0.000300  loss: 0.1322 (0.1383)  loss_objectness: 0.0679 (0.0689)  loss_rpn_box_reg: 0.0635 (0.0693)  time: 0.6875  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [156]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1333 (0.1388)  loss_objectness: 0.0674 (0.0690)  loss_rpn_box_reg: 0.0617 (0.0697)  time: 0.6794  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [156]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1333 (0.1396)  loss_objectness: 0.0645 (0.0695)  loss_rpn_box_reg: 0.0617 (0.0700)  time: 0.6782  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [156]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1269 (0.1391)  loss_objectness: 0.0670 (0.0693)  loss_rpn_box_reg: 0.0660 (0.0698)  time: 0.6830  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [156]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1386 (0.1395)  loss_objectness: 0.0708 (0.0692)  loss_rpn_box_reg: 0.0676 (0.0703)  time: 0.6890  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [156]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1375 (0.1394)  loss_objectness: 0.0696 (0.0693)  loss_rpn_box_reg: 0.0702 (0.0701)  time: 0.6943  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [156]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1340 (0.1396)  loss_objectness: 0.0706 (0.0698)  loss_rpn_box_reg: 0.0584 (0.0698)  time: 0.6863  data: 0.2964  max mem: 5923\n",
      "Training Epoch: [156]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1416 (0.1400)  loss_objectness: 0.0712 (0.0701)  loss_rpn_box_reg: 0.0649 (0.0699)  time: 0.6888  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [156]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1351 (0.1397)  loss_objectness: 0.0688 (0.0700)  loss_rpn_box_reg: 0.0681 (0.0697)  time: 0.6835  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [156]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1343 (0.1403)  loss_objectness: 0.0713 (0.0706)  loss_rpn_box_reg: 0.0630 (0.0696)  time: 0.6711  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [156]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1343 (0.1401)  loss_objectness: 0.0749 (0.0705)  loss_rpn_box_reg: 0.0672 (0.0696)  time: 0.6740  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [156]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1317 (0.1401)  loss_objectness: 0.0655 (0.0704)  loss_rpn_box_reg: 0.0679 (0.0697)  time: 0.6799  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [156]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1314 (0.1401)  loss_objectness: 0.0697 (0.0706)  loss_rpn_box_reg: 0.0626 (0.0695)  time: 0.6746  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [156]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1363 (0.1398)  loss_objectness: 0.0697 (0.0706)  loss_rpn_box_reg: 0.0593 (0.0693)  time: 0.6786  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [156]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1463 (0.1405)  loss_objectness: 0.0747 (0.0708)  loss_rpn_box_reg: 0.0679 (0.0696)  time: 0.6842  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [156]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1642 (0.1414)  loss_objectness: 0.0755 (0.0714)  loss_rpn_box_reg: 0.0797 (0.0700)  time: 0.6713  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [156]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1457 (0.1416)  loss_objectness: 0.0670 (0.0714)  loss_rpn_box_reg: 0.0663 (0.0702)  time: 0.6752  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [156] Total time: 0:02:51 (0.6856 s / it)\n",
      "Testing Epoch: [156]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1372 (0.1372)  loss_objectness: 0.0488 (0.0488)  loss_rpn_box_reg: 0.0884 (0.0884)  time: 0.6241  data: 0.2931  max mem: 5923\n",
      "Testing Epoch: [156]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1393 (0.1411)  loss_objectness: 0.0573 (0.0602)  loss_rpn_box_reg: 0.0762 (0.0809)  time: 0.6269  data: 0.3056  max mem: 5923\n",
      "Testing Epoch: [156] Total time: 0:00:39 (0.6349 s / it)\n",
      "Training Epoch: [157]  [  0/250]  eta: 0:02:53  lr: 0.000300  loss: 0.1364 (0.1364)  loss_objectness: 0.0624 (0.0624)  loss_rpn_box_reg: 0.0740 (0.0740)  time: 0.6922  data: 0.3161  max mem: 5923\n",
      "Training Epoch: [157]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1230 (0.1290)  loss_objectness: 0.0680 (0.0712)  loss_rpn_box_reg: 0.0485 (0.0578)  time: 0.6798  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [157]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1218 (0.1328)  loss_objectness: 0.0680 (0.0696)  loss_rpn_box_reg: 0.0534 (0.0632)  time: 0.6865  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [157]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1252 (0.1320)  loss_objectness: 0.0621 (0.0690)  loss_rpn_box_reg: 0.0637 (0.0630)  time: 0.6979  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [157]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1317 (0.1356)  loss_objectness: 0.0639 (0.0692)  loss_rpn_box_reg: 0.0675 (0.0664)  time: 0.6881  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [157]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1397 (0.1370)  loss_objectness: 0.0678 (0.0686)  loss_rpn_box_reg: 0.0737 (0.0684)  time: 0.6867  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [157]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1374 (0.1362)  loss_objectness: 0.0636 (0.0675)  loss_rpn_box_reg: 0.0708 (0.0687)  time: 0.6917  data: 0.2960  max mem: 5923\n",
      "Training Epoch: [157]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1238 (0.1356)  loss_objectness: 0.0642 (0.0671)  loss_rpn_box_reg: 0.0616 (0.0684)  time: 0.6840  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [157]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1243 (0.1347)  loss_objectness: 0.0675 (0.0676)  loss_rpn_box_reg: 0.0601 (0.0671)  time: 0.6924  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [157]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1378 (0.1369)  loss_objectness: 0.0731 (0.0699)  loss_rpn_box_reg: 0.0638 (0.0670)  time: 0.6978  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [157]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1456 (0.1381)  loss_objectness: 0.0727 (0.0707)  loss_rpn_box_reg: 0.0687 (0.0675)  time: 0.6986  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [157]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1438 (0.1382)  loss_objectness: 0.0690 (0.0703)  loss_rpn_box_reg: 0.0751 (0.0678)  time: 0.6910  data: 0.2975  max mem: 5923\n",
      "Training Epoch: [157]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1389 (0.1380)  loss_objectness: 0.0656 (0.0704)  loss_rpn_box_reg: 0.0620 (0.0677)  time: 0.6832  data: 0.2985  max mem: 5923\n",
      "Training Epoch: [157]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1399 (0.1394)  loss_objectness: 0.0639 (0.0705)  loss_rpn_box_reg: 0.0708 (0.0689)  time: 0.6853  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [157]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1458 (0.1390)  loss_objectness: 0.0639 (0.0708)  loss_rpn_box_reg: 0.0621 (0.0682)  time: 0.6793  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [157]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1368 (0.1399)  loss_objectness: 0.0811 (0.0714)  loss_rpn_box_reg: 0.0621 (0.0685)  time: 0.6824  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [157]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1394 (0.1399)  loss_objectness: 0.0717 (0.0714)  loss_rpn_box_reg: 0.0643 (0.0685)  time: 0.6931  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [157]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1418 (0.1402)  loss_objectness: 0.0642 (0.0713)  loss_rpn_box_reg: 0.0751 (0.0689)  time: 0.6852  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [157]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1378 (0.1401)  loss_objectness: 0.0651 (0.0708)  loss_rpn_box_reg: 0.0751 (0.0693)  time: 0.6807  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [157]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1153 (0.1394)  loss_objectness: 0.0651 (0.0708)  loss_rpn_box_reg: 0.0565 (0.0686)  time: 0.6962  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [157]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1319 (0.1392)  loss_objectness: 0.0694 (0.0709)  loss_rpn_box_reg: 0.0517 (0.0683)  time: 0.6841  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [157]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1359 (0.1392)  loss_objectness: 0.0683 (0.0708)  loss_rpn_box_reg: 0.0569 (0.0684)  time: 0.6952  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [157]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1428 (0.1403)  loss_objectness: 0.0682 (0.0710)  loss_rpn_box_reg: 0.0741 (0.0693)  time: 0.7077  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [157]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1462 (0.1403)  loss_objectness: 0.0732 (0.0711)  loss_rpn_box_reg: 0.0703 (0.0692)  time: 0.6880  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [157]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1361 (0.1403)  loss_objectness: 0.0704 (0.0711)  loss_rpn_box_reg: 0.0616 (0.0691)  time: 0.7032  data: 0.2889  max mem: 5923\n",
      "Training Epoch: [157]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1526 (0.1412)  loss_objectness: 0.0719 (0.0716)  loss_rpn_box_reg: 0.0694 (0.0696)  time: 0.6981  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [157] Total time: 0:02:52 (0.6902 s / it)\n",
      "Testing Epoch: [157]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1315 (0.1315)  loss_objectness: 0.0438 (0.0438)  loss_rpn_box_reg: 0.0877 (0.0877)  time: 0.7182  data: 0.3891  max mem: 5923\n",
      "Testing Epoch: [157]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1288 (0.1400)  loss_objectness: 0.0529 (0.0608)  loss_rpn_box_reg: 0.0714 (0.0792)  time: 0.6358  data: 0.3108  max mem: 5923\n",
      "Testing Epoch: [157] Total time: 0:00:39 (0.6377 s / it)\n",
      "Training Epoch: [158]  [  0/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1716 (0.1716)  loss_objectness: 0.0702 (0.0702)  loss_rpn_box_reg: 0.1014 (0.1014)  time: 0.6531  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [158]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1365 (0.1419)  loss_objectness: 0.0702 (0.0694)  loss_rpn_box_reg: 0.0548 (0.0725)  time: 0.6808  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [158]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1302 (0.1360)  loss_objectness: 0.0620 (0.0675)  loss_rpn_box_reg: 0.0683 (0.0685)  time: 0.6857  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [158]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1313 (0.1364)  loss_objectness: 0.0685 (0.0686)  loss_rpn_box_reg: 0.0693 (0.0678)  time: 0.6784  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [158]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1330 (0.1361)  loss_objectness: 0.0749 (0.0706)  loss_rpn_box_reg: 0.0605 (0.0655)  time: 0.6768  data: 0.3003  max mem: 5923\n",
      "Training Epoch: [158]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1284 (0.1345)  loss_objectness: 0.0752 (0.0714)  loss_rpn_box_reg: 0.0554 (0.0631)  time: 0.6880  data: 0.2984  max mem: 5923\n",
      "Training Epoch: [158]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1331 (0.1364)  loss_objectness: 0.0741 (0.0716)  loss_rpn_box_reg: 0.0569 (0.0648)  time: 0.6891  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [158]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1386 (0.1373)  loss_objectness: 0.0659 (0.0711)  loss_rpn_box_reg: 0.0742 (0.0662)  time: 0.6838  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [158]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1500 (0.1390)  loss_objectness: 0.0659 (0.0717)  loss_rpn_box_reg: 0.0709 (0.0673)  time: 0.6828  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [158]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1424 (0.1395)  loss_objectness: 0.0650 (0.0715)  loss_rpn_box_reg: 0.0709 (0.0681)  time: 0.6901  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [158]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1385 (0.1390)  loss_objectness: 0.0683 (0.0711)  loss_rpn_box_reg: 0.0776 (0.0679)  time: 0.7000  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [158]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1289 (0.1379)  loss_objectness: 0.0629 (0.0704)  loss_rpn_box_reg: 0.0563 (0.0674)  time: 0.7041  data: 0.2968  max mem: 5923\n",
      "Training Epoch: [158]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1392 (0.1384)  loss_objectness: 0.0629 (0.0704)  loss_rpn_box_reg: 0.0643 (0.0680)  time: 0.6960  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [158]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1404 (0.1388)  loss_objectness: 0.0717 (0.0708)  loss_rpn_box_reg: 0.0709 (0.0679)  time: 0.6939  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [158]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1411 (0.1403)  loss_objectness: 0.0790 (0.0714)  loss_rpn_box_reg: 0.0729 (0.0689)  time: 0.6960  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [158]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1496 (0.1410)  loss_objectness: 0.0753 (0.0713)  loss_rpn_box_reg: 0.0735 (0.0697)  time: 0.7040  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [158]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1385 (0.1410)  loss_objectness: 0.0672 (0.0716)  loss_rpn_box_reg: 0.0656 (0.0694)  time: 0.6977  data: 0.2886  max mem: 5923\n",
      "Training Epoch: [158]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1379 (0.1414)  loss_objectness: 0.0675 (0.0716)  loss_rpn_box_reg: 0.0659 (0.0698)  time: 0.6823  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [158]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1422 (0.1422)  loss_objectness: 0.0675 (0.0717)  loss_rpn_box_reg: 0.0814 (0.0705)  time: 0.6713  data: 0.2898  max mem: 5923\n",
      "Training Epoch: [158]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1432 (0.1421)  loss_objectness: 0.0710 (0.0720)  loss_rpn_box_reg: 0.0636 (0.0701)  time: 0.6759  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [158]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1388 (0.1420)  loss_objectness: 0.0770 (0.0721)  loss_rpn_box_reg: 0.0619 (0.0699)  time: 0.6928  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [158]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1357 (0.1420)  loss_objectness: 0.0706 (0.0720)  loss_rpn_box_reg: 0.0619 (0.0700)  time: 0.6830  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [158]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1428 (0.1420)  loss_objectness: 0.0663 (0.0717)  loss_rpn_box_reg: 0.0645 (0.0703)  time: 0.6946  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [158]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1319 (0.1416)  loss_objectness: 0.0624 (0.0715)  loss_rpn_box_reg: 0.0682 (0.0701)  time: 0.6926  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [158]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1319 (0.1417)  loss_objectness: 0.0614 (0.0712)  loss_rpn_box_reg: 0.0705 (0.0705)  time: 0.6679  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [158]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1318 (0.1410)  loss_objectness: 0.0607 (0.0710)  loss_rpn_box_reg: 0.0597 (0.0700)  time: 0.6676  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [158] Total time: 0:02:51 (0.6868 s / it)\n",
      "Testing Epoch: [158]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1353 (0.1353)  loss_objectness: 0.0457 (0.0457)  loss_rpn_box_reg: 0.0896 (0.0896)  time: 0.6301  data: 0.2971  max mem: 5923\n",
      "Testing Epoch: [158]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1268 (0.1384)  loss_objectness: 0.0545 (0.0574)  loss_rpn_box_reg: 0.0752 (0.0810)  time: 0.6257  data: 0.3082  max mem: 5923\n",
      "Testing Epoch: [158] Total time: 0:00:39 (0.6326 s / it)\n",
      "Training Epoch: [159]  [  0/250]  eta: 0:02:57  lr: 0.000300  loss: 0.1717 (0.1717)  loss_objectness: 0.0909 (0.0909)  loss_rpn_box_reg: 0.0808 (0.0808)  time: 0.7112  data: 0.3021  max mem: 5923\n",
      "Training Epoch: [159]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1437 (0.1446)  loss_objectness: 0.0698 (0.0675)  loss_rpn_box_reg: 0.0819 (0.0771)  time: 0.6720  data: 0.2837  max mem: 5923\n",
      "Training Epoch: [159]  [ 20/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1353 (0.1335)  loss_objectness: 0.0649 (0.0657)  loss_rpn_box_reg: 0.0723 (0.0678)  time: 0.6740  data: 0.2874  max mem: 5923\n",
      "Training Epoch: [159]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1310 (0.1347)  loss_objectness: 0.0675 (0.0668)  loss_rpn_box_reg: 0.0558 (0.0679)  time: 0.6858  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [159]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1310 (0.1324)  loss_objectness: 0.0697 (0.0674)  loss_rpn_box_reg: 0.0558 (0.0650)  time: 0.6851  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [159]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1268 (0.1342)  loss_objectness: 0.0624 (0.0680)  loss_rpn_box_reg: 0.0559 (0.0661)  time: 0.6957  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [159]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1307 (0.1355)  loss_objectness: 0.0636 (0.0681)  loss_rpn_box_reg: 0.0681 (0.0674)  time: 0.6994  data: 0.2873  max mem: 5923\n",
      "Training Epoch: [159]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1421 (0.1363)  loss_objectness: 0.0669 (0.0684)  loss_rpn_box_reg: 0.0703 (0.0679)  time: 0.6832  data: 0.2871  max mem: 5923\n",
      "Training Epoch: [159]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1361 (0.1376)  loss_objectness: 0.0672 (0.0688)  loss_rpn_box_reg: 0.0613 (0.0688)  time: 0.6836  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [159]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1367 (0.1375)  loss_objectness: 0.0640 (0.0692)  loss_rpn_box_reg: 0.0589 (0.0684)  time: 0.6743  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [159]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1344 (0.1373)  loss_objectness: 0.0623 (0.0689)  loss_rpn_box_reg: 0.0716 (0.0683)  time: 0.6605  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [159]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1339 (0.1381)  loss_objectness: 0.0640 (0.0697)  loss_rpn_box_reg: 0.0672 (0.0684)  time: 0.6688  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [159]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1231 (0.1370)  loss_objectness: 0.0638 (0.0691)  loss_rpn_box_reg: 0.0595 (0.0680)  time: 0.6794  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [159]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1297 (0.1383)  loss_objectness: 0.0672 (0.0702)  loss_rpn_box_reg: 0.0595 (0.0681)  time: 0.6705  data: 0.2898  max mem: 5923\n",
      "Training Epoch: [159]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1302 (0.1379)  loss_objectness: 0.0700 (0.0700)  loss_rpn_box_reg: 0.0638 (0.0679)  time: 0.6676  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [159]  [150/250]  eta: 0:01:07  lr: 0.000300  loss: 0.1332 (0.1384)  loss_objectness: 0.0705 (0.0707)  loss_rpn_box_reg: 0.0599 (0.0676)  time: 0.6762  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [159]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1403 (0.1390)  loss_objectness: 0.0735 (0.0711)  loss_rpn_box_reg: 0.0634 (0.0679)  time: 0.6926  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [159]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1448 (0.1389)  loss_objectness: 0.0672 (0.0710)  loss_rpn_box_reg: 0.0668 (0.0678)  time: 0.6983  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [159]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1529 (0.1398)  loss_objectness: 0.0687 (0.0714)  loss_rpn_box_reg: 0.0678 (0.0684)  time: 0.6913  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [159]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1295 (0.1393)  loss_objectness: 0.0652 (0.0712)  loss_rpn_box_reg: 0.0617 (0.0681)  time: 0.6944  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [159]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1249 (0.1395)  loss_objectness: 0.0654 (0.0713)  loss_rpn_box_reg: 0.0526 (0.0683)  time: 0.6922  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [159]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1339 (0.1397)  loss_objectness: 0.0728 (0.0712)  loss_rpn_box_reg: 0.0638 (0.0685)  time: 0.6878  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [159]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1401 (0.1399)  loss_objectness: 0.0705 (0.0716)  loss_rpn_box_reg: 0.0655 (0.0683)  time: 0.6832  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [159]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1384 (0.1400)  loss_objectness: 0.0705 (0.0716)  loss_rpn_box_reg: 0.0655 (0.0684)  time: 0.6929  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [159]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1384 (0.1406)  loss_objectness: 0.0659 (0.0713)  loss_rpn_box_reg: 0.0715 (0.0693)  time: 0.6871  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [159]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1462 (0.1407)  loss_objectness: 0.0694 (0.0711)  loss_rpn_box_reg: 0.0761 (0.0696)  time: 0.6767  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [159] Total time: 0:02:50 (0.6830 s / it)\n",
      "Testing Epoch: [159]  [ 0/62]  eta: 0:00:45  lr: 0.000300  loss: 0.1374 (0.1374)  loss_objectness: 0.0478 (0.0478)  loss_rpn_box_reg: 0.0897 (0.0897)  time: 0.7412  data: 0.3811  max mem: 5923\n",
      "Testing Epoch: [159]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1331 (0.1402)  loss_objectness: 0.0551 (0.0591)  loss_rpn_box_reg: 0.0772 (0.0811)  time: 0.6276  data: 0.3046  max mem: 5923\n",
      "Testing Epoch: [159] Total time: 0:00:39 (0.6359 s / it)\n",
      "Training Epoch: [160]  [  0/250]  eta: 0:02:59  lr: 0.000300  loss: 0.1249 (0.1249)  loss_objectness: 0.0689 (0.0689)  loss_rpn_box_reg: 0.0560 (0.0560)  time: 0.7172  data: 0.2821  max mem: 5923\n",
      "Training Epoch: [160]  [ 10/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1346 (0.1290)  loss_objectness: 0.0638 (0.0653)  loss_rpn_box_reg: 0.0693 (0.0637)  time: 0.6652  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [160]  [ 20/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1313 (0.1333)  loss_objectness: 0.0638 (0.0665)  loss_rpn_box_reg: 0.0693 (0.0668)  time: 0.6751  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [160]  [ 30/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1313 (0.1363)  loss_objectness: 0.0649 (0.0671)  loss_rpn_box_reg: 0.0641 (0.0692)  time: 0.6819  data: 0.2882  max mem: 5923\n",
      "Training Epoch: [160]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1451 (0.1409)  loss_objectness: 0.0679 (0.0713)  loss_rpn_box_reg: 0.0616 (0.0696)  time: 0.6851  data: 0.2873  max mem: 5923\n",
      "Training Epoch: [160]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1366 (0.1372)  loss_objectness: 0.0700 (0.0703)  loss_rpn_box_reg: 0.0534 (0.0669)  time: 0.6882  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [160]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1175 (0.1353)  loss_objectness: 0.0614 (0.0689)  loss_rpn_box_reg: 0.0536 (0.0664)  time: 0.6885  data: 0.2858  max mem: 5923\n",
      "Training Epoch: [160]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1409 (0.1381)  loss_objectness: 0.0636 (0.0693)  loss_rpn_box_reg: 0.0692 (0.0688)  time: 0.6935  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [160]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1432 (0.1376)  loss_objectness: 0.0650 (0.0695)  loss_rpn_box_reg: 0.0739 (0.0682)  time: 0.6822  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [160]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1231 (0.1365)  loss_objectness: 0.0607 (0.0691)  loss_rpn_box_reg: 0.0555 (0.0674)  time: 0.6751  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [160]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1390 (0.1385)  loss_objectness: 0.0696 (0.0703)  loss_rpn_box_reg: 0.0577 (0.0682)  time: 0.6731  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [160]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1384 (0.1374)  loss_objectness: 0.0742 (0.0701)  loss_rpn_box_reg: 0.0565 (0.0673)  time: 0.6890  data: 0.3047  max mem: 5923\n",
      "Training Epoch: [160]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1324 (0.1375)  loss_objectness: 0.0653 (0.0700)  loss_rpn_box_reg: 0.0565 (0.0675)  time: 0.6923  data: 0.3038  max mem: 5923\n",
      "Training Epoch: [160]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1395 (0.1382)  loss_objectness: 0.0648 (0.0699)  loss_rpn_box_reg: 0.0695 (0.0683)  time: 0.6739  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [160]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1309 (0.1378)  loss_objectness: 0.0598 (0.0699)  loss_rpn_box_reg: 0.0634 (0.0680)  time: 0.6860  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [160]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1309 (0.1381)  loss_objectness: 0.0633 (0.0698)  loss_rpn_box_reg: 0.0539 (0.0683)  time: 0.6961  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [160]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1352 (0.1380)  loss_objectness: 0.0643 (0.0694)  loss_rpn_box_reg: 0.0686 (0.0686)  time: 0.6883  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [160]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1352 (0.1377)  loss_objectness: 0.0661 (0.0692)  loss_rpn_box_reg: 0.0653 (0.0685)  time: 0.6927  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [160]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1340 (0.1388)  loss_objectness: 0.0661 (0.0694)  loss_rpn_box_reg: 0.0653 (0.0694)  time: 0.6894  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [160]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1477 (0.1392)  loss_objectness: 0.0651 (0.0695)  loss_rpn_box_reg: 0.0798 (0.0698)  time: 0.6769  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [160]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1441 (0.1397)  loss_objectness: 0.0681 (0.0698)  loss_rpn_box_reg: 0.0676 (0.0698)  time: 0.6818  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [160]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1359 (0.1395)  loss_objectness: 0.0743 (0.0700)  loss_rpn_box_reg: 0.0655 (0.0695)  time: 0.6976  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [160]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1240 (0.1390)  loss_objectness: 0.0660 (0.0699)  loss_rpn_box_reg: 0.0590 (0.0690)  time: 0.6895  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [160]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1240 (0.1391)  loss_objectness: 0.0660 (0.0698)  loss_rpn_box_reg: 0.0590 (0.0693)  time: 0.6729  data: 0.2898  max mem: 5923\n",
      "Training Epoch: [160]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1383 (0.1393)  loss_objectness: 0.0701 (0.0699)  loss_rpn_box_reg: 0.0682 (0.0693)  time: 0.6731  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [160]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1449 (0.1395)  loss_objectness: 0.0728 (0.0699)  loss_rpn_box_reg: 0.0712 (0.0695)  time: 0.6829  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [160] Total time: 0:02:51 (0.6843 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:00  model_time: 0.6061 (0.6061)  evaluator_time: 0.0590 (0.0590)  time: 0.9682  data: 0.2871  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3981 (0.3940)  evaluator_time: 0.0730 (0.0802)  time: 0.7793  data: 0.2966  max mem: 5923\n",
      "Test: Total time: 0:00:48 (0.7838 s / it)\n",
      "Averaged stats: model_time: 0.3981 (0.3940)  evaluator_time: 0.0730 (0.0802)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.11s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.177\n",
      "Testing Epoch: [160]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1343 (0.1343)  loss_objectness: 0.0467 (0.0467)  loss_rpn_box_reg: 0.0876 (0.0876)  time: 0.7172  data: 0.3931  max mem: 5923\n",
      "Testing Epoch: [160]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1309 (0.1400)  loss_objectness: 0.0528 (0.0587)  loss_rpn_box_reg: 0.0738 (0.0813)  time: 0.6265  data: 0.3068  max mem: 5923\n",
      "Testing Epoch: [160] Total time: 0:00:39 (0.6325 s / it)\n",
      "Training Epoch: [161]  [  0/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1705 (0.1705)  loss_objectness: 0.0736 (0.0736)  loss_rpn_box_reg: 0.0969 (0.0969)  time: 0.6852  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [161]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1503 (0.1502)  loss_objectness: 0.0693 (0.0689)  loss_rpn_box_reg: 0.0753 (0.0814)  time: 0.6823  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [161]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1429 (0.1449)  loss_objectness: 0.0696 (0.0683)  loss_rpn_box_reg: 0.0688 (0.0766)  time: 0.6931  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [161]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1419 (0.1433)  loss_objectness: 0.0743 (0.0702)  loss_rpn_box_reg: 0.0666 (0.0731)  time: 0.6953  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [161]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1395 (0.1393)  loss_objectness: 0.0662 (0.0684)  loss_rpn_box_reg: 0.0581 (0.0709)  time: 0.6829  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [161]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1198 (0.1374)  loss_objectness: 0.0636 (0.0683)  loss_rpn_box_reg: 0.0580 (0.0691)  time: 0.6759  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [161]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1349 (0.1383)  loss_objectness: 0.0669 (0.0682)  loss_rpn_box_reg: 0.0612 (0.0701)  time: 0.6741  data: 0.2892  max mem: 5923\n",
      "Training Epoch: [161]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1392 (0.1391)  loss_objectness: 0.0752 (0.0693)  loss_rpn_box_reg: 0.0631 (0.0699)  time: 0.6819  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [161]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1467 (0.1399)  loss_objectness: 0.0760 (0.0703)  loss_rpn_box_reg: 0.0617 (0.0696)  time: 0.6760  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [161]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1397 (0.1399)  loss_objectness: 0.0745 (0.0705)  loss_rpn_box_reg: 0.0642 (0.0694)  time: 0.6818  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [161]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1405 (0.1405)  loss_objectness: 0.0701 (0.0703)  loss_rpn_box_reg: 0.0642 (0.0701)  time: 0.6903  data: 0.2876  max mem: 5923\n",
      "Training Epoch: [161]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1316 (0.1397)  loss_objectness: 0.0599 (0.0696)  loss_rpn_box_reg: 0.0628 (0.0701)  time: 0.6755  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [161]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1276 (0.1393)  loss_objectness: 0.0684 (0.0698)  loss_rpn_box_reg: 0.0618 (0.0695)  time: 0.6735  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [161]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1327 (0.1391)  loss_objectness: 0.0684 (0.0690)  loss_rpn_box_reg: 0.0690 (0.0702)  time: 0.6719  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [161]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1459 (0.1401)  loss_objectness: 0.0671 (0.0698)  loss_rpn_box_reg: 0.0756 (0.0703)  time: 0.6732  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [161]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1447 (0.1395)  loss_objectness: 0.0673 (0.0695)  loss_rpn_box_reg: 0.0701 (0.0701)  time: 0.6831  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [161]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1329 (0.1398)  loss_objectness: 0.0630 (0.0695)  loss_rpn_box_reg: 0.0641 (0.0703)  time: 0.6756  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [161]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1462 (0.1406)  loss_objectness: 0.0688 (0.0698)  loss_rpn_box_reg: 0.0790 (0.0708)  time: 0.6852  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [161]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1509 (0.1415)  loss_objectness: 0.0760 (0.0707)  loss_rpn_box_reg: 0.0768 (0.0708)  time: 0.7085  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [161]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1344 (0.1410)  loss_objectness: 0.0753 (0.0709)  loss_rpn_box_reg: 0.0656 (0.0701)  time: 0.6992  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [161]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1268 (0.1404)  loss_objectness: 0.0672 (0.0706)  loss_rpn_box_reg: 0.0594 (0.0698)  time: 0.6920  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [161]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1341 (0.1404)  loss_objectness: 0.0652 (0.0704)  loss_rpn_box_reg: 0.0625 (0.0700)  time: 0.6976  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [161]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1378 (0.1405)  loss_objectness: 0.0693 (0.0706)  loss_rpn_box_reg: 0.0721 (0.0699)  time: 0.6996  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [161]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1345 (0.1402)  loss_objectness: 0.0662 (0.0705)  loss_rpn_box_reg: 0.0647 (0.0697)  time: 0.6967  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [161]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1266 (0.1399)  loss_objectness: 0.0683 (0.0707)  loss_rpn_box_reg: 0.0571 (0.0692)  time: 0.6948  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [161]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1309 (0.1403)  loss_objectness: 0.0732 (0.0711)  loss_rpn_box_reg: 0.0565 (0.0692)  time: 0.6920  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [161] Total time: 0:02:51 (0.6863 s / it)\n",
      "Testing Epoch: [161]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1406 (0.1406)  loss_objectness: 0.0500 (0.0500)  loss_rpn_box_reg: 0.0906 (0.0906)  time: 0.6201  data: 0.2951  max mem: 5923\n",
      "Testing Epoch: [161]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1331 (0.1418)  loss_objectness: 0.0549 (0.0607)  loss_rpn_box_reg: 0.0751 (0.0811)  time: 0.6400  data: 0.3083  max mem: 5923\n",
      "Testing Epoch: [161] Total time: 0:00:39 (0.6390 s / it)\n",
      "Training Epoch: [162]  [  0/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1238 (0.1238)  loss_objectness: 0.0498 (0.0498)  loss_rpn_box_reg: 0.0740 (0.0740)  time: 0.6181  data: 0.2971  max mem: 5923\n",
      "Training Epoch: [162]  [ 10/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1241 (0.1326)  loss_objectness: 0.0699 (0.0702)  loss_rpn_box_reg: 0.0616 (0.0624)  time: 0.6763  data: 0.2994  max mem: 5923\n",
      "Training Epoch: [162]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1211 (0.1332)  loss_objectness: 0.0625 (0.0697)  loss_rpn_box_reg: 0.0616 (0.0635)  time: 0.6847  data: 0.2960  max mem: 5923\n",
      "Training Epoch: [162]  [ 30/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1300 (0.1391)  loss_objectness: 0.0670 (0.0709)  loss_rpn_box_reg: 0.0679 (0.0683)  time: 0.6759  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [162]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1265 (0.1350)  loss_objectness: 0.0670 (0.0706)  loss_rpn_box_reg: 0.0604 (0.0644)  time: 0.6806  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [162]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1265 (0.1380)  loss_objectness: 0.0722 (0.0716)  loss_rpn_box_reg: 0.0591 (0.0664)  time: 0.6931  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [162]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1418 (0.1377)  loss_objectness: 0.0715 (0.0710)  loss_rpn_box_reg: 0.0753 (0.0668)  time: 0.6975  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [162]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1388 (0.1394)  loss_objectness: 0.0694 (0.0715)  loss_rpn_box_reg: 0.0752 (0.0679)  time: 0.6863  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [162]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1385 (0.1391)  loss_objectness: 0.0680 (0.0710)  loss_rpn_box_reg: 0.0745 (0.0681)  time: 0.6674  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [162]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1247 (0.1378)  loss_objectness: 0.0662 (0.0702)  loss_rpn_box_reg: 0.0654 (0.0676)  time: 0.6665  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [162]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1353 (0.1382)  loss_objectness: 0.0702 (0.0699)  loss_rpn_box_reg: 0.0662 (0.0683)  time: 0.6864  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [162]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1385 (0.1384)  loss_objectness: 0.0695 (0.0696)  loss_rpn_box_reg: 0.0662 (0.0687)  time: 0.6995  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [162]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1350 (0.1380)  loss_objectness: 0.0636 (0.0693)  loss_rpn_box_reg: 0.0614 (0.0687)  time: 0.6798  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [162]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1389 (0.1390)  loss_objectness: 0.0636 (0.0696)  loss_rpn_box_reg: 0.0684 (0.0694)  time: 0.6798  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [162]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1367 (0.1390)  loss_objectness: 0.0718 (0.0699)  loss_rpn_box_reg: 0.0700 (0.0691)  time: 0.6845  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [162]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1276 (0.1380)  loss_objectness: 0.0679 (0.0694)  loss_rpn_box_reg: 0.0627 (0.0686)  time: 0.6838  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [162]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1247 (0.1381)  loss_objectness: 0.0664 (0.0695)  loss_rpn_box_reg: 0.0627 (0.0686)  time: 0.7011  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [162]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1349 (0.1379)  loss_objectness: 0.0673 (0.0694)  loss_rpn_box_reg: 0.0669 (0.0685)  time: 0.7003  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [162]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1346 (0.1384)  loss_objectness: 0.0673 (0.0698)  loss_rpn_box_reg: 0.0669 (0.0686)  time: 0.6930  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [162]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1335 (0.1385)  loss_objectness: 0.0717 (0.0699)  loss_rpn_box_reg: 0.0647 (0.0686)  time: 0.6846  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [162]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1314 (0.1388)  loss_objectness: 0.0717 (0.0703)  loss_rpn_box_reg: 0.0628 (0.0685)  time: 0.6735  data: 0.2969  max mem: 5923\n",
      "Training Epoch: [162]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1448 (0.1392)  loss_objectness: 0.0689 (0.0701)  loss_rpn_box_reg: 0.0659 (0.0691)  time: 0.6853  data: 0.2976  max mem: 5923\n",
      "Training Epoch: [162]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1442 (0.1395)  loss_objectness: 0.0701 (0.0706)  loss_rpn_box_reg: 0.0659 (0.0689)  time: 0.7033  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [162]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1442 (0.1397)  loss_objectness: 0.0759 (0.0705)  loss_rpn_box_reg: 0.0683 (0.0691)  time: 0.7065  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [162]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1535 (0.1403)  loss_objectness: 0.0666 (0.0705)  loss_rpn_box_reg: 0.0793 (0.0698)  time: 0.6828  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [162]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1486 (0.1399)  loss_objectness: 0.0675 (0.0704)  loss_rpn_box_reg: 0.0742 (0.0695)  time: 0.6705  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [162] Total time: 0:02:51 (0.6855 s / it)\n",
      "Testing Epoch: [162]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1337 (0.1337)  loss_objectness: 0.0455 (0.0455)  loss_rpn_box_reg: 0.0882 (0.0882)  time: 0.6231  data: 0.3021  max mem: 5923\n",
      "Testing Epoch: [162]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1285 (0.1380)  loss_objectness: 0.0560 (0.0583)  loss_rpn_box_reg: 0.0685 (0.0797)  time: 0.6299  data: 0.3058  max mem: 5923\n",
      "Testing Epoch: [162] Total time: 0:00:39 (0.6313 s / it)\n",
      "Training Epoch: [163]  [  0/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1577 (0.1577)  loss_objectness: 0.0649 (0.0649)  loss_rpn_box_reg: 0.0929 (0.0929)  time: 0.6611  data: 0.2861  max mem: 5923\n",
      "Training Epoch: [163]  [ 10/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1302 (0.1359)  loss_objectness: 0.0669 (0.0665)  loss_rpn_box_reg: 0.0758 (0.0694)  time: 0.6611  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [163]  [ 20/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1270 (0.1376)  loss_objectness: 0.0669 (0.0686)  loss_rpn_box_reg: 0.0640 (0.0690)  time: 0.6765  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [163]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1292 (0.1385)  loss_objectness: 0.0678 (0.0690)  loss_rpn_box_reg: 0.0646 (0.0695)  time: 0.6876  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [163]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1306 (0.1355)  loss_objectness: 0.0633 (0.0666)  loss_rpn_box_reg: 0.0639 (0.0689)  time: 0.6790  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [163]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1316 (0.1357)  loss_objectness: 0.0635 (0.0675)  loss_rpn_box_reg: 0.0603 (0.0681)  time: 0.6858  data: 0.2879  max mem: 5923\n",
      "Training Epoch: [163]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1290 (0.1345)  loss_objectness: 0.0674 (0.0678)  loss_rpn_box_reg: 0.0574 (0.0667)  time: 0.7070  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [163]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1230 (0.1342)  loss_objectness: 0.0656 (0.0687)  loss_rpn_box_reg: 0.0570 (0.0655)  time: 0.7007  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [163]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1417 (0.1363)  loss_objectness: 0.0661 (0.0701)  loss_rpn_box_reg: 0.0582 (0.0662)  time: 0.6818  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [163]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1548 (0.1374)  loss_objectness: 0.0614 (0.0694)  loss_rpn_box_reg: 0.0699 (0.0680)  time: 0.6775  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [163]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1308 (0.1373)  loss_objectness: 0.0606 (0.0696)  loss_rpn_box_reg: 0.0694 (0.0677)  time: 0.6786  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [163]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1408 (0.1381)  loss_objectness: 0.0675 (0.0695)  loss_rpn_box_reg: 0.0630 (0.0687)  time: 0.6847  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [163]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1458 (0.1389)  loss_objectness: 0.0718 (0.0701)  loss_rpn_box_reg: 0.0751 (0.0688)  time: 0.6894  data: 0.2966  max mem: 5923\n",
      "Training Epoch: [163]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1263 (0.1378)  loss_objectness: 0.0672 (0.0698)  loss_rpn_box_reg: 0.0607 (0.0680)  time: 0.6917  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [163]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1250 (0.1382)  loss_objectness: 0.0672 (0.0700)  loss_rpn_box_reg: 0.0528 (0.0682)  time: 0.6828  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [163]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1471 (0.1385)  loss_objectness: 0.0632 (0.0696)  loss_rpn_box_reg: 0.0775 (0.0689)  time: 0.6818  data: 0.2882  max mem: 5923\n",
      "Training Epoch: [163]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1311 (0.1385)  loss_objectness: 0.0631 (0.0695)  loss_rpn_box_reg: 0.0682 (0.0690)  time: 0.6898  data: 0.2889  max mem: 5923\n",
      "Training Epoch: [163]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1324 (0.1386)  loss_objectness: 0.0678 (0.0695)  loss_rpn_box_reg: 0.0573 (0.0690)  time: 0.6761  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [163]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1424 (0.1389)  loss_objectness: 0.0735 (0.0697)  loss_rpn_box_reg: 0.0682 (0.0692)  time: 0.6758  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [163]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1418 (0.1392)  loss_objectness: 0.0742 (0.0702)  loss_rpn_box_reg: 0.0660 (0.0689)  time: 0.6853  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [163]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1418 (0.1394)  loss_objectness: 0.0710 (0.0704)  loss_rpn_box_reg: 0.0642 (0.0691)  time: 0.6829  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [163]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1480 (0.1398)  loss_objectness: 0.0740 (0.0705)  loss_rpn_box_reg: 0.0656 (0.0693)  time: 0.6710  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [163]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1467 (0.1395)  loss_objectness: 0.0683 (0.0704)  loss_rpn_box_reg: 0.0656 (0.0690)  time: 0.6656  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [163]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1494 (0.1403)  loss_objectness: 0.0708 (0.0708)  loss_rpn_box_reg: 0.0705 (0.0695)  time: 0.6865  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [163]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1519 (0.1408)  loss_objectness: 0.0755 (0.0711)  loss_rpn_box_reg: 0.0800 (0.0697)  time: 0.6847  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [163]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1441 (0.1405)  loss_objectness: 0.0762 (0.0711)  loss_rpn_box_reg: 0.0634 (0.0694)  time: 0.6759  data: 0.2898  max mem: 5923\n",
      "Training Epoch: [163] Total time: 0:02:50 (0.6829 s / it)\n",
      "Testing Epoch: [163]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1414 (0.1414)  loss_objectness: 0.0510 (0.0510)  loss_rpn_box_reg: 0.0903 (0.0903)  time: 0.6201  data: 0.2911  max mem: 5923\n",
      "Testing Epoch: [163]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1342 (0.1459)  loss_objectness: 0.0592 (0.0645)  loss_rpn_box_reg: 0.0776 (0.0814)  time: 0.6250  data: 0.3050  max mem: 5923\n",
      "Testing Epoch: [163] Total time: 0:00:39 (0.6350 s / it)\n",
      "Training Epoch: [164]  [  0/250]  eta: 0:03:07  lr: 0.000300  loss: 0.1615 (0.1615)  loss_objectness: 0.0681 (0.0681)  loss_rpn_box_reg: 0.0935 (0.0935)  time: 0.7502  data: 0.2991  max mem: 5923\n",
      "Training Epoch: [164]  [ 10/250]  eta: 0:02:49  lr: 0.000300  loss: 0.1311 (0.1332)  loss_objectness: 0.0609 (0.0624)  loss_rpn_box_reg: 0.0710 (0.0708)  time: 0.7077  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [164]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1344 (0.1366)  loss_objectness: 0.0624 (0.0657)  loss_rpn_box_reg: 0.0682 (0.0708)  time: 0.6944  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [164]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1377 (0.1332)  loss_objectness: 0.0624 (0.0636)  loss_rpn_box_reg: 0.0674 (0.0697)  time: 0.6855  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [164]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1383 (0.1358)  loss_objectness: 0.0681 (0.0686)  loss_rpn_box_reg: 0.0625 (0.0672)  time: 0.6799  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [164]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1452 (0.1369)  loss_objectness: 0.0693 (0.0709)  loss_rpn_box_reg: 0.0570 (0.0660)  time: 0.6759  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [164]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1392 (0.1370)  loss_objectness: 0.0686 (0.0703)  loss_rpn_box_reg: 0.0660 (0.0667)  time: 0.6805  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [164]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1361 (0.1377)  loss_objectness: 0.0614 (0.0703)  loss_rpn_box_reg: 0.0664 (0.0674)  time: 0.6865  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [164]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1232 (0.1370)  loss_objectness: 0.0641 (0.0704)  loss_rpn_box_reg: 0.0623 (0.0666)  time: 0.6863  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [164]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1392 (0.1386)  loss_objectness: 0.0710 (0.0707)  loss_rpn_box_reg: 0.0643 (0.0678)  time: 0.6819  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [164]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1382 (0.1378)  loss_objectness: 0.0710 (0.0707)  loss_rpn_box_reg: 0.0643 (0.0671)  time: 0.6783  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [164]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1382 (0.1395)  loss_objectness: 0.0686 (0.0705)  loss_rpn_box_reg: 0.0698 (0.0691)  time: 0.6731  data: 0.2880  max mem: 5923\n",
      "Training Epoch: [164]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1436 (0.1402)  loss_objectness: 0.0708 (0.0712)  loss_rpn_box_reg: 0.0722 (0.0691)  time: 0.6843  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [164]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1263 (0.1396)  loss_objectness: 0.0623 (0.0703)  loss_rpn_box_reg: 0.0636 (0.0692)  time: 0.6739  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [164]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1316 (0.1403)  loss_objectness: 0.0623 (0.0707)  loss_rpn_box_reg: 0.0716 (0.0696)  time: 0.6662  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [164]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1477 (0.1411)  loss_objectness: 0.0696 (0.0707)  loss_rpn_box_reg: 0.0726 (0.0703)  time: 0.6799  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [164]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1438 (0.1409)  loss_objectness: 0.0696 (0.0708)  loss_rpn_box_reg: 0.0671 (0.0702)  time: 0.6721  data: 0.2892  max mem: 5923\n",
      "Training Epoch: [164]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1358 (0.1407)  loss_objectness: 0.0686 (0.0707)  loss_rpn_box_reg: 0.0629 (0.0700)  time: 0.6832  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [164]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1269 (0.1408)  loss_objectness: 0.0724 (0.0709)  loss_rpn_box_reg: 0.0604 (0.0699)  time: 0.6853  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [164]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1295 (0.1405)  loss_objectness: 0.0727 (0.0710)  loss_rpn_box_reg: 0.0591 (0.0695)  time: 0.6828  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [164]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1365 (0.1413)  loss_objectness: 0.0726 (0.0714)  loss_rpn_box_reg: 0.0699 (0.0698)  time: 0.6833  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [164]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1383 (0.1416)  loss_objectness: 0.0671 (0.0715)  loss_rpn_box_reg: 0.0776 (0.0701)  time: 0.6804  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [164]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1393 (0.1415)  loss_objectness: 0.0728 (0.0716)  loss_rpn_box_reg: 0.0655 (0.0700)  time: 0.6865  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [164]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1365 (0.1411)  loss_objectness: 0.0686 (0.0716)  loss_rpn_box_reg: 0.0620 (0.0695)  time: 0.6940  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [164]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1282 (0.1411)  loss_objectness: 0.0650 (0.0714)  loss_rpn_box_reg: 0.0671 (0.0697)  time: 0.7021  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [164]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1320 (0.1411)  loss_objectness: 0.0688 (0.0714)  loss_rpn_box_reg: 0.0771 (0.0697)  time: 0.6995  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [164] Total time: 0:02:51 (0.6840 s / it)\n",
      "Testing Epoch: [164]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1361 (0.1361)  loss_objectness: 0.0461 (0.0461)  loss_rpn_box_reg: 0.0899 (0.0899)  time: 0.6221  data: 0.2861  max mem: 5923\n",
      "Testing Epoch: [164]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1383 (0.1451)  loss_objectness: 0.0620 (0.0649)  loss_rpn_box_reg: 0.0680 (0.0801)  time: 0.6324  data: 0.3118  max mem: 5923\n",
      "Testing Epoch: [164] Total time: 0:00:39 (0.6362 s / it)\n",
      "Training Epoch: [165]  [  0/250]  eta: 0:03:08  lr: 0.000300  loss: 0.1071 (0.1071)  loss_objectness: 0.0799 (0.0799)  loss_rpn_box_reg: 0.0271 (0.0271)  time: 0.7542  data: 0.3101  max mem: 5923\n",
      "Training Epoch: [165]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1452 (0.1373)  loss_objectness: 0.0799 (0.0737)  loss_rpn_box_reg: 0.0609 (0.0636)  time: 0.6869  data: 0.2973  max mem: 5923\n",
      "Training Epoch: [165]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1423 (0.1356)  loss_objectness: 0.0695 (0.0712)  loss_rpn_box_reg: 0.0652 (0.0644)  time: 0.6938  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [165]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1357 (0.1363)  loss_objectness: 0.0695 (0.0727)  loss_rpn_box_reg: 0.0595 (0.0636)  time: 0.6904  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [165]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1341 (0.1357)  loss_objectness: 0.0733 (0.0725)  loss_rpn_box_reg: 0.0595 (0.0632)  time: 0.6880  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [165]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1348 (0.1409)  loss_objectness: 0.0733 (0.0738)  loss_rpn_box_reg: 0.0678 (0.0671)  time: 0.6876  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [165]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1467 (0.1388)  loss_objectness: 0.0757 (0.0728)  loss_rpn_box_reg: 0.0680 (0.0660)  time: 0.6788  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [165]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1394 (0.1398)  loss_objectness: 0.0708 (0.0724)  loss_rpn_box_reg: 0.0713 (0.0674)  time: 0.6874  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [165]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1359 (0.1394)  loss_objectness: 0.0638 (0.0715)  loss_rpn_box_reg: 0.0734 (0.0679)  time: 0.6911  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [165]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1332 (0.1393)  loss_objectness: 0.0604 (0.0707)  loss_rpn_box_reg: 0.0727 (0.0686)  time: 0.6938  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [165]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1356 (0.1401)  loss_objectness: 0.0609 (0.0707)  loss_rpn_box_reg: 0.0783 (0.0694)  time: 0.6876  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [165]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1422 (0.1406)  loss_objectness: 0.0611 (0.0713)  loss_rpn_box_reg: 0.0783 (0.0693)  time: 0.6674  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [165]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1303 (0.1389)  loss_objectness: 0.0702 (0.0708)  loss_rpn_box_reg: 0.0471 (0.0681)  time: 0.6857  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [165]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1307 (0.1395)  loss_objectness: 0.0702 (0.0716)  loss_rpn_box_reg: 0.0578 (0.0679)  time: 0.7000  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [165]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1369 (0.1391)  loss_objectness: 0.0679 (0.0709)  loss_rpn_box_reg: 0.0635 (0.0682)  time: 0.6806  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [165]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1339 (0.1388)  loss_objectness: 0.0611 (0.0705)  loss_rpn_box_reg: 0.0645 (0.0683)  time: 0.6831  data: 0.2875  max mem: 5923\n",
      "Training Epoch: [165]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1379 (0.1398)  loss_objectness: 0.0683 (0.0708)  loss_rpn_box_reg: 0.0720 (0.0690)  time: 0.6892  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [165]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1495 (0.1404)  loss_objectness: 0.0760 (0.0714)  loss_rpn_box_reg: 0.0744 (0.0690)  time: 0.6920  data: 0.2966  max mem: 5923\n",
      "Training Epoch: [165]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1495 (0.1412)  loss_objectness: 0.0782 (0.0721)  loss_rpn_box_reg: 0.0678 (0.0691)  time: 0.6887  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [165]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1302 (0.1405)  loss_objectness: 0.0719 (0.0715)  loss_rpn_box_reg: 0.0655 (0.0690)  time: 0.6963  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [165]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1302 (0.1408)  loss_objectness: 0.0703 (0.0720)  loss_rpn_box_reg: 0.0655 (0.0687)  time: 0.6895  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [165]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1340 (0.1403)  loss_objectness: 0.0700 (0.0719)  loss_rpn_box_reg: 0.0652 (0.0684)  time: 0.6873  data: 0.2898  max mem: 5923\n",
      "Training Epoch: [165]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1261 (0.1401)  loss_objectness: 0.0676 (0.0717)  loss_rpn_box_reg: 0.0545 (0.0684)  time: 0.6964  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [165]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1377 (0.1403)  loss_objectness: 0.0748 (0.0720)  loss_rpn_box_reg: 0.0629 (0.0683)  time: 0.6945  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [165]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1417 (0.1405)  loss_objectness: 0.0748 (0.0719)  loss_rpn_box_reg: 0.0708 (0.0686)  time: 0.6860  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [165]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1472 (0.1413)  loss_objectness: 0.0717 (0.0718)  loss_rpn_box_reg: 0.0764 (0.0696)  time: 0.6820  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [165] Total time: 0:02:52 (0.6886 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:02  model_time: 0.6742 (0.6742)  evaluator_time: 0.0490 (0.0490)  time: 1.0142  data: 0.2761  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3681 (0.3672)  evaluator_time: 0.0570 (0.0647)  time: 0.7344  data: 0.3068  max mem: 5923\n",
      "Test: Total time: 0:00:46 (0.7429 s / it)\n",
      "Averaged stats: model_time: 0.3681 (0.3672)  evaluator_time: 0.0570 (0.0647)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.95s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.094\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.047\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.154\n",
      "Testing Epoch: [165]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1328 (0.1328)  loss_objectness: 0.0448 (0.0448)  loss_rpn_box_reg: 0.0881 (0.0881)  time: 0.6181  data: 0.2941  max mem: 5923\n",
      "Testing Epoch: [165]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1352 (0.1406)  loss_objectness: 0.0547 (0.0590)  loss_rpn_box_reg: 0.0710 (0.0817)  time: 0.6273  data: 0.3068  max mem: 5923\n",
      "Testing Epoch: [165] Total time: 0:00:39 (0.6297 s / it)\n",
      "Training Epoch: [166]  [  0/250]  eta: 0:02:49  lr: 0.000300  loss: 0.1408 (0.1408)  loss_objectness: 0.0659 (0.0659)  loss_rpn_box_reg: 0.0749 (0.0749)  time: 0.6792  data: 0.2981  max mem: 5923\n",
      "Training Epoch: [166]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1342 (0.1368)  loss_objectness: 0.0659 (0.0656)  loss_rpn_box_reg: 0.0698 (0.0712)  time: 0.6837  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [166]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1276 (0.1325)  loss_objectness: 0.0667 (0.0677)  loss_rpn_box_reg: 0.0591 (0.0648)  time: 0.6806  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [166]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1351 (0.1373)  loss_objectness: 0.0740 (0.0699)  loss_rpn_box_reg: 0.0578 (0.0674)  time: 0.6740  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [166]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1392 (0.1382)  loss_objectness: 0.0740 (0.0695)  loss_rpn_box_reg: 0.0693 (0.0687)  time: 0.6804  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [166]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1315 (0.1362)  loss_objectness: 0.0693 (0.0692)  loss_rpn_box_reg: 0.0629 (0.0670)  time: 0.6854  data: 0.2876  max mem: 5923\n",
      "Training Epoch: [166]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1378 (0.1370)  loss_objectness: 0.0684 (0.0687)  loss_rpn_box_reg: 0.0673 (0.0682)  time: 0.6833  data: 0.2865  max mem: 5923\n",
      "Training Epoch: [166]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1328 (0.1355)  loss_objectness: 0.0675 (0.0684)  loss_rpn_box_reg: 0.0673 (0.0671)  time: 0.6821  data: 0.2876  max mem: 5923\n",
      "Training Epoch: [166]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1242 (0.1338)  loss_objectness: 0.0655 (0.0676)  loss_rpn_box_reg: 0.0608 (0.0662)  time: 0.6808  data: 0.2878  max mem: 5923\n",
      "Training Epoch: [166]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1249 (0.1356)  loss_objectness: 0.0681 (0.0685)  loss_rpn_box_reg: 0.0550 (0.0672)  time: 0.6825  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [166]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1401 (0.1367)  loss_objectness: 0.0733 (0.0689)  loss_rpn_box_reg: 0.0574 (0.0678)  time: 0.6873  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [166]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1395 (0.1369)  loss_objectness: 0.0645 (0.0688)  loss_rpn_box_reg: 0.0741 (0.0680)  time: 0.6825  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [166]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1289 (0.1357)  loss_objectness: 0.0636 (0.0682)  loss_rpn_box_reg: 0.0741 (0.0675)  time: 0.6793  data: 0.2859  max mem: 5923\n",
      "Training Epoch: [166]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1289 (0.1363)  loss_objectness: 0.0636 (0.0687)  loss_rpn_box_reg: 0.0624 (0.0676)  time: 0.6757  data: 0.2872  max mem: 5923\n",
      "Training Epoch: [166]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1476 (0.1377)  loss_objectness: 0.0707 (0.0689)  loss_rpn_box_reg: 0.0741 (0.0688)  time: 0.6811  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [166]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1395 (0.1371)  loss_objectness: 0.0674 (0.0691)  loss_rpn_box_reg: 0.0711 (0.0680)  time: 0.6920  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [166]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1297 (0.1371)  loss_objectness: 0.0672 (0.0692)  loss_rpn_box_reg: 0.0626 (0.0679)  time: 0.6723  data: 0.2876  max mem: 5923\n",
      "Training Epoch: [166]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1328 (0.1370)  loss_objectness: 0.0683 (0.0693)  loss_rpn_box_reg: 0.0683 (0.0677)  time: 0.6663  data: 0.2879  max mem: 5923\n",
      "Training Epoch: [166]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1416 (0.1376)  loss_objectness: 0.0723 (0.0692)  loss_rpn_box_reg: 0.0721 (0.0684)  time: 0.6822  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [166]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1373 (0.1376)  loss_objectness: 0.0672 (0.0689)  loss_rpn_box_reg: 0.0759 (0.0688)  time: 0.6934  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [166]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1373 (0.1380)  loss_objectness: 0.0637 (0.0687)  loss_rpn_box_reg: 0.0759 (0.0692)  time: 0.6861  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [166]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1460 (0.1383)  loss_objectness: 0.0638 (0.0687)  loss_rpn_box_reg: 0.0771 (0.0696)  time: 0.6670  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [166]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1460 (0.1385)  loss_objectness: 0.0725 (0.0690)  loss_rpn_box_reg: 0.0668 (0.0695)  time: 0.6751  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [166]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1373 (0.1383)  loss_objectness: 0.0691 (0.0688)  loss_rpn_box_reg: 0.0668 (0.0696)  time: 0.6892  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [166]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1288 (0.1385)  loss_objectness: 0.0654 (0.0689)  loss_rpn_box_reg: 0.0733 (0.0696)  time: 0.6933  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [166]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1318 (0.1386)  loss_objectness: 0.0660 (0.0690)  loss_rpn_box_reg: 0.0733 (0.0696)  time: 0.7030  data: 0.2894  max mem: 5923\n",
      "Training Epoch: [166] Total time: 0:02:50 (0.6829 s / it)\n",
      "Testing Epoch: [166]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1371 (0.1371)  loss_objectness: 0.0491 (0.0491)  loss_rpn_box_reg: 0.0880 (0.0880)  time: 0.6111  data: 0.2841  max mem: 5923\n",
      "Testing Epoch: [166]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1368 (0.1397)  loss_objectness: 0.0557 (0.0592)  loss_rpn_box_reg: 0.0735 (0.0805)  time: 0.6309  data: 0.3106  max mem: 5923\n",
      "Testing Epoch: [166] Total time: 0:00:39 (0.6307 s / it)\n",
      "Training Epoch: [167]  [  0/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1038 (0.1038)  loss_objectness: 0.0449 (0.0449)  loss_rpn_box_reg: 0.0589 (0.0589)  time: 0.6371  data: 0.2811  max mem: 5923\n",
      "Training Epoch: [167]  [ 10/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1284 (0.1318)  loss_objectness: 0.0630 (0.0617)  loss_rpn_box_reg: 0.0606 (0.0701)  time: 0.6909  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [167]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1316 (0.1383)  loss_objectness: 0.0728 (0.0697)  loss_rpn_box_reg: 0.0614 (0.0685)  time: 0.6833  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [167]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1279 (0.1376)  loss_objectness: 0.0709 (0.0681)  loss_rpn_box_reg: 0.0624 (0.0695)  time: 0.6842  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [167]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1279 (0.1386)  loss_objectness: 0.0599 (0.0682)  loss_rpn_box_reg: 0.0657 (0.0705)  time: 0.6895  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [167]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1345 (0.1364)  loss_objectness: 0.0599 (0.0678)  loss_rpn_box_reg: 0.0655 (0.0686)  time: 0.6859  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [167]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1283 (0.1369)  loss_objectness: 0.0622 (0.0676)  loss_rpn_box_reg: 0.0643 (0.0693)  time: 0.6863  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [167]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1283 (0.1359)  loss_objectness: 0.0599 (0.0666)  loss_rpn_box_reg: 0.0670 (0.0693)  time: 0.6937  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [167]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1309 (0.1366)  loss_objectness: 0.0622 (0.0670)  loss_rpn_box_reg: 0.0663 (0.0696)  time: 0.6928  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [167]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1351 (0.1364)  loss_objectness: 0.0665 (0.0676)  loss_rpn_box_reg: 0.0663 (0.0688)  time: 0.6771  data: 0.2880  max mem: 5923\n",
      "Training Epoch: [167]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1327 (0.1359)  loss_objectness: 0.0712 (0.0683)  loss_rpn_box_reg: 0.0585 (0.0676)  time: 0.6835  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [167]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1304 (0.1359)  loss_objectness: 0.0717 (0.0689)  loss_rpn_box_reg: 0.0533 (0.0670)  time: 0.6840  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [167]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1350 (0.1364)  loss_objectness: 0.0701 (0.0692)  loss_rpn_box_reg: 0.0649 (0.0671)  time: 0.6720  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [167]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1370 (0.1364)  loss_objectness: 0.0701 (0.0694)  loss_rpn_box_reg: 0.0649 (0.0671)  time: 0.6653  data: 0.2856  max mem: 5923\n",
      "Training Epoch: [167]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1401 (0.1375)  loss_objectness: 0.0699 (0.0696)  loss_rpn_box_reg: 0.0649 (0.0679)  time: 0.6733  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [167]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1439 (0.1385)  loss_objectness: 0.0791 (0.0705)  loss_rpn_box_reg: 0.0644 (0.0680)  time: 0.6744  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [167]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1411 (0.1392)  loss_objectness: 0.0760 (0.0706)  loss_rpn_box_reg: 0.0647 (0.0686)  time: 0.6677  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [167]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1346 (0.1384)  loss_objectness: 0.0655 (0.0705)  loss_rpn_box_reg: 0.0611 (0.0680)  time: 0.6818  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [167]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1388 (0.1394)  loss_objectness: 0.0655 (0.0703)  loss_rpn_box_reg: 0.0621 (0.0691)  time: 0.6877  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [167]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1516 (0.1397)  loss_objectness: 0.0682 (0.0705)  loss_rpn_box_reg: 0.0773 (0.0692)  time: 0.6771  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [167]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1288 (0.1389)  loss_objectness: 0.0682 (0.0701)  loss_rpn_box_reg: 0.0563 (0.0688)  time: 0.6863  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [167]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1397 (0.1395)  loss_objectness: 0.0646 (0.0701)  loss_rpn_box_reg: 0.0686 (0.0694)  time: 0.6944  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [167]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1406 (0.1392)  loss_objectness: 0.0672 (0.0701)  loss_rpn_box_reg: 0.0680 (0.0691)  time: 0.6812  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [167]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1366 (0.1391)  loss_objectness: 0.0673 (0.0699)  loss_rpn_box_reg: 0.0590 (0.0692)  time: 0.6831  data: 0.2882  max mem: 5923\n",
      "Training Epoch: [167]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1339 (0.1394)  loss_objectness: 0.0662 (0.0701)  loss_rpn_box_reg: 0.0677 (0.0693)  time: 0.6796  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [167]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1339 (0.1397)  loss_objectness: 0.0664 (0.0702)  loss_rpn_box_reg: 0.0710 (0.0695)  time: 0.6706  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [167] Total time: 0:02:50 (0.6814 s / it)\n",
      "Testing Epoch: [167]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1335 (0.1335)  loss_objectness: 0.0472 (0.0472)  loss_rpn_box_reg: 0.0863 (0.0863)  time: 0.6171  data: 0.2911  max mem: 5923\n",
      "Testing Epoch: [167]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1329 (0.1401)  loss_objectness: 0.0548 (0.0598)  loss_rpn_box_reg: 0.0703 (0.0804)  time: 0.6273  data: 0.3053  max mem: 5923\n",
      "Testing Epoch: [167] Total time: 0:00:39 (0.6325 s / it)\n",
      "Training Epoch: [168]  [  0/250]  eta: 0:02:56  lr: 0.000300  loss: 0.1687 (0.1687)  loss_objectness: 0.1137 (0.1137)  loss_rpn_box_reg: 0.0549 (0.0549)  time: 0.7042  data: 0.3001  max mem: 5923\n",
      "Training Epoch: [168]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1448 (0.1411)  loss_objectness: 0.0710 (0.0766)  loss_rpn_box_reg: 0.0592 (0.0645)  time: 0.6836  data: 0.2965  max mem: 5923\n",
      "Training Epoch: [168]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1368 (0.1383)  loss_objectness: 0.0706 (0.0742)  loss_rpn_box_reg: 0.0594 (0.0641)  time: 0.6865  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [168]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1359 (0.1375)  loss_objectness: 0.0716 (0.0733)  loss_rpn_box_reg: 0.0595 (0.0642)  time: 0.6884  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [168]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1398 (0.1430)  loss_objectness: 0.0734 (0.0729)  loss_rpn_box_reg: 0.0754 (0.0701)  time: 0.6773  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [168]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1432 (0.1433)  loss_objectness: 0.0650 (0.0715)  loss_rpn_box_reg: 0.0801 (0.0718)  time: 0.6823  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [168]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1373 (0.1407)  loss_objectness: 0.0668 (0.0718)  loss_rpn_box_reg: 0.0632 (0.0689)  time: 0.6807  data: 0.2967  max mem: 5923\n",
      "Training Epoch: [168]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1249 (0.1390)  loss_objectness: 0.0743 (0.0712)  loss_rpn_box_reg: 0.0537 (0.0678)  time: 0.6674  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [168]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1303 (0.1388)  loss_objectness: 0.0687 (0.0713)  loss_rpn_box_reg: 0.0597 (0.0676)  time: 0.6675  data: 0.2883  max mem: 5923\n",
      "Training Epoch: [168]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1378 (0.1396)  loss_objectness: 0.0620 (0.0711)  loss_rpn_box_reg: 0.0633 (0.0685)  time: 0.6682  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [168]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1356 (0.1403)  loss_objectness: 0.0635 (0.0707)  loss_rpn_box_reg: 0.0745 (0.0697)  time: 0.6682  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [168]  [110/250]  eta: 0:01:34  lr: 0.000300  loss: 0.1376 (0.1399)  loss_objectness: 0.0640 (0.0710)  loss_rpn_box_reg: 0.0619 (0.0689)  time: 0.6823  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [168]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1376 (0.1395)  loss_objectness: 0.0691 (0.0710)  loss_rpn_box_reg: 0.0592 (0.0685)  time: 0.6963  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [168]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1314 (0.1397)  loss_objectness: 0.0645 (0.0705)  loss_rpn_box_reg: 0.0637 (0.0691)  time: 0.6766  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [168]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1296 (0.1396)  loss_objectness: 0.0660 (0.0711)  loss_rpn_box_reg: 0.0588 (0.0685)  time: 0.6684  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [168]  [150/250]  eta: 0:01:07  lr: 0.000300  loss: 0.1363 (0.1404)  loss_objectness: 0.0705 (0.0709)  loss_rpn_box_reg: 0.0701 (0.0695)  time: 0.6809  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [168]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1552 (0.1409)  loss_objectness: 0.0648 (0.0713)  loss_rpn_box_reg: 0.0753 (0.0696)  time: 0.6856  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [168]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1428 (0.1411)  loss_objectness: 0.0753 (0.0717)  loss_rpn_box_reg: 0.0642 (0.0694)  time: 0.6830  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [168]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1465 (0.1412)  loss_objectness: 0.0674 (0.0712)  loss_rpn_box_reg: 0.0680 (0.0700)  time: 0.6793  data: 0.2863  max mem: 5923\n",
      "Training Epoch: [168]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1425 (0.1409)  loss_objectness: 0.0633 (0.0713)  loss_rpn_box_reg: 0.0679 (0.0696)  time: 0.6821  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [168]  [200/250]  eta: 0:00:33  lr: 0.000300  loss: 0.1425 (0.1412)  loss_objectness: 0.0753 (0.0715)  loss_rpn_box_reg: 0.0625 (0.0697)  time: 0.6877  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [168]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1281 (0.1405)  loss_objectness: 0.0704 (0.0712)  loss_rpn_box_reg: 0.0617 (0.0693)  time: 0.6912  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [168]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1255 (0.1408)  loss_objectness: 0.0643 (0.0712)  loss_rpn_box_reg: 0.0610 (0.0696)  time: 0.6851  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [168]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1462 (0.1408)  loss_objectness: 0.0622 (0.0710)  loss_rpn_box_reg: 0.0706 (0.0698)  time: 0.6854  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [168]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1354 (0.1407)  loss_objectness: 0.0665 (0.0711)  loss_rpn_box_reg: 0.0692 (0.0696)  time: 0.6895  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [168]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1359 (0.1409)  loss_objectness: 0.0707 (0.0712)  loss_rpn_box_reg: 0.0661 (0.0697)  time: 0.6867  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [168] Total time: 0:02:50 (0.6814 s / it)\n",
      "Testing Epoch: [168]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1321 (0.1321)  loss_objectness: 0.0465 (0.0465)  loss_rpn_box_reg: 0.0856 (0.0856)  time: 0.6281  data: 0.2991  max mem: 5923\n",
      "Testing Epoch: [168]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1323 (0.1403)  loss_objectness: 0.0548 (0.0584)  loss_rpn_box_reg: 0.0804 (0.0819)  time: 0.6256  data: 0.3045  max mem: 5923\n",
      "Testing Epoch: [168] Total time: 0:00:39 (0.6305 s / it)\n",
      "Training Epoch: [169]  [  0/250]  eta: 0:03:01  lr: 0.000300  loss: 0.1283 (0.1283)  loss_objectness: 0.0809 (0.0809)  loss_rpn_box_reg: 0.0474 (0.0474)  time: 0.7252  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [169]  [ 10/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1283 (0.1306)  loss_objectness: 0.0589 (0.0641)  loss_rpn_box_reg: 0.0647 (0.0665)  time: 0.6682  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [169]  [ 20/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1387 (0.1369)  loss_objectness: 0.0589 (0.0718)  loss_rpn_box_reg: 0.0588 (0.0651)  time: 0.6720  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [169]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1387 (0.1374)  loss_objectness: 0.0724 (0.0726)  loss_rpn_box_reg: 0.0615 (0.0648)  time: 0.6825  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [169]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1249 (0.1345)  loss_objectness: 0.0689 (0.0716)  loss_rpn_box_reg: 0.0615 (0.0629)  time: 0.6924  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [169]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1290 (0.1357)  loss_objectness: 0.0684 (0.0702)  loss_rpn_box_reg: 0.0606 (0.0655)  time: 0.6882  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [169]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1404 (0.1377)  loss_objectness: 0.0680 (0.0712)  loss_rpn_box_reg: 0.0711 (0.0666)  time: 0.6830  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [169]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1404 (0.1377)  loss_objectness: 0.0759 (0.0724)  loss_rpn_box_reg: 0.0631 (0.0653)  time: 0.6807  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [169]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1408 (0.1388)  loss_objectness: 0.0672 (0.0711)  loss_rpn_box_reg: 0.0681 (0.0677)  time: 0.6703  data: 0.2879  max mem: 5923\n",
      "Training Epoch: [169]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1455 (0.1393)  loss_objectness: 0.0632 (0.0713)  loss_rpn_box_reg: 0.0741 (0.0680)  time: 0.6802  data: 0.2855  max mem: 5923\n",
      "Training Epoch: [169]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1317 (0.1388)  loss_objectness: 0.0666 (0.0707)  loss_rpn_box_reg: 0.0618 (0.0682)  time: 0.6792  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [169]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1292 (0.1384)  loss_objectness: 0.0619 (0.0697)  loss_rpn_box_reg: 0.0643 (0.0687)  time: 0.6788  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [169]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1335 (0.1392)  loss_objectness: 0.0625 (0.0697)  loss_rpn_box_reg: 0.0691 (0.0695)  time: 0.6799  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [169]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1347 (0.1400)  loss_objectness: 0.0660 (0.0697)  loss_rpn_box_reg: 0.0691 (0.0703)  time: 0.6814  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [169]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1289 (0.1398)  loss_objectness: 0.0660 (0.0698)  loss_rpn_box_reg: 0.0607 (0.0699)  time: 0.6883  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [169]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1410 (0.1400)  loss_objectness: 0.0681 (0.0698)  loss_rpn_box_reg: 0.0644 (0.0702)  time: 0.6866  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [169]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1386 (0.1396)  loss_objectness: 0.0573 (0.0691)  loss_rpn_box_reg: 0.0722 (0.0706)  time: 0.6808  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [169]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1254 (0.1394)  loss_objectness: 0.0608 (0.0692)  loss_rpn_box_reg: 0.0659 (0.0703)  time: 0.6758  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [169]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1279 (0.1388)  loss_objectness: 0.0738 (0.0695)  loss_rpn_box_reg: 0.0619 (0.0693)  time: 0.6827  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [169]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1279 (0.1388)  loss_objectness: 0.0718 (0.0697)  loss_rpn_box_reg: 0.0539 (0.0691)  time: 0.6892  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [169]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1461 (0.1396)  loss_objectness: 0.0692 (0.0699)  loss_rpn_box_reg: 0.0666 (0.0697)  time: 0.6913  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [169]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1502 (0.1401)  loss_objectness: 0.0692 (0.0701)  loss_rpn_box_reg: 0.0769 (0.0701)  time: 0.6822  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [169]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1529 (0.1407)  loss_objectness: 0.0711 (0.0705)  loss_rpn_box_reg: 0.0741 (0.0702)  time: 0.6762  data: 0.2884  max mem: 5923\n",
      "Training Epoch: [169]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1454 (0.1409)  loss_objectness: 0.0797 (0.0709)  loss_rpn_box_reg: 0.0684 (0.0700)  time: 0.6932  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [169]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1436 (0.1411)  loss_objectness: 0.0797 (0.0711)  loss_rpn_box_reg: 0.0684 (0.0700)  time: 0.6864  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [169]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1353 (0.1411)  loss_objectness: 0.0770 (0.0713)  loss_rpn_box_reg: 0.0602 (0.0698)  time: 0.6657  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [169] Total time: 0:02:50 (0.6815 s / it)\n",
      "Testing Epoch: [169]  [ 0/62]  eta: 0:00:43  lr: 0.000300  loss: 0.1349 (0.1349)  loss_objectness: 0.0497 (0.0497)  loss_rpn_box_reg: 0.0853 (0.0853)  time: 0.7072  data: 0.3851  max mem: 5923\n",
      "Testing Epoch: [169]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1362 (0.1423)  loss_objectness: 0.0596 (0.0622)  loss_rpn_box_reg: 0.0729 (0.0801)  time: 0.6329  data: 0.3078  max mem: 5923\n",
      "Testing Epoch: [169] Total time: 0:00:39 (0.6343 s / it)\n",
      "Training Epoch: [170]  [  0/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1025 (0.1025)  loss_objectness: 0.0589 (0.0589)  loss_rpn_box_reg: 0.0436 (0.0436)  time: 0.6662  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [170]  [ 10/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1226 (0.1302)  loss_objectness: 0.0672 (0.0704)  loss_rpn_box_reg: 0.0533 (0.0598)  time: 0.6473  data: 0.2872  max mem: 5923\n",
      "Training Epoch: [170]  [ 20/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1280 (0.1339)  loss_objectness: 0.0605 (0.0662)  loss_rpn_box_reg: 0.0638 (0.0678)  time: 0.6701  data: 0.2868  max mem: 5923\n",
      "Training Epoch: [170]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1297 (0.1350)  loss_objectness: 0.0567 (0.0656)  loss_rpn_box_reg: 0.0745 (0.0694)  time: 0.6968  data: 0.2873  max mem: 5923\n",
      "Training Epoch: [170]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1275 (0.1341)  loss_objectness: 0.0569 (0.0662)  loss_rpn_box_reg: 0.0703 (0.0678)  time: 0.6874  data: 0.2854  max mem: 5923\n",
      "Training Epoch: [170]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1286 (0.1351)  loss_objectness: 0.0740 (0.0679)  loss_rpn_box_reg: 0.0599 (0.0672)  time: 0.6852  data: 0.2873  max mem: 5923\n",
      "Training Epoch: [170]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1360 (0.1368)  loss_objectness: 0.0740 (0.0682)  loss_rpn_box_reg: 0.0671 (0.0685)  time: 0.6808  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [170]  [ 70/250]  eta: 0:02:01  lr: 0.000300  loss: 0.1400 (0.1389)  loss_objectness: 0.0640 (0.0683)  loss_rpn_box_reg: 0.0760 (0.0706)  time: 0.6671  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [170]  [ 80/250]  eta: 0:01:54  lr: 0.000300  loss: 0.1309 (0.1393)  loss_objectness: 0.0667 (0.0686)  loss_rpn_box_reg: 0.0654 (0.0707)  time: 0.6595  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [170]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1308 (0.1401)  loss_objectness: 0.0733 (0.0688)  loss_rpn_box_reg: 0.0651 (0.0713)  time: 0.6730  data: 0.2869  max mem: 5923\n",
      "Training Epoch: [170]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1414 (0.1409)  loss_objectness: 0.0737 (0.0690)  loss_rpn_box_reg: 0.0768 (0.0719)  time: 0.6834  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [170]  [110/250]  eta: 0:01:34  lr: 0.000300  loss: 0.1385 (0.1399)  loss_objectness: 0.0625 (0.0684)  loss_rpn_box_reg: 0.0731 (0.0715)  time: 0.6677  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [170]  [120/250]  eta: 0:01:27  lr: 0.000300  loss: 0.1347 (0.1404)  loss_objectness: 0.0717 (0.0692)  loss_rpn_box_reg: 0.0647 (0.0712)  time: 0.6721  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [170]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1423 (0.1402)  loss_objectness: 0.0748 (0.0693)  loss_rpn_box_reg: 0.0675 (0.0709)  time: 0.6831  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [170]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1298 (0.1393)  loss_objectness: 0.0737 (0.0696)  loss_rpn_box_reg: 0.0594 (0.0698)  time: 0.6893  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [170]  [150/250]  eta: 0:01:07  lr: 0.000300  loss: 0.1351 (0.1397)  loss_objectness: 0.0750 (0.0700)  loss_rpn_box_reg: 0.0610 (0.0697)  time: 0.6823  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [170]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1514 (0.1415)  loss_objectness: 0.0768 (0.0703)  loss_rpn_box_reg: 0.0771 (0.0712)  time: 0.6853  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [170]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1406 (0.1408)  loss_objectness: 0.0768 (0.0704)  loss_rpn_box_reg: 0.0697 (0.0704)  time: 0.6859  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [170]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1261 (0.1409)  loss_objectness: 0.0706 (0.0705)  loss_rpn_box_reg: 0.0580 (0.0703)  time: 0.6788  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [170]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1245 (0.1400)  loss_objectness: 0.0647 (0.0704)  loss_rpn_box_reg: 0.0613 (0.0696)  time: 0.6869  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [170]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1304 (0.1394)  loss_objectness: 0.0653 (0.0703)  loss_rpn_box_reg: 0.0603 (0.0691)  time: 0.7025  data: 0.2879  max mem: 5923\n",
      "Training Epoch: [170]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1353 (0.1400)  loss_objectness: 0.0730 (0.0708)  loss_rpn_box_reg: 0.0623 (0.0692)  time: 0.7065  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [170]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1432 (0.1397)  loss_objectness: 0.0730 (0.0708)  loss_rpn_box_reg: 0.0577 (0.0690)  time: 0.6893  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [170]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1432 (0.1403)  loss_objectness: 0.0693 (0.0707)  loss_rpn_box_reg: 0.0708 (0.0695)  time: 0.6997  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [170]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1376 (0.1397)  loss_objectness: 0.0628 (0.0703)  loss_rpn_box_reg: 0.0640 (0.0693)  time: 0.6887  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [170]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1414 (0.1404)  loss_objectness: 0.0675 (0.0710)  loss_rpn_box_reg: 0.0586 (0.0694)  time: 0.6767  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [170] Total time: 0:02:50 (0.6827 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:06  model_time: 0.6181 (0.6181)  evaluator_time: 0.0550 (0.0550)  time: 1.0652  data: 0.3771  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3761 (0.3822)  evaluator_time: 0.0650 (0.0777)  time: 0.7562  data: 0.2952  max mem: 5923\n",
      "Test: Total time: 0:00:47 (0.7674 s / it)\n",
      "Averaged stats: model_time: 0.3761 (0.3822)  evaluator_time: 0.0650 (0.0777)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.03s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
      "Testing Epoch: [170]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1326 (0.1326)  loss_objectness: 0.0461 (0.0461)  loss_rpn_box_reg: 0.0865 (0.0865)  time: 0.6211  data: 0.3001  max mem: 5923\n",
      "Testing Epoch: [170]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1311 (0.1389)  loss_objectness: 0.0569 (0.0591)  loss_rpn_box_reg: 0.0694 (0.0798)  time: 0.6273  data: 0.3079  max mem: 5923\n",
      "Testing Epoch: [170] Total time: 0:00:39 (0.6332 s / it)\n",
      "Training Epoch: [171]  [  0/250]  eta: 0:02:53  lr: 0.000300  loss: 0.1600 (0.1600)  loss_objectness: 0.0680 (0.0680)  loss_rpn_box_reg: 0.0920 (0.0920)  time: 0.6932  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [171]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1357 (0.1425)  loss_objectness: 0.0644 (0.0661)  loss_rpn_box_reg: 0.0756 (0.0763)  time: 0.6958  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [171]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1503 (0.1480)  loss_objectness: 0.0645 (0.0700)  loss_rpn_box_reg: 0.0804 (0.0780)  time: 0.6834  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [171]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1421 (0.1407)  loss_objectness: 0.0639 (0.0675)  loss_rpn_box_reg: 0.0701 (0.0732)  time: 0.6766  data: 0.2886  max mem: 5923\n",
      "Training Epoch: [171]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1272 (0.1395)  loss_objectness: 0.0627 (0.0666)  loss_rpn_box_reg: 0.0663 (0.0729)  time: 0.6885  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [171]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1370 (0.1399)  loss_objectness: 0.0661 (0.0658)  loss_rpn_box_reg: 0.0787 (0.0741)  time: 0.6913  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [171]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1370 (0.1396)  loss_objectness: 0.0706 (0.0668)  loss_rpn_box_reg: 0.0660 (0.0728)  time: 0.6950  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [171]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1282 (0.1390)  loss_objectness: 0.0764 (0.0683)  loss_rpn_box_reg: 0.0601 (0.0707)  time: 0.6960  data: 0.2963  max mem: 5923\n",
      "Training Epoch: [171]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1317 (0.1384)  loss_objectness: 0.0635 (0.0676)  loss_rpn_box_reg: 0.0665 (0.0708)  time: 0.6943  data: 0.2969  max mem: 5923\n",
      "Training Epoch: [171]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1380 (0.1396)  loss_objectness: 0.0618 (0.0671)  loss_rpn_box_reg: 0.0688 (0.0725)  time: 0.6904  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [171]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1446 (0.1401)  loss_objectness: 0.0657 (0.0680)  loss_rpn_box_reg: 0.0716 (0.0721)  time: 0.6816  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [171]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1318 (0.1388)  loss_objectness: 0.0644 (0.0677)  loss_rpn_box_reg: 0.0582 (0.0711)  time: 0.6826  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [171]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1295 (0.1379)  loss_objectness: 0.0666 (0.0677)  loss_rpn_box_reg: 0.0583 (0.0703)  time: 0.6919  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [171]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1359 (0.1382)  loss_objectness: 0.0730 (0.0682)  loss_rpn_box_reg: 0.0623 (0.0700)  time: 0.6929  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [171]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1422 (0.1381)  loss_objectness: 0.0776 (0.0684)  loss_rpn_box_reg: 0.0623 (0.0697)  time: 0.6954  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [171]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1368 (0.1382)  loss_objectness: 0.0749 (0.0688)  loss_rpn_box_reg: 0.0563 (0.0693)  time: 0.6988  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [171]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1297 (0.1377)  loss_objectness: 0.0744 (0.0695)  loss_rpn_box_reg: 0.0535 (0.0683)  time: 0.6862  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [171]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1343 (0.1386)  loss_objectness: 0.0786 (0.0700)  loss_rpn_box_reg: 0.0535 (0.0686)  time: 0.6785  data: 0.2962  max mem: 5923\n",
      "Training Epoch: [171]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1370 (0.1390)  loss_objectness: 0.0741 (0.0699)  loss_rpn_box_reg: 0.0656 (0.0690)  time: 0.6953  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [171]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1315 (0.1385)  loss_objectness: 0.0695 (0.0700)  loss_rpn_box_reg: 0.0656 (0.0685)  time: 0.6951  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [171]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1440 (0.1391)  loss_objectness: 0.0726 (0.0705)  loss_rpn_box_reg: 0.0627 (0.0685)  time: 0.6628  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [171]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1514 (0.1398)  loss_objectness: 0.0832 (0.0710)  loss_rpn_box_reg: 0.0663 (0.0688)  time: 0.6633  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [171]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1320 (0.1393)  loss_objectness: 0.0749 (0.0709)  loss_rpn_box_reg: 0.0635 (0.0685)  time: 0.6794  data: 0.2880  max mem: 5923\n",
      "Training Epoch: [171]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1308 (0.1394)  loss_objectness: 0.0642 (0.0707)  loss_rpn_box_reg: 0.0630 (0.0686)  time: 0.6838  data: 0.2873  max mem: 5923\n",
      "Training Epoch: [171]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1462 (0.1402)  loss_objectness: 0.0685 (0.0712)  loss_rpn_box_reg: 0.0700 (0.0690)  time: 0.6812  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [171]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1501 (0.1405)  loss_objectness: 0.0708 (0.0711)  loss_rpn_box_reg: 0.0708 (0.0694)  time: 0.6782  data: 0.2974  max mem: 5923\n",
      "Training Epoch: [171] Total time: 0:02:51 (0.6862 s / it)\n",
      "Testing Epoch: [171]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1321 (0.1321)  loss_objectness: 0.0445 (0.0445)  loss_rpn_box_reg: 0.0877 (0.0877)  time: 0.6151  data: 0.2891  max mem: 5923\n",
      "Testing Epoch: [171]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1326 (0.1402)  loss_objectness: 0.0545 (0.0586)  loss_rpn_box_reg: 0.0763 (0.0817)  time: 0.6238  data: 0.3054  max mem: 5923\n",
      "Testing Epoch: [171] Total time: 0:00:39 (0.6331 s / it)\n",
      "Training Epoch: [172]  [  0/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1350 (0.1350)  loss_objectness: 0.0819 (0.0819)  loss_rpn_box_reg: 0.0531 (0.0531)  time: 0.6491  data: 0.2841  max mem: 5923\n",
      "Training Epoch: [172]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1377 (0.1401)  loss_objectness: 0.0819 (0.0791)  loss_rpn_box_reg: 0.0579 (0.0610)  time: 0.6999  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [172]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1377 (0.1379)  loss_objectness: 0.0664 (0.0735)  loss_rpn_box_reg: 0.0613 (0.0644)  time: 0.6953  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [172]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1262 (0.1375)  loss_objectness: 0.0632 (0.0725)  loss_rpn_box_reg: 0.0602 (0.0650)  time: 0.6778  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [172]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1272 (0.1361)  loss_objectness: 0.0668 (0.0716)  loss_rpn_box_reg: 0.0585 (0.0645)  time: 0.6809  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [172]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1358 (0.1392)  loss_objectness: 0.0668 (0.0705)  loss_rpn_box_reg: 0.0683 (0.0686)  time: 0.6951  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [172]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1397 (0.1383)  loss_objectness: 0.0673 (0.0708)  loss_rpn_box_reg: 0.0719 (0.0674)  time: 0.6985  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [172]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1324 (0.1376)  loss_objectness: 0.0742 (0.0714)  loss_rpn_box_reg: 0.0588 (0.0662)  time: 0.6812  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [172]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1349 (0.1391)  loss_objectness: 0.0760 (0.0721)  loss_rpn_box_reg: 0.0577 (0.0671)  time: 0.6746  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [172]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1393 (0.1388)  loss_objectness: 0.0748 (0.0719)  loss_rpn_box_reg: 0.0615 (0.0670)  time: 0.6901  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [172]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1341 (0.1377)  loss_objectness: 0.0707 (0.0714)  loss_rpn_box_reg: 0.0615 (0.0663)  time: 0.6955  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [172]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1295 (0.1381)  loss_objectness: 0.0573 (0.0711)  loss_rpn_box_reg: 0.0661 (0.0670)  time: 0.6926  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [172]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1242 (0.1378)  loss_objectness: 0.0604 (0.0709)  loss_rpn_box_reg: 0.0665 (0.0669)  time: 0.6904  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [172]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1421 (0.1396)  loss_objectness: 0.0709 (0.0714)  loss_rpn_box_reg: 0.0700 (0.0682)  time: 0.6842  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [172]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1474 (0.1401)  loss_objectness: 0.0811 (0.0717)  loss_rpn_box_reg: 0.0779 (0.0684)  time: 0.6766  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [172]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1423 (0.1404)  loss_objectness: 0.0731 (0.0720)  loss_rpn_box_reg: 0.0622 (0.0684)  time: 0.6811  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [172]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1420 (0.1408)  loss_objectness: 0.0731 (0.0721)  loss_rpn_box_reg: 0.0622 (0.0686)  time: 0.6818  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [172]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1338 (0.1407)  loss_objectness: 0.0655 (0.0717)  loss_rpn_box_reg: 0.0678 (0.0691)  time: 0.6719  data: 0.2894  max mem: 5923\n",
      "Training Epoch: [172]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1317 (0.1394)  loss_objectness: 0.0615 (0.0707)  loss_rpn_box_reg: 0.0672 (0.0687)  time: 0.6750  data: 0.2862  max mem: 5923\n",
      "Training Epoch: [172]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1175 (0.1393)  loss_objectness: 0.0529 (0.0706)  loss_rpn_box_reg: 0.0643 (0.0687)  time: 0.6669  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [172]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1433 (0.1401)  loss_objectness: 0.0685 (0.0707)  loss_rpn_box_reg: 0.0653 (0.0693)  time: 0.6614  data: 0.2966  max mem: 5923\n",
      "Training Epoch: [172]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1403 (0.1402)  loss_objectness: 0.0630 (0.0706)  loss_rpn_box_reg: 0.0653 (0.0696)  time: 0.6757  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [172]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1403 (0.1404)  loss_objectness: 0.0637 (0.0709)  loss_rpn_box_reg: 0.0701 (0.0695)  time: 0.6828  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [172]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1485 (0.1406)  loss_objectness: 0.0667 (0.0707)  loss_rpn_box_reg: 0.0733 (0.0699)  time: 0.6880  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [172]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1465 (0.1407)  loss_objectness: 0.0667 (0.0710)  loss_rpn_box_reg: 0.0641 (0.0697)  time: 0.6857  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [172]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1314 (0.1409)  loss_objectness: 0.0689 (0.0712)  loss_rpn_box_reg: 0.0627 (0.0697)  time: 0.6803  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [172] Total time: 0:02:50 (0.6830 s / it)\n",
      "Testing Epoch: [172]  [ 0/62]  eta: 0:00:43  lr: 0.000300  loss: 0.1428 (0.1428)  loss_objectness: 0.0531 (0.0531)  loss_rpn_box_reg: 0.0897 (0.0897)  time: 0.7072  data: 0.3841  max mem: 5923\n",
      "Testing Epoch: [172]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1283 (0.1412)  loss_objectness: 0.0543 (0.0593)  loss_rpn_box_reg: 0.0770 (0.0819)  time: 0.6265  data: 0.3070  max mem: 5923\n",
      "Testing Epoch: [172] Total time: 0:00:39 (0.6316 s / it)\n",
      "Training Epoch: [173]  [  0/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1195 (0.1195)  loss_objectness: 0.0744 (0.0744)  loss_rpn_box_reg: 0.0451 (0.0451)  time: 0.6161  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [173]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1467 (0.1390)  loss_objectness: 0.0706 (0.0705)  loss_rpn_box_reg: 0.0610 (0.0685)  time: 0.6832  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [173]  [ 20/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1318 (0.1345)  loss_objectness: 0.0661 (0.0672)  loss_rpn_box_reg: 0.0596 (0.0673)  time: 0.6812  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [173]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1318 (0.1382)  loss_objectness: 0.0628 (0.0677)  loss_rpn_box_reg: 0.0659 (0.0706)  time: 0.6777  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [173]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1351 (0.1381)  loss_objectness: 0.0648 (0.0682)  loss_rpn_box_reg: 0.0696 (0.0699)  time: 0.6876  data: 0.2892  max mem: 5923\n",
      "Training Epoch: [173]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1220 (0.1350)  loss_objectness: 0.0616 (0.0668)  loss_rpn_box_reg: 0.0588 (0.0683)  time: 0.6909  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [173]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1220 (0.1356)  loss_objectness: 0.0614 (0.0680)  loss_rpn_box_reg: 0.0588 (0.0676)  time: 0.6805  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [173]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1350 (0.1354)  loss_objectness: 0.0655 (0.0674)  loss_rpn_box_reg: 0.0650 (0.0680)  time: 0.6721  data: 0.2882  max mem: 5923\n",
      "Training Epoch: [173]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1350 (0.1362)  loss_objectness: 0.0635 (0.0677)  loss_rpn_box_reg: 0.0659 (0.0685)  time: 0.6792  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [173]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1357 (0.1376)  loss_objectness: 0.0668 (0.0677)  loss_rpn_box_reg: 0.0659 (0.0699)  time: 0.6821  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [173]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1522 (0.1385)  loss_objectness: 0.0702 (0.0681)  loss_rpn_box_reg: 0.0738 (0.0704)  time: 0.6812  data: 0.2889  max mem: 5923\n",
      "Training Epoch: [173]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1522 (0.1381)  loss_objectness: 0.0702 (0.0683)  loss_rpn_box_reg: 0.0668 (0.0698)  time: 0.6835  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [173]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1465 (0.1389)  loss_objectness: 0.0679 (0.0685)  loss_rpn_box_reg: 0.0668 (0.0704)  time: 0.6822  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [173]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1408 (0.1388)  loss_objectness: 0.0673 (0.0680)  loss_rpn_box_reg: 0.0764 (0.0708)  time: 0.6988  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [173]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1276 (0.1376)  loss_objectness: 0.0628 (0.0682)  loss_rpn_box_reg: 0.0582 (0.0694)  time: 0.7017  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [173]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1334 (0.1375)  loss_objectness: 0.0677 (0.0684)  loss_rpn_box_reg: 0.0506 (0.0691)  time: 0.6927  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [173]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1370 (0.1375)  loss_objectness: 0.0677 (0.0686)  loss_rpn_box_reg: 0.0607 (0.0690)  time: 0.7051  data: 0.2996  max mem: 5923\n",
      "Training Epoch: [173]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1263 (0.1372)  loss_objectness: 0.0619 (0.0680)  loss_rpn_box_reg: 0.0662 (0.0692)  time: 0.6926  data: 0.2962  max mem: 5923\n",
      "Training Epoch: [173]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1278 (0.1366)  loss_objectness: 0.0650 (0.0684)  loss_rpn_box_reg: 0.0562 (0.0682)  time: 0.6838  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [173]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1294 (0.1361)  loss_objectness: 0.0653 (0.0681)  loss_rpn_box_reg: 0.0545 (0.0679)  time: 0.6929  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [173]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1367 (0.1366)  loss_objectness: 0.0653 (0.0686)  loss_rpn_box_reg: 0.0635 (0.0680)  time: 0.6820  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [173]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1490 (0.1374)  loss_objectness: 0.0733 (0.0692)  loss_rpn_box_reg: 0.0652 (0.0682)  time: 0.6775  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [173]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1436 (0.1377)  loss_objectness: 0.0687 (0.0693)  loss_rpn_box_reg: 0.0596 (0.0683)  time: 0.6755  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [173]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1411 (0.1380)  loss_objectness: 0.0685 (0.0694)  loss_rpn_box_reg: 0.0660 (0.0686)  time: 0.6677  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [173]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1470 (0.1385)  loss_objectness: 0.0667 (0.0695)  loss_rpn_box_reg: 0.0746 (0.0690)  time: 0.6732  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [173]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1549 (0.1392)  loss_objectness: 0.0735 (0.0700)  loss_rpn_box_reg: 0.0777 (0.0692)  time: 0.6773  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [173] Total time: 0:02:50 (0.6840 s / it)\n",
      "Testing Epoch: [173]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1347 (0.1347)  loss_objectness: 0.0454 (0.0454)  loss_rpn_box_reg: 0.0893 (0.0893)  time: 0.6381  data: 0.3001  max mem: 5923\n",
      "Testing Epoch: [173]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1327 (0.1412)  loss_objectness: 0.0563 (0.0606)  loss_rpn_box_reg: 0.0732 (0.0806)  time: 0.6239  data: 0.3061  max mem: 5923\n",
      "Testing Epoch: [173] Total time: 0:00:39 (0.6318 s / it)\n",
      "Training Epoch: [174]  [  0/250]  eta: 0:02:55  lr: 0.000300  loss: 0.1442 (0.1442)  loss_objectness: 0.0704 (0.0704)  loss_rpn_box_reg: 0.0739 (0.0739)  time: 0.7032  data: 0.3021  max mem: 5923\n",
      "Training Epoch: [174]  [ 10/250]  eta: 0:02:48  lr: 0.000300  loss: 0.1442 (0.1438)  loss_objectness: 0.0722 (0.0724)  loss_rpn_box_reg: 0.0695 (0.0714)  time: 0.7031  data: 0.2972  max mem: 5923\n",
      "Training Epoch: [174]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1275 (0.1388)  loss_objectness: 0.0593 (0.0653)  loss_rpn_box_reg: 0.0678 (0.0735)  time: 0.6986  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [174]  [ 30/250]  eta: 0:02:33  lr: 0.000300  loss: 0.1179 (0.1347)  loss_objectness: 0.0545 (0.0663)  loss_rpn_box_reg: 0.0612 (0.0684)  time: 0.6967  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [174]  [ 40/250]  eta: 0:02:26  lr: 0.000300  loss: 0.1241 (0.1358)  loss_objectness: 0.0640 (0.0669)  loss_rpn_box_reg: 0.0590 (0.0689)  time: 0.6994  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [174]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1337 (0.1358)  loss_objectness: 0.0684 (0.0674)  loss_rpn_box_reg: 0.0714 (0.0684)  time: 0.6831  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [174]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1300 (0.1361)  loss_objectness: 0.0647 (0.0675)  loss_rpn_box_reg: 0.0667 (0.0685)  time: 0.6696  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [174]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1300 (0.1367)  loss_objectness: 0.0633 (0.0679)  loss_rpn_box_reg: 0.0667 (0.0688)  time: 0.6765  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [174]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1256 (0.1350)  loss_objectness: 0.0585 (0.0668)  loss_rpn_box_reg: 0.0671 (0.0682)  time: 0.6829  data: 0.2894  max mem: 5923\n",
      "Training Epoch: [174]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1256 (0.1361)  loss_objectness: 0.0592 (0.0674)  loss_rpn_box_reg: 0.0689 (0.0687)  time: 0.6904  data: 0.2864  max mem: 5923\n",
      "Training Epoch: [174]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1336 (0.1365)  loss_objectness: 0.0697 (0.0680)  loss_rpn_box_reg: 0.0652 (0.0685)  time: 0.6983  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [174]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1369 (0.1371)  loss_objectness: 0.0729 (0.0687)  loss_rpn_box_reg: 0.0614 (0.0684)  time: 0.6943  data: 0.2991  max mem: 5923\n",
      "Training Epoch: [174]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1460 (0.1384)  loss_objectness: 0.0745 (0.0690)  loss_rpn_box_reg: 0.0723 (0.0694)  time: 0.6777  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [174]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1465 (0.1389)  loss_objectness: 0.0703 (0.0690)  loss_rpn_box_reg: 0.0736 (0.0699)  time: 0.6800  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [174]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1409 (0.1393)  loss_objectness: 0.0698 (0.0694)  loss_rpn_box_reg: 0.0736 (0.0700)  time: 0.6846  data: 0.2880  max mem: 5923\n",
      "Training Epoch: [174]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1360 (0.1397)  loss_objectness: 0.0694 (0.0694)  loss_rpn_box_reg: 0.0708 (0.0703)  time: 0.6792  data: 0.2880  max mem: 5923\n",
      "Training Epoch: [174]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1454 (0.1403)  loss_objectness: 0.0720 (0.0700)  loss_rpn_box_reg: 0.0685 (0.0703)  time: 0.6881  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [174]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1424 (0.1403)  loss_objectness: 0.0739 (0.0707)  loss_rpn_box_reg: 0.0626 (0.0695)  time: 0.6903  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [174]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1417 (0.1406)  loss_objectness: 0.0641 (0.0707)  loss_rpn_box_reg: 0.0589 (0.0699)  time: 0.6905  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [174]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1424 (0.1411)  loss_objectness: 0.0644 (0.0708)  loss_rpn_box_reg: 0.0791 (0.0703)  time: 0.6933  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [174]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1362 (0.1406)  loss_objectness: 0.0688 (0.0707)  loss_rpn_box_reg: 0.0699 (0.0698)  time: 0.6895  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [174]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1304 (0.1405)  loss_objectness: 0.0688 (0.0708)  loss_rpn_box_reg: 0.0653 (0.0698)  time: 0.6792  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [174]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1501 (0.1410)  loss_objectness: 0.0773 (0.0711)  loss_rpn_box_reg: 0.0653 (0.0698)  time: 0.6757  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [174]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1517 (0.1413)  loss_objectness: 0.0777 (0.0717)  loss_rpn_box_reg: 0.0653 (0.0696)  time: 0.6707  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [174]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1506 (0.1418)  loss_objectness: 0.0763 (0.0717)  loss_rpn_box_reg: 0.0658 (0.0701)  time: 0.6675  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [174]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1413 (0.1416)  loss_objectness: 0.0700 (0.0714)  loss_rpn_box_reg: 0.0777 (0.0702)  time: 0.6770  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [174] Total time: 0:02:51 (0.6854 s / it)\n",
      "Testing Epoch: [174]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1325 (0.1325)  loss_objectness: 0.0437 (0.0437)  loss_rpn_box_reg: 0.0887 (0.0887)  time: 0.6161  data: 0.2921  max mem: 5923\n",
      "Testing Epoch: [174]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1263 (0.1386)  loss_objectness: 0.0534 (0.0592)  loss_rpn_box_reg: 0.0704 (0.0795)  time: 0.6304  data: 0.3095  max mem: 5923\n",
      "Testing Epoch: [174] Total time: 0:00:39 (0.6327 s / it)\n",
      "Training Epoch: [175]  [  0/250]  eta: 0:03:04  lr: 0.000300  loss: 0.0922 (0.0922)  loss_objectness: 0.0501 (0.0501)  loss_rpn_box_reg: 0.0420 (0.0420)  time: 0.7362  data: 0.2741  max mem: 5923\n",
      "Training Epoch: [175]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1413 (0.1433)  loss_objectness: 0.0607 (0.0715)  loss_rpn_box_reg: 0.0655 (0.0718)  time: 0.6843  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [175]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1413 (0.1450)  loss_objectness: 0.0649 (0.0724)  loss_rpn_box_reg: 0.0721 (0.0727)  time: 0.6797  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [175]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1401 (0.1428)  loss_objectness: 0.0703 (0.0713)  loss_rpn_box_reg: 0.0675 (0.0715)  time: 0.6744  data: 0.2880  max mem: 5923\n",
      "Training Epoch: [175]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1427 (0.1449)  loss_objectness: 0.0747 (0.0732)  loss_rpn_box_reg: 0.0640 (0.0717)  time: 0.6773  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [175]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1373 (0.1438)  loss_objectness: 0.0757 (0.0732)  loss_rpn_box_reg: 0.0616 (0.0706)  time: 0.6838  data: 0.2979  max mem: 5923\n",
      "Training Epoch: [175]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1345 (0.1449)  loss_objectness: 0.0726 (0.0729)  loss_rpn_box_reg: 0.0703 (0.0720)  time: 0.6876  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [175]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1425 (0.1431)  loss_objectness: 0.0719 (0.0728)  loss_rpn_box_reg: 0.0719 (0.0703)  time: 0.6795  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [175]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1426 (0.1439)  loss_objectness: 0.0694 (0.0728)  loss_rpn_box_reg: 0.0719 (0.0711)  time: 0.6829  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [175]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1426 (0.1426)  loss_objectness: 0.0671 (0.0716)  loss_rpn_box_reg: 0.0721 (0.0710)  time: 0.6854  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [175]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1264 (0.1405)  loss_objectness: 0.0626 (0.0710)  loss_rpn_box_reg: 0.0568 (0.0695)  time: 0.6805  data: 0.2874  max mem: 5923\n",
      "Training Epoch: [175]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1264 (0.1401)  loss_objectness: 0.0694 (0.0712)  loss_rpn_box_reg: 0.0568 (0.0689)  time: 0.6853  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [175]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1254 (0.1396)  loss_objectness: 0.0694 (0.0710)  loss_rpn_box_reg: 0.0582 (0.0687)  time: 0.6828  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [175]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1357 (0.1396)  loss_objectness: 0.0655 (0.0709)  loss_rpn_box_reg: 0.0627 (0.0687)  time: 0.6767  data: 0.2883  max mem: 5923\n",
      "Training Epoch: [175]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1431 (0.1398)  loss_objectness: 0.0704 (0.0707)  loss_rpn_box_reg: 0.0706 (0.0690)  time: 0.6892  data: 0.2872  max mem: 5923\n",
      "Training Epoch: [175]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1387 (0.1403)  loss_objectness: 0.0702 (0.0709)  loss_rpn_box_reg: 0.0640 (0.0693)  time: 0.6901  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [175]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1366 (0.1396)  loss_objectness: 0.0670 (0.0706)  loss_rpn_box_reg: 0.0639 (0.0689)  time: 0.6735  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [175]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1363 (0.1394)  loss_objectness: 0.0666 (0.0702)  loss_rpn_box_reg: 0.0639 (0.0692)  time: 0.6715  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [175]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1402 (0.1406)  loss_objectness: 0.0554 (0.0701)  loss_rpn_box_reg: 0.0768 (0.0705)  time: 0.6707  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [175]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1418 (0.1401)  loss_objectness: 0.0626 (0.0699)  loss_rpn_box_reg: 0.0700 (0.0702)  time: 0.6747  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [175]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1418 (0.1399)  loss_objectness: 0.0659 (0.0698)  loss_rpn_box_reg: 0.0673 (0.0702)  time: 0.6852  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [175]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1323 (0.1396)  loss_objectness: 0.0689 (0.0698)  loss_rpn_box_reg: 0.0673 (0.0698)  time: 0.6953  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [175]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1307 (0.1395)  loss_objectness: 0.0647 (0.0698)  loss_rpn_box_reg: 0.0623 (0.0698)  time: 0.6941  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [175]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1325 (0.1393)  loss_objectness: 0.0658 (0.0697)  loss_rpn_box_reg: 0.0578 (0.0695)  time: 0.6877  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [175]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1330 (0.1395)  loss_objectness: 0.0711 (0.0698)  loss_rpn_box_reg: 0.0578 (0.0697)  time: 0.6827  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [175]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1416 (0.1396)  loss_objectness: 0.0738 (0.0701)  loss_rpn_box_reg: 0.0679 (0.0695)  time: 0.6824  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [175] Total time: 0:02:50 (0.6826 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:01  model_time: 0.6241 (0.6241)  evaluator_time: 0.0690 (0.0690)  time: 0.9942  data: 0.2851  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.4011 (0.3989)  evaluator_time: 0.0700 (0.0760)  time: 0.7932  data: 0.3165  max mem: 5923\n",
      "Test: Total time: 0:00:49 (0.7918 s / it)\n",
      "Averaged stats: model_time: 0.4011 (0.3989)  evaluator_time: 0.0700 (0.0760)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.14s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.054\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.176\n",
      "Testing Epoch: [175]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1332 (0.1332)  loss_objectness: 0.0421 (0.0421)  loss_rpn_box_reg: 0.0911 (0.0911)  time: 0.6121  data: 0.2901  max mem: 5923\n",
      "Testing Epoch: [175]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1411 (0.1400)  loss_objectness: 0.0554 (0.0585)  loss_rpn_box_reg: 0.0747 (0.0814)  time: 0.6296  data: 0.3077  max mem: 5923\n",
      "Testing Epoch: [175] Total time: 0:00:39 (0.6303 s / it)\n",
      "Training Epoch: [176]  [  0/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1510 (0.1510)  loss_objectness: 0.0506 (0.0506)  loss_rpn_box_reg: 0.1005 (0.1005)  time: 0.6642  data: 0.3011  max mem: 5923\n",
      "Training Epoch: [176]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1399 (0.1436)  loss_objectness: 0.0647 (0.0675)  loss_rpn_box_reg: 0.0720 (0.0761)  time: 0.6735  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [176]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1347 (0.1368)  loss_objectness: 0.0687 (0.0678)  loss_rpn_box_reg: 0.0667 (0.0691)  time: 0.6813  data: 0.2992  max mem: 5923\n",
      "Training Epoch: [176]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1319 (0.1373)  loss_objectness: 0.0681 (0.0663)  loss_rpn_box_reg: 0.0667 (0.0710)  time: 0.6818  data: 0.2977  max mem: 5923\n",
      "Training Epoch: [176]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1319 (0.1411)  loss_objectness: 0.0637 (0.0695)  loss_rpn_box_reg: 0.0731 (0.0716)  time: 0.6903  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [176]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1387 (0.1417)  loss_objectness: 0.0637 (0.0692)  loss_rpn_box_reg: 0.0729 (0.0725)  time: 0.6948  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [176]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1371 (0.1422)  loss_objectness: 0.0656 (0.0702)  loss_rpn_box_reg: 0.0724 (0.0720)  time: 0.6994  data: 0.3023  max mem: 5923\n",
      "Training Epoch: [176]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1371 (0.1428)  loss_objectness: 0.0718 (0.0715)  loss_rpn_box_reg: 0.0658 (0.0713)  time: 0.6964  data: 0.3052  max mem: 5923\n",
      "Training Epoch: [176]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1383 (0.1419)  loss_objectness: 0.0701 (0.0712)  loss_rpn_box_reg: 0.0631 (0.0707)  time: 0.6728  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [176]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1381 (0.1417)  loss_objectness: 0.0640 (0.0708)  loss_rpn_box_reg: 0.0659 (0.0709)  time: 0.6732  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [176]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1388 (0.1421)  loss_objectness: 0.0664 (0.0708)  loss_rpn_box_reg: 0.0683 (0.0713)  time: 0.6661  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [176]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1369 (0.1425)  loss_objectness: 0.0664 (0.0711)  loss_rpn_box_reg: 0.0666 (0.0714)  time: 0.6630  data: 0.2875  max mem: 5923\n",
      "Training Epoch: [176]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1333 (0.1425)  loss_objectness: 0.0661 (0.0710)  loss_rpn_box_reg: 0.0671 (0.0715)  time: 0.6781  data: 0.2872  max mem: 5923\n",
      "Training Epoch: [176]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1536 (0.1426)  loss_objectness: 0.0661 (0.0711)  loss_rpn_box_reg: 0.0693 (0.0715)  time: 0.6857  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [176]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1519 (0.1425)  loss_objectness: 0.0619 (0.0712)  loss_rpn_box_reg: 0.0654 (0.0714)  time: 0.6948  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [176]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1436 (0.1428)  loss_objectness: 0.0671 (0.0714)  loss_rpn_box_reg: 0.0610 (0.0714)  time: 0.7091  data: 0.2970  max mem: 5923\n",
      "Training Epoch: [176]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1448 (0.1434)  loss_objectness: 0.0677 (0.0721)  loss_rpn_box_reg: 0.0645 (0.0713)  time: 0.7042  data: 0.3003  max mem: 5923\n",
      "Training Epoch: [176]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1402 (0.1428)  loss_objectness: 0.0684 (0.0720)  loss_rpn_box_reg: 0.0645 (0.0708)  time: 0.6873  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [176]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1305 (0.1423)  loss_objectness: 0.0660 (0.0719)  loss_rpn_box_reg: 0.0633 (0.0705)  time: 0.6933  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [176]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1322 (0.1422)  loss_objectness: 0.0630 (0.0714)  loss_rpn_box_reg: 0.0675 (0.0708)  time: 0.6916  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [176]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1443 (0.1429)  loss_objectness: 0.0670 (0.0717)  loss_rpn_box_reg: 0.0766 (0.0712)  time: 0.6877  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [176]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1322 (0.1419)  loss_objectness: 0.0664 (0.0715)  loss_rpn_box_reg: 0.0607 (0.0703)  time: 0.6784  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [176]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1192 (0.1410)  loss_objectness: 0.0648 (0.0712)  loss_rpn_box_reg: 0.0519 (0.0697)  time: 0.6763  data: 0.2876  max mem: 5923\n",
      "Training Epoch: [176]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1192 (0.1409)  loss_objectness: 0.0645 (0.0712)  loss_rpn_box_reg: 0.0581 (0.0697)  time: 0.6995  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [176]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1439 (0.1412)  loss_objectness: 0.0703 (0.0715)  loss_rpn_box_reg: 0.0678 (0.0696)  time: 0.6967  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [176]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1428 (0.1413)  loss_objectness: 0.0754 (0.0716)  loss_rpn_box_reg: 0.0677 (0.0697)  time: 0.6904  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [176] Total time: 0:02:51 (0.6870 s / it)\n",
      "Testing Epoch: [176]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1357 (0.1357)  loss_objectness: 0.0484 (0.0484)  loss_rpn_box_reg: 0.0873 (0.0873)  time: 0.6111  data: 0.2881  max mem: 5923\n",
      "Testing Epoch: [176]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1272 (0.1374)  loss_objectness: 0.0535 (0.0576)  loss_rpn_box_reg: 0.0752 (0.0798)  time: 0.6238  data: 0.3025  max mem: 5923\n",
      "Testing Epoch: [176] Total time: 0:00:39 (0.6298 s / it)\n",
      "Training Epoch: [177]  [  0/250]  eta: 0:02:56  lr: 0.000300  loss: 0.1864 (0.1864)  loss_objectness: 0.0731 (0.0731)  loss_rpn_box_reg: 0.1133 (0.1133)  time: 0.7052  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [177]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1441 (0.1367)  loss_objectness: 0.0731 (0.0685)  loss_rpn_box_reg: 0.0655 (0.0682)  time: 0.6859  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [177]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1358 (0.1389)  loss_objectness: 0.0750 (0.0744)  loss_rpn_box_reg: 0.0551 (0.0645)  time: 0.6810  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [177]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1323 (0.1372)  loss_objectness: 0.0684 (0.0712)  loss_rpn_box_reg: 0.0686 (0.0660)  time: 0.6807  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [177]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1305 (0.1362)  loss_objectness: 0.0614 (0.0701)  loss_rpn_box_reg: 0.0707 (0.0662)  time: 0.6929  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [177]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1308 (0.1371)  loss_objectness: 0.0649 (0.0692)  loss_rpn_box_reg: 0.0696 (0.0679)  time: 0.6964  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [177]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1354 (0.1370)  loss_objectness: 0.0635 (0.0693)  loss_rpn_box_reg: 0.0696 (0.0678)  time: 0.6769  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [177]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1425 (0.1390)  loss_objectness: 0.0705 (0.0702)  loss_rpn_box_reg: 0.0676 (0.0688)  time: 0.6839  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [177]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1407 (0.1384)  loss_objectness: 0.0689 (0.0700)  loss_rpn_box_reg: 0.0665 (0.0684)  time: 0.6987  data: 0.2976  max mem: 5923\n",
      "Training Epoch: [177]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1331 (0.1377)  loss_objectness: 0.0705 (0.0699)  loss_rpn_box_reg: 0.0654 (0.0677)  time: 0.6982  data: 0.2966  max mem: 5923\n",
      "Training Epoch: [177]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1360 (0.1384)  loss_objectness: 0.0716 (0.0696)  loss_rpn_box_reg: 0.0681 (0.0688)  time: 0.6889  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [177]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1427 (0.1391)  loss_objectness: 0.0695 (0.0702)  loss_rpn_box_reg: 0.0744 (0.0689)  time: 0.6729  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [177]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1463 (0.1403)  loss_objectness: 0.0693 (0.0701)  loss_rpn_box_reg: 0.0752 (0.0701)  time: 0.6893  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [177]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1492 (0.1404)  loss_objectness: 0.0685 (0.0703)  loss_rpn_box_reg: 0.0704 (0.0702)  time: 0.6875  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [177]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1345 (0.1391)  loss_objectness: 0.0683 (0.0702)  loss_rpn_box_reg: 0.0598 (0.0689)  time: 0.6723  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [177]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1267 (0.1407)  loss_objectness: 0.0683 (0.0706)  loss_rpn_box_reg: 0.0738 (0.0701)  time: 0.6796  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [177]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1469 (0.1405)  loss_objectness: 0.0693 (0.0707)  loss_rpn_box_reg: 0.0738 (0.0699)  time: 0.6895  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [177]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1432 (0.1410)  loss_objectness: 0.0766 (0.0712)  loss_rpn_box_reg: 0.0631 (0.0698)  time: 0.6908  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [177]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1432 (0.1411)  loss_objectness: 0.0748 (0.0712)  loss_rpn_box_reg: 0.0621 (0.0699)  time: 0.6812  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [177]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1369 (0.1404)  loss_objectness: 0.0581 (0.0705)  loss_rpn_box_reg: 0.0632 (0.0700)  time: 0.6824  data: 0.2884  max mem: 5923\n",
      "Training Epoch: [177]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1337 (0.1403)  loss_objectness: 0.0555 (0.0702)  loss_rpn_box_reg: 0.0644 (0.0701)  time: 0.6875  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [177]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1379 (0.1404)  loss_objectness: 0.0683 (0.0705)  loss_rpn_box_reg: 0.0631 (0.0699)  time: 0.6815  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [177]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1319 (0.1398)  loss_objectness: 0.0618 (0.0701)  loss_rpn_box_reg: 0.0621 (0.0697)  time: 0.6770  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [177]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1319 (0.1400)  loss_objectness: 0.0633 (0.0701)  loss_rpn_box_reg: 0.0706 (0.0699)  time: 0.6776  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [177]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1352 (0.1399)  loss_objectness: 0.0697 (0.0700)  loss_rpn_box_reg: 0.0702 (0.0699)  time: 0.6765  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [177]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1320 (0.1404)  loss_objectness: 0.0697 (0.0704)  loss_rpn_box_reg: 0.0693 (0.0700)  time: 0.6850  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [177] Total time: 0:02:51 (0.6850 s / it)\n",
      "Testing Epoch: [177]  [ 0/62]  eta: 0:00:43  lr: 0.000300  loss: 0.1336 (0.1336)  loss_objectness: 0.0439 (0.0439)  loss_rpn_box_reg: 0.0897 (0.0897)  time: 0.7072  data: 0.3851  max mem: 5923\n",
      "Testing Epoch: [177]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1339 (0.1427)  loss_objectness: 0.0549 (0.0604)  loss_rpn_box_reg: 0.0735 (0.0823)  time: 0.6270  data: 0.3098  max mem: 5923\n",
      "Testing Epoch: [177] Total time: 0:00:39 (0.6353 s / it)\n",
      "Training Epoch: [178]  [  0/250]  eta: 0:02:55  lr: 0.000300  loss: 0.1205 (0.1205)  loss_objectness: 0.0508 (0.0508)  loss_rpn_box_reg: 0.0697 (0.0697)  time: 0.7022  data: 0.3091  max mem: 5923\n",
      "Training Epoch: [178]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1407 (0.1341)  loss_objectness: 0.0742 (0.0717)  loss_rpn_box_reg: 0.0689 (0.0624)  time: 0.6937  data: 0.2978  max mem: 5923\n",
      "Training Epoch: [178]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1468 (0.1407)  loss_objectness: 0.0689 (0.0666)  loss_rpn_box_reg: 0.0729 (0.0741)  time: 0.6992  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [178]  [ 30/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1379 (0.1386)  loss_objectness: 0.0667 (0.0677)  loss_rpn_box_reg: 0.0720 (0.0709)  time: 0.7051  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [178]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1358 (0.1411)  loss_objectness: 0.0681 (0.0680)  loss_rpn_box_reg: 0.0710 (0.0732)  time: 0.6868  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [178]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1367 (0.1432)  loss_objectness: 0.0692 (0.0691)  loss_rpn_box_reg: 0.0743 (0.0741)  time: 0.6724  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [178]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1266 (0.1400)  loss_objectness: 0.0669 (0.0683)  loss_rpn_box_reg: 0.0579 (0.0717)  time: 0.6727  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [178]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1257 (0.1395)  loss_objectness: 0.0619 (0.0683)  loss_rpn_box_reg: 0.0632 (0.0712)  time: 0.6672  data: 0.2861  max mem: 5923\n",
      "Training Epoch: [178]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1269 (0.1375)  loss_objectness: 0.0674 (0.0686)  loss_rpn_box_reg: 0.0607 (0.0690)  time: 0.6829  data: 0.2860  max mem: 5923\n",
      "Training Epoch: [178]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1310 (0.1386)  loss_objectness: 0.0709 (0.0697)  loss_rpn_box_reg: 0.0541 (0.0688)  time: 0.6995  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [178]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1382 (0.1393)  loss_objectness: 0.0732 (0.0701)  loss_rpn_box_reg: 0.0590 (0.0692)  time: 0.6815  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [178]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1424 (0.1400)  loss_objectness: 0.0627 (0.0691)  loss_rpn_box_reg: 0.0744 (0.0709)  time: 0.6712  data: 0.2870  max mem: 5923\n",
      "Training Epoch: [178]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1353 (0.1405)  loss_objectness: 0.0608 (0.0689)  loss_rpn_box_reg: 0.0820 (0.0716)  time: 0.6831  data: 0.2898  max mem: 5923\n",
      "Training Epoch: [178]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1313 (0.1398)  loss_objectness: 0.0671 (0.0688)  loss_rpn_box_reg: 0.0679 (0.0710)  time: 0.6874  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [178]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1313 (0.1402)  loss_objectness: 0.0654 (0.0690)  loss_rpn_box_reg: 0.0595 (0.0713)  time: 0.6919  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [178]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1393 (0.1401)  loss_objectness: 0.0650 (0.0689)  loss_rpn_box_reg: 0.0663 (0.0712)  time: 0.7020  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [178]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1529 (0.1413)  loss_objectness: 0.0728 (0.0698)  loss_rpn_box_reg: 0.0739 (0.0715)  time: 0.6896  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [178]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1533 (0.1410)  loss_objectness: 0.0728 (0.0695)  loss_rpn_box_reg: 0.0700 (0.0715)  time: 0.6898  data: 0.2968  max mem: 5923\n",
      "Training Epoch: [178]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1380 (0.1413)  loss_objectness: 0.0736 (0.0698)  loss_rpn_box_reg: 0.0637 (0.0715)  time: 0.6966  data: 0.3016  max mem: 5923\n",
      "Training Epoch: [178]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1380 (0.1413)  loss_objectness: 0.0772 (0.0702)  loss_rpn_box_reg: 0.0587 (0.0710)  time: 0.6939  data: 0.3031  max mem: 5923\n",
      "Training Epoch: [178]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1418 (0.1417)  loss_objectness: 0.0778 (0.0707)  loss_rpn_box_reg: 0.0663 (0.0711)  time: 0.6886  data: 0.3005  max mem: 5923\n",
      "Training Epoch: [178]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1416 (0.1416)  loss_objectness: 0.0706 (0.0707)  loss_rpn_box_reg: 0.0672 (0.0709)  time: 0.6851  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [178]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1251 (0.1412)  loss_objectness: 0.0692 (0.0709)  loss_rpn_box_reg: 0.0531 (0.0702)  time: 0.6880  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [178]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1335 (0.1411)  loss_objectness: 0.0705 (0.0711)  loss_rpn_box_reg: 0.0488 (0.0700)  time: 0.6733  data: 0.3000  max mem: 5923\n",
      "Training Epoch: [178]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1445 (0.1414)  loss_objectness: 0.0713 (0.0711)  loss_rpn_box_reg: 0.0692 (0.0702)  time: 0.6679  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [178]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1424 (0.1413)  loss_objectness: 0.0637 (0.0710)  loss_rpn_box_reg: 0.0728 (0.0703)  time: 0.6772  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [178] Total time: 0:02:51 (0.6858 s / it)\n",
      "Testing Epoch: [178]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1354 (0.1354)  loss_objectness: 0.0491 (0.0491)  loss_rpn_box_reg: 0.0863 (0.0863)  time: 0.6181  data: 0.2911  max mem: 5923\n",
      "Testing Epoch: [178]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1288 (0.1454)  loss_objectness: 0.0584 (0.0644)  loss_rpn_box_reg: 0.0788 (0.0810)  time: 0.6247  data: 0.3085  max mem: 5923\n",
      "Testing Epoch: [178] Total time: 0:00:39 (0.6355 s / it)\n",
      "Training Epoch: [179]  [  0/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1670 (0.1670)  loss_objectness: 0.0719 (0.0719)  loss_rpn_box_reg: 0.0951 (0.0951)  time: 0.6461  data: 0.2771  max mem: 5923\n",
      "Training Epoch: [179]  [ 10/250]  eta: 0:02:48  lr: 0.000300  loss: 0.1383 (0.1386)  loss_objectness: 0.0640 (0.0672)  loss_rpn_box_reg: 0.0714 (0.0714)  time: 0.7006  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [179]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1406 (0.1431)  loss_objectness: 0.0710 (0.0718)  loss_rpn_box_reg: 0.0727 (0.0713)  time: 0.6883  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [179]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1426 (0.1397)  loss_objectness: 0.0726 (0.0704)  loss_rpn_box_reg: 0.0714 (0.0693)  time: 0.6879  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [179]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1252 (0.1372)  loss_objectness: 0.0585 (0.0682)  loss_rpn_box_reg: 0.0699 (0.0690)  time: 0.6951  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [179]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1271 (0.1385)  loss_objectness: 0.0689 (0.0695)  loss_rpn_box_reg: 0.0624 (0.0689)  time: 0.6934  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [179]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1400 (0.1399)  loss_objectness: 0.0724 (0.0702)  loss_rpn_box_reg: 0.0622 (0.0697)  time: 0.6902  data: 0.2960  max mem: 5923\n",
      "Training Epoch: [179]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1323 (0.1383)  loss_objectness: 0.0592 (0.0687)  loss_rpn_box_reg: 0.0705 (0.0696)  time: 0.6796  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [179]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1346 (0.1402)  loss_objectness: 0.0587 (0.0687)  loss_rpn_box_reg: 0.0732 (0.0715)  time: 0.6804  data: 0.2882  max mem: 5923\n",
      "Training Epoch: [179]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1346 (0.1399)  loss_objectness: 0.0657 (0.0692)  loss_rpn_box_reg: 0.0706 (0.0707)  time: 0.6798  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [179]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1286 (0.1387)  loss_objectness: 0.0687 (0.0688)  loss_rpn_box_reg: 0.0633 (0.0699)  time: 0.6849  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [179]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1258 (0.1382)  loss_objectness: 0.0658 (0.0688)  loss_rpn_box_reg: 0.0632 (0.0693)  time: 0.6841  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [179]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1290 (0.1376)  loss_objectness: 0.0658 (0.0684)  loss_rpn_box_reg: 0.0632 (0.0692)  time: 0.6837  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [179]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1290 (0.1374)  loss_objectness: 0.0610 (0.0683)  loss_rpn_box_reg: 0.0638 (0.0690)  time: 0.6768  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [179]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1386 (0.1381)  loss_objectness: 0.0691 (0.0689)  loss_rpn_box_reg: 0.0676 (0.0692)  time: 0.6667  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [179]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1398 (0.1383)  loss_objectness: 0.0692 (0.0687)  loss_rpn_box_reg: 0.0711 (0.0696)  time: 0.6789  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [179]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1461 (0.1400)  loss_objectness: 0.0671 (0.0696)  loss_rpn_box_reg: 0.0743 (0.0704)  time: 0.6877  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [179]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1390 (0.1392)  loss_objectness: 0.0681 (0.0694)  loss_rpn_box_reg: 0.0694 (0.0698)  time: 0.6761  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [179]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1264 (0.1393)  loss_objectness: 0.0681 (0.0693)  loss_rpn_box_reg: 0.0605 (0.0700)  time: 0.6859  data: 0.2870  max mem: 5923\n",
      "Training Epoch: [179]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1396 (0.1391)  loss_objectness: 0.0687 (0.0696)  loss_rpn_box_reg: 0.0635 (0.0695)  time: 0.6979  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [179]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1396 (0.1390)  loss_objectness: 0.0663 (0.0694)  loss_rpn_box_reg: 0.0644 (0.0696)  time: 0.6843  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [179]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1287 (0.1383)  loss_objectness: 0.0600 (0.0689)  loss_rpn_box_reg: 0.0630 (0.0694)  time: 0.6760  data: 0.2870  max mem: 5923\n",
      "Training Epoch: [179]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1294 (0.1384)  loss_objectness: 0.0652 (0.0692)  loss_rpn_box_reg: 0.0616 (0.0692)  time: 0.6706  data: 0.2877  max mem: 5923\n",
      "Training Epoch: [179]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1388 (0.1388)  loss_objectness: 0.0728 (0.0696)  loss_rpn_box_reg: 0.0622 (0.0692)  time: 0.6741  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [179]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1488 (0.1390)  loss_objectness: 0.0791 (0.0696)  loss_rpn_box_reg: 0.0765 (0.0694)  time: 0.6726  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [179]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1487 (0.1395)  loss_objectness: 0.0684 (0.0700)  loss_rpn_box_reg: 0.0658 (0.0695)  time: 0.6746  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [179] Total time: 0:02:50 (0.6824 s / it)\n",
      "Testing Epoch: [179]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1285 (0.1285)  loss_objectness: 0.0434 (0.0434)  loss_rpn_box_reg: 0.0851 (0.0851)  time: 0.6061  data: 0.2821  max mem: 5923\n",
      "Testing Epoch: [179]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1314 (0.1399)  loss_objectness: 0.0570 (0.0594)  loss_rpn_box_reg: 0.0728 (0.0805)  time: 0.6359  data: 0.3164  max mem: 5923\n",
      "Testing Epoch: [179] Total time: 0:00:39 (0.6318 s / it)\n",
      "Training Epoch: [180]  [  0/250]  eta: 0:02:55  lr: 0.000300  loss: 0.1199 (0.1199)  loss_objectness: 0.0550 (0.0550)  loss_rpn_box_reg: 0.0649 (0.0649)  time: 0.7032  data: 0.2751  max mem: 5923\n",
      "Training Epoch: [180]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1470 (0.1449)  loss_objectness: 0.0697 (0.0722)  loss_rpn_box_reg: 0.0698 (0.0727)  time: 0.6872  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [180]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1398 (0.1403)  loss_objectness: 0.0666 (0.0679)  loss_rpn_box_reg: 0.0707 (0.0725)  time: 0.6900  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [180]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1384 (0.1410)  loss_objectness: 0.0659 (0.0701)  loss_rpn_box_reg: 0.0684 (0.0709)  time: 0.6899  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [180]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1455 (0.1429)  loss_objectness: 0.0677 (0.0709)  loss_rpn_box_reg: 0.0716 (0.0720)  time: 0.6908  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [180]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1508 (0.1432)  loss_objectness: 0.0662 (0.0714)  loss_rpn_box_reg: 0.0758 (0.0718)  time: 0.6823  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [180]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1508 (0.1453)  loss_objectness: 0.0714 (0.0716)  loss_rpn_box_reg: 0.0752 (0.0738)  time: 0.6919  data: 0.2984  max mem: 5923\n",
      "Training Epoch: [180]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1423 (0.1446)  loss_objectness: 0.0709 (0.0712)  loss_rpn_box_reg: 0.0773 (0.0734)  time: 0.6972  data: 0.2981  max mem: 5923\n",
      "Training Epoch: [180]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1281 (0.1428)  loss_objectness: 0.0696 (0.0708)  loss_rpn_box_reg: 0.0683 (0.0720)  time: 0.6932  data: 0.2960  max mem: 5923\n",
      "Training Epoch: [180]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1320 (0.1412)  loss_objectness: 0.0689 (0.0704)  loss_rpn_box_reg: 0.0495 (0.0708)  time: 0.7053  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [180]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1241 (0.1387)  loss_objectness: 0.0618 (0.0697)  loss_rpn_box_reg: 0.0563 (0.0689)  time: 0.6860  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [180]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1140 (0.1386)  loss_objectness: 0.0620 (0.0697)  loss_rpn_box_reg: 0.0563 (0.0688)  time: 0.6799  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [180]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1258 (0.1381)  loss_objectness: 0.0654 (0.0699)  loss_rpn_box_reg: 0.0589 (0.0682)  time: 0.6823  data: 0.3009  max mem: 5923\n",
      "Training Epoch: [180]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1328 (0.1386)  loss_objectness: 0.0659 (0.0698)  loss_rpn_box_reg: 0.0631 (0.0688)  time: 0.6794  data: 0.2973  max mem: 5923\n",
      "Training Epoch: [180]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1434 (0.1394)  loss_objectness: 0.0676 (0.0699)  loss_rpn_box_reg: 0.0702 (0.0695)  time: 0.6761  data: 0.2971  max mem: 5923\n",
      "Training Epoch: [180]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1544 (0.1405)  loss_objectness: 0.0741 (0.0705)  loss_rpn_box_reg: 0.0710 (0.0700)  time: 0.6697  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [180]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1433 (0.1404)  loss_objectness: 0.0660 (0.0704)  loss_rpn_box_reg: 0.0675 (0.0700)  time: 0.6778  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [180]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1340 (0.1403)  loss_objectness: 0.0627 (0.0705)  loss_rpn_box_reg: 0.0588 (0.0698)  time: 0.6886  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [180]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1349 (0.1408)  loss_objectness: 0.0664 (0.0708)  loss_rpn_box_reg: 0.0694 (0.0700)  time: 0.6847  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [180]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1495 (0.1411)  loss_objectness: 0.0708 (0.0709)  loss_rpn_box_reg: 0.0694 (0.0703)  time: 0.6870  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [180]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1322 (0.1410)  loss_objectness: 0.0700 (0.0711)  loss_rpn_box_reg: 0.0598 (0.0699)  time: 0.6976  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [180]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1416 (0.1413)  loss_objectness: 0.0696 (0.0712)  loss_rpn_box_reg: 0.0643 (0.0701)  time: 0.6961  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [180]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1416 (0.1408)  loss_objectness: 0.0692 (0.0711)  loss_rpn_box_reg: 0.0656 (0.0697)  time: 0.7018  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [180]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1224 (0.1405)  loss_objectness: 0.0610 (0.0708)  loss_rpn_box_reg: 0.0596 (0.0697)  time: 0.6920  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [180]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1327 (0.1404)  loss_objectness: 0.0629 (0.0706)  loss_rpn_box_reg: 0.0679 (0.0698)  time: 0.6924  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [180]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1381 (0.1401)  loss_objectness: 0.0663 (0.0706)  loss_rpn_box_reg: 0.0679 (0.0695)  time: 0.6941  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [180] Total time: 0:02:52 (0.6886 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:04  model_time: 0.6842 (0.6842)  evaluator_time: 0.0600 (0.0600)  time: 1.0472  data: 0.2871  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3951 (0.3944)  evaluator_time: 0.0720 (0.0775)  time: 0.7855  data: 0.3172  max mem: 5923\n",
      "Test: Total time: 0:00:48 (0.7864 s / it)\n",
      "Averaged stats: model_time: 0.3951 (0.3944)  evaluator_time: 0.0720 (0.0775)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.10s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [180]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1343 (0.1343)  loss_objectness: 0.0448 (0.0448)  loss_rpn_box_reg: 0.0895 (0.0895)  time: 0.6201  data: 0.2841  max mem: 5923\n",
      "Testing Epoch: [180]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1317 (0.1392)  loss_objectness: 0.0550 (0.0590)  loss_rpn_box_reg: 0.0756 (0.0803)  time: 0.6348  data: 0.3119  max mem: 5923\n",
      "Testing Epoch: [180] Total time: 0:00:39 (0.6326 s / it)\n",
      "Training Epoch: [181]  [  0/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1998 (0.1998)  loss_objectness: 0.0641 (0.0641)  loss_rpn_box_reg: 0.1357 (0.1357)  time: 0.6631  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [181]  [ 10/250]  eta: 0:02:49  lr: 0.000300  loss: 0.1272 (0.1337)  loss_objectness: 0.0640 (0.0629)  loss_rpn_box_reg: 0.0737 (0.0708)  time: 0.7046  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [181]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1272 (0.1306)  loss_objectness: 0.0640 (0.0660)  loss_rpn_box_reg: 0.0555 (0.0646)  time: 0.6940  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [181]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1349 (0.1349)  loss_objectness: 0.0696 (0.0681)  loss_rpn_box_reg: 0.0555 (0.0668)  time: 0.6827  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [181]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1383 (0.1394)  loss_objectness: 0.0740 (0.0717)  loss_rpn_box_reg: 0.0661 (0.0677)  time: 0.6779  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [181]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1368 (0.1389)  loss_objectness: 0.0770 (0.0708)  loss_rpn_box_reg: 0.0661 (0.0681)  time: 0.6859  data: 0.2987  max mem: 5923\n",
      "Training Epoch: [181]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1298 (0.1389)  loss_objectness: 0.0693 (0.0702)  loss_rpn_box_reg: 0.0637 (0.0686)  time: 0.6970  data: 0.2974  max mem: 5923\n",
      "Training Epoch: [181]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1322 (0.1405)  loss_objectness: 0.0687 (0.0711)  loss_rpn_box_reg: 0.0667 (0.0695)  time: 0.6861  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [181]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1457 (0.1425)  loss_objectness: 0.0671 (0.0706)  loss_rpn_box_reg: 0.0757 (0.0719)  time: 0.6718  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [181]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1483 (0.1425)  loss_objectness: 0.0671 (0.0707)  loss_rpn_box_reg: 0.0787 (0.0718)  time: 0.6815  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [181]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1289 (0.1415)  loss_objectness: 0.0658 (0.0698)  loss_rpn_box_reg: 0.0675 (0.0717)  time: 0.6934  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [181]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1315 (0.1410)  loss_objectness: 0.0623 (0.0692)  loss_rpn_box_reg: 0.0712 (0.0717)  time: 0.6856  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [181]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1287 (0.1393)  loss_objectness: 0.0661 (0.0694)  loss_rpn_box_reg: 0.0626 (0.0699)  time: 0.6765  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [181]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1233 (0.1383)  loss_objectness: 0.0672 (0.0690)  loss_rpn_box_reg: 0.0545 (0.0693)  time: 0.6882  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [181]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1313 (0.1383)  loss_objectness: 0.0644 (0.0687)  loss_rpn_box_reg: 0.0645 (0.0696)  time: 0.6937  data: 0.2972  max mem: 5923\n",
      "Training Epoch: [181]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1313 (0.1375)  loss_objectness: 0.0609 (0.0680)  loss_rpn_box_reg: 0.0704 (0.0695)  time: 0.6863  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [181]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1396 (0.1387)  loss_objectness: 0.0694 (0.0690)  loss_rpn_box_reg: 0.0765 (0.0697)  time: 0.6758  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [181]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1503 (0.1395)  loss_objectness: 0.0793 (0.0690)  loss_rpn_box_reg: 0.0778 (0.0705)  time: 0.6850  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [181]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1503 (0.1397)  loss_objectness: 0.0714 (0.0694)  loss_rpn_box_reg: 0.0772 (0.0703)  time: 0.6936  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [181]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1350 (0.1396)  loss_objectness: 0.0714 (0.0694)  loss_rpn_box_reg: 0.0667 (0.0702)  time: 0.6718  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [181]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1350 (0.1401)  loss_objectness: 0.0652 (0.0697)  loss_rpn_box_reg: 0.0671 (0.0704)  time: 0.6907  data: 0.2985  max mem: 5923\n",
      "Training Epoch: [181]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1429 (0.1400)  loss_objectness: 0.0641 (0.0695)  loss_rpn_box_reg: 0.0715 (0.0705)  time: 0.6980  data: 0.2976  max mem: 5923\n",
      "Training Epoch: [181]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1283 (0.1393)  loss_objectness: 0.0552 (0.0693)  loss_rpn_box_reg: 0.0687 (0.0700)  time: 0.6689  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [181]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1176 (0.1390)  loss_objectness: 0.0627 (0.0693)  loss_rpn_box_reg: 0.0545 (0.0697)  time: 0.6710  data: 0.2863  max mem: 5923\n",
      "Training Epoch: [181]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1251 (0.1391)  loss_objectness: 0.0650 (0.0694)  loss_rpn_box_reg: 0.0569 (0.0697)  time: 0.6796  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [181]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1319 (0.1394)  loss_objectness: 0.0695 (0.0697)  loss_rpn_box_reg: 0.0682 (0.0697)  time: 0.6856  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [181] Total time: 0:02:51 (0.6845 s / it)\n",
      "Testing Epoch: [181]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1361 (0.1361)  loss_objectness: 0.0458 (0.0458)  loss_rpn_box_reg: 0.0904 (0.0904)  time: 0.6351  data: 0.2901  max mem: 5923\n",
      "Testing Epoch: [181]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1316 (0.1452)  loss_objectness: 0.0595 (0.0635)  loss_rpn_box_reg: 0.0773 (0.0817)  time: 0.6367  data: 0.3121  max mem: 5923\n",
      "Testing Epoch: [181] Total time: 0:00:39 (0.6355 s / it)\n",
      "Training Epoch: [182]  [  0/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1243 (0.1243)  loss_objectness: 0.0607 (0.0607)  loss_rpn_box_reg: 0.0636 (0.0636)  time: 0.6662  data: 0.3041  max mem: 5923\n",
      "Training Epoch: [182]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1465 (0.1587)  loss_objectness: 0.0667 (0.0744)  loss_rpn_box_reg: 0.0754 (0.0843)  time: 0.6801  data: 0.2876  max mem: 5923\n",
      "Training Epoch: [182]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1415 (0.1489)  loss_objectness: 0.0667 (0.0698)  loss_rpn_box_reg: 0.0721 (0.0791)  time: 0.6874  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [182]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1298 (0.1420)  loss_objectness: 0.0608 (0.0665)  loss_rpn_box_reg: 0.0602 (0.0755)  time: 0.6896  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [182]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1147 (0.1367)  loss_objectness: 0.0597 (0.0650)  loss_rpn_box_reg: 0.0600 (0.0717)  time: 0.6785  data: 0.2873  max mem: 5923\n",
      "Training Epoch: [182]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1289 (0.1380)  loss_objectness: 0.0652 (0.0661)  loss_rpn_box_reg: 0.0635 (0.0719)  time: 0.6776  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [182]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1409 (0.1368)  loss_objectness: 0.0677 (0.0657)  loss_rpn_box_reg: 0.0643 (0.0711)  time: 0.6868  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [182]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1251 (0.1356)  loss_objectness: 0.0685 (0.0659)  loss_rpn_box_reg: 0.0591 (0.0697)  time: 0.6845  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [182]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1251 (0.1358)  loss_objectness: 0.0693 (0.0663)  loss_rpn_box_reg: 0.0617 (0.0696)  time: 0.6798  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [182]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1290 (0.1355)  loss_objectness: 0.0588 (0.0658)  loss_rpn_box_reg: 0.0679 (0.0697)  time: 0.6756  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [182]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1205 (0.1344)  loss_objectness: 0.0614 (0.0657)  loss_rpn_box_reg: 0.0631 (0.0687)  time: 0.6786  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [182]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1167 (0.1334)  loss_objectness: 0.0614 (0.0650)  loss_rpn_box_reg: 0.0577 (0.0685)  time: 0.6748  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [182]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1317 (0.1346)  loss_objectness: 0.0616 (0.0659)  loss_rpn_box_reg: 0.0577 (0.0687)  time: 0.6784  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [182]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1441 (0.1351)  loss_objectness: 0.0617 (0.0658)  loss_rpn_box_reg: 0.0735 (0.0693)  time: 0.6874  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [182]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1417 (0.1356)  loss_objectness: 0.0705 (0.0665)  loss_rpn_box_reg: 0.0735 (0.0692)  time: 0.6877  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [182]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1327 (0.1347)  loss_objectness: 0.0629 (0.0661)  loss_rpn_box_reg: 0.0574 (0.0686)  time: 0.6872  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [182]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1327 (0.1346)  loss_objectness: 0.0592 (0.0660)  loss_rpn_box_reg: 0.0641 (0.0686)  time: 0.6843  data: 0.2873  max mem: 5923\n",
      "Training Epoch: [182]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1382 (0.1346)  loss_objectness: 0.0658 (0.0664)  loss_rpn_box_reg: 0.0621 (0.0682)  time: 0.6839  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [182]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1419 (0.1353)  loss_objectness: 0.0688 (0.0669)  loss_rpn_box_reg: 0.0621 (0.0684)  time: 0.6842  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [182]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1444 (0.1363)  loss_objectness: 0.0693 (0.0677)  loss_rpn_box_reg: 0.0696 (0.0686)  time: 0.6875  data: 0.2969  max mem: 5923\n",
      "Training Epoch: [182]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1417 (0.1368)  loss_objectness: 0.0746 (0.0683)  loss_rpn_box_reg: 0.0695 (0.0685)  time: 0.6904  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [182]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1388 (0.1373)  loss_objectness: 0.0746 (0.0687)  loss_rpn_box_reg: 0.0652 (0.0685)  time: 0.6994  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [182]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1492 (0.1383)  loss_objectness: 0.0778 (0.0691)  loss_rpn_box_reg: 0.0748 (0.0692)  time: 0.6854  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [182]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1493 (0.1387)  loss_objectness: 0.0826 (0.0698)  loss_rpn_box_reg: 0.0681 (0.0689)  time: 0.6835  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [182]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1464 (0.1391)  loss_objectness: 0.0827 (0.0702)  loss_rpn_box_reg: 0.0600 (0.0689)  time: 0.6866  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [182]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1478 (0.1400)  loss_objectness: 0.0793 (0.0706)  loss_rpn_box_reg: 0.0753 (0.0694)  time: 0.6700  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [182] Total time: 0:02:50 (0.6834 s / it)\n",
      "Testing Epoch: [182]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1328 (0.1328)  loss_objectness: 0.0466 (0.0466)  loss_rpn_box_reg: 0.0863 (0.0863)  time: 0.6381  data: 0.3111  max mem: 5923\n",
      "Testing Epoch: [182]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1354 (0.1413)  loss_objectness: 0.0562 (0.0599)  loss_rpn_box_reg: 0.0790 (0.0814)  time: 0.6303  data: 0.3105  max mem: 5923\n",
      "Testing Epoch: [182] Total time: 0:00:39 (0.6313 s / it)\n",
      "Training Epoch: [183]  [  0/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1413 (0.1413)  loss_objectness: 0.0842 (0.0842)  loss_rpn_box_reg: 0.0571 (0.0571)  time: 0.6321  data: 0.3121  max mem: 5923\n",
      "Training Epoch: [183]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1230 (0.1226)  loss_objectness: 0.0673 (0.0686)  loss_rpn_box_reg: 0.0473 (0.0541)  time: 0.6822  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [183]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1234 (0.1317)  loss_objectness: 0.0689 (0.0716)  loss_rpn_box_reg: 0.0563 (0.0601)  time: 0.6822  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [183]  [ 30/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1277 (0.1290)  loss_objectness: 0.0681 (0.0686)  loss_rpn_box_reg: 0.0640 (0.0604)  time: 0.6707  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [183]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1277 (0.1312)  loss_objectness: 0.0670 (0.0685)  loss_rpn_box_reg: 0.0672 (0.0627)  time: 0.6786  data: 0.2884  max mem: 5923\n",
      "Training Epoch: [183]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1420 (0.1327)  loss_objectness: 0.0681 (0.0692)  loss_rpn_box_reg: 0.0598 (0.0635)  time: 0.6937  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [183]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1353 (0.1329)  loss_objectness: 0.0620 (0.0693)  loss_rpn_box_reg: 0.0603 (0.0636)  time: 0.6891  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [183]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1313 (0.1335)  loss_objectness: 0.0620 (0.0695)  loss_rpn_box_reg: 0.0624 (0.0641)  time: 0.6875  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [183]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1343 (0.1342)  loss_objectness: 0.0738 (0.0700)  loss_rpn_box_reg: 0.0639 (0.0642)  time: 0.7039  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [183]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1352 (0.1341)  loss_objectness: 0.0669 (0.0693)  loss_rpn_box_reg: 0.0639 (0.0647)  time: 0.7034  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [183]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1352 (0.1349)  loss_objectness: 0.0654 (0.0692)  loss_rpn_box_reg: 0.0692 (0.0657)  time: 0.6904  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [183]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1407 (0.1368)  loss_objectness: 0.0680 (0.0698)  loss_rpn_box_reg: 0.0692 (0.0671)  time: 0.6869  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [183]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1440 (0.1370)  loss_objectness: 0.0728 (0.0694)  loss_rpn_box_reg: 0.0715 (0.0675)  time: 0.6937  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [183]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1190 (0.1359)  loss_objectness: 0.0579 (0.0689)  loss_rpn_box_reg: 0.0604 (0.0669)  time: 0.6938  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [183]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1219 (0.1364)  loss_objectness: 0.0591 (0.0688)  loss_rpn_box_reg: 0.0607 (0.0676)  time: 0.6807  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [183]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1329 (0.1366)  loss_objectness: 0.0691 (0.0692)  loss_rpn_box_reg: 0.0685 (0.0674)  time: 0.6835  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [183]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1244 (0.1360)  loss_objectness: 0.0691 (0.0690)  loss_rpn_box_reg: 0.0542 (0.0669)  time: 0.6963  data: 0.2963  max mem: 5923\n",
      "Training Epoch: [183]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1330 (0.1366)  loss_objectness: 0.0683 (0.0694)  loss_rpn_box_reg: 0.0608 (0.0672)  time: 0.6894  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [183]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1409 (0.1366)  loss_objectness: 0.0679 (0.0695)  loss_rpn_box_reg: 0.0641 (0.0671)  time: 0.6864  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [183]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1409 (0.1368)  loss_objectness: 0.0667 (0.0695)  loss_rpn_box_reg: 0.0620 (0.0673)  time: 0.6966  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [183]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1400 (0.1368)  loss_objectness: 0.0658 (0.0694)  loss_rpn_box_reg: 0.0663 (0.0674)  time: 0.6784  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [183]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1528 (0.1385)  loss_objectness: 0.0752 (0.0698)  loss_rpn_box_reg: 0.0787 (0.0687)  time: 0.6650  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [183]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1528 (0.1392)  loss_objectness: 0.0776 (0.0702)  loss_rpn_box_reg: 0.0851 (0.0690)  time: 0.6772  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [183]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1358 (0.1390)  loss_objectness: 0.0708 (0.0700)  loss_rpn_box_reg: 0.0673 (0.0690)  time: 0.6816  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [183]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1351 (0.1391)  loss_objectness: 0.0698 (0.0701)  loss_rpn_box_reg: 0.0688 (0.0690)  time: 0.6866  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [183]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1374 (0.1392)  loss_objectness: 0.0701 (0.0700)  loss_rpn_box_reg: 0.0680 (0.0691)  time: 0.6822  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [183] Total time: 0:02:51 (0.6862 s / it)\n",
      "Testing Epoch: [183]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1357 (0.1357)  loss_objectness: 0.0473 (0.0473)  loss_rpn_box_reg: 0.0884 (0.0884)  time: 0.6291  data: 0.3011  max mem: 5923\n",
      "Testing Epoch: [183]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1282 (0.1392)  loss_objectness: 0.0533 (0.0585)  loss_rpn_box_reg: 0.0753 (0.0808)  time: 0.6322  data: 0.3134  max mem: 5923\n",
      "Testing Epoch: [183] Total time: 0:00:39 (0.6347 s / it)\n",
      "Training Epoch: [184]  [  0/250]  eta: 0:02:58  lr: 0.000300  loss: 0.0887 (0.0887)  loss_objectness: 0.0692 (0.0692)  loss_rpn_box_reg: 0.0196 (0.0196)  time: 0.7152  data: 0.2821  max mem: 5923\n",
      "Training Epoch: [184]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1329 (0.1300)  loss_objectness: 0.0692 (0.0690)  loss_rpn_box_reg: 0.0609 (0.0610)  time: 0.6956  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [184]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1231 (0.1233)  loss_objectness: 0.0614 (0.0635)  loss_rpn_box_reg: 0.0609 (0.0599)  time: 0.6807  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [184]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1140 (0.1232)  loss_objectness: 0.0588 (0.0628)  loss_rpn_box_reg: 0.0547 (0.0604)  time: 0.6767  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [184]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1140 (0.1251)  loss_objectness: 0.0588 (0.0622)  loss_rpn_box_reg: 0.0549 (0.0629)  time: 0.6922  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [184]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1247 (0.1265)  loss_objectness: 0.0628 (0.0632)  loss_rpn_box_reg: 0.0552 (0.0633)  time: 0.6923  data: 0.2964  max mem: 5923\n",
      "Training Epoch: [184]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1288 (0.1287)  loss_objectness: 0.0681 (0.0646)  loss_rpn_box_reg: 0.0552 (0.0641)  time: 0.6802  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [184]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1252 (0.1291)  loss_objectness: 0.0694 (0.0649)  loss_rpn_box_reg: 0.0530 (0.0642)  time: 0.6789  data: 0.2985  max mem: 5923\n",
      "Training Epoch: [184]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1192 (0.1283)  loss_objectness: 0.0670 (0.0650)  loss_rpn_box_reg: 0.0520 (0.0633)  time: 0.6941  data: 0.2986  max mem: 5923\n",
      "Training Epoch: [184]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1223 (0.1285)  loss_objectness: 0.0621 (0.0650)  loss_rpn_box_reg: 0.0583 (0.0635)  time: 0.7000  data: 0.2992  max mem: 5923\n",
      "Training Epoch: [184]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1488 (0.1309)  loss_objectness: 0.0615 (0.0653)  loss_rpn_box_reg: 0.0673 (0.0656)  time: 0.6897  data: 0.2995  max mem: 5923\n",
      "Training Epoch: [184]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1478 (0.1304)  loss_objectness: 0.0598 (0.0649)  loss_rpn_box_reg: 0.0785 (0.0656)  time: 0.6922  data: 0.2968  max mem: 5923\n",
      "Training Epoch: [184]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1373 (0.1316)  loss_objectness: 0.0611 (0.0655)  loss_rpn_box_reg: 0.0736 (0.0661)  time: 0.7109  data: 0.2967  max mem: 5923\n",
      "Training Epoch: [184]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1448 (0.1335)  loss_objectness: 0.0725 (0.0663)  loss_rpn_box_reg: 0.0762 (0.0672)  time: 0.7058  data: 0.2981  max mem: 5923\n",
      "Training Epoch: [184]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1460 (0.1344)  loss_objectness: 0.0751 (0.0671)  loss_rpn_box_reg: 0.0786 (0.0672)  time: 0.6907  data: 0.2971  max mem: 5923\n",
      "Training Epoch: [184]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1537 (0.1356)  loss_objectness: 0.0751 (0.0674)  loss_rpn_box_reg: 0.0812 (0.0682)  time: 0.6864  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [184]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1548 (0.1366)  loss_objectness: 0.0727 (0.0681)  loss_rpn_box_reg: 0.0766 (0.0685)  time: 0.6833  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [184]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1459 (0.1374)  loss_objectness: 0.0769 (0.0687)  loss_rpn_box_reg: 0.0661 (0.0688)  time: 0.6859  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [184]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1445 (0.1378)  loss_objectness: 0.0748 (0.0689)  loss_rpn_box_reg: 0.0661 (0.0689)  time: 0.6847  data: 0.2971  max mem: 5923\n",
      "Training Epoch: [184]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1501 (0.1386)  loss_objectness: 0.0677 (0.0692)  loss_rpn_box_reg: 0.0679 (0.0693)  time: 0.6753  data: 0.2971  max mem: 5923\n",
      "Training Epoch: [184]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1426 (0.1382)  loss_objectness: 0.0648 (0.0689)  loss_rpn_box_reg: 0.0635 (0.0693)  time: 0.6828  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [184]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1218 (0.1381)  loss_objectness: 0.0665 (0.0692)  loss_rpn_box_reg: 0.0574 (0.0689)  time: 0.6886  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [184]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1242 (0.1387)  loss_objectness: 0.0694 (0.0694)  loss_rpn_box_reg: 0.0619 (0.0693)  time: 0.6806  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [184]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1435 (0.1391)  loss_objectness: 0.0717 (0.0696)  loss_rpn_box_reg: 0.0734 (0.0695)  time: 0.6856  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [184]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1405 (0.1391)  loss_objectness: 0.0686 (0.0696)  loss_rpn_box_reg: 0.0696 (0.0695)  time: 0.6791  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [184]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1322 (0.1388)  loss_objectness: 0.0707 (0.0696)  loss_rpn_box_reg: 0.0635 (0.0692)  time: 0.6737  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [184] Total time: 0:02:51 (0.6872 s / it)\n",
      "Testing Epoch: [184]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1413 (0.1413)  loss_objectness: 0.0504 (0.0504)  loss_rpn_box_reg: 0.0909 (0.0909)  time: 0.6321  data: 0.3031  max mem: 5923\n",
      "Testing Epoch: [184]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1324 (0.1433)  loss_objectness: 0.0583 (0.0622)  loss_rpn_box_reg: 0.0731 (0.0812)  time: 0.6281  data: 0.3093  max mem: 5923\n",
      "Testing Epoch: [184] Total time: 0:00:39 (0.6355 s / it)\n",
      "Training Epoch: [185]  [  0/250]  eta: 0:02:49  lr: 0.000300  loss: 0.1323 (0.1323)  loss_objectness: 0.0902 (0.0902)  loss_rpn_box_reg: 0.0421 (0.0421)  time: 0.6782  data: 0.3121  max mem: 5923\n",
      "Training Epoch: [185]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1416 (0.1372)  loss_objectness: 0.0722 (0.0746)  loss_rpn_box_reg: 0.0668 (0.0626)  time: 0.6979  data: 0.2982  max mem: 5923\n",
      "Training Epoch: [185]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1416 (0.1416)  loss_objectness: 0.0662 (0.0736)  loss_rpn_box_reg: 0.0668 (0.0680)  time: 0.6822  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [185]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1371 (0.1372)  loss_objectness: 0.0639 (0.0711)  loss_rpn_box_reg: 0.0650 (0.0662)  time: 0.6670  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [185]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1282 (0.1361)  loss_objectness: 0.0643 (0.0709)  loss_rpn_box_reg: 0.0574 (0.0652)  time: 0.6852  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [185]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1302 (0.1362)  loss_objectness: 0.0649 (0.0705)  loss_rpn_box_reg: 0.0608 (0.0657)  time: 0.6881  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [185]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1316 (0.1384)  loss_objectness: 0.0649 (0.0696)  loss_rpn_box_reg: 0.0680 (0.0688)  time: 0.6847  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [185]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1294 (0.1390)  loss_objectness: 0.0665 (0.0694)  loss_rpn_box_reg: 0.0757 (0.0696)  time: 0.6888  data: 0.2975  max mem: 5923\n",
      "Training Epoch: [185]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1274 (0.1392)  loss_objectness: 0.0694 (0.0694)  loss_rpn_box_reg: 0.0672 (0.0698)  time: 0.6827  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [185]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1364 (0.1406)  loss_objectness: 0.0728 (0.0695)  loss_rpn_box_reg: 0.0653 (0.0711)  time: 0.6907  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [185]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1397 (0.1402)  loss_objectness: 0.0728 (0.0697)  loss_rpn_box_reg: 0.0753 (0.0705)  time: 0.6903  data: 0.2874  max mem: 5923\n",
      "Training Epoch: [185]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1355 (0.1401)  loss_objectness: 0.0693 (0.0699)  loss_rpn_box_reg: 0.0702 (0.0702)  time: 0.6848  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [185]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1346 (0.1397)  loss_objectness: 0.0704 (0.0698)  loss_rpn_box_reg: 0.0638 (0.0699)  time: 0.6854  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [185]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1355 (0.1404)  loss_objectness: 0.0650 (0.0695)  loss_rpn_box_reg: 0.0690 (0.0709)  time: 0.6751  data: 0.2870  max mem: 5923\n",
      "Training Epoch: [185]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1454 (0.1404)  loss_objectness: 0.0676 (0.0698)  loss_rpn_box_reg: 0.0717 (0.0706)  time: 0.6771  data: 0.2880  max mem: 5923\n",
      "Training Epoch: [185]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1301 (0.1398)  loss_objectness: 0.0714 (0.0701)  loss_rpn_box_reg: 0.0596 (0.0698)  time: 0.6873  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [185]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1418 (0.1398)  loss_objectness: 0.0667 (0.0699)  loss_rpn_box_reg: 0.0630 (0.0700)  time: 0.6822  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [185]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1422 (0.1397)  loss_objectness: 0.0667 (0.0699)  loss_rpn_box_reg: 0.0725 (0.0698)  time: 0.6757  data: 0.2886  max mem: 5923\n",
      "Training Epoch: [185]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1292 (0.1388)  loss_objectness: 0.0698 (0.0697)  loss_rpn_box_reg: 0.0632 (0.0692)  time: 0.6778  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [185]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1261 (0.1387)  loss_objectness: 0.0651 (0.0697)  loss_rpn_box_reg: 0.0567 (0.0690)  time: 0.6857  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [185]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1234 (0.1378)  loss_objectness: 0.0593 (0.0693)  loss_rpn_box_reg: 0.0588 (0.0685)  time: 0.6881  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [185]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1387 (0.1385)  loss_objectness: 0.0601 (0.0692)  loss_rpn_box_reg: 0.0705 (0.0693)  time: 0.6778  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [185]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1454 (0.1387)  loss_objectness: 0.0676 (0.0694)  loss_rpn_box_reg: 0.0705 (0.0692)  time: 0.6634  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [185]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1420 (0.1387)  loss_objectness: 0.0705 (0.0694)  loss_rpn_box_reg: 0.0661 (0.0693)  time: 0.6729  data: 0.2884  max mem: 5923\n",
      "Training Epoch: [185]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1332 (0.1387)  loss_objectness: 0.0645 (0.0691)  loss_rpn_box_reg: 0.0705 (0.0696)  time: 0.6856  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [185]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1332 (0.1386)  loss_objectness: 0.0685 (0.0692)  loss_rpn_box_reg: 0.0732 (0.0694)  time: 0.6715  data: 0.2877  max mem: 5923\n",
      "Training Epoch: [185] Total time: 0:02:50 (0.6814 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:05  model_time: 0.7052 (0.7052)  evaluator_time: 0.0540 (0.0540)  time: 1.0552  data: 0.2801  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3851 (0.3893)  evaluator_time: 0.0690 (0.0776)  time: 0.7744  data: 0.3009  max mem: 5923\n",
      "Test: Total time: 0:00:48 (0.7754 s / it)\n",
      "Averaged stats: model_time: 0.3851 (0.3893)  evaluator_time: 0.0690 (0.0776)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.06s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.173\n",
      "Testing Epoch: [185]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1387 (0.1387)  loss_objectness: 0.0456 (0.0456)  loss_rpn_box_reg: 0.0931 (0.0931)  time: 0.6231  data: 0.2911  max mem: 5923\n",
      "Testing Epoch: [185]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1341 (0.1435)  loss_objectness: 0.0534 (0.0595)  loss_rpn_box_reg: 0.0771 (0.0840)  time: 0.6374  data: 0.3144  max mem: 5923\n",
      "Testing Epoch: [185] Total time: 0:00:39 (0.6335 s / it)\n",
      "Training Epoch: [186]  [  0/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1810 (0.1810)  loss_objectness: 0.0458 (0.0458)  loss_rpn_box_reg: 0.1352 (0.1352)  time: 0.6511  data: 0.3031  max mem: 5923\n",
      "Training Epoch: [186]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1308 (0.1312)  loss_objectness: 0.0630 (0.0663)  loss_rpn_box_reg: 0.0575 (0.0650)  time: 0.6812  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [186]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1204 (0.1290)  loss_objectness: 0.0651 (0.0673)  loss_rpn_box_reg: 0.0575 (0.0617)  time: 0.6865  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [186]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1282 (0.1300)  loss_objectness: 0.0634 (0.0656)  loss_rpn_box_reg: 0.0635 (0.0644)  time: 0.6943  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [186]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1309 (0.1310)  loss_objectness: 0.0634 (0.0658)  loss_rpn_box_reg: 0.0709 (0.0652)  time: 0.6883  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [186]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1430 (0.1323)  loss_objectness: 0.0652 (0.0674)  loss_rpn_box_reg: 0.0610 (0.0649)  time: 0.6744  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [186]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1416 (0.1347)  loss_objectness: 0.0685 (0.0688)  loss_rpn_box_reg: 0.0610 (0.0659)  time: 0.6785  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [186]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1401 (0.1347)  loss_objectness: 0.0706 (0.0688)  loss_rpn_box_reg: 0.0653 (0.0659)  time: 0.6807  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [186]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1270 (0.1330)  loss_objectness: 0.0671 (0.0683)  loss_rpn_box_reg: 0.0557 (0.0647)  time: 0.6798  data: 0.2963  max mem: 5923\n",
      "Training Epoch: [186]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1226 (0.1337)  loss_objectness: 0.0623 (0.0682)  loss_rpn_box_reg: 0.0601 (0.0655)  time: 0.6925  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [186]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1228 (0.1329)  loss_objectness: 0.0623 (0.0679)  loss_rpn_box_reg: 0.0622 (0.0650)  time: 0.6910  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [186]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1279 (0.1354)  loss_objectness: 0.0691 (0.0688)  loss_rpn_box_reg: 0.0645 (0.0666)  time: 0.6847  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [186]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1446 (0.1353)  loss_objectness: 0.0676 (0.0685)  loss_rpn_box_reg: 0.0734 (0.0669)  time: 0.6817  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [186]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1305 (0.1354)  loss_objectness: 0.0645 (0.0683)  loss_rpn_box_reg: 0.0681 (0.0672)  time: 0.6869  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [186]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1419 (0.1357)  loss_objectness: 0.0664 (0.0684)  loss_rpn_box_reg: 0.0658 (0.0673)  time: 0.6954  data: 0.2963  max mem: 5923\n",
      "Training Epoch: [186]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1399 (0.1370)  loss_objectness: 0.0701 (0.0690)  loss_rpn_box_reg: 0.0662 (0.0680)  time: 0.6967  data: 0.2970  max mem: 5923\n",
      "Training Epoch: [186]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1352 (0.1364)  loss_objectness: 0.0697 (0.0686)  loss_rpn_box_reg: 0.0662 (0.0678)  time: 0.6871  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [186]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1328 (0.1363)  loss_objectness: 0.0629 (0.0684)  loss_rpn_box_reg: 0.0616 (0.0678)  time: 0.6905  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [186]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1358 (0.1369)  loss_objectness: 0.0660 (0.0682)  loss_rpn_box_reg: 0.0683 (0.0687)  time: 0.6962  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [186]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1358 (0.1368)  loss_objectness: 0.0666 (0.0681)  loss_rpn_box_reg: 0.0683 (0.0687)  time: 0.6824  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [186]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1308 (0.1375)  loss_objectness: 0.0693 (0.0687)  loss_rpn_box_reg: 0.0613 (0.0689)  time: 0.6829  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [186]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1433 (0.1384)  loss_objectness: 0.0741 (0.0691)  loss_rpn_box_reg: 0.0672 (0.0693)  time: 0.6953  data: 0.2999  max mem: 5923\n",
      "Training Epoch: [186]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1530 (0.1389)  loss_objectness: 0.0760 (0.0697)  loss_rpn_box_reg: 0.0673 (0.0692)  time: 0.6969  data: 0.2997  max mem: 5923\n",
      "Training Epoch: [186]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1535 (0.1396)  loss_objectness: 0.0736 (0.0699)  loss_rpn_box_reg: 0.0808 (0.0697)  time: 0.6878  data: 0.2991  max mem: 5923\n",
      "Training Epoch: [186]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1562 (0.1397)  loss_objectness: 0.0752 (0.0702)  loss_rpn_box_reg: 0.0708 (0.0695)  time: 0.6917  data: 0.2964  max mem: 5923\n",
      "Training Epoch: [186]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1400 (0.1399)  loss_objectness: 0.0814 (0.0704)  loss_rpn_box_reg: 0.0667 (0.0695)  time: 0.6870  data: 0.2980  max mem: 5923\n",
      "Training Epoch: [186] Total time: 0:02:51 (0.6875 s / it)\n",
      "Testing Epoch: [186]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1352 (0.1352)  loss_objectness: 0.0476 (0.0476)  loss_rpn_box_reg: 0.0876 (0.0876)  time: 0.6211  data: 0.2871  max mem: 5923\n",
      "Testing Epoch: [186]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1263 (0.1426)  loss_objectness: 0.0561 (0.0623)  loss_rpn_box_reg: 0.0685 (0.0802)  time: 0.6356  data: 0.3143  max mem: 5923\n",
      "Testing Epoch: [186] Total time: 0:00:39 (0.6381 s / it)\n",
      "Training Epoch: [187]  [  0/250]  eta: 0:02:57  lr: 0.000300  loss: 0.1164 (0.1164)  loss_objectness: 0.0586 (0.0586)  loss_rpn_box_reg: 0.0579 (0.0579)  time: 0.7082  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [187]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1169 (0.1288)  loss_objectness: 0.0673 (0.0682)  loss_rpn_box_reg: 0.0579 (0.0606)  time: 0.6873  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [187]  [ 20/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1384 (0.1442)  loss_objectness: 0.0762 (0.0738)  loss_rpn_box_reg: 0.0640 (0.0705)  time: 0.6762  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [187]  [ 30/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1384 (0.1384)  loss_objectness: 0.0762 (0.0714)  loss_rpn_box_reg: 0.0664 (0.0671)  time: 0.6691  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [187]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1284 (0.1406)  loss_objectness: 0.0663 (0.0699)  loss_rpn_box_reg: 0.0658 (0.0707)  time: 0.6765  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [187]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1418 (0.1420)  loss_objectness: 0.0692 (0.0704)  loss_rpn_box_reg: 0.0699 (0.0715)  time: 0.6885  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [187]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1414 (0.1416)  loss_objectness: 0.0703 (0.0700)  loss_rpn_box_reg: 0.0743 (0.0716)  time: 0.6872  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [187]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1376 (0.1398)  loss_objectness: 0.0604 (0.0691)  loss_rpn_box_reg: 0.0711 (0.0706)  time: 0.6880  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [187]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1263 (0.1392)  loss_objectness: 0.0545 (0.0682)  loss_rpn_box_reg: 0.0631 (0.0710)  time: 0.6971  data: 0.2884  max mem: 5923\n",
      "Training Epoch: [187]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1263 (0.1381)  loss_objectness: 0.0613 (0.0676)  loss_rpn_box_reg: 0.0631 (0.0705)  time: 0.6817  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [187]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1288 (0.1367)  loss_objectness: 0.0646 (0.0679)  loss_rpn_box_reg: 0.0576 (0.0688)  time: 0.6731  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [187]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1296 (0.1374)  loss_objectness: 0.0659 (0.0682)  loss_rpn_box_reg: 0.0617 (0.0692)  time: 0.6839  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [187]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1334 (0.1385)  loss_objectness: 0.0670 (0.0688)  loss_rpn_box_reg: 0.0666 (0.0697)  time: 0.6703  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [187]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1389 (0.1377)  loss_objectness: 0.0670 (0.0687)  loss_rpn_box_reg: 0.0584 (0.0691)  time: 0.6779  data: 0.2853  max mem: 5923\n",
      "Training Epoch: [187]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1373 (0.1385)  loss_objectness: 0.0670 (0.0687)  loss_rpn_box_reg: 0.0636 (0.0697)  time: 0.6991  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [187]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1347 (0.1384)  loss_objectness: 0.0641 (0.0689)  loss_rpn_box_reg: 0.0657 (0.0695)  time: 0.6823  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [187]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1359 (0.1389)  loss_objectness: 0.0617 (0.0692)  loss_rpn_box_reg: 0.0679 (0.0697)  time: 0.6685  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [187]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1413 (0.1393)  loss_objectness: 0.0680 (0.0694)  loss_rpn_box_reg: 0.0679 (0.0699)  time: 0.6933  data: 0.3003  max mem: 5923\n",
      "Training Epoch: [187]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1413 (0.1398)  loss_objectness: 0.0756 (0.0697)  loss_rpn_box_reg: 0.0633 (0.0700)  time: 0.6943  data: 0.2997  max mem: 5923\n",
      "Training Epoch: [187]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1354 (0.1395)  loss_objectness: 0.0736 (0.0698)  loss_rpn_box_reg: 0.0633 (0.0696)  time: 0.6813  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [187]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1285 (0.1390)  loss_objectness: 0.0686 (0.0699)  loss_rpn_box_reg: 0.0596 (0.0690)  time: 0.6814  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [187]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1392 (0.1396)  loss_objectness: 0.0686 (0.0700)  loss_rpn_box_reg: 0.0613 (0.0696)  time: 0.6793  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [187]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1470 (0.1402)  loss_objectness: 0.0707 (0.0702)  loss_rpn_box_reg: 0.0838 (0.0700)  time: 0.6756  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [187]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1416 (0.1397)  loss_objectness: 0.0758 (0.0702)  loss_rpn_box_reg: 0.0705 (0.0695)  time: 0.6808  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [187]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1387 (0.1399)  loss_objectness: 0.0651 (0.0703)  loss_rpn_box_reg: 0.0605 (0.0696)  time: 0.6968  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [187]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1400 (0.1403)  loss_objectness: 0.0651 (0.0706)  loss_rpn_box_reg: 0.0690 (0.0697)  time: 0.6821  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [187] Total time: 0:02:50 (0.6827 s / it)\n",
      "Testing Epoch: [187]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1371 (0.1371)  loss_objectness: 0.0520 (0.0520)  loss_rpn_box_reg: 0.0852 (0.0852)  time: 0.6221  data: 0.2971  max mem: 5923\n",
      "Testing Epoch: [187]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1258 (0.1429)  loss_objectness: 0.0564 (0.0640)  loss_rpn_box_reg: 0.0706 (0.0790)  time: 0.6319  data: 0.3094  max mem: 5923\n",
      "Testing Epoch: [187] Total time: 0:00:39 (0.6341 s / it)\n",
      "Training Epoch: [188]  [  0/250]  eta: 0:02:54  lr: 0.000300  loss: 0.1425 (0.1425)  loss_objectness: 0.0696 (0.0696)  loss_rpn_box_reg: 0.0729 (0.0729)  time: 0.6962  data: 0.3041  max mem: 5923\n",
      "Training Epoch: [188]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1318 (0.1342)  loss_objectness: 0.0696 (0.0703)  loss_rpn_box_reg: 0.0613 (0.0638)  time: 0.6830  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [188]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1318 (0.1357)  loss_objectness: 0.0664 (0.0694)  loss_rpn_box_reg: 0.0630 (0.0662)  time: 0.6835  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [188]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1357 (0.1370)  loss_objectness: 0.0667 (0.0687)  loss_rpn_box_reg: 0.0663 (0.0683)  time: 0.6775  data: 0.2898  max mem: 5923\n",
      "Training Epoch: [188]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1382 (0.1394)  loss_objectness: 0.0700 (0.0710)  loss_rpn_box_reg: 0.0595 (0.0684)  time: 0.6700  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [188]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1392 (0.1375)  loss_objectness: 0.0666 (0.0697)  loss_rpn_box_reg: 0.0595 (0.0678)  time: 0.6755  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [188]  [ 60/250]  eta: 0:02:08  lr: 0.000300  loss: 0.1426 (0.1396)  loss_objectness: 0.0666 (0.0703)  loss_rpn_box_reg: 0.0635 (0.0693)  time: 0.6818  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [188]  [ 70/250]  eta: 0:02:01  lr: 0.000300  loss: 0.1497 (0.1407)  loss_objectness: 0.0699 (0.0698)  loss_rpn_box_reg: 0.0779 (0.0709)  time: 0.6744  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [188]  [ 80/250]  eta: 0:01:54  lr: 0.000300  loss: 0.1421 (0.1410)  loss_objectness: 0.0677 (0.0699)  loss_rpn_box_reg: 0.0717 (0.0711)  time: 0.6636  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [188]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1346 (0.1406)  loss_objectness: 0.0709 (0.0703)  loss_rpn_box_reg: 0.0621 (0.0702)  time: 0.6837  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [188]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1248 (0.1400)  loss_objectness: 0.0675 (0.0699)  loss_rpn_box_reg: 0.0632 (0.0701)  time: 0.6877  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [188]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1406 (0.1401)  loss_objectness: 0.0723 (0.0705)  loss_rpn_box_reg: 0.0660 (0.0696)  time: 0.6896  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [188]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1288 (0.1386)  loss_objectness: 0.0723 (0.0698)  loss_rpn_box_reg: 0.0627 (0.0688)  time: 0.6891  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [188]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1336 (0.1389)  loss_objectness: 0.0648 (0.0700)  loss_rpn_box_reg: 0.0672 (0.0690)  time: 0.6744  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [188]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1413 (0.1395)  loss_objectness: 0.0684 (0.0697)  loss_rpn_box_reg: 0.0764 (0.0697)  time: 0.6876  data: 0.2973  max mem: 5923\n",
      "Training Epoch: [188]  [150/250]  eta: 0:01:07  lr: 0.000300  loss: 0.1487 (0.1401)  loss_objectness: 0.0636 (0.0697)  loss_rpn_box_reg: 0.0803 (0.0704)  time: 0.6806  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [188]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1427 (0.1395)  loss_objectness: 0.0716 (0.0697)  loss_rpn_box_reg: 0.0719 (0.0698)  time: 0.6817  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [188]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1279 (0.1394)  loss_objectness: 0.0779 (0.0701)  loss_rpn_box_reg: 0.0558 (0.0694)  time: 0.6804  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [188]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1279 (0.1394)  loss_objectness: 0.0697 (0.0703)  loss_rpn_box_reg: 0.0555 (0.0692)  time: 0.6773  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [188]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1323 (0.1401)  loss_objectness: 0.0774 (0.0707)  loss_rpn_box_reg: 0.0587 (0.0694)  time: 0.6965  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [188]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1318 (0.1401)  loss_objectness: 0.0749 (0.0706)  loss_rpn_box_reg: 0.0680 (0.0695)  time: 0.6998  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [188]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1344 (0.1402)  loss_objectness: 0.0716 (0.0706)  loss_rpn_box_reg: 0.0652 (0.0696)  time: 0.6916  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [188]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1412 (0.1405)  loss_objectness: 0.0735 (0.0707)  loss_rpn_box_reg: 0.0707 (0.0698)  time: 0.6740  data: 0.2968  max mem: 5923\n",
      "Training Epoch: [188]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1465 (0.1408)  loss_objectness: 0.0720 (0.0705)  loss_rpn_box_reg: 0.0745 (0.0703)  time: 0.6762  data: 0.2976  max mem: 5923\n",
      "Training Epoch: [188]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1445 (0.1410)  loss_objectness: 0.0684 (0.0708)  loss_rpn_box_reg: 0.0650 (0.0702)  time: 0.6793  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [188]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1413 (0.1410)  loss_objectness: 0.0729 (0.0710)  loss_rpn_box_reg: 0.0640 (0.0700)  time: 0.6716  data: 0.2972  max mem: 5923\n",
      "Training Epoch: [188] Total time: 0:02:50 (0.6813 s / it)\n",
      "Testing Epoch: [188]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1327 (0.1327)  loss_objectness: 0.0437 (0.0437)  loss_rpn_box_reg: 0.0890 (0.0890)  time: 0.7172  data: 0.3951  max mem: 5923\n",
      "Testing Epoch: [188]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1265 (0.1370)  loss_objectness: 0.0541 (0.0581)  loss_rpn_box_reg: 0.0672 (0.0789)  time: 0.6311  data: 0.3093  max mem: 5923\n",
      "Testing Epoch: [188] Total time: 0:00:39 (0.6336 s / it)\n",
      "Training Epoch: [189]  [  0/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1007 (0.1007)  loss_objectness: 0.0624 (0.0624)  loss_rpn_box_reg: 0.0383 (0.0383)  time: 0.6852  data: 0.3241  max mem: 5923\n",
      "Training Epoch: [189]  [ 10/250]  eta: 0:02:45  lr: 0.000300  loss: 0.1382 (0.1483)  loss_objectness: 0.0742 (0.0742)  loss_rpn_box_reg: 0.0691 (0.0740)  time: 0.6880  data: 0.3002  max mem: 5923\n",
      "Training Epoch: [189]  [ 20/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1280 (0.1367)  loss_objectness: 0.0644 (0.0664)  loss_rpn_box_reg: 0.0652 (0.0703)  time: 0.7029  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [189]  [ 30/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1222 (0.1354)  loss_objectness: 0.0611 (0.0659)  loss_rpn_box_reg: 0.0644 (0.0695)  time: 0.7085  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [189]  [ 40/250]  eta: 0:02:26  lr: 0.000300  loss: 0.1281 (0.1355)  loss_objectness: 0.0611 (0.0671)  loss_rpn_box_reg: 0.0631 (0.0684)  time: 0.6883  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [189]  [ 50/250]  eta: 0:02:19  lr: 0.000300  loss: 0.1296 (0.1339)  loss_objectness: 0.0724 (0.0674)  loss_rpn_box_reg: 0.0631 (0.0665)  time: 0.6856  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [189]  [ 60/250]  eta: 0:02:12  lr: 0.000300  loss: 0.1402 (0.1371)  loss_objectness: 0.0721 (0.0680)  loss_rpn_box_reg: 0.0680 (0.0690)  time: 0.6940  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [189]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1402 (0.1367)  loss_objectness: 0.0700 (0.0682)  loss_rpn_box_reg: 0.0683 (0.0685)  time: 0.6919  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [189]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1256 (0.1358)  loss_objectness: 0.0656 (0.0671)  loss_rpn_box_reg: 0.0653 (0.0688)  time: 0.6842  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [189]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1280 (0.1353)  loss_objectness: 0.0577 (0.0670)  loss_rpn_box_reg: 0.0621 (0.0684)  time: 0.6768  data: 0.2898  max mem: 5923\n",
      "Training Epoch: [189]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1315 (0.1378)  loss_objectness: 0.0677 (0.0674)  loss_rpn_box_reg: 0.0688 (0.0705)  time: 0.6802  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [189]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1421 (0.1390)  loss_objectness: 0.0700 (0.0687)  loss_rpn_box_reg: 0.0704 (0.0703)  time: 0.6911  data: 0.2982  max mem: 5923\n",
      "Training Epoch: [189]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1352 (0.1396)  loss_objectness: 0.0791 (0.0697)  loss_rpn_box_reg: 0.0671 (0.0698)  time: 0.6911  data: 0.2964  max mem: 5923\n",
      "Training Epoch: [189]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1301 (0.1385)  loss_objectness: 0.0733 (0.0692)  loss_rpn_box_reg: 0.0566 (0.0693)  time: 0.6901  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [189]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1286 (0.1389)  loss_objectness: 0.0669 (0.0697)  loss_rpn_box_reg: 0.0577 (0.0691)  time: 0.6824  data: 0.2968  max mem: 5923\n",
      "Training Epoch: [189]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1378 (0.1390)  loss_objectness: 0.0688 (0.0697)  loss_rpn_box_reg: 0.0695 (0.0693)  time: 0.6775  data: 0.2996  max mem: 5923\n",
      "Training Epoch: [189]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1349 (0.1383)  loss_objectness: 0.0679 (0.0695)  loss_rpn_box_reg: 0.0631 (0.0687)  time: 0.6925  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [189]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1349 (0.1392)  loss_objectness: 0.0723 (0.0701)  loss_rpn_box_reg: 0.0613 (0.0691)  time: 0.6881  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [189]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1394 (0.1394)  loss_objectness: 0.0696 (0.0698)  loss_rpn_box_reg: 0.0706 (0.0696)  time: 0.6803  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [189]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1382 (0.1396)  loss_objectness: 0.0688 (0.0698)  loss_rpn_box_reg: 0.0719 (0.0698)  time: 0.6712  data: 0.2968  max mem: 5923\n",
      "Training Epoch: [189]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1346 (0.1402)  loss_objectness: 0.0651 (0.0701)  loss_rpn_box_reg: 0.0711 (0.0701)  time: 0.6757  data: 0.2982  max mem: 5923\n",
      "Training Epoch: [189]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1358 (0.1402)  loss_objectness: 0.0642 (0.0699)  loss_rpn_box_reg: 0.0730 (0.0703)  time: 0.6918  data: 0.3002  max mem: 5923\n",
      "Training Epoch: [189]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1355 (0.1397)  loss_objectness: 0.0634 (0.0696)  loss_rpn_box_reg: 0.0639 (0.0701)  time: 0.6886  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [189]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1267 (0.1392)  loss_objectness: 0.0628 (0.0695)  loss_rpn_box_reg: 0.0576 (0.0697)  time: 0.6862  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [189]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1330 (0.1392)  loss_objectness: 0.0642 (0.0693)  loss_rpn_box_reg: 0.0646 (0.0698)  time: 0.6800  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [189]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1418 (0.1397)  loss_objectness: 0.0707 (0.0699)  loss_rpn_box_reg: 0.0649 (0.0698)  time: 0.6795  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [189] Total time: 0:02:51 (0.6868 s / it)\n",
      "Testing Epoch: [189]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1415 (0.1415)  loss_objectness: 0.0526 (0.0526)  loss_rpn_box_reg: 0.0889 (0.0889)  time: 0.6181  data: 0.2921  max mem: 5923\n",
      "Testing Epoch: [189]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1296 (0.1397)  loss_objectness: 0.0566 (0.0594)  loss_rpn_box_reg: 0.0721 (0.0803)  time: 0.6297  data: 0.3079  max mem: 5923\n",
      "Testing Epoch: [189] Total time: 0:00:39 (0.6318 s / it)\n",
      "Training Epoch: [190]  [  0/250]  eta: 0:02:50  lr: 0.000300  loss: 0.1209 (0.1209)  loss_objectness: 0.0737 (0.0737)  loss_rpn_box_reg: 0.0472 (0.0472)  time: 0.6812  data: 0.3091  max mem: 5923\n",
      "Training Epoch: [190]  [ 10/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1278 (0.1221)  loss_objectness: 0.0737 (0.0710)  loss_rpn_box_reg: 0.0472 (0.0511)  time: 0.6559  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [190]  [ 20/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1306 (0.1305)  loss_objectness: 0.0659 (0.0688)  loss_rpn_box_reg: 0.0582 (0.0617)  time: 0.6637  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [190]  [ 30/250]  eta: 0:02:26  lr: 0.000300  loss: 0.1388 (0.1356)  loss_objectness: 0.0711 (0.0708)  loss_rpn_box_reg: 0.0752 (0.0648)  time: 0.6717  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [190]  [ 40/250]  eta: 0:02:20  lr: 0.000300  loss: 0.1388 (0.1342)  loss_objectness: 0.0711 (0.0703)  loss_rpn_box_reg: 0.0678 (0.0639)  time: 0.6706  data: 0.2883  max mem: 5923\n",
      "Training Epoch: [190]  [ 50/250]  eta: 0:02:14  lr: 0.000300  loss: 0.1304 (0.1350)  loss_objectness: 0.0702 (0.0699)  loss_rpn_box_reg: 0.0655 (0.0651)  time: 0.6776  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [190]  [ 60/250]  eta: 0:02:07  lr: 0.000300  loss: 0.1350 (0.1352)  loss_objectness: 0.0744 (0.0711)  loss_rpn_box_reg: 0.0605 (0.0641)  time: 0.6850  data: 0.2969  max mem: 5923\n",
      "Training Epoch: [190]  [ 70/250]  eta: 0:02:01  lr: 0.000300  loss: 0.1350 (0.1371)  loss_objectness: 0.0746 (0.0713)  loss_rpn_box_reg: 0.0671 (0.0657)  time: 0.6908  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [190]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1462 (0.1383)  loss_objectness: 0.0686 (0.0713)  loss_rpn_box_reg: 0.0705 (0.0670)  time: 0.6882  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [190]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1429 (0.1384)  loss_objectness: 0.0675 (0.0715)  loss_rpn_box_reg: 0.0711 (0.0669)  time: 0.6926  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [190]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1310 (0.1376)  loss_objectness: 0.0663 (0.0712)  loss_rpn_box_reg: 0.0642 (0.0665)  time: 0.6946  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [190]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1330 (0.1389)  loss_objectness: 0.0663 (0.0718)  loss_rpn_box_reg: 0.0628 (0.0671)  time: 0.6836  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [190]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1399 (0.1393)  loss_objectness: 0.0664 (0.0716)  loss_rpn_box_reg: 0.0650 (0.0677)  time: 0.6944  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [190]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1399 (0.1391)  loss_objectness: 0.0664 (0.0714)  loss_rpn_box_reg: 0.0634 (0.0676)  time: 0.7047  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [190]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1355 (0.1390)  loss_objectness: 0.0723 (0.0715)  loss_rpn_box_reg: 0.0624 (0.0675)  time: 0.6939  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [190]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1306 (0.1388)  loss_objectness: 0.0681 (0.0711)  loss_rpn_box_reg: 0.0644 (0.0677)  time: 0.6723  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [190]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1271 (0.1390)  loss_objectness: 0.0681 (0.0716)  loss_rpn_box_reg: 0.0585 (0.0674)  time: 0.6701  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [190]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1249 (0.1390)  loss_objectness: 0.0657 (0.0712)  loss_rpn_box_reg: 0.0704 (0.0679)  time: 0.6771  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [190]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1342 (0.1395)  loss_objectness: 0.0685 (0.0716)  loss_rpn_box_reg: 0.0660 (0.0679)  time: 0.6707  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [190]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1495 (0.1405)  loss_objectness: 0.0744 (0.0720)  loss_rpn_box_reg: 0.0680 (0.0685)  time: 0.6777  data: 0.2977  max mem: 5923\n",
      "Training Epoch: [190]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1495 (0.1411)  loss_objectness: 0.0754 (0.0721)  loss_rpn_box_reg: 0.0742 (0.0690)  time: 0.6824  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [190]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1366 (0.1409)  loss_objectness: 0.0667 (0.0719)  loss_rpn_box_reg: 0.0701 (0.0690)  time: 0.6829  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [190]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1366 (0.1409)  loss_objectness: 0.0633 (0.0716)  loss_rpn_box_reg: 0.0692 (0.0692)  time: 0.6756  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [190]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1363 (0.1409)  loss_objectness: 0.0669 (0.0718)  loss_rpn_box_reg: 0.0690 (0.0692)  time: 0.6844  data: 0.2871  max mem: 5923\n",
      "Training Epoch: [190]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1326 (0.1407)  loss_objectness: 0.0721 (0.0717)  loss_rpn_box_reg: 0.0626 (0.0690)  time: 0.6885  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [190]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1332 (0.1407)  loss_objectness: 0.0635 (0.0715)  loss_rpn_box_reg: 0.0691 (0.0692)  time: 0.6755  data: 0.2883  max mem: 5923\n",
      "Training Epoch: [190] Total time: 0:02:50 (0.6816 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:00:59  model_time: 0.6101 (0.6101)  evaluator_time: 0.0520 (0.0520)  time: 0.9552  data: 0.2781  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3711 (0.3753)  evaluator_time: 0.0620 (0.0688)  time: 0.7483  data: 0.2995  max mem: 5923\n",
      "Test: Total time: 0:00:46 (0.7538 s / it)\n",
      "Averaged stats: model_time: 0.3711 (0.3753)  evaluator_time: 0.0620 (0.0688)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.99s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.023\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.095\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.156\n",
      "Testing Epoch: [190]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1291 (0.1291)  loss_objectness: 0.0414 (0.0414)  loss_rpn_box_reg: 0.0878 (0.0878)  time: 0.7252  data: 0.3881  max mem: 5923\n",
      "Testing Epoch: [190]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1262 (0.1392)  loss_objectness: 0.0519 (0.0590)  loss_rpn_box_reg: 0.0744 (0.0802)  time: 0.6302  data: 0.3092  max mem: 5923\n",
      "Testing Epoch: [190] Total time: 0:00:39 (0.6355 s / it)\n",
      "Training Epoch: [191]  [  0/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1492 (0.1492)  loss_objectness: 0.0959 (0.0959)  loss_rpn_box_reg: 0.0534 (0.0534)  time: 0.6581  data: 0.3261  max mem: 5923\n",
      "Training Epoch: [191]  [ 10/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1492 (0.1362)  loss_objectness: 0.0697 (0.0721)  loss_rpn_box_reg: 0.0735 (0.0641)  time: 0.6686  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [191]  [ 20/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1368 (0.1307)  loss_objectness: 0.0672 (0.0686)  loss_rpn_box_reg: 0.0666 (0.0620)  time: 0.6731  data: 0.2886  max mem: 5923\n",
      "Training Epoch: [191]  [ 30/250]  eta: 0:02:27  lr: 0.000300  loss: 0.1400 (0.1380)  loss_objectness: 0.0653 (0.0719)  loss_rpn_box_reg: 0.0696 (0.0661)  time: 0.6698  data: 0.2869  max mem: 5923\n",
      "Training Epoch: [191]  [ 40/250]  eta: 0:02:21  lr: 0.000300  loss: 0.1482 (0.1375)  loss_objectness: 0.0710 (0.0720)  loss_rpn_box_reg: 0.0643 (0.0655)  time: 0.6750  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [191]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1353 (0.1396)  loss_objectness: 0.0724 (0.0729)  loss_rpn_box_reg: 0.0598 (0.0667)  time: 0.6881  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [191]  [ 60/250]  eta: 0:02:08  lr: 0.000300  loss: 0.1472 (0.1408)  loss_objectness: 0.0710 (0.0715)  loss_rpn_box_reg: 0.0662 (0.0692)  time: 0.6868  data: 0.2892  max mem: 5923\n",
      "Training Epoch: [191]  [ 70/250]  eta: 0:02:01  lr: 0.000300  loss: 0.1358 (0.1393)  loss_objectness: 0.0594 (0.0709)  loss_rpn_box_reg: 0.0662 (0.0684)  time: 0.6798  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [191]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1357 (0.1389)  loss_objectness: 0.0684 (0.0711)  loss_rpn_box_reg: 0.0639 (0.0678)  time: 0.6959  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [191]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1406 (0.1383)  loss_objectness: 0.0684 (0.0710)  loss_rpn_box_reg: 0.0642 (0.0672)  time: 0.6952  data: 0.2883  max mem: 5923\n",
      "Training Epoch: [191]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1406 (0.1381)  loss_objectness: 0.0659 (0.0710)  loss_rpn_box_reg: 0.0594 (0.0671)  time: 0.6765  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [191]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1383 (0.1379)  loss_objectness: 0.0653 (0.0709)  loss_rpn_box_reg: 0.0608 (0.0670)  time: 0.6763  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [191]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1467 (0.1383)  loss_objectness: 0.0643 (0.0702)  loss_rpn_box_reg: 0.0655 (0.0682)  time: 0.6871  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [191]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1347 (0.1385)  loss_objectness: 0.0675 (0.0705)  loss_rpn_box_reg: 0.0633 (0.0680)  time: 0.6986  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [191]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1335 (0.1391)  loss_objectness: 0.0685 (0.0703)  loss_rpn_box_reg: 0.0675 (0.0688)  time: 0.6912  data: 0.2989  max mem: 5923\n",
      "Training Epoch: [191]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1439 (0.1388)  loss_objectness: 0.0697 (0.0705)  loss_rpn_box_reg: 0.0701 (0.0683)  time: 0.6848  data: 0.2970  max mem: 5923\n",
      "Training Epoch: [191]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1373 (0.1385)  loss_objectness: 0.0773 (0.0709)  loss_rpn_box_reg: 0.0598 (0.0676)  time: 0.6833  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [191]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1276 (0.1373)  loss_objectness: 0.0707 (0.0702)  loss_rpn_box_reg: 0.0577 (0.0672)  time: 0.6792  data: 0.2883  max mem: 5923\n",
      "Training Epoch: [191]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1281 (0.1379)  loss_objectness: 0.0634 (0.0703)  loss_rpn_box_reg: 0.0622 (0.0676)  time: 0.7003  data: 0.2898  max mem: 5923\n",
      "Training Epoch: [191]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1422 (0.1383)  loss_objectness: 0.0650 (0.0700)  loss_rpn_box_reg: 0.0660 (0.0683)  time: 0.6970  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [191]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1306 (0.1378)  loss_objectness: 0.0582 (0.0697)  loss_rpn_box_reg: 0.0698 (0.0681)  time: 0.6867  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [191]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1366 (0.1383)  loss_objectness: 0.0664 (0.0696)  loss_rpn_box_reg: 0.0730 (0.0688)  time: 0.6872  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [191]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1533 (0.1393)  loss_objectness: 0.0726 (0.0700)  loss_rpn_box_reg: 0.0803 (0.0693)  time: 0.6713  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [191]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1429 (0.1390)  loss_objectness: 0.0726 (0.0698)  loss_rpn_box_reg: 0.0768 (0.0692)  time: 0.6835  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [191]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1317 (0.1389)  loss_objectness: 0.0681 (0.0699)  loss_rpn_box_reg: 0.0670 (0.0690)  time: 0.6945  data: 0.2886  max mem: 5923\n",
      "Training Epoch: [191]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1358 (0.1395)  loss_objectness: 0.0716 (0.0702)  loss_rpn_box_reg: 0.0639 (0.0693)  time: 0.6839  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [191] Total time: 0:02:51 (0.6844 s / it)\n",
      "Testing Epoch: [191]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1308 (0.1308)  loss_objectness: 0.0418 (0.0418)  loss_rpn_box_reg: 0.0890 (0.0890)  time: 0.6011  data: 0.2771  max mem: 5923\n",
      "Testing Epoch: [191]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1255 (0.1397)  loss_objectness: 0.0544 (0.0595)  loss_rpn_box_reg: 0.0707 (0.0802)  time: 0.6230  data: 0.3049  max mem: 5923\n",
      "Testing Epoch: [191] Total time: 0:00:39 (0.6303 s / it)\n",
      "Training Epoch: [192]  [  0/250]  eta: 0:02:52  lr: 0.000300  loss: 0.1451 (0.1451)  loss_objectness: 0.0785 (0.0785)  loss_rpn_box_reg: 0.0666 (0.0666)  time: 0.6902  data: 0.3221  max mem: 5923\n",
      "Training Epoch: [192]  [ 10/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1414 (0.1353)  loss_objectness: 0.0698 (0.0671)  loss_rpn_box_reg: 0.0666 (0.0682)  time: 0.6642  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [192]  [ 20/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1316 (0.1309)  loss_objectness: 0.0657 (0.0661)  loss_rpn_box_reg: 0.0586 (0.0649)  time: 0.6629  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [192]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1241 (0.1325)  loss_objectness: 0.0642 (0.0673)  loss_rpn_box_reg: 0.0596 (0.0652)  time: 0.6853  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [192]  [ 40/250]  eta: 0:02:21  lr: 0.000300  loss: 0.1376 (0.1368)  loss_objectness: 0.0693 (0.0684)  loss_rpn_box_reg: 0.0613 (0.0684)  time: 0.6886  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [192]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1453 (0.1378)  loss_objectness: 0.0673 (0.0681)  loss_rpn_box_reg: 0.0734 (0.0697)  time: 0.6787  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [192]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1422 (0.1385)  loss_objectness: 0.0728 (0.0695)  loss_rpn_box_reg: 0.0734 (0.0690)  time: 0.6877  data: 0.2965  max mem: 5923\n",
      "Training Epoch: [192]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1313 (0.1360)  loss_objectness: 0.0745 (0.0695)  loss_rpn_box_reg: 0.0586 (0.0665)  time: 0.6959  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [192]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1244 (0.1353)  loss_objectness: 0.0662 (0.0688)  loss_rpn_box_reg: 0.0505 (0.0665)  time: 0.6844  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [192]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1271 (0.1364)  loss_objectness: 0.0662 (0.0691)  loss_rpn_box_reg: 0.0696 (0.0673)  time: 0.6884  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [192]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1205 (0.1352)  loss_objectness: 0.0685 (0.0693)  loss_rpn_box_reg: 0.0549 (0.0659)  time: 0.7158  data: 0.3032  max mem: 5923\n",
      "Training Epoch: [192]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1195 (0.1345)  loss_objectness: 0.0685 (0.0693)  loss_rpn_box_reg: 0.0502 (0.0652)  time: 0.7169  data: 0.3059  max mem: 5923\n",
      "Training Epoch: [192]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1357 (0.1348)  loss_objectness: 0.0665 (0.0693)  loss_rpn_box_reg: 0.0632 (0.0655)  time: 0.7008  data: 0.3004  max mem: 5923\n",
      "Training Epoch: [192]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1407 (0.1351)  loss_objectness: 0.0665 (0.0692)  loss_rpn_box_reg: 0.0706 (0.0659)  time: 0.6817  data: 0.3015  max mem: 5923\n",
      "Training Epoch: [192]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1334 (0.1358)  loss_objectness: 0.0709 (0.0692)  loss_rpn_box_reg: 0.0744 (0.0666)  time: 0.6799  data: 0.3031  max mem: 5923\n",
      "Training Epoch: [192]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1312 (0.1364)  loss_objectness: 0.0680 (0.0692)  loss_rpn_box_reg: 0.0751 (0.0672)  time: 0.6893  data: 0.3082  max mem: 5923\n",
      "Training Epoch: [192]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1430 (0.1378)  loss_objectness: 0.0745 (0.0699)  loss_rpn_box_reg: 0.0727 (0.0680)  time: 0.6892  data: 0.3076  max mem: 5923\n",
      "Training Epoch: [192]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1421 (0.1379)  loss_objectness: 0.0693 (0.0698)  loss_rpn_box_reg: 0.0664 (0.0681)  time: 0.6942  data: 0.3034  max mem: 5923\n",
      "Training Epoch: [192]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1243 (0.1386)  loss_objectness: 0.0706 (0.0703)  loss_rpn_box_reg: 0.0628 (0.0683)  time: 0.6985  data: 0.3004  max mem: 5923\n",
      "Training Epoch: [192]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1342 (0.1389)  loss_objectness: 0.0736 (0.0704)  loss_rpn_box_reg: 0.0690 (0.0685)  time: 0.6864  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [192]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1408 (0.1390)  loss_objectness: 0.0736 (0.0706)  loss_rpn_box_reg: 0.0643 (0.0684)  time: 0.6786  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [192]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1460 (0.1395)  loss_objectness: 0.0696 (0.0707)  loss_rpn_box_reg: 0.0692 (0.0688)  time: 0.7199  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [192]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1487 (0.1400)  loss_objectness: 0.0702 (0.0708)  loss_rpn_box_reg: 0.0720 (0.0692)  time: 0.7113  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [192]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1487 (0.1401)  loss_objectness: 0.0702 (0.0708)  loss_rpn_box_reg: 0.0718 (0.0694)  time: 0.6765  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [192]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1456 (0.1404)  loss_objectness: 0.0647 (0.0710)  loss_rpn_box_reg: 0.0735 (0.0694)  time: 0.6878  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [192]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1472 (0.1406)  loss_objectness: 0.0674 (0.0711)  loss_rpn_box_reg: 0.0735 (0.0695)  time: 0.6939  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [192] Total time: 0:02:52 (0.6909 s / it)\n",
      "Testing Epoch: [192]  [ 0/62]  eta: 0:00:45  lr: 0.000300  loss: 0.1330 (0.1330)  loss_objectness: 0.0466 (0.0466)  loss_rpn_box_reg: 0.0864 (0.0864)  time: 0.7282  data: 0.4041  max mem: 5923\n",
      "Testing Epoch: [192]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1290 (0.1387)  loss_objectness: 0.0568 (0.0593)  loss_rpn_box_reg: 0.0712 (0.0794)  time: 0.6373  data: 0.3142  max mem: 5923\n",
      "Testing Epoch: [192] Total time: 0:00:39 (0.6410 s / it)\n",
      "Training Epoch: [193]  [  0/250]  eta: 0:03:04  lr: 0.000300  loss: 0.1559 (0.1559)  loss_objectness: 0.0983 (0.0983)  loss_rpn_box_reg: 0.0575 (0.0575)  time: 0.7372  data: 0.2981  max mem: 5923\n",
      "Training Epoch: [193]  [ 10/250]  eta: 0:02:48  lr: 0.000300  loss: 0.1481 (0.1344)  loss_objectness: 0.0669 (0.0685)  loss_rpn_box_reg: 0.0575 (0.0659)  time: 0.7009  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [193]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1316 (0.1394)  loss_objectness: 0.0592 (0.0687)  loss_rpn_box_reg: 0.0622 (0.0707)  time: 0.6890  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [193]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1438 (0.1415)  loss_objectness: 0.0631 (0.0681)  loss_rpn_box_reg: 0.0680 (0.0734)  time: 0.6801  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [193]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1438 (0.1410)  loss_objectness: 0.0713 (0.0688)  loss_rpn_box_reg: 0.0708 (0.0721)  time: 0.6807  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [193]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1373 (0.1402)  loss_objectness: 0.0717 (0.0702)  loss_rpn_box_reg: 0.0624 (0.0700)  time: 0.6868  data: 0.2971  max mem: 5923\n",
      "Training Epoch: [193]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1455 (0.1412)  loss_objectness: 0.0708 (0.0704)  loss_rpn_box_reg: 0.0640 (0.0708)  time: 0.6918  data: 0.2989  max mem: 5923\n",
      "Training Epoch: [193]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1271 (0.1383)  loss_objectness: 0.0633 (0.0691)  loss_rpn_box_reg: 0.0637 (0.0691)  time: 0.6889  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [193]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1271 (0.1389)  loss_objectness: 0.0626 (0.0688)  loss_rpn_box_reg: 0.0637 (0.0701)  time: 0.6730  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [193]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1308 (0.1371)  loss_objectness: 0.0617 (0.0678)  loss_rpn_box_reg: 0.0679 (0.0693)  time: 0.6667  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [193]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1305 (0.1361)  loss_objectness: 0.0688 (0.0679)  loss_rpn_box_reg: 0.0513 (0.0682)  time: 0.6888  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [193]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1216 (0.1357)  loss_objectness: 0.0622 (0.0674)  loss_rpn_box_reg: 0.0568 (0.0683)  time: 0.7009  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [193]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1216 (0.1357)  loss_objectness: 0.0606 (0.0674)  loss_rpn_box_reg: 0.0629 (0.0683)  time: 0.6877  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [193]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1365 (0.1362)  loss_objectness: 0.0665 (0.0681)  loss_rpn_box_reg: 0.0637 (0.0681)  time: 0.6717  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [193]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1365 (0.1364)  loss_objectness: 0.0693 (0.0682)  loss_rpn_box_reg: 0.0637 (0.0683)  time: 0.6851  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [193]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1511 (0.1375)  loss_objectness: 0.0693 (0.0687)  loss_rpn_box_reg: 0.0674 (0.0687)  time: 0.6851  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [193]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1537 (0.1386)  loss_objectness: 0.0735 (0.0693)  loss_rpn_box_reg: 0.0679 (0.0693)  time: 0.6725  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [193]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1382 (0.1382)  loss_objectness: 0.0684 (0.0690)  loss_rpn_box_reg: 0.0672 (0.0691)  time: 0.6765  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [193]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1383 (0.1390)  loss_objectness: 0.0660 (0.0695)  loss_rpn_box_reg: 0.0628 (0.0695)  time: 0.6659  data: 0.2861  max mem: 5923\n",
      "Training Epoch: [193]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1406 (0.1389)  loss_objectness: 0.0660 (0.0694)  loss_rpn_box_reg: 0.0642 (0.0695)  time: 0.6790  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [193]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1364 (0.1393)  loss_objectness: 0.0711 (0.0698)  loss_rpn_box_reg: 0.0559 (0.0695)  time: 0.6951  data: 0.2981  max mem: 5923\n",
      "Training Epoch: [193]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1332 (0.1388)  loss_objectness: 0.0741 (0.0699)  loss_rpn_box_reg: 0.0587 (0.0690)  time: 0.6902  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [193]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1424 (0.1401)  loss_objectness: 0.0700 (0.0701)  loss_rpn_box_reg: 0.0717 (0.0700)  time: 0.6863  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [193]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1496 (0.1396)  loss_objectness: 0.0639 (0.0699)  loss_rpn_box_reg: 0.0745 (0.0697)  time: 0.6866  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [193]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1379 (0.1399)  loss_objectness: 0.0654 (0.0699)  loss_rpn_box_reg: 0.0686 (0.0701)  time: 0.6852  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [193]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1402 (0.1400)  loss_objectness: 0.0662 (0.0701)  loss_rpn_box_reg: 0.0686 (0.0699)  time: 0.6844  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [193] Total time: 0:02:51 (0.6840 s / it)\n",
      "Testing Epoch: [193]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1323 (0.1323)  loss_objectness: 0.0419 (0.0419)  loss_rpn_box_reg: 0.0903 (0.0903)  time: 0.6231  data: 0.2961  max mem: 5923\n",
      "Testing Epoch: [193]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1348 (0.1415)  loss_objectness: 0.0540 (0.0602)  loss_rpn_box_reg: 0.0801 (0.0813)  time: 0.6275  data: 0.3056  max mem: 5923\n",
      "Testing Epoch: [193] Total time: 0:00:39 (0.6309 s / it)\n",
      "Training Epoch: [194]  [  0/250]  eta: 0:02:48  lr: 0.000300  loss: 0.1002 (0.1002)  loss_objectness: 0.0700 (0.0700)  loss_rpn_box_reg: 0.0302 (0.0302)  time: 0.6722  data: 0.3121  max mem: 5923\n",
      "Training Epoch: [194]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1381 (0.1312)  loss_objectness: 0.0700 (0.0683)  loss_rpn_box_reg: 0.0687 (0.0629)  time: 0.6815  data: 0.2993  max mem: 5923\n",
      "Training Epoch: [194]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1436 (0.1363)  loss_objectness: 0.0646 (0.0688)  loss_rpn_box_reg: 0.0687 (0.0675)  time: 0.6874  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [194]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1359 (0.1349)  loss_objectness: 0.0726 (0.0697)  loss_rpn_box_reg: 0.0576 (0.0652)  time: 0.6989  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [194]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1262 (0.1348)  loss_objectness: 0.0702 (0.0696)  loss_rpn_box_reg: 0.0586 (0.0652)  time: 0.6909  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [194]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1265 (0.1333)  loss_objectness: 0.0641 (0.0684)  loss_rpn_box_reg: 0.0637 (0.0650)  time: 0.6899  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [194]  [ 60/250]  eta: 0:02:11  lr: 0.000300  loss: 0.1324 (0.1348)  loss_objectness: 0.0687 (0.0697)  loss_rpn_box_reg: 0.0558 (0.0651)  time: 0.6950  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [194]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1300 (0.1348)  loss_objectness: 0.0740 (0.0706)  loss_rpn_box_reg: 0.0587 (0.0642)  time: 0.6918  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [194]  [ 80/250]  eta: 0:01:58  lr: 0.000300  loss: 0.1343 (0.1371)  loss_objectness: 0.0667 (0.0715)  loss_rpn_box_reg: 0.0587 (0.0656)  time: 0.7046  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [194]  [ 90/250]  eta: 0:01:51  lr: 0.000300  loss: 0.1385 (0.1375)  loss_objectness: 0.0726 (0.0713)  loss_rpn_box_reg: 0.0729 (0.0661)  time: 0.7016  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [194]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1431 (0.1384)  loss_objectness: 0.0721 (0.0713)  loss_rpn_box_reg: 0.0694 (0.0670)  time: 0.6772  data: 0.2973  max mem: 5923\n",
      "Training Epoch: [194]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1343 (0.1387)  loss_objectness: 0.0691 (0.0716)  loss_rpn_box_reg: 0.0619 (0.0671)  time: 0.6764  data: 0.2992  max mem: 5923\n",
      "Training Epoch: [194]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1347 (0.1394)  loss_objectness: 0.0683 (0.0718)  loss_rpn_box_reg: 0.0600 (0.0676)  time: 0.6828  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [194]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1347 (0.1389)  loss_objectness: 0.0716 (0.0714)  loss_rpn_box_reg: 0.0640 (0.0675)  time: 0.6878  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [194]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1285 (0.1389)  loss_objectness: 0.0655 (0.0710)  loss_rpn_box_reg: 0.0640 (0.0679)  time: 0.7006  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [194]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1336 (0.1390)  loss_objectness: 0.0639 (0.0704)  loss_rpn_box_reg: 0.0712 (0.0686)  time: 0.6913  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [194]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1346 (0.1392)  loss_objectness: 0.0690 (0.0707)  loss_rpn_box_reg: 0.0701 (0.0684)  time: 0.6831  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [194]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1346 (0.1388)  loss_objectness: 0.0721 (0.0706)  loss_rpn_box_reg: 0.0628 (0.0682)  time: 0.6888  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [194]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1382 (0.1396)  loss_objectness: 0.0700 (0.0708)  loss_rpn_box_reg: 0.0660 (0.0687)  time: 0.6867  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [194]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1331 (0.1395)  loss_objectness: 0.0759 (0.0711)  loss_rpn_box_reg: 0.0654 (0.0684)  time: 0.6846  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [194]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1333 (0.1395)  loss_objectness: 0.0726 (0.0712)  loss_rpn_box_reg: 0.0617 (0.0683)  time: 0.6888  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [194]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1333 (0.1393)  loss_objectness: 0.0669 (0.0709)  loss_rpn_box_reg: 0.0663 (0.0684)  time: 0.6809  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [194]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1368 (0.1391)  loss_objectness: 0.0640 (0.0709)  loss_rpn_box_reg: 0.0675 (0.0682)  time: 0.6689  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [194]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1423 (0.1395)  loss_objectness: 0.0728 (0.0708)  loss_rpn_box_reg: 0.0693 (0.0686)  time: 0.6683  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [194]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1376 (0.1392)  loss_objectness: 0.0694 (0.0708)  loss_rpn_box_reg: 0.0683 (0.0684)  time: 0.6747  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [194]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1354 (0.1398)  loss_objectness: 0.0693 (0.0708)  loss_rpn_box_reg: 0.0593 (0.0690)  time: 0.6947  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [194] Total time: 0:02:51 (0.6876 s / it)\n",
      "Testing Epoch: [194]  [ 0/62]  eta: 0:00:40  lr: 0.000300  loss: 0.1342 (0.1342)  loss_objectness: 0.0448 (0.0448)  loss_rpn_box_reg: 0.0894 (0.0894)  time: 0.6551  data: 0.2961  max mem: 5923\n",
      "Testing Epoch: [194]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1290 (0.1421)  loss_objectness: 0.0542 (0.0602)  loss_rpn_box_reg: 0.0757 (0.0819)  time: 0.6348  data: 0.3134  max mem: 5923\n",
      "Testing Epoch: [194] Total time: 0:00:39 (0.6341 s / it)\n",
      "Training Epoch: [195]  [  0/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1757 (0.1757)  loss_objectness: 0.0749 (0.0749)  loss_rpn_box_reg: 0.1008 (0.1008)  time: 0.6712  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [195]  [ 10/250]  eta: 0:02:47  lr: 0.000300  loss: 0.1523 (0.1510)  loss_objectness: 0.0749 (0.0712)  loss_rpn_box_reg: 0.0839 (0.0798)  time: 0.6971  data: 0.2988  max mem: 5923\n",
      "Training Epoch: [195]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1471 (0.1468)  loss_objectness: 0.0684 (0.0697)  loss_rpn_box_reg: 0.0705 (0.0771)  time: 0.6920  data: 0.3004  max mem: 5923\n",
      "Training Epoch: [195]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1336 (0.1391)  loss_objectness: 0.0536 (0.0645)  loss_rpn_box_reg: 0.0688 (0.0746)  time: 0.6883  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [195]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1380 (0.1419)  loss_objectness: 0.0598 (0.0675)  loss_rpn_box_reg: 0.0690 (0.0744)  time: 0.6857  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [195]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1475 (0.1435)  loss_objectness: 0.0767 (0.0692)  loss_rpn_box_reg: 0.0690 (0.0743)  time: 0.6750  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [195]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1403 (0.1427)  loss_objectness: 0.0713 (0.0699)  loss_rpn_box_reg: 0.0664 (0.0728)  time: 0.6692  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [195]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1327 (0.1417)  loss_objectness: 0.0685 (0.0698)  loss_rpn_box_reg: 0.0601 (0.0719)  time: 0.6694  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [195]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1396 (0.1420)  loss_objectness: 0.0658 (0.0702)  loss_rpn_box_reg: 0.0632 (0.0718)  time: 0.6720  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [195]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1407 (0.1412)  loss_objectness: 0.0644 (0.0693)  loss_rpn_box_reg: 0.0632 (0.0719)  time: 0.6754  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [195]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1316 (0.1405)  loss_objectness: 0.0611 (0.0688)  loss_rpn_box_reg: 0.0603 (0.0718)  time: 0.6748  data: 0.2866  max mem: 5923\n",
      "Training Epoch: [195]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1366 (0.1414)  loss_objectness: 0.0632 (0.0684)  loss_rpn_box_reg: 0.0701 (0.0729)  time: 0.6879  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [195]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1405 (0.1421)  loss_objectness: 0.0655 (0.0689)  loss_rpn_box_reg: 0.0816 (0.0732)  time: 0.6936  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [195]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1421 (0.1425)  loss_objectness: 0.0652 (0.0690)  loss_rpn_box_reg: 0.0707 (0.0736)  time: 0.6833  data: 0.2886  max mem: 5923\n",
      "Training Epoch: [195]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1396 (0.1426)  loss_objectness: 0.0675 (0.0689)  loss_rpn_box_reg: 0.0675 (0.0737)  time: 0.6817  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [195]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1389 (0.1424)  loss_objectness: 0.0693 (0.0691)  loss_rpn_box_reg: 0.0673 (0.0733)  time: 0.6833  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [195]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1356 (0.1425)  loss_objectness: 0.0703 (0.0694)  loss_rpn_box_reg: 0.0634 (0.0731)  time: 0.6950  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [195]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1351 (0.1421)  loss_objectness: 0.0703 (0.0696)  loss_rpn_box_reg: 0.0634 (0.0725)  time: 0.7022  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [195]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1295 (0.1418)  loss_objectness: 0.0728 (0.0698)  loss_rpn_box_reg: 0.0634 (0.0720)  time: 0.6961  data: 0.2998  max mem: 5923\n",
      "Training Epoch: [195]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1296 (0.1415)  loss_objectness: 0.0707 (0.0702)  loss_rpn_box_reg: 0.0634 (0.0714)  time: 0.6910  data: 0.2991  max mem: 5923\n",
      "Training Epoch: [195]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1373 (0.1417)  loss_objectness: 0.0781 (0.0707)  loss_rpn_box_reg: 0.0654 (0.0710)  time: 0.6923  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [195]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1426 (0.1422)  loss_objectness: 0.0753 (0.0709)  loss_rpn_box_reg: 0.0673 (0.0713)  time: 0.6952  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [195]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1366 (0.1418)  loss_objectness: 0.0721 (0.0710)  loss_rpn_box_reg: 0.0650 (0.0708)  time: 0.6931  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [195]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1290 (0.1415)  loss_objectness: 0.0650 (0.0708)  loss_rpn_box_reg: 0.0555 (0.0707)  time: 0.6740  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [195]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1374 (0.1417)  loss_objectness: 0.0670 (0.0710)  loss_rpn_box_reg: 0.0644 (0.0706)  time: 0.6784  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [195]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1350 (0.1413)  loss_objectness: 0.0682 (0.0712)  loss_rpn_box_reg: 0.0605 (0.0701)  time: 0.6852  data: 0.2964  max mem: 5923\n",
      "Training Epoch: [195] Total time: 0:02:51 (0.6849 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:05  model_time: 0.7022 (0.7022)  evaluator_time: 0.0590 (0.0590)  time: 1.0572  data: 0.2811  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3971 (0.4040)  evaluator_time: 0.0760 (0.0881)  time: 0.7974  data: 0.3008  max mem: 5923\n",
      "Test: Total time: 0:00:49 (0.7990 s / it)\n",
      "Averaged stats: model_time: 0.3971 (0.4040)  evaluator_time: 0.0760 (0.0881)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.16s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.057\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.075\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.172\n",
      "Testing Epoch: [195]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1336 (0.1336)  loss_objectness: 0.0437 (0.0437)  loss_rpn_box_reg: 0.0899 (0.0899)  time: 0.6231  data: 0.2841  max mem: 5923\n",
      "Testing Epoch: [195]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1338 (0.1435)  loss_objectness: 0.0632 (0.0633)  loss_rpn_box_reg: 0.0773 (0.0803)  time: 0.6312  data: 0.3117  max mem: 5923\n",
      "Testing Epoch: [195] Total time: 0:00:39 (0.6325 s / it)\n",
      "Training Epoch: [196]  [  0/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1852 (0.1852)  loss_objectness: 0.0841 (0.0841)  loss_rpn_box_reg: 0.1010 (0.1010)  time: 0.6672  data: 0.3181  max mem: 5923\n",
      "Training Epoch: [196]  [ 10/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1346 (0.1438)  loss_objectness: 0.0747 (0.0700)  loss_rpn_box_reg: 0.0758 (0.0738)  time: 0.6722  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [196]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1329 (0.1398)  loss_objectness: 0.0705 (0.0714)  loss_rpn_box_reg: 0.0664 (0.0684)  time: 0.6939  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [196]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1310 (0.1348)  loss_objectness: 0.0658 (0.0681)  loss_rpn_box_reg: 0.0591 (0.0667)  time: 0.6944  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [196]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1310 (0.1357)  loss_objectness: 0.0636 (0.0688)  loss_rpn_box_reg: 0.0634 (0.0669)  time: 0.6800  data: 0.2874  max mem: 5923\n",
      "Training Epoch: [196]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1223 (0.1330)  loss_objectness: 0.0655 (0.0680)  loss_rpn_box_reg: 0.0580 (0.0650)  time: 0.6862  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [196]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1208 (0.1336)  loss_objectness: 0.0651 (0.0696)  loss_rpn_box_reg: 0.0497 (0.0640)  time: 0.6806  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [196]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1496 (0.1375)  loss_objectness: 0.0797 (0.0718)  loss_rpn_box_reg: 0.0630 (0.0657)  time: 0.6836  data: 0.2964  max mem: 5923\n",
      "Training Epoch: [196]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1496 (0.1367)  loss_objectness: 0.0737 (0.0718)  loss_rpn_box_reg: 0.0684 (0.0648)  time: 0.6882  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [196]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1263 (0.1375)  loss_objectness: 0.0688 (0.0718)  loss_rpn_box_reg: 0.0676 (0.0657)  time: 0.6820  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [196]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1430 (0.1390)  loss_objectness: 0.0755 (0.0719)  loss_rpn_box_reg: 0.0814 (0.0671)  time: 0.6732  data: 0.2883  max mem: 5923\n",
      "Training Epoch: [196]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1342 (0.1384)  loss_objectness: 0.0706 (0.0717)  loss_rpn_box_reg: 0.0583 (0.0667)  time: 0.6725  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [196]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1240 (0.1382)  loss_objectness: 0.0656 (0.0713)  loss_rpn_box_reg: 0.0525 (0.0670)  time: 0.6790  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [196]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1311 (0.1378)  loss_objectness: 0.0634 (0.0710)  loss_rpn_box_reg: 0.0511 (0.0668)  time: 0.6797  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [196]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1282 (0.1372)  loss_objectness: 0.0569 (0.0700)  loss_rpn_box_reg: 0.0565 (0.0672)  time: 0.6811  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [196]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1282 (0.1375)  loss_objectness: 0.0569 (0.0701)  loss_rpn_box_reg: 0.0641 (0.0673)  time: 0.6939  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [196]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1351 (0.1375)  loss_objectness: 0.0730 (0.0706)  loss_rpn_box_reg: 0.0611 (0.0669)  time: 0.7004  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [196]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1493 (0.1382)  loss_objectness: 0.0736 (0.0707)  loss_rpn_box_reg: 0.0676 (0.0675)  time: 0.6876  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [196]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1510 (0.1386)  loss_objectness: 0.0657 (0.0705)  loss_rpn_box_reg: 0.0755 (0.0682)  time: 0.6918  data: 0.2982  max mem: 5923\n",
      "Training Epoch: [196]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1481 (0.1391)  loss_objectness: 0.0648 (0.0705)  loss_rpn_box_reg: 0.0777 (0.0686)  time: 0.7024  data: 0.2976  max mem: 5923\n",
      "Training Epoch: [196]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1469 (0.1391)  loss_objectness: 0.0645 (0.0701)  loss_rpn_box_reg: 0.0720 (0.0690)  time: 0.6887  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [196]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1348 (0.1395)  loss_objectness: 0.0645 (0.0705)  loss_rpn_box_reg: 0.0693 (0.0690)  time: 0.6829  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [196]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1354 (0.1395)  loss_objectness: 0.0726 (0.0705)  loss_rpn_box_reg: 0.0607 (0.0690)  time: 0.6875  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [196]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1354 (0.1390)  loss_objectness: 0.0721 (0.0705)  loss_rpn_box_reg: 0.0587 (0.0685)  time: 0.6919  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [196]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1400 (0.1399)  loss_objectness: 0.0708 (0.0708)  loss_rpn_box_reg: 0.0577 (0.0691)  time: 0.6965  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [196]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1374 (0.1394)  loss_objectness: 0.0660 (0.0705)  loss_rpn_box_reg: 0.0607 (0.0690)  time: 0.6813  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [196] Total time: 0:02:51 (0.6861 s / it)\n",
      "Testing Epoch: [196]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1312 (0.1312)  loss_objectness: 0.0441 (0.0441)  loss_rpn_box_reg: 0.0871 (0.0871)  time: 0.6151  data: 0.2871  max mem: 5923\n",
      "Testing Epoch: [196]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1295 (0.1388)  loss_objectness: 0.0564 (0.0578)  loss_rpn_box_reg: 0.0743 (0.0810)  time: 0.6372  data: 0.3152  max mem: 5923\n",
      "Testing Epoch: [196] Total time: 0:00:39 (0.6419 s / it)\n",
      "Training Epoch: [197]  [  0/250]  eta: 0:03:00  lr: 0.000300  loss: 0.1397 (0.1397)  loss_objectness: 0.0819 (0.0819)  loss_rpn_box_reg: 0.0579 (0.0579)  time: 0.7212  data: 0.2971  max mem: 5923\n",
      "Training Epoch: [197]  [ 10/250]  eta: 0:02:50  lr: 0.000300  loss: 0.1397 (0.1376)  loss_objectness: 0.0757 (0.0728)  loss_rpn_box_reg: 0.0676 (0.0648)  time: 0.7087  data: 0.2996  max mem: 5923\n",
      "Training Epoch: [197]  [ 20/250]  eta: 0:02:41  lr: 0.000300  loss: 0.1421 (0.1402)  loss_objectness: 0.0728 (0.0742)  loss_rpn_box_reg: 0.0627 (0.0660)  time: 0.7025  data: 0.2984  max mem: 5923\n",
      "Training Epoch: [197]  [ 30/250]  eta: 0:02:33  lr: 0.000300  loss: 0.1413 (0.1404)  loss_objectness: 0.0692 (0.0727)  loss_rpn_box_reg: 0.0616 (0.0677)  time: 0.6944  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [197]  [ 40/250]  eta: 0:02:27  lr: 0.000300  loss: 0.1385 (0.1395)  loss_objectness: 0.0719 (0.0729)  loss_rpn_box_reg: 0.0662 (0.0666)  time: 0.7048  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [197]  [ 50/250]  eta: 0:02:20  lr: 0.000300  loss: 0.1300 (0.1385)  loss_objectness: 0.0720 (0.0724)  loss_rpn_box_reg: 0.0623 (0.0661)  time: 0.7018  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [197]  [ 60/250]  eta: 0:02:12  lr: 0.000300  loss: 0.1347 (0.1398)  loss_objectness: 0.0678 (0.0714)  loss_rpn_box_reg: 0.0644 (0.0685)  time: 0.6809  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [197]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1361 (0.1396)  loss_objectness: 0.0615 (0.0705)  loss_rpn_box_reg: 0.0757 (0.0691)  time: 0.6720  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [197]  [ 80/250]  eta: 0:01:58  lr: 0.000300  loss: 0.1366 (0.1392)  loss_objectness: 0.0678 (0.0705)  loss_rpn_box_reg: 0.0643 (0.0687)  time: 0.6949  data: 0.2974  max mem: 5923\n",
      "Training Epoch: [197]  [ 90/250]  eta: 0:01:51  lr: 0.000300  loss: 0.1389 (0.1393)  loss_objectness: 0.0714 (0.0708)  loss_rpn_box_reg: 0.0640 (0.0684)  time: 0.7017  data: 0.2980  max mem: 5923\n",
      "Training Epoch: [197]  [100/250]  eta: 0:01:44  lr: 0.000300  loss: 0.1389 (0.1385)  loss_objectness: 0.0632 (0.0700)  loss_rpn_box_reg: 0.0640 (0.0685)  time: 0.6960  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [197]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1411 (0.1392)  loss_objectness: 0.0632 (0.0704)  loss_rpn_box_reg: 0.0633 (0.0688)  time: 0.7089  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [197]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1412 (0.1389)  loss_objectness: 0.0698 (0.0698)  loss_rpn_box_reg: 0.0719 (0.0691)  time: 0.6949  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [197]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1311 (0.1385)  loss_objectness: 0.0685 (0.0697)  loss_rpn_box_reg: 0.0719 (0.0688)  time: 0.6738  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [197]  [140/250]  eta: 0:01:16  lr: 0.000300  loss: 0.1311 (0.1384)  loss_objectness: 0.0670 (0.0697)  loss_rpn_box_reg: 0.0635 (0.0688)  time: 0.6730  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [197]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1347 (0.1382)  loss_objectness: 0.0670 (0.0696)  loss_rpn_box_reg: 0.0616 (0.0686)  time: 0.6894  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [197]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1334 (0.1382)  loss_objectness: 0.0675 (0.0693)  loss_rpn_box_reg: 0.0620 (0.0689)  time: 0.6919  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [197]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1294 (0.1382)  loss_objectness: 0.0678 (0.0696)  loss_rpn_box_reg: 0.0616 (0.0686)  time: 0.6821  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [197]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1388 (0.1390)  loss_objectness: 0.0785 (0.0702)  loss_rpn_box_reg: 0.0658 (0.0688)  time: 0.6880  data: 0.2970  max mem: 5923\n",
      "Training Epoch: [197]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1388 (0.1384)  loss_objectness: 0.0727 (0.0703)  loss_rpn_box_reg: 0.0653 (0.0681)  time: 0.6845  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [197]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1331 (0.1381)  loss_objectness: 0.0684 (0.0702)  loss_rpn_box_reg: 0.0576 (0.0679)  time: 0.6794  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [197]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1369 (0.1385)  loss_objectness: 0.0676 (0.0701)  loss_rpn_box_reg: 0.0691 (0.0684)  time: 0.6785  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [197]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1364 (0.1385)  loss_objectness: 0.0715 (0.0702)  loss_rpn_box_reg: 0.0734 (0.0683)  time: 0.6799  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [197]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1324 (0.1385)  loss_objectness: 0.0658 (0.0700)  loss_rpn_box_reg: 0.0701 (0.0685)  time: 0.6803  data: 0.2892  max mem: 5923\n",
      "Training Epoch: [197]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1391 (0.1391)  loss_objectness: 0.0679 (0.0701)  loss_rpn_box_reg: 0.0647 (0.0690)  time: 0.6789  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [197]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1484 (0.1397)  loss_objectness: 0.0669 (0.0704)  loss_rpn_box_reg: 0.0680 (0.0692)  time: 0.6910  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [197] Total time: 0:02:52 (0.6894 s / it)\n",
      "Testing Epoch: [197]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1361 (0.1361)  loss_objectness: 0.0448 (0.0448)  loss_rpn_box_reg: 0.0913 (0.0913)  time: 0.6331  data: 0.2871  max mem: 5923\n",
      "Testing Epoch: [197]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1249 (0.1435)  loss_objectness: 0.0555 (0.0613)  loss_rpn_box_reg: 0.0759 (0.0822)  time: 0.6249  data: 0.3067  max mem: 5923\n",
      "Testing Epoch: [197] Total time: 0:00:39 (0.6338 s / it)\n",
      "Training Epoch: [198]  [  0/250]  eta: 0:03:02  lr: 0.000300  loss: 0.2110 (0.2110)  loss_objectness: 0.0908 (0.0908)  loss_rpn_box_reg: 0.1202 (0.1202)  time: 0.7312  data: 0.2981  max mem: 5923\n",
      "Training Epoch: [198]  [ 10/250]  eta: 0:02:48  lr: 0.000300  loss: 0.1340 (0.1537)  loss_objectness: 0.0678 (0.0692)  loss_rpn_box_reg: 0.0765 (0.0844)  time: 0.7018  data: 0.2962  max mem: 5923\n",
      "Training Epoch: [198]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1340 (0.1476)  loss_objectness: 0.0678 (0.0701)  loss_rpn_box_reg: 0.0668 (0.0775)  time: 0.6799  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [198]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1304 (0.1425)  loss_objectness: 0.0651 (0.0679)  loss_rpn_box_reg: 0.0668 (0.0746)  time: 0.6729  data: 0.2865  max mem: 5923\n",
      "Training Epoch: [198]  [ 40/250]  eta: 0:02:21  lr: 0.000300  loss: 0.1304 (0.1421)  loss_objectness: 0.0624 (0.0683)  loss_rpn_box_reg: 0.0692 (0.0738)  time: 0.6685  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [198]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1507 (0.1448)  loss_objectness: 0.0706 (0.0699)  loss_rpn_box_reg: 0.0717 (0.0749)  time: 0.6718  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [198]  [ 60/250]  eta: 0:02:08  lr: 0.000300  loss: 0.1507 (0.1455)  loss_objectness: 0.0707 (0.0706)  loss_rpn_box_reg: 0.0817 (0.0749)  time: 0.6761  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [198]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1318 (0.1440)  loss_objectness: 0.0708 (0.0708)  loss_rpn_box_reg: 0.0569 (0.0732)  time: 0.6829  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [198]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1389 (0.1455)  loss_objectness: 0.0748 (0.0720)  loss_rpn_box_reg: 0.0668 (0.0734)  time: 0.6957  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [198]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1455 (0.1443)  loss_objectness: 0.0748 (0.0718)  loss_rpn_box_reg: 0.0688 (0.0725)  time: 0.6865  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [198]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1216 (0.1410)  loss_objectness: 0.0605 (0.0701)  loss_rpn_box_reg: 0.0615 (0.0709)  time: 0.6975  data: 0.2970  max mem: 5923\n",
      "Training Epoch: [198]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1216 (0.1404)  loss_objectness: 0.0586 (0.0696)  loss_rpn_box_reg: 0.0628 (0.0707)  time: 0.7012  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [198]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1340 (0.1398)  loss_objectness: 0.0696 (0.0697)  loss_rpn_box_reg: 0.0613 (0.0702)  time: 0.6791  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [198]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1334 (0.1399)  loss_objectness: 0.0696 (0.0696)  loss_rpn_box_reg: 0.0620 (0.0702)  time: 0.6620  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [198]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1302 (0.1394)  loss_objectness: 0.0672 (0.0699)  loss_rpn_box_reg: 0.0636 (0.0695)  time: 0.6665  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [198]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1313 (0.1392)  loss_objectness: 0.0660 (0.0698)  loss_rpn_box_reg: 0.0617 (0.0695)  time: 0.6780  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [198]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1380 (0.1395)  loss_objectness: 0.0643 (0.0693)  loss_rpn_box_reg: 0.0676 (0.0702)  time: 0.6876  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [198]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1359 (0.1393)  loss_objectness: 0.0657 (0.0697)  loss_rpn_box_reg: 0.0623 (0.0696)  time: 0.6840  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [198]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1359 (0.1395)  loss_objectness: 0.0759 (0.0700)  loss_rpn_box_reg: 0.0543 (0.0696)  time: 0.6751  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [198]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1301 (0.1396)  loss_objectness: 0.0747 (0.0701)  loss_rpn_box_reg: 0.0570 (0.0695)  time: 0.6725  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [198]  [200/250]  eta: 0:00:33  lr: 0.000300  loss: 0.1360 (0.1401)  loss_objectness: 0.0747 (0.0702)  loss_rpn_box_reg: 0.0635 (0.0698)  time: 0.6631  data: 0.2877  max mem: 5923\n",
      "Training Epoch: [198]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1360 (0.1396)  loss_objectness: 0.0726 (0.0703)  loss_rpn_box_reg: 0.0635 (0.0694)  time: 0.6785  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [198]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1270 (0.1388)  loss_objectness: 0.0708 (0.0701)  loss_rpn_box_reg: 0.0551 (0.0687)  time: 0.7002  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [198]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1280 (0.1385)  loss_objectness: 0.0659 (0.0699)  loss_rpn_box_reg: 0.0564 (0.0687)  time: 0.6979  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [198]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1318 (0.1388)  loss_objectness: 0.0666 (0.0700)  loss_rpn_box_reg: 0.0707 (0.0688)  time: 0.6917  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [198]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1413 (0.1395)  loss_objectness: 0.0679 (0.0703)  loss_rpn_box_reg: 0.0749 (0.0692)  time: 0.6859  data: 0.2884  max mem: 5923\n",
      "Training Epoch: [198] Total time: 0:02:50 (0.6823 s / it)\n",
      "Testing Epoch: [198]  [ 0/62]  eta: 0:00:45  lr: 0.000300  loss: 0.1321 (0.1321)  loss_objectness: 0.0434 (0.0434)  loss_rpn_box_reg: 0.0887 (0.0887)  time: 0.7262  data: 0.3921  max mem: 5923\n",
      "Testing Epoch: [198]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1324 (0.1409)  loss_objectness: 0.0563 (0.0602)  loss_rpn_box_reg: 0.0741 (0.0807)  time: 0.6305  data: 0.3090  max mem: 5923\n",
      "Testing Epoch: [198] Total time: 0:00:39 (0.6331 s / it)\n",
      "Training Epoch: [199]  [  0/250]  eta: 0:02:49  lr: 0.000300  loss: 0.1400 (0.1400)  loss_objectness: 0.0634 (0.0634)  loss_rpn_box_reg: 0.0766 (0.0766)  time: 0.6772  data: 0.2861  max mem: 5923\n",
      "Training Epoch: [199]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1233 (0.1247)  loss_objectness: 0.0663 (0.0651)  loss_rpn_box_reg: 0.0553 (0.0596)  time: 0.6848  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [199]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1233 (0.1304)  loss_objectness: 0.0687 (0.0689)  loss_rpn_box_reg: 0.0553 (0.0614)  time: 0.6840  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [199]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1333 (0.1346)  loss_objectness: 0.0704 (0.0683)  loss_rpn_box_reg: 0.0619 (0.0663)  time: 0.6897  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [199]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1291 (0.1332)  loss_objectness: 0.0681 (0.0671)  loss_rpn_box_reg: 0.0619 (0.0661)  time: 0.7004  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [199]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1255 (0.1328)  loss_objectness: 0.0684 (0.0683)  loss_rpn_box_reg: 0.0582 (0.0646)  time: 0.6953  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [199]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1379 (0.1342)  loss_objectness: 0.0707 (0.0686)  loss_rpn_box_reg: 0.0600 (0.0656)  time: 0.6747  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [199]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1414 (0.1354)  loss_objectness: 0.0700 (0.0696)  loss_rpn_box_reg: 0.0628 (0.0658)  time: 0.6652  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [199]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1414 (0.1372)  loss_objectness: 0.0767 (0.0709)  loss_rpn_box_reg: 0.0664 (0.0663)  time: 0.6695  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [199]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1471 (0.1383)  loss_objectness: 0.0775 (0.0714)  loss_rpn_box_reg: 0.0664 (0.0669)  time: 0.6705  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [199]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1289 (0.1381)  loss_objectness: 0.0638 (0.0705)  loss_rpn_box_reg: 0.0714 (0.0676)  time: 0.6859  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [199]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1266 (0.1373)  loss_objectness: 0.0600 (0.0695)  loss_rpn_box_reg: 0.0714 (0.0678)  time: 0.7040  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [199]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1366 (0.1375)  loss_objectness: 0.0670 (0.0702)  loss_rpn_box_reg: 0.0640 (0.0673)  time: 0.6902  data: 0.2881  max mem: 5923\n",
      "Training Epoch: [199]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1384 (0.1375)  loss_objectness: 0.0744 (0.0703)  loss_rpn_box_reg: 0.0620 (0.0672)  time: 0.6757  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [199]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1366 (0.1372)  loss_objectness: 0.0618 (0.0699)  loss_rpn_box_reg: 0.0685 (0.0673)  time: 0.6814  data: 0.2875  max mem: 5923\n",
      "Training Epoch: [199]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1298 (0.1362)  loss_objectness: 0.0617 (0.0699)  loss_rpn_box_reg: 0.0636 (0.0664)  time: 0.6805  data: 0.2885  max mem: 5923\n",
      "Training Epoch: [199]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1266 (0.1370)  loss_objectness: 0.0674 (0.0700)  loss_rpn_box_reg: 0.0547 (0.0669)  time: 0.6774  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [199]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1390 (0.1369)  loss_objectness: 0.0669 (0.0699)  loss_rpn_box_reg: 0.0605 (0.0670)  time: 0.6804  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [199]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1390 (0.1374)  loss_objectness: 0.0653 (0.0701)  loss_rpn_box_reg: 0.0687 (0.0673)  time: 0.6874  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [199]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1482 (0.1381)  loss_objectness: 0.0729 (0.0706)  loss_rpn_box_reg: 0.0674 (0.0675)  time: 0.6910  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [199]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1361 (0.1375)  loss_objectness: 0.0671 (0.0701)  loss_rpn_box_reg: 0.0593 (0.0675)  time: 0.6810  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [199]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1231 (0.1376)  loss_objectness: 0.0597 (0.0698)  loss_rpn_box_reg: 0.0593 (0.0677)  time: 0.6852  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [199]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1402 (0.1383)  loss_objectness: 0.0652 (0.0700)  loss_rpn_box_reg: 0.0699 (0.0683)  time: 0.6876  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [199]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1462 (0.1386)  loss_objectness: 0.0649 (0.0699)  loss_rpn_box_reg: 0.0774 (0.0688)  time: 0.6824  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [199]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1489 (0.1396)  loss_objectness: 0.0761 (0.0707)  loss_rpn_box_reg: 0.0722 (0.0689)  time: 0.6839  data: 0.2979  max mem: 5923\n",
      "Training Epoch: [199]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1431 (0.1395)  loss_objectness: 0.0761 (0.0705)  loss_rpn_box_reg: 0.0722 (0.0691)  time: 0.6788  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [199] Total time: 0:02:50 (0.6831 s / it)\n",
      "Testing Epoch: [199]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1331 (0.1331)  loss_objectness: 0.0453 (0.0453)  loss_rpn_box_reg: 0.0878 (0.0878)  time: 0.6171  data: 0.2941  max mem: 5923\n",
      "Testing Epoch: [199]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1372 (0.1422)  loss_objectness: 0.0567 (0.0603)  loss_rpn_box_reg: 0.0744 (0.0819)  time: 0.6266  data: 0.3044  max mem: 5923\n",
      "Testing Epoch: [199] Total time: 0:00:39 (0.6326 s / it)\n",
      "Training Epoch: [200]  [  0/250]  eta: 0:03:09  lr: 0.000300  loss: 0.1941 (0.1941)  loss_objectness: 0.1049 (0.1049)  loss_rpn_box_reg: 0.0892 (0.0892)  time: 0.7562  data: 0.3211  max mem: 5923\n",
      "Training Epoch: [200]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1387 (0.1444)  loss_objectness: 0.0717 (0.0702)  loss_rpn_box_reg: 0.0754 (0.0742)  time: 0.6805  data: 0.2894  max mem: 5923\n",
      "Training Epoch: [200]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1387 (0.1443)  loss_objectness: 0.0584 (0.0673)  loss_rpn_box_reg: 0.0744 (0.0770)  time: 0.6759  data: 0.2864  max mem: 5923\n",
      "Training Epoch: [200]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1487 (0.1509)  loss_objectness: 0.0654 (0.0715)  loss_rpn_box_reg: 0.0744 (0.0794)  time: 0.6761  data: 0.2888  max mem: 5923\n",
      "Training Epoch: [200]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1331 (0.1438)  loss_objectness: 0.0681 (0.0697)  loss_rpn_box_reg: 0.0664 (0.0741)  time: 0.6807  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [200]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1206 (0.1418)  loss_objectness: 0.0672 (0.0715)  loss_rpn_box_reg: 0.0559 (0.0703)  time: 0.6885  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [200]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1351 (0.1425)  loss_objectness: 0.0721 (0.0719)  loss_rpn_box_reg: 0.0591 (0.0706)  time: 0.6894  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [200]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1317 (0.1425)  loss_objectness: 0.0716 (0.0717)  loss_rpn_box_reg: 0.0726 (0.0707)  time: 0.6861  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [200]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1265 (0.1402)  loss_objectness: 0.0693 (0.0710)  loss_rpn_box_reg: 0.0581 (0.0692)  time: 0.6780  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [200]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1278 (0.1411)  loss_objectness: 0.0712 (0.0714)  loss_rpn_box_reg: 0.0581 (0.0697)  time: 0.6783  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [200]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1375 (0.1407)  loss_objectness: 0.0690 (0.0711)  loss_rpn_box_reg: 0.0655 (0.0696)  time: 0.7025  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [200]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1375 (0.1408)  loss_objectness: 0.0702 (0.0712)  loss_rpn_box_reg: 0.0663 (0.0696)  time: 0.7052  data: 0.2962  max mem: 5923\n",
      "Training Epoch: [200]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1366 (0.1403)  loss_objectness: 0.0711 (0.0709)  loss_rpn_box_reg: 0.0663 (0.0694)  time: 0.6986  data: 0.2967  max mem: 5923\n",
      "Training Epoch: [200]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1323 (0.1406)  loss_objectness: 0.0675 (0.0707)  loss_rpn_box_reg: 0.0544 (0.0698)  time: 0.7101  data: 0.2974  max mem: 5923\n",
      "Training Epoch: [200]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1342 (0.1400)  loss_objectness: 0.0635 (0.0705)  loss_rpn_box_reg: 0.0600 (0.0694)  time: 0.6909  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [200]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1364 (0.1405)  loss_objectness: 0.0635 (0.0709)  loss_rpn_box_reg: 0.0610 (0.0696)  time: 0.6836  data: 0.2974  max mem: 5923\n",
      "Training Epoch: [200]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1451 (0.1403)  loss_objectness: 0.0707 (0.0710)  loss_rpn_box_reg: 0.0691 (0.0693)  time: 0.6999  data: 0.2969  max mem: 5923\n",
      "Training Epoch: [200]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1412 (0.1404)  loss_objectness: 0.0735 (0.0713)  loss_rpn_box_reg: 0.0660 (0.0691)  time: 0.6878  data: 0.2966  max mem: 5923\n",
      "Training Epoch: [200]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1332 (0.1403)  loss_objectness: 0.0712 (0.0714)  loss_rpn_box_reg: 0.0660 (0.0689)  time: 0.6767  data: 0.2977  max mem: 5923\n",
      "Training Epoch: [200]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1361 (0.1403)  loss_objectness: 0.0705 (0.0717)  loss_rpn_box_reg: 0.0620 (0.0686)  time: 0.6741  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [200]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1385 (0.1402)  loss_objectness: 0.0684 (0.0715)  loss_rpn_box_reg: 0.0648 (0.0687)  time: 0.6794  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [200]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1302 (0.1401)  loss_objectness: 0.0631 (0.0714)  loss_rpn_box_reg: 0.0617 (0.0687)  time: 0.6913  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [200]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1284 (0.1403)  loss_objectness: 0.0642 (0.0712)  loss_rpn_box_reg: 0.0617 (0.0691)  time: 0.6907  data: 0.2962  max mem: 5923\n",
      "Training Epoch: [200]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1308 (0.1400)  loss_objectness: 0.0614 (0.0709)  loss_rpn_box_reg: 0.0623 (0.0691)  time: 0.6850  data: 0.2966  max mem: 5923\n",
      "Training Epoch: [200]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1334 (0.1403)  loss_objectness: 0.0675 (0.0711)  loss_rpn_box_reg: 0.0661 (0.0692)  time: 0.6757  data: 0.2954  max mem: 5923\n",
      "Training Epoch: [200]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1376 (0.1403)  loss_objectness: 0.0696 (0.0711)  loss_rpn_box_reg: 0.0659 (0.0693)  time: 0.6736  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [200] Total time: 0:02:51 (0.6863 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:00  model_time: 0.6221 (0.6221)  evaluator_time: 0.0580 (0.0580)  time: 0.9772  data: 0.2821  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3871 (0.3902)  evaluator_time: 0.0810 (0.0856)  time: 0.7769  data: 0.2954  max mem: 5923\n",
      "Test: Total time: 0:00:48 (0.7786 s / it)\n",
      "Averaged stats: model_time: 0.3871 (0.3902)  evaluator_time: 0.0810 (0.0856)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.09s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.182\n",
      "Testing Epoch: [200]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1391 (0.1391)  loss_objectness: 0.0467 (0.0467)  loss_rpn_box_reg: 0.0924 (0.0924)  time: 0.6381  data: 0.3051  max mem: 5923\n",
      "Testing Epoch: [200]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1326 (0.1422)  loss_objectness: 0.0581 (0.0602)  loss_rpn_box_reg: 0.0769 (0.0820)  time: 0.6309  data: 0.3111  max mem: 5923\n",
      "Testing Epoch: [200] Total time: 0:00:39 (0.6350 s / it)\n",
      "Training Epoch: [201]  [  0/250]  eta: 0:02:56  lr: 0.000300  loss: 0.1724 (0.1724)  loss_objectness: 0.0804 (0.0804)  loss_rpn_box_reg: 0.0919 (0.0919)  time: 0.7062  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [201]  [ 10/250]  eta: 0:02:50  lr: 0.000300  loss: 0.1440 (0.1412)  loss_objectness: 0.0704 (0.0675)  loss_rpn_box_reg: 0.0736 (0.0737)  time: 0.7097  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [201]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1303 (0.1400)  loss_objectness: 0.0699 (0.0699)  loss_rpn_box_reg: 0.0614 (0.0701)  time: 0.6898  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [201]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1351 (0.1415)  loss_objectness: 0.0689 (0.0714)  loss_rpn_box_reg: 0.0649 (0.0701)  time: 0.6622  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [201]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1351 (0.1395)  loss_objectness: 0.0687 (0.0708)  loss_rpn_box_reg: 0.0663 (0.0687)  time: 0.6729  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [201]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1291 (0.1390)  loss_objectness: 0.0708 (0.0715)  loss_rpn_box_reg: 0.0640 (0.0674)  time: 0.6832  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [201]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1291 (0.1381)  loss_objectness: 0.0667 (0.0705)  loss_rpn_box_reg: 0.0642 (0.0676)  time: 0.6842  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [201]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1297 (0.1382)  loss_objectness: 0.0651 (0.0695)  loss_rpn_box_reg: 0.0673 (0.0687)  time: 0.6862  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [201]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1324 (0.1390)  loss_objectness: 0.0651 (0.0692)  loss_rpn_box_reg: 0.0673 (0.0698)  time: 0.6797  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [201]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1325 (0.1379)  loss_objectness: 0.0645 (0.0692)  loss_rpn_box_reg: 0.0697 (0.0687)  time: 0.6810  data: 0.2950  max mem: 5923\n",
      "Training Epoch: [201]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1275 (0.1367)  loss_objectness: 0.0699 (0.0692)  loss_rpn_box_reg: 0.0513 (0.0676)  time: 0.6842  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [201]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1286 (0.1365)  loss_objectness: 0.0658 (0.0690)  loss_rpn_box_reg: 0.0576 (0.0674)  time: 0.6959  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [201]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1257 (0.1362)  loss_objectness: 0.0658 (0.0689)  loss_rpn_box_reg: 0.0606 (0.0673)  time: 0.7033  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [201]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1257 (0.1367)  loss_objectness: 0.0647 (0.0689)  loss_rpn_box_reg: 0.0628 (0.0678)  time: 0.6874  data: 0.2862  max mem: 5923\n",
      "Training Epoch: [201]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1426 (0.1390)  loss_objectness: 0.0716 (0.0701)  loss_rpn_box_reg: 0.0719 (0.0689)  time: 0.6773  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [201]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1562 (0.1401)  loss_objectness: 0.0827 (0.0712)  loss_rpn_box_reg: 0.0724 (0.0689)  time: 0.6818  data: 0.2972  max mem: 5923\n",
      "Training Epoch: [201]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1442 (0.1398)  loss_objectness: 0.0751 (0.0710)  loss_rpn_box_reg: 0.0669 (0.0688)  time: 0.6824  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [201]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1300 (0.1397)  loss_objectness: 0.0647 (0.0707)  loss_rpn_box_reg: 0.0669 (0.0690)  time: 0.6857  data: 0.2973  max mem: 5923\n",
      "Training Epoch: [201]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1427 (0.1402)  loss_objectness: 0.0686 (0.0709)  loss_rpn_box_reg: 0.0675 (0.0693)  time: 0.6899  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [201]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1504 (0.1405)  loss_objectness: 0.0738 (0.0712)  loss_rpn_box_reg: 0.0668 (0.0692)  time: 0.6842  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [201]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1570 (0.1413)  loss_objectness: 0.0798 (0.0717)  loss_rpn_box_reg: 0.0744 (0.0696)  time: 0.6825  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [201]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1456 (0.1409)  loss_objectness: 0.0695 (0.0714)  loss_rpn_box_reg: 0.0762 (0.0694)  time: 0.6878  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [201]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1360 (0.1412)  loss_objectness: 0.0645 (0.0715)  loss_rpn_box_reg: 0.0742 (0.0697)  time: 0.6895  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [201]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1509 (0.1415)  loss_objectness: 0.0695 (0.0716)  loss_rpn_box_reg: 0.0739 (0.0699)  time: 0.6881  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [201]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1325 (0.1414)  loss_objectness: 0.0676 (0.0716)  loss_rpn_box_reg: 0.0679 (0.0698)  time: 0.6746  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [201]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1269 (0.1416)  loss_objectness: 0.0676 (0.0718)  loss_rpn_box_reg: 0.0679 (0.0698)  time: 0.6756  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [201] Total time: 0:02:51 (0.6847 s / it)\n",
      "Testing Epoch: [201]  [ 0/62]  eta: 0:00:39  lr: 0.000300  loss: 0.1409 (0.1409)  loss_objectness: 0.0500 (0.0500)  loss_rpn_box_reg: 0.0909 (0.0909)  time: 0.6371  data: 0.2941  max mem: 5923\n",
      "Testing Epoch: [201]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1305 (0.1400)  loss_objectness: 0.0585 (0.0589)  loss_rpn_box_reg: 0.0700 (0.0811)  time: 0.6242  data: 0.3067  max mem: 5923\n",
      "Testing Epoch: [201] Total time: 0:00:39 (0.6331 s / it)\n",
      "Training Epoch: [202]  [  0/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1320 (0.1320)  loss_objectness: 0.0524 (0.0524)  loss_rpn_box_reg: 0.0795 (0.0795)  time: 0.6862  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [202]  [ 10/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1357 (0.1348)  loss_objectness: 0.0703 (0.0689)  loss_rpn_box_reg: 0.0720 (0.0659)  time: 0.6695  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [202]  [ 20/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1297 (0.1389)  loss_objectness: 0.0659 (0.0675)  loss_rpn_box_reg: 0.0717 (0.0714)  time: 0.6724  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [202]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1483 (0.1463)  loss_objectness: 0.0685 (0.0703)  loss_rpn_box_reg: 0.0799 (0.0760)  time: 0.6930  data: 0.3028  max mem: 5923\n",
      "Training Epoch: [202]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1425 (0.1415)  loss_objectness: 0.0708 (0.0696)  loss_rpn_box_reg: 0.0673 (0.0719)  time: 0.6996  data: 0.2976  max mem: 5923\n",
      "Training Epoch: [202]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1318 (0.1407)  loss_objectness: 0.0665 (0.0694)  loss_rpn_box_reg: 0.0606 (0.0714)  time: 0.6887  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [202]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1344 (0.1394)  loss_objectness: 0.0723 (0.0702)  loss_rpn_box_reg: 0.0561 (0.0692)  time: 0.6847  data: 0.2966  max mem: 5923\n",
      "Training Epoch: [202]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1299 (0.1388)  loss_objectness: 0.0743 (0.0700)  loss_rpn_box_reg: 0.0569 (0.0688)  time: 0.6860  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [202]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1376 (0.1393)  loss_objectness: 0.0668 (0.0695)  loss_rpn_box_reg: 0.0725 (0.0697)  time: 0.6927  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [202]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1527 (0.1401)  loss_objectness: 0.0643 (0.0695)  loss_rpn_box_reg: 0.0766 (0.0706)  time: 0.6958  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [202]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1527 (0.1412)  loss_objectness: 0.0673 (0.0699)  loss_rpn_box_reg: 0.0766 (0.0713)  time: 0.6900  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [202]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1537 (0.1419)  loss_objectness: 0.0723 (0.0699)  loss_rpn_box_reg: 0.0758 (0.0720)  time: 0.6929  data: 0.2987  max mem: 5923\n",
      "Training Epoch: [202]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1364 (0.1416)  loss_objectness: 0.0772 (0.0702)  loss_rpn_box_reg: 0.0699 (0.0714)  time: 0.6889  data: 0.2969  max mem: 5923\n",
      "Training Epoch: [202]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1268 (0.1415)  loss_objectness: 0.0722 (0.0704)  loss_rpn_box_reg: 0.0627 (0.0711)  time: 0.6744  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [202]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1382 (0.1415)  loss_objectness: 0.0698 (0.0706)  loss_rpn_box_reg: 0.0673 (0.0709)  time: 0.6810  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [202]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1382 (0.1415)  loss_objectness: 0.0679 (0.0707)  loss_rpn_box_reg: 0.0690 (0.0709)  time: 0.6857  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [202]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1340 (0.1414)  loss_objectness: 0.0679 (0.0708)  loss_rpn_box_reg: 0.0613 (0.0706)  time: 0.6884  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [202]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1423 (0.1411)  loss_objectness: 0.0724 (0.0710)  loss_rpn_box_reg: 0.0613 (0.0701)  time: 0.7006  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [202]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1378 (0.1401)  loss_objectness: 0.0667 (0.0703)  loss_rpn_box_reg: 0.0627 (0.0699)  time: 0.7014  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [202]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1406 (0.1408)  loss_objectness: 0.0670 (0.0708)  loss_rpn_box_reg: 0.0653 (0.0699)  time: 0.6832  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [202]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1542 (0.1409)  loss_objectness: 0.0759 (0.0709)  loss_rpn_box_reg: 0.0653 (0.0700)  time: 0.6839  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [202]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1349 (0.1407)  loss_objectness: 0.0604 (0.0707)  loss_rpn_box_reg: 0.0616 (0.0700)  time: 0.6848  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [202]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1310 (0.1405)  loss_objectness: 0.0632 (0.0706)  loss_rpn_box_reg: 0.0606 (0.0699)  time: 0.6847  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [202]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1321 (0.1406)  loss_objectness: 0.0670 (0.0707)  loss_rpn_box_reg: 0.0652 (0.0700)  time: 0.6961  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [202]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1502 (0.1410)  loss_objectness: 0.0741 (0.0710)  loss_rpn_box_reg: 0.0698 (0.0700)  time: 0.6908  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [202]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1323 (0.1409)  loss_objectness: 0.0674 (0.0709)  loss_rpn_box_reg: 0.0701 (0.0699)  time: 0.6875  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [202] Total time: 0:02:52 (0.6883 s / it)\n",
      "Testing Epoch: [202]  [ 0/62]  eta: 0:00:45  lr: 0.000300  loss: 0.1363 (0.1363)  loss_objectness: 0.0450 (0.0450)  loss_rpn_box_reg: 0.0913 (0.0913)  time: 0.7282  data: 0.4051  max mem: 5923\n",
      "Testing Epoch: [202]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1292 (0.1397)  loss_objectness: 0.0562 (0.0577)  loss_rpn_box_reg: 0.0731 (0.0821)  time: 0.6321  data: 0.3146  max mem: 5923\n",
      "Testing Epoch: [202] Total time: 0:00:39 (0.6360 s / it)\n",
      "Training Epoch: [203]  [  0/250]  eta: 0:02:58  lr: 0.000300  loss: 0.1259 (0.1259)  loss_objectness: 0.0516 (0.0516)  loss_rpn_box_reg: 0.0743 (0.0743)  time: 0.7152  data: 0.2841  max mem: 5923\n",
      "Training Epoch: [203]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1251 (0.1287)  loss_objectness: 0.0588 (0.0641)  loss_rpn_box_reg: 0.0599 (0.0646)  time: 0.6930  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [203]  [ 20/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1251 (0.1293)  loss_objectness: 0.0662 (0.0671)  loss_rpn_box_reg: 0.0599 (0.0621)  time: 0.6947  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [203]  [ 30/250]  eta: 0:02:31  lr: 0.000300  loss: 0.1404 (0.1322)  loss_objectness: 0.0658 (0.0662)  loss_rpn_box_reg: 0.0645 (0.0660)  time: 0.6875  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [203]  [ 40/250]  eta: 0:02:24  lr: 0.000300  loss: 0.1363 (0.1344)  loss_objectness: 0.0641 (0.0675)  loss_rpn_box_reg: 0.0645 (0.0669)  time: 0.6782  data: 0.2938  max mem: 5923\n",
      "Training Epoch: [203]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1332 (0.1329)  loss_objectness: 0.0707 (0.0679)  loss_rpn_box_reg: 0.0610 (0.0650)  time: 0.6749  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [203]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1302 (0.1332)  loss_objectness: 0.0668 (0.0675)  loss_rpn_box_reg: 0.0590 (0.0657)  time: 0.6686  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [203]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1269 (0.1324)  loss_objectness: 0.0637 (0.0670)  loss_rpn_box_reg: 0.0590 (0.0654)  time: 0.6692  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [203]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1292 (0.1332)  loss_objectness: 0.0677 (0.0672)  loss_rpn_box_reg: 0.0658 (0.0660)  time: 0.6856  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [203]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1379 (0.1337)  loss_objectness: 0.0703 (0.0676)  loss_rpn_box_reg: 0.0681 (0.0660)  time: 0.6907  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [203]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1337 (0.1350)  loss_objectness: 0.0703 (0.0685)  loss_rpn_box_reg: 0.0657 (0.0665)  time: 0.6851  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [203]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1313 (0.1339)  loss_objectness: 0.0652 (0.0684)  loss_rpn_box_reg: 0.0627 (0.0655)  time: 0.6982  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [203]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1313 (0.1349)  loss_objectness: 0.0674 (0.0692)  loss_rpn_box_reg: 0.0611 (0.0657)  time: 0.6905  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [203]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1403 (0.1363)  loss_objectness: 0.0708 (0.0695)  loss_rpn_box_reg: 0.0630 (0.0668)  time: 0.6807  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [203]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1351 (0.1362)  loss_objectness: 0.0676 (0.0694)  loss_rpn_box_reg: 0.0631 (0.0669)  time: 0.6830  data: 0.2886  max mem: 5923\n",
      "Training Epoch: [203]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1352 (0.1376)  loss_objectness: 0.0682 (0.0697)  loss_rpn_box_reg: 0.0703 (0.0679)  time: 0.6812  data: 0.2884  max mem: 5923\n",
      "Training Epoch: [203]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1420 (0.1380)  loss_objectness: 0.0709 (0.0701)  loss_rpn_box_reg: 0.0695 (0.0679)  time: 0.6819  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [203]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1414 (0.1381)  loss_objectness: 0.0724 (0.0705)  loss_rpn_box_reg: 0.0650 (0.0676)  time: 0.6841  data: 0.2974  max mem: 5923\n",
      "Training Epoch: [203]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1351 (0.1376)  loss_objectness: 0.0708 (0.0703)  loss_rpn_box_reg: 0.0635 (0.0673)  time: 0.6841  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [203]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1398 (0.1389)  loss_objectness: 0.0712 (0.0704)  loss_rpn_box_reg: 0.0709 (0.0685)  time: 0.6661  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [203]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1524 (0.1392)  loss_objectness: 0.0714 (0.0705)  loss_rpn_box_reg: 0.0762 (0.0688)  time: 0.6683  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [203]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1380 (0.1396)  loss_objectness: 0.0799 (0.0709)  loss_rpn_box_reg: 0.0716 (0.0687)  time: 0.6863  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [203]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1471 (0.1404)  loss_objectness: 0.0681 (0.0706)  loss_rpn_box_reg: 0.0792 (0.0698)  time: 0.6811  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [203]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1471 (0.1407)  loss_objectness: 0.0655 (0.0710)  loss_rpn_box_reg: 0.0699 (0.0697)  time: 0.6851  data: 0.2912  max mem: 5923\n",
      "Training Epoch: [203]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1271 (0.1401)  loss_objectness: 0.0692 (0.0707)  loss_rpn_box_reg: 0.0595 (0.0694)  time: 0.6953  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [203]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1247 (0.1401)  loss_objectness: 0.0692 (0.0705)  loss_rpn_box_reg: 0.0595 (0.0696)  time: 0.6916  data: 0.2871  max mem: 5923\n",
      "Training Epoch: [203] Total time: 0:02:50 (0.6832 s / it)\n",
      "Testing Epoch: [203]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1361 (0.1361)  loss_objectness: 0.0493 (0.0493)  loss_rpn_box_reg: 0.0867 (0.0867)  time: 0.6231  data: 0.2911  max mem: 5923\n",
      "Testing Epoch: [203]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1316 (0.1400)  loss_objectness: 0.0576 (0.0598)  loss_rpn_box_reg: 0.0743 (0.0803)  time: 0.6328  data: 0.3110  max mem: 5923\n",
      "Testing Epoch: [203] Total time: 0:00:39 (0.6345 s / it)\n",
      "Training Epoch: [204]  [  0/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1146 (0.1146)  loss_objectness: 0.0600 (0.0600)  loss_rpn_box_reg: 0.0546 (0.0546)  time: 0.6221  data: 0.2991  max mem: 5923\n",
      "Training Epoch: [204]  [ 10/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1376 (0.1306)  loss_objectness: 0.0661 (0.0685)  loss_rpn_box_reg: 0.0546 (0.0620)  time: 0.6672  data: 0.2962  max mem: 5923\n",
      "Training Epoch: [204]  [ 20/250]  eta: 0:02:34  lr: 0.000300  loss: 0.1299 (0.1261)  loss_objectness: 0.0661 (0.0664)  loss_rpn_box_reg: 0.0578 (0.0597)  time: 0.6734  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [204]  [ 30/250]  eta: 0:02:28  lr: 0.000300  loss: 0.1257 (0.1306)  loss_objectness: 0.0646 (0.0666)  loss_rpn_box_reg: 0.0637 (0.0641)  time: 0.6761  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [204]  [ 40/250]  eta: 0:02:21  lr: 0.000300  loss: 0.1339 (0.1326)  loss_objectness: 0.0646 (0.0658)  loss_rpn_box_reg: 0.0748 (0.0668)  time: 0.6789  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [204]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1211 (0.1304)  loss_objectness: 0.0562 (0.0643)  loss_rpn_box_reg: 0.0748 (0.0661)  time: 0.6966  data: 0.2928  max mem: 5923\n",
      "Training Epoch: [204]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1251 (0.1309)  loss_objectness: 0.0562 (0.0641)  loss_rpn_box_reg: 0.0658 (0.0668)  time: 0.7057  data: 0.2944  max mem: 5923\n",
      "Training Epoch: [204]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1349 (0.1329)  loss_objectness: 0.0659 (0.0653)  loss_rpn_box_reg: 0.0666 (0.0676)  time: 0.6961  data: 0.3006  max mem: 5923\n",
      "Training Epoch: [204]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1441 (0.1338)  loss_objectness: 0.0738 (0.0668)  loss_rpn_box_reg: 0.0650 (0.0670)  time: 0.6883  data: 0.2987  max mem: 5923\n",
      "Training Epoch: [204]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1358 (0.1338)  loss_objectness: 0.0755 (0.0673)  loss_rpn_box_reg: 0.0606 (0.0665)  time: 0.6807  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [204]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1382 (0.1342)  loss_objectness: 0.0729 (0.0681)  loss_rpn_box_reg: 0.0599 (0.0661)  time: 0.6782  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [204]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1459 (0.1353)  loss_objectness: 0.0729 (0.0687)  loss_rpn_box_reg: 0.0687 (0.0666)  time: 0.6675  data: 0.2949  max mem: 5923\n",
      "Training Epoch: [204]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1479 (0.1366)  loss_objectness: 0.0709 (0.0693)  loss_rpn_box_reg: 0.0743 (0.0673)  time: 0.6716  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [204]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1537 (0.1380)  loss_objectness: 0.0791 (0.0702)  loss_rpn_box_reg: 0.0704 (0.0677)  time: 0.6882  data: 0.2942  max mem: 5923\n",
      "Training Epoch: [204]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1323 (0.1380)  loss_objectness: 0.0740 (0.0699)  loss_rpn_box_reg: 0.0660 (0.0681)  time: 0.6849  data: 0.2960  max mem: 5923\n",
      "Training Epoch: [204]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1322 (0.1382)  loss_objectness: 0.0658 (0.0698)  loss_rpn_box_reg: 0.0676 (0.0685)  time: 0.6873  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [204]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1542 (0.1398)  loss_objectness: 0.0745 (0.0705)  loss_rpn_box_reg: 0.0764 (0.0693)  time: 0.6887  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [204]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1454 (0.1404)  loss_objectness: 0.0677 (0.0703)  loss_rpn_box_reg: 0.0810 (0.0701)  time: 0.6714  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [204]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1415 (0.1410)  loss_objectness: 0.0604 (0.0703)  loss_rpn_box_reg: 0.0828 (0.0707)  time: 0.6663  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [204]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1417 (0.1407)  loss_objectness: 0.0642 (0.0702)  loss_rpn_box_reg: 0.0694 (0.0705)  time: 0.6735  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [204]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1296 (0.1399)  loss_objectness: 0.0642 (0.0701)  loss_rpn_box_reg: 0.0551 (0.0697)  time: 0.6819  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [204]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1296 (0.1401)  loss_objectness: 0.0707 (0.0703)  loss_rpn_box_reg: 0.0536 (0.0698)  time: 0.6867  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [204]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1339 (0.1397)  loss_objectness: 0.0727 (0.0703)  loss_rpn_box_reg: 0.0631 (0.0694)  time: 0.6887  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [204]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1368 (0.1400)  loss_objectness: 0.0748 (0.0706)  loss_rpn_box_reg: 0.0643 (0.0694)  time: 0.6882  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [204]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1453 (0.1403)  loss_objectness: 0.0768 (0.0709)  loss_rpn_box_reg: 0.0711 (0.0694)  time: 0.6851  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [204]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1450 (0.1402)  loss_objectness: 0.0728 (0.0708)  loss_rpn_box_reg: 0.0714 (0.0694)  time: 0.6881  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [204] Total time: 0:02:50 (0.6824 s / it)\n",
      "Testing Epoch: [204]  [ 0/62]  eta: 0:00:45  lr: 0.000300  loss: 0.1330 (0.1330)  loss_objectness: 0.0443 (0.0443)  loss_rpn_box_reg: 0.0887 (0.0887)  time: 0.7292  data: 0.3991  max mem: 5923\n",
      "Testing Epoch: [204]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1333 (0.1405)  loss_objectness: 0.0588 (0.0587)  loss_rpn_box_reg: 0.0743 (0.0817)  time: 0.6306  data: 0.3104  max mem: 5923\n",
      "Testing Epoch: [204] Total time: 0:00:39 (0.6327 s / it)\n",
      "Training Epoch: [205]  [  0/250]  eta: 0:02:52  lr: 0.000300  loss: 0.1258 (0.1258)  loss_objectness: 0.0525 (0.0525)  loss_rpn_box_reg: 0.0733 (0.0733)  time: 0.6882  data: 0.2951  max mem: 5923\n",
      "Training Epoch: [205]  [ 10/250]  eta: 0:02:50  lr: 0.000300  loss: 0.1372 (0.1376)  loss_objectness: 0.0607 (0.0670)  loss_rpn_box_reg: 0.0724 (0.0705)  time: 0.7099  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [205]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1330 (0.1336)  loss_objectness: 0.0578 (0.0648)  loss_rpn_box_reg: 0.0662 (0.0688)  time: 0.6901  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [205]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1289 (0.1355)  loss_objectness: 0.0666 (0.0677)  loss_rpn_box_reg: 0.0653 (0.0678)  time: 0.6854  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [205]  [ 40/250]  eta: 0:02:25  lr: 0.000300  loss: 0.1418 (0.1347)  loss_objectness: 0.0715 (0.0690)  loss_rpn_box_reg: 0.0575 (0.0658)  time: 0.6919  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [205]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1439 (0.1340)  loss_objectness: 0.0701 (0.0692)  loss_rpn_box_reg: 0.0575 (0.0647)  time: 0.6818  data: 0.2886  max mem: 5923\n",
      "Training Epoch: [205]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1467 (0.1364)  loss_objectness: 0.0695 (0.0700)  loss_rpn_box_reg: 0.0665 (0.0664)  time: 0.6709  data: 0.2878  max mem: 5923\n",
      "Training Epoch: [205]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1396 (0.1358)  loss_objectness: 0.0695 (0.0695)  loss_rpn_box_reg: 0.0665 (0.0663)  time: 0.6868  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [205]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1238 (0.1347)  loss_objectness: 0.0665 (0.0696)  loss_rpn_box_reg: 0.0522 (0.0651)  time: 0.7010  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [205]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1172 (0.1356)  loss_objectness: 0.0674 (0.0698)  loss_rpn_box_reg: 0.0613 (0.0657)  time: 0.6830  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [205]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1395 (0.1363)  loss_objectness: 0.0660 (0.0697)  loss_rpn_box_reg: 0.0685 (0.0667)  time: 0.6917  data: 0.2960  max mem: 5923\n",
      "Training Epoch: [205]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1405 (0.1365)  loss_objectness: 0.0654 (0.0695)  loss_rpn_box_reg: 0.0741 (0.0670)  time: 0.7034  data: 0.2955  max mem: 5923\n",
      "Training Epoch: [205]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1356 (0.1359)  loss_objectness: 0.0650 (0.0688)  loss_rpn_box_reg: 0.0672 (0.0671)  time: 0.6997  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [205]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1208 (0.1351)  loss_objectness: 0.0623 (0.0683)  loss_rpn_box_reg: 0.0598 (0.0668)  time: 0.6992  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [205]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1285 (0.1357)  loss_objectness: 0.0572 (0.0683)  loss_rpn_box_reg: 0.0635 (0.0673)  time: 0.6903  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [205]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1263 (0.1355)  loss_objectness: 0.0645 (0.0681)  loss_rpn_box_reg: 0.0618 (0.0673)  time: 0.6796  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [205]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1259 (0.1358)  loss_objectness: 0.0677 (0.0686)  loss_rpn_box_reg: 0.0604 (0.0672)  time: 0.6857  data: 0.2998  max mem: 5923\n",
      "Training Epoch: [205]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1318 (0.1362)  loss_objectness: 0.0657 (0.0682)  loss_rpn_box_reg: 0.0636 (0.0680)  time: 0.6808  data: 0.2956  max mem: 5923\n",
      "Training Epoch: [205]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1485 (0.1370)  loss_objectness: 0.0712 (0.0686)  loss_rpn_box_reg: 0.0716 (0.0684)  time: 0.6728  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [205]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1536 (0.1381)  loss_objectness: 0.0761 (0.0690)  loss_rpn_box_reg: 0.0716 (0.0691)  time: 0.6693  data: 0.2960  max mem: 5923\n",
      "Training Epoch: [205]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1536 (0.1392)  loss_objectness: 0.0761 (0.0694)  loss_rpn_box_reg: 0.0709 (0.0698)  time: 0.6672  data: 0.2978  max mem: 5923\n",
      "Training Epoch: [205]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1532 (0.1403)  loss_objectness: 0.0750 (0.0697)  loss_rpn_box_reg: 0.0809 (0.0706)  time: 0.6763  data: 0.2986  max mem: 5923\n",
      "Training Epoch: [205]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1418 (0.1399)  loss_objectness: 0.0704 (0.0697)  loss_rpn_box_reg: 0.0740 (0.0702)  time: 0.6652  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [205]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1351 (0.1398)  loss_objectness: 0.0673 (0.0698)  loss_rpn_box_reg: 0.0567 (0.0700)  time: 0.6631  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [205]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1308 (0.1394)  loss_objectness: 0.0642 (0.0696)  loss_rpn_box_reg: 0.0590 (0.0698)  time: 0.6913  data: 0.2980  max mem: 5923\n",
      "Training Epoch: [205]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1333 (0.1399)  loss_objectness: 0.0673 (0.0702)  loss_rpn_box_reg: 0.0586 (0.0697)  time: 0.6994  data: 0.2965  max mem: 5923\n",
      "Training Epoch: [205] Total time: 0:02:51 (0.6851 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:00:59  model_time: 0.6091 (0.6091)  evaluator_time: 0.0580 (0.0580)  time: 0.9672  data: 0.2851  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.3891 (0.3936)  evaluator_time: 0.0700 (0.0822)  time: 0.7790  data: 0.3089  max mem: 5923\n",
      "Test: Total time: 0:00:48 (0.7817 s / it)\n",
      "Averaged stats: model_time: 0.3891 (0.3936)  evaluator_time: 0.0700 (0.0822)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.11s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.022\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.054\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.165\n",
      "Testing Epoch: [205]  [ 0/62]  eta: 0:00:42  lr: 0.000300  loss: 0.1371 (0.1371)  loss_objectness: 0.0439 (0.0439)  loss_rpn_box_reg: 0.0932 (0.0932)  time: 0.6932  data: 0.3721  max mem: 5923\n",
      "Testing Epoch: [205]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1325 (0.1421)  loss_objectness: 0.0571 (0.0613)  loss_rpn_box_reg: 0.0709 (0.0808)  time: 0.6336  data: 0.3124  max mem: 5923\n",
      "Testing Epoch: [205] Total time: 0:00:39 (0.6332 s / it)\n",
      "Training Epoch: [206]  [  0/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1126 (0.1126)  loss_objectness: 0.0648 (0.0648)  loss_rpn_box_reg: 0.0478 (0.0478)  time: 0.6672  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [206]  [ 10/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1285 (0.1393)  loss_objectness: 0.0690 (0.0696)  loss_rpn_box_reg: 0.0625 (0.0697)  time: 0.6702  data: 0.2962  max mem: 5923\n",
      "Training Epoch: [206]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1285 (0.1364)  loss_objectness: 0.0667 (0.0676)  loss_rpn_box_reg: 0.0672 (0.0689)  time: 0.6848  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [206]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1228 (0.1306)  loss_objectness: 0.0615 (0.0650)  loss_rpn_box_reg: 0.0607 (0.0656)  time: 0.6902  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [206]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1273 (0.1341)  loss_objectness: 0.0643 (0.0675)  loss_rpn_box_reg: 0.0593 (0.0666)  time: 0.6682  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [206]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1353 (0.1355)  loss_objectness: 0.0699 (0.0681)  loss_rpn_box_reg: 0.0651 (0.0674)  time: 0.6714  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [206]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1335 (0.1355)  loss_objectness: 0.0654 (0.0681)  loss_rpn_box_reg: 0.0638 (0.0674)  time: 0.6850  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [206]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1348 (0.1366)  loss_objectness: 0.0670 (0.0693)  loss_rpn_box_reg: 0.0638 (0.0673)  time: 0.6852  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [206]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1348 (0.1369)  loss_objectness: 0.0670 (0.0683)  loss_rpn_box_reg: 0.0608 (0.0686)  time: 0.6763  data: 0.2869  max mem: 5923\n",
      "Training Epoch: [206]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1424 (0.1372)  loss_objectness: 0.0619 (0.0683)  loss_rpn_box_reg: 0.0777 (0.0689)  time: 0.6562  data: 0.2892  max mem: 5923\n",
      "Training Epoch: [206]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1462 (0.1387)  loss_objectness: 0.0673 (0.0689)  loss_rpn_box_reg: 0.0777 (0.0698)  time: 0.6624  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [206]  [110/250]  eta: 0:01:34  lr: 0.000300  loss: 0.1437 (0.1388)  loss_objectness: 0.0754 (0.0698)  loss_rpn_box_reg: 0.0580 (0.0690)  time: 0.6768  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [206]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1247 (0.1377)  loss_objectness: 0.0675 (0.0693)  loss_rpn_box_reg: 0.0552 (0.0684)  time: 0.7070  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [206]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1215 (0.1389)  loss_objectness: 0.0647 (0.0697)  loss_rpn_box_reg: 0.0568 (0.0693)  time: 0.7072  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [206]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1426 (0.1401)  loss_objectness: 0.0718 (0.0703)  loss_rpn_box_reg: 0.0699 (0.0697)  time: 0.6770  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [206]  [150/250]  eta: 0:01:07  lr: 0.000300  loss: 0.1313 (0.1397)  loss_objectness: 0.0740 (0.0704)  loss_rpn_box_reg: 0.0666 (0.0693)  time: 0.6715  data: 0.2883  max mem: 5923\n",
      "Training Epoch: [206]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1357 (0.1404)  loss_objectness: 0.0758 (0.0707)  loss_rpn_box_reg: 0.0669 (0.0697)  time: 0.6813  data: 0.2894  max mem: 5923\n",
      "Training Epoch: [206]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1431 (0.1402)  loss_objectness: 0.0764 (0.0710)  loss_rpn_box_reg: 0.0655 (0.0693)  time: 0.6953  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [206]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1448 (0.1409)  loss_objectness: 0.0757 (0.0716)  loss_rpn_box_reg: 0.0655 (0.0694)  time: 0.6840  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [206]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1389 (0.1409)  loss_objectness: 0.0710 (0.0713)  loss_rpn_box_reg: 0.0642 (0.0696)  time: 0.6832  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [206]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1351 (0.1413)  loss_objectness: 0.0734 (0.0718)  loss_rpn_box_reg: 0.0649 (0.0695)  time: 0.6968  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [206]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1511 (0.1417)  loss_objectness: 0.0779 (0.0719)  loss_rpn_box_reg: 0.0684 (0.0698)  time: 0.6940  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [206]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1532 (0.1423)  loss_objectness: 0.0811 (0.0725)  loss_rpn_box_reg: 0.0692 (0.0698)  time: 0.6894  data: 0.2952  max mem: 5923\n",
      "Training Epoch: [206]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1485 (0.1422)  loss_objectness: 0.0754 (0.0721)  loss_rpn_box_reg: 0.0679 (0.0701)  time: 0.6914  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [206]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1468 (0.1428)  loss_objectness: 0.0680 (0.0722)  loss_rpn_box_reg: 0.0757 (0.0706)  time: 0.6820  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [206]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1522 (0.1429)  loss_objectness: 0.0775 (0.0726)  loss_rpn_box_reg: 0.0697 (0.0702)  time: 0.6872  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [206] Total time: 0:02:50 (0.6834 s / it)\n",
      "Testing Epoch: [206]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1385 (0.1385)  loss_objectness: 0.0463 (0.0463)  loss_rpn_box_reg: 0.0922 (0.0922)  time: 0.6271  data: 0.3061  max mem: 5923\n",
      "Testing Epoch: [206]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1353 (0.1441)  loss_objectness: 0.0578 (0.0631)  loss_rpn_box_reg: 0.0754 (0.0810)  time: 0.6247  data: 0.3044  max mem: 5923\n",
      "Testing Epoch: [206] Total time: 0:00:39 (0.6309 s / it)\n",
      "Training Epoch: [207]  [  0/250]  eta: 0:03:11  lr: 0.000300  loss: 0.1108 (0.1108)  loss_objectness: 0.0658 (0.0658)  loss_rpn_box_reg: 0.0450 (0.0450)  time: 0.7642  data: 0.3211  max mem: 5923\n",
      "Training Epoch: [207]  [ 10/250]  eta: 0:02:46  lr: 0.000300  loss: 0.1219 (0.1342)  loss_objectness: 0.0649 (0.0654)  loss_rpn_box_reg: 0.0628 (0.0687)  time: 0.6917  data: 0.2962  max mem: 5923\n",
      "Training Epoch: [207]  [ 20/250]  eta: 0:02:38  lr: 0.000300  loss: 0.1219 (0.1352)  loss_objectness: 0.0649 (0.0683)  loss_rpn_box_reg: 0.0585 (0.0669)  time: 0.6875  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [207]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1185 (0.1338)  loss_objectness: 0.0667 (0.0670)  loss_rpn_box_reg: 0.0563 (0.0669)  time: 0.6740  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [207]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1327 (0.1342)  loss_objectness: 0.0653 (0.0668)  loss_rpn_box_reg: 0.0566 (0.0675)  time: 0.6736  data: 0.2957  max mem: 5923\n",
      "Training Epoch: [207]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1327 (0.1360)  loss_objectness: 0.0654 (0.0690)  loss_rpn_box_reg: 0.0572 (0.0670)  time: 0.6829  data: 0.2989  max mem: 5923\n",
      "Training Epoch: [207]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1313 (0.1379)  loss_objectness: 0.0740 (0.0699)  loss_rpn_box_reg: 0.0665 (0.0680)  time: 0.6909  data: 0.2945  max mem: 5923\n",
      "Training Epoch: [207]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1313 (0.1380)  loss_objectness: 0.0690 (0.0692)  loss_rpn_box_reg: 0.0728 (0.0687)  time: 0.6868  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [207]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1326 (0.1374)  loss_objectness: 0.0688 (0.0689)  loss_rpn_box_reg: 0.0728 (0.0685)  time: 0.6836  data: 0.2876  max mem: 5923\n",
      "Training Epoch: [207]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1333 (0.1376)  loss_objectness: 0.0688 (0.0689)  loss_rpn_box_reg: 0.0653 (0.0687)  time: 0.6894  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [207]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1396 (0.1380)  loss_objectness: 0.0710 (0.0692)  loss_rpn_box_reg: 0.0653 (0.0688)  time: 0.6809  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [207]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1396 (0.1382)  loss_objectness: 0.0680 (0.0696)  loss_rpn_box_reg: 0.0658 (0.0686)  time: 0.6806  data: 0.2875  max mem: 5923\n",
      "Training Epoch: [207]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1402 (0.1387)  loss_objectness: 0.0696 (0.0699)  loss_rpn_box_reg: 0.0701 (0.0688)  time: 0.6875  data: 0.2876  max mem: 5923\n",
      "Training Epoch: [207]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1370 (0.1380)  loss_objectness: 0.0690 (0.0698)  loss_rpn_box_reg: 0.0679 (0.0682)  time: 0.6830  data: 0.2875  max mem: 5923\n",
      "Training Epoch: [207]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1363 (0.1379)  loss_objectness: 0.0650 (0.0693)  loss_rpn_box_reg: 0.0695 (0.0686)  time: 0.6779  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [207]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1413 (0.1387)  loss_objectness: 0.0673 (0.0698)  loss_rpn_box_reg: 0.0740 (0.0689)  time: 0.6812  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [207]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1522 (0.1401)  loss_objectness: 0.0683 (0.0698)  loss_rpn_box_reg: 0.0798 (0.0703)  time: 0.6872  data: 0.2969  max mem: 5923\n",
      "Training Epoch: [207]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1471 (0.1398)  loss_objectness: 0.0648 (0.0693)  loss_rpn_box_reg: 0.0798 (0.0706)  time: 0.6972  data: 0.2976  max mem: 5923\n",
      "Training Epoch: [207]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1427 (0.1400)  loss_objectness: 0.0658 (0.0694)  loss_rpn_box_reg: 0.0733 (0.0706)  time: 0.6833  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [207]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1281 (0.1391)  loss_objectness: 0.0707 (0.0692)  loss_rpn_box_reg: 0.0579 (0.0699)  time: 0.6867  data: 0.2879  max mem: 5923\n",
      "Training Epoch: [207]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1257 (0.1392)  loss_objectness: 0.0683 (0.0695)  loss_rpn_box_reg: 0.0589 (0.0697)  time: 0.6986  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [207]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1403 (0.1388)  loss_objectness: 0.0752 (0.0694)  loss_rpn_box_reg: 0.0676 (0.0694)  time: 0.6916  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [207]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1264 (0.1385)  loss_objectness: 0.0690 (0.0695)  loss_rpn_box_reg: 0.0643 (0.0689)  time: 0.6856  data: 0.2864  max mem: 5923\n",
      "Training Epoch: [207]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1384 (0.1391)  loss_objectness: 0.0701 (0.0699)  loss_rpn_box_reg: 0.0638 (0.0691)  time: 0.6660  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [207]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1526 (0.1397)  loss_objectness: 0.0719 (0.0700)  loss_rpn_box_reg: 0.0732 (0.0697)  time: 0.6697  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [207]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1382 (0.1396)  loss_objectness: 0.0718 (0.0701)  loss_rpn_box_reg: 0.0730 (0.0695)  time: 0.6812  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [207] Total time: 0:02:51 (0.6840 s / it)\n",
      "Testing Epoch: [207]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1426 (0.1426)  loss_objectness: 0.0508 (0.0508)  loss_rpn_box_reg: 0.0918 (0.0918)  time: 0.6131  data: 0.2871  max mem: 5923\n",
      "Testing Epoch: [207]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1363 (0.1446)  loss_objectness: 0.0575 (0.0627)  loss_rpn_box_reg: 0.0759 (0.0819)  time: 0.6309  data: 0.3131  max mem: 5923\n",
      "Testing Epoch: [207] Total time: 0:00:39 (0.6326 s / it)\n",
      "Training Epoch: [208]  [  0/250]  eta: 0:03:03  lr: 0.000300  loss: 0.1353 (0.1353)  loss_objectness: 0.0701 (0.0701)  loss_rpn_box_reg: 0.0652 (0.0652)  time: 0.7322  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [208]  [ 10/250]  eta: 0:02:49  lr: 0.000300  loss: 0.1353 (0.1368)  loss_objectness: 0.0700 (0.0683)  loss_rpn_box_reg: 0.0652 (0.0685)  time: 0.7063  data: 0.2962  max mem: 5923\n",
      "Training Epoch: [208]  [ 20/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1223 (0.1360)  loss_objectness: 0.0700 (0.0698)  loss_rpn_box_reg: 0.0573 (0.0662)  time: 0.7045  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [208]  [ 30/250]  eta: 0:02:33  lr: 0.000300  loss: 0.1238 (0.1344)  loss_objectness: 0.0667 (0.0685)  loss_rpn_box_reg: 0.0572 (0.0660)  time: 0.6945  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [208]  [ 40/250]  eta: 0:02:26  lr: 0.000300  loss: 0.1238 (0.1367)  loss_objectness: 0.0663 (0.0675)  loss_rpn_box_reg: 0.0674 (0.0691)  time: 0.6869  data: 0.2882  max mem: 5923\n",
      "Training Epoch: [208]  [ 50/250]  eta: 0:02:18  lr: 0.000300  loss: 0.1338 (0.1391)  loss_objectness: 0.0655 (0.0667)  loss_rpn_box_reg: 0.0759 (0.0724)  time: 0.6809  data: 0.2882  max mem: 5923\n",
      "Training Epoch: [208]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1366 (0.1382)  loss_objectness: 0.0662 (0.0681)  loss_rpn_box_reg: 0.0725 (0.0702)  time: 0.6674  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [208]  [ 70/250]  eta: 0:02:03  lr: 0.000300  loss: 0.1341 (0.1369)  loss_objectness: 0.0662 (0.0678)  loss_rpn_box_reg: 0.0625 (0.0692)  time: 0.6727  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [208]  [ 80/250]  eta: 0:01:56  lr: 0.000300  loss: 0.1323 (0.1361)  loss_objectness: 0.0608 (0.0670)  loss_rpn_box_reg: 0.0646 (0.0692)  time: 0.6816  data: 0.2875  max mem: 5923\n",
      "Training Epoch: [208]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1245 (0.1371)  loss_objectness: 0.0579 (0.0666)  loss_rpn_box_reg: 0.0664 (0.0705)  time: 0.6922  data: 0.2887  max mem: 5923\n",
      "Training Epoch: [208]  [100/250]  eta: 0:01:43  lr: 0.000300  loss: 0.1404 (0.1382)  loss_objectness: 0.0690 (0.0680)  loss_rpn_box_reg: 0.0664 (0.0702)  time: 0.7063  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [208]  [110/250]  eta: 0:01:36  lr: 0.000300  loss: 0.1427 (0.1397)  loss_objectness: 0.0798 (0.0692)  loss_rpn_box_reg: 0.0663 (0.0705)  time: 0.7048  data: 0.2958  max mem: 5923\n",
      "Training Epoch: [208]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1356 (0.1384)  loss_objectness: 0.0760 (0.0692)  loss_rpn_box_reg: 0.0631 (0.0693)  time: 0.7003  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [208]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1233 (0.1387)  loss_objectness: 0.0671 (0.0699)  loss_rpn_box_reg: 0.0500 (0.0688)  time: 0.6794  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [208]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1373 (0.1393)  loss_objectness: 0.0765 (0.0702)  loss_rpn_box_reg: 0.0670 (0.0691)  time: 0.6782  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [208]  [150/250]  eta: 0:01:09  lr: 0.000300  loss: 0.1373 (0.1387)  loss_objectness: 0.0647 (0.0696)  loss_rpn_box_reg: 0.0670 (0.0691)  time: 0.7039  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [208]  [160/250]  eta: 0:01:02  lr: 0.000300  loss: 0.1261 (0.1386)  loss_objectness: 0.0650 (0.0695)  loss_rpn_box_reg: 0.0653 (0.0691)  time: 0.6937  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [208]  [170/250]  eta: 0:00:55  lr: 0.000300  loss: 0.1394 (0.1391)  loss_objectness: 0.0706 (0.0696)  loss_rpn_box_reg: 0.0702 (0.0694)  time: 0.6870  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [208]  [180/250]  eta: 0:00:48  lr: 0.000300  loss: 0.1442 (0.1386)  loss_objectness: 0.0678 (0.0695)  loss_rpn_box_reg: 0.0619 (0.0691)  time: 0.6937  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [208]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1351 (0.1391)  loss_objectness: 0.0640 (0.0698)  loss_rpn_box_reg: 0.0619 (0.0693)  time: 0.6841  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [208]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1411 (0.1389)  loss_objectness: 0.0722 (0.0701)  loss_rpn_box_reg: 0.0633 (0.0687)  time: 0.6822  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [208]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1410 (0.1388)  loss_objectness: 0.0697 (0.0702)  loss_rpn_box_reg: 0.0595 (0.0686)  time: 0.6789  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [208]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1421 (0.1393)  loss_objectness: 0.0739 (0.0705)  loss_rpn_box_reg: 0.0666 (0.0687)  time: 0.6828  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [208]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1452 (0.1395)  loss_objectness: 0.0755 (0.0705)  loss_rpn_box_reg: 0.0751 (0.0690)  time: 0.6716  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [208]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1379 (0.1396)  loss_objectness: 0.0701 (0.0705)  loss_rpn_box_reg: 0.0704 (0.0692)  time: 0.6593  data: 0.2931  max mem: 5923\n",
      "Training Epoch: [208]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1379 (0.1401)  loss_objectness: 0.0699 (0.0705)  loss_rpn_box_reg: 0.0662 (0.0696)  time: 0.6784  data: 0.2946  max mem: 5923\n",
      "Training Epoch: [208] Total time: 0:02:51 (0.6868 s / it)\n",
      "Testing Epoch: [208]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1410 (0.1410)  loss_objectness: 0.0492 (0.0492)  loss_rpn_box_reg: 0.0918 (0.0918)  time: 0.6151  data: 0.2901  max mem: 5923\n",
      "Testing Epoch: [208]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1251 (0.1401)  loss_objectness: 0.0521 (0.0591)  loss_rpn_box_reg: 0.0736 (0.0810)  time: 0.6263  data: 0.3068  max mem: 5923\n",
      "Testing Epoch: [208] Total time: 0:00:39 (0.6322 s / it)\n",
      "Training Epoch: [209]  [  0/250]  eta: 0:02:59  lr: 0.000300  loss: 0.1321 (0.1321)  loss_objectness: 0.0728 (0.0728)  loss_rpn_box_reg: 0.0594 (0.0594)  time: 0.7162  data: 0.2861  max mem: 5923\n",
      "Training Epoch: [209]  [ 10/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1318 (0.1346)  loss_objectness: 0.0629 (0.0651)  loss_rpn_box_reg: 0.0671 (0.0694)  time: 0.6775  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [209]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1318 (0.1383)  loss_objectness: 0.0629 (0.0657)  loss_rpn_box_reg: 0.0713 (0.0725)  time: 0.6801  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [209]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1227 (0.1322)  loss_objectness: 0.0584 (0.0639)  loss_rpn_box_reg: 0.0564 (0.0682)  time: 0.6860  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [209]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1198 (0.1311)  loss_objectness: 0.0575 (0.0637)  loss_rpn_box_reg: 0.0564 (0.0674)  time: 0.6848  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [209]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1434 (0.1344)  loss_objectness: 0.0640 (0.0642)  loss_rpn_box_reg: 0.0697 (0.0702)  time: 0.6746  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [209]  [ 60/250]  eta: 0:02:08  lr: 0.000300  loss: 0.1361 (0.1334)  loss_objectness: 0.0637 (0.0649)  loss_rpn_box_reg: 0.0721 (0.0685)  time: 0.6689  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [209]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1336 (0.1332)  loss_objectness: 0.0600 (0.0649)  loss_rpn_box_reg: 0.0577 (0.0683)  time: 0.6754  data: 0.2889  max mem: 5923\n",
      "Training Epoch: [209]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1339 (0.1334)  loss_objectness: 0.0610 (0.0653)  loss_rpn_box_reg: 0.0590 (0.0681)  time: 0.6855  data: 0.2867  max mem: 5923\n",
      "Training Epoch: [209]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1339 (0.1337)  loss_objectness: 0.0732 (0.0665)  loss_rpn_box_reg: 0.0607 (0.0672)  time: 0.6835  data: 0.2925  max mem: 5923\n",
      "Training Epoch: [209]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1403 (0.1340)  loss_objectness: 0.0729 (0.0669)  loss_rpn_box_reg: 0.0673 (0.0671)  time: 0.6847  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [209]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1321 (0.1337)  loss_objectness: 0.0671 (0.0665)  loss_rpn_box_reg: 0.0646 (0.0673)  time: 0.6923  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [209]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1279 (0.1336)  loss_objectness: 0.0641 (0.0668)  loss_rpn_box_reg: 0.0588 (0.0668)  time: 0.6856  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [209]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1278 (0.1328)  loss_objectness: 0.0662 (0.0671)  loss_rpn_box_reg: 0.0556 (0.0656)  time: 0.6850  data: 0.2882  max mem: 5923\n",
      "Training Epoch: [209]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1361 (0.1330)  loss_objectness: 0.0688 (0.0673)  loss_rpn_box_reg: 0.0609 (0.0657)  time: 0.6937  data: 0.2901  max mem: 5923\n",
      "Training Epoch: [209]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1448 (0.1348)  loss_objectness: 0.0701 (0.0677)  loss_rpn_box_reg: 0.0670 (0.0671)  time: 0.6743  data: 0.2968  max mem: 5923\n",
      "Training Epoch: [209]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1499 (0.1354)  loss_objectness: 0.0712 (0.0683)  loss_rpn_box_reg: 0.0679 (0.0672)  time: 0.6759  data: 0.2982  max mem: 5923\n",
      "Training Epoch: [209]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1402 (0.1360)  loss_objectness: 0.0626 (0.0680)  loss_rpn_box_reg: 0.0679 (0.0680)  time: 0.6900  data: 0.2959  max mem: 5923\n",
      "Training Epoch: [209]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1379 (0.1359)  loss_objectness: 0.0626 (0.0681)  loss_rpn_box_reg: 0.0707 (0.0678)  time: 0.6858  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [209]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1410 (0.1367)  loss_objectness: 0.0779 (0.0686)  loss_rpn_box_reg: 0.0598 (0.0681)  time: 0.6968  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [209]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1434 (0.1376)  loss_objectness: 0.0789 (0.0693)  loss_rpn_box_reg: 0.0592 (0.0683)  time: 0.6859  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [209]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1372 (0.1375)  loss_objectness: 0.0674 (0.0690)  loss_rpn_box_reg: 0.0804 (0.0685)  time: 0.6866  data: 0.2884  max mem: 5923\n",
      "Training Epoch: [209]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1338 (0.1381)  loss_objectness: 0.0663 (0.0692)  loss_rpn_box_reg: 0.0755 (0.0690)  time: 0.6919  data: 0.2869  max mem: 5923\n",
      "Training Epoch: [209]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1471 (0.1385)  loss_objectness: 0.0680 (0.0693)  loss_rpn_box_reg: 0.0720 (0.0692)  time: 0.6836  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [209]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1488 (0.1396)  loss_objectness: 0.0688 (0.0698)  loss_rpn_box_reg: 0.0706 (0.0698)  time: 0.6957  data: 0.2993  max mem: 5923\n",
      "Training Epoch: [209]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1497 (0.1396)  loss_objectness: 0.0714 (0.0702)  loss_rpn_box_reg: 0.0679 (0.0695)  time: 0.7016  data: 0.2965  max mem: 5923\n",
      "Training Epoch: [209] Total time: 0:02:51 (0.6856 s / it)\n",
      "Testing Epoch: [209]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1379 (0.1379)  loss_objectness: 0.0490 (0.0490)  loss_rpn_box_reg: 0.0890 (0.0890)  time: 0.6191  data: 0.2921  max mem: 5923\n",
      "Testing Epoch: [209]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1302 (0.1444)  loss_objectness: 0.0550 (0.0613)  loss_rpn_box_reg: 0.0774 (0.0831)  time: 0.6314  data: 0.3103  max mem: 5923\n",
      "Testing Epoch: [209] Total time: 0:00:39 (0.6319 s / it)\n",
      "Training Epoch: [210]  [  0/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1534 (0.1534)  loss_objectness: 0.0703 (0.0703)  loss_rpn_box_reg: 0.0831 (0.0831)  time: 0.6872  data: 0.3061  max mem: 5923\n",
      "Training Epoch: [210]  [ 10/250]  eta: 0:02:43  lr: 0.000300  loss: 0.1303 (0.1338)  loss_objectness: 0.0621 (0.0661)  loss_rpn_box_reg: 0.0595 (0.0677)  time: 0.6827  data: 0.2889  max mem: 5923\n",
      "Training Epoch: [210]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1287 (0.1316)  loss_objectness: 0.0641 (0.0673)  loss_rpn_box_reg: 0.0567 (0.0644)  time: 0.6779  data: 0.2852  max mem: 5923\n",
      "Training Epoch: [210]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1423 (0.1390)  loss_objectness: 0.0707 (0.0694)  loss_rpn_box_reg: 0.0668 (0.0696)  time: 0.6869  data: 0.2890  max mem: 5923\n",
      "Training Epoch: [210]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1395 (0.1385)  loss_objectness: 0.0732 (0.0708)  loss_rpn_box_reg: 0.0637 (0.0677)  time: 0.6870  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [210]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1369 (0.1414)  loss_objectness: 0.0732 (0.0726)  loss_rpn_box_reg: 0.0581 (0.0688)  time: 0.6782  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [210]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1404 (0.1421)  loss_objectness: 0.0749 (0.0738)  loss_rpn_box_reg: 0.0591 (0.0683)  time: 0.6811  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [210]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1404 (0.1411)  loss_objectness: 0.0711 (0.0727)  loss_rpn_box_reg: 0.0696 (0.0685)  time: 0.6705  data: 0.2872  max mem: 5923\n",
      "Training Epoch: [210]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1331 (0.1414)  loss_objectness: 0.0667 (0.0720)  loss_rpn_box_reg: 0.0755 (0.0694)  time: 0.6749  data: 0.2880  max mem: 5923\n",
      "Training Epoch: [210]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1331 (0.1415)  loss_objectness: 0.0690 (0.0720)  loss_rpn_box_reg: 0.0701 (0.0695)  time: 0.6790  data: 0.2892  max mem: 5923\n",
      "Training Epoch: [210]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1311 (0.1407)  loss_objectness: 0.0624 (0.0712)  loss_rpn_box_reg: 0.0695 (0.0695)  time: 0.6660  data: 0.2872  max mem: 5923\n",
      "Training Epoch: [210]  [110/250]  eta: 0:01:34  lr: 0.000300  loss: 0.1311 (0.1406)  loss_objectness: 0.0615 (0.0708)  loss_rpn_box_reg: 0.0572 (0.0698)  time: 0.6698  data: 0.2867  max mem: 5923\n",
      "Training Epoch: [210]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1440 (0.1419)  loss_objectness: 0.0695 (0.0712)  loss_rpn_box_reg: 0.0667 (0.0707)  time: 0.6843  data: 0.2929  max mem: 5923\n",
      "Training Epoch: [210]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1440 (0.1416)  loss_objectness: 0.0730 (0.0713)  loss_rpn_box_reg: 0.0667 (0.0702)  time: 0.6821  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [210]  [140/250]  eta: 0:01:14  lr: 0.000300  loss: 0.1324 (0.1409)  loss_objectness: 0.0738 (0.0714)  loss_rpn_box_reg: 0.0550 (0.0695)  time: 0.6750  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [210]  [150/250]  eta: 0:01:07  lr: 0.000300  loss: 0.1389 (0.1411)  loss_objectness: 0.0740 (0.0720)  loss_rpn_box_reg: 0.0626 (0.0691)  time: 0.6862  data: 0.2939  max mem: 5923\n",
      "Training Epoch: [210]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1414 (0.1413)  loss_objectness: 0.0714 (0.0719)  loss_rpn_box_reg: 0.0653 (0.0694)  time: 0.6858  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [210]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1433 (0.1423)  loss_objectness: 0.0688 (0.0721)  loss_rpn_box_reg: 0.0679 (0.0702)  time: 0.6735  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [210]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1466 (0.1422)  loss_objectness: 0.0657 (0.0720)  loss_rpn_box_reg: 0.0692 (0.0702)  time: 0.6799  data: 0.2940  max mem: 5923\n",
      "Training Epoch: [210]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1355 (0.1423)  loss_objectness: 0.0584 (0.0719)  loss_rpn_box_reg: 0.0692 (0.0704)  time: 0.6808  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [210]  [200/250]  eta: 0:00:33  lr: 0.000300  loss: 0.1403 (0.1427)  loss_objectness: 0.0657 (0.0720)  loss_rpn_box_reg: 0.0689 (0.0707)  time: 0.6762  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [210]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1306 (0.1424)  loss_objectness: 0.0711 (0.0717)  loss_rpn_box_reg: 0.0666 (0.0708)  time: 0.6867  data: 0.2867  max mem: 5923\n",
      "Training Epoch: [210]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1306 (0.1421)  loss_objectness: 0.0623 (0.0715)  loss_rpn_box_reg: 0.0613 (0.0706)  time: 0.6820  data: 0.2851  max mem: 5923\n",
      "Training Epoch: [210]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1324 (0.1414)  loss_objectness: 0.0634 (0.0715)  loss_rpn_box_reg: 0.0543 (0.0699)  time: 0.6871  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [210]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1324 (0.1415)  loss_objectness: 0.0654 (0.0717)  loss_rpn_box_reg: 0.0642 (0.0699)  time: 0.6822  data: 0.2927  max mem: 5923\n",
      "Training Epoch: [210]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1437 (0.1415)  loss_objectness: 0.0746 (0.0718)  loss_rpn_box_reg: 0.0706 (0.0697)  time: 0.6731  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [210] Total time: 0:02:49 (0.6798 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/62]  eta: 0:01:07  model_time: 0.6281 (0.6281)  evaluator_time: 0.0590 (0.0590)  time: 1.0952  data: 0.3931  max mem: 5923\n",
      "Test:  [61/62]  eta: 0:00:00  model_time: 0.4061 (0.4009)  evaluator_time: 0.0750 (0.0804)  time: 0.7961  data: 0.3095  max mem: 5923\n",
      "Test: Total time: 0:00:49 (0.7969 s / it)\n",
      "Averaged stats: model_time: 0.4061 (0.4009)  evaluator_time: 0.0750 (0.0804)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.14s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.054\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "Testing Epoch: [210]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1344 (0.1344)  loss_objectness: 0.0448 (0.0448)  loss_rpn_box_reg: 0.0896 (0.0896)  time: 0.6251  data: 0.2841  max mem: 5923\n",
      "Testing Epoch: [210]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1310 (0.1416)  loss_objectness: 0.0558 (0.0608)  loss_rpn_box_reg: 0.0763 (0.0809)  time: 0.6309  data: 0.3102  max mem: 5923\n",
      "Testing Epoch: [210] Total time: 0:00:39 (0.6324 s / it)\n",
      "Training Epoch: [211]  [  0/250]  eta: 0:02:50  lr: 0.000300  loss: 0.1385 (0.1385)  loss_objectness: 0.0843 (0.0843)  loss_rpn_box_reg: 0.0542 (0.0542)  time: 0.6822  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [211]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1340 (0.1388)  loss_objectness: 0.0582 (0.0661)  loss_rpn_box_reg: 0.0661 (0.0727)  time: 0.6873  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [211]  [ 20/250]  eta: 0:02:36  lr: 0.000300  loss: 0.1309 (0.1381)  loss_objectness: 0.0587 (0.0654)  loss_rpn_box_reg: 0.0661 (0.0727)  time: 0.6823  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [211]  [ 30/250]  eta: 0:02:30  lr: 0.000300  loss: 0.1332 (0.1399)  loss_objectness: 0.0621 (0.0692)  loss_rpn_box_reg: 0.0622 (0.0707)  time: 0.6839  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [211]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1345 (0.1393)  loss_objectness: 0.0713 (0.0694)  loss_rpn_box_reg: 0.0692 (0.0700)  time: 0.6875  data: 0.2964  max mem: 5923\n",
      "Training Epoch: [211]  [ 50/250]  eta: 0:02:16  lr: 0.000300  loss: 0.1319 (0.1380)  loss_objectness: 0.0713 (0.0693)  loss_rpn_box_reg: 0.0696 (0.0687)  time: 0.6801  data: 0.2943  max mem: 5923\n",
      "Training Epoch: [211]  [ 60/250]  eta: 0:02:09  lr: 0.000300  loss: 0.1241 (0.1355)  loss_objectness: 0.0616 (0.0687)  loss_rpn_box_reg: 0.0585 (0.0668)  time: 0.6769  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [211]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1247 (0.1355)  loss_objectness: 0.0573 (0.0679)  loss_rpn_box_reg: 0.0607 (0.0676)  time: 0.6835  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [211]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1374 (0.1362)  loss_objectness: 0.0650 (0.0683)  loss_rpn_box_reg: 0.0667 (0.0679)  time: 0.6819  data: 0.2893  max mem: 5923\n",
      "Training Epoch: [211]  [ 90/250]  eta: 0:01:49  lr: 0.000300  loss: 0.1356 (0.1366)  loss_objectness: 0.0695 (0.0690)  loss_rpn_box_reg: 0.0590 (0.0676)  time: 0.6943  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [211]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1416 (0.1381)  loss_objectness: 0.0677 (0.0688)  loss_rpn_box_reg: 0.0733 (0.0693)  time: 0.6965  data: 0.2936  max mem: 5923\n",
      "Training Epoch: [211]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1458 (0.1380)  loss_objectness: 0.0662 (0.0692)  loss_rpn_box_reg: 0.0689 (0.0688)  time: 0.6823  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [211]  [120/250]  eta: 0:01:29  lr: 0.000300  loss: 0.1317 (0.1377)  loss_objectness: 0.0670 (0.0690)  loss_rpn_box_reg: 0.0654 (0.0687)  time: 0.6926  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [211]  [130/250]  eta: 0:01:22  lr: 0.000300  loss: 0.1256 (0.1377)  loss_objectness: 0.0670 (0.0693)  loss_rpn_box_reg: 0.0634 (0.0684)  time: 0.6931  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [211]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1321 (0.1375)  loss_objectness: 0.0680 (0.0695)  loss_rpn_box_reg: 0.0583 (0.0680)  time: 0.6898  data: 0.2913  max mem: 5923\n",
      "Training Epoch: [211]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1341 (0.1380)  loss_objectness: 0.0715 (0.0697)  loss_rpn_box_reg: 0.0624 (0.0683)  time: 0.6735  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [211]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1333 (0.1377)  loss_objectness: 0.0715 (0.0699)  loss_rpn_box_reg: 0.0624 (0.0678)  time: 0.6755  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [211]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1333 (0.1377)  loss_objectness: 0.0715 (0.0700)  loss_rpn_box_reg: 0.0627 (0.0677)  time: 0.6841  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [211]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1425 (0.1379)  loss_objectness: 0.0724 (0.0699)  loss_rpn_box_reg: 0.0632 (0.0680)  time: 0.6718  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [211]  [190/250]  eta: 0:00:41  lr: 0.000300  loss: 0.1464 (0.1387)  loss_objectness: 0.0682 (0.0701)  loss_rpn_box_reg: 0.0744 (0.0686)  time: 0.6787  data: 0.2906  max mem: 5923\n",
      "Training Epoch: [211]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1464 (0.1391)  loss_objectness: 0.0646 (0.0702)  loss_rpn_box_reg: 0.0725 (0.0689)  time: 0.6971  data: 0.2934  max mem: 5923\n",
      "Training Epoch: [211]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1391 (0.1391)  loss_objectness: 0.0722 (0.0705)  loss_rpn_box_reg: 0.0651 (0.0686)  time: 0.6984  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [211]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1243 (0.1385)  loss_objectness: 0.0704 (0.0702)  loss_rpn_box_reg: 0.0619 (0.0683)  time: 0.6800  data: 0.2884  max mem: 5923\n",
      "Training Epoch: [211]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1251 (0.1385)  loss_objectness: 0.0652 (0.0701)  loss_rpn_box_reg: 0.0624 (0.0684)  time: 0.6667  data: 0.2846  max mem: 5923\n",
      "Training Epoch: [211]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1322 (0.1387)  loss_objectness: 0.0652 (0.0700)  loss_rpn_box_reg: 0.0683 (0.0687)  time: 0.6705  data: 0.2864  max mem: 5923\n",
      "Training Epoch: [211]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1342 (0.1389)  loss_objectness: 0.0661 (0.0701)  loss_rpn_box_reg: 0.0684 (0.0688)  time: 0.6731  data: 0.2876  max mem: 5923\n",
      "Training Epoch: [211] Total time: 0:02:50 (0.6828 s / it)\n",
      "Testing Epoch: [211]  [ 0/62]  eta: 0:00:38  lr: 0.000300  loss: 0.1413 (0.1413)  loss_objectness: 0.0499 (0.0499)  loss_rpn_box_reg: 0.0914 (0.0914)  time: 0.6191  data: 0.2911  max mem: 5923\n",
      "Testing Epoch: [211]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1310 (0.1415)  loss_objectness: 0.0592 (0.0605)  loss_rpn_box_reg: 0.0747 (0.0811)  time: 0.6259  data: 0.3041  max mem: 5923\n",
      "Testing Epoch: [211] Total time: 0:00:39 (0.6297 s / it)\n",
      "Training Epoch: [212]  [  0/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1006 (0.1006)  loss_objectness: 0.0602 (0.0602)  loss_rpn_box_reg: 0.0405 (0.0405)  time: 0.6842  data: 0.2861  max mem: 5923\n",
      "Training Epoch: [212]  [ 10/250]  eta: 0:02:42  lr: 0.000300  loss: 0.1341 (0.1401)  loss_objectness: 0.0700 (0.0714)  loss_rpn_box_reg: 0.0634 (0.0687)  time: 0.6769  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [212]  [ 20/250]  eta: 0:02:35  lr: 0.000300  loss: 0.1353 (0.1430)  loss_objectness: 0.0700 (0.0717)  loss_rpn_box_reg: 0.0647 (0.0713)  time: 0.6765  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [212]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1298 (0.1391)  loss_objectness: 0.0670 (0.0690)  loss_rpn_box_reg: 0.0624 (0.0701)  time: 0.6833  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [212]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1292 (0.1379)  loss_objectness: 0.0670 (0.0688)  loss_rpn_box_reg: 0.0568 (0.0692)  time: 0.6785  data: 0.2895  max mem: 5923\n",
      "Training Epoch: [212]  [ 50/250]  eta: 0:02:15  lr: 0.000300  loss: 0.1391 (0.1379)  loss_objectness: 0.0681 (0.0693)  loss_rpn_box_reg: 0.0647 (0.0686)  time: 0.6703  data: 0.2921  max mem: 5923\n",
      "Training Epoch: [212]  [ 60/250]  eta: 0:02:08  lr: 0.000300  loss: 0.1391 (0.1402)  loss_objectness: 0.0662 (0.0697)  loss_rpn_box_reg: 0.0703 (0.0705)  time: 0.6804  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [212]  [ 70/250]  eta: 0:02:02  lr: 0.000300  loss: 0.1471 (0.1404)  loss_objectness: 0.0725 (0.0706)  loss_rpn_box_reg: 0.0722 (0.0699)  time: 0.6803  data: 0.2924  max mem: 5923\n",
      "Training Epoch: [212]  [ 80/250]  eta: 0:01:55  lr: 0.000300  loss: 0.1326 (0.1387)  loss_objectness: 0.0638 (0.0695)  loss_rpn_box_reg: 0.0649 (0.0692)  time: 0.6755  data: 0.2933  max mem: 5923\n",
      "Training Epoch: [212]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1207 (0.1388)  loss_objectness: 0.0615 (0.0695)  loss_rpn_box_reg: 0.0637 (0.0693)  time: 0.6916  data: 0.2922  max mem: 5923\n",
      "Training Epoch: [212]  [100/250]  eta: 0:01:42  lr: 0.000300  loss: 0.1321 (0.1380)  loss_objectness: 0.0602 (0.0690)  loss_rpn_box_reg: 0.0637 (0.0690)  time: 0.6963  data: 0.2897  max mem: 5923\n",
      "Training Epoch: [212]  [110/250]  eta: 0:01:35  lr: 0.000300  loss: 0.1351 (0.1378)  loss_objectness: 0.0602 (0.0685)  loss_rpn_box_reg: 0.0619 (0.0693)  time: 0.6784  data: 0.2917  max mem: 5923\n",
      "Training Epoch: [212]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1376 (0.1379)  loss_objectness: 0.0553 (0.0682)  loss_rpn_box_reg: 0.0761 (0.0697)  time: 0.6832  data: 0.2910  max mem: 5923\n",
      "Training Epoch: [212]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1398 (0.1384)  loss_objectness: 0.0613 (0.0686)  loss_rpn_box_reg: 0.0772 (0.0698)  time: 0.6888  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [212]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1398 (0.1389)  loss_objectness: 0.0762 (0.0689)  loss_rpn_box_reg: 0.0770 (0.0700)  time: 0.6838  data: 0.2932  max mem: 5923\n",
      "Training Epoch: [212]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1407 (0.1389)  loss_objectness: 0.0718 (0.0687)  loss_rpn_box_reg: 0.0756 (0.0702)  time: 0.6862  data: 0.2908  max mem: 5923\n",
      "Training Epoch: [212]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1368 (0.1389)  loss_objectness: 0.0631 (0.0685)  loss_rpn_box_reg: 0.0756 (0.0704)  time: 0.6805  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [212]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1368 (0.1394)  loss_objectness: 0.0631 (0.0688)  loss_rpn_box_reg: 0.0718 (0.0706)  time: 0.6789  data: 0.2911  max mem: 5923\n",
      "Training Epoch: [212]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1368 (0.1395)  loss_objectness: 0.0730 (0.0688)  loss_rpn_box_reg: 0.0699 (0.0707)  time: 0.6807  data: 0.2900  max mem: 5923\n",
      "Training Epoch: [212]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1354 (0.1396)  loss_objectness: 0.0707 (0.0690)  loss_rpn_box_reg: 0.0690 (0.0706)  time: 0.6931  data: 0.2915  max mem: 5923\n",
      "Training Epoch: [212]  [200/250]  eta: 0:00:34  lr: 0.000300  loss: 0.1331 (0.1396)  loss_objectness: 0.0716 (0.0694)  loss_rpn_box_reg: 0.0614 (0.0702)  time: 0.7005  data: 0.2903  max mem: 5923\n",
      "Training Epoch: [212]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1331 (0.1395)  loss_objectness: 0.0743 (0.0698)  loss_rpn_box_reg: 0.0614 (0.0697)  time: 0.6828  data: 0.2867  max mem: 5923\n",
      "Training Epoch: [212]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1361 (0.1393)  loss_objectness: 0.0745 (0.0698)  loss_rpn_box_reg: 0.0637 (0.0695)  time: 0.6787  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [212]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1357 (0.1395)  loss_objectness: 0.0715 (0.0701)  loss_rpn_box_reg: 0.0663 (0.0694)  time: 0.6913  data: 0.2947  max mem: 5923\n",
      "Training Epoch: [212]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1317 (0.1391)  loss_objectness: 0.0711 (0.0701)  loss_rpn_box_reg: 0.0610 (0.0690)  time: 0.6815  data: 0.2892  max mem: 5923\n",
      "Training Epoch: [212]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1386 (0.1396)  loss_objectness: 0.0714 (0.0704)  loss_rpn_box_reg: 0.0580 (0.0693)  time: 0.6730  data: 0.2896  max mem: 5923\n",
      "Training Epoch: [212] Total time: 0:02:50 (0.6829 s / it)\n",
      "Testing Epoch: [212]  [ 0/62]  eta: 0:00:44  lr: 0.000300  loss: 0.1358 (0.1358)  loss_objectness: 0.0458 (0.0458)  loss_rpn_box_reg: 0.0900 (0.0900)  time: 0.7202  data: 0.3911  max mem: 5923\n",
      "Testing Epoch: [212]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1327 (0.1414)  loss_objectness: 0.0569 (0.0598)  loss_rpn_box_reg: 0.0780 (0.0816)  time: 0.6286  data: 0.3081  max mem: 5923\n",
      "Testing Epoch: [212] Total time: 0:00:39 (0.6311 s / it)\n",
      "Training Epoch: [213]  [  0/250]  eta: 0:02:57  lr: 0.000300  loss: 0.1264 (0.1264)  loss_objectness: 0.0689 (0.0689)  loss_rpn_box_reg: 0.0575 (0.0575)  time: 0.7112  data: 0.2961  max mem: 5923\n",
      "Training Epoch: [213]  [ 10/250]  eta: 0:02:39  lr: 0.000300  loss: 0.1264 (0.1288)  loss_objectness: 0.0695 (0.0658)  loss_rpn_box_reg: 0.0575 (0.0630)  time: 0.6640  data: 0.2862  max mem: 5923\n",
      "Training Epoch: [213]  [ 20/250]  eta: 0:02:37  lr: 0.000300  loss: 0.1342 (0.1376)  loss_objectness: 0.0661 (0.0664)  loss_rpn_box_reg: 0.0679 (0.0712)  time: 0.6837  data: 0.2902  max mem: 5923\n",
      "Training Epoch: [213]  [ 30/250]  eta: 0:02:29  lr: 0.000300  loss: 0.1342 (0.1338)  loss_objectness: 0.0661 (0.0670)  loss_rpn_box_reg: 0.0647 (0.0669)  time: 0.6855  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [213]  [ 40/250]  eta: 0:02:22  lr: 0.000300  loss: 0.1365 (0.1353)  loss_objectness: 0.0698 (0.0691)  loss_rpn_box_reg: 0.0580 (0.0662)  time: 0.6676  data: 0.2899  max mem: 5923\n",
      "Training Epoch: [213]  [ 50/250]  eta: 0:02:14  lr: 0.000300  loss: 0.1383 (0.1364)  loss_objectness: 0.0729 (0.0701)  loss_rpn_box_reg: 0.0621 (0.0663)  time: 0.6696  data: 0.2920  max mem: 5923\n",
      "Training Epoch: [213]  [ 60/250]  eta: 0:02:08  lr: 0.000300  loss: 0.1356 (0.1368)  loss_objectness: 0.0735 (0.0705)  loss_rpn_box_reg: 0.0614 (0.0663)  time: 0.6717  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [213]  [ 70/250]  eta: 0:02:01  lr: 0.000300  loss: 0.1366 (0.1403)  loss_objectness: 0.0827 (0.0725)  loss_rpn_box_reg: 0.0614 (0.0679)  time: 0.6747  data: 0.2960  max mem: 5923\n",
      "Training Epoch: [213]  [ 80/250]  eta: 0:01:54  lr: 0.000300  loss: 0.1326 (0.1383)  loss_objectness: 0.0720 (0.0714)  loss_rpn_box_reg: 0.0552 (0.0669)  time: 0.6710  data: 0.2976  max mem: 5923\n",
      "Training Epoch: [213]  [ 90/250]  eta: 0:01:48  lr: 0.000300  loss: 0.1276 (0.1370)  loss_objectness: 0.0630 (0.0705)  loss_rpn_box_reg: 0.0540 (0.0665)  time: 0.6782  data: 0.2916  max mem: 5923\n",
      "Training Epoch: [213]  [100/250]  eta: 0:01:41  lr: 0.000300  loss: 0.1363 (0.1376)  loss_objectness: 0.0630 (0.0705)  loss_rpn_box_reg: 0.0641 (0.0671)  time: 0.6889  data: 0.2891  max mem: 5923\n",
      "Training Epoch: [213]  [110/250]  eta: 0:01:34  lr: 0.000300  loss: 0.1344 (0.1376)  loss_objectness: 0.0632 (0.0701)  loss_rpn_box_reg: 0.0646 (0.0675)  time: 0.6821  data: 0.2904  max mem: 5923\n",
      "Training Epoch: [213]  [120/250]  eta: 0:01:28  lr: 0.000300  loss: 0.1324 (0.1373)  loss_objectness: 0.0632 (0.0700)  loss_rpn_box_reg: 0.0626 (0.0672)  time: 0.7011  data: 0.2935  max mem: 5923\n",
      "Training Epoch: [213]  [130/250]  eta: 0:01:21  lr: 0.000300  loss: 0.1227 (0.1364)  loss_objectness: 0.0670 (0.0697)  loss_rpn_box_reg: 0.0622 (0.0666)  time: 0.7031  data: 0.2926  max mem: 5923\n",
      "Training Epoch: [213]  [140/250]  eta: 0:01:15  lr: 0.000300  loss: 0.1243 (0.1365)  loss_objectness: 0.0601 (0.0689)  loss_rpn_box_reg: 0.0668 (0.0676)  time: 0.6878  data: 0.2907  max mem: 5923\n",
      "Training Epoch: [213]  [150/250]  eta: 0:01:08  lr: 0.000300  loss: 0.1357 (0.1367)  loss_objectness: 0.0614 (0.0692)  loss_rpn_box_reg: 0.0740 (0.0675)  time: 0.6782  data: 0.2923  max mem: 5923\n",
      "Training Epoch: [213]  [160/250]  eta: 0:01:01  lr: 0.000300  loss: 0.1410 (0.1368)  loss_objectness: 0.0691 (0.0692)  loss_rpn_box_reg: 0.0725 (0.0676)  time: 0.6703  data: 0.2941  max mem: 5923\n",
      "Training Epoch: [213]  [170/250]  eta: 0:00:54  lr: 0.000300  loss: 0.1469 (0.1383)  loss_objectness: 0.0676 (0.0694)  loss_rpn_box_reg: 0.0797 (0.0689)  time: 0.6739  data: 0.2918  max mem: 5923\n",
      "Training Epoch: [213]  [180/250]  eta: 0:00:47  lr: 0.000300  loss: 0.1422 (0.1382)  loss_objectness: 0.0675 (0.0693)  loss_rpn_box_reg: 0.0791 (0.0688)  time: 0.6710  data: 0.2883  max mem: 5923\n",
      "Training Epoch: [213]  [190/250]  eta: 0:00:40  lr: 0.000300  loss: 0.1320 (0.1376)  loss_objectness: 0.0644 (0.0690)  loss_rpn_box_reg: 0.0666 (0.0686)  time: 0.6725  data: 0.2875  max mem: 5923\n",
      "Training Epoch: [213]  [200/250]  eta: 0:00:33  lr: 0.000300  loss: 0.1320 (0.1373)  loss_objectness: 0.0579 (0.0685)  loss_rpn_box_reg: 0.0618 (0.0688)  time: 0.6732  data: 0.2861  max mem: 5923\n",
      "Training Epoch: [213]  [210/250]  eta: 0:00:27  lr: 0.000300  loss: 0.1518 (0.1380)  loss_objectness: 0.0652 (0.0689)  loss_rpn_box_reg: 0.0662 (0.0691)  time: 0.6856  data: 0.2909  max mem: 5923\n",
      "Training Epoch: [213]  [220/250]  eta: 0:00:20  lr: 0.000300  loss: 0.1463 (0.1379)  loss_objectness: 0.0711 (0.0690)  loss_rpn_box_reg: 0.0662 (0.0689)  time: 0.7046  data: 0.2995  max mem: 5923\n",
      "Training Epoch: [213]  [230/250]  eta: 0:00:13  lr: 0.000300  loss: 0.1354 (0.1381)  loss_objectness: 0.0705 (0.0693)  loss_rpn_box_reg: 0.0600 (0.0688)  time: 0.7018  data: 0.2984  max mem: 5923\n",
      "Training Epoch: [213]  [240/250]  eta: 0:00:06  lr: 0.000300  loss: 0.1325 (0.1379)  loss_objectness: 0.0631 (0.0689)  loss_rpn_box_reg: 0.0686 (0.0689)  time: 0.6888  data: 0.2937  max mem: 5923\n",
      "Training Epoch: [213]  [249/250]  eta: 0:00:00  lr: 0.000300  loss: 0.1281 (0.1382)  loss_objectness: 0.0614 (0.0690)  loss_rpn_box_reg: 0.0667 (0.0692)  time: 0.6953  data: 0.2919  max mem: 5923\n",
      "Training Epoch: [213] Total time: 0:02:50 (0.6825 s / it)\n",
      "Testing Epoch: [213]  [ 0/62]  eta: 0:00:37  lr: 0.000300  loss: 0.1335 (0.1335)  loss_objectness: 0.0474 (0.0474)  loss_rpn_box_reg: 0.0861 (0.0861)  time: 0.6111  data: 0.2891  max mem: 5923\n",
      "Testing Epoch: [213]  [61/62]  eta: 0:00:00  lr: 0.000300  loss: 0.1293 (0.1385)  loss_objectness: 0.0541 (0.0587)  loss_rpn_box_reg: 0.0735 (0.0799)  time: 0.6309  data: 0.3123  max mem: 5923\n",
      "Testing Epoch: [213] Total time: 0:00:39 (0.6334 s / it)\n",
      "Training Epoch: [214]  [  0/250]  eta: 0:02:51  lr: 0.000300  loss: 0.1414 (0.1414)  loss_objectness: 0.0592 (0.0592)  loss_rpn_box_reg: 0.0822 (0.0822)  time: 0.6872  data: 0.2751  max mem: 5923\n",
      "Training Epoch: [214]  [ 10/250]  eta: 0:02:44  lr: 0.000300  loss: 0.1469 (0.1575)  loss_objectness: 0.0772 (0.0757)  loss_rpn_box_reg: 0.0726 (0.0818)  time: 0.6862  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [214]  [ 20/250]  eta: 0:02:40  lr: 0.000300  loss: 0.1350 (0.1433)  loss_objectness: 0.0624 (0.0673)  loss_rpn_box_reg: 0.0676 (0.0760)  time: 0.6983  data: 0.2914  max mem: 5923\n",
      "Training Epoch: [214]  [ 30/250]  eta: 0:02:32  lr: 0.000300  loss: 0.1237 (0.1358)  loss_objectness: 0.0586 (0.0642)  loss_rpn_box_reg: 0.0663 (0.0716)  time: 0.6938  data: 0.2875  max mem: 5923\n",
      "Training Epoch: [214]  [ 40/250]  eta: 0:02:23  lr: 0.000300  loss: 0.1237 (0.1351)  loss_objectness: 0.0560 (0.0639)  loss_rpn_box_reg: 0.0642 (0.0712)  time: 0.6721  data: 0.2905  max mem: 5923\n",
      "Training Epoch: [214]  [ 50/250]  eta: 0:02:17  lr: 0.000300  loss: 0.1372 (0.1386)  loss_objectness: 0.0649 (0.0655)  loss_rpn_box_reg: 0.0688 (0.0731)  time: 0.6800  data: 0.2953  max mem: 5923\n",
      "Training Epoch: [214]  [ 60/250]  eta: 0:02:10  lr: 0.000300  loss: 0.1381 (0.1394)  loss_objectness: 0.0718 (0.0669)  loss_rpn_box_reg: 0.0688 (0.0725)  time: 0.6903  data: 0.2930  max mem: 5923\n",
      "Training Epoch: [214]  [ 70/250]  eta: 0:02:04  lr: 0.000300  loss: 0.1319 (0.1366)  loss_objectness: 0.0700 (0.0663)  loss_rpn_box_reg: 0.0554 (0.0703)  time: 0.6975  data: 0.2948  max mem: 5923\n",
      "Training Epoch: [214]  [ 80/250]  eta: 0:01:57  lr: 0.000300  loss: 0.1354 (0.1380)  loss_objectness: 0.0700 (0.0677)  loss_rpn_box_reg: 0.0672 (0.0702)  time: 0.6997  data: 0.2971  max mem: 5923\n",
      "Training Epoch: [214]  [ 90/250]  eta: 0:01:50  lr: 0.000300  loss: 0.1411 (0.1378)  loss_objectness: 0.0741 (0.0686)  loss_rpn_box_reg: 0.0655 (0.0692)  time: 0.6906  data: 0.2982  max mem: 5923\n",
      "Training Epoch: [214]  [100/250]  eta: 0:01:44  lr: 0.000300  loss: 0.1364 (0.1388)  loss_objectness: 0.0755 (0.0691)  loss_rpn_box_reg: 0.0630 (0.0698)  time: 0.7098  data: 0.3160  max mem: 5923\n",
      "Training Epoch: [214]  [110/250]  eta: 0:01:37  lr: 0.000300  loss: 0.1424 (0.1396)  loss_objectness: 0.0741 (0.0694)  loss_rpn_box_reg: 0.0697 (0.0703)  time: 0.7213  data: 0.3190  max mem: 5923\n",
      "Training Epoch: [214]  [120/250]  eta: 0:01:30  lr: 0.000300  loss: 0.1337 (0.1387)  loss_objectness: 0.0741 (0.0698)  loss_rpn_box_reg: 0.0543 (0.0689)  time: 0.7111  data: 0.3086  max mem: 5923\n",
      "Training Epoch: [214]  [130/250]  eta: 0:01:23  lr: 0.000300  loss: 0.1309 (0.1384)  loss_objectness: 0.0728 (0.0696)  loss_rpn_box_reg: 0.0543 (0.0687)  time: 0.7098  data: 0.3132  max mem: 5923\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     18\u001B[0m     train_model(model, evaluation_dataset, evaluation_dataset, num_epochs\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mNUM_EPOCHS, MODEL_TYPE\u001B[38;5;241m=\u001B[39mMODEL_TYPE, WEIGHTS_NAME \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrpn\u001B[39m\u001B[38;5;124m'\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, CONTINUE_TRAINING\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 20\u001B[0m     \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevaluation_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNUM_EPOCHS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMODEL_TYPE\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMODEL_TYPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mWEIGHTS_NAME\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrpn\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCONTINUE_TRAINING\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Data_drive\\Github\\TORCH_CLIP_FRCNN_Trainable\\engine.py:184\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_dataset, validation_dataset, num_epochs, MODEL_TYPE, batch_size, WEIGHTS_NAME, CONTINUE_TRAINING)\u001B[0m\n\u001B[0;32m    180\u001B[0m best_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m9999\u001B[39m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m epoch \u001B[38;5;241m<\u001B[39m num_epochs:\n\u001B[0;32m    182\u001B[0m \n\u001B[0;32m    183\u001B[0m     \u001B[38;5;66;03m# train for one epoch, printing every 10 iterations\u001B[39;00m\n\u001B[1;32m--> 184\u001B[0m     training_metrics \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_data_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDEVICE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscaler\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    186\u001B[0m     \u001B[38;5;66;03m# if MODEL_TYPE == 'CLIP-FRCNN':  # check that we dont change the weights from the backbone\u001B[39;00m\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;66;03m#     weight_tester.test(model)\u001B[39;00m\n\u001B[0;32m    189\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m5\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:  \u001B[38;5;66;03m#evaluate the mAP of the model every 3 epochs\u001B[39;00m\n\u001B[0;32m    190\u001B[0m         \u001B[38;5;66;03m# evaluate on the test dataset\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Data_drive\\Github\\TORCH_CLIP_FRCNN_Trainable\\engine.py:38\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[1;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler, training)\u001B[0m\n\u001B[0;32m     36\u001B[0m targets \u001B[38;5;241m=\u001B[39m [{k: v\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m t\u001B[38;5;241m.\u001B[39mitems()} \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m targets]\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast(enabled\u001B[38;5;241m=\u001B[39mscaler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m---> 38\u001B[0m     loss_dict \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;66;03m#del loss_dict['loss_classifier'] #for the CLIP model, we do not use classification loss\u001B[39;00m\n\u001B[0;32m     42\u001B[0m     losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(loss \u001B[38;5;28;01mfor\u001B[39;00m loss \u001B[38;5;129;01min\u001B[39;00m loss_dict\u001B[38;5;241m.\u001B[39mvalues())\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mC:\\Data_drive\\Github\\TORCH_CLIP_FRCNN_Trainable\\custom_rpn.py:98\u001B[0m, in \u001B[0;36mZeroShotOD.forward\u001B[1;34m(self, images, targets)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(features, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m     97\u001B[0m     features \u001B[38;5;241m=\u001B[39m OrderedDict([(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m'\u001B[39m, features)])\n\u001B[1;32m---> 98\u001B[0m proposals, proposal_losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrpn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    100\u001B[0m detections \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torchvision\\models\\detection\\rpn.py:344\u001B[0m, in \u001B[0;36mRegionProposalNetwork.forward\u001B[1;34m(self, images, features, targets)\u001B[0m\n\u001B[0;32m    342\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(features\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[0;32m    343\u001B[0m objectness, pred_bbox_deltas \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead(features)\n\u001B[1;32m--> 344\u001B[0m anchors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43manchor_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    346\u001B[0m num_images \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(anchors)\n\u001B[0;32m    347\u001B[0m num_anchors_per_level_shape_tensors \u001B[38;5;241m=\u001B[39m [o[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;28;01mfor\u001B[39;00m o \u001B[38;5;129;01min\u001B[39;00m objectness]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torchvision\\models\\detection\\anchor_utils.py:122\u001B[0m, in \u001B[0;36mAnchorGenerator.forward\u001B[1;34m(self, image_list, feature_maps)\u001B[0m\n\u001B[0;32m    120\u001B[0m image_size \u001B[38;5;241m=\u001B[39m image_list\u001B[38;5;241m.\u001B[39mtensors\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:]\n\u001B[0;32m    121\u001B[0m dtype, device \u001B[38;5;241m=\u001B[39m feature_maps[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdtype, feature_maps[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdevice\n\u001B[1;32m--> 122\u001B[0m strides \u001B[38;5;241m=\u001B[39m [[torch\u001B[38;5;241m.\u001B[39mtensor(image_size[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m g[\u001B[38;5;241m0\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint64, device\u001B[38;5;241m=\u001B[39mdevice),\n\u001B[0;32m    123\u001B[0m             torch\u001B[38;5;241m.\u001B[39mtensor(image_size[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m g[\u001B[38;5;241m1\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint64, device\u001B[38;5;241m=\u001B[39mdevice)] \u001B[38;5;28;01mfor\u001B[39;00m g \u001B[38;5;129;01min\u001B[39;00m grid_sizes]\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_cell_anchors(dtype, device)\n\u001B[0;32m    125\u001B[0m anchors_over_all_feature_maps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrid_anchors(grid_sizes, strides)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torchvision\\models\\detection\\anchor_utils.py:122\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    120\u001B[0m image_size \u001B[38;5;241m=\u001B[39m image_list\u001B[38;5;241m.\u001B[39mtensors\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:]\n\u001B[0;32m    121\u001B[0m dtype, device \u001B[38;5;241m=\u001B[39m feature_maps[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdtype, feature_maps[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdevice\n\u001B[1;32m--> 122\u001B[0m strides \u001B[38;5;241m=\u001B[39m [[\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_size\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mg\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint64\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m    123\u001B[0m             torch\u001B[38;5;241m.\u001B[39mtensor(image_size[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m g[\u001B[38;5;241m1\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint64, device\u001B[38;5;241m=\u001B[39mdevice)] \u001B[38;5;28;01mfor\u001B[39;00m g \u001B[38;5;129;01min\u001B[39;00m grid_sizes]\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_cell_anchors(dtype, device)\n\u001B[0;32m    125\u001B[0m anchors_over_all_feature_maps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrid_anchors(grid_sizes, strides)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "MODEL_TYPE='CLIP-RPN'\n",
    "# CLIP-RPN creates an RPN for training and uses CLIP to classify the regions of interest\n",
    "# CLIP-Backbone-FRCNN creates a FRCNN using CLIP features as the model backbone\n",
    "# CLIP-FRCNN creates a FRCNN using CLIP features as the model backbone, and embeds the rois using CLIP's embedding\n",
    "# Fully custom vanilla uses a pre-trained resnet50 backbone, and generates new anchor generator and roi pooling\n",
    "# Custom-Vanilla uses the pre-trained FRCNN from pytorch and replaces the roi heads only\n",
    "#\n",
    "import clip\n",
    "text_tokens = clip.tokenize([\"This is \" + desc for desc in item_list]).cuda()\n",
    "\n",
    "model = create_model(MODEL_TYPE, text_tokens)\n",
    "test = False\n",
    "\n",
    "# print(model)\n",
    "print(f'rpn score thresh: {model.rpn.score_thresh}')\n",
    "\n",
    "if test:\n",
    "    train_model(model, evaluation_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, WEIGHTS_NAME = 'rpn', batch_size=2, CONTINUE_TRAINING=False)\n",
    "else:\n",
    "    train_model(model, train_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, WEIGHTS_NAME = 'rpn', batch_size=16, CONTINUE_TRAINING=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "epoch = 213\n",
    "torch.save({'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict()},\n",
    "                       f'{MODEL_TYPE}_rpn_{epoch}.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# MODEL_TYPE='CLIP-FRCNN'\n",
    "# # CLIP-Backbone-FRCNN creates a FRCNN using CLIP features as the model backbone\n",
    "# # CLIP-FRCNN creates a FRCNN using CLIP features as the model backbone, and embeds the rois using CLIP's embedding\n",
    "# # Fully custom vanilla uses a pre-trained resnet50 backbone, and generates new anchor generator and roi pooling\n",
    "# # Custom-Vanilla uses the pre-trained FRCNN from pytorch and replaces the roi heads only\n",
    "# #\n",
    "# import clip\n",
    "# text_tokens = clip.tokenize([\"This is \" + desc for desc in item_list]).cuda()\n",
    "#\n",
    "# model = create_model(MODEL_TYPE, text_tokens)\n",
    "# test = False\n",
    "#\n",
    "# # print(model)\n",
    "# # print(f'rpn nms thresh: {model.rpn.nms_thresh}')\n",
    "#\n",
    "# if test:\n",
    "#     train_model(model, evaluation_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, WEIGHTS_NAME = 'box_regressors', batch_size=2)\n",
    "# else:\n",
    "#     train_model(model, train_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, WEIGHTS_NAME = 'box_regressors', batch_size=16, CONTINUE_TRAINING=True)\n",
    "#\n",
    "# #started at 0941 on 22 March 2022"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# MODEL_TYPE='CLIP-Backbone-FRCNN'\n",
    "#\n",
    "# model = create_model(MODEL_TYPE, classes=item_list)\n",
    "# test = True\n",
    "#\n",
    "# if test:\n",
    "#     train_model(model, evaluation_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=2)\n",
    "# else:\n",
    "#     train_model(model, train_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "acbb3df601244291b8b2fb9ea1137573",
      "32b6ec3046e64d04b4134553dc434fe0",
      "d8c6a316609d4ca5bfee139b93177ef5",
      "a1645bdfb02b42fba268f7000f183639",
      "4a4788a4fd6841788b20cfbf54a3d10b",
      "5d836b94d13e459d82429606496e4d4f",
      "a410071b34034a91aeda7ef1114969c2",
      "c063e7d90f6a4027b53d1b70c8c07742"
     ]
    },
    "id": "bHa6KRbEWuxz",
    "outputId": "3b4ebd0b-aa69-4a4d-b73c-b8cf24d8b461"
   },
   "outputs": [],
   "source": [
    "# #train a custom vanilla model so that we can compare and make sure the CLIP FRCNN is comparable\n",
    "# # Fully-Custom-Vanilla is most appropriate as it generates the model in a similar fashion\n",
    "# MODEL_TYPE = 'Fully-Custom-Vanilla'\n",
    "#\n",
    "# vanilla_model = create_model(MODEL_TYPE, classes=item_list)\n",
    "#\n",
    "# test = True\n",
    "#\n",
    "# if test:\n",
    "#     train_model(vanilla_model, evaluation_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=2)\n",
    "# else:\n",
    "#     train_model(vanilla_model, train_dataset, evaluation_dataset, num_epochs=10, MODEL_TYPE=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj3vLT1eXFnk"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkzG1i3AW1O7",
    "outputId": "ec7971c3-66ef-4a57-e710-248cb53dee8e"
   },
   "outputs": [],
   "source": [
    "add_detections(model, evaluation_dataset, fo_dataset, field_name=\"predictions\")\n",
    "\n",
    "results = fo.evaluate_detections(\n",
    "    test_view,\n",
    "    \"predictions\",\n",
    "    classes=item_list,\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uYdXrhgYdJ_",
    "outputId": "2eb792e9-342f-4dc8-f6c0-e1503d8bf193"
   },
   "outputs": [],
   "source": [
    "session.view = test_view\n",
    "results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcJBOM76aJPR",
    "outputId": "ac452527-7608-4e8d-f57e-18a0470acd30"
   },
   "outputs": [],
   "source": [
    "results.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nddFfGSnXo7i"
   },
   "source": [
    "By default, objects are only matched with other objects of the same class. In order to get an interesting confusion matrix, we need to match interclass objects by setting `classwise=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_53aCMna2Vt",
    "outputId": "4db71f31-73e3-4036-f623-efd8e2ac85bf"
   },
   "outputs": [],
   "source": [
    "results_interclass = fo.evaluate_detections(\n",
    "    test_view, \n",
    "    \"predictions\", \n",
    "    classes=item_list,\n",
    "    compute_mAP=True, \n",
    "    classwise=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot = results.plot_pr_curves(classes=item_list)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "Nbqf-NuAZ7Ps",
    "outputId": "571cd947-c94a-4b9a-ed93-2330fbddea7e"
   },
   "outputs": [],
   "source": [
    "results_interclass.plot_confusion_matrix(classes=item_list, include_other=False, include_missing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElSV7tTbYKLr"
   },
   "source": [
    "The [detection evaluation](https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#detections) also added the attributes `eval_fp`, `eval_tp`, and `eval_fn` to every predicted detection indicating if it is a false positive, true positive, or false negative. \n",
    "Let's create a view to find the worst samples by sorting by `eval_fp` using the [FiftyOne App](https://voxel51.com/docs/fiftyone/user_guide/app.html) to visualize the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786,
     "resources": {
      "https://localhost:5151/polling?sessionId=de0b710e-15f8-4c57-ba46-ae7955f716b1": {
       "data": "eyJtZXNzYWdlcyI6IFtdfQ==",
       "headers": [
        [
         "access-control-allow-headers",
         "x-requested-with"
        ],
        [
         "content-type",
         "text/html; charset=UTF-8"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "Pm4Z52rd8AC1",
    "outputId": "62d39076-7ef3-4fe3-95ae-500d0f8f8a3f"
   },
   "outputs": [],
   "source": [
    "session.view = test_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786,
     "resources": {
      "https://localhost:5151/polling?sessionId=ebbc318d-3578-4fb1-9ae7-68596117572b": {
       "data": "eyJtZXNzYWdlcyI6IFtdfQ==",
       "headers": [
        [
         "access-control-allow-headers",
         "x-requested-with"
        ],
        [
         "content-type",
         "text/html; charset=UTF-8"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "njLG0l5K-ucV",
    "outputId": "bda6f02d-d8fe-49be-d212-31e0e70779e3"
   },
   "outputs": [],
   "source": [
    "session.view = test_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReXDVFgLZLtf"
   },
   "source": [
    "It would be best to get this [data reannotated to fix these mistakes](https://towardsdatascience.com/managing-annotation-mistakes-with-fiftyone-and-labelbox-fc6e87b51102), but in the meantime, we can easily remedy this by simply creating a new view that remaps the labels `car`, `truck`, and `bus` all to `vehicle` and then retraining the model with that. This is only possible because we are backing our data in FiftyOne and loading views into PyTorch as needed. Without FiftyOne, the PyTorch dataset class or the underlying data would need to be changed to remap these classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# map labels to single vehicle class\n",
    "vehicle_list = ['car', 'bus', 'truck']\n",
    "vehicles_map = {c: \"vehicle\" for c in vehicle_list}\n",
    "\n",
    "train_map_view = train_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "test_map_view = test_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "torch_map_dataset = FiftyOneTorchDataset(train_map_view, train_transforms)\n",
    "torch_map_dataset_test = FiftyOneTorchDataset(test_map_view, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynRCHQv8XB_v"
   },
   "outputs": [],
   "source": [
    "# Only 2 classes (background and vehicle)\n",
    "MODEL_TYPE = 'Vanilla-FRCNN'\n",
    "vehicle_model = create_model(MODEL_TYPE, num_classes=(len(vehicles_map)+1))\n",
    "train_model(vehicle_model, torch_map_dataset, torch_map_dataset_test, num_epochs=2, MODEL_TYPE=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-mrVOl4XFbp",
    "outputId": "6d8bec76-ebe8-4a36-959a-52bb1aab8498"
   },
   "outputs": [],
   "source": [
    "add_detections(vehicle_model, torch_map_dataset_test, test_map_view, field_name=\"vehicle_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfd3xvhaXhl_",
    "outputId": "d9c4a2fe-538a-4979-c3f8-f5ede0c98aa1"
   },
   "outputs": [],
   "source": [
    "vehicle_results = fo.evaluate_detections(\n",
    "    test_map_view, \n",
    "    \"vehicle_predictions\", \n",
    "    classes=[\"vehicle\"], \n",
    "    eval_key=\"vehicle_eval\", \n",
    "    compute_mAP=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFvddH3rk0NR",
    "outputId": "59572ba2-f9ad-4dd2-e9ac-90877190ff99"
   },
   "outputs": [],
   "source": [
    "vehicle_results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwbhq18sk1PL",
    "outputId": "d6985867-5049-4678-cc88-d5041a0079ed"
   },
   "outputs": [],
   "source": [
    "vehicle_results.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJMAkJbWZ_u1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Due to our ability to easily visualize and manage our dataset with FiftyOne, we were able to spot and take action on a dataset issue that would otherwise have gone unnoticed if we only concerned ourselves with dataset-wide evaluation metrics and fixed dataset representations. Through these efforts, we managed to increase the mAP of the model to 43%.\n",
    "\n",
    "Even though this example workflow may not work in all situations, this kind of class-merging strategy can be effective in cases where more fine-grained discrimination is not called for."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "fiftyone_pytorch_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "torch-frcnn",
   "language": "python",
   "display_name": "torch-frcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "32b6ec3046e64d04b4134553dc434fe0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a4788a4fd6841788b20cfbf54a3d10b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5d836b94d13e459d82429606496e4d4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1645bdfb02b42fba268f7000f183639": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c063e7d90f6a4027b53d1b70c8c07742",
      "placeholder": "​",
      "style": "IPY_MODEL_a410071b34034a91aeda7ef1114969c2",
      "value": " 160M/160M [01:05&lt;00:00, 2.55MB/s]"
     }
    },
    "a410071b34034a91aeda7ef1114969c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acbb3df601244291b8b2fb9ea1137573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8c6a316609d4ca5bfee139b93177ef5",
       "IPY_MODEL_a1645bdfb02b42fba268f7000f183639"
      ],
      "layout": "IPY_MODEL_32b6ec3046e64d04b4134553dc434fe0"
     }
    },
    "c063e7d90f6a4027b53d1b70c8c07742": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8c6a316609d4ca5bfee139b93177ef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d836b94d13e459d82429606496e4d4f",
      "max": 167502836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a4788a4fd6841788b20cfbf54a3d10b",
      "value": 167502836
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}