{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Code for using FiftyOne to train a Faster RCNN on COCO data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
<<<<<<< Updated upstream
      "text/plain": "<torch._C.Generator at 0x189a7bfd1f0>"
=======
      "text/plain": "<torch._C.Generator at 0x248b382c730>"
>>>>>>> Stashed changes
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "from dataset import FiftyOneTorchDataset\n",
    "from model import create_model\n",
    "from utils import add_detections, get_transforms\n",
    "\n",
    "from engine import train_model\n",
    "import config\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load full dataset from model zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5crNDNsRWdPT",
    "outputId": "4f3ff734-ca0a-4312-a811-7f84db514fac",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Downloading split 'train' to 'G:/Data\\coco-2017\\train' if necessary\n",
      "Downloading annotations to 'G:/Data\\coco-2017\\tmp-download\\annotations_trainval2017.zip'\n",
      " 100% |██████|    1.9Gb/1.9Gb [6.6s elapsed, 0s remaining, 297.9Mb/s]       \n",
      "Extracting annotations to 'G:\\Data\\coco-2017\\raw\\instances_train2017.json'\n",
      "Downloading images to 'G:/Data\\coco-2017\\tmp-download\\train2017.zip'\n",
      " 100% |████|  144.1Gb/144.1Gb [8.5m elapsed, 0s remaining, 296.0Mb/s]       \n",
      "Extracting images to 'G:/Data\\coco-2017\\train\\data'\n",
      "Writing annotations to 'G:/Data\\coco-2017\\train\\labels.json'\n",
      "Dataset info written to 'G:/Data\\coco-2017\\info.json'\n",
      "Loading 'coco-2017' split 'train'\n",
      " 100% |███████████| 118287/118287 [8.0m elapsed, 0s remaining, 259.2 samples/s]       \n",
      "Dataset 'coco-2017-train' created\n",
      "Downloading split 'validation' to 'G:/Data\\coco-2017\\validation' if necessary\n",
      "Found annotations at 'G:\\Data\\coco-2017\\raw\\instances_val2017.json'\n",
      "Downloading images to 'G:/Data\\coco-2017\\tmp-download\\val2017.zip'\n",
      " 100% |██████|    6.1Gb/6.1Gb [28.6s elapsed, 0s remaining, 204.3Mb/s]      \n",
      "Extracting images to 'G:/Data\\coco-2017\\validation\\data'\n",
      "Writing annotations to 'G:/Data\\coco-2017\\validation\\labels.json'\n",
      "Dataset info written to 'G:/Data\\coco-2017\\info.json'\n",
      "Loading 'coco-2017' split 'validation'\n",
      " 100% |███████████████| 5000/5000 [19.1s elapsed, 0s remaining, 263.2 samples/s]      \n",
=======
      "Downloading split 'train' to 'C:\\Users\\blain\\fiftyone\\coco-2017\\train' if necessary\n",
      "Found annotations at 'C:\\Users\\blain\\fiftyone\\coco-2017\\raw\\instances_train2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading 'coco-2017' split 'train'\n",
      " 100% |███████████| 118287/118287 [6.5m elapsed, 0s remaining, 342.7 samples/s]      \n",
      "Dataset 'coco-2017-train' created\n",
      "Downloading split 'validation' to 'C:\\Users\\blain\\fiftyone\\coco-2017\\validation' if necessary\n",
      "Found annotations at 'C:\\Users\\blain\\fiftyone\\coco-2017\\raw\\instances_val2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading 'coco-2017' split 'validation'\n",
      " 100% |███████████████| 5000/5000 [14.8s elapsed, 0s remaining, 345.6 samples/s]      \n",
>>>>>>> Stashed changes
      "Dataset 'coco-2017-validation' created\n"
     ]
    }
   ],
   "source": [
    "fo.config.dataset_zoo_dir = \"G:/Data\"\n",
    "\n",
    "#Load in the dataset from the FiftyOne model Zoo\n",
    "fo_train_dataset = foz.load_zoo_dataset(\"coco-2017\", \"train\")\n",
    "fo_validation_dataset = foz.load_zoo_dataset(\"coco-2017\", \"validation\")\n",
    "#needed to calculate image height and width\n",
    "fo_train_dataset.compute_metadata()\n",
    "fo_validation_dataset.compute_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqU6Ckq4WKHK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For example, cluttered images make it difficult for models to localize objects. We can use FiftyOne to create a view containing only samples with more than, say, 10 objects. You can perform the same operations on views as datasets, so we can create an instance of our PyTorch dataset from this view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kLACOukJFUxd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#if we want to see images with more than 10 items, we can\n",
    "# busy_view = fo_dataset.match(F(\"ground_truth.detections\").length() > 10)\n",
    "# busy_torch_dataset = FiftyOneTorchDataset(busy_view)\n",
    "# session.view = busy_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKsE_7TOWXBE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create training and testing views (and corresponding PyTorch datasets) that only contain some items from the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TELK0NWmWrMT",
    "outputId": "8bf582cf-e483-4643-8f6b-7c664a2d6c5f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning on 118287 samples\n",
      "Testing on 5000 samples\n"
     ]
    },
    {
     "data": {
<<<<<<< Updated upstream
      "text/plain": "<IPython.lib.display.IFrame at 0x18a04bb1e20>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"800\"\n            src=\"http://localhost:5151/?notebook=true&handleId=cf138ef6-f6d6-436a-ab97-970a7a51d48e\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
=======
      "text/plain": "<IPython.lib.display.IFrame at 0x2499d771f70>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"800\"\n            src=\"http://localhost:5151/?notebook=true&handleId=5d5be16c-4b8d-45f2-976f-4b75dd186927\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
>>>>>>> Stashed changes
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_transforms, test_transforms = get_transforms()\n",
    "\n",
    "\n",
    "print(f'Traning on {len(fo_train_dataset)} samples')\n",
    "print(f'Testing on {len(fo_validation_dataset)} samples')\n",
    "\n",
    "session = fo.launch_app(fo_train_dataset)\n",
    "\n",
    "item_list = fo_train_dataset.distinct(\"ground_truth.detections.label\")\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "train_dataset = FiftyOneTorchDataset(fo_train_dataset, train_transforms,\n",
    "        classes=item_list)\n",
    "validation_dataset = FiftyOneTorchDataset(fo_validation_dataset, test_transforms,\n",
    "        classes=item_list)\n",
    "\n",
    "#session.view = train_view\n",
    "\n",
    "#this is needed for later use, but not for creating the dataset\n",
    "if item_list[0] != 'background':\n",
    "     item_list.insert(0,'background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# # map labels to single vehicle class\n",
    "# vehicle_list = ['car', 'bus', 'truck']\n",
    "# vehicles_map = {c: \"vehicle\" for c in vehicle_list}\n",
    "#\n",
    "# train_map_view = train_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "# test_map_view = test_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "#\n",
    "# # use our dataset and defined transformations\n",
    "# torch_map_dataset = FiftyOneTorchDataset(train_map_view, train_transforms)\n",
    "# torch_map_dataset_test = FiftyOneTorchDataset(test_map_view, test_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5je6lVBWz5r",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
<<<<<<< Updated upstream
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 244M/244M [00:08<00:00, 29.9MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Training Epoch: [0]  [    0/14785]  eta: 1 day, 8:12:05  lr: 0.000001  loss: 0.9569 (0.9569)  loss_objectness: 0.7073 (0.7073)  loss_rpn_box_reg: 0.2496 (0.2496)  time: 7.8408  data: 1.1250  max mem: 3615\n",
      "Training Epoch: [0]  [   10/14785]  eta: 6:16:57  lr: 0.000004  loss: 1.0292 (1.0237)  loss_objectness: 0.7073 (0.6984)  loss_rpn_box_reg: 0.3333 (0.3253)  time: 1.5308  data: 0.5341  max mem: 3615\n",
      "Training Epoch: [0]  [   20/14785]  eta: 5:01:22  lr: 0.000007  loss: 0.9005 (0.9728)  loss_objectness: 0.6703 (0.6674)  loss_rpn_box_reg: 0.2888 (0.3054)  time: 0.8939  data: 0.4328  max mem: 3615\n",
      "Training Epoch: [0]  [   30/14785]  eta: 4:21:23  lr: 0.000010  loss: 0.8749 (0.9554)  loss_objectness: 0.5977 (0.6307)  loss_rpn_box_reg: 0.2943 (0.3248)  time: 0.8056  data: 0.3717  max mem: 3615\n",
      "Training Epoch: [0]  [   40/14785]  eta: 4:01:37  lr: 0.000013  loss: 0.8264 (0.9135)  loss_objectness: 0.5078 (0.5897)  loss_rpn_box_reg: 0.3204 (0.3238)  time: 0.7297  data: 0.3568  max mem: 3615\n",
      "Training Epoch: [0]  [   50/14785]  eta: 3:48:36  lr: 0.000016  loss: 0.6588 (0.8655)  loss_objectness: 0.4257 (0.5507)  loss_rpn_box_reg: 0.2947 (0.3148)  time: 0.7262  data: 0.3570  max mem: 3615\n",
      "Training Epoch: [0]  [   60/14785]  eta: 3:39:33  lr: 0.000019  loss: 0.6320 (0.8290)  loss_objectness: 0.3519 (0.5145)  loss_rpn_box_reg: 0.2688 (0.3145)  time: 0.7129  data: 0.3448  max mem: 3615\n",
      "Training Epoch: [0]  [   70/14785]  eta: 3:33:12  lr: 0.000022  loss: 0.5758 (0.7998)  loss_objectness: 0.3190 (0.4849)  loss_rpn_box_reg: 0.2738 (0.3148)  time: 0.7125  data: 0.3474  max mem: 3615\n",
      "Training Epoch: [0]  [   80/14785]  eta: 3:28:06  lr: 0.000025  loss: 0.6422 (0.7762)  loss_objectness: 0.3139 (0.4634)  loss_rpn_box_reg: 0.3032 (0.3128)  time: 0.7105  data: 0.3479  max mem: 3615\n",
      "Training Epoch: [0]  [   90/14785]  eta: 3:24:14  lr: 0.000028  loss: 0.5284 (0.7442)  loss_objectness: 0.2613 (0.4382)  loss_rpn_box_reg: 0.2714 (0.3060)  time: 0.7082  data: 0.3338  max mem: 3615\n",
      "Training Epoch: [0]  [  100/14785]  eta: 3:21:11  lr: 0.000031  loss: 0.5012 (0.7283)  loss_objectness: 0.2387 (0.4207)  loss_rpn_box_reg: 0.2756 (0.3076)  time: 0.7122  data: 0.3264  max mem: 3615\n",
      "Training Epoch: [0]  [  110/14785]  eta: 3:18:06  lr: 0.000034  loss: 0.4897 (0.7001)  loss_objectness: 0.2242 (0.4008)  loss_rpn_box_reg: 0.2655 (0.2993)  time: 0.7010  data: 0.3236  max mem: 3615\n",
      "Training Epoch: [0]  [  120/14785]  eta: 3:15:52  lr: 0.000037  loss: 0.4516 (0.6853)  loss_objectness: 0.1913 (0.3862)  loss_rpn_box_reg: 0.2611 (0.2991)  time: 0.6972  data: 0.3266  max mem: 3615\n",
      "Training Epoch: [0]  [  130/14785]  eta: 3:14:04  lr: 0.000040  loss: 0.4148 (0.6683)  loss_objectness: 0.1935 (0.3716)  loss_rpn_box_reg: 0.2213 (0.2967)  time: 0.7090  data: 0.3298  max mem: 3615\n",
      "Training Epoch: [0]  [  140/14785]  eta: 3:12:03  lr: 0.000043  loss: 0.4042 (0.6508)  loss_objectness: 0.1979 (0.3609)  loss_rpn_box_reg: 0.2137 (0.2900)  time: 0.6989  data: 0.3236  max mem: 3615\n",
      "Training Epoch: [0]  [  150/14785]  eta: 3:10:42  lr: 0.000046  loss: 0.4235 (0.6369)  loss_objectness: 0.1992 (0.3496)  loss_rpn_box_reg: 0.2324 (0.2874)  time: 0.6985  data: 0.3159  max mem: 3615\n",
      "Training Epoch: [0]  [  160/14785]  eta: 3:09:16  lr: 0.000049  loss: 0.4974 (0.6305)  loss_objectness: 0.1955 (0.3408)  loss_rpn_box_reg: 0.2516 (0.2897)  time: 0.7034  data: 0.3256  max mem: 3615\n",
      "Training Epoch: [0]  [  170/14785]  eta: 3:08:02  lr: 0.000052  loss: 0.5040 (0.6217)  loss_objectness: 0.1955 (0.3328)  loss_rpn_box_reg: 0.2934 (0.2889)  time: 0.6978  data: 0.3319  max mem: 3615\n",
      "Training Epoch: [0]  [  180/14785]  eta: 3:07:09  lr: 0.000055  loss: 0.4323 (0.6128)  loss_objectness: 0.1774 (0.3243)  loss_rpn_box_reg: 0.2669 (0.2885)  time: 0.7072  data: 0.3297  max mem: 3615\n",
      "Training Epoch: [0]  [  190/14785]  eta: 3:05:51  lr: 0.000058  loss: 0.4425 (0.6047)  loss_objectness: 0.1812 (0.3177)  loss_rpn_box_reg: 0.2434 (0.2869)  time: 0.6961  data: 0.3235  max mem: 3615\n",
      "Training Epoch: [0]  [  200/14785]  eta: 3:05:07  lr: 0.000061  loss: 0.4425 (0.5955)  loss_objectness: 0.1864 (0.3112)  loss_rpn_box_reg: 0.2239 (0.2843)  time: 0.6955  data: 0.3166  max mem: 3615\n",
      "Training Epoch: [0]  [  210/14785]  eta: 3:04:07  lr: 0.000064  loss: 0.4270 (0.5901)  loss_objectness: 0.1873 (0.3063)  loss_rpn_box_reg: 0.2490 (0.2838)  time: 0.7000  data: 0.3204  max mem: 3615\n",
      "Training Epoch: [0]  [  220/14785]  eta: 3:03:17  lr: 0.000067  loss: 0.4662 (0.5837)  loss_objectness: 0.2045 (0.3011)  loss_rpn_box_reg: 0.2708 (0.2826)  time: 0.6901  data: 0.3252  max mem: 3615\n",
      "Training Epoch: [0]  [  230/14785]  eta: 3:02:43  lr: 0.000070  loss: 0.4262 (0.5766)  loss_objectness: 0.1860 (0.2960)  loss_rpn_box_reg: 0.2462 (0.2805)  time: 0.7031  data: 0.3221  max mem: 3615\n",
      "Training Epoch: [0]  [  240/14785]  eta: 3:01:53  lr: 0.000073  loss: 0.4295 (0.5714)  loss_objectness: 0.1778 (0.2916)  loss_rpn_box_reg: 0.2327 (0.2799)  time: 0.6979  data: 0.3178  max mem: 3615\n",
      "Training Epoch: [0]  [  250/14785]  eta: 3:01:24  lr: 0.000076  loss: 0.4377 (0.5654)  loss_objectness: 0.1778 (0.2871)  loss_rpn_box_reg: 0.2327 (0.2784)  time: 0.6984  data: 0.3251  max mem: 3615\n",
      "Training Epoch: [0]  [  260/14785]  eta: 3:01:04  lr: 0.000079  loss: 0.4558 (0.5636)  loss_objectness: 0.1815 (0.2836)  loss_rpn_box_reg: 0.2571 (0.2800)  time: 0.7196  data: 0.3317  max mem: 3615\n",
      "Training Epoch: [0]  [  270/14785]  eta: 3:00:10  lr: 0.000082  loss: 0.4770 (0.5602)  loss_objectness: 0.1769 (0.2802)  loss_rpn_box_reg: 0.2708 (0.2800)  time: 0.6936  data: 0.3196  max mem: 3615\n",
      "Training Epoch: [0]  [  280/14785]  eta: 2:59:22  lr: 0.000085  loss: 0.4567 (0.5567)  loss_objectness: 0.1600 (0.2765)  loss_rpn_box_reg: 0.2322 (0.2802)  time: 0.6640  data: 0.3162  max mem: 3615\n",
      "Training Epoch: [0]  [  290/14785]  eta: 2:58:54  lr: 0.000088  loss: 0.4350 (0.5502)  loss_objectness: 0.1778 (0.2729)  loss_rpn_box_reg: 0.2257 (0.2773)  time: 0.6839  data: 0.3272  max mem: 3615\n",
      "Training Epoch: [0]  [  300/14785]  eta: 2:58:20  lr: 0.000091  loss: 0.3968 (0.5461)  loss_objectness: 0.1778 (0.2693)  loss_rpn_box_reg: 0.2143 (0.2768)  time: 0.6928  data: 0.3234  max mem: 3615\n",
      "Training Epoch: [0]  [  310/14785]  eta: 2:57:55  lr: 0.000094  loss: 0.3506 (0.5400)  loss_objectness: 0.1578 (0.2661)  loss_rpn_box_reg: 0.1981 (0.2739)  time: 0.6923  data: 0.3219  max mem: 3615\n",
      "Training Epoch: [0]  [  320/14785]  eta: 2:57:34  lr: 0.000097  loss: 0.3714 (0.5370)  loss_objectness: 0.1582 (0.2625)  loss_rpn_box_reg: 0.2071 (0.2745)  time: 0.7038  data: 0.3230  max mem: 3615\n",
      "Training Epoch: [0]  [  330/14785]  eta: 2:57:12  lr: 0.000100  loss: 0.4175 (0.5326)  loss_objectness: 0.1485 (0.2590)  loss_rpn_box_reg: 0.2532 (0.2736)  time: 0.7054  data: 0.3163  max mem: 3615\n",
      "Training Epoch: [0]  [  340/14785]  eta: 2:56:49  lr: 0.000102  loss: 0.4199 (0.5300)  loss_objectness: 0.1534 (0.2566)  loss_rpn_box_reg: 0.2532 (0.2734)  time: 0.7016  data: 0.3169  max mem: 3615\n",
      "Training Epoch: [0]  [  350/14785]  eta: 2:56:25  lr: 0.000105  loss: 0.4400 (0.5272)  loss_objectness: 0.1629 (0.2539)  loss_rpn_box_reg: 0.2677 (0.2733)  time: 0.6962  data: 0.3203  max mem: 3615\n",
      "Training Epoch: [0]  [  360/14785]  eta: 2:56:15  lr: 0.000108  loss: 0.3760 (0.5224)  loss_objectness: 0.1524 (0.2510)  loss_rpn_box_reg: 0.2386 (0.2714)  time: 0.7093  data: 0.3258  max mem: 3615\n",
      "Training Epoch: [0]  [  370/14785]  eta: 2:55:57  lr: 0.000111  loss: 0.3836 (0.5201)  loss_objectness: 0.1594 (0.2491)  loss_rpn_box_reg: 0.2264 (0.2709)  time: 0.7166  data: 0.3247  max mem: 3615\n",
      "Training Epoch: [0]  [  380/14785]  eta: 2:55:34  lr: 0.000114  loss: 0.4117 (0.5169)  loss_objectness: 0.1631 (0.2475)  loss_rpn_box_reg: 0.2238 (0.2694)  time: 0.6982  data: 0.3216  max mem: 3615\n",
      "Training Epoch: [0]  [  390/14785]  eta: 2:55:14  lr: 0.000117  loss: 0.3527 (0.5126)  loss_objectness: 0.1450 (0.2450)  loss_rpn_box_reg: 0.1732 (0.2676)  time: 0.6942  data: 0.3258  max mem: 3615\n",
      "Training Epoch: [0]  [  400/14785]  eta: 2:54:59  lr: 0.000120  loss: 0.3215 (0.5097)  loss_objectness: 0.1315 (0.2427)  loss_rpn_box_reg: 0.1814 (0.2670)  time: 0.7034  data: 0.3296  max mem: 3615\n",
      "Training Epoch: [0]  [  410/14785]  eta: 2:54:38  lr: 0.000123  loss: 0.3589 (0.5063)  loss_objectness: 0.1416 (0.2406)  loss_rpn_box_reg: 0.2110 (0.2657)  time: 0.6988  data: 0.3300  max mem: 3615\n",
      "Training Epoch: [0]  [  420/14785]  eta: 2:54:28  lr: 0.000126  loss: 0.3437 (0.5036)  loss_objectness: 0.1452 (0.2384)  loss_rpn_box_reg: 0.2171 (0.2653)  time: 0.7053  data: 0.3280  max mem: 3615\n",
      "Training Epoch: [0]  [  430/14785]  eta: 2:54:15  lr: 0.000129  loss: 0.3437 (0.5010)  loss_objectness: 0.1395 (0.2366)  loss_rpn_box_reg: 0.2171 (0.2644)  time: 0.7175  data: 0.3305  max mem: 3615\n",
      "Training Epoch: [0]  [  440/14785]  eta: 2:53:58  lr: 0.000132  loss: 0.3773 (0.4980)  loss_objectness: 0.1477 (0.2348)  loss_rpn_box_reg: 0.2095 (0.2632)  time: 0.7062  data: 0.3210  max mem: 3615\n",
      "Training Epoch: [0]  [  450/14785]  eta: 2:53:39  lr: 0.000135  loss: 0.3850 (0.4973)  loss_objectness: 0.1519 (0.2336)  loss_rpn_box_reg: 0.2095 (0.2637)  time: 0.6937  data: 0.3179  max mem: 3615\n",
      "Training Epoch: [0]  [  460/14785]  eta: 2:53:34  lr: 0.000138  loss: 0.3874 (0.4948)  loss_objectness: 0.1612 (0.2322)  loss_rpn_box_reg: 0.2182 (0.2626)  time: 0.7114  data: 0.3358  max mem: 3615\n",
      "Training Epoch: [0]  [  470/14785]  eta: 2:53:18  lr: 0.000141  loss: 0.4010 (0.4931)  loss_objectness: 0.1638 (0.2306)  loss_rpn_box_reg: 0.2221 (0.2625)  time: 0.7160  data: 0.3390  max mem: 3615\n",
      "Training Epoch: [0]  [  480/14785]  eta: 2:52:59  lr: 0.000144  loss: 0.4010 (0.4914)  loss_objectness: 0.1715 (0.2294)  loss_rpn_box_reg: 0.2483 (0.2620)  time: 0.6930  data: 0.3312  max mem: 3615\n",
      "Training Epoch: [0]  [  490/14785]  eta: 2:52:48  lr: 0.000147  loss: 0.3860 (0.4898)  loss_objectness: 0.1545 (0.2282)  loss_rpn_box_reg: 0.2296 (0.2616)  time: 0.6995  data: 0.3314  max mem: 3615\n",
      "Training Epoch: [0]  [  500/14785]  eta: 2:52:33  lr: 0.000150  loss: 0.4000 (0.4891)  loss_objectness: 0.1629 (0.2270)  loss_rpn_box_reg: 0.2674 (0.2621)  time: 0.7055  data: 0.3327  max mem: 3615\n",
      "Training Epoch: [0]  [  510/14785]  eta: 2:52:23  lr: 0.000153  loss: 0.4497 (0.4882)  loss_objectness: 0.1654 (0.2262)  loss_rpn_box_reg: 0.2758 (0.2620)  time: 0.7066  data: 0.3251  max mem: 3615\n",
      "Training Epoch: [0]  [  520/14785]  eta: 2:52:09  lr: 0.000156  loss: 0.3677 (0.4858)  loss_objectness: 0.1615 (0.2246)  loss_rpn_box_reg: 0.2287 (0.2612)  time: 0.7069  data: 0.3200  max mem: 3615\n",
      "Training Epoch: [0]  [  530/14785]  eta: 2:51:47  lr: 0.000159  loss: 0.3520 (0.4842)  loss_objectness: 0.1537 (0.2237)  loss_rpn_box_reg: 0.2141 (0.2605)  time: 0.6858  data: 0.3244  max mem: 3615\n",
      "Training Epoch: [0]  [  540/14785]  eta: 2:51:32  lr: 0.000162  loss: 0.3343 (0.4813)  loss_objectness: 0.1537 (0.2223)  loss_rpn_box_reg: 0.1962 (0.2589)  time: 0.6830  data: 0.3241  max mem: 3615\n",
      "Training Epoch: [0]  [  550/14785]  eta: 2:51:17  lr: 0.000165  loss: 0.3454 (0.4806)  loss_objectness: 0.1542 (0.2218)  loss_rpn_box_reg: 0.1962 (0.2588)  time: 0.6924  data: 0.3225  max mem: 3615\n",
      "Training Epoch: [0]  [  560/14785]  eta: 2:51:01  lr: 0.000168  loss: 0.3969 (0.4782)  loss_objectness: 0.1513 (0.2204)  loss_rpn_box_reg: 0.2106 (0.2578)  time: 0.6891  data: 0.3193  max mem: 3615\n",
      "Training Epoch: [0]  [  570/14785]  eta: 2:50:43  lr: 0.000171  loss: 0.3480 (0.4784)  loss_objectness: 0.1530 (0.2201)  loss_rpn_box_reg: 0.2084 (0.2583)  time: 0.6822  data: 0.3152  max mem: 3615\n",
      "Training Epoch: [0]  [  580/14785]  eta: 2:50:22  lr: 0.000174  loss: 0.4690 (0.4778)  loss_objectness: 0.1609 (0.2194)  loss_rpn_box_reg: 0.2629 (0.2585)  time: 0.6720  data: 0.3136  max mem: 3615\n",
      "Training Epoch: [0]  [  590/14785]  eta: 2:50:15  lr: 0.000177  loss: 0.4096 (0.4763)  loss_objectness: 0.1609 (0.2185)  loss_rpn_box_reg: 0.2710 (0.2578)  time: 0.6936  data: 0.3164  max mem: 3615\n",
      "Training Epoch: [0]  [  600/14785]  eta: 2:50:03  lr: 0.000180  loss: 0.4184 (0.4752)  loss_objectness: 0.1637 (0.2175)  loss_rpn_box_reg: 0.2496 (0.2576)  time: 0.7091  data: 0.3159  max mem: 3615\n",
      "Training Epoch: [0]  [  610/14785]  eta: 2:49:54  lr: 0.000183  loss: 0.4206 (0.4748)  loss_objectness: 0.1637 (0.2168)  loss_rpn_box_reg: 0.2586 (0.2580)  time: 0.7055  data: 0.3214  max mem: 3615\n",
      "Training Epoch: [0]  [  620/14785]  eta: 2:49:45  lr: 0.000186  loss: 0.4251 (0.4741)  loss_objectness: 0.1488 (0.2156)  loss_rpn_box_reg: 0.2731 (0.2584)  time: 0.7110  data: 0.3279  max mem: 3615\n",
      "Training Epoch: [0]  [  630/14785]  eta: 2:49:32  lr: 0.000189  loss: 0.3713 (0.4726)  loss_objectness: 0.1380 (0.2147)  loss_rpn_box_reg: 0.2149 (0.2579)  time: 0.7019  data: 0.3240  max mem: 3615\n",
      "Training Epoch: [0]  [  640/14785]  eta: 2:49:23  lr: 0.000192  loss: 0.3069 (0.4707)  loss_objectness: 0.1316 (0.2137)  loss_rpn_box_reg: 0.1843 (0.2570)  time: 0.7010  data: 0.3255  max mem: 3615\n",
      "Training Epoch: [0]  [  650/14785]  eta: 2:49:10  lr: 0.000195  loss: 0.3614 (0.4697)  loss_objectness: 0.1316 (0.2130)  loss_rpn_box_reg: 0.2062 (0.2567)  time: 0.7010  data: 0.3295  max mem: 3615\n",
      "Training Epoch: [0]  [  660/14785]  eta: 2:48:59  lr: 0.000198  loss: 0.3614 (0.4690)  loss_objectness: 0.1552 (0.2123)  loss_rpn_box_reg: 0.2161 (0.2567)  time: 0.6963  data: 0.3254  max mem: 3615\n",
      "Training Epoch: [0]  [  670/14785]  eta: 2:48:39  lr: 0.000201  loss: 0.3595 (0.4682)  loss_objectness: 0.1468 (0.2116)  loss_rpn_box_reg: 0.2096 (0.2567)  time: 0.6786  data: 0.3206  max mem: 3615\n",
      "Training Epoch: [0]  [  680/14785]  eta: 2:48:28  lr: 0.000204  loss: 0.3652 (0.4667)  loss_objectness: 0.1513 (0.2107)  loss_rpn_box_reg: 0.1991 (0.2560)  time: 0.6783  data: 0.3207  max mem: 3615\n",
      "Training Epoch: [0]  [  690/14785]  eta: 2:48:19  lr: 0.000207  loss: 0.3636 (0.4654)  loss_objectness: 0.1421 (0.2097)  loss_rpn_box_reg: 0.2378 (0.2557)  time: 0.7039  data: 0.3185  max mem: 3615\n",
      "Training Epoch: [0]  [  700/14785]  eta: 2:48:17  lr: 0.000210  loss: 0.3673 (0.4640)  loss_objectness: 0.1326 (0.2088)  loss_rpn_box_reg: 0.2405 (0.2551)  time: 0.7252  data: 0.3242  max mem: 3615\n",
      "Training Epoch: [0]  [  710/14785]  eta: 2:48:12  lr: 0.000213  loss: 0.3673 (0.4629)  loss_objectness: 0.1318 (0.2079)  loss_rpn_box_reg: 0.2200 (0.2550)  time: 0.7337  data: 0.3317  max mem: 3615\n",
      "Training Epoch: [0]  [  720/14785]  eta: 2:47:58  lr: 0.000216  loss: 0.3797 (0.4623)  loss_objectness: 0.1474 (0.2077)  loss_rpn_box_reg: 0.2016 (0.2547)  time: 0.7057  data: 0.3249  max mem: 3615\n",
      "Training Epoch: [0]  [  730/14785]  eta: 2:47:42  lr: 0.000219  loss: 0.3509 (0.4614)  loss_objectness: 0.1474 (0.2069)  loss_rpn_box_reg: 0.2341 (0.2545)  time: 0.6762  data: 0.3109  max mem: 3615\n",
      "Training Epoch: [0]  [  740/14785]  eta: 2:47:33  lr: 0.000222  loss: 0.3696 (0.4609)  loss_objectness: 0.1338 (0.2062)  loss_rpn_box_reg: 0.2341 (0.2547)  time: 0.6865  data: 0.3132  max mem: 3615\n",
      "Training Epoch: [0]  [  750/14785]  eta: 2:47:20  lr: 0.000225  loss: 0.4171 (0.4608)  loss_objectness: 0.1396 (0.2056)  loss_rpn_box_reg: 0.2687 (0.2552)  time: 0.6969  data: 0.3268  max mem: 3615\n",
      "Training Epoch: [0]  [  760/14785]  eta: 2:47:07  lr: 0.000228  loss: 0.4051 (0.4598)  loss_objectness: 0.1476 (0.2050)  loss_rpn_box_reg: 0.2687 (0.2548)  time: 0.6847  data: 0.3204  max mem: 3615\n",
      "Training Epoch: [0]  [  770/14785]  eta: 2:47:00  lr: 0.000231  loss: 0.3775 (0.4588)  loss_objectness: 0.1529 (0.2045)  loss_rpn_box_reg: 0.2097 (0.2543)  time: 0.6978  data: 0.3223  max mem: 3615\n",
      "Training Epoch: [0]  [  780/14785]  eta: 2:46:46  lr: 0.000234  loss: 0.3329 (0.4579)  loss_objectness: 0.1529 (0.2042)  loss_rpn_box_reg: 0.1793 (0.2536)  time: 0.6969  data: 0.3260  max mem: 3615\n",
      "Training Epoch: [0]  [  790/14785]  eta: 2:46:39  lr: 0.000237  loss: 0.3329 (0.4566)  loss_objectness: 0.1410 (0.2038)  loss_rpn_box_reg: 0.1793 (0.2528)  time: 0.6982  data: 0.3188  max mem: 3615\n",
      "Training Epoch: [0]  [  800/14785]  eta: 2:46:26  lr: 0.000240  loss: 0.3797 (0.4557)  loss_objectness: 0.1459 (0.2032)  loss_rpn_box_reg: 0.2267 (0.2525)  time: 0.6977  data: 0.3144  max mem: 3615\n",
      "Training Epoch: [0]  [  810/14785]  eta: 2:46:14  lr: 0.000243  loss: 0.3624 (0.4549)  loss_objectness: 0.1559 (0.2031)  loss_rpn_box_reg: 0.2267 (0.2518)  time: 0.6834  data: 0.3129  max mem: 3615\n",
      "Training Epoch: [0]  [  820/14785]  eta: 2:46:11  lr: 0.000246  loss: 0.3619 (0.4538)  loss_objectness: 0.1399 (0.2021)  loss_rpn_box_reg: 0.2198 (0.2517)  time: 0.7120  data: 0.3257  max mem: 3615\n",
      "Training Epoch: [0]  [  830/14785]  eta: 2:45:58  lr: 0.000249  loss: 0.3679 (0.4536)  loss_objectness: 0.1295 (0.2018)  loss_rpn_box_reg: 0.2304 (0.2518)  time: 0.7083  data: 0.3287  max mem: 3615\n",
      "Training Epoch: [0]  [  840/14785]  eta: 2:45:47  lr: 0.000252  loss: 0.3732 (0.4527)  loss_objectness: 0.1599 (0.2015)  loss_rpn_box_reg: 0.2208 (0.2512)  time: 0.6856  data: 0.3203  max mem: 3615\n",
      "Training Epoch: [0]  [  850/14785]  eta: 2:45:39  lr: 0.000255  loss: 0.3638 (0.4517)  loss_objectness: 0.1435 (0.2008)  loss_rpn_box_reg: 0.2037 (0.2509)  time: 0.6980  data: 0.3146  max mem: 3615\n",
      "Training Epoch: [0]  [  860/14785]  eta: 2:45:26  lr: 0.000258  loss: 0.3661 (0.4518)  loss_objectness: 0.1496 (0.2003)  loss_rpn_box_reg: 0.2143 (0.2515)  time: 0.6922  data: 0.3105  max mem: 3615\n",
      "Training Epoch: [0]  [  870/14785]  eta: 2:45:17  lr: 0.000261  loss: 0.3909 (0.4512)  loss_objectness: 0.1500 (0.1997)  loss_rpn_box_reg: 0.2214 (0.2515)  time: 0.6903  data: 0.3147  max mem: 3615\n",
      "Training Epoch: [0]  [  880/14785]  eta: 2:45:06  lr: 0.000264  loss: 0.3447 (0.4504)  loss_objectness: 0.1224 (0.1990)  loss_rpn_box_reg: 0.2214 (0.2515)  time: 0.6933  data: 0.3145  max mem: 3615\n",
      "Training Epoch: [0]  [  890/14785]  eta: 2:44:57  lr: 0.000267  loss: 0.3967 (0.4502)  loss_objectness: 0.1343 (0.1988)  loss_rpn_box_reg: 0.2195 (0.2515)  time: 0.6947  data: 0.3162  max mem: 3615\n",
      "Training Epoch: [0]  [  900/14785]  eta: 2:44:47  lr: 0.000270  loss: 0.4149 (0.4499)  loss_objectness: 0.1629 (0.1983)  loss_rpn_box_reg: 0.2452 (0.2516)  time: 0.6984  data: 0.3222  max mem: 3615\n",
      "Training Epoch: [0]  [  910/14785]  eta: 2:44:34  lr: 0.000273  loss: 0.4083 (0.4492)  loss_objectness: 0.1519 (0.1980)  loss_rpn_box_reg: 0.2390 (0.2512)  time: 0.6836  data: 0.3146  max mem: 3615\n",
      "Training Epoch: [0]  [  920/14785]  eta: 2:44:24  lr: 0.000276  loss: 0.3785 (0.4482)  loss_objectness: 0.1409 (0.1974)  loss_rpn_box_reg: 0.2210 (0.2508)  time: 0.6839  data: 0.3152  max mem: 3615\n",
      "Training Epoch: [0]  [  930/14785]  eta: 2:44:18  lr: 0.000279  loss: 0.3396 (0.4474)  loss_objectness: 0.1415 (0.1969)  loss_rpn_box_reg: 0.1972 (0.2505)  time: 0.7051  data: 0.3213  max mem: 3615\n",
      "Training Epoch: [0]  [  940/14785]  eta: 2:44:07  lr: 0.000282  loss: 0.3647 (0.4474)  loss_objectness: 0.1509 (0.1967)  loss_rpn_box_reg: 0.2215 (0.2507)  time: 0.7001  data: 0.3193  max mem: 3615\n",
      "Training Epoch: [0]  [  950/14785]  eta: 2:43:57  lr: 0.000285  loss: 0.4408 (0.4473)  loss_objectness: 0.1685 (0.1965)  loss_rpn_box_reg: 0.2746 (0.2508)  time: 0.6889  data: 0.3177  max mem: 3615\n",
      "Training Epoch: [0]  [  960/14785]  eta: 2:43:49  lr: 0.000288  loss: 0.3881 (0.4462)  loss_objectness: 0.1677 (0.1961)  loss_rpn_box_reg: 0.2204 (0.2501)  time: 0.6987  data: 0.3189  max mem: 3615\n",
      "Training Epoch: [0]  [  970/14785]  eta: 2:43:34  lr: 0.000291  loss: 0.3427 (0.4453)  loss_objectness: 0.1690 (0.1959)  loss_rpn_box_reg: 0.1787 (0.2495)  time: 0.6796  data: 0.3147  max mem: 3615\n",
      "Training Epoch: [0]  [  980/14785]  eta: 2:43:24  lr: 0.000294  loss: 0.3941 (0.4449)  loss_objectness: 0.1529 (0.1954)  loss_rpn_box_reg: 0.1934 (0.2495)  time: 0.6742  data: 0.3086  max mem: 3615\n",
      "Training Epoch: [0]  [  990/14785]  eta: 2:43:11  lr: 0.000297  loss: 0.3334 (0.4439)  loss_objectness: 0.1359 (0.1948)  loss_rpn_box_reg: 0.2082 (0.2491)  time: 0.6763  data: 0.3020  max mem: 3615\n",
      "Training Epoch: [0]  [ 1000/14785]  eta: 2:43:00  lr: 0.000300  loss: 0.3856 (0.4440)  loss_objectness: 0.1443 (0.1946)  loss_rpn_box_reg: 0.2466 (0.2494)  time: 0.6720  data: 0.3049  max mem: 3615\n",
      "Training Epoch: [0]  [ 1010/14785]  eta: 2:42:53  lr: 0.000300  loss: 0.4333 (0.4438)  loss_objectness: 0.1626 (0.1942)  loss_rpn_box_reg: 0.3031 (0.2496)  time: 0.6984  data: 0.3116  max mem: 3615\n",
      "Training Epoch: [0]  [ 1020/14785]  eta: 2:42:44  lr: 0.000300  loss: 0.3685 (0.4435)  loss_objectness: 0.1355 (0.1937)  loss_rpn_box_reg: 0.2209 (0.2498)  time: 0.7037  data: 0.3132  max mem: 3615\n",
      "Training Epoch: [0]  [ 1030/14785]  eta: 2:42:36  lr: 0.000300  loss: 0.3266 (0.4421)  loss_objectness: 0.1264 (0.1932)  loss_rpn_box_reg: 0.1913 (0.2489)  time: 0.6964  data: 0.3170  max mem: 3615\n",
      "Training Epoch: [0]  [ 1040/14785]  eta: 2:42:27  lr: 0.000300  loss: 0.2975 (0.4414)  loss_objectness: 0.1299 (0.1926)  loss_rpn_box_reg: 0.1730 (0.2487)  time: 0.6996  data: 0.3158  max mem: 3615\n",
      "Training Epoch: [0]  [ 1050/14785]  eta: 2:42:19  lr: 0.000300  loss: 0.2975 (0.4401)  loss_objectness: 0.1379 (0.1921)  loss_rpn_box_reg: 0.1857 (0.2481)  time: 0.7011  data: 0.3120  max mem: 3615\n",
      "Training Epoch: [0]  [ 1060/14785]  eta: 2:42:09  lr: 0.000300  loss: 0.2935 (0.4391)  loss_objectness: 0.1246 (0.1915)  loss_rpn_box_reg: 0.1656 (0.2476)  time: 0.6945  data: 0.3099  max mem: 3615\n",
      "Training Epoch: [0]  [ 1070/14785]  eta: 2:41:56  lr: 0.000300  loss: 0.3043 (0.4381)  loss_objectness: 0.1197 (0.1910)  loss_rpn_box_reg: 0.1821 (0.2471)  time: 0.6735  data: 0.3066  max mem: 3615\n",
      "Training Epoch: [0]  [ 1080/14785]  eta: 2:41:43  lr: 0.000300  loss: 0.3762 (0.4381)  loss_objectness: 0.1515 (0.1911)  loss_rpn_box_reg: 0.1991 (0.2470)  time: 0.6631  data: 0.3043  max mem: 3615\n",
      "Training Epoch: [0]  [ 1090/14785]  eta: 2:41:34  lr: 0.000300  loss: 0.4149 (0.4371)  loss_objectness: 0.1568 (0.1908)  loss_rpn_box_reg: 0.1991 (0.2463)  time: 0.6771  data: 0.3109  max mem: 3615\n",
      "Training Epoch: [0]  [ 1100/14785]  eta: 2:41:23  lr: 0.000300  loss: 0.3123 (0.4365)  loss_objectness: 0.1513 (0.1907)  loss_rpn_box_reg: 0.1480 (0.2458)  time: 0.6842  data: 0.3135  max mem: 3615\n",
      "Training Epoch: [0]  [ 1110/14785]  eta: 2:41:14  lr: 0.000300  loss: 0.3788 (0.4365)  loss_objectness: 0.1454 (0.1904)  loss_rpn_box_reg: 0.2214 (0.2461)  time: 0.6865  data: 0.3140  max mem: 3615\n",
      "Training Epoch: [0]  [ 1120/14785]  eta: 2:41:05  lr: 0.000300  loss: 0.3788 (0.4365)  loss_objectness: 0.1382 (0.1900)  loss_rpn_box_reg: 0.2649 (0.2465)  time: 0.6927  data: 0.3174  max mem: 3615\n",
      "Training Epoch: [0]  [ 1130/14785]  eta: 2:40:59  lr: 0.000300  loss: 0.3472 (0.4360)  loss_objectness: 0.1367 (0.1894)  loss_rpn_box_reg: 0.2144 (0.2465)  time: 0.7020  data: 0.3165  max mem: 3615\n",
      "Training Epoch: [0]  [ 1140/14785]  eta: 2:40:48  lr: 0.000300  loss: 0.3308 (0.4354)  loss_objectness: 0.1204 (0.1889)  loss_rpn_box_reg: 0.2153 (0.2465)  time: 0.6942  data: 0.3167  max mem: 3615\n",
      "Training Epoch: [0]  [ 1150/14785]  eta: 2:40:39  lr: 0.000300  loss: 0.3442 (0.4346)  loss_objectness: 0.1204 (0.1885)  loss_rpn_box_reg: 0.1971 (0.2461)  time: 0.6842  data: 0.3199  max mem: 3615\n",
      "Training Epoch: [0]  [ 1160/14785]  eta: 2:40:32  lr: 0.000300  loss: 0.3637 (0.4342)  loss_objectness: 0.1509 (0.1882)  loss_rpn_box_reg: 0.2152 (0.2461)  time: 0.6998  data: 0.3160  max mem: 3615\n",
      "Training Epoch: [0]  [ 1170/14785]  eta: 2:40:18  lr: 0.000300  loss: 0.4039 (0.4346)  loss_objectness: 0.1680 (0.1881)  loss_rpn_box_reg: 0.2625 (0.2464)  time: 0.6764  data: 0.3047  max mem: 3615\n",
      "Training Epoch: [0]  [ 1180/14785]  eta: 2:40:13  lr: 0.000300  loss: 0.3956 (0.4342)  loss_objectness: 0.1795 (0.1878)  loss_rpn_box_reg: 0.2226 (0.2464)  time: 0.6825  data: 0.3075  max mem: 3615\n",
      "Training Epoch: [0]  [ 1190/14785]  eta: 2:40:06  lr: 0.000300  loss: 0.3787 (0.4341)  loss_objectness: 0.1357 (0.1875)  loss_rpn_box_reg: 0.2226 (0.2466)  time: 0.7137  data: 0.3222  max mem: 3615\n",
      "Training Epoch: [0]  [ 1200/14785]  eta: 2:39:55  lr: 0.000300  loss: 0.3942 (0.4337)  loss_objectness: 0.1456 (0.1871)  loss_rpn_box_reg: 0.2140 (0.2465)  time: 0.6924  data: 0.3190  max mem: 3615\n",
      "Training Epoch: [0]  [ 1210/14785]  eta: 2:39:44  lr: 0.000300  loss: 0.3507 (0.4331)  loss_objectness: 0.1361 (0.1868)  loss_rpn_box_reg: 0.2071 (0.2463)  time: 0.6733  data: 0.3070  max mem: 3615\n",
      "Training Epoch: [0]  [ 1220/14785]  eta: 2:39:34  lr: 0.000300  loss: 0.3509 (0.4331)  loss_objectness: 0.1314 (0.1867)  loss_rpn_box_reg: 0.2026 (0.2464)  time: 0.6757  data: 0.3092  max mem: 3615\n",
      "Training Epoch: [0]  [ 1230/14785]  eta: 2:39:27  lr: 0.000300  loss: 0.3967 (0.4335)  loss_objectness: 0.1639 (0.1868)  loss_rpn_box_reg: 0.2545 (0.2467)  time: 0.6908  data: 0.3129  max mem: 3615\n",
      "Training Epoch: [0]  [ 1240/14785]  eta: 2:39:20  lr: 0.000300  loss: 0.3468 (0.4326)  loss_objectness: 0.1634 (0.1866)  loss_rpn_box_reg: 0.1867 (0.2460)  time: 0.7072  data: 0.3161  max mem: 3615\n",
      "Training Epoch: [0]  [ 1250/14785]  eta: 2:39:11  lr: 0.000300  loss: 0.3649 (0.4327)  loss_objectness: 0.1591 (0.1864)  loss_rpn_box_reg: 0.1814 (0.2463)  time: 0.6981  data: 0.3171  max mem: 3615\n",
      "Training Epoch: [0]  [ 1260/14785]  eta: 2:39:02  lr: 0.000300  loss: 0.3925 (0.4328)  loss_objectness: 0.1297 (0.1862)  loss_rpn_box_reg: 0.2509 (0.2466)  time: 0.6881  data: 0.3170  max mem: 3615\n",
      "Training Epoch: [0]  [ 1270/14785]  eta: 2:38:53  lr: 0.000300  loss: 0.3404 (0.4322)  loss_objectness: 0.1297 (0.1859)  loss_rpn_box_reg: 0.1951 (0.2463)  time: 0.6878  data: 0.3132  max mem: 3615\n",
      "Training Epoch: [0]  [ 1280/14785]  eta: 2:38:45  lr: 0.000300  loss: 0.3300 (0.4316)  loss_objectness: 0.1364 (0.1857)  loss_rpn_box_reg: 0.1634 (0.2458)  time: 0.6876  data: 0.3126  max mem: 3615\n",
      "Training Epoch: [0]  [ 1290/14785]  eta: 2:38:38  lr: 0.000300  loss: 0.3627 (0.4314)  loss_objectness: 0.1573 (0.1855)  loss_rpn_box_reg: 0.1895 (0.2459)  time: 0.7042  data: 0.3187  max mem: 3615\n",
      "Training Epoch: [0]  [ 1300/14785]  eta: 2:38:30  lr: 0.000300  loss: 0.4176 (0.4314)  loss_objectness: 0.1573 (0.1853)  loss_rpn_box_reg: 0.2288 (0.2461)  time: 0.7018  data: 0.3171  max mem: 3615\n",
      "Training Epoch: [0]  [ 1310/14785]  eta: 2:38:23  lr: 0.000300  loss: 0.4049 (0.4310)  loss_objectness: 0.1464 (0.1851)  loss_rpn_box_reg: 0.2288 (0.2459)  time: 0.6965  data: 0.3164  max mem: 3615\n",
      "Training Epoch: [0]  [ 1320/14785]  eta: 2:38:12  lr: 0.000300  loss: 0.3569 (0.4306)  loss_objectness: 0.1464 (0.1849)  loss_rpn_box_reg: 0.2008 (0.2458)  time: 0.6881  data: 0.3094  max mem: 3615\n",
      "Training Epoch: [0]  [ 1330/14785]  eta: 2:38:03  lr: 0.000300  loss: 0.3678 (0.4307)  loss_objectness: 0.1626 (0.1847)  loss_rpn_box_reg: 0.2117 (0.2460)  time: 0.6794  data: 0.3081  max mem: 3615\n",
      "Training Epoch: [0]  [ 1340/14785]  eta: 2:37:56  lr: 0.000300  loss: 0.3678 (0.4301)  loss_objectness: 0.1489 (0.1844)  loss_rpn_box_reg: 0.2117 (0.2457)  time: 0.6968  data: 0.3175  max mem: 3615\n",
      "Training Epoch: [0]  [ 1350/14785]  eta: 2:37:47  lr: 0.000300  loss: 0.3266 (0.4296)  loss_objectness: 0.1419 (0.1842)  loss_rpn_box_reg: 0.1913 (0.2454)  time: 0.6917  data: 0.3158  max mem: 3615\n",
      "Training Epoch: [0]  [ 1360/14785]  eta: 2:37:38  lr: 0.000300  loss: 0.2954 (0.4288)  loss_objectness: 0.1424 (0.1839)  loss_rpn_box_reg: 0.1748 (0.2450)  time: 0.6857  data: 0.3156  max mem: 3615\n",
      "Training Epoch: [0]  [ 1370/14785]  eta: 2:37:27  lr: 0.000300  loss: 0.2954 (0.4283)  loss_objectness: 0.1424 (0.1836)  loss_rpn_box_reg: 0.1571 (0.2447)  time: 0.6745  data: 0.3156  max mem: 3615\n",
      "Training Epoch: [0]  [ 1380/14785]  eta: 2:37:19  lr: 0.000300  loss: 0.3389 (0.4278)  loss_objectness: 0.1518 (0.1833)  loss_rpn_box_reg: 0.1985 (0.2445)  time: 0.6752  data: 0.3086  max mem: 3615\n",
      "Training Epoch: [0]  [ 1390/14785]  eta: 2:37:08  lr: 0.000300  loss: 0.3246 (0.4271)  loss_objectness: 0.1290 (0.1829)  loss_rpn_box_reg: 0.1809 (0.2442)  time: 0.6798  data: 0.3080  max mem: 3615\n",
      "Training Epoch: [0]  [ 1400/14785]  eta: 2:36:57  lr: 0.000300  loss: 0.3230 (0.4265)  loss_objectness: 0.1273 (0.1826)  loss_rpn_box_reg: 0.1580 (0.2438)  time: 0.6639  data: 0.3102  max mem: 3615\n",
      "Training Epoch: [0]  [ 1410/14785]  eta: 2:36:48  lr: 0.000300  loss: 0.3454 (0.4262)  loss_objectness: 0.1563 (0.1825)  loss_rpn_box_reg: 0.1806 (0.2437)  time: 0.6740  data: 0.3088  max mem: 3615\n",
      "Training Epoch: [0]  [ 1420/14785]  eta: 2:36:38  lr: 0.000300  loss: 0.3704 (0.4255)  loss_objectness: 0.1538 (0.1822)  loss_rpn_box_reg: 0.1834 (0.2433)  time: 0.6762  data: 0.3052  max mem: 3615\n",
      "Training Epoch: [0]  [ 1430/14785]  eta: 2:36:27  lr: 0.000300  loss: 0.3239 (0.4251)  loss_objectness: 0.1281 (0.1820)  loss_rpn_box_reg: 0.1834 (0.2431)  time: 0.6654  data: 0.2991  max mem: 3615\n",
      "Training Epoch: [0]  [ 1440/14785]  eta: 2:36:19  lr: 0.000300  loss: 0.3723 (0.4249)  loss_objectness: 0.1383 (0.1817)  loss_rpn_box_reg: 0.2503 (0.2431)  time: 0.6763  data: 0.3058  max mem: 3615\n",
      "Training Epoch: [0]  [ 1450/14785]  eta: 2:36:11  lr: 0.000300  loss: 0.3699 (0.4248)  loss_objectness: 0.1471 (0.1816)  loss_rpn_box_reg: 0.2372 (0.2432)  time: 0.6925  data: 0.3102  max mem: 3615\n",
      "Training Epoch: [0]  [ 1460/14785]  eta: 2:36:01  lr: 0.000300  loss: 0.3679 (0.4245)  loss_objectness: 0.1432 (0.1813)  loss_rpn_box_reg: 0.2372 (0.2431)  time: 0.6853  data: 0.3091  max mem: 3615\n",
      "Training Epoch: [0]  [ 1470/14785]  eta: 2:35:53  lr: 0.000300  loss: 0.3160 (0.4236)  loss_objectness: 0.1408 (0.1810)  loss_rpn_box_reg: 0.1952 (0.2426)  time: 0.6827  data: 0.3105  max mem: 3615\n",
      "Training Epoch: [0]  [ 1480/14785]  eta: 2:35:42  lr: 0.000300  loss: 0.2983 (0.4239)  loss_objectness: 0.1408 (0.1810)  loss_rpn_box_reg: 0.2001 (0.2429)  time: 0.6719  data: 0.3036  max mem: 3615\n",
      "Training Epoch: [0]  [ 1490/14785]  eta: 2:35:32  lr: 0.000300  loss: 0.4819 (0.4241)  loss_objectness: 0.1516 (0.1809)  loss_rpn_box_reg: 0.2890 (0.2431)  time: 0.6607  data: 0.3043  max mem: 3615\n",
      "Training Epoch: [0]  [ 1500/14785]  eta: 2:35:24  lr: 0.000300  loss: 0.3561 (0.4232)  loss_objectness: 0.1226 (0.1805)  loss_rpn_box_reg: 0.2338 (0.2427)  time: 0.6823  data: 0.3014  max mem: 3615\n",
      "Training Epoch: [0]  [ 1510/14785]  eta: 2:35:15  lr: 0.000300  loss: 0.3591 (0.4231)  loss_objectness: 0.1295 (0.1803)  loss_rpn_box_reg: 0.2053 (0.2428)  time: 0.6850  data: 0.3000  max mem: 3615\n",
      "Training Epoch: [0]  [ 1520/14785]  eta: 2:35:07  lr: 0.000300  loss: 0.3703 (0.4226)  loss_objectness: 0.1367 (0.1802)  loss_rpn_box_reg: 0.2067 (0.2425)  time: 0.6825  data: 0.3036  max mem: 3615\n",
      "Training Epoch: [0]  [ 1530/14785]  eta: 2:34:59  lr: 0.000300  loss: 0.3632 (0.4221)  loss_objectness: 0.1324 (0.1799)  loss_rpn_box_reg: 0.2006 (0.2423)  time: 0.6901  data: 0.3078  max mem: 3615\n",
      "Training Epoch: [0]  [ 1540/14785]  eta: 2:34:51  lr: 0.000300  loss: 0.3497 (0.4223)  loss_objectness: 0.1374 (0.1796)  loss_rpn_box_reg: 0.2183 (0.2427)  time: 0.6913  data: 0.3100  max mem: 3615\n",
      "Training Epoch: [0]  [ 1550/14785]  eta: 2:34:43  lr: 0.000300  loss: 0.3240 (0.4215)  loss_objectness: 0.1342 (0.1792)  loss_rpn_box_reg: 0.2076 (0.2423)  time: 0.6895  data: 0.3065  max mem: 3615\n",
      "Training Epoch: [0]  [ 1560/14785]  eta: 2:34:34  lr: 0.000300  loss: 0.3240 (0.4214)  loss_objectness: 0.1207 (0.1792)  loss_rpn_box_reg: 0.2124 (0.2422)  time: 0.6834  data: 0.3105  max mem: 3615\n",
      "Training Epoch: [0]  [ 1570/14785]  eta: 2:34:25  lr: 0.000300  loss: 0.3813 (0.4212)  loss_objectness: 0.1623 (0.1790)  loss_rpn_box_reg: 0.2474 (0.2422)  time: 0.6784  data: 0.3108  max mem: 3615\n",
      "Training Epoch: [0]  [ 1580/14785]  eta: 2:34:15  lr: 0.000300  loss: 0.4082 (0.4214)  loss_objectness: 0.1373 (0.1789)  loss_rpn_box_reg: 0.2700 (0.2426)  time: 0.6745  data: 0.3033  max mem: 3615\n",
      "Training Epoch: [0]  [ 1590/14785]  eta: 2:34:04  lr: 0.000300  loss: 0.4239 (0.4216)  loss_objectness: 0.1463 (0.1787)  loss_rpn_box_reg: 0.2700 (0.2429)  time: 0.6602  data: 0.2980  max mem: 3615\n",
      "Training Epoch: [0]  [ 1600/14785]  eta: 2:33:55  lr: 0.000300  loss: 0.4013 (0.4214)  loss_objectness: 0.1434 (0.1786)  loss_rpn_box_reg: 0.2285 (0.2427)  time: 0.6610  data: 0.3029  max mem: 3615\n",
      "Training Epoch: [0]  [ 1610/14785]  eta: 2:33:46  lr: 0.000300  loss: 0.2854 (0.4209)  loss_objectness: 0.1339 (0.1785)  loss_rpn_box_reg: 0.1829 (0.2424)  time: 0.6757  data: 0.3034  max mem: 3615\n",
      "Training Epoch: [0]  [ 1620/14785]  eta: 2:33:37  lr: 0.000300  loss: 0.2672 (0.4203)  loss_objectness: 0.1429 (0.1782)  loss_rpn_box_reg: 0.1680 (0.2421)  time: 0.6761  data: 0.2997  max mem: 3615\n",
      "Training Epoch: [0]  [ 1630/14785]  eta: 2:33:26  lr: 0.000300  loss: 0.3106 (0.4198)  loss_objectness: 0.1366 (0.1781)  loss_rpn_box_reg: 0.1786 (0.2418)  time: 0.6643  data: 0.3043  max mem: 3615\n",
      "Training Epoch: [0]  [ 1640/14785]  eta: 2:33:19  lr: 0.000300  loss: 0.3566 (0.4200)  loss_objectness: 0.1366 (0.1779)  loss_rpn_box_reg: 0.2158 (0.2420)  time: 0.6768  data: 0.3054  max mem: 3615\n",
      "Training Epoch: [0]  [ 1650/14785]  eta: 2:33:13  lr: 0.000300  loss: 0.3566 (0.4198)  loss_objectness: 0.1218 (0.1777)  loss_rpn_box_reg: 0.2322 (0.2421)  time: 0.7081  data: 0.3089  max mem: 3615\n",
      "Training Epoch: [0]  [ 1660/14785]  eta: 2:33:02  lr: 0.000300  loss: 0.3427 (0.4197)  loss_objectness: 0.1356 (0.1776)  loss_rpn_box_reg: 0.2071 (0.2421)  time: 0.6798  data: 0.3034  max mem: 3615\n",
      "Training Epoch: [0]  [ 1670/14785]  eta: 2:32:55  lr: 0.000300  loss: 0.3427 (0.4195)  loss_objectness: 0.1432 (0.1774)  loss_rpn_box_reg: 0.1958 (0.2420)  time: 0.6711  data: 0.3024  max mem: 3615\n",
      "Training Epoch: [0]  [ 1680/14785]  eta: 2:32:45  lr: 0.000300  loss: 0.3892 (0.4195)  loss_objectness: 0.1438 (0.1773)  loss_rpn_box_reg: 0.2352 (0.2422)  time: 0.6821  data: 0.3053  max mem: 3615\n",
      "Training Epoch: [0]  [ 1690/14785]  eta: 2:32:37  lr: 0.000300  loss: 0.3987 (0.4196)  loss_objectness: 0.1438 (0.1772)  loss_rpn_box_reg: 0.2391 (0.2424)  time: 0.6744  data: 0.3000  max mem: 3615\n",
      "Training Epoch: [0]  [ 1700/14785]  eta: 2:32:27  lr: 0.000300  loss: 0.4288 (0.4195)  loss_objectness: 0.1547 (0.1771)  loss_rpn_box_reg: 0.2395 (0.2424)  time: 0.6728  data: 0.2970  max mem: 3615\n",
      "Training Epoch: [0]  [ 1710/14785]  eta: 2:32:21  lr: 0.000300  loss: 0.3497 (0.4192)  loss_objectness: 0.1528 (0.1769)  loss_rpn_box_reg: 0.2034 (0.2423)  time: 0.6842  data: 0.3046  max mem: 3615\n",
      "Training Epoch: [0]  [ 1720/14785]  eta: 2:32:13  lr: 0.000300  loss: 0.3497 (0.4189)  loss_objectness: 0.1252 (0.1767)  loss_rpn_box_reg: 0.1957 (0.2421)  time: 0.6991  data: 0.3163  max mem: 3615\n",
      "Training Epoch: [0]  [ 1730/14785]  eta: 2:32:03  lr: 0.000300  loss: 0.2779 (0.4179)  loss_objectness: 0.1120 (0.1763)  loss_rpn_box_reg: 0.1544 (0.2415)  time: 0.6752  data: 0.3127  max mem: 3615\n",
      "Training Epoch: [0]  [ 1740/14785]  eta: 2:31:54  lr: 0.000300  loss: 0.2629 (0.4175)  loss_objectness: 0.1094 (0.1761)  loss_rpn_box_reg: 0.1544 (0.2414)  time: 0.6644  data: 0.3082  max mem: 3615\n",
      "Training Epoch: [0]  [ 1750/14785]  eta: 2:31:46  lr: 0.000300  loss: 0.4067 (0.4178)  loss_objectness: 0.1551 (0.1762)  loss_rpn_box_reg: 0.2816 (0.2416)  time: 0.6761  data: 0.3076  max mem: 3615\n",
      "Training Epoch: [0]  [ 1760/14785]  eta: 2:31:38  lr: 0.000300  loss: 0.3830 (0.4174)  loss_objectness: 0.1420 (0.1760)  loss_rpn_box_reg: 0.2343 (0.2414)  time: 0.6869  data: 0.3059  max mem: 3615\n",
      "Training Epoch: [0]  [ 1770/14785]  eta: 2:31:30  lr: 0.000300  loss: 0.3358 (0.4173)  loss_objectness: 0.1325 (0.1758)  loss_rpn_box_reg: 0.1936 (0.2415)  time: 0.6877  data: 0.3098  max mem: 3615\n",
      "Training Epoch: [0]  [ 1780/14785]  eta: 2:31:20  lr: 0.000300  loss: 0.3549 (0.4174)  loss_objectness: 0.1586 (0.1758)  loss_rpn_box_reg: 0.1936 (0.2415)  time: 0.6677  data: 0.3026  max mem: 3615\n",
      "Training Epoch: [0]  [ 1790/14785]  eta: 2:31:10  lr: 0.000300  loss: 0.3549 (0.4168)  loss_objectness: 0.1586 (0.1756)  loss_rpn_box_reg: 0.1834 (0.2412)  time: 0.6568  data: 0.2946  max mem: 3615\n",
      "Training Epoch: [0]  [ 1800/14785]  eta: 2:31:00  lr: 0.000300  loss: 0.3126 (0.4167)  loss_objectness: 0.1396 (0.1756)  loss_rpn_box_reg: 0.1706 (0.2411)  time: 0.6603  data: 0.3032  max mem: 3615\n",
      "Training Epoch: [0]  [ 1810/14785]  eta: 2:30:51  lr: 0.000300  loss: 0.3167 (0.4164)  loss_objectness: 0.1524 (0.1755)  loss_rpn_box_reg: 0.2007 (0.2409)  time: 0.6613  data: 0.3053  max mem: 3615\n",
      "Training Epoch: [0]  [ 1820/14785]  eta: 2:30:43  lr: 0.000300  loss: 0.3167 (0.4160)  loss_objectness: 0.1329 (0.1753)  loss_rpn_box_reg: 0.1879 (0.2407)  time: 0.6704  data: 0.3036  max mem: 3615\n",
      "Training Epoch: [0]  [ 1830/14785]  eta: 2:30:34  lr: 0.000300  loss: 0.3397 (0.4157)  loss_objectness: 0.1312 (0.1751)  loss_rpn_box_reg: 0.1719 (0.2405)  time: 0.6785  data: 0.2955  max mem: 3615\n",
      "Training Epoch: [0]  [ 1840/14785]  eta: 2:30:26  lr: 0.000300  loss: 0.3988 (0.4156)  loss_objectness: 0.1414 (0.1750)  loss_rpn_box_reg: 0.2024 (0.2406)  time: 0.6816  data: 0.2988  max mem: 3615\n",
      "Training Epoch: [0]  [ 1850/14785]  eta: 2:30:20  lr: 0.000300  loss: 0.3558 (0.4153)  loss_objectness: 0.1401 (0.1748)  loss_rpn_box_reg: 0.2179 (0.2405)  time: 0.6977  data: 0.3109  max mem: 3615\n",
      "Training Epoch: [0]  [ 1860/14785]  eta: 2:30:13  lr: 0.000300  loss: 0.3302 (0.4150)  loss_objectness: 0.1362 (0.1746)  loss_rpn_box_reg: 0.1660 (0.2404)  time: 0.6993  data: 0.3108  max mem: 3615\n",
      "Training Epoch: [0]  [ 1870/14785]  eta: 2:30:04  lr: 0.000300  loss: 0.3639 (0.4147)  loss_objectness: 0.1384 (0.1745)  loss_rpn_box_reg: 0.1789 (0.2402)  time: 0.6798  data: 0.3006  max mem: 3615\n",
      "Training Epoch: [0]  [ 1880/14785]  eta: 2:29:56  lr: 0.000300  loss: 0.3519 (0.4145)  loss_objectness: 0.1379 (0.1744)  loss_rpn_box_reg: 0.2247 (0.2401)  time: 0.6765  data: 0.3053  max mem: 3615\n",
      "Training Epoch: [0]  [ 1890/14785]  eta: 2:29:47  lr: 0.000300  loss: 0.3519 (0.4143)  loss_objectness: 0.1543 (0.1743)  loss_rpn_box_reg: 0.2152 (0.2400)  time: 0.6750  data: 0.3124  max mem: 3615\n",
      "Training Epoch: [0]  [ 1900/14785]  eta: 2:29:40  lr: 0.000300  loss: 0.3889 (0.4140)  loss_objectness: 0.1515 (0.1741)  loss_rpn_box_reg: 0.2192 (0.2399)  time: 0.6822  data: 0.3071  max mem: 3615\n",
      "Training Epoch: [0]  [ 1910/14785]  eta: 2:29:30  lr: 0.000300  loss: 0.3315 (0.4134)  loss_objectness: 0.1335 (0.1739)  loss_rpn_box_reg: 0.1899 (0.2395)  time: 0.6721  data: 0.2975  max mem: 3615\n",
      "Training Epoch: [0]  [ 1920/14785]  eta: 2:29:20  lr: 0.000300  loss: 0.3471 (0.4135)  loss_objectness: 0.1498 (0.1739)  loss_rpn_box_reg: 0.1899 (0.2396)  time: 0.6553  data: 0.2920  max mem: 3615\n",
      "Training Epoch: [0]  [ 1930/14785]  eta: 2:29:12  lr: 0.000300  loss: 0.3471 (0.4129)  loss_objectness: 0.1538 (0.1738)  loss_rpn_box_reg: 0.1868 (0.2392)  time: 0.6687  data: 0.2977  max mem: 3615\n",
      "Training Epoch: [0]  [ 1940/14785]  eta: 2:29:03  lr: 0.000300  loss: 0.3027 (0.4130)  loss_objectness: 0.1474 (0.1738)  loss_rpn_box_reg: 0.1609 (0.2393)  time: 0.6740  data: 0.3006  max mem: 3615\n",
      "Training Epoch: [0]  [ 1950/14785]  eta: 2:28:54  lr: 0.000300  loss: 0.3594 (0.4127)  loss_objectness: 0.1672 (0.1737)  loss_rpn_box_reg: 0.1911 (0.2390)  time: 0.6668  data: 0.3067  max mem: 3615\n",
      "Training Epoch: [0]  [ 1960/14785]  eta: 2:28:45  lr: 0.000300  loss: 0.3328 (0.4125)  loss_objectness: 0.1457 (0.1736)  loss_rpn_box_reg: 0.1822 (0.2389)  time: 0.6616  data: 0.3090  max mem: 3615\n",
      "Training Epoch: [0]  [ 1970/14785]  eta: 2:28:37  lr: 0.000300  loss: 0.3530 (0.4124)  loss_objectness: 0.1424 (0.1734)  loss_rpn_box_reg: 0.2356 (0.2390)  time: 0.6735  data: 0.3068  max mem: 3615\n",
      "Training Epoch: [0]  [ 1980/14785]  eta: 2:28:30  lr: 0.000300  loss: 0.3798 (0.4124)  loss_objectness: 0.1430 (0.1734)  loss_rpn_box_reg: 0.2386 (0.2390)  time: 0.6870  data: 0.3050  max mem: 3615\n",
      "Training Epoch: [0]  [ 1990/14785]  eta: 2:28:21  lr: 0.000300  loss: 0.4116 (0.4126)  loss_objectness: 0.1549 (0.1734)  loss_rpn_box_reg: 0.2381 (0.2392)  time: 0.6784  data: 0.3027  max mem: 3615\n",
      "Training Epoch: [0]  [ 2000/14785]  eta: 2:28:11  lr: 0.000300  loss: 0.3741 (0.4124)  loss_objectness: 0.1492 (0.1733)  loss_rpn_box_reg: 0.2381 (0.2392)  time: 0.6548  data: 0.2960  max mem: 3615\n",
      "Training Epoch: [0]  [ 2010/14785]  eta: 2:28:03  lr: 0.000300  loss: 0.3752 (0.4124)  loss_objectness: 0.1464 (0.1732)  loss_rpn_box_reg: 0.2368 (0.2392)  time: 0.6640  data: 0.2959  max mem: 3615\n",
      "Training Epoch: [0]  [ 2020/14785]  eta: 2:27:54  lr: 0.000300  loss: 0.3723 (0.4121)  loss_objectness: 0.1386 (0.1731)  loss_rpn_box_reg: 0.1984 (0.2390)  time: 0.6699  data: 0.2995  max mem: 3615\n",
      "Training Epoch: [0]  [ 2030/14785]  eta: 2:27:46  lr: 0.000300  loss: 0.3723 (0.4122)  loss_objectness: 0.1386 (0.1730)  loss_rpn_box_reg: 0.2265 (0.2392)  time: 0.6692  data: 0.3023  max mem: 3615\n",
      "Training Epoch: [0]  [ 2040/14785]  eta: 2:27:38  lr: 0.000300  loss: 0.3590 (0.4118)  loss_objectness: 0.1363 (0.1729)  loss_rpn_box_reg: 0.2265 (0.2389)  time: 0.6790  data: 0.3011  max mem: 3615\n",
      "Training Epoch: [0]  [ 2050/14785]  eta: 2:27:28  lr: 0.000300  loss: 0.3113 (0.4116)  loss_objectness: 0.1281 (0.1727)  loss_rpn_box_reg: 0.1642 (0.2389)  time: 0.6661  data: 0.2908  max mem: 3615\n",
      "Training Epoch: [0]  [ 2060/14785]  eta: 2:27:20  lr: 0.000300  loss: 0.3483 (0.4115)  loss_objectness: 0.1419 (0.1727)  loss_rpn_box_reg: 0.1940 (0.2388)  time: 0.6624  data: 0.3032  max mem: 3615\n",
      "Training Epoch: [0]  [ 2070/14785]  eta: 2:27:12  lr: 0.000300  loss: 0.3493 (0.4114)  loss_objectness: 0.1337 (0.1725)  loss_rpn_box_reg: 0.2012 (0.2388)  time: 0.6727  data: 0.3024  max mem: 3615\n",
      "Training Epoch: [0]  [ 2080/14785]  eta: 2:27:04  lr: 0.000300  loss: 0.3562 (0.4112)  loss_objectness: 0.1337 (0.1724)  loss_rpn_box_reg: 0.2355 (0.2387)  time: 0.6802  data: 0.2893  max mem: 3615\n",
      "Training Epoch: [0]  [ 2090/14785]  eta: 2:26:55  lr: 0.000300  loss: 0.3497 (0.4108)  loss_objectness: 0.1357 (0.1723)  loss_rpn_box_reg: 0.2149 (0.2385)  time: 0.6744  data: 0.2974  max mem: 3615\n",
      "Training Epoch: [0]  [ 2100/14785]  eta: 2:26:47  lr: 0.000300  loss: 0.3552 (0.4107)  loss_objectness: 0.1286 (0.1721)  loss_rpn_box_reg: 0.2129 (0.2386)  time: 0.6671  data: 0.2994  max mem: 3615\n",
      "Training Epoch: [0]  [ 2110/14785]  eta: 2:26:38  lr: 0.000300  loss: 0.3604 (0.4105)  loss_objectness: 0.1486 (0.1721)  loss_rpn_box_reg: 0.2119 (0.2384)  time: 0.6667  data: 0.3056  max mem: 3615\n",
      "Training Epoch: [0]  [ 2120/14785]  eta: 2:26:30  lr: 0.000300  loss: 0.3222 (0.4103)  loss_objectness: 0.1476 (0.1720)  loss_rpn_box_reg: 0.1760 (0.2383)  time: 0.6659  data: 0.3037  max mem: 3615\n",
      "Training Epoch: [0]  [ 2130/14785]  eta: 2:26:21  lr: 0.000300  loss: 0.3882 (0.4102)  loss_objectness: 0.1574 (0.1721)  loss_rpn_box_reg: 0.1825 (0.2382)  time: 0.6665  data: 0.2925  max mem: 3615\n",
      "Training Epoch: [0]  [ 2140/14785]  eta: 2:26:12  lr: 0.000300  loss: 0.4034 (0.4103)  loss_objectness: 0.1695 (0.1720)  loss_rpn_box_reg: 0.2198 (0.2384)  time: 0.6635  data: 0.2970  max mem: 3615\n",
      "Training Epoch: [0]  [ 2150/14785]  eta: 2:26:04  lr: 0.000300  loss: 0.3633 (0.4105)  loss_objectness: 0.1695 (0.1720)  loss_rpn_box_reg: 0.2310 (0.2385)  time: 0.6650  data: 0.3051  max mem: 3615\n",
      "Training Epoch: [0]  [ 2160/14785]  eta: 2:25:55  lr: 0.000300  loss: 0.3325 (0.4100)  loss_objectness: 0.1407 (0.1718)  loss_rpn_box_reg: 0.2002 (0.2382)  time: 0.6673  data: 0.3040  max mem: 3615\n",
      "Training Epoch: [0]  [ 2170/14785]  eta: 2:25:47  lr: 0.000300  loss: 0.3611 (0.4101)  loss_objectness: 0.1509 (0.1717)  loss_rpn_box_reg: 0.2002 (0.2383)  time: 0.6659  data: 0.3049  max mem: 3615\n",
      "Training Epoch: [0]  [ 2180/14785]  eta: 2:25:39  lr: 0.000300  loss: 0.3422 (0.4098)  loss_objectness: 0.1399 (0.1716)  loss_rpn_box_reg: 0.2095 (0.2382)  time: 0.6693  data: 0.3042  max mem: 3615\n",
      "Training Epoch: [0]  [ 2190/14785]  eta: 2:25:31  lr: 0.000300  loss: 0.3422 (0.4095)  loss_objectness: 0.1290 (0.1714)  loss_rpn_box_reg: 0.2068 (0.2381)  time: 0.6749  data: 0.3020  max mem: 3615\n",
      "Training Epoch: [0]  [ 2200/14785]  eta: 2:25:21  lr: 0.000300  loss: 0.3522 (0.4092)  loss_objectness: 0.1245 (0.1713)  loss_rpn_box_reg: 0.2002 (0.2379)  time: 0.6654  data: 0.3050  max mem: 3615\n",
      "Training Epoch: [0]  [ 2210/14785]  eta: 2:25:13  lr: 0.000300  loss: 0.3521 (0.4091)  loss_objectness: 0.1377 (0.1712)  loss_rpn_box_reg: 0.2144 (0.2379)  time: 0.6572  data: 0.3048  max mem: 3615\n",
      "Training Epoch: [0]  [ 2220/14785]  eta: 2:25:05  lr: 0.000300  loss: 0.3636 (0.4088)  loss_objectness: 0.1362 (0.1710)  loss_rpn_box_reg: 0.2230 (0.2378)  time: 0.6707  data: 0.2975  max mem: 3615\n",
      "Training Epoch: [0]  [ 2230/14785]  eta: 2:24:57  lr: 0.000300  loss: 0.3669 (0.4088)  loss_objectness: 0.1226 (0.1709)  loss_rpn_box_reg: 0.2409 (0.2379)  time: 0.6740  data: 0.2877  max mem: 3615\n",
      "Training Epoch: [0]  [ 2240/14785]  eta: 2:24:48  lr: 0.000300  loss: 0.3911 (0.4088)  loss_objectness: 0.1545 (0.1708)  loss_rpn_box_reg: 0.2476 (0.2380)  time: 0.6651  data: 0.2906  max mem: 3615\n",
      "Training Epoch: [0]  [ 2250/14785]  eta: 2:24:39  lr: 0.000300  loss: 0.3779 (0.4085)  loss_objectness: 0.1320 (0.1707)  loss_rpn_box_reg: 0.2195 (0.2378)  time: 0.6594  data: 0.3024  max mem: 3615\n",
      "Training Epoch: [0]  [ 2260/14785]  eta: 2:24:31  lr: 0.000300  loss: 0.3190 (0.4081)  loss_objectness: 0.1267 (0.1706)  loss_rpn_box_reg: 0.1970 (0.2376)  time: 0.6613  data: 0.3033  max mem: 3615\n",
      "Training Epoch: [0]  [ 2270/14785]  eta: 2:24:24  lr: 0.000300  loss: 0.3190 (0.4078)  loss_objectness: 0.1351 (0.1704)  loss_rpn_box_reg: 0.1864 (0.2374)  time: 0.6806  data: 0.3118  max mem: 3615\n",
      "Training Epoch: [0]  [ 2280/14785]  eta: 2:24:14  lr: 0.000300  loss: 0.3216 (0.4077)  loss_objectness: 0.1331 (0.1703)  loss_rpn_box_reg: 0.1864 (0.2374)  time: 0.6684  data: 0.3119  max mem: 3615\n",
      "Training Epoch: [0]  [ 2290/14785]  eta: 2:24:08  lr: 0.000300  loss: 0.3496 (0.4079)  loss_objectness: 0.1286 (0.1702)  loss_rpn_box_reg: 0.2416 (0.2377)  time: 0.6693  data: 0.3059  max mem: 3615\n",
      "Training Epoch: [0]  [ 2300/14785]  eta: 2:24:00  lr: 0.000300  loss: 0.3811 (0.4075)  loss_objectness: 0.1350 (0.1700)  loss_rpn_box_reg: 0.2615 (0.2376)  time: 0.6920  data: 0.3085  max mem: 3615\n",
      "Training Epoch: [0]  [ 2310/14785]  eta: 2:23:51  lr: 0.000300  loss: 0.3528 (0.4075)  loss_objectness: 0.1450 (0.1701)  loss_rpn_box_reg: 0.2088 (0.2374)  time: 0.6670  data: 0.2988  max mem: 3615\n",
      "Training Epoch: [0]  [ 2320/14785]  eta: 2:23:44  lr: 0.000300  loss: 0.3166 (0.4072)  loss_objectness: 0.1488 (0.1699)  loss_rpn_box_reg: 0.1772 (0.2373)  time: 0.6663  data: 0.2996  max mem: 3615\n",
      "Training Epoch: [0]  [ 2330/14785]  eta: 2:23:35  lr: 0.000300  loss: 0.2925 (0.4067)  loss_objectness: 0.1328 (0.1697)  loss_rpn_box_reg: 0.1730 (0.2370)  time: 0.6705  data: 0.2983  max mem: 3615\n",
      "Training Epoch: [0]  [ 2340/14785]  eta: 2:23:28  lr: 0.000300  loss: 0.3294 (0.4068)  loss_objectness: 0.1355 (0.1697)  loss_rpn_box_reg: 0.2102 (0.2371)  time: 0.6702  data: 0.2980  max mem: 3615\n",
      "Training Epoch: [0]  [ 2350/14785]  eta: 2:23:20  lr: 0.000300  loss: 0.3906 (0.4068)  loss_objectness: 0.1381 (0.1696)  loss_rpn_box_reg: 0.2318 (0.2371)  time: 0.6824  data: 0.3050  max mem: 3615\n",
      "Training Epoch: [0]  [ 2360/14785]  eta: 2:23:12  lr: 0.000300  loss: 0.3444 (0.4064)  loss_objectness: 0.1381 (0.1695)  loss_rpn_box_reg: 0.2185 (0.2369)  time: 0.6750  data: 0.2979  max mem: 3615\n",
      "Training Epoch: [0]  [ 2370/14785]  eta: 2:23:04  lr: 0.000300  loss: 0.3387 (0.4066)  loss_objectness: 0.1597 (0.1695)  loss_rpn_box_reg: 0.2093 (0.2371)  time: 0.6651  data: 0.2919  max mem: 3615\n",
      "Training Epoch: [0]  [ 2380/14785]  eta: 2:22:56  lr: 0.000300  loss: 0.3766 (0.4067)  loss_objectness: 0.1639 (0.1695)  loss_rpn_box_reg: 0.2206 (0.2372)  time: 0.6707  data: 0.3015  max mem: 3615\n",
      "Training Epoch: [0]  [ 2390/14785]  eta: 2:22:47  lr: 0.000300  loss: 0.3519 (0.4064)  loss_objectness: 0.1488 (0.1694)  loss_rpn_box_reg: 0.2071 (0.2370)  time: 0.6652  data: 0.3003  max mem: 3615\n",
      "Training Epoch: [0]  [ 2400/14785]  eta: 2:22:40  lr: 0.000300  loss: 0.3472 (0.4063)  loss_objectness: 0.1488 (0.1693)  loss_rpn_box_reg: 0.1984 (0.2371)  time: 0.6713  data: 0.2978  max mem: 3615\n",
      "Training Epoch: [0]  [ 2410/14785]  eta: 2:22:32  lr: 0.000300  loss: 0.3831 (0.4063)  loss_objectness: 0.1477 (0.1693)  loss_rpn_box_reg: 0.2125 (0.2370)  time: 0.6764  data: 0.2962  max mem: 3615\n",
      "Training Epoch: [0]  [ 2420/14785]  eta: 2:22:24  lr: 0.000300  loss: 0.3707 (0.4062)  loss_objectness: 0.1477 (0.1692)  loss_rpn_box_reg: 0.2125 (0.2370)  time: 0.6705  data: 0.2939  max mem: 3615\n",
      "Training Epoch: [0]  [ 2430/14785]  eta: 2:22:16  lr: 0.000300  loss: 0.3571 (0.4061)  loss_objectness: 0.1302 (0.1692)  loss_rpn_box_reg: 0.2031 (0.2370)  time: 0.6779  data: 0.2985  max mem: 3615\n",
      "Training Epoch: [0]  [ 2440/14785]  eta: 2:22:09  lr: 0.000300  loss: 0.3446 (0.4063)  loss_objectness: 0.1524 (0.1692)  loss_rpn_box_reg: 0.2144 (0.2371)  time: 0.6785  data: 0.3032  max mem: 3615\n",
      "Training Epoch: [0]  [ 2450/14785]  eta: 2:22:01  lr: 0.000300  loss: 0.3531 (0.4062)  loss_objectness: 0.1303 (0.1690)  loss_rpn_box_reg: 0.2362 (0.2372)  time: 0.6731  data: 0.3045  max mem: 3615\n",
      "Training Epoch: [0]  [ 2460/14785]  eta: 2:21:53  lr: 0.000300  loss: 0.3361 (0.4058)  loss_objectness: 0.1225 (0.1689)  loss_rpn_box_reg: 0.2271 (0.2369)  time: 0.6645  data: 0.2893  max mem: 3615\n",
      "Training Epoch: [0]  [ 2470/14785]  eta: 2:21:45  lr: 0.000300  loss: 0.2898 (0.4058)  loss_objectness: 0.1402 (0.1688)  loss_rpn_box_reg: 0.1577 (0.2369)  time: 0.6693  data: 0.2779  max mem: 3615\n",
      "Training Epoch: [0]  [ 2480/14785]  eta: 2:21:37  lr: 0.000300  loss: 0.4037 (0.4058)  loss_objectness: 0.1402 (0.1688)  loss_rpn_box_reg: 0.2710 (0.2370)  time: 0.6719  data: 0.2855  max mem: 3615\n",
      "Training Epoch: [0]  [ 2490/14785]  eta: 2:21:29  lr: 0.000300  loss: 0.3510 (0.4058)  loss_objectness: 0.1453 (0.1687)  loss_rpn_box_reg: 0.2234 (0.2371)  time: 0.6730  data: 0.2975  max mem: 3615\n",
      "Training Epoch: [0]  [ 2500/14785]  eta: 2:21:22  lr: 0.000300  loss: 0.3952 (0.4061)  loss_objectness: 0.1453 (0.1687)  loss_rpn_box_reg: 0.2590 (0.2373)  time: 0.6799  data: 0.3014  max mem: 3615\n",
      "Training Epoch: [0]  [ 2510/14785]  eta: 2:21:15  lr: 0.000300  loss: 0.3952 (0.4060)  loss_objectness: 0.1359 (0.1686)  loss_rpn_box_reg: 0.2694 (0.2374)  time: 0.6855  data: 0.2987  max mem: 3615\n",
      "Training Epoch: [0]  [ 2520/14785]  eta: 2:21:05  lr: 0.000300  loss: 0.3698 (0.4060)  loss_objectness: 0.1380 (0.1686)  loss_rpn_box_reg: 0.2075 (0.2374)  time: 0.6609  data: 0.2940  max mem: 3615\n",
      "Training Epoch: [0]  [ 2530/14785]  eta: 2:20:55  lr: 0.000300  loss: 0.3620 (0.4059)  loss_objectness: 0.1581 (0.1686)  loss_rpn_box_reg: 0.1882 (0.2373)  time: 0.6305  data: 0.2865  max mem: 3615\n",
      "Training Epoch: [0]  [ 2540/14785]  eta: 2:20:47  lr: 0.000300  loss: 0.3662 (0.4059)  loss_objectness: 0.1445 (0.1686)  loss_rpn_box_reg: 0.1802 (0.2373)  time: 0.6424  data: 0.2827  max mem: 3615\n",
      "Training Epoch: [0]  [ 2550/14785]  eta: 2:20:39  lr: 0.000300  loss: 0.4471 (0.4061)  loss_objectness: 0.1501 (0.1685)  loss_rpn_box_reg: 0.2731 (0.2376)  time: 0.6618  data: 0.2882  max mem: 3615\n",
      "Training Epoch: [0]  [ 2560/14785]  eta: 2:20:32  lr: 0.000300  loss: 0.4471 (0.4060)  loss_objectness: 0.1501 (0.1685)  loss_rpn_box_reg: 0.2731 (0.2376)  time: 0.6753  data: 0.2967  max mem: 3615\n",
      "Training Epoch: [0]  [ 2570/14785]  eta: 2:20:24  lr: 0.000300  loss: 0.3529 (0.4059)  loss_objectness: 0.1427 (0.1684)  loss_rpn_box_reg: 0.2057 (0.2375)  time: 0.6729  data: 0.3003  max mem: 3615\n",
      "Training Epoch: [0]  [ 2580/14785]  eta: 2:20:15  lr: 0.000300  loss: 0.3814 (0.4060)  loss_objectness: 0.1528 (0.1685)  loss_rpn_box_reg: 0.2057 (0.2375)  time: 0.6593  data: 0.2964  max mem: 3615\n",
      "Training Epoch: [0]  [ 2590/14785]  eta: 2:20:08  lr: 0.000300  loss: 0.3778 (0.4057)  loss_objectness: 0.1437 (0.1683)  loss_rpn_box_reg: 0.2093 (0.2374)  time: 0.6761  data: 0.2955  max mem: 3615\n",
      "Training Epoch: [0]  [ 2600/14785]  eta: 2:20:01  lr: 0.000300  loss: 0.3451 (0.4058)  loss_objectness: 0.1281 (0.1682)  loss_rpn_box_reg: 0.2296 (0.2376)  time: 0.6839  data: 0.2984  max mem: 3615\n",
      "Training Epoch: [0]  [ 2610/14785]  eta: 2:19:52  lr: 0.000300  loss: 0.3451 (0.4056)  loss_objectness: 0.1249 (0.1681)  loss_rpn_box_reg: 0.2108 (0.2375)  time: 0.6647  data: 0.2995  max mem: 3615\n",
      "Training Epoch: [0]  [ 2620/14785]  eta: 2:19:45  lr: 0.000300  loss: 0.3423 (0.4056)  loss_objectness: 0.1249 (0.1681)  loss_rpn_box_reg: 0.2024 (0.2375)  time: 0.6703  data: 0.2934  max mem: 3615\n",
      "Training Epoch: [0]  [ 2630/14785]  eta: 2:19:37  lr: 0.000300  loss: 0.3333 (0.4054)  loss_objectness: 0.1387 (0.1679)  loss_rpn_box_reg: 0.2150 (0.2374)  time: 0.6740  data: 0.2841  max mem: 3615\n",
      "Training Epoch: [0]  [ 2640/14785]  eta: 2:19:29  lr: 0.000300  loss: 0.3421 (0.4053)  loss_objectness: 0.1306 (0.1678)  loss_rpn_box_reg: 0.2176 (0.2375)  time: 0.6656  data: 0.2854  max mem: 3615\n",
      "Training Epoch: [0]  [ 2650/14785]  eta: 2:19:21  lr: 0.000300  loss: 0.3186 (0.4048)  loss_objectness: 0.1197 (0.1677)  loss_rpn_box_reg: 0.1748 (0.2371)  time: 0.6580  data: 0.2871  max mem: 3615\n",
      "Training Epoch: [0]  [ 2660/14785]  eta: 2:19:14  lr: 0.000300  loss: 0.3146 (0.4048)  loss_objectness: 0.1185 (0.1676)  loss_rpn_box_reg: 0.1529 (0.2372)  time: 0.6692  data: 0.2910  max mem: 3615\n",
      "Training Epoch: [0]  [ 2670/14785]  eta: 2:19:06  lr: 0.000300  loss: 0.3870 (0.4049)  loss_objectness: 0.1525 (0.1675)  loss_rpn_box_reg: 0.2633 (0.2374)  time: 0.6831  data: 0.2969  max mem: 3615\n",
      "Training Epoch: [0]  [ 2680/14785]  eta: 2:18:58  lr: 0.000300  loss: 0.3870 (0.4049)  loss_objectness: 0.1506 (0.1675)  loss_rpn_box_reg: 0.2377 (0.2374)  time: 0.6668  data: 0.2925  max mem: 3615\n",
      "Training Epoch: [0]  [ 2690/14785]  eta: 2:18:50  lr: 0.000300  loss: 0.3735 (0.4048)  loss_objectness: 0.1604 (0.1675)  loss_rpn_box_reg: 0.1911 (0.2374)  time: 0.6653  data: 0.2909  max mem: 3615\n",
      "Training Epoch: [0]  [ 2700/14785]  eta: 2:18:42  lr: 0.000300  loss: 0.3480 (0.4047)  loss_objectness: 0.1473 (0.1674)  loss_rpn_box_reg: 0.1829 (0.2373)  time: 0.6684  data: 0.2914  max mem: 3615\n",
      "Training Epoch: [0]  [ 2710/14785]  eta: 2:18:33  lr: 0.000300  loss: 0.3038 (0.4046)  loss_objectness: 0.1441 (0.1674)  loss_rpn_box_reg: 0.1657 (0.2372)  time: 0.6499  data: 0.2920  max mem: 3615\n",
      "Training Epoch: [0]  [ 2720/14785]  eta: 2:18:25  lr: 0.000300  loss: 0.3397 (0.4044)  loss_objectness: 0.1481 (0.1673)  loss_rpn_box_reg: 0.1959 (0.2371)  time: 0.6444  data: 0.2899  max mem: 3615\n",
      "Training Epoch: [0]  [ 2730/14785]  eta: 2:18:16  lr: 0.000300  loss: 0.3879 (0.4043)  loss_objectness: 0.1481 (0.1672)  loss_rpn_box_reg: 0.2080 (0.2371)  time: 0.6525  data: 0.2884  max mem: 3615\n",
      "Training Epoch: [0]  [ 2740/14785]  eta: 2:18:09  lr: 0.000300  loss: 0.3371 (0.4040)  loss_objectness: 0.1291 (0.1670)  loss_rpn_box_reg: 0.1689 (0.2369)  time: 0.6675  data: 0.2949  max mem: 3615\n",
      "Training Epoch: [0]  [ 2750/14785]  eta: 2:18:01  lr: 0.000300  loss: 0.3244 (0.4039)  loss_objectness: 0.1128 (0.1669)  loss_rpn_box_reg: 0.1739 (0.2370)  time: 0.6731  data: 0.2991  max mem: 3615\n",
      "Training Epoch: [0]  [ 2760/14785]  eta: 2:17:53  lr: 0.000300  loss: 0.3994 (0.4039)  loss_objectness: 0.1389 (0.1669)  loss_rpn_box_reg: 0.2049 (0.2370)  time: 0.6664  data: 0.2938  max mem: 3615\n",
      "Training Epoch: [0]  [ 2770/14785]  eta: 2:17:45  lr: 0.000300  loss: 0.4093 (0.4039)  loss_objectness: 0.1391 (0.1668)  loss_rpn_box_reg: 0.2463 (0.2371)  time: 0.6671  data: 0.2841  max mem: 3615\n",
      "Training Epoch: [0]  [ 2780/14785]  eta: 2:17:37  lr: 0.000300  loss: 0.3649 (0.4037)  loss_objectness: 0.1305 (0.1667)  loss_rpn_box_reg: 0.2392 (0.2371)  time: 0.6563  data: 0.2844  max mem: 3615\n",
      "Training Epoch: [0]  [ 2790/14785]  eta: 2:17:29  lr: 0.000300  loss: 0.3649 (0.4038)  loss_objectness: 0.1305 (0.1666)  loss_rpn_box_reg: 0.2132 (0.2372)  time: 0.6609  data: 0.2908  max mem: 3615\n",
      "Training Epoch: [0]  [ 2800/14785]  eta: 2:17:21  lr: 0.000300  loss: 0.3268 (0.4035)  loss_objectness: 0.1451 (0.1665)  loss_rpn_box_reg: 0.2013 (0.2370)  time: 0.6612  data: 0.2935  max mem: 3615\n",
      "Training Epoch: [0]  [ 2810/14785]  eta: 2:17:12  lr: 0.000300  loss: 0.2904 (0.4033)  loss_objectness: 0.1452 (0.1665)  loss_rpn_box_reg: 0.1566 (0.2369)  time: 0.6439  data: 0.2851  max mem: 3615\n",
      "Training Epoch: [0]  [ 2820/14785]  eta: 2:17:04  lr: 0.000300  loss: 0.2724 (0.4030)  loss_objectness: 0.1451 (0.1664)  loss_rpn_box_reg: 0.1584 (0.2367)  time: 0.6536  data: 0.2838  max mem: 3615\n",
      "Training Epoch: [0]  [ 2830/14785]  eta: 2:16:57  lr: 0.000300  loss: 0.3067 (0.4029)  loss_objectness: 0.1279 (0.1663)  loss_rpn_box_reg: 0.1789 (0.2367)  time: 0.6794  data: 0.2921  max mem: 3615\n",
      "Training Epoch: [0]  [ 2840/14785]  eta: 2:16:49  lr: 0.000300  loss: 0.3677 (0.4031)  loss_objectness: 0.1673 (0.1664)  loss_rpn_box_reg: 0.2105 (0.2367)  time: 0.6744  data: 0.2955  max mem: 3615\n",
      "Training Epoch: [0]  [ 2850/14785]  eta: 2:16:41  lr: 0.000300  loss: 0.4064 (0.4031)  loss_objectness: 0.1673 (0.1664)  loss_rpn_box_reg: 0.2216 (0.2367)  time: 0.6593  data: 0.3019  max mem: 3615\n",
      "Training Epoch: [0]  [ 2860/14785]  eta: 2:16:34  lr: 0.000300  loss: 0.2958 (0.4027)  loss_objectness: 0.1111 (0.1662)  loss_rpn_box_reg: 0.1710 (0.2365)  time: 0.6706  data: 0.2997  max mem: 3615\n",
      "Training Epoch: [0]  [ 2870/14785]  eta: 2:16:26  lr: 0.000300  loss: 0.3203 (0.4028)  loss_objectness: 0.1360 (0.1663)  loss_rpn_box_reg: 0.1908 (0.2366)  time: 0.6694  data: 0.2927  max mem: 3615\n",
      "Training Epoch: [0]  [ 2880/14785]  eta: 2:16:18  lr: 0.000300  loss: 0.3338 (0.4026)  loss_objectness: 0.1518 (0.1662)  loss_rpn_box_reg: 0.1882 (0.2364)  time: 0.6604  data: 0.2957  max mem: 3615\n",
      "Training Epoch: [0]  [ 2890/14785]  eta: 2:16:10  lr: 0.000300  loss: 0.3338 (0.4026)  loss_objectness: 0.1420 (0.1661)  loss_rpn_box_reg: 0.1888 (0.2365)  time: 0.6618  data: 0.2970  max mem: 3615\n",
      "Training Epoch: [0]  [ 2900/14785]  eta: 2:16:04  lr: 0.000300  loss: 0.3421 (0.4023)  loss_objectness: 0.1182 (0.1660)  loss_rpn_box_reg: 0.2223 (0.2364)  time: 0.6774  data: 0.2920  max mem: 3615\n",
      "Training Epoch: [0]  [ 2910/14785]  eta: 2:15:56  lr: 0.000300  loss: 0.3884 (0.4026)  loss_objectness: 0.1227 (0.1661)  loss_rpn_box_reg: 0.2223 (0.2365)  time: 0.6746  data: 0.2933  max mem: 3615\n",
      "Training Epoch: [0]  [ 2920/14785]  eta: 2:15:47  lr: 0.000300  loss: 0.4393 (0.4028)  loss_objectness: 0.1681 (0.1661)  loss_rpn_box_reg: 0.2677 (0.2367)  time: 0.6550  data: 0.2974  max mem: 3615\n",
      "Training Epoch: [0]  [ 2930/14785]  eta: 2:15:40  lr: 0.000300  loss: 0.3881 (0.4026)  loss_objectness: 0.1477 (0.1660)  loss_rpn_box_reg: 0.2548 (0.2366)  time: 0.6670  data: 0.2926  max mem: 3615\n",
      "Training Epoch: [0]  [ 2940/14785]  eta: 2:15:32  lr: 0.000300  loss: 0.2968 (0.4024)  loss_objectness: 0.1477 (0.1660)  loss_rpn_box_reg: 0.1497 (0.2363)  time: 0.6667  data: 0.2892  max mem: 3615\n",
      "Training Epoch: [0]  [ 2950/14785]  eta: 2:15:24  lr: 0.000300  loss: 0.2998 (0.4023)  loss_objectness: 0.1402 (0.1659)  loss_rpn_box_reg: 0.1544 (0.2364)  time: 0.6593  data: 0.2879  max mem: 3615\n",
      "Training Epoch: [0]  [ 2960/14785]  eta: 2:15:16  lr: 0.000300  loss: 0.3120 (0.4021)  loss_objectness: 0.1408 (0.1659)  loss_rpn_box_reg: 0.1965 (0.2362)  time: 0.6629  data: 0.2858  max mem: 3615\n",
      "Training Epoch: [0]  [ 2970/14785]  eta: 2:15:08  lr: 0.000300  loss: 0.2996 (0.4018)  loss_objectness: 0.1432 (0.1658)  loss_rpn_box_reg: 0.1818 (0.2361)  time: 0.6560  data: 0.2832  max mem: 3615\n",
      "Training Epoch: [0]  [ 2980/14785]  eta: 2:15:01  lr: 0.000300  loss: 0.2885 (0.4016)  loss_objectness: 0.1257 (0.1657)  loss_rpn_box_reg: 0.1818 (0.2359)  time: 0.6681  data: 0.2911  max mem: 3615\n",
      "Training Epoch: [0]  [ 2990/14785]  eta: 2:14:54  lr: 0.000300  loss: 0.3337 (0.4017)  loss_objectness: 0.1433 (0.1656)  loss_rpn_box_reg: 0.1898 (0.2361)  time: 0.6769  data: 0.3052  max mem: 3615\n",
      "Training Epoch: [0]  [ 3000/14785]  eta: 2:14:44  lr: 0.000300  loss: 0.3697 (0.4016)  loss_objectness: 0.1477 (0.1656)  loss_rpn_box_reg: 0.2357 (0.2360)  time: 0.6397  data: 0.2983  max mem: 3615\n",
      "Training Epoch: [0]  [ 3010/14785]  eta: 2:14:36  lr: 0.000300  loss: 0.3697 (0.4017)  loss_objectness: 0.1477 (0.1656)  loss_rpn_box_reg: 0.2071 (0.2361)  time: 0.6392  data: 0.2930  max mem: 3615\n",
      "Training Epoch: [0]  [ 3020/14785]  eta: 2:14:29  lr: 0.000300  loss: 0.3884 (0.4016)  loss_objectness: 0.1382 (0.1655)  loss_rpn_box_reg: 0.2303 (0.2361)  time: 0.6653  data: 0.2922  max mem: 3615\n",
      "Training Epoch: [0]  [ 3030/14785]  eta: 2:14:21  lr: 0.000300  loss: 0.3442 (0.4014)  loss_objectness: 0.1338 (0.1654)  loss_rpn_box_reg: 0.2201 (0.2360)  time: 0.6620  data: 0.2900  max mem: 3615\n",
      "Training Epoch: [0]  [ 3040/14785]  eta: 2:14:13  lr: 0.000300  loss: 0.3245 (0.4012)  loss_objectness: 0.1379 (0.1654)  loss_rpn_box_reg: 0.1637 (0.2358)  time: 0.6573  data: 0.2925  max mem: 3615\n",
      "Training Epoch: [0]  [ 3050/14785]  eta: 2:14:05  lr: 0.000300  loss: 0.3702 (0.4014)  loss_objectness: 0.1578 (0.1654)  loss_rpn_box_reg: 0.1853 (0.2360)  time: 0.6556  data: 0.2839  max mem: 3615\n",
      "Training Epoch: [0]  [ 3060/14785]  eta: 2:13:57  lr: 0.000300  loss: 0.4505 (0.4015)  loss_objectness: 0.1663 (0.1654)  loss_rpn_box_reg: 0.2577 (0.2361)  time: 0.6623  data: 0.2835  max mem: 3615\n",
      "Training Epoch: [0]  [ 3070/14785]  eta: 2:13:50  lr: 0.000300  loss: 0.3981 (0.4013)  loss_objectness: 0.1405 (0.1653)  loss_rpn_box_reg: 0.2164 (0.2360)  time: 0.6701  data: 0.2842  max mem: 3615\n",
      "Training Epoch: [0]  [ 3080/14785]  eta: 2:13:42  lr: 0.000300  loss: 0.3981 (0.4012)  loss_objectness: 0.1315 (0.1652)  loss_rpn_box_reg: 0.1833 (0.2360)  time: 0.6619  data: 0.2863  max mem: 3615\n",
      "Training Epoch: [0]  [ 3090/14785]  eta: 2:13:34  lr: 0.000300  loss: 0.3900 (0.4011)  loss_objectness: 0.1277 (0.1652)  loss_rpn_box_reg: 0.2385 (0.2360)  time: 0.6617  data: 0.2899  max mem: 3615\n",
      "Training Epoch: [0]  [ 3100/14785]  eta: 2:13:26  lr: 0.000300  loss: 0.3778 (0.4011)  loss_objectness: 0.1375 (0.1652)  loss_rpn_box_reg: 0.2164 (0.2360)  time: 0.6605  data: 0.2891  max mem: 3615\n",
      "Training Epoch: [0]  [ 3110/14785]  eta: 2:13:19  lr: 0.000300  loss: 0.4460 (0.4013)  loss_objectness: 0.1530 (0.1652)  loss_rpn_box_reg: 0.2315 (0.2361)  time: 0.6647  data: 0.2920  max mem: 3615\n",
      "Training Epoch: [0]  [ 3120/14785]  eta: 2:13:11  lr: 0.000300  loss: 0.4228 (0.4012)  loss_objectness: 0.1436 (0.1651)  loss_rpn_box_reg: 0.2830 (0.2362)  time: 0.6677  data: 0.2878  max mem: 3615\n",
      "Training Epoch: [0]  [ 3130/14785]  eta: 2:13:03  lr: 0.000300  loss: 0.3410 (0.4010)  loss_objectness: 0.1326 (0.1650)  loss_rpn_box_reg: 0.2075 (0.2360)  time: 0.6594  data: 0.2882  max mem: 3615\n",
      "Training Epoch: [0]  [ 3140/14785]  eta: 2:12:55  lr: 0.000300  loss: 0.2782 (0.4008)  loss_objectness: 0.1391 (0.1649)  loss_rpn_box_reg: 0.1528 (0.2358)  time: 0.6568  data: 0.2862  max mem: 3615\n",
      "Training Epoch: [0]  [ 3150/14785]  eta: 2:12:50  lr: 0.000300  loss: 0.3232 (0.4008)  loss_objectness: 0.1443 (0.1649)  loss_rpn_box_reg: 0.1895 (0.2358)  time: 0.6848  data: 0.3156  max mem: 3615\n",
      "Training Epoch: [0]  [ 3160/14785]  eta: 2:13:15  lr: 0.000300  loss: 0.4055 (0.4009)  loss_objectness: 0.1623 (0.1650)  loss_rpn_box_reg: 0.2347 (0.2359)  time: 1.1374  data: 0.7696  max mem: 3615\n",
      "Training Epoch: [0]  [ 3170/14785]  eta: 2:13:07  lr: 0.000300  loss: 0.4033 (0.4009)  loss_objectness: 0.1498 (0.1649)  loss_rpn_box_reg: 0.2321 (0.2359)  time: 1.1136  data: 0.7445  max mem: 3615\n",
      "Training Epoch: [0]  [ 3180/14785]  eta: 2:12:58  lr: 0.000300  loss: 0.3396 (0.4008)  loss_objectness: 0.1371 (0.1649)  loss_rpn_box_reg: 0.2110 (0.2359)  time: 0.6520  data: 0.2950  max mem: 3615\n",
      "Training Epoch: [0]  [ 3190/14785]  eta: 2:12:50  lr: 0.000300  loss: 0.3270 (0.4008)  loss_objectness: 0.1340 (0.1648)  loss_rpn_box_reg: 0.1924 (0.2359)  time: 0.6408  data: 0.2873  max mem: 3615\n",
      "Training Epoch: [0]  [ 3200/14785]  eta: 2:12:43  lr: 0.000300  loss: 0.3270 (0.4007)  loss_objectness: 0.1340 (0.1647)  loss_rpn_box_reg: 0.1924 (0.2359)  time: 0.6651  data: 0.2822  max mem: 3615\n",
      "Training Epoch: [0]  [ 3210/14785]  eta: 2:12:35  lr: 0.000300  loss: 0.3034 (0.4005)  loss_objectness: 0.1168 (0.1647)  loss_rpn_box_reg: 0.1873 (0.2358)  time: 0.6618  data: 0.2820  max mem: 3615\n",
      "Training Epoch: [0]  [ 3220/14785]  eta: 2:12:28  lr: 0.000300  loss: 0.3034 (0.4003)  loss_objectness: 0.1183 (0.1646)  loss_rpn_box_reg: 0.1829 (0.2357)  time: 0.6628  data: 0.2855  max mem: 3615\n",
      "Training Epoch: [0]  [ 3230/14785]  eta: 2:12:20  lr: 0.000300  loss: 0.3184 (0.4002)  loss_objectness: 0.1400 (0.1645)  loss_rpn_box_reg: 0.1829 (0.2356)  time: 0.6732  data: 0.2843  max mem: 3615\n",
      "Training Epoch: [0]  [ 3240/14785]  eta: 2:12:12  lr: 0.000300  loss: 0.3184 (0.4001)  loss_objectness: 0.1609 (0.1645)  loss_rpn_box_reg: 0.1784 (0.2356)  time: 0.6685  data: 0.2822  max mem: 3615\n",
      "Training Epoch: [0]  [ 3250/14785]  eta: 2:12:05  lr: 0.000300  loss: 0.2814 (0.3998)  loss_objectness: 0.1471 (0.1644)  loss_rpn_box_reg: 0.1365 (0.2354)  time: 0.6710  data: 0.2896  max mem: 3615\n",
      "Training Epoch: [0]  [ 3260/14785]  eta: 2:11:57  lr: 0.000300  loss: 0.2814 (0.3995)  loss_objectness: 0.1381 (0.1644)  loss_rpn_box_reg: 0.1344 (0.2352)  time: 0.6675  data: 0.2884  max mem: 3615\n",
      "Training Epoch: [0]  [ 3270/14785]  eta: 2:11:49  lr: 0.000300  loss: 0.2970 (0.3993)  loss_objectness: 0.1380 (0.1643)  loss_rpn_box_reg: 0.1621 (0.2350)  time: 0.6606  data: 0.2856  max mem: 3615\n",
      "Training Epoch: [0]  [ 3280/14785]  eta: 2:11:42  lr: 0.000300  loss: 0.2852 (0.3990)  loss_objectness: 0.1356 (0.1642)  loss_rpn_box_reg: 0.1496 (0.2348)  time: 0.6588  data: 0.2824  max mem: 3615\n",
      "Training Epoch: [0]  [ 3290/14785]  eta: 2:11:34  lr: 0.000300  loss: 0.3396 (0.3992)  loss_objectness: 0.1471 (0.1642)  loss_rpn_box_reg: 0.2158 (0.2350)  time: 0.6585  data: 0.2778  max mem: 3615\n",
      "Training Epoch: [0]  [ 3300/14785]  eta: 2:11:26  lr: 0.000300  loss: 0.3706 (0.3991)  loss_objectness: 0.1412 (0.1641)  loss_rpn_box_reg: 0.2280 (0.2349)  time: 0.6571  data: 0.2833  max mem: 3615\n",
      "Training Epoch: [0]  [ 3310/14785]  eta: 2:11:17  lr: 0.000300  loss: 0.3601 (0.3990)  loss_objectness: 0.1393 (0.1641)  loss_rpn_box_reg: 0.2280 (0.2349)  time: 0.6523  data: 0.2751  max mem: 3615\n",
      "Training Epoch: [0]  [ 3320/14785]  eta: 2:11:10  lr: 0.000300  loss: 0.3761 (0.3989)  loss_objectness: 0.1462 (0.1640)  loss_rpn_box_reg: 0.2133 (0.2349)  time: 0.6497  data: 0.2726  max mem: 3615\n",
      "Training Epoch: [0]  [ 3330/14785]  eta: 2:11:02  lr: 0.000300  loss: 0.2777 (0.3988)  loss_objectness: 0.1194 (0.1639)  loss_rpn_box_reg: 0.1801 (0.2349)  time: 0.6568  data: 0.2846  max mem: 3615\n",
      "Training Epoch: [0]  [ 3340/14785]  eta: 2:10:55  lr: 0.000300  loss: 0.2985 (0.3986)  loss_objectness: 0.1216 (0.1639)  loss_rpn_box_reg: 0.1686 (0.2348)  time: 0.6679  data: 0.2907  max mem: 3615\n",
      "Training Epoch: [0]  [ 3350/14785]  eta: 2:10:46  lr: 0.000300  loss: 0.3239 (0.3986)  loss_objectness: 0.1281 (0.1638)  loss_rpn_box_reg: 0.1930 (0.2348)  time: 0.6615  data: 0.2917  max mem: 3615\n",
      "Training Epoch: [0]  [ 3360/14785]  eta: 2:10:39  lr: 0.000300  loss: 0.3709 (0.3987)  loss_objectness: 0.1513 (0.1639)  loss_rpn_box_reg: 0.2019 (0.2348)  time: 0.6525  data: 0.2788  max mem: 3615\n",
      "Training Epoch: [0]  [ 3370/14785]  eta: 2:10:31  lr: 0.000300  loss: 0.3878 (0.3986)  loss_objectness: 0.1486 (0.1638)  loss_rpn_box_reg: 0.2075 (0.2348)  time: 0.6584  data: 0.2763  max mem: 3615\n",
      "Training Epoch: [0]  [ 3380/14785]  eta: 2:10:23  lr: 0.000300  loss: 0.3214 (0.3985)  loss_objectness: 0.1169 (0.1637)  loss_rpn_box_reg: 0.1965 (0.2348)  time: 0.6555  data: 0.2848  max mem: 3615\n",
      "Training Epoch: [0]  [ 3390/14785]  eta: 2:10:15  lr: 0.000300  loss: 0.3092 (0.3983)  loss_objectness: 0.1280 (0.1636)  loss_rpn_box_reg: 0.1957 (0.2347)  time: 0.6627  data: 0.2898  max mem: 3615\n",
      "Training Epoch: [0]  [ 3400/14785]  eta: 2:10:07  lr: 0.000300  loss: 0.3125 (0.3982)  loss_objectness: 0.1342 (0.1636)  loss_rpn_box_reg: 0.1768 (0.2346)  time: 0.6565  data: 0.2894  max mem: 3615\n",
      "Training Epoch: [0]  [ 3410/14785]  eta: 2:10:00  lr: 0.000300  loss: 0.3307 (0.3982)  loss_objectness: 0.1347 (0.1636)  loss_rpn_box_reg: 0.1938 (0.2347)  time: 0.6585  data: 0.2946  max mem: 3615\n",
      "Training Epoch: [0]  [ 3420/14785]  eta: 2:09:53  lr: 0.000300  loss: 0.3800 (0.3981)  loss_objectness: 0.1347 (0.1635)  loss_rpn_box_reg: 0.2138 (0.2346)  time: 0.6747  data: 0.2915  max mem: 3615\n",
      "Training Epoch: [0]  [ 3430/14785]  eta: 2:09:45  lr: 0.000300  loss: 0.3424 (0.3981)  loss_objectness: 0.1200 (0.1634)  loss_rpn_box_reg: 0.1969 (0.2347)  time: 0.6736  data: 0.2857  max mem: 3615\n",
      "Training Epoch: [0]  [ 3440/14785]  eta: 2:09:37  lr: 0.000300  loss: 0.3424 (0.3979)  loss_objectness: 0.1149 (0.1633)  loss_rpn_box_reg: 0.1969 (0.2346)  time: 0.6627  data: 0.2891  max mem: 3615\n",
      "Training Epoch: [0]  [ 3450/14785]  eta: 2:09:31  lr: 0.000300  loss: 0.3117 (0.3978)  loss_objectness: 0.1324 (0.1633)  loss_rpn_box_reg: 0.1840 (0.2346)  time: 0.6745  data: 0.2878  max mem: 3615\n",
      "Training Epoch: [0]  [ 3460/14785]  eta: 2:09:22  lr: 0.000300  loss: 0.3196 (0.3977)  loss_objectness: 0.1403 (0.1633)  loss_rpn_box_reg: 0.1840 (0.2344)  time: 0.6679  data: 0.2918  max mem: 3615\n",
      "Training Epoch: [0]  [ 3470/14785]  eta: 2:09:15  lr: 0.000300  loss: 0.3316 (0.3976)  loss_objectness: 0.1468 (0.1632)  loss_rpn_box_reg: 0.1704 (0.2344)  time: 0.6453  data: 0.2890  max mem: 3615\n",
      "Training Epoch: [0]  [ 3480/14785]  eta: 2:09:07  lr: 0.000300  loss: 0.3257 (0.3974)  loss_objectness: 0.1468 (0.1632)  loss_rpn_box_reg: 0.1704 (0.2343)  time: 0.6510  data: 0.2791  max mem: 3615\n",
      "Training Epoch: [0]  [ 3490/14785]  eta: 2:08:59  lr: 0.000300  loss: 0.3538 (0.3974)  loss_objectness: 0.1402 (0.1631)  loss_rpn_box_reg: 0.2065 (0.2343)  time: 0.6564  data: 0.2807  max mem: 3615\n",
      "Training Epoch: [0]  [ 3500/14785]  eta: 2:08:50  lr: 0.000300  loss: 0.3259 (0.3971)  loss_objectness: 0.1250 (0.1630)  loss_rpn_box_reg: 0.2000 (0.2341)  time: 0.6421  data: 0.2816  max mem: 3615\n",
      "Training Epoch: [0]  [ 3510/14785]  eta: 2:08:42  lr: 0.000300  loss: 0.3365 (0.3971)  loss_objectness: 0.1339 (0.1630)  loss_rpn_box_reg: 0.1723 (0.2341)  time: 0.6339  data: 0.2784  max mem: 3615\n",
      "Training Epoch: [0]  [ 3520/14785]  eta: 2:08:35  lr: 0.000300  loss: 0.4224 (0.3971)  loss_objectness: 0.1468 (0.1629)  loss_rpn_box_reg: 0.2372 (0.2342)  time: 0.6573  data: 0.2848  max mem: 3615\n",
      "Training Epoch: [0]  [ 3530/14785]  eta: 2:08:26  lr: 0.000300  loss: 0.3346 (0.3970)  loss_objectness: 0.1447 (0.1629)  loss_rpn_box_reg: 0.2031 (0.2341)  time: 0.6499  data: 0.2820  max mem: 3615\n",
      "Training Epoch: [0]  [ 3540/14785]  eta: 2:08:18  lr: 0.000300  loss: 0.3582 (0.3971)  loss_objectness: 0.1432 (0.1629)  loss_rpn_box_reg: 0.2287 (0.2342)  time: 0.6381  data: 0.2792  max mem: 3615\n",
      "Training Epoch: [0]  [ 3550/14785]  eta: 2:08:11  lr: 0.000300  loss: 0.3608 (0.3972)  loss_objectness: 0.1482 (0.1629)  loss_rpn_box_reg: 0.2343 (0.2343)  time: 0.6601  data: 0.2852  max mem: 3615\n",
      "Training Epoch: [0]  [ 3560/14785]  eta: 2:08:49  lr: 0.000300  loss: 0.3608 (0.3971)  loss_objectness: 0.1482 (0.1628)  loss_rpn_box_reg: 0.2334 (0.2343)  time: 1.3882  data: 1.0107  max mem: 3615\n",
      "Training Epoch: [0]  [ 3570/14785]  eta: 2:08:41  lr: 0.000300  loss: 0.2968 (0.3970)  loss_objectness: 0.1198 (0.1628)  loss_rpn_box_reg: 0.1980 (0.2343)  time: 1.3907  data: 1.0199  max mem: 3615\n",
      "Training Epoch: [0]  [ 3580/14785]  eta: 2:08:33  lr: 0.000300  loss: 0.3684 (0.3971)  loss_objectness: 0.1273 (0.1627)  loss_rpn_box_reg: 0.2144 (0.2344)  time: 0.6609  data: 0.2911  max mem: 3615\n",
      "Training Epoch: [0]  [ 3590/14785]  eta: 2:08:26  lr: 0.000300  loss: 0.3815 (0.3972)  loss_objectness: 0.1338 (0.1627)  loss_rpn_box_reg: 0.2500 (0.2345)  time: 0.6569  data: 0.2800  max mem: 3615\n",
      "Training Epoch: [0]  [ 3600/14785]  eta: 2:08:18  lr: 0.000300  loss: 0.4167 (0.3974)  loss_objectness: 0.1567 (0.1628)  loss_rpn_box_reg: 0.2402 (0.2346)  time: 0.6615  data: 0.2898  max mem: 3615\n",
      "Training Epoch: [0]  [ 3610/14785]  eta: 2:08:10  lr: 0.000300  loss: 0.3567 (0.3974)  loss_objectness: 0.1541 (0.1628)  loss_rpn_box_reg: 0.2282 (0.2346)  time: 0.6573  data: 0.2893  max mem: 3615\n",
      "Training Epoch: [0]  [ 3620/14785]  eta: 2:08:02  lr: 0.000300  loss: 0.3567 (0.3974)  loss_objectness: 0.1340 (0.1627)  loss_rpn_box_reg: 0.2322 (0.2347)  time: 0.6553  data: 0.2757  max mem: 3615\n",
      "Training Epoch: [0]  [ 3630/14785]  eta: 2:07:54  lr: 0.000300  loss: 0.3934 (0.3974)  loss_objectness: 0.1144 (0.1627)  loss_rpn_box_reg: 0.2464 (0.2348)  time: 0.6490  data: 0.2722  max mem: 3615\n",
      "Training Epoch: [0]  [ 3640/14785]  eta: 2:07:47  lr: 0.000300  loss: 0.3483 (0.3975)  loss_objectness: 0.1470 (0.1627)  loss_rpn_box_reg: 0.2236 (0.2348)  time: 0.6761  data: 0.2884  max mem: 3615\n",
      "Training Epoch: [0]  [ 3650/14785]  eta: 2:07:39  lr: 0.000300  loss: 0.3305 (0.3974)  loss_objectness: 0.1320 (0.1626)  loss_rpn_box_reg: 0.2071 (0.2348)  time: 0.6713  data: 0.2893  max mem: 3615\n",
      "Training Epoch: [0]  [ 3660/14785]  eta: 2:07:32  lr: 0.000300  loss: 0.3184 (0.3972)  loss_objectness: 0.1191 (0.1625)  loss_rpn_box_reg: 0.1947 (0.2347)  time: 0.6569  data: 0.2837  max mem: 3615\n",
      "Training Epoch: [0]  [ 3670/14785]  eta: 2:07:23  lr: 0.000300  loss: 0.3343 (0.3973)  loss_objectness: 0.1188 (0.1625)  loss_rpn_box_reg: 0.2198 (0.2348)  time: 0.6561  data: 0.2829  max mem: 3615\n",
      "Training Epoch: [0]  [ 3680/14785]  eta: 2:07:16  lr: 0.000300  loss: 0.3284 (0.3970)  loss_objectness: 0.1234 (0.1624)  loss_rpn_box_reg: 0.1984 (0.2346)  time: 0.6548  data: 0.2810  max mem: 3615\n",
      "Training Epoch: [0]  [ 3690/14785]  eta: 2:07:08  lr: 0.000300  loss: 0.3162 (0.3970)  loss_objectness: 0.1400 (0.1623)  loss_rpn_box_reg: 0.1764 (0.2346)  time: 0.6678  data: 0.2810  max mem: 3615\n",
      "Training Epoch: [0]  [ 3700/14785]  eta: 2:07:01  lr: 0.000300  loss: 0.3743 (0.3970)  loss_objectness: 0.1429 (0.1623)  loss_rpn_box_reg: 0.2278 (0.2347)  time: 0.6688  data: 0.2840  max mem: 3615\n",
      "Training Epoch: [0]  [ 3710/14785]  eta: 2:06:54  lr: 0.000300  loss: 0.4153 (0.3970)  loss_objectness: 0.1388 (0.1623)  loss_rpn_box_reg: 0.2314 (0.2347)  time: 0.6727  data: 0.2895  max mem: 3615\n",
      "Training Epoch: [0]  [ 3720/14785]  eta: 2:06:46  lr: 0.000300  loss: 0.3484 (0.3969)  loss_objectness: 0.1365 (0.1623)  loss_rpn_box_reg: 0.1724 (0.2346)  time: 0.6716  data: 0.2811  max mem: 3615\n",
      "Training Epoch: [0]  [ 3730/14785]  eta: 2:06:38  lr: 0.000300  loss: 0.3378 (0.3968)  loss_objectness: 0.1537 (0.1623)  loss_rpn_box_reg: 0.1630 (0.2345)  time: 0.6606  data: 0.2752  max mem: 3615\n",
      "Training Epoch: [0]  [ 3740/14785]  eta: 2:06:31  lr: 0.000300  loss: 0.3380 (0.3967)  loss_objectness: 0.1467 (0.1622)  loss_rpn_box_reg: 0.1983 (0.2345)  time: 0.6623  data: 0.2823  max mem: 3615\n",
      "Training Epoch: [0]  [ 3750/14785]  eta: 2:06:24  lr: 0.000300  loss: 0.3345 (0.3967)  loss_objectness: 0.1414 (0.1621)  loss_rpn_box_reg: 0.1983 (0.2345)  time: 0.6736  data: 0.2926  max mem: 3615\n",
      "Training Epoch: [0]  [ 3760/14785]  eta: 2:06:15  lr: 0.000300  loss: 0.3115 (0.3966)  loss_objectness: 0.1410 (0.1621)  loss_rpn_box_reg: 0.1722 (0.2344)  time: 0.6539  data: 0.2840  max mem: 3615\n",
      "Training Epoch: [0]  [ 3770/14785]  eta: 2:06:08  lr: 0.000300  loss: 0.3074 (0.3965)  loss_objectness: 0.1383 (0.1621)  loss_rpn_box_reg: 0.1722 (0.2344)  time: 0.6504  data: 0.2777  max mem: 3615\n",
      "Training Epoch: [0]  [ 3780/14785]  eta: 2:06:00  lr: 0.000300  loss: 0.4089 (0.3968)  loss_objectness: 0.1597 (0.1622)  loss_rpn_box_reg: 0.2343 (0.2346)  time: 0.6607  data: 0.2875  max mem: 3615\n",
      "Training Epoch: [0]  [ 3790/14785]  eta: 2:05:53  lr: 0.000300  loss: 0.4577 (0.3967)  loss_objectness: 0.1765 (0.1622)  loss_rpn_box_reg: 0.2586 (0.2346)  time: 0.6582  data: 0.2864  max mem: 3615\n",
      "Training Epoch: [0]  [ 3800/14785]  eta: 2:05:45  lr: 0.000300  loss: 0.3713 (0.3967)  loss_objectness: 0.1244 (0.1621)  loss_rpn_box_reg: 0.2154 (0.2346)  time: 0.6682  data: 0.2857  max mem: 3615\n",
      "Training Epoch: [0]  [ 3810/14785]  eta: 2:05:38  lr: 0.000300  loss: 0.3664 (0.3966)  loss_objectness: 0.1399 (0.1621)  loss_rpn_box_reg: 0.2125 (0.2345)  time: 0.6765  data: 0.2878  max mem: 3615\n",
      "Training Epoch: [0]  [ 3820/14785]  eta: 2:05:29  lr: 0.000300  loss: 0.3739 (0.3966)  loss_objectness: 0.1408 (0.1620)  loss_rpn_box_reg: 0.2191 (0.2346)  time: 0.6481  data: 0.2798  max mem: 3615\n",
      "Training Epoch: [0]  [ 3830/14785]  eta: 2:05:22  lr: 0.000300  loss: 0.3588 (0.3965)  loss_objectness: 0.1233 (0.1620)  loss_rpn_box_reg: 0.2190 (0.2345)  time: 0.6369  data: 0.2733  max mem: 3615\n",
      "Training Epoch: [0]  [ 3840/14785]  eta: 2:05:14  lr: 0.000300  loss: 0.3555 (0.3966)  loss_objectness: 0.1178 (0.1619)  loss_rpn_box_reg: 0.2190 (0.2348)  time: 0.6611  data: 0.2844  max mem: 3615\n",
      "Training Epoch: [0]  [ 3850/14785]  eta: 2:05:06  lr: 0.000300  loss: 0.3315 (0.3964)  loss_objectness: 0.1160 (0.1617)  loss_rpn_box_reg: 0.2121 (0.2346)  time: 0.6564  data: 0.2890  max mem: 3615\n",
      "Training Epoch: [0]  [ 3860/14785]  eta: 2:04:58  lr: 0.000300  loss: 0.3186 (0.3963)  loss_objectness: 0.1193 (0.1617)  loss_rpn_box_reg: 0.1920 (0.2345)  time: 0.6361  data: 0.2810  max mem: 3615\n",
      "Training Epoch: [0]  [ 3870/14785]  eta: 2:04:50  lr: 0.000300  loss: 0.3775 (0.3964)  loss_objectness: 0.1457 (0.1617)  loss_rpn_box_reg: 0.2013 (0.2347)  time: 0.6397  data: 0.2814  max mem: 3615\n",
      "Training Epoch: [0]  [ 3880/14785]  eta: 2:04:43  lr: 0.000300  loss: 0.3677 (0.3964)  loss_objectness: 0.1424 (0.1617)  loss_rpn_box_reg: 0.2220 (0.2347)  time: 0.6674  data: 0.2890  max mem: 3615\n",
      "Training Epoch: [0]  [ 3890/14785]  eta: 2:04:36  lr: 0.000300  loss: 0.3796 (0.3964)  loss_objectness: 0.1341 (0.1616)  loss_rpn_box_reg: 0.2428 (0.2347)  time: 0.6860  data: 0.2987  max mem: 3615\n",
      "Training Epoch: [0]  [ 3900/14785]  eta: 2:04:31  lr: 0.000300  loss: 0.4322 (0.3964)  loss_objectness: 0.1302 (0.1616)  loss_rpn_box_reg: 0.2917 (0.2348)  time: 0.7291  data: 0.3364  max mem: 3615\n",
      "Training Epoch: [0]  [ 3910/14785]  eta: 2:05:03  lr: 0.000300  loss: 0.4002 (0.3965)  loss_objectness: 0.1437 (0.1616)  loss_rpn_box_reg: 0.2431 (0.2349)  time: 1.4242  data: 1.0524  max mem: 3615\n",
      "Training Epoch: [0]  [ 3920/14785]  eta: 2:04:55  lr: 0.000300  loss: 0.3902 (0.3965)  loss_objectness: 0.1597 (0.1615)  loss_rpn_box_reg: 0.2431 (0.2349)  time: 1.3613  data: 1.0109  max mem: 3615\n",
      "Training Epoch: [0]  [ 3930/14785]  eta: 2:04:48  lr: 0.000300  loss: 0.3661 (0.3965)  loss_objectness: 0.1313 (0.1614)  loss_rpn_box_reg: 0.2115 (0.2350)  time: 0.6589  data: 0.2859  max mem: 3615\n",
      "Training Epoch: [0]  [ 3940/14785]  eta: 2:04:40  lr: 0.000300  loss: 0.3437 (0.3964)  loss_objectness: 0.1389 (0.1615)  loss_rpn_box_reg: 0.2079 (0.2350)  time: 0.6668  data: 0.2802  max mem: 3615\n",
      "Training Epoch: [0]  [ 3950/14785]  eta: 2:04:32  lr: 0.000300  loss: 0.3538 (0.3964)  loss_objectness: 0.1574 (0.1615)  loss_rpn_box_reg: 0.1874 (0.2349)  time: 0.6535  data: 0.2799  max mem: 3615\n",
      "Training Epoch: [0]  [ 3960/14785]  eta: 2:04:25  lr: 0.000300  loss: 0.3382 (0.3961)  loss_objectness: 0.1514 (0.1614)  loss_rpn_box_reg: 0.1874 (0.2347)  time: 0.6595  data: 0.2820  max mem: 3615\n",
      "Training Epoch: [0]  [ 3970/14785]  eta: 2:04:16  lr: 0.000300  loss: 0.3847 (0.3963)  loss_objectness: 0.1548 (0.1615)  loss_rpn_box_reg: 0.2103 (0.2348)  time: 0.6539  data: 0.2776  max mem: 3615\n",
      "Training Epoch: [0]  [ 3980/14785]  eta: 2:04:08  lr: 0.000300  loss: 0.3847 (0.3962)  loss_objectness: 0.1558 (0.1614)  loss_rpn_box_reg: 0.2368 (0.2348)  time: 0.6427  data: 0.2728  max mem: 3615\n",
      "Training Epoch: [0]  [ 3990/14785]  eta: 2:04:01  lr: 0.000300  loss: 0.3347 (0.3961)  loss_objectness: 0.1265 (0.1614)  loss_rpn_box_reg: 0.2055 (0.2347)  time: 0.6580  data: 0.2815  max mem: 3615\n",
      "Training Epoch: [0]  [ 4000/14785]  eta: 2:03:54  lr: 0.000300  loss: 0.3107 (0.3960)  loss_objectness: 0.1206 (0.1613)  loss_rpn_box_reg: 0.1693 (0.2346)  time: 0.6821  data: 0.2955  max mem: 3615\n",
      "Training Epoch: [0]  [ 4010/14785]  eta: 2:03:46  lr: 0.000300  loss: 0.3362 (0.3958)  loss_objectness: 0.1192 (0.1613)  loss_rpn_box_reg: 0.2063 (0.2345)  time: 0.6627  data: 0.2854  max mem: 3615\n",
      "Training Epoch: [0]  [ 4020/14785]  eta: 2:03:38  lr: 0.000300  loss: 0.3720 (0.3960)  loss_objectness: 0.1370 (0.1613)  loss_rpn_box_reg: 0.2274 (0.2347)  time: 0.6531  data: 0.2777  max mem: 3615\n",
      "Training Epoch: [0]  [ 4030/14785]  eta: 2:03:31  lr: 0.000300  loss: 0.4093 (0.3960)  loss_objectness: 0.1370 (0.1612)  loss_rpn_box_reg: 0.2789 (0.2348)  time: 0.6768  data: 0.2845  max mem: 3615\n",
      "Training Epoch: [0]  [ 4040/14785]  eta: 2:03:23  lr: 0.000300  loss: 0.3922 (0.3959)  loss_objectness: 0.1313 (0.1612)  loss_rpn_box_reg: 0.2580 (0.2348)  time: 0.6559  data: 0.2736  max mem: 3615\n",
      "Training Epoch: [0]  [ 4050/14785]  eta: 2:03:16  lr: 0.000300  loss: 0.3240 (0.3958)  loss_objectness: 0.1276 (0.1611)  loss_rpn_box_reg: 0.1754 (0.2347)  time: 0.6668  data: 0.2786  max mem: 3615\n",
      "Training Epoch: [0]  [ 4060/14785]  eta: 2:03:09  lr: 0.000300  loss: 0.2854 (0.3957)  loss_objectness: 0.1276 (0.1611)  loss_rpn_box_reg: 0.1737 (0.2347)  time: 0.6830  data: 0.2934  max mem: 3615\n",
      "Training Epoch: [0]  [ 4070/14785]  eta: 2:03:01  lr: 0.000300  loss: 0.2862 (0.3955)  loss_objectness: 0.1284 (0.1610)  loss_rpn_box_reg: 0.1737 (0.2345)  time: 0.6699  data: 0.2902  max mem: 3615\n",
      "Training Epoch: [0]  [ 4080/14785]  eta: 2:02:54  lr: 0.000300  loss: 0.3074 (0.3953)  loss_objectness: 0.1154 (0.1609)  loss_rpn_box_reg: 0.1623 (0.2344)  time: 0.6661  data: 0.2844  max mem: 3615\n",
      "Training Epoch: [0]  [ 4090/14785]  eta: 2:02:46  lr: 0.000300  loss: 0.2993 (0.3951)  loss_objectness: 0.1241 (0.1608)  loss_rpn_box_reg: 0.1740 (0.2343)  time: 0.6574  data: 0.2822  max mem: 3615\n",
      "Training Epoch: [0]  [ 4100/14785]  eta: 2:02:38  lr: 0.000300  loss: 0.3096 (0.3950)  loss_objectness: 0.1332 (0.1608)  loss_rpn_box_reg: 0.1749 (0.2342)  time: 0.6587  data: 0.2917  max mem: 3615\n",
      "Training Epoch: [0]  [ 4110/14785]  eta: 2:02:31  lr: 0.000300  loss: 0.3302 (0.3949)  loss_objectness: 0.1361 (0.1608)  loss_rpn_box_reg: 0.1829 (0.2341)  time: 0.6563  data: 0.2873  max mem: 3615\n",
      "Training Epoch: [0]  [ 4120/14785]  eta: 2:02:22  lr: 0.000300  loss: 0.3274 (0.3948)  loss_objectness: 0.1360 (0.1607)  loss_rpn_box_reg: 0.1869 (0.2341)  time: 0.6347  data: 0.2698  max mem: 3615\n",
      "Training Epoch: [0]  [ 4130/14785]  eta: 2:02:14  lr: 0.000300  loss: 0.3082 (0.3945)  loss_objectness: 0.1098 (0.1606)  loss_rpn_box_reg: 0.1882 (0.2339)  time: 0.6416  data: 0.2708  max mem: 3615\n",
      "Training Epoch: [0]  [ 4140/14785]  eta: 2:02:06  lr: 0.000300  loss: 0.2854 (0.3943)  loss_objectness: 0.1114 (0.1605)  loss_rpn_box_reg: 0.1611 (0.2338)  time: 0.6538  data: 0.2787  max mem: 3615\n",
      "Training Epoch: [0]  [ 4150/14785]  eta: 2:01:58  lr: 0.000300  loss: 0.3449 (0.3944)  loss_objectness: 0.1343 (0.1606)  loss_rpn_box_reg: 0.1836 (0.2338)  time: 0.6356  data: 0.2797  max mem: 3615\n",
      "Training Epoch: [0]  [ 4160/14785]  eta: 2:01:50  lr: 0.000300  loss: 0.4032 (0.3944)  loss_objectness: 0.1567 (0.1606)  loss_rpn_box_reg: 0.2166 (0.2339)  time: 0.6370  data: 0.2792  max mem: 3615\n",
      "Training Epoch: [0]  [ 4170/14785]  eta: 2:01:42  lr: 0.000300  loss: 0.3716 (0.3944)  loss_objectness: 0.1413 (0.1605)  loss_rpn_box_reg: 0.2412 (0.2339)  time: 0.6534  data: 0.2794  max mem: 3615\n",
      "Training Epoch: [0]  [ 4180/14785]  eta: 2:01:35  lr: 0.000300  loss: 0.3716 (0.3944)  loss_objectness: 0.1376 (0.1605)  loss_rpn_box_reg: 0.2358 (0.2339)  time: 0.6704  data: 0.2847  max mem: 3615\n",
      "Training Epoch: [0]  [ 4190/14785]  eta: 2:01:27  lr: 0.000300  loss: 0.3878 (0.3945)  loss_objectness: 0.1481 (0.1605)  loss_rpn_box_reg: 0.2707 (0.2340)  time: 0.6606  data: 0.2874  max mem: 3615\n",
      "Training Epoch: [0]  [ 4200/14785]  eta: 2:01:19  lr: 0.000300  loss: 0.3412 (0.3944)  loss_objectness: 0.1583 (0.1605)  loss_rpn_box_reg: 0.1841 (0.2339)  time: 0.6319  data: 0.2772  max mem: 3615\n",
      "Training Epoch: [0]  [ 4210/14785]  eta: 2:01:10  lr: 0.000300  loss: 0.3137 (0.3943)  loss_objectness: 0.1310 (0.1604)  loss_rpn_box_reg: 0.1939 (0.2339)  time: 0.6285  data: 0.2761  max mem: 3615\n",
      "Training Epoch: [0]  [ 4220/14785]  eta: 2:01:02  lr: 0.000300  loss: 0.3052 (0.3941)  loss_objectness: 0.1262 (0.1604)  loss_rpn_box_reg: 0.1644 (0.2337)  time: 0.6235  data: 0.2725  max mem: 3615\n",
      "Training Epoch: [0]  [ 4230/14785]  eta: 2:00:54  lr: 0.000300  loss: 0.3006 (0.3940)  loss_objectness: 0.1241 (0.1603)  loss_rpn_box_reg: 0.1644 (0.2337)  time: 0.6296  data: 0.2681  max mem: 3615\n",
      "Training Epoch: [0]  [ 4240/14785]  eta: 2:00:46  lr: 0.000300  loss: 0.3006 (0.3939)  loss_objectness: 0.1387 (0.1603)  loss_rpn_box_reg: 0.1799 (0.2336)  time: 0.6508  data: 0.2808  max mem: 3615\n",
      "Training Epoch: [0]  [ 4250/14785]  eta: 2:00:39  lr: 0.000300  loss: 0.2990 (0.3937)  loss_objectness: 0.1387 (0.1602)  loss_rpn_box_reg: 0.1644 (0.2335)  time: 0.6613  data: 0.2857  max mem: 3615\n",
      "Training Epoch: [0]  [ 4260/14785]  eta: 2:00:31  lr: 0.000300  loss: 0.3327 (0.3937)  loss_objectness: 0.1435 (0.1602)  loss_rpn_box_reg: 0.1863 (0.2334)  time: 0.6607  data: 0.2802  max mem: 3615\n",
      "Training Epoch: [0]  [ 4270/14785]  eta: 2:00:23  lr: 0.000300  loss: 0.3479 (0.3936)  loss_objectness: 0.1471 (0.1602)  loss_rpn_box_reg: 0.1752 (0.2334)  time: 0.6525  data: 0.2756  max mem: 3615\n",
      "Training Epoch: [0]  [ 4280/14785]  eta: 2:00:16  lr: 0.000300  loss: 0.3362 (0.3935)  loss_objectness: 0.1378 (0.1602)  loss_rpn_box_reg: 0.1851 (0.2334)  time: 0.6706  data: 0.2850  max mem: 3615\n",
      "Training Epoch: [0]  [ 4290/14785]  eta: 2:00:09  lr: 0.000300  loss: 0.3362 (0.3934)  loss_objectness: 0.1269 (0.1601)  loss_rpn_box_reg: 0.1869 (0.2333)  time: 0.6817  data: 0.2931  max mem: 3615\n",
      "Training Epoch: [0]  [ 4300/14785]  eta: 2:00:43  lr: 0.000300  loss: 0.3660 (0.3935)  loss_objectness: 0.1394 (0.1601)  loss_rpn_box_reg: 0.2022 (0.2333)  time: 1.5112  data: 1.1318  max mem: 3615\n",
      "Training Epoch: [0]  [ 4310/14785]  eta: 2:00:35  lr: 0.000300  loss: 0.3334 (0.3933)  loss_objectness: 0.1329 (0.1601)  loss_rpn_box_reg: 0.1954 (0.2332)  time: 1.4902  data: 1.1245  max mem: 3615\n",
      "Training Epoch: [0]  [ 4320/14785]  eta: 2:00:26  lr: 0.000300  loss: 0.3269 (0.3934)  loss_objectness: 0.1319 (0.1600)  loss_rpn_box_reg: 0.1933 (0.2333)  time: 0.6288  data: 0.2746  max mem: 3615\n",
      "Training Epoch: [0]  [ 4330/14785]  eta: 2:00:18  lr: 0.000300  loss: 0.3868 (0.3933)  loss_objectness: 0.1264 (0.1600)  loss_rpn_box_reg: 0.2374 (0.2333)  time: 0.6301  data: 0.2736  max mem: 3615\n",
      "Training Epoch: [0]  [ 4340/14785]  eta: 2:00:10  lr: 0.000300  loss: 0.3227 (0.3931)  loss_objectness: 0.1082 (0.1599)  loss_rpn_box_reg: 0.2374 (0.2332)  time: 0.6402  data: 0.2794  max mem: 3615\n",
      "Training Epoch: [0]  [ 4350/14785]  eta: 2:00:02  lr: 0.000300  loss: 0.3428 (0.3931)  loss_objectness: 0.1390 (0.1599)  loss_rpn_box_reg: 0.2255 (0.2332)  time: 0.6481  data: 0.2832  max mem: 3615\n",
      "Training Epoch: [0]  [ 4360/14785]  eta: 1:59:54  lr: 0.000300  loss: 0.3435 (0.3932)  loss_objectness: 0.1474 (0.1599)  loss_rpn_box_reg: 0.2247 (0.2333)  time: 0.6535  data: 0.2824  max mem: 3615\n",
      "Training Epoch: [0]  [ 4370/14785]  eta: 1:59:47  lr: 0.000300  loss: 0.3488 (0.3930)  loss_objectness: 0.1341 (0.1598)  loss_rpn_box_reg: 0.1940 (0.2332)  time: 0.6614  data: 0.2799  max mem: 3615\n",
      "Training Epoch: [0]  [ 4380/14785]  eta: 1:59:39  lr: 0.000300  loss: 0.3488 (0.3929)  loss_objectness: 0.1296 (0.1598)  loss_rpn_box_reg: 0.1578 (0.2332)  time: 0.6493  data: 0.2752  max mem: 3615\n",
      "Training Epoch: [0]  [ 4390/14785]  eta: 1:59:30  lr: 0.000300  loss: 0.3490 (0.3929)  loss_objectness: 0.1282 (0.1597)  loss_rpn_box_reg: 0.1848 (0.2331)  time: 0.6339  data: 0.2721  max mem: 3615\n",
      "Training Epoch: [0]  [ 4400/14785]  eta: 1:59:22  lr: 0.000300  loss: 0.3490 (0.3930)  loss_objectness: 0.1331 (0.1597)  loss_rpn_box_reg: 0.2239 (0.2333)  time: 0.6394  data: 0.2654  max mem: 3615\n",
      "Training Epoch: [0]  [ 4410/14785]  eta: 1:59:15  lr: 0.000300  loss: 0.3753 (0.3930)  loss_objectness: 0.1304 (0.1597)  loss_rpn_box_reg: 0.2250 (0.2333)  time: 0.6624  data: 0.2797  max mem: 3615\n",
      "Training Epoch: [0]  [ 4420/14785]  eta: 1:59:08  lr: 0.000300  loss: 0.3944 (0.3930)  loss_objectness: 0.1346 (0.1597)  loss_rpn_box_reg: 0.2220 (0.2333)  time: 0.6752  data: 0.2842  max mem: 3615\n",
      "Training Epoch: [0]  [ 4430/14785]  eta: 1:59:00  lr: 0.000300  loss: 0.4048 (0.3930)  loss_objectness: 0.1641 (0.1597)  loss_rpn_box_reg: 0.2495 (0.2333)  time: 0.6571  data: 0.2744  max mem: 3615\n",
      "Training Epoch: [0]  [ 4440/14785]  eta: 1:58:52  lr: 0.000300  loss: 0.3627 (0.3929)  loss_objectness: 0.1497 (0.1597)  loss_rpn_box_reg: 0.2088 (0.2332)  time: 0.6410  data: 0.2800  max mem: 3615\n",
      "Training Epoch: [0]  [ 4450/14785]  eta: 1:58:44  lr: 0.000300  loss: 0.2986 (0.3928)  loss_objectness: 0.1297 (0.1597)  loss_rpn_box_reg: 0.1592 (0.2331)  time: 0.6402  data: 0.2782  max mem: 3615\n",
      "Training Epoch: [0]  [ 4460/14785]  eta: 1:58:36  lr: 0.000300  loss: 0.3050 (0.3927)  loss_objectness: 0.1147 (0.1596)  loss_rpn_box_reg: 0.1868 (0.2331)  time: 0.6503  data: 0.2772  max mem: 3615\n",
      "Training Epoch: [0]  [ 4470/14785]  eta: 1:58:28  lr: 0.000300  loss: 0.3050 (0.3925)  loss_objectness: 0.1220 (0.1596)  loss_rpn_box_reg: 0.1722 (0.2329)  time: 0.6485  data: 0.2706  max mem: 3615\n",
      "Training Epoch: [0]  [ 4480/14785]  eta: 1:58:20  lr: 0.000300  loss: 0.2898 (0.3924)  loss_objectness: 0.1145 (0.1595)  loss_rpn_box_reg: 0.1722 (0.2329)  time: 0.6417  data: 0.2707  max mem: 3615\n",
      "Training Epoch: [0]  [ 4490/14785]  eta: 1:58:12  lr: 0.000300  loss: 0.3530 (0.3924)  loss_objectness: 0.1381 (0.1595)  loss_rpn_box_reg: 0.2101 (0.2329)  time: 0.6415  data: 0.2726  max mem: 3615\n",
      "Training Epoch: [0]  [ 4500/14785]  eta: 1:58:04  lr: 0.000300  loss: 0.4286 (0.3926)  loss_objectness: 0.1577 (0.1595)  loss_rpn_box_reg: 0.2666 (0.2331)  time: 0.6389  data: 0.2750  max mem: 3615\n",
      "Training Epoch: [0]  [ 4510/14785]  eta: 1:57:57  lr: 0.000300  loss: 0.4208 (0.3925)  loss_objectness: 0.1396 (0.1595)  loss_rpn_box_reg: 0.2666 (0.2331)  time: 0.6477  data: 0.2823  max mem: 3615\n",
      "Training Epoch: [0]  [ 4520/14785]  eta: 1:57:49  lr: 0.000300  loss: 0.2889 (0.3924)  loss_objectness: 0.1173 (0.1594)  loss_rpn_box_reg: 0.1710 (0.2330)  time: 0.6521  data: 0.2760  max mem: 3615\n",
      "Training Epoch: [0]  [ 4530/14785]  eta: 1:57:41  lr: 0.000300  loss: 0.2889 (0.3923)  loss_objectness: 0.1153 (0.1593)  loss_rpn_box_reg: 0.1736 (0.2329)  time: 0.6492  data: 0.2675  max mem: 3615\n",
      "Training Epoch: [0]  [ 4540/14785]  eta: 1:57:34  lr: 0.000300  loss: 0.2978 (0.3922)  loss_objectness: 0.1298 (0.1593)  loss_rpn_box_reg: 0.1791 (0.2329)  time: 0.6668  data: 0.2758  max mem: 3615\n",
      "Training Epoch: [0]  [ 4550/14785]  eta: 1:57:26  lr: 0.000300  loss: 0.3330 (0.3921)  loss_objectness: 0.1429 (0.1593)  loss_rpn_box_reg: 0.1946 (0.2328)  time: 0.6715  data: 0.2846  max mem: 3615\n",
      "Training Epoch: [0]  [ 4560/14785]  eta: 1:57:19  lr: 0.000300  loss: 0.3609 (0.3921)  loss_objectness: 0.1361 (0.1593)  loss_rpn_box_reg: 0.2142 (0.2328)  time: 0.6548  data: 0.2780  max mem: 3615\n",
      "Training Epoch: [0]  [ 4570/14785]  eta: 1:57:11  lr: 0.000300  loss: 0.3219 (0.3919)  loss_objectness: 0.1412 (0.1592)  loss_rpn_box_reg: 0.1923 (0.2327)  time: 0.6461  data: 0.2747  max mem: 3615\n",
      "Training Epoch: [0]  [ 4580/14785]  eta: 1:57:03  lr: 0.000300  loss: 0.2872 (0.3918)  loss_objectness: 0.1377 (0.1592)  loss_rpn_box_reg: 0.1796 (0.2326)  time: 0.6387  data: 0.2786  max mem: 3615\n",
      "Training Epoch: [0]  [ 4590/14785]  eta: 1:56:55  lr: 0.000300  loss: 0.3286 (0.3918)  loss_objectness: 0.1334 (0.1592)  loss_rpn_box_reg: 0.1972 (0.2326)  time: 0.6460  data: 0.2779  max mem: 3615\n",
      "Training Epoch: [0]  [ 4600/14785]  eta: 1:56:48  lr: 0.000300  loss: 0.3496 (0.3917)  loss_objectness: 0.1338 (0.1591)  loss_rpn_box_reg: 0.1972 (0.2325)  time: 0.6606  data: 0.2742  max mem: 3615\n",
      "Training Epoch: [0]  [ 4610/14785]  eta: 1:56:40  lr: 0.000300  loss: 0.2991 (0.3915)  loss_objectness: 0.1183 (0.1591)  loss_rpn_box_reg: 0.1561 (0.2324)  time: 0.6547  data: 0.2697  max mem: 3615\n",
      "Training Epoch: [0]  [ 4620/14785]  eta: 1:56:32  lr: 0.000300  loss: 0.3043 (0.3914)  loss_objectness: 0.1183 (0.1590)  loss_rpn_box_reg: 0.1675 (0.2324)  time: 0.6389  data: 0.2623  max mem: 3615\n",
      "Training Epoch: [0]  [ 4630/14785]  eta: 1:56:24  lr: 0.000300  loss: 0.3251 (0.3913)  loss_objectness: 0.1295 (0.1590)  loss_rpn_box_reg: 0.1959 (0.2323)  time: 0.6387  data: 0.2651  max mem: 3615\n",
      "Training Epoch: [0]  [ 4640/14785]  eta: 1:56:16  lr: 0.000300  loss: 0.3272 (0.3913)  loss_objectness: 0.1411 (0.1590)  loss_rpn_box_reg: 0.1847 (0.2322)  time: 0.6475  data: 0.2673  max mem: 3615\n",
      "Training Epoch: [0]  [ 4650/14785]  eta: 1:56:49  lr: 0.000300  loss: 0.3574 (0.3912)  loss_objectness: 0.1368 (0.1590)  loss_rpn_box_reg: 0.1856 (0.2322)  time: 1.5712  data: 1.1936  max mem: 3615\n",
      "Training Epoch: [0]  [ 4660/14785]  eta: 1:56:41  lr: 0.000300  loss: 0.3929 (0.3913)  loss_objectness: 0.1367 (0.1591)  loss_rpn_box_reg: 0.2580 (0.2322)  time: 1.5793  data: 1.2041  max mem: 3615\n",
      "Training Epoch: [0]  [ 4670/14785]  eta: 1:56:34  lr: 0.000300  loss: 0.4182 (0.3914)  loss_objectness: 0.1386 (0.1590)  loss_rpn_box_reg: 0.2630 (0.2323)  time: 0.6730  data: 0.2935  max mem: 3615\n",
      "Training Epoch: [0]  [ 4680/14785]  eta: 1:56:26  lr: 0.000300  loss: 0.3655 (0.3912)  loss_objectness: 0.1327 (0.1590)  loss_rpn_box_reg: 0.2302 (0.2323)  time: 0.6545  data: 0.2822  max mem: 3615\n",
      "Training Epoch: [0]  [ 4690/14785]  eta: 1:56:19  lr: 0.000300  loss: 0.3736 (0.3913)  loss_objectness: 0.1269 (0.1589)  loss_rpn_box_reg: 0.2293 (0.2324)  time: 0.6579  data: 0.2803  max mem: 3615\n",
      "Training Epoch: [0]  [ 4700/14785]  eta: 1:56:11  lr: 0.000300  loss: 0.3840 (0.3914)  loss_objectness: 0.1508 (0.1589)  loss_rpn_box_reg: 0.2716 (0.2325)  time: 0.6734  data: 0.2870  max mem: 3615\n",
      "Training Epoch: [0]  [ 4710/14785]  eta: 1:56:04  lr: 0.000300  loss: 0.3729 (0.3915)  loss_objectness: 0.1447 (0.1589)  loss_rpn_box_reg: 0.2332 (0.2326)  time: 0.6564  data: 0.2759  max mem: 3615\n",
      "Training Epoch: [0]  [ 4720/14785]  eta: 1:55:55  lr: 0.000300  loss: 0.3667 (0.3914)  loss_objectness: 0.1276 (0.1589)  loss_rpn_box_reg: 0.2418 (0.2326)  time: 0.6456  data: 0.2718  max mem: 3615\n",
      "Training Epoch: [0]  [ 4730/14785]  eta: 1:55:48  lr: 0.000300  loss: 0.3667 (0.3914)  loss_objectness: 0.1316 (0.1588)  loss_rpn_box_reg: 0.2038 (0.2326)  time: 0.6550  data: 0.2706  max mem: 3615\n",
      "Training Epoch: [0]  [ 4740/14785]  eta: 1:55:40  lr: 0.000300  loss: 0.4332 (0.3915)  loss_objectness: 0.1430 (0.1588)  loss_rpn_box_reg: 0.2465 (0.2327)  time: 0.6592  data: 0.2704  max mem: 3615\n",
      "Training Epoch: [0]  [ 4750/14785]  eta: 1:55:33  lr: 0.000300  loss: 0.3643 (0.3914)  loss_objectness: 0.1358 (0.1588)  loss_rpn_box_reg: 0.2299 (0.2326)  time: 0.6552  data: 0.2695  max mem: 3615\n",
      "Training Epoch: [0]  [ 4760/14785]  eta: 1:55:25  lr: 0.000300  loss: 0.4018 (0.3915)  loss_objectness: 0.1707 (0.1589)  loss_rpn_box_reg: 0.2181 (0.2326)  time: 0.6536  data: 0.2730  max mem: 3615\n",
      "Training Epoch: [0]  [ 4770/14785]  eta: 1:55:17  lr: 0.000300  loss: 0.4018 (0.3915)  loss_objectness: 0.1568 (0.1588)  loss_rpn_box_reg: 0.2226 (0.2327)  time: 0.6545  data: 0.2864  max mem: 3615\n",
      "Training Epoch: [0]  [ 4780/14785]  eta: 1:55:10  lr: 0.000300  loss: 0.3384 (0.3913)  loss_objectness: 0.1287 (0.1588)  loss_rpn_box_reg: 0.2140 (0.2326)  time: 0.6550  data: 0.2895  max mem: 3615\n",
      "Training Epoch: [0]  [ 4790/14785]  eta: 1:55:02  lr: 0.000300  loss: 0.2987 (0.3912)  loss_objectness: 0.1131 (0.1587)  loss_rpn_box_reg: 0.1779 (0.2325)  time: 0.6429  data: 0.2656  max mem: 3615\n",
      "Training Epoch: [0]  [ 4800/14785]  eta: 1:54:54  lr: 0.000300  loss: 0.3390 (0.3913)  loss_objectness: 0.1131 (0.1587)  loss_rpn_box_reg: 0.1907 (0.2325)  time: 0.6482  data: 0.2616  max mem: 3615\n",
      "Training Epoch: [0]  [ 4810/14785]  eta: 1:54:46  lr: 0.000300  loss: 0.3643 (0.3912)  loss_objectness: 0.1461 (0.1587)  loss_rpn_box_reg: 0.2157 (0.2325)  time: 0.6407  data: 0.2704  max mem: 3615\n",
      "Training Epoch: [0]  [ 4820/14785]  eta: 1:54:38  lr: 0.000300  loss: 0.3643 (0.3912)  loss_objectness: 0.1307 (0.1587)  loss_rpn_box_reg: 0.2217 (0.2325)  time: 0.6385  data: 0.2716  max mem: 3615\n",
      "Training Epoch: [0]  [ 4830/14785]  eta: 1:54:31  lr: 0.000300  loss: 0.3879 (0.3913)  loss_objectness: 0.1307 (0.1586)  loss_rpn_box_reg: 0.2612 (0.2327)  time: 0.6606  data: 0.2776  max mem: 3615\n",
      "Training Epoch: [0]  [ 4840/14785]  eta: 1:54:23  lr: 0.000300  loss: 0.4165 (0.3913)  loss_objectness: 0.1356 (0.1586)  loss_rpn_box_reg: 0.2612 (0.2327)  time: 0.6689  data: 0.2811  max mem: 3615\n",
      "Training Epoch: [0]  [ 4850/14785]  eta: 1:54:15  lr: 0.000300  loss: 0.3734 (0.3912)  loss_objectness: 0.1309 (0.1586)  loss_rpn_box_reg: 0.2068 (0.2327)  time: 0.6476  data: 0.2719  max mem: 3615\n",
      "Training Epoch: [0]  [ 4860/14785]  eta: 1:54:07  lr: 0.000300  loss: 0.3734 (0.3912)  loss_objectness: 0.1410 (0.1585)  loss_rpn_box_reg: 0.2195 (0.2327)  time: 0.6261  data: 0.2583  max mem: 3615\n",
      "Training Epoch: [0]  [ 4870/14785]  eta: 1:53:59  lr: 0.000300  loss: 0.3796 (0.3913)  loss_objectness: 0.1566 (0.1585)  loss_rpn_box_reg: 0.2238 (0.2328)  time: 0.6274  data: 0.2615  max mem: 3615\n",
      "Training Epoch: [0]  [ 4880/14785]  eta: 1:53:51  lr: 0.000300  loss: 0.3690 (0.3912)  loss_objectness: 0.1388 (0.1585)  loss_rpn_box_reg: 0.2211 (0.2327)  time: 0.6368  data: 0.2727  max mem: 3615\n",
      "Training Epoch: [0]  [ 4890/14785]  eta: 1:53:44  lr: 0.000300  loss: 0.3830 (0.3912)  loss_objectness: 0.1177 (0.1584)  loss_rpn_box_reg: 0.2330 (0.2328)  time: 0.6626  data: 0.2776  max mem: 3615\n",
      "Training Epoch: [0]  [ 4900/14785]  eta: 1:53:36  lr: 0.000300  loss: 0.3600 (0.3912)  loss_objectness: 0.1279 (0.1584)  loss_rpn_box_reg: 0.2261 (0.2328)  time: 0.6682  data: 0.2746  max mem: 3615\n",
      "Training Epoch: [0]  [ 4910/14785]  eta: 1:53:28  lr: 0.000300  loss: 0.2985 (0.3911)  loss_objectness: 0.1392 (0.1584)  loss_rpn_box_reg: 0.1790 (0.2327)  time: 0.6385  data: 0.2618  max mem: 3615\n",
      "Training Epoch: [0]  [ 4920/14785]  eta: 1:53:20  lr: 0.000300  loss: 0.3380 (0.3911)  loss_objectness: 0.1332 (0.1584)  loss_rpn_box_reg: 0.2048 (0.2327)  time: 0.6206  data: 0.2575  max mem: 3615\n",
      "Training Epoch: [0]  [ 4930/14785]  eta: 1:53:12  lr: 0.000300  loss: 0.3348 (0.3910)  loss_objectness: 0.1386 (0.1584)  loss_rpn_box_reg: 0.2019 (0.2326)  time: 0.6371  data: 0.2641  max mem: 3615\n",
      "Training Epoch: [0]  [ 4940/14785]  eta: 1:53:05  lr: 0.000300  loss: 0.4237 (0.3912)  loss_objectness: 0.1466 (0.1584)  loss_rpn_box_reg: 0.2530 (0.2329)  time: 0.6614  data: 0.2723  max mem: 3615\n",
      "Training Epoch: [0]  [ 4950/14785]  eta: 1:52:57  lr: 0.000300  loss: 0.4443 (0.3913)  loss_objectness: 0.1417 (0.1584)  loss_rpn_box_reg: 0.3315 (0.2329)  time: 0.6547  data: 0.2735  max mem: 3615\n",
      "Training Epoch: [0]  [ 4960/14785]  eta: 1:52:49  lr: 0.000300  loss: 0.3916 (0.3913)  loss_objectness: 0.1518 (0.1583)  loss_rpn_box_reg: 0.2219 (0.2329)  time: 0.6480  data: 0.2663  max mem: 3615\n",
      "Training Epoch: [0]  [ 4970/14785]  eta: 1:52:42  lr: 0.000300  loss: 0.3254 (0.3911)  loss_objectness: 0.1358 (0.1583)  loss_rpn_box_reg: 0.1702 (0.2328)  time: 0.6581  data: 0.2669  max mem: 3615\n",
      "Training Epoch: [0]  [ 4980/14785]  eta: 1:52:34  lr: 0.000300  loss: 0.4076 (0.3912)  loss_objectness: 0.1425 (0.1583)  loss_rpn_box_reg: 0.2295 (0.2329)  time: 0.6417  data: 0.2633  max mem: 3615\n",
      "Training Epoch: [0]  [ 4990/14785]  eta: 1:52:26  lr: 0.000300  loss: 0.4163 (0.3911)  loss_objectness: 0.1567 (0.1583)  loss_rpn_box_reg: 0.2312 (0.2329)  time: 0.6391  data: 0.2679  max mem: 3615\n",
      "Training Epoch: [0]  [ 5000/14785]  eta: 1:52:18  lr: 0.000300  loss: 0.3059 (0.3911)  loss_objectness: 0.1225 (0.1583)  loss_rpn_box_reg: 0.1914 (0.2328)  time: 0.6490  data: 0.2723  max mem: 3615\n",
      "Training Epoch: [0]  [ 5010/14785]  eta: 1:52:11  lr: 0.000300  loss: 0.3396 (0.3910)  loss_objectness: 0.1331 (0.1582)  loss_rpn_box_reg: 0.2076 (0.2328)  time: 0.6490  data: 0.2696  max mem: 3615\n",
      "Training Epoch: [0]  [ 5020/14785]  eta: 1:52:03  lr: 0.000300  loss: 0.3781 (0.3912)  loss_objectness: 0.1490 (0.1583)  loss_rpn_box_reg: 0.2291 (0.2329)  time: 0.6506  data: 0.2751  max mem: 3615\n",
      "Training Epoch: [0]  [ 5030/14785]  eta: 1:51:56  lr: 0.000300  loss: 0.3961 (0.3911)  loss_objectness: 0.1551 (0.1582)  loss_rpn_box_reg: 0.2051 (0.2329)  time: 0.6469  data: 0.2724  max mem: 3615\n",
      "Training Epoch: [0]  [ 5040/14785]  eta: 1:52:15  lr: 0.000300  loss: 0.3961 (0.3911)  loss_objectness: 0.1388 (0.1582)  loss_rpn_box_reg: 0.2051 (0.2329)  time: 1.3550  data: 0.9708  max mem: 3615\n",
      "Training Epoch: [0]  [ 5050/14785]  eta: 1:52:07  lr: 0.000300  loss: 0.4069 (0.3912)  loss_objectness: 0.1322 (0.1582)  loss_rpn_box_reg: 0.2531 (0.2330)  time: 1.3460  data: 0.9727  max mem: 3615\n",
      "Training Epoch: [0]  [ 5060/14785]  eta: 1:51:59  lr: 0.000300  loss: 0.3475 (0.3911)  loss_objectness: 0.1311 (0.1582)  loss_rpn_box_reg: 0.2093 (0.2329)  time: 0.6265  data: 0.2691  max mem: 3615\n",
      "Training Epoch: [0]  [ 5070/14785]  eta: 1:51:51  lr: 0.000300  loss: 0.3427 (0.3911)  loss_objectness: 0.1321 (0.1582)  loss_rpn_box_reg: 0.2010 (0.2329)  time: 0.6222  data: 0.2664  max mem: 3615\n",
      "Training Epoch: [0]  [ 5080/14785]  eta: 1:51:43  lr: 0.000300  loss: 0.3210 (0.3910)  loss_objectness: 0.1331 (0.1582)  loss_rpn_box_reg: 0.2010 (0.2328)  time: 0.6312  data: 0.2690  max mem: 3615\n",
      "Training Epoch: [0]  [ 5090/14785]  eta: 1:51:35  lr: 0.000300  loss: 0.3131 (0.3909)  loss_objectness: 0.1279 (0.1581)  loss_rpn_box_reg: 0.1800 (0.2328)  time: 0.6365  data: 0.2635  max mem: 3615\n",
      "Training Epoch: [0]  [ 5100/14785]  eta: 1:51:27  lr: 0.000300  loss: 0.3635 (0.3910)  loss_objectness: 0.1408 (0.1581)  loss_rpn_box_reg: 0.1934 (0.2329)  time: 0.6309  data: 0.2576  max mem: 3615\n",
      "Training Epoch: [0]  [ 5110/14785]  eta: 1:51:19  lr: 0.000300  loss: 0.3880 (0.3910)  loss_objectness: 0.1494 (0.1581)  loss_rpn_box_reg: 0.2476 (0.2329)  time: 0.6311  data: 0.2615  max mem: 3615\n",
      "Training Epoch: [0]  [ 5120/14785]  eta: 1:51:11  lr: 0.000300  loss: 0.3542 (0.3909)  loss_objectness: 0.1471 (0.1581)  loss_rpn_box_reg: 0.2073 (0.2328)  time: 0.6304  data: 0.2581  max mem: 3615\n",
      "Training Epoch: [0]  [ 5130/14785]  eta: 1:51:03  lr: 0.000300  loss: 0.3050 (0.3908)  loss_objectness: 0.1233 (0.1580)  loss_rpn_box_reg: 0.1972 (0.2328)  time: 0.6325  data: 0.2552  max mem: 3615\n",
      "Training Epoch: [0]  [ 5140/14785]  eta: 1:50:55  lr: 0.000300  loss: 0.2974 (0.3907)  loss_objectness: 0.1382 (0.1580)  loss_rpn_box_reg: 0.1870 (0.2328)  time: 0.6398  data: 0.2572  max mem: 3615\n",
      "Training Epoch: [0]  [ 5150/14785]  eta: 1:50:47  lr: 0.000300  loss: 0.3543 (0.3908)  loss_objectness: 0.1297 (0.1579)  loss_rpn_box_reg: 0.1986 (0.2328)  time: 0.6341  data: 0.2566  max mem: 3615\n",
      "Training Epoch: [0]  [ 5160/14785]  eta: 1:50:39  lr: 0.000300  loss: 0.3711 (0.3908)  loss_objectness: 0.1224 (0.1579)  loss_rpn_box_reg: 0.2435 (0.2329)  time: 0.6421  data: 0.2596  max mem: 3615\n",
      "Training Epoch: [0]  [ 5170/14785]  eta: 1:50:31  lr: 0.000300  loss: 0.3144 (0.3907)  loss_objectness: 0.1195 (0.1578)  loss_rpn_box_reg: 0.1975 (0.2329)  time: 0.6469  data: 0.2656  max mem: 3615\n",
      "Training Epoch: [0]  [ 5180/14785]  eta: 1:50:24  lr: 0.000300  loss: 0.3002 (0.3906)  loss_objectness: 0.1168 (0.1578)  loss_rpn_box_reg: 0.1857 (0.2328)  time: 0.6537  data: 0.2729  max mem: 3615\n",
      "Training Epoch: [0]  [ 5190/14785]  eta: 1:50:16  lr: 0.000300  loss: 0.3087 (0.3905)  loss_objectness: 0.1260 (0.1578)  loss_rpn_box_reg: 0.1857 (0.2327)  time: 0.6570  data: 0.2726  max mem: 3615\n",
      "Training Epoch: [0]  [ 5200/14785]  eta: 1:50:09  lr: 0.000300  loss: 0.3111 (0.3904)  loss_objectness: 0.1367 (0.1577)  loss_rpn_box_reg: 0.1678 (0.2326)  time: 0.6528  data: 0.2714  max mem: 3615\n",
      "Training Epoch: [0]  [ 5210/14785]  eta: 1:50:02  lr: 0.000300  loss: 0.3615 (0.3904)  loss_objectness: 0.1493 (0.1577)  loss_rpn_box_reg: 0.2221 (0.2327)  time: 0.6584  data: 0.2764  max mem: 3615\n",
      "Training Epoch: [0]  [ 5220/14785]  eta: 1:49:54  lr: 0.000300  loss: 0.3527 (0.3903)  loss_objectness: 0.1549 (0.1577)  loss_rpn_box_reg: 0.1939 (0.2326)  time: 0.6640  data: 0.2724  max mem: 3615\n",
      "Training Epoch: [0]  [ 5230/14785]  eta: 1:49:46  lr: 0.000300  loss: 0.3442 (0.3902)  loss_objectness: 0.1503 (0.1577)  loss_rpn_box_reg: 0.1835 (0.2326)  time: 0.6455  data: 0.2690  max mem: 3615\n",
      "Training Epoch: [0]  [ 5240/14785]  eta: 1:49:38  lr: 0.000300  loss: 0.3581 (0.3902)  loss_objectness: 0.1592 (0.1577)  loss_rpn_box_reg: 0.1835 (0.2325)  time: 0.6267  data: 0.2648  max mem: 3615\n",
      "Training Epoch: [0]  [ 5250/14785]  eta: 1:49:30  lr: 0.000300  loss: 0.3337 (0.3901)  loss_objectness: 0.1592 (0.1577)  loss_rpn_box_reg: 0.1745 (0.2324)  time: 0.6302  data: 0.2641  max mem: 3615\n",
      "Training Epoch: [0]  [ 5260/14785]  eta: 1:49:23  lr: 0.000300  loss: 0.3088 (0.3900)  loss_objectness: 0.1289 (0.1576)  loss_rpn_box_reg: 0.1533 (0.2324)  time: 0.6511  data: 0.2721  max mem: 3615\n",
      "Training Epoch: [0]  [ 5270/14785]  eta: 1:49:16  lr: 0.000300  loss: 0.3293 (0.3900)  loss_objectness: 0.1289 (0.1576)  loss_rpn_box_reg: 0.2112 (0.2324)  time: 0.6689  data: 0.2741  max mem: 3615\n",
      "Training Epoch: [0]  [ 5280/14785]  eta: 1:49:08  lr: 0.000300  loss: 0.3653 (0.3900)  loss_objectness: 0.1312 (0.1576)  loss_rpn_box_reg: 0.2266 (0.2325)  time: 0.6557  data: 0.2719  max mem: 3615\n",
      "Training Epoch: [0]  [ 5290/14785]  eta: 1:49:00  lr: 0.000300  loss: 0.3402 (0.3900)  loss_objectness: 0.1194 (0.1575)  loss_rpn_box_reg: 0.2067 (0.2325)  time: 0.6389  data: 0.2645  max mem: 3615\n",
      "Training Epoch: [0]  [ 5300/14785]  eta: 1:48:53  lr: 0.000300  loss: 0.2916 (0.3899)  loss_objectness: 0.1156 (0.1575)  loss_rpn_box_reg: 0.1727 (0.2324)  time: 0.6394  data: 0.2652  max mem: 3615\n",
      "Training Epoch: [0]  [ 5310/14785]  eta: 1:48:45  lr: 0.000300  loss: 0.2747 (0.3898)  loss_objectness: 0.1143 (0.1575)  loss_rpn_box_reg: 0.1603 (0.2323)  time: 0.6475  data: 0.2716  max mem: 3615\n",
      "Training Epoch: [0]  [ 5320/14785]  eta: 1:48:37  lr: 0.000300  loss: 0.3791 (0.3900)  loss_objectness: 0.1299 (0.1575)  loss_rpn_box_reg: 0.2538 (0.2325)  time: 0.6434  data: 0.2684  max mem: 3615\n",
      "Training Epoch: [0]  [ 5330/14785]  eta: 1:48:29  lr: 0.000300  loss: 0.4057 (0.3900)  loss_objectness: 0.1384 (0.1575)  loss_rpn_box_reg: 0.2642 (0.2325)  time: 0.6340  data: 0.2671  max mem: 3615\n",
      "Training Epoch: [0]  [ 5340/14785]  eta: 1:48:21  lr: 0.000300  loss: 0.3889 (0.3900)  loss_objectness: 0.1394 (0.1574)  loss_rpn_box_reg: 0.2267 (0.2325)  time: 0.6233  data: 0.2653  max mem: 3615\n",
      "Training Epoch: [0]  [ 5350/14785]  eta: 1:48:13  lr: 0.000300  loss: 0.3823 (0.3899)  loss_objectness: 0.1368 (0.1574)  loss_rpn_box_reg: 0.2177 (0.2325)  time: 0.6209  data: 0.2585  max mem: 3615\n",
      "Training Epoch: [0]  [ 5360/14785]  eta: 1:48:05  lr: 0.000300  loss: 0.3388 (0.3899)  loss_objectness: 0.1368 (0.1574)  loss_rpn_box_reg: 0.2011 (0.2325)  time: 0.6215  data: 0.2567  max mem: 3615\n",
      "Training Epoch: [0]  [ 5370/14785]  eta: 1:47:57  lr: 0.000300  loss: 0.3388 (0.3898)  loss_objectness: 0.1330 (0.1573)  loss_rpn_box_reg: 0.2067 (0.2325)  time: 0.6266  data: 0.2553  max mem: 3615\n",
      "Training Epoch: [0]  [ 5380/14785]  eta: 1:47:50  lr: 0.000300  loss: 0.3522 (0.3897)  loss_objectness: 0.1213 (0.1573)  loss_rpn_box_reg: 0.2067 (0.2325)  time: 0.6420  data: 0.2672  max mem: 3615\n",
      "Training Epoch: [0]  [ 5390/14785]  eta: 1:47:42  lr: 0.000300  loss: 0.3086 (0.3895)  loss_objectness: 0.1129 (0.1572)  loss_rpn_box_reg: 0.1724 (0.2323)  time: 0.6471  data: 0.2703  max mem: 3615\n",
      "Training Epoch: [0]  [ 5400/14785]  eta: 1:47:37  lr: 0.000300  loss: 0.3086 (0.3894)  loss_objectness: 0.1187 (0.1571)  loss_rpn_box_reg: 0.1552 (0.2323)  time: 0.7272  data: 0.3470  max mem: 3615\n",
      "Training Epoch: [0]  [ 5410/14785]  eta: 1:47:49  lr: 0.000300  loss: 0.3253 (0.3894)  loss_objectness: 0.1187 (0.1571)  loss_rpn_box_reg: 0.1763 (0.2323)  time: 1.2808  data: 0.9082  max mem: 3615\n",
      "Training Epoch: [0]  [ 5420/14785]  eta: 1:47:41  lr: 0.000300  loss: 0.3088 (0.3893)  loss_objectness: 0.1377 (0.1571)  loss_rpn_box_reg: 0.1676 (0.2322)  time: 1.1953  data: 0.8268  max mem: 3615\n",
      "Training Epoch: [0]  [ 5430/14785]  eta: 1:47:33  lr: 0.000300  loss: 0.3273 (0.3893)  loss_objectness: 0.1411 (0.1571)  loss_rpn_box_reg: 0.1879 (0.2322)  time: 0.6324  data: 0.2708  max mem: 3615\n",
      "Training Epoch: [0]  [ 5440/14785]  eta: 1:47:25  lr: 0.000300  loss: 0.3480 (0.3892)  loss_objectness: 0.1459 (0.1571)  loss_rpn_box_reg: 0.2169 (0.2322)  time: 0.6415  data: 0.2789  max mem: 3615\n",
      "Training Epoch: [0]  [ 5450/14785]  eta: 1:47:18  lr: 0.000300  loss: 0.3333 (0.3891)  loss_objectness: 0.1445 (0.1570)  loss_rpn_box_reg: 0.1774 (0.2321)  time: 0.6640  data: 0.2849  max mem: 3615\n",
      "Training Epoch: [0]  [ 5460/14785]  eta: 1:47:10  lr: 0.000300  loss: 0.3254 (0.3891)  loss_objectness: 0.1463 (0.1570)  loss_rpn_box_reg: 0.1894 (0.2321)  time: 0.6510  data: 0.2811  max mem: 3615\n",
      "Training Epoch: [0]  [ 5470/14785]  eta: 1:47:02  lr: 0.000300  loss: 0.3254 (0.3890)  loss_objectness: 0.1464 (0.1570)  loss_rpn_box_reg: 0.1894 (0.2320)  time: 0.6290  data: 0.2715  max mem: 3615\n",
      "Training Epoch: [0]  [ 5480/14785]  eta: 1:46:54  lr: 0.000300  loss: 0.3170 (0.3889)  loss_objectness: 0.1287 (0.1569)  loss_rpn_box_reg: 0.1724 (0.2320)  time: 0.6249  data: 0.2607  max mem: 3615\n",
      "Training Epoch: [0]  [ 5490/14785]  eta: 1:46:46  lr: 0.000300  loss: 0.3714 (0.3889)  loss_objectness: 0.1288 (0.1569)  loss_rpn_box_reg: 0.2123 (0.2320)  time: 0.6139  data: 0.2527  max mem: 3615\n",
      "Training Epoch: [0]  [ 5500/14785]  eta: 1:46:38  lr: 0.000300  loss: 0.3035 (0.3888)  loss_objectness: 0.1249 (0.1568)  loss_rpn_box_reg: 0.1813 (0.2319)  time: 0.6065  data: 0.2486  max mem: 3615\n",
      "Training Epoch: [0]  [ 5510/14785]  eta: 1:46:29  lr: 0.000300  loss: 0.3035 (0.3887)  loss_objectness: 0.1261 (0.1568)  loss_rpn_box_reg: 0.1773 (0.2319)  time: 0.6095  data: 0.2595  max mem: 3615\n",
      "Training Epoch: [0]  [ 5520/14785]  eta: 1:46:22  lr: 0.000300  loss: 0.3627 (0.3887)  loss_objectness: 0.1431 (0.1568)  loss_rpn_box_reg: 0.2061 (0.2319)  time: 0.6261  data: 0.2727  max mem: 3615\n",
      "Training Epoch: [0]  [ 5530/14785]  eta: 1:46:14  lr: 0.000300  loss: 0.3504 (0.3885)  loss_objectness: 0.1378 (0.1567)  loss_rpn_box_reg: 0.2061 (0.2318)  time: 0.6422  data: 0.2668  max mem: 3615\n",
      "Training Epoch: [0]  [ 5540/14785]  eta: 1:46:07  lr: 0.000300  loss: 0.3251 (0.3885)  loss_objectness: 0.1417 (0.1567)  loss_rpn_box_reg: 0.1977 (0.2318)  time: 0.6447  data: 0.2640  max mem: 3615\n",
      "Training Epoch: [0]  [ 5550/14785]  eta: 1:45:59  lr: 0.000300  loss: 0.3343 (0.3885)  loss_objectness: 0.1435 (0.1567)  loss_rpn_box_reg: 0.1677 (0.2318)  time: 0.6433  data: 0.2705  max mem: 3615\n",
      "Training Epoch: [0]  [ 5560/14785]  eta: 1:45:51  lr: 0.000300  loss: 0.3216 (0.3884)  loss_objectness: 0.1249 (0.1567)  loss_rpn_box_reg: 0.1677 (0.2317)  time: 0.6429  data: 0.2701  max mem: 3615\n",
      "Training Epoch: [0]  [ 5570/14785]  eta: 1:45:44  lr: 0.000300  loss: 0.2895 (0.3883)  loss_objectness: 0.1354 (0.1567)  loss_rpn_box_reg: 0.1636 (0.2316)  time: 0.6425  data: 0.2593  max mem: 3615\n",
      "Training Epoch: [0]  [ 5580/14785]  eta: 1:45:36  lr: 0.000300  loss: 0.3255 (0.3883)  loss_objectness: 0.1454 (0.1567)  loss_rpn_box_reg: 0.1767 (0.2316)  time: 0.6327  data: 0.2557  max mem: 3615\n",
      "Training Epoch: [0]  [ 5590/14785]  eta: 1:45:28  lr: 0.000300  loss: 0.3415 (0.3882)  loss_objectness: 0.1546 (0.1567)  loss_rpn_box_reg: 0.2153 (0.2316)  time: 0.6342  data: 0.2625  max mem: 3615\n",
      "Training Epoch: [0]  [ 5600/14785]  eta: 1:45:20  lr: 0.000300  loss: 0.3448 (0.3882)  loss_objectness: 0.1395 (0.1566)  loss_rpn_box_reg: 0.2209 (0.2316)  time: 0.6173  data: 0.2585  max mem: 3615\n",
      "Training Epoch: [0]  [ 5610/14785]  eta: 1:45:12  lr: 0.000300  loss: 0.3749 (0.3883)  loss_objectness: 0.1432 (0.1567)  loss_rpn_box_reg: 0.2406 (0.2316)  time: 0.6108  data: 0.2649  max mem: 3615\n",
      "Training Epoch: [0]  [ 5620/14785]  eta: 1:45:04  lr: 0.000300  loss: 0.3958 (0.3883)  loss_objectness: 0.1715 (0.1567)  loss_rpn_box_reg: 0.2553 (0.2316)  time: 0.6384  data: 0.2758  max mem: 3615\n",
      "Training Epoch: [0]  [ 5630/14785]  eta: 1:44:56  lr: 0.000300  loss: 0.3787 (0.3883)  loss_objectness: 0.1616 (0.1567)  loss_rpn_box_reg: 0.2323 (0.2316)  time: 0.6273  data: 0.2649  max mem: 3615\n",
      "Training Epoch: [0]  [ 5640/14785]  eta: 1:44:49  lr: 0.000300  loss: 0.3776 (0.3882)  loss_objectness: 0.1339 (0.1567)  loss_rpn_box_reg: 0.2323 (0.2316)  time: 0.6289  data: 0.2617  max mem: 3615\n",
      "Training Epoch: [0]  [ 5650/14785]  eta: 1:44:41  lr: 0.000300  loss: 0.3340 (0.3882)  loss_objectness: 0.1242 (0.1566)  loss_rpn_box_reg: 0.2111 (0.2316)  time: 0.6397  data: 0.2660  max mem: 3615\n",
      "Training Epoch: [0]  [ 5660/14785]  eta: 1:44:33  lr: 0.000300  loss: 0.2921 (0.3881)  loss_objectness: 0.1231 (0.1566)  loss_rpn_box_reg: 0.1665 (0.2315)  time: 0.6261  data: 0.2607  max mem: 3615\n",
      "Training Epoch: [0]  [ 5670/14785]  eta: 1:44:25  lr: 0.000300  loss: 0.3882 (0.3883)  loss_objectness: 0.1518 (0.1566)  loss_rpn_box_reg: 0.1989 (0.2317)  time: 0.6281  data: 0.2694  max mem: 3615\n",
      "Training Epoch: [0]  [ 5680/14785]  eta: 1:44:17  lr: 0.000300  loss: 0.3909 (0.3884)  loss_objectness: 0.1642 (0.1566)  loss_rpn_box_reg: 0.2340 (0.2317)  time: 0.6185  data: 0.2655  max mem: 3615\n",
      "Training Epoch: [0]  [ 5690/14785]  eta: 1:44:09  lr: 0.000300  loss: 0.3097 (0.3883)  loss_objectness: 0.1498 (0.1566)  loss_rpn_box_reg: 0.1909 (0.2316)  time: 0.6183  data: 0.2495  max mem: 3615\n",
      "Training Epoch: [0]  [ 5700/14785]  eta: 1:44:01  lr: 0.000300  loss: 0.3053 (0.3882)  loss_objectness: 0.1385 (0.1566)  loss_rpn_box_reg: 0.1625 (0.2316)  time: 0.6326  data: 0.2540  max mem: 3615\n",
      "Training Epoch: [0]  [ 5710/14785]  eta: 1:43:54  lr: 0.000300  loss: 0.3113 (0.3881)  loss_objectness: 0.1428 (0.1565)  loss_rpn_box_reg: 0.1625 (0.2316)  time: 0.6314  data: 0.2630  max mem: 3615\n",
      "Training Epoch: [0]  [ 5720/14785]  eta: 1:43:45  lr: 0.000300  loss: 0.3165 (0.3880)  loss_objectness: 0.1277 (0.1565)  loss_rpn_box_reg: 0.1688 (0.2315)  time: 0.6187  data: 0.2572  max mem: 3615\n",
      "Training Epoch: [0]  [ 5730/14785]  eta: 1:43:37  lr: 0.000300  loss: 0.2728 (0.3878)  loss_objectness: 0.1277 (0.1565)  loss_rpn_box_reg: 0.1602 (0.2314)  time: 0.6054  data: 0.2494  max mem: 3615\n",
      "Training Epoch: [0]  [ 5740/14785]  eta: 1:43:30  lr: 0.000300  loss: 0.3560 (0.3879)  loss_objectness: 0.1385 (0.1565)  loss_rpn_box_reg: 0.2035 (0.2314)  time: 0.6238  data: 0.2583  max mem: 3615\n",
      "Training Epoch: [0]  [ 5750/14785]  eta: 1:43:22  lr: 0.000300  loss: 0.3702 (0.3879)  loss_objectness: 0.1385 (0.1564)  loss_rpn_box_reg: 0.2349 (0.2315)  time: 0.6410  data: 0.2675  max mem: 3615\n",
      "Training Epoch: [0]  [ 5760/14785]  eta: 1:43:14  lr: 0.000300  loss: 0.3448 (0.3878)  loss_objectness: 0.1344 (0.1564)  loss_rpn_box_reg: 0.2162 (0.2314)  time: 0.6336  data: 0.2645  max mem: 3615\n",
      "Training Epoch: [0]  [ 5770/14785]  eta: 1:43:07  lr: 0.000300  loss: 0.2532 (0.3876)  loss_objectness: 0.1220 (0.1563)  loss_rpn_box_reg: 0.1465 (0.2313)  time: 0.6302  data: 0.2596  max mem: 3615\n",
      "Training Epoch: [0]  [ 5780/14785]  eta: 1:42:59  lr: 0.000300  loss: 0.2661 (0.3876)  loss_objectness: 0.1243 (0.1563)  loss_rpn_box_reg: 0.1526 (0.2313)  time: 0.6290  data: 0.2614  max mem: 3615\n",
      "Training Epoch: [0]  [ 5790/14785]  eta: 1:43:08  lr: 0.000300  loss: 0.3030 (0.3877)  loss_objectness: 0.1332 (0.1563)  loss_rpn_box_reg: 0.1840 (0.2313)  time: 1.1776  data: 0.8208  max mem: 3615\n",
      "Training Epoch: [0]  [ 5800/14785]  eta: 1:43:02  lr: 0.000300  loss: 0.3123 (0.3876)  loss_objectness: 0.1290 (0.1563)  loss_rpn_box_reg: 0.1840 (0.2313)  time: 1.2400  data: 0.8835  max mem: 3615\n",
      "Training Epoch: [0]  [ 5810/14785]  eta: 1:42:54  lr: 0.000300  loss: 0.3169 (0.3877)  loss_objectness: 0.1332 (0.1563)  loss_rpn_box_reg: 0.1979 (0.2313)  time: 0.6895  data: 0.3303  max mem: 3615\n",
      "Training Epoch: [0]  [ 5820/14785]  eta: 1:42:46  lr: 0.000300  loss: 0.4269 (0.3877)  loss_objectness: 0.1616 (0.1563)  loss_rpn_box_reg: 0.2499 (0.2314)  time: 0.6211  data: 0.2653  max mem: 3615\n",
      "Training Epoch: [0]  [ 5830/14785]  eta: 1:42:39  lr: 0.000300  loss: 0.3852 (0.3877)  loss_objectness: 0.1437 (0.1563)  loss_rpn_box_reg: 0.2195 (0.2314)  time: 0.6279  data: 0.2568  max mem: 3615\n",
      "Training Epoch: [0]  [ 5840/14785]  eta: 1:42:31  lr: 0.000300  loss: 0.3646 (0.3877)  loss_objectness: 0.1364 (0.1563)  loss_rpn_box_reg: 0.2231 (0.2314)  time: 0.6391  data: 0.2571  max mem: 3615\n",
      "Training Epoch: [0]  [ 5850/14785]  eta: 1:42:23  lr: 0.000300  loss: 0.3768 (0.3877)  loss_objectness: 0.1467 (0.1563)  loss_rpn_box_reg: 0.2247 (0.2314)  time: 0.6359  data: 0.2602  max mem: 3615\n",
      "Training Epoch: [0]  [ 5860/14785]  eta: 1:42:16  lr: 0.000300  loss: 0.3659 (0.3877)  loss_objectness: 0.1473 (0.1562)  loss_rpn_box_reg: 0.2169 (0.2314)  time: 0.6282  data: 0.2534  max mem: 3615\n",
      "Training Epoch: [0]  [ 5870/14785]  eta: 1:42:08  lr: 0.000300  loss: 0.3279 (0.3876)  loss_objectness: 0.1293 (0.1562)  loss_rpn_box_reg: 0.2067 (0.2314)  time: 0.6329  data: 0.2563  max mem: 3615\n",
      "Training Epoch: [0]  [ 5880/14785]  eta: 1:42:00  lr: 0.000300  loss: 0.3121 (0.3874)  loss_objectness: 0.1268 (0.1561)  loss_rpn_box_reg: 0.1927 (0.2313)  time: 0.6287  data: 0.2551  max mem: 3615\n",
      "Training Epoch: [0]  [ 5890/14785]  eta: 1:41:52  lr: 0.000300  loss: 0.3373 (0.3876)  loss_objectness: 0.1309 (0.1561)  loss_rpn_box_reg: 0.1993 (0.2315)  time: 0.6146  data: 0.2549  max mem: 3615\n",
      "Training Epoch: [0]  [ 5900/14785]  eta: 1:41:44  lr: 0.000300  loss: 0.3523 (0.3875)  loss_objectness: 0.1427 (0.1561)  loss_rpn_box_reg: 0.2197 (0.2314)  time: 0.6036  data: 0.2597  max mem: 3615\n",
      "Training Epoch: [0]  [ 5910/14785]  eta: 1:41:36  lr: 0.000300  loss: 0.3716 (0.3876)  loss_objectness: 0.1579 (0.1562)  loss_rpn_box_reg: 0.1882 (0.2314)  time: 0.5984  data: 0.2544  max mem: 3615\n",
      "Training Epoch: [0]  [ 5920/14785]  eta: 1:41:28  lr: 0.000300  loss: 0.3716 (0.3875)  loss_objectness: 0.1463 (0.1562)  loss_rpn_box_reg: 0.2110 (0.2314)  time: 0.6157  data: 0.2561  max mem: 3615\n",
      "Training Epoch: [0]  [ 5930/14785]  eta: 1:41:20  lr: 0.000300  loss: 0.3084 (0.3874)  loss_objectness: 0.1339 (0.1561)  loss_rpn_box_reg: 0.1880 (0.2313)  time: 0.6167  data: 0.2599  max mem: 3615\n",
      "Training Epoch: [0]  [ 5940/14785]  eta: 1:41:12  lr: 0.000300  loss: 0.3164 (0.3875)  loss_objectness: 0.1417 (0.1561)  loss_rpn_box_reg: 0.1965 (0.2313)  time: 0.6266  data: 0.2708  max mem: 3615\n",
      "Training Epoch: [0]  [ 5950/14785]  eta: 1:41:05  lr: 0.000300  loss: 0.3836 (0.3875)  loss_objectness: 0.1444 (0.1561)  loss_rpn_box_reg: 0.2746 (0.2313)  time: 0.6406  data: 0.2730  max mem: 3615\n",
      "Training Epoch: [0]  [ 5960/14785]  eta: 1:40:57  lr: 0.000300  loss: 0.3639 (0.3874)  loss_objectness: 0.1501 (0.1561)  loss_rpn_box_reg: 0.2234 (0.2313)  time: 0.6171  data: 0.2626  max mem: 3615\n",
      "Training Epoch: [0]  [ 5970/14785]  eta: 1:40:49  lr: 0.000300  loss: 0.3639 (0.3874)  loss_objectness: 0.1544 (0.1561)  loss_rpn_box_reg: 0.2054 (0.2313)  time: 0.6102  data: 0.2473  max mem: 3615\n",
      "Training Epoch: [0]  [ 5980/14785]  eta: 1:40:41  lr: 0.000300  loss: 0.3535 (0.3874)  loss_objectness: 0.1547 (0.1561)  loss_rpn_box_reg: 0.1785 (0.2312)  time: 0.6106  data: 0.2442  max mem: 3615\n",
      "Training Epoch: [0]  [ 5990/14785]  eta: 1:40:33  lr: 0.000300  loss: 0.3282 (0.3873)  loss_objectness: 0.1488 (0.1561)  loss_rpn_box_reg: 0.1717 (0.2312)  time: 0.6148  data: 0.2590  max mem: 3615\n",
      "Training Epoch: [0]  [ 6000/14785]  eta: 1:40:25  lr: 0.000300  loss: 0.3282 (0.3872)  loss_objectness: 0.1275 (0.1561)  loss_rpn_box_reg: 0.1913 (0.2311)  time: 0.6241  data: 0.2568  max mem: 3615\n",
      "Training Epoch: [0]  [ 6010/14785]  eta: 1:40:17  lr: 0.000300  loss: 0.3095 (0.3872)  loss_objectness: 0.1397 (0.1561)  loss_rpn_box_reg: 0.1820 (0.2311)  time: 0.6199  data: 0.2520  max mem: 3615\n",
      "Training Epoch: [0]  [ 6020/14785]  eta: 1:40:09  lr: 0.000300  loss: 0.3095 (0.3872)  loss_objectness: 0.1487 (0.1561)  loss_rpn_box_reg: 0.1820 (0.2311)  time: 0.6137  data: 0.2627  max mem: 3615\n",
      "Training Epoch: [0]  [ 6030/14785]  eta: 1:40:02  lr: 0.000300  loss: 0.3201 (0.3872)  loss_objectness: 0.1233 (0.1560)  loss_rpn_box_reg: 0.2122 (0.2311)  time: 0.6254  data: 0.2614  max mem: 3615\n",
      "Training Epoch: [0]  [ 6040/14785]  eta: 1:39:54  lr: 0.000300  loss: 0.3362 (0.3871)  loss_objectness: 0.1309 (0.1560)  loss_rpn_box_reg: 0.2122 (0.2311)  time: 0.6378  data: 0.2519  max mem: 3615\n",
      "Training Epoch: [0]  [ 6050/14785]  eta: 1:39:46  lr: 0.000300  loss: 0.3270 (0.3870)  loss_objectness: 0.1293 (0.1560)  loss_rpn_box_reg: 0.1978 (0.2310)  time: 0.6270  data: 0.2550  max mem: 3615\n",
      "Training Epoch: [0]  [ 6060/14785]  eta: 1:39:39  lr: 0.000300  loss: 0.3341 (0.3870)  loss_objectness: 0.1322 (0.1560)  loss_rpn_box_reg: 0.1978 (0.2310)  time: 0.6182  data: 0.2593  max mem: 3615\n",
      "Training Epoch: [0]  [ 6070/14785]  eta: 1:39:31  lr: 0.000300  loss: 0.3497 (0.3869)  loss_objectness: 0.1346 (0.1560)  loss_rpn_box_reg: 0.2072 (0.2310)  time: 0.6318  data: 0.2571  max mem: 3615\n",
      "Training Epoch: [0]  [ 6080/14785]  eta: 1:39:23  lr: 0.000300  loss: 0.3577 (0.3869)  loss_objectness: 0.1448 (0.1559)  loss_rpn_box_reg: 0.2021 (0.2309)  time: 0.6351  data: 0.2497  max mem: 3615\n",
      "Training Epoch: [0]  [ 6090/14785]  eta: 1:39:16  lr: 0.000300  loss: 0.3524 (0.3868)  loss_objectness: 0.1395 (0.1559)  loss_rpn_box_reg: 0.2041 (0.2309)  time: 0.6197  data: 0.2528  max mem: 3615\n",
      "Training Epoch: [0]  [ 6100/14785]  eta: 1:39:08  lr: 0.000300  loss: 0.3413 (0.3868)  loss_objectness: 0.1317 (0.1559)  loss_rpn_box_reg: 0.2103 (0.2309)  time: 0.6078  data: 0.2545  max mem: 3615\n",
      "Training Epoch: [0]  [ 6110/14785]  eta: 1:39:00  lr: 0.000300  loss: 0.3288 (0.3867)  loss_objectness: 0.1312 (0.1559)  loss_rpn_box_reg: 0.1982 (0.2309)  time: 0.6064  data: 0.2516  max mem: 3615\n",
      "Training Epoch: [0]  [ 6120/14785]  eta: 1:38:52  lr: 0.000300  loss: 0.3066 (0.3867)  loss_objectness: 0.1318 (0.1559)  loss_rpn_box_reg: 0.1754 (0.2308)  time: 0.6169  data: 0.2527  max mem: 3615\n",
      "Training Epoch: [0]  [ 6130/14785]  eta: 1:38:44  lr: 0.000300  loss: 0.3253 (0.3867)  loss_objectness: 0.1568 (0.1559)  loss_rpn_box_reg: 0.2085 (0.2308)  time: 0.6258  data: 0.2519  max mem: 3615\n",
      "Training Epoch: [0]  [ 6140/14785]  eta: 1:38:36  lr: 0.000300  loss: 0.3325 (0.3868)  loss_objectness: 0.1545 (0.1559)  loss_rpn_box_reg: 0.2236 (0.2309)  time: 0.6197  data: 0.2536  max mem: 3615\n",
      "Training Epoch: [0]  [ 6150/14785]  eta: 1:38:28  lr: 0.000300  loss: 0.3820 (0.3868)  loss_objectness: 0.1545 (0.1559)  loss_rpn_box_reg: 0.2108 (0.2309)  time: 0.6072  data: 0.2556  max mem: 3615\n",
      "Training Epoch: [0]  [ 6160/14785]  eta: 1:38:21  lr: 0.000300  loss: 0.3423 (0.3867)  loss_objectness: 0.1127 (0.1558)  loss_rpn_box_reg: 0.2037 (0.2308)  time: 0.6104  data: 0.2496  max mem: 3615\n",
      "Training Epoch: [0]  [ 6170/14785]  eta: 1:38:13  lr: 0.000300  loss: 0.3067 (0.3867)  loss_objectness: 0.1083 (0.1558)  loss_rpn_box_reg: 0.2037 (0.2309)  time: 0.6215  data: 0.2526  max mem: 3615\n",
      "Training Epoch: [0]  [ 6180/14785]  eta: 1:38:05  lr: 0.000300  loss: 0.3544 (0.3867)  loss_objectness: 0.1390 (0.1558)  loss_rpn_box_reg: 0.2208 (0.2309)  time: 0.6275  data: 0.2586  max mem: 3615\n",
      "Training Epoch: [0]  [ 6190/14785]  eta: 1:37:58  lr: 0.000300  loss: 0.3442 (0.3867)  loss_objectness: 0.1414 (0.1558)  loss_rpn_box_reg: 0.1887 (0.2309)  time: 0.6355  data: 0.2537  max mem: 3615\n",
      "Training Epoch: [0]  [ 6200/14785]  eta: 1:37:51  lr: 0.000300  loss: 0.3268 (0.3866)  loss_objectness: 0.1319 (0.1558)  loss_rpn_box_reg: 0.1898 (0.2309)  time: 0.6430  data: 0.2542  max mem: 3615\n",
      "Training Epoch: [0]  [ 6210/14785]  eta: 1:37:50  lr: 0.000300  loss: 0.3277 (0.3866)  loss_objectness: 0.1281 (0.1557)  loss_rpn_box_reg: 0.2082 (0.2308)  time: 0.8965  data: 0.5203  max mem: 3615\n",
      "Training Epoch: [0]  [ 6220/14785]  eta: 1:37:43  lr: 0.000300  loss: 0.3739 (0.3866)  loss_objectness: 0.1356 (0.1557)  loss_rpn_box_reg: 0.2519 (0.2309)  time: 0.8971  data: 0.5267  max mem: 3615\n",
      "Training Epoch: [0]  [ 6230/14785]  eta: 1:37:35  lr: 0.000300  loss: 0.4921 (0.3868)  loss_objectness: 0.1532 (0.1558)  loss_rpn_box_reg: 0.3089 (0.2310)  time: 0.6338  data: 0.2757  max mem: 3615\n",
      "Training Epoch: [0]  [ 6240/14785]  eta: 1:37:28  lr: 0.000300  loss: 0.4274 (0.3868)  loss_objectness: 0.1496 (0.1558)  loss_rpn_box_reg: 0.3092 (0.2310)  time: 0.6343  data: 0.2767  max mem: 3615\n",
      "Training Epoch: [0]  [ 6250/14785]  eta: 1:37:20  lr: 0.000300  loss: 0.3238 (0.3866)  loss_objectness: 0.1391 (0.1557)  loss_rpn_box_reg: 0.1765 (0.2309)  time: 0.6361  data: 0.2643  max mem: 3615\n",
      "Training Epoch: [0]  [ 6260/14785]  eta: 1:37:12  lr: 0.000300  loss: 0.3444 (0.3865)  loss_objectness: 0.1160 (0.1557)  loss_rpn_box_reg: 0.1765 (0.2309)  time: 0.6260  data: 0.2566  max mem: 3615\n",
      "Training Epoch: [0]  [ 6270/14785]  eta: 1:37:05  lr: 0.000300  loss: 0.3419 (0.3864)  loss_objectness: 0.1218 (0.1556)  loss_rpn_box_reg: 0.1810 (0.2308)  time: 0.6340  data: 0.2585  max mem: 3615\n",
      "Training Epoch: [0]  [ 6280/14785]  eta: 1:36:58  lr: 0.000300  loss: 0.3391 (0.3864)  loss_objectness: 0.1246 (0.1556)  loss_rpn_box_reg: 0.2030 (0.2308)  time: 0.6497  data: 0.2666  max mem: 3615\n",
      "Training Epoch: [0]  [ 6290/14785]  eta: 1:36:50  lr: 0.000300  loss: 0.3076 (0.3863)  loss_objectness: 0.1446 (0.1556)  loss_rpn_box_reg: 0.1842 (0.2307)  time: 0.6369  data: 0.2618  max mem: 3615\n",
      "Training Epoch: [0]  [ 6300/14785]  eta: 1:36:42  lr: 0.000300  loss: 0.3033 (0.3862)  loss_objectness: 0.1399 (0.1556)  loss_rpn_box_reg: 0.1430 (0.2307)  time: 0.6221  data: 0.2477  max mem: 3615\n",
      "Training Epoch: [0]  [ 6310/14785]  eta: 1:36:34  lr: 0.000300  loss: 0.2815 (0.3862)  loss_objectness: 0.1257 (0.1555)  loss_rpn_box_reg: 0.1530 (0.2306)  time: 0.6118  data: 0.2486  max mem: 3615\n",
      "Training Epoch: [0]  [ 6320/14785]  eta: 1:36:27  lr: 0.000300  loss: 0.2815 (0.3861)  loss_objectness: 0.1389 (0.1555)  loss_rpn_box_reg: 0.1530 (0.2306)  time: 0.6138  data: 0.2518  max mem: 3615\n",
      "Training Epoch: [0]  [ 6330/14785]  eta: 1:36:19  lr: 0.000300  loss: 0.3255 (0.3861)  loss_objectness: 0.1272 (0.1555)  loss_rpn_box_reg: 0.1746 (0.2306)  time: 0.6208  data: 0.2510  max mem: 3615\n",
      "Training Epoch: [0]  [ 6340/14785]  eta: 1:36:12  lr: 0.000300  loss: 0.3573 (0.3861)  loss_objectness: 0.1245 (0.1555)  loss_rpn_box_reg: 0.2383 (0.2306)  time: 0.6215  data: 0.2585  max mem: 3615\n",
      "Training Epoch: [0]  [ 6350/14785]  eta: 1:36:04  lr: 0.000300  loss: 0.3573 (0.3860)  loss_objectness: 0.1339 (0.1554)  loss_rpn_box_reg: 0.2361 (0.2306)  time: 0.6246  data: 0.2560  max mem: 3615\n",
      "Training Epoch: [0]  [ 6360/14785]  eta: 1:35:56  lr: 0.000300  loss: 0.3651 (0.3861)  loss_objectness: 0.1283 (0.1554)  loss_rpn_box_reg: 0.2414 (0.2307)  time: 0.6251  data: 0.2492  max mem: 3615\n",
      "Training Epoch: [0]  [ 6370/14785]  eta: 1:35:49  lr: 0.000300  loss: 0.3790 (0.3861)  loss_objectness: 0.1283 (0.1554)  loss_rpn_box_reg: 0.2358 (0.2307)  time: 0.6277  data: 0.2590  max mem: 3615\n",
      "Training Epoch: [0]  [ 6380/14785]  eta: 1:35:41  lr: 0.000300  loss: 0.3698 (0.3860)  loss_objectness: 0.1294 (0.1554)  loss_rpn_box_reg: 0.2229 (0.2306)  time: 0.6266  data: 0.2582  max mem: 3615\n",
      "Training Epoch: [0]  [ 6390/14785]  eta: 1:35:33  lr: 0.000300  loss: 0.3371 (0.3860)  loss_objectness: 0.1392 (0.1554)  loss_rpn_box_reg: 0.1846 (0.2306)  time: 0.6239  data: 0.2526  max mem: 3615\n",
      "Training Epoch: [0]  [ 6400/14785]  eta: 1:35:26  lr: 0.000300  loss: 0.3533 (0.3860)  loss_objectness: 0.1413 (0.1553)  loss_rpn_box_reg: 0.2197 (0.2306)  time: 0.6118  data: 0.2552  max mem: 3615\n",
      "Training Epoch: [0]  [ 6410/14785]  eta: 1:35:18  lr: 0.000300  loss: 0.3533 (0.3860)  loss_objectness: 0.1397 (0.1553)  loss_rpn_box_reg: 0.2123 (0.2306)  time: 0.6119  data: 0.2526  max mem: 3615\n",
      "Training Epoch: [0]  [ 6420/14785]  eta: 1:35:10  lr: 0.000300  loss: 0.3421 (0.3859)  loss_objectness: 0.1320 (0.1553)  loss_rpn_box_reg: 0.1877 (0.2306)  time: 0.6192  data: 0.2528  max mem: 3615\n",
      "Training Epoch: [0]  [ 6430/14785]  eta: 1:35:03  lr: 0.000300  loss: 0.2935 (0.3858)  loss_objectness: 0.1294 (0.1553)  loss_rpn_box_reg: 0.1831 (0.2305)  time: 0.6319  data: 0.2530  max mem: 3615\n",
      "Training Epoch: [0]  [ 6440/14785]  eta: 1:34:55  lr: 0.000300  loss: 0.3002 (0.3857)  loss_objectness: 0.1216 (0.1552)  loss_rpn_box_reg: 0.1743 (0.2305)  time: 0.6349  data: 0.2491  max mem: 3615\n",
      "Training Epoch: [0]  [ 6450/14785]  eta: 1:34:48  lr: 0.000300  loss: 0.3394 (0.3857)  loss_objectness: 0.1204 (0.1552)  loss_rpn_box_reg: 0.1981 (0.2304)  time: 0.6238  data: 0.2494  max mem: 3615\n",
      "Training Epoch: [0]  [ 6460/14785]  eta: 1:34:40  lr: 0.000300  loss: 0.3540 (0.3856)  loss_objectness: 0.1337 (0.1552)  loss_rpn_box_reg: 0.2010 (0.2304)  time: 0.6170  data: 0.2478  max mem: 3615\n",
      "Training Epoch: [0]  [ 6470/14785]  eta: 1:34:32  lr: 0.000300  loss: 0.3500 (0.3856)  loss_objectness: 0.1340 (0.1552)  loss_rpn_box_reg: 0.2111 (0.2304)  time: 0.5990  data: 0.2447  max mem: 3615\n",
      "Training Epoch: [0]  [ 6480/14785]  eta: 1:34:24  lr: 0.000300  loss: 0.3593 (0.3856)  loss_objectness: 0.1503 (0.1552)  loss_rpn_box_reg: 0.1974 (0.2305)  time: 0.6042  data: 0.2479  max mem: 3615\n",
      "Training Epoch: [0]  [ 6490/14785]  eta: 1:34:17  lr: 0.000300  loss: 0.3593 (0.3856)  loss_objectness: 0.1503 (0.1552)  loss_rpn_box_reg: 0.1943 (0.2304)  time: 0.6257  data: 0.2584  max mem: 3615\n",
      "Training Epoch: [0]  [ 6500/14785]  eta: 1:34:10  lr: 0.000300  loss: 0.3689 (0.3856)  loss_objectness: 0.1372 (0.1552)  loss_rpn_box_reg: 0.2327 (0.2305)  time: 0.6314  data: 0.2655  max mem: 3615\n",
      "Training Epoch: [0]  [ 6510/14785]  eta: 1:34:02  lr: 0.000300  loss: 0.3688 (0.3856)  loss_objectness: 0.1362 (0.1552)  loss_rpn_box_reg: 0.2327 (0.2304)  time: 0.6277  data: 0.2607  max mem: 3615\n",
      "Training Epoch: [0]  [ 6520/14785]  eta: 1:33:54  lr: 0.000300  loss: 0.3266 (0.3855)  loss_objectness: 0.1240 (0.1551)  loss_rpn_box_reg: 0.1742 (0.2304)  time: 0.6260  data: 0.2588  max mem: 3615\n",
      "Training Epoch: [0]  [ 6530/14785]  eta: 1:33:47  lr: 0.000300  loss: 0.3452 (0.3855)  loss_objectness: 0.1248 (0.1551)  loss_rpn_box_reg: 0.1843 (0.2304)  time: 0.6230  data: 0.2556  max mem: 3615\n",
      "Training Epoch: [0]  [ 6540/14785]  eta: 1:33:39  lr: 0.000300  loss: 0.3490 (0.3854)  loss_objectness: 0.1328 (0.1551)  loss_rpn_box_reg: 0.2046 (0.2304)  time: 0.6275  data: 0.2497  max mem: 3615\n",
      "Training Epoch: [0]  [ 6550/14785]  eta: 1:33:32  lr: 0.000300  loss: 0.3068 (0.3853)  loss_objectness: 0.1328 (0.1550)  loss_rpn_box_reg: 0.1786 (0.2303)  time: 0.6382  data: 0.2493  max mem: 3615\n",
      "Training Epoch: [0]  [ 6560/14785]  eta: 1:33:24  lr: 0.000300  loss: 0.3495 (0.3855)  loss_objectness: 0.1373 (0.1550)  loss_rpn_box_reg: 0.1992 (0.2304)  time: 0.6217  data: 0.2524  max mem: 3615\n",
      "Training Epoch: [0]  [ 6570/14785]  eta: 1:33:17  lr: 0.000300  loss: 0.4735 (0.3856)  loss_objectness: 0.1635 (0.1551)  loss_rpn_box_reg: 0.2983 (0.2305)  time: 0.6088  data: 0.2584  max mem: 3615\n",
      "Training Epoch: [0]  [ 6580/14785]  eta: 1:33:09  lr: 0.000300  loss: 0.3534 (0.3855)  loss_objectness: 0.1244 (0.1550)  loss_rpn_box_reg: 0.2087 (0.2305)  time: 0.6192  data: 0.2585  max mem: 3615\n",
      "Training Epoch: [0]  [ 6590/14785]  eta: 1:33:02  lr: 0.000300  loss: 0.3350 (0.3854)  loss_objectness: 0.1299 (0.1550)  loss_rpn_box_reg: 0.1816 (0.2305)  time: 0.6305  data: 0.2483  max mem: 3615\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All bounding boxes should have positive height and width. Found invalid box [494.1076354980469, 647.2166137695312, 495.8232421875, 647.2166137695312] for target at index 2.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 10>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# CLIP-RPN creates an RPN for training and uses CLIP to classify the regions of interest\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# CLIP-Backbone-FRCNN creates a FRCNN using CLIP features as the model backbone\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# CLIP-FRCNN creates a FRCNN using CLIP features as the model backbone, and embeds the rois using CLIP's embedding\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Fully custom vanilla uses a pre-trained resnet50 backbone, and generates new anchor generator and roi pooling\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Custom-Vanilla uses the pre-trained FRCNN from pytorch and replaces the roi heads only\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m      8\u001B[0m model \u001B[38;5;241m=\u001B[39m create_model(MODEL_TYPE, item_list)\n\u001B[1;32m---> 10\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNUM_EPOCHS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMODEL_TYPE\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMODEL_TYPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mWEIGHTS_NAME\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrpn_full_training\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCONTINUE_TRAINING\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Github\\Git\\TORCH_CLIP_FRCNN_Trainable\\engine.py:184\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_dataset, validation_dataset, num_epochs, MODEL_TYPE, batch_size, WEIGHTS_NAME, CONTINUE_TRAINING)\u001B[0m\n\u001B[0;32m    180\u001B[0m best_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m9999\u001B[39m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m epoch \u001B[38;5;241m<\u001B[39m num_epochs:\n\u001B[0;32m    182\u001B[0m \n\u001B[0;32m    183\u001B[0m     \u001B[38;5;66;03m# train for one epoch, printing every 10 iterations\u001B[39;00m\n\u001B[1;32m--> 184\u001B[0m     training_metrics \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_data_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDEVICE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscaler\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    186\u001B[0m     \u001B[38;5;66;03m# if MODEL_TYPE == 'CLIP-FRCNN':  # check that we dont change the weights from the backbone\u001B[39;00m\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;66;03m#     weight_tester.test(model)\u001B[39;00m\n\u001B[0;32m    189\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m5\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:  \u001B[38;5;66;03m#evaluate the mAP of the model every 3 epochs\u001B[39;00m\n\u001B[0;32m    190\u001B[0m         \u001B[38;5;66;03m# evaluate on the test dataset\u001B[39;00m\n",
      "File \u001B[1;32mG:\\Github\\Git\\TORCH_CLIP_FRCNN_Trainable\\engine.py:38\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[1;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler, training)\u001B[0m\n\u001B[0;32m     36\u001B[0m targets \u001B[38;5;241m=\u001B[39m [{k: v\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m t\u001B[38;5;241m.\u001B[39mitems()} \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m targets]\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast(enabled\u001B[38;5;241m=\u001B[39mscaler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m---> 38\u001B[0m     loss_dict \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;66;03m#del loss_dict['loss_classifier'] #for the CLIP model, we do not use classification loss\u001B[39;00m\n\u001B[0;32m     42\u001B[0m     losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(loss \u001B[38;5;28;01mfor\u001B[39;00m loss \u001B[38;5;129;01min\u001B[39;00m loss_dict\u001B[38;5;241m.\u001B[39mvalues())\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\torch-frcnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mG:\\Github\\Git\\TORCH_CLIP_FRCNN_Trainable\\custom_rpn.py:92\u001B[0m, in \u001B[0;36mZeroShotOD.forward\u001B[1;34m(self, images, targets)\u001B[0m\n\u001B[0;32m     90\u001B[0m             bb_idx \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mwhere(degenerate_boxes\u001B[38;5;241m.\u001B[39many(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     91\u001B[0m             degen_bb: List[\u001B[38;5;28mfloat\u001B[39m] \u001B[38;5;241m=\u001B[39m boxes[bb_idx]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m---> 92\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll bounding boxes should have positive height and width.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     93\u001B[0m                              \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Found invalid box \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m for target at index \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     94\u001B[0m                              \u001B[38;5;241m.\u001B[39mformat(degen_bb, target_idx))\n\u001B[0;32m     96\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackbone(images\u001B[38;5;241m.\u001B[39mtensors)\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(features, torch\u001B[38;5;241m.\u001B[39mTensor):\n",
      "\u001B[1;31mValueError\u001B[0m: All bounding boxes should have positive height and width. Found invalid box [494.1076354980469, 647.2166137695312, 495.8232421875, 647.2166137695312] for target at index 2."
=======
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m MODEL_TYPE\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCLIP-RPN\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# CLIP-RPN creates an RPN for training and uses CLIP to classify the regions of interest\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# CLIP-Backbone-FRCNN creates a FRCNN using CLIP features as the model backbone\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# CLIP-FRCNN creates a FRCNN using CLIP features as the model backbone, and embeds the rois using CLIP's embedding\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Fully custom vanilla uses a pre-trained resnet50 backbone, and generates new anchor generator and roi pooling\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Custom-Vanilla uses the pre-trained FRCNN from pytorch and replaces the roi heads only\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMODEL_TYPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mitem_list\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m train_model(model, train_dataset, validation_dataset, num_epochs\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mNUM_EPOCHS, MODEL_TYPE\u001B[38;5;241m=\u001B[39mMODEL_TYPE, WEIGHTS_NAME \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrpn_full_training\u001B[39m\u001B[38;5;124m'\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m, CONTINUE_TRAINING\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Documents\\Git\\TORCH_CLIP_FRCNN_Trainable\\model.py:213\u001B[0m, in \u001B[0;36mcreate_model\u001B[1;34m(model_type, classes)\u001B[0m\n\u001B[0;32m    210\u001B[0m rpn_pre_nms_top_n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(training\u001B[38;5;241m=\u001B[39mrpn_pre_nms_top_n_train, testing\u001B[38;5;241m=\u001B[39mrpn_pre_nms_top_n_test)\n\u001B[0;32m    211\u001B[0m rpn_post_nms_top_n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(training\u001B[38;5;241m=\u001B[39mrpn_post_nms_top_n_train, testing\u001B[38;5;241m=\u001B[39mrpn_post_nms_top_n_test)\n\u001B[1;32m--> 213\u001B[0m rpn \u001B[38;5;241m=\u001B[39m \u001B[43mRegionProposalNetwork\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrpn_anchor_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrpn_head\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    215\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrpn_fg_iou_thresh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrpn_bg_iou_thresh\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    216\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrpn_batch_size_per_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrpn_positive_fraction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    217\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrpn_pre_nms_top_n\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrpn_post_nms_top_n\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrpn_nms_thresh\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscore_thresh\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrpn_score_thresh\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    220\u001B[0m min_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m800\u001B[39m\n\u001B[0;32m    221\u001B[0m max_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1333\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torchvision\\models\\detection\\rpn.py:152\u001B[0m, in \u001B[0;36mRegionProposalNetwork.__init__\u001B[1;34m(self, anchor_generator, head, fg_iou_thresh, bg_iou_thresh, batch_size_per_image, positive_fraction, pre_nms_top_n, post_nms_top_n, nms_thresh, score_thresh)\u001B[0m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;66;03m# used during testing\u001B[39;00m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pre_nms_top_n \u001B[38;5;241m=\u001B[39m pre_nms_top_n\n\u001B[1;32m--> 152\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post_nms_top_n \u001B[38;5;241m=\u001B[39m \u001B[43mpost_nms_top_n\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnms_thresh \u001B[38;5;241m=\u001B[39m nms_thresh\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscore_thresh \u001B[38;5;241m=\u001B[39m score_thresh\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torchvision\\models\\detection\\rpn.py:152\u001B[0m, in \u001B[0;36mRegionProposalNetwork.__init__\u001B[1;34m(self, anchor_generator, head, fg_iou_thresh, bg_iou_thresh, batch_size_per_image, positive_fraction, pre_nms_top_n, post_nms_top_n, nms_thresh, score_thresh)\u001B[0m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;66;03m# used during testing\u001B[39;00m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pre_nms_top_n \u001B[38;5;241m=\u001B[39m pre_nms_top_n\n\u001B[1;32m--> 152\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post_nms_top_n \u001B[38;5;241m=\u001B[39m \u001B[43mpost_nms_top_n\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnms_thresh \u001B[38;5;241m=\u001B[39m nms_thresh\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscore_thresh \u001B[38;5;241m=\u001B[39m score_thresh\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1180\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:621\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:930\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:921\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:318\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.3.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1147\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1144\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1147\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.3.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1162\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1159\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1161\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1162\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1166\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "MODEL_TYPE='CLIP-RPN'\n",
    "# CLIP-RPN creates an RPN for training and uses CLIP to classify the regions of interest\n",
    "# CLIP-Backbone-FRCNN creates a FRCNN using CLIP features as the model backbone\n",
    "# CLIP-FRCNN creates a FRCNN using CLIP features as the model backbone, and embeds the rois using CLIP's embedding\n",
    "# Fully custom vanilla uses a pre-trained resnet50 backbone, and generates new anchor generator and roi pooling\n",
    "# Custom-Vanilla uses the pre-trained FRCNN from pytorch and replaces the roi heads only\n",
    "#\n",
    "model = create_model(MODEL_TYPE, item_list)\n",
    "\n",
    "train_model(model, train_dataset, validation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, WEIGHTS_NAME = 'rpn_full_training', batch_size=8, CONTINUE_TRAINING=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "torch.save({'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict()},\n",
    "                       f'{MODEL_TYPE}_rpn_{epoch}.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# MODEL_TYPE='CLIP-FRCNN'\n",
    "# # CLIP-Backbone-FRCNN creates a FRCNN using CLIP features as the model backbone\n",
    "# # CLIP-FRCNN creates a FRCNN using CLIP features as the model backbone, and embeds the rois using CLIP's embedding\n",
    "# # Fully custom vanilla uses a pre-trained resnet50 backbone, and generates new anchor generator and roi pooling\n",
    "# # Custom-Vanilla uses the pre-trained FRCNN from pytorch and replaces the roi heads only\n",
    "# #\n",
    "# import clip\n",
    "# text_tokens = clip.tokenize([\"This is \" + desc for desc in item_list]).cuda()\n",
    "#\n",
    "# model = create_model(MODEL_TYPE, text_tokens)\n",
    "# test = False\n",
    "#\n",
    "# # print(model)\n",
    "# # print(f'rpn nms thresh: {model.rpn.nms_thresh}')\n",
    "#\n",
    "# if test:\n",
    "#     train_model(model, evaluation_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, WEIGHTS_NAME = 'box_regressors', batch_size=2)\n",
    "# else:\n",
    "#     train_model(model, train_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, WEIGHTS_NAME = 'box_regressors', batch_size=16, CONTINUE_TRAINING=True)\n",
    "#\n",
    "# #started at 0941 on 22 March 2022"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# MODEL_TYPE='CLIP-Backbone-FRCNN'\n",
    "#\n",
    "# model = create_model(MODEL_TYPE, classes=item_list)\n",
    "# test = True\n",
    "#\n",
    "# if test:\n",
    "#     train_model(model, evaluation_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=2)\n",
    "# else:\n",
    "#     train_model(model, train_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "acbb3df601244291b8b2fb9ea1137573",
      "32b6ec3046e64d04b4134553dc434fe0",
      "d8c6a316609d4ca5bfee139b93177ef5",
      "a1645bdfb02b42fba268f7000f183639",
      "4a4788a4fd6841788b20cfbf54a3d10b",
      "5d836b94d13e459d82429606496e4d4f",
      "a410071b34034a91aeda7ef1114969c2",
      "c063e7d90f6a4027b53d1b70c8c07742"
     ]
    },
    "id": "bHa6KRbEWuxz",
    "outputId": "3b4ebd0b-aa69-4a4d-b73c-b8cf24d8b461",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# #train a custom vanilla model so that we can compare and make sure the CLIP FRCNN is comparable\n",
    "# # Fully-Custom-Vanilla is most appropriate as it generates the model in a similar fashion\n",
    "# MODEL_TYPE = 'Fully-Custom-Vanilla'\n",
    "#\n",
    "# vanilla_model = create_model(MODEL_TYPE, classes=item_list)\n",
    "#\n",
    "# test = True\n",
    "#\n",
    "# if test:\n",
    "#     train_model(vanilla_model, evaluation_dataset, evaluation_dataset, num_epochs=config.NUM_EPOCHS, MODEL_TYPE=MODEL_TYPE, batch_size=2)\n",
    "# else:\n",
    "#     train_model(vanilla_model, train_dataset, evaluation_dataset, num_epochs=10, MODEL_TYPE=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj3vLT1eXFnk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkzG1i3AW1O7",
    "outputId": "ec7971c3-66ef-4a57-e710-248cb53dee8e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "add_detections(model, evaluation_dataset, fo_dataset, field_name=\"predictions\")\n",
    "\n",
    "results = fo.evaluate_detections(\n",
    "    test_view,\n",
    "    \"predictions\",\n",
    "    classes=item_list,\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uYdXrhgYdJ_",
    "outputId": "2eb792e9-342f-4dc8-f6c0-e1503d8bf193",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session.view = test_view\n",
    "results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcJBOM76aJPR",
    "outputId": "ac452527-7608-4e8d-f57e-18a0470acd30",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nddFfGSnXo7i",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "By default, objects are only matched with other objects of the same class. In order to get an interesting confusion matrix, we need to match interclass objects by setting `classwise=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_53aCMna2Vt",
    "outputId": "4db71f31-73e3-4036-f623-efd8e2ac85bf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_interclass = fo.evaluate_detections(\n",
    "    test_view, \n",
    "    \"predictions\", \n",
    "    classes=item_list,\n",
    "    compute_mAP=True, \n",
    "    classwise=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot = results.plot_pr_curves(classes=item_list)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "Nbqf-NuAZ7Ps",
    "outputId": "571cd947-c94a-4b9a-ed93-2330fbddea7e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_interclass.plot_confusion_matrix(classes=item_list, include_other=False, include_missing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElSV7tTbYKLr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The [detection evaluation](https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#detections) also added the attributes `eval_fp`, `eval_tp`, and `eval_fn` to every predicted detection indicating if it is a false positive, true positive, or false negative. \n",
    "Let's create a view to find the worst samples by sorting by `eval_fp` using the [FiftyOne App](https://voxel51.com/docs/fiftyone/user_guide/app.html) to visualize the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786,
     "resources": {
      "https://localhost:5151/polling?sessionId=de0b710e-15f8-4c57-ba46-ae7955f716b1": {
       "data": "eyJtZXNzYWdlcyI6IFtdfQ==",
       "headers": [
        [
         "access-control-allow-headers",
         "x-requested-with"
        ],
        [
         "content-type",
         "text/html; charset=UTF-8"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "Pm4Z52rd8AC1",
    "outputId": "62d39076-7ef3-4fe3-95ae-500d0f8f8a3f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session.view = test_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786,
     "resources": {
      "https://localhost:5151/polling?sessionId=ebbc318d-3578-4fb1-9ae7-68596117572b": {
       "data": "eyJtZXNzYWdlcyI6IFtdfQ==",
       "headers": [
        [
         "access-control-allow-headers",
         "x-requested-with"
        ],
        [
         "content-type",
         "text/html; charset=UTF-8"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "njLG0l5K-ucV",
    "outputId": "bda6f02d-d8fe-49be-d212-31e0e70779e3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session.view = test_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReXDVFgLZLtf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It would be best to get this [data reannotated to fix these mistakes](https://towardsdatascience.com/managing-annotation-mistakes-with-fiftyone-and-labelbox-fc6e87b51102), but in the meantime, we can easily remedy this by simply creating a new view that remaps the labels `car`, `truck`, and `bus` all to `vehicle` and then retraining the model with that. This is only possible because we are backing our data in FiftyOne and loading views into PyTorch as needed. Without FiftyOne, the PyTorch dataset class or the underlying data would need to be changed to remap these classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# map labels to single vehicle class\n",
    "vehicle_list = ['car', 'bus', 'truck']\n",
    "vehicles_map = {c: \"vehicle\" for c in vehicle_list}\n",
    "\n",
    "train_map_view = train_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "test_map_view = test_view.map_labels(\"ground_truth\", vehicles_map)\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "torch_map_dataset = FiftyOneTorchDataset(train_map_view, train_transforms)\n",
    "torch_map_dataset_test = FiftyOneTorchDataset(test_map_view, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynRCHQv8XB_v",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Only 2 classes (background and vehicle)\n",
    "MODEL_TYPE = 'Vanilla-FRCNN'\n",
    "vehicle_model = create_model(MODEL_TYPE, num_classes=(len(vehicles_map)+1))\n",
    "train_model(vehicle_model, torch_map_dataset, torch_map_dataset_test, num_epochs=2, MODEL_TYPE=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-mrVOl4XFbp",
    "outputId": "6d8bec76-ebe8-4a36-959a-52bb1aab8498",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "add_detections(vehicle_model, torch_map_dataset_test, test_map_view, field_name=\"vehicle_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfd3xvhaXhl_",
    "outputId": "d9c4a2fe-538a-4979-c3f8-f5ede0c98aa1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vehicle_results = fo.evaluate_detections(\n",
    "    test_map_view, \n",
    "    \"vehicle_predictions\", \n",
    "    classes=[\"vehicle\"], \n",
    "    eval_key=\"vehicle_eval\", \n",
    "    compute_mAP=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFvddH3rk0NR",
    "outputId": "59572ba2-f9ad-4dd2-e9ac-90877190ff99",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vehicle_results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwbhq18sk1PL",
    "outputId": "d6985867-5049-4678-cc88-d5041a0079ed",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vehicle_results.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJMAkJbWZ_u1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Due to our ability to easily visualize and manage our dataset with FiftyOne, we were able to spot and take action on a dataset issue that would otherwise have gone unnoticed if we only concerned ourselves with dataset-wide evaluation metrics and fixed dataset representations. Through these efforts, we managed to increase the mAP of the model to 43%.\n",
    "\n",
    "Even though this example workflow may not work in all situations, this kind of class-merging strategy can be effective in cases where more fine-grained discrimination is not called for."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "fiftyone_pytorch_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "torch-frcnn",
   "language": "python",
   "display_name": "torch-frcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "32b6ec3046e64d04b4134553dc434fe0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a4788a4fd6841788b20cfbf54a3d10b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5d836b94d13e459d82429606496e4d4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1645bdfb02b42fba268f7000f183639": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c063e7d90f6a4027b53d1b70c8c07742",
      "placeholder": "​",
      "style": "IPY_MODEL_a410071b34034a91aeda7ef1114969c2",
      "value": " 160M/160M [01:05&lt;00:00, 2.55MB/s]"
     }
    },
    "a410071b34034a91aeda7ef1114969c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acbb3df601244291b8b2fb9ea1137573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8c6a316609d4ca5bfee139b93177ef5",
       "IPY_MODEL_a1645bdfb02b42fba268f7000f183639"
      ],
      "layout": "IPY_MODEL_32b6ec3046e64d04b4134553dc434fe0"
     }
    },
    "c063e7d90f6a4027b53d1b70c8c07742": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8c6a316609d4ca5bfee139b93177ef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d836b94d13e459d82429606496e4d4f",
      "max": 167502836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a4788a4fd6841788b20cfbf54a3d10b",
      "value": 167502836
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}